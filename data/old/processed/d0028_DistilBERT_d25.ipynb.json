{
    "nb_idx": 28,
    "nb_name": "d0028",
    "filename": "d25.ipynb",
    "filepath": "data/data_Kaggle/raw/d25.ipynb",
    "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n \n # 0. Background\n\n\n## Introduction\nThe Titanic: Machine Learning from Disaster competition represents an engaging challenge that merges historical significance with predictive analytics. It provides an opportunity for data science enthusiasts and experts to apply machine learning techniques to a dataset that is both rich in history and complexity.\n\n## Problem Definition\nThe competition's objective is to predict survival on the Titanic, the passenger liner that sank in 1912 after colliding with an iceberg. The event holds substantial historical significance due to the loss of life, particularly because it reflected the societal norms of the era, such as class distinctions. The task of predicting survival is not merely an academic exercise but also a reflection on the human aspects behind data, underscoring the potential of machine learning in understanding human factors in historical events.\n\n## Expected Outputs\nThe expected output is a predictive model capable of determining the survival outcome for each passenger in the test set. Participants must submit a CSV file with two columns: `PassengerId` and `Survived`. The `Survived` column should contain the binary predictions: 1 for survived and 0 for did not survive. The model's performance is measured based on the accuracy of these predictions.\n\n## Dataset\nThe provided dataset consists of several attributes for each passenger aboard the Titanic:\n\n  - `PassengerId`: Unique identifier for each passenger.\n  - `Survived`: Survival status (0 = No, 1 = Yes).\n  - `Pclass`: Passenger class (1 = 1st, 2 = 2nd, 3 = 3rd).\n  - `Name`: Name of the passenger.\n  - `Sex`: Gender of the passenger (male or female).\n  - `Age`: Age of the passenger. Some entries are NaN, indicating missing values.\n  - `SibSp`: Number of siblings or spouses aboard.\n  - `Parch`: Number of parents or children aboard.\n  - `Ticket`: Ticket number.\n  - `Fare`: Passenger fare.\n  - `Cabin`: Cabin number. Contains NaN values, which represent missing data.\n  - `Embarked`: Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton).\n\nThe dataset will be used to train machine learning models that can discern patterns and associations between the features and the likelihood of survival.\n\n## Problem Type\nThe challenge is a binary classification problem, a type of supervised learning where the aim is to categorize the passengers into two groups: those who survived and those who did not. The nature of the `Survived` variable as a binary indicator makes it a clear case of classification rather than regression, which would predict continuous outcomes.\n\n## Conclusion\nThe Titanic Kaggle competition is a testbed for machine learning methodologies, offering insights into the social fabric of the early 20th century while advancing the field of data science. It presents a problem that is both historically enriching and technically stimulating, with the potential to develop predictive models that are not only accurate but also interpretative of the human stories behind the data.\nI will use a dataset containing information about those on board to develop a machine learning model that attempts to predict who survived. \n # 1. Reading the data \n # temel k\u00fct\u00fcphaneler\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n test_df = pd.read_csv('/kaggle/input/titanic/test.csv')\ndf = pd.read_csv('/kaggle/input/titanic/train.csv')\ndf \n Here's a description of the data as displayed in the DataFrame:\n\n- **Columns in the DataFrame:**\n  - `PassengerId`: Unique identifier for each passenger.\n  - `Survived`: Survival status (0 = No, 1 = Yes).\n  - `Pclass`: Passenger class (1 = 1st, 2 = 2nd, 3 = 3rd).\n  - `Name`: Name of the passenger.\n  - `Sex`: Gender of the passenger (male or female).\n  - `Age`: Age of the passenger. Some entries are NaN, indicating missing values.\n  - `SibSp`: Number of siblings or spouses aboard.\n  - `Parch`: Number of parents or children aboard.\n  - `Ticket`: Ticket number.\n  - `Fare`: Passenger fare.\n  - `Cabin`: Cabin number. Contains NaN values, which represent missing data.\n  - `Embarked`: Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton).\n\n- **Sample Data:**\n  - The first row corresponds to a male passenger with a `PassengerId` of 1, who did not survive, was in 3rd class, and embarked from Southampton (`Embarked` = S).\n  - The third row shows a female passenger, `PassengerId` 3, who survived, was in 3rd class, and also embarked from Southampton.\n  - There are some missing data points, indicated by `NaN` (not a number), especially in the `Age` and `Cabin` columns, which will require careful handling during data preprocessing for any machine learning tasks.\n\n- **Data Use:**\n  - `Survived` is the target variable for the prediction model.\n  - Other columns serve as features to train machine learning models to predict the target variable. Features like `Name` and `Ticket` might be used for feature engineering, while `Cabin` and `Age` would need to deal with missing values.\n\nThis data is  used to train classification models to predict the `Survived` column, which is a binary outcome indicating whether a passenger survived the Titanic disaster. \n # 2.Exploratory Data Analysis (EDA)  \n # 2.1 Pclass\n\n\"Pclass\" signifies the accommodation category for travelers on the Titanic, reflective of their socio-economic stature. \n\n- 1st Class: This tier was the domain of the affluent and illustrious\u2014magnates, celebrities, or distinguished personas. It offered spacious quarters and superior dining and amenities.\n\n- 2nd Class: Serving as a mid-level option, it was less opulent than 1st Class but provided a comfortable journey for middle-class travelers. The cabins were more compact, and there were fewer luxuries.\n\n- 3rd Class: This was the most basic level of travel, primarily for individuals of modest means, often immigrants or those with lesser financial resources. Accommodations were more confined, with basic amenities.\n\nThe Pclass is indicative of the passengers' financial and social ranking. It is a critical factor in survival analysis due to the potential influence of class on emergency response and evacuation procedures during the disaster. \n plt.figure(figsize=(8, 6))\nax = sns.countplot(data=df, x='Pclass')\n\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.0f'), \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha = 'center', va = 'center', \n                xytext = (0, 10), \n                textcoords = 'offset points')\n\nplt.title('Distribution of Passenger Classes')\nplt.xlabel('Passenger Class')\nplt.ylabel('Count')\nplt.show() \n Here are some observations and comments based on the chart:\n\n1. **Third Class is the Most Populous:** With 491 passengers, the Third Class had the highest number of passengers compared to the other classes. This reflects the economic demographics of the time, where a larger portion of the population were of lower socio-economic status, which also correlates with the common practice of ships carrying more third-class passengers to maximize ticket sales.\n\n2. **First Class has More Passengers than Second:** There were 216 passengers in First Class and slightly fewer, 184, in Second Class. This could indicate that the Titanic was quite luxurious and attracted a significant number of affluent passengers who could afford the higher fare for better accommodations and services.\n\n3. **Economic Implications:** The distribution shows the economic stratification of society at the time. A substantial number of people were traveling in Third Class, possibly in hope of starting a new life in America, which was a common reason for travel among immigrants during that period.\n\n4. **Implications for Survival Analysis:** Given the larger number of Third Class passengers, if resources and lifeboats were limited and preferentially allocated to higher classes, this could have significantly influenced survival rates. Historical accounts suggest that First Class passengers had better access to lifeboats, which is an important aspect to consider in survival analysis.\n\n5. **Data Visualization Insights:** The bar chart effectively communicates the difference in class sizes, which is crucial for data exploration in predictive modeling. It's a good practice to visualize data this way to understand the underlying distributions before applying machine learning algorithms.\n\n6. **Potential Bias in Model Training:** When training machine learning models on this data, the imbalance in class distribution may introduce bias. Models might perform better at predicting survival for Third Class passengers simply because there are more data points for that class.\n\nOverall, the visualization underscores the importance of considering passenger class as a feature in predictive models and as a factor in historical analyses of the Titanic disaster. \n # 2.2 Sex \n plt.figure(figsize=(8, 6))\nax = sns.countplot(data=df, x='Sex')\n\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.0f'), \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha = 'center', va = 'center', \n                xytext = (0, 10), \n                textcoords = 'offset points')\n\nplt.title('Distribution of Sex')\nplt.xlabel('Sex of Passengers')\nplt.ylabel('Count')\nplt.show() \n  Here are some insights and comments regarding the chart:\n\n1. **Gender Disparity:** The chart illustrates that there were considerably more male passengers (577) than female passengers (314) on the Titanic. This reflects the gender demographics of passengers who were traveling at that time.\n\n2. **Implications for Survival Predictions:** Historical records indicate that the protocol of \"women and children first\" was often followed during maritime disasters. Therefore, despite being outnumbered, female passengers might have had a higher survival rate compared to males, which is a critical consideration for predictive modeling.\n\n3. **Visualization Effectiveness:** The bar chart clearly demonstrates the disparity in numbers between male and female passengers. Such visualizations are important in exploratory data analysis as they provide immediate insights into the dataset's structure before any statistical modeling.\n\n4. **Influence on Model Training:** The imbalance shown here may influence the performance of machine learning models. If the model is not adjusted to account for this imbalance, it may become biased towards predicting the survival of males, simply because there are more male passengers in the dataset.\n\n5. **Historical Context:** The higher number of males might be reflective of the societal norms of the time, where men were more likely to travel alone for business or emigration purposes, while women often traveled with families.\n\n6. **Data Preparation Considerations:** When preparing the dataset for machine learning, it might be beneficial to consider techniques like stratification to ensure that both genders are adequately represented in the training and validation sets.\n\n \n # Calculate the mean survival rates by sex\nsurvival_rates = df.groupby('Sex')['Survived'].mean().reset_index()\n\n# Create the bar plot\nsns.barplot(x='Sex', y='Survived', data=survival_rates)\n\n# Adding the actual survival rates on top of the bars\nfor index, value in enumerate(survival_rates['Survived']):\n    plt.text(index, value, f'{value:.4f}', ha='center', va='bottom')\n\n# Set the title and labels for the plot\nplt.title('Survival Rates by Sex')\nplt.ylabel('Average Survival Rate')\nplt.xlabel('Sex')\n\n# Display the plot\nplt.show() \n Here are some comments and interpretations based on the chart:\n\n1. **Significant Gender-Based Survival Disparity:** The bar chart highlights a stark difference in survival rates between females and males. Female passengers had a much higher survival rate of approximately 74.2%, while the survival rate for male passengers was markedly lower at about 18.9%.\n\n \n # 2.3. Age \n sns.histplot(x=\"Age\", hue=\"Survived\", palette=\"mako\", data=df[[\"Age\",\"Survived\"]])\nplt.title(\"Age Distribution\", color='black', fontsize=14) \nplt.yticks([])\nplt.box(False)\nplt.show() \n Here are some comments and insights based on the chart:\n\n1. **Bimodal Distribution:** The age distribution appears to be bimodal, with two peaks suggesting that younger adults and children were the most common age groups among the passengers.\n\n2. **Higher Survival Rate Among Younger Passengers:** The lighter-colored bars, which represent the passengers who survived, seem more prominent in the lower age groups, suggesting that younger passengers had a higher survival rate.\n\n3. **Declining Survival with Age:** There is a noticeable decline in survival rate as age increases, particularly noticeable in passengers older than 30 years old.\n\n4. **Children's Survival:** The survival rate for very young passengers (children) seems to be high, which could be attributed to the \"women and children first\" policy during lifeboat loading.\n\n5. **Effective Visualization:** This stacked histogram effectively conveys the relationship between age and survival. It allows for easy comparison between the number of survivors and non-survivors within each age group.\n\n6. **Insights for Model Training:** For predictive modeling, this visualization suggests that age could be an important feature, potentially requiring more nuanced treatment such as binning into categorical age groups or creating age-related interaction features.\n\n \n # 2.4. SibSp \n plt.figure(figsize=(10, 6))\nax = sns.countplot(data=df, x='SibSp')\n\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.0f'), \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha = 'center', va = 'center', \n                xytext = (0, 10), \n                textcoords = 'offset points')\n\nplt.title('Distribution of Siblings Amount')\nplt.xlabel('Title of Passengers')\nplt.ylabel('Count')\nplt.show() \n Here are some observations and insights from the chart:\n\n1. **Most Passengers Traveled Alone:** A significant majority of passengers, indicated by the tallest bar with a count of 608, did not have siblings or spouses on board. This suggests that solo travel was common.\n\n2. **Smaller Family Units:** The second bar, with a count of 209, shows that a substantial number of passengers traveled with one sibling or spouse, indicating smaller family units or couples without children.\n\n3. **Rarity of Large Families:** Very few passengers traveled with more than two siblings or spouses. The counts for passengers with three or more siblings/spouses are markedly lower, which highlights the rarity of large families or sibling groups traveling together.\n\n4. **Exceptional Cases:** There are a few exceptional cases of passengers with large numbers of siblings/spouses on board, such as 5 or 8, which are very uncommon. These could potentially represent larger family groups or possibly group tickets.\n\n5. **Potential Impact on Survival:** The number of siblings/spouses could have implications for survival rates, as those with family aboard might have sought one another out during the disaster, potentially affecting their likelihood of reaching the lifeboats.\n\n\nThis chart provides a clear visual representation of the distribution of family sizes aboard the Titanic, with the majority being individuals or couples. \n **Let's examine the survival rate according to the number of siblings or spouses.**\n \n survival_by_sibsp = df.groupby('SibSp')['Survived'].mean()\n\nplt.figure(figsize=(8, 6))\nax = sns.barplot(x=survival_by_sibsp.index, y=survival_by_sibsp.values)\nplt.title('Survival Rate by SibSp')\nplt.xlabel('Number of Siblings/Spouses')\nplt.ylabel('Survival Rate')\n\ntotal = float(len(df))\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x() + p.get_width() / 2., height + 0.02, '{:.1%}'.format(height), ha=\"center\")\n\nplt.show() \n Here are some key takeaways from the chart:\n\n1. **Varied Survival Rates:** The survival rates differ across the number of siblings/spouses. Passengers without any siblings or spouses on board had a survival rate of 34.5%, while those with one sibling/spouse had a higher survival rate of 53.6%.\n\n2. **Decreasing Trend with More Siblings/Spouses:** As the number of siblings/spouses increases, there's a general trend of decreasing survival rates. This is evident from the drop to 46.4% for passengers with two siblings/spouses, 25% for those with three, and even lower for four.\n\n3. **Zero Survival for Larger Families:** There are no survivors among the passengers who had five or eight siblings/spouses on board, as indicated by the 0.0% survival rate for these groups.\n\n4. **Highest Survival for Smaller Families:** The highest survival rate is observed among passengers with one sibling/spouse, which could suggest that those with a single family member to look out for could more easily maneuver and access life-saving resources.\n\n5. **Potential Outliers:** The passengers with a very high number of siblings/spouses (such as 5 and 8) are outliers with a survival rate of 0%. This might reflect the difficulty of larger groups to secure a place on lifeboats or could also indicate data entry errors or exceptional cases that warrant further investigation.\n\n\nThis chart provides insight into the dynamics of survival aboard the Titanic and indicates that the presence of family members could have both aided and hindered survival chances, depending on the size of the family. \n # 2.5. Ticket \n Let's examine the tickets. Individuals who bought identical tickets are regarded as a collective unit and are attributed to a newly created attribute named 'Group_Size'. \n df[\"Ticket\"].value_counts() \n newdf = df.copy()\n\nnewdf[\"Group_Size\"] = newdf.groupby(\"Ticket\")[\"PassengerId\"].transform(\"count\")\nnewdf[\"Group_Size\"]  \n plt.figure(figsize=(10, 6))\nax = sns.countplot(data=newdf, x='Group_Size')\n\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.0f'), \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha = 'center', va = 'center', \n                xytext = (0, 10), \n                textcoords = 'offset points')\n\nplt.title('Distribution of Group Size')\nplt.xlabel('Group Size of Passengers')\nplt.ylabel('Count')\nplt.show() \n  Here are some observations from the chart:\n\n1. **Solo Travelers:** The largest bar represents individuals traveling alone (group size of 1), with a count of 547. This indicates that the majority of passengers on the Titanic purchased tickets individually rather than as part of a group.\n\n2. **Small Groups:** The second-largest bar represents groups of two, with a count of 188, suggesting that traveling in pairs was also common. This could include couples or two friends/family members traveling together.\n\n3. **Declining Numbers with Larger Groups:** As the group size increases, the number of such groups decreases significantly. For example, there are only 63 groups of size 3, and even fewer as the size increases.\n\n4. **Larger Groups are Less Common:** Very large groups (such as those with sizes 5, 6, or 7) are much less common, as indicated by the relatively small bar heights for these group sizes.\n\n5. **Potential Family or Tour Groups:** Some of the larger group sizes, like 7, with a count of 21, could indicate families traveling together or organized tour groups.\n\n6. **Implications for Survival Analysis:** The group size may have had an impact on survival rates, as those in larger groups might have had different dynamics when it came to evacuation procedures compared to those traveling alone or in pairs.\n\nThis visualization provides a clear representation of how passengers were distributed by group size, which can be a useful feature for understanding social dynamics on the Titanic and for predictive modeling of survival. \n # 2.6. Cabin \n First, the following steps were performed:\n\n1. Missing values in the 'Cabin' column were filled with the string \"Unknown\".\n2. Only the first letter of each cabin entry was retained to categorize the cabins.\n3. A count plot was created to show the count of passengers who did and did not survive, separated by cabin category.\n \n newdf = df.copy()\nnewdf[\"Cabin\"].fillna(\"Unknown\",inplace=True)\nnewdf[\"Cabin\"] = newdf[\"Cabin\"].str[0]\nsns.set(style=\"darkgrid\")\nsns.countplot( x='Survived', data=newdf, hue=\"Cabin\", palette=\"Set1\"); \n \nHere are some observations based on the count plot in the image:\n\n- The majority of passengers have an unknown cabin designation, denoted as 'U', with a high non-survival rate.\n- Passengers from cabin categories 'C', 'E', 'G', 'D', 'A', 'B', 'F', and 'T' are also represented, with varying counts of survival and non-survival.\n- Cabin 'C' has the second-highest count among those who did not survive and a significant count of survivors.\n- Cabins 'E' and 'D' show a relatively higher survival rate compared to non-survival.\n- The 'T' cabin category has a very low count, which may indicate it's an outlier or a special case.\n\nThis visualization suggests that cabin location may have played a role in the passengers' likelihood of survival, which could be related to the proximity to lifeboats or other escape routes. It's worth noting that the high number of unknown cabins can affect the overall analysis and interpretations drawn from this data. \n # 2.7. Embarked \n sns.set(style=\"darkgrid\")\nsns.countplot( x='Survived', data=df, hue=\"Embarked\", palette=\"Set1\"); \n It represents the survival of passengers based on the port where they embarked on the Titanic, with \"S\" for Southampton, \"C\" for Cherbourg, and \"Q\" for Queenstown.\n\nHere are some observations from the chart:\n\n- A larger number of passengers embarked from Southampton (S), with a higher count of those who did not survive (0) compared to those who did (1).\n- For passengers who embarked from Cherbourg (C), the survival count is relatively high compared to the non-survival count.\n- Queenstown (Q) had the fewest passengers, with a non-survival rate that appears to be slightly higher than the survival rate.\n- The survival rate of passengers from Cherbourg stands out as being higher than that of the other two ports.\n\nThis chart could suggest that passengers embarking from different ports had different survival rates, possibly due to various factors such as the socioeconomic status of passengers, which could correlate with their point of embarkation, or perhaps the location on the ship where passengers from different ports were accommodated. \n # 2.8. And Target Distribution \n sns.set(style=\"darkgrid\")\nsns.countplot( x='Survived', data=df, hue=\"Survived\", palette=\"Set1\"); \n  In this chart:\n\n- The red bar represents passengers who did not survive (0).\n- The blue bar represents passengers who did survive (1).\n\nObservations from the chart are:\n\n- There are more non-survivors than survivors, with the non-survivors' bar being significantly taller.\n- This imbalance in the target variable distribution may suggest a need for stratified sampling or other techniques to address class imbalance when training machine learning models.\n- The visualization gives a clear representation of the binary classification nature of the problem, where the goal is to predict one of these two possible outcomes. \n # 3. Data Cleaning \n def missing_zero_values_table(df):\n    zero_val = (df == 0.00).astype(int).sum(axis=0)\n    mis_val = df.isnull().sum()\n    mis_val_percent = 100 * df.isnull().sum() / len(df)\n    mz_table = pd.concat([zero_val, mis_val, mis_val_percent], axis=1)\n    mz_table = mz_table.rename(\n    columns = {0 : 'Zero Values', 1 : 'Missing Values', 2 : '% of Total Values'})\n    mz_table['Total Zero Missing Values'] = mz_table['Zero Values'] + mz_table['Missing Values']\n    mz_table['% Total Zero Missing Values'] = 100 * mz_table['Total Zero Missing Values'] / len(df)\n    mz_table['Data Type'] = df.dtypes\n    mz_table = mz_table[ mz_table.iloc[:,1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns and \" + str(df.shape[0]) + \" Rows.\\n\"\n           \"There are \" + str(mz_table.shape[0]) +\n            \"columns that have missing values.\")\n    return mz_table\n\n\nmissing_zero_values_table(df) \n missing_zero_values_table(test_df) \n `missing_zero_values_table` analyzes the dataframes for zero values and missing values.\n\nHere's a summary of the missing data information provided in the tables:\n\n**Training DataFrame:**\n- Contains 13 columns and 891 rows.\n- Three columns have missing values:\n  - `Cabin`: 687 missing values, which is 77.1% of the total number of rows.\n  - `Age`: 177 missing values, 19.9% of the rows.\n  - `Embarked`: 2 missing values, 0.2% of the rows.\n\n**Test DataFrame:**\n- Contains 11 columns and 418 rows.\n- Three columns have missing values:\n  - `Cabin`: 327 missing values, 78.2% of the rows.\n  - `Age`: 86 missing values, 20.6% of the rows.\n  - `Fare`: 1 missing value, 0.2% of the rows, and also 2 zero values.\n\nFrom this information, we can deduce that:\n\n- The `Cabin` column has a very high percentage of missing values in both datasets, suggesting that it may not be a reliable feature for machine learning models unless some form of imputation or feature engineering is done.\n- The `Age` column has a significant, but much smaller, percentage of missing values. Imputation strategies such as median age could be considered.\n- The `Embarked` column in the training set and the `Fare` column in the test set have a very small number of missing values and could be filled with the most common value or the median, respectively.\n- The presence of two zero values in the `Fare` column of the test set might indicate either free tickets or data entry errors and might require further investigation or a decision on a case-by-case basis.\n\nTo clean this data, you would typically fill in the missing values with appropriate statistics (like the median or mode), or possibly infer missing values based on other data. For categorical data like `Cabin` and `Embarked`, you might consider filling in missing values with the most common category, or creating a new category for missing data. For numerical data like `Age` and `Fare`, you might use a measure of central tendency (mean, median) or employ a model-based imputation method. \n def clean_data(data):\n    data['Fare'] = data['Fare'].fillna(data['Fare'].dropna().median())\n    data['Age'] =  data['Age'].fillna(data['Age'].dropna().median())\n    \n    data.loc[data['Sex'] == 'male', 'Sex'] = 0\n    data.loc[data['Sex'] =='female',  'Sex'] = 1\n    \n    data['Embarked'] = data['Embarked'].fillna('S')\n    data.loc[data[\"Embarked\"] == 'S', 'Embarked'] = 0\n    data.loc[data['Embarked'] == 'C', 'Embarked'] = 1\n    data.loc[data['Embarked'] == 'Q', 'Embarked'] =2\n    \n    data.drop([\"Cabin\"],axis=1,inplace=True) \n clean_data(df)\nclean_data(test_df) \n `clean_data`  is written to perform several data cleaning operations on a pandas DataFrame. Below is a description of what each line of code within the function does:\n\n1. `data['Fare'] = data['Fare'].fillna(data['Fare'].dropna().median())`: This line fills any missing (NaN) values in the 'Fare' column with the median fare calculated from the non-missing values.\n\n2. `data['Age'] = data['Age'].fillna(data['Age'].dropna().median())`: This line fills any missing (NaN) values in the 'Age' column with the median age calculated from the non-missing values.\n\n3. `data.loc[data['Sex'] == 'male', 'Sex'] = 0`: This line converts the categorical 'Sex' data into numerical form, replacing 'male' with 0.\n\n4. `data.loc[data['Sex'] == 'female', 'Sex'] = 1`: Similarly, this line replaces 'female' with 1 in the 'Sex' column.\n\n5. `data['Embarked'] = data['Embarked'].fillna('S')`: This line fills any missing values in the 'Embarked' column with 'S', which likely stands for Southampton, the most common port of embarkation.\n\n6. `data.loc[data['Embarked'] == 'S', 'Embarked'] = 0`: This line assigns a numeric value of 0 to all instances where the embarkation port is 'S'.\n\n7. `data.loc[data['Embarked'] == 'C', 'Embarked'] = 1`: This line assigns a numeric value of 1 to all instances where the embarkation port is 'C'.\n\n8. `data.loc[data['Embarked'] == 'Q', 'Embarked'] = 2`: This line assigns a numeric value of 2 to all instances where the embarkation port is 'Q'.\n\n9. `data.drop([\"Cabin\"], axis=1, inplace=True)`: This line removes the 'Cabin' column from the DataFrame entirely, which might be due to the high percentage of missing values as shown in the one, making it potentially less useful for predictive modeling.\n\nOverall, this function handles missing values, converts categorical variables to numerical, and drops a column with excessive missing data, which are common steps in preparing data for machine learning algorithms. \n # 4. Creating a Model \n # 4.1. Train-Test Split \n from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\ndf[\"Survived\"] = df[\"Survived\"].astype(int)\nX = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']].values\ny = df[\"Survived\"].values\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1,stratify=y, random_state = 105) \n X_train \n y_train \n # 4.2. Hyperparameter search\n\nEach dictionary is named after the classifier it is intended for and includes a set of parameters and the range of values to be tested for each. The classifiers and their respective hyperparameters are as follows:\n\n1. **Decision Tree Classifier (`dt_hyperparameters`)**:\n   - `min_samples_split`: A range of values from 10 to 500, with a step of 20.\n   - `max_depth`: A range of values from 1 to 20, with a step of 2.\n\n2. **Support Vector Machine (`svc_hyperparameters`)**:\n   - `kernel`: A fixed value of 'rbf' indicating the use of the radial basis function kernel.\n   - `gamma`: A list of potential values `[0.001, 0.01, 0.1]`.\n   - `C`: A list of potential regularization parameter values `[1, 10, 50, 100, 250, 500]`.\n\n3. **Random Forest Classifier (`rf_hyperparameters`)**:\n   - `max_depth`: A list of potential values `[1, 3, 5,7]`.\n   - `min_samples_leaf`: A list of potential values `[1, 3, 5]`.\n   - `n_estimators`: The number of trees in the forest with values `[50, 100, 150]`.\n\n4. **K Nearest Neighbors (`knn_hyperparameters`)**:\n   - `n_neighbors`: A list of potential values `[1, 3, 5, 7]`.\n   - `metric`: A single value 'manhattan', which is a type of distance measurement.\n\nFinally, a list called `classifier_param` is defined which aggregates the dictionaries of hyperparameters for each classifier.\n\nThis setup will be used in combination with a grid search cross-validation procedure, where each combination of parameters for each classifier will be tested to find the best performing model based on some evaluation metric.  \n dt_hyperparameters= {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_hyperparameters= {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1],\n                 \"C\": [1,10,50,100,250,500]}\n\n\nrf_hyperparameters= {\"max_depth\":[1,3,5,7],\n                \"min_samples_leaf\":[1,3,5],\n                \"n_estimators\":[50,100,150]}\n\nknn_hyperparameters= {\"n_neighbors\": [1,3,5,7],\n                 \"metric\":[\"manhattan\"]} \n             \nclassifier_param = [\n                    dt_hyperparameters,\n                   svc_hyperparameters,\n                   rf_hyperparameters,\n                   knn_hyperparameters] \n # e\u011fitim i\u00e7in\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.exceptions import ConvergenceWarning\n# Suppress ConvergenceWarning\nwarnings.simplefilter('ignore', ConvergenceWarning)\n\nrandom_state=45\nclassifier = [\n             DecisionTreeClassifier(random_state = random_state),\n             SVC(),\n             RandomForestClassifier(random_state = random_state),\n             KNeighborsClassifier()]\n\n\ncv_result = []\nreal_test_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    real_test_result.append(clf.score(X_test, y_test))  \n best_estimators \n These appear to be the best-performing models as determined by a hyperparameter tuning process such as grid search or random search. Here's a summary of the models and their corresponding best hyperparameters:\n\n1. **DecisionTreeClassifier**: Found to perform best with a maximum depth of 7 (`max_depth=7`) and a minimum number of samples required to split an internal node (`min_samples_split=10`). A `random_state` has been set to 45, which is used for initializing the internal random number generator, ensuring reproducibility of the results.\n\n2. **SVC (Support Vector Classifier)**: The optimal hyperparameters for the support vector machine include a regularization parameter `C` set to 500 and a kernel coefficient `gamma` set to 0.001. The kernel is not explicitly mentioned, but since 'rbf' was part of the search space in the hyperparameter search snippet, it is likely that the radial basis function kernel is used.\n\n3. **RandomForestClassifier**: For the random forest, the best parameters include a maximum depth of 3 (`max_depth=3`), a minimum number of samples required to be at a leaf node (`min_samples_leaf=3`), and the number of trees in the forest (`n_estimators=50`). The `random_state` is again set to 45 for reproducibility.\n\n4. **KNeighborsClassifier**: This model is configured to use 7 neighbors (`n_neighbors=7`) and the Manhattan distance metric for its operation.\n\nThese models are typically stored in a list after the completion of hyperparameter tuning to easily access the best version of each classifier for further evaluation, ensemble methods, or deployment. \n And, the resulting DataFrame cv_results is displayed below the code snippet, showing each classifier along with its corresponding cross-validation mean and test result. The scores are as follows: \n cv_results = pd.DataFrame({ \"Machine Learning Models\":\n                                               [\"Decision Tree Classifier\", \n                                                \"Support Vector Machines\",\n                                                \"Random Forest Classifier\",\n                                                 \"K Nearest Neighbors Classifier\"],\n                           \"Cross Validation Mean\": cv_result, \n                           \"Test Result\": real_test_result})\ncv_results\n \n # 4.3. Utilizing Ensemble Learning to Enhance Predictive Accuracy\n\nThe provided code snippet is implementing a voting ensemble machine learning model that combines the predictions from three different classifiers: Decision Tree, Random Forest, and K Nearest Neighbors. Each classifier has been previously tuned to find its best hyperparameters. The ensemble model is trained on a dataset, then used to make predictions on a test set. The accuracy of the model on the test set is calculated and printed, resulting in an accuracy of about 87.77%. This high accuracy indicates that the ensemble method is effective for the given prediction task. \n from sklearn.ensemble import VotingClassifier\nvoting = VotingClassifier(estimators=[\n                                      ('Decision Tree Classifier', best_estimators[0]), \n                                      ('Random Forest Classifier', best_estimators[2]),\n                                      ('K Nearest Neighbors Classifier', best_estimators[3])])\nvoting.fit(X_train,y_train)\nvoting_pred = voting.predict(X_test)\n\nprint('Accuracy: ', accuracy_score(y_test, voting_pred)) \n # 5. Making Predictions on the Original Test Set for the Leaderboard Submission \n submission= pd.read_csv(\"/kaggle/input/titanic/gender_submission.csv\")\ntest =  test_df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']].values\nsubmission[\"Survived\"]=voting.predict(test)\nsubmission.to_csv('submission.csv',index=False)\nsubmission",
    "code_source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n \n # temel k\u00fct\u00fcphaneler\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n test_df = pd.read_csv('/kaggle/input/titanic/test.csv')\ndf = pd.read_csv('/kaggle/input/titanic/train.csv')\ndf \n plt.figure(figsize=(8, 6))\nax = sns.countplot(data=df, x='Pclass')\n\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.0f'), \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha = 'center', va = 'center', \n                xytext = (0, 10), \n                textcoords = 'offset points')\n\nplt.title('Distribution of Passenger Classes')\nplt.xlabel('Passenger Class')\nplt.ylabel('Count')\nplt.show() \n plt.figure(figsize=(8, 6))\nax = sns.countplot(data=df, x='Sex')\n\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.0f'), \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha = 'center', va = 'center', \n                xytext = (0, 10), \n                textcoords = 'offset points')\n\nplt.title('Distribution of Sex')\nplt.xlabel('Sex of Passengers')\nplt.ylabel('Count')\nplt.show() \n # Calculate the mean survival rates by sex\nsurvival_rates = df.groupby('Sex')['Survived'].mean().reset_index()\n\n# Create the bar plot\nsns.barplot(x='Sex', y='Survived', data=survival_rates)\n\n# Adding the actual survival rates on top of the bars\nfor index, value in enumerate(survival_rates['Survived']):\n    plt.text(index, value, f'{value:.4f}', ha='center', va='bottom')\n\n# Set the title and labels for the plot\nplt.title('Survival Rates by Sex')\nplt.ylabel('Average Survival Rate')\nplt.xlabel('Sex')\n\n# Display the plot\nplt.show() \n sns.histplot(x=\"Age\", hue=\"Survived\", palette=\"mako\", data=df[[\"Age\",\"Survived\"]])\nplt.title(\"Age Distribution\", color='black', fontsize=14) \nplt.yticks([])\nplt.box(False)\nplt.show() \n plt.figure(figsize=(10, 6))\nax = sns.countplot(data=df, x='SibSp')\n\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.0f'), \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha = 'center', va = 'center', \n                xytext = (0, 10), \n                textcoords = 'offset points')\n\nplt.title('Distribution of Siblings Amount')\nplt.xlabel('Title of Passengers')\nplt.ylabel('Count')\nplt.show() \n survival_by_sibsp = df.groupby('SibSp')['Survived'].mean()\n\nplt.figure(figsize=(8, 6))\nax = sns.barplot(x=survival_by_sibsp.index, y=survival_by_sibsp.values)\nplt.title('Survival Rate by SibSp')\nplt.xlabel('Number of Siblings/Spouses')\nplt.ylabel('Survival Rate')\n\ntotal = float(len(df))\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x() + p.get_width() / 2., height + 0.02, '{:.1%}'.format(height), ha=\"center\")\n\nplt.show() \n df[\"Ticket\"].value_counts() \n newdf = df.copy()\n\nnewdf[\"Group_Size\"] = newdf.groupby(\"Ticket\")[\"PassengerId\"].transform(\"count\")\nnewdf[\"Group_Size\"]  \n plt.figure(figsize=(10, 6))\nax = sns.countplot(data=newdf, x='Group_Size')\n\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.0f'), \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha = 'center', va = 'center', \n                xytext = (0, 10), \n                textcoords = 'offset points')\n\nplt.title('Distribution of Group Size')\nplt.xlabel('Group Size of Passengers')\nplt.ylabel('Count')\nplt.show() \n newdf = df.copy()\nnewdf[\"Cabin\"].fillna(\"Unknown\",inplace=True)\nnewdf[\"Cabin\"] = newdf[\"Cabin\"].str[0]\nsns.set(style=\"darkgrid\")\nsns.countplot( x='Survived', data=newdf, hue=\"Cabin\", palette=\"Set1\"); \n sns.set(style=\"darkgrid\")\nsns.countplot( x='Survived', data=df, hue=\"Embarked\", palette=\"Set1\"); \n sns.set(style=\"darkgrid\")\nsns.countplot( x='Survived', data=df, hue=\"Survived\", palette=\"Set1\"); \n def missing_zero_values_table(df):\n    zero_val = (df == 0.00).astype(int).sum(axis=0)\n    mis_val = df.isnull().sum()\n    mis_val_percent = 100 * df.isnull().sum() / len(df)\n    mz_table = pd.concat([zero_val, mis_val, mis_val_percent], axis=1)\n    mz_table = mz_table.rename(\n    columns = {0 : 'Zero Values', 1 : 'Missing Values', 2 : '% of Total Values'})\n    mz_table['Total Zero Missing Values'] = mz_table['Zero Values'] + mz_table['Missing Values']\n    mz_table['% Total Zero Missing Values'] = 100 * mz_table['Total Zero Missing Values'] / len(df)\n    mz_table['Data Type'] = df.dtypes\n    mz_table = mz_table[ mz_table.iloc[:,1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns and \" + str(df.shape[0]) + \" Rows.\\n\"\n           \"There are \" + str(mz_table.shape[0]) +\n            \"columns that have missing values.\")\n    return mz_table\n\n\nmissing_zero_values_table(df) \n missing_zero_values_table(test_df) \n def clean_data(data):\n    data['Fare'] = data['Fare'].fillna(data['Fare'].dropna().median())\n    data['Age'] =  data['Age'].fillna(data['Age'].dropna().median())\n    \n    data.loc[data['Sex'] == 'male', 'Sex'] = 0\n    data.loc[data['Sex'] =='female',  'Sex'] = 1\n    \n    data['Embarked'] = data['Embarked'].fillna('S')\n    data.loc[data[\"Embarked\"] == 'S', 'Embarked'] = 0\n    data.loc[data['Embarked'] == 'C', 'Embarked'] = 1\n    data.loc[data['Embarked'] == 'Q', 'Embarked'] =2\n    \n    data.drop([\"Cabin\"],axis=1,inplace=True) \n clean_data(df)\nclean_data(test_df) \n from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\ndf[\"Survived\"] = df[\"Survived\"].astype(int)\nX = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']].values\ny = df[\"Survived\"].values\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1,stratify=y, random_state = 105) \n X_train \n y_train \n dt_hyperparameters= {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_hyperparameters= {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1],\n                 \"C\": [1,10,50,100,250,500]}\n\n\nrf_hyperparameters= {\"max_depth\":[1,3,5,7],\n                \"min_samples_leaf\":[1,3,5],\n                \"n_estimators\":[50,100,150]}\n\nknn_hyperparameters= {\"n_neighbors\": [1,3,5,7],\n                 \"metric\":[\"manhattan\"]} \n             \nclassifier_param = [\n                    dt_hyperparameters,\n                   svc_hyperparameters,\n                   rf_hyperparameters,\n                   knn_hyperparameters] \n # e\u011fitim i\u00e7in\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.exceptions import ConvergenceWarning\n# Suppress ConvergenceWarning\nwarnings.simplefilter('ignore', ConvergenceWarning)\n\nrandom_state=45\nclassifier = [\n             DecisionTreeClassifier(random_state = random_state),\n             SVC(),\n             RandomForestClassifier(random_state = random_state),\n             KNeighborsClassifier()]\n\n\ncv_result = []\nreal_test_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    real_test_result.append(clf.score(X_test, y_test))  \n best_estimators \n cv_results = pd.DataFrame({ \"Machine Learning Models\":\n                                               [\"Decision Tree Classifier\", \n                                                \"Support Vector Machines\",\n                                                \"Random Forest Classifier\",\n                                                 \"K Nearest Neighbors Classifier\"],\n                           \"Cross Validation Mean\": cv_result, \n                           \"Test Result\": real_test_result})\ncv_results\n \n from sklearn.ensemble import VotingClassifier\nvoting = VotingClassifier(estimators=[\n                                      ('Decision Tree Classifier', best_estimators[0]), \n                                      ('Random Forest Classifier', best_estimators[2]),\n                                      ('K Nearest Neighbors Classifier', best_estimators[3])])\nvoting.fit(X_train,y_train)\nvoting_pred = voting.predict(X_test)\n\nprint('Accuracy: ', accuracy_score(y_test, voting_pred)) \n submission= pd.read_csv(\"/kaggle/input/titanic/gender_submission.csv\")\ntest =  test_df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']].values\nsubmission[\"Survived\"]=voting.predict(test)\nsubmission.to_csv('submission.csv',index=False)\nsubmission",
    "markdown_source": "# 0. Background\n\n\n## Introduction\nThe Titanic: Machine Learning from Disaster competition represents an engaging challenge that merges historical significance with predictive analytics. It provides an opportunity for data science enthusiasts and experts to apply machine learning techniques to a dataset that is both rich in history and complexity.\n\n## Problem Definition\nThe competition's objective is to predict survival on the Titanic, the passenger liner that sank in 1912 after colliding with an iceberg. The event holds substantial historical significance due to the loss of life, particularly because it reflected the societal norms of the era, such as class distinctions. The task of predicting survival is not merely an academic exercise but also a reflection on the human aspects behind data, underscoring the potential of machine learning in understanding human factors in historical events.\n\n## Expected Outputs\nThe expected output is a predictive model capable of determining the survival outcome for each passenger in the test set. Participants must submit a CSV file with two columns: `PassengerId` and `Survived`. The `Survived` column should contain the binary predictions: 1 for survived and 0 for did not survive. The model's performance is measured based on the accuracy of these predictions.\n\n## Dataset\nThe provided dataset consists of several attributes for each passenger aboard the Titanic:\n\n  - `PassengerId`: Unique identifier for each passenger.\n  - `Survived`: Survival status (0 = No, 1 = Yes).\n  - `Pclass`: Passenger class (1 = 1st, 2 = 2nd, 3 = 3rd).\n  - `Name`: Name of the passenger.\n  - `Sex`: Gender of the passenger (male or female).\n  - `Age`: Age of the passenger. Some entries are NaN, indicating missing values.\n  - `SibSp`: Number of siblings or spouses aboard.\n  - `Parch`: Number of parents or children aboard.\n  - `Ticket`: Ticket number.\n  - `Fare`: Passenger fare.\n  - `Cabin`: Cabin number. Contains NaN values, which represent missing data.\n  - `Embarked`: Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton).\n\nThe dataset will be used to train machine learning models that can discern patterns and associations between the features and the likelihood of survival.\n\n## Problem Type\nThe challenge is a binary classification problem, a type of supervised learning where the aim is to categorize the passengers into two groups: those who survived and those who did not. The nature of the `Survived` variable as a binary indicator makes it a clear case of classification rather than regression, which would predict continuous outcomes.\n\n## Conclusion\nThe Titanic Kaggle competition is a testbed for machine learning methodologies, offering insights into the social fabric of the early 20th century while advancing the field of data science. It presents a problem that is both historically enriching and technically stimulating, with the potential to develop predictive models that are not only accurate but also interpretative of the human stories behind the data.\nI will use a dataset containing information about those on board to develop a machine learning model that attempts to predict who survived. \n # 1. Reading the data \n Here's a description of the data as displayed in the DataFrame:\n\n- **Columns in the DataFrame:**\n  - `PassengerId`: Unique identifier for each passenger.\n  - `Survived`: Survival status (0 = No, 1 = Yes).\n  - `Pclass`: Passenger class (1 = 1st, 2 = 2nd, 3 = 3rd).\n  - `Name`: Name of the passenger.\n  - `Sex`: Gender of the passenger (male or female).\n  - `Age`: Age of the passenger. Some entries are NaN, indicating missing values.\n  - `SibSp`: Number of siblings or spouses aboard.\n  - `Parch`: Number of parents or children aboard.\n  - `Ticket`: Ticket number.\n  - `Fare`: Passenger fare.\n  - `Cabin`: Cabin number. Contains NaN values, which represent missing data.\n  - `Embarked`: Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton).\n\n- **Sample Data:**\n  - The first row corresponds to a male passenger with a `PassengerId` of 1, who did not survive, was in 3rd class, and embarked from Southampton (`Embarked` = S).\n  - The third row shows a female passenger, `PassengerId` 3, who survived, was in 3rd class, and also embarked from Southampton.\n  - There are some missing data points, indicated by `NaN` (not a number), especially in the `Age` and `Cabin` columns, which will require careful handling during data preprocessing for any machine learning tasks.\n\n- **Data Use:**\n  - `Survived` is the target variable for the prediction model.\n  - Other columns serve as features to train machine learning models to predict the target variable. Features like `Name` and `Ticket` might be used for feature engineering, while `Cabin` and `Age` would need to deal with missing values.\n\nThis data is  used to train classification models to predict the `Survived` column, which is a binary outcome indicating whether a passenger survived the Titanic disaster. \n # 2.Exploratory Data Analysis (EDA)  \n # 2.1 Pclass\n\n\"Pclass\" signifies the accommodation category for travelers on the Titanic, reflective of their socio-economic stature. \n\n- 1st Class: This tier was the domain of the affluent and illustrious\u2014magnates, celebrities, or distinguished personas. It offered spacious quarters and superior dining and amenities.\n\n- 2nd Class: Serving as a mid-level option, it was less opulent than 1st Class but provided a comfortable journey for middle-class travelers. The cabins were more compact, and there were fewer luxuries.\n\n- 3rd Class: This was the most basic level of travel, primarily for individuals of modest means, often immigrants or those with lesser financial resources. Accommodations were more confined, with basic amenities.\n\nThe Pclass is indicative of the passengers' financial and social ranking. It is a critical factor in survival analysis due to the potential influence of class on emergency response and evacuation procedures during the disaster. \n Here are some observations and comments based on the chart:\n\n1. **Third Class is the Most Populous:** With 491 passengers, the Third Class had the highest number of passengers compared to the other classes. This reflects the economic demographics of the time, where a larger portion of the population were of lower socio-economic status, which also correlates with the common practice of ships carrying more third-class passengers to maximize ticket sales.\n\n2. **First Class has More Passengers than Second:** There were 216 passengers in First Class and slightly fewer, 184, in Second Class. This could indicate that the Titanic was quite luxurious and attracted a significant number of affluent passengers who could afford the higher fare for better accommodations and services.\n\n3. **Economic Implications:** The distribution shows the economic stratification of society at the time. A substantial number of people were traveling in Third Class, possibly in hope of starting a new life in America, which was a common reason for travel among immigrants during that period.\n\n4. **Implications for Survival Analysis:** Given the larger number of Third Class passengers, if resources and lifeboats were limited and preferentially allocated to higher classes, this could have significantly influenced survival rates. Historical accounts suggest that First Class passengers had better access to lifeboats, which is an important aspect to consider in survival analysis.\n\n5. **Data Visualization Insights:** The bar chart effectively communicates the difference in class sizes, which is crucial for data exploration in predictive modeling. It's a good practice to visualize data this way to understand the underlying distributions before applying machine learning algorithms.\n\n6. **Potential Bias in Model Training:** When training machine learning models on this data, the imbalance in class distribution may introduce bias. Models might perform better at predicting survival for Third Class passengers simply because there are more data points for that class.\n\nOverall, the visualization underscores the importance of considering passenger class as a feature in predictive models and as a factor in historical analyses of the Titanic disaster. \n # 2.2 Sex \n  Here are some insights and comments regarding the chart:\n\n1. **Gender Disparity:** The chart illustrates that there were considerably more male passengers (577) than female passengers (314) on the Titanic. This reflects the gender demographics of passengers who were traveling at that time.\n\n2. **Implications for Survival Predictions:** Historical records indicate that the protocol of \"women and children first\" was often followed during maritime disasters. Therefore, despite being outnumbered, female passengers might have had a higher survival rate compared to males, which is a critical consideration for predictive modeling.\n\n3. **Visualization Effectiveness:** The bar chart clearly demonstrates the disparity in numbers between male and female passengers. Such visualizations are important in exploratory data analysis as they provide immediate insights into the dataset's structure before any statistical modeling.\n\n4. **Influence on Model Training:** The imbalance shown here may influence the performance of machine learning models. If the model is not adjusted to account for this imbalance, it may become biased towards predicting the survival of males, simply because there are more male passengers in the dataset.\n\n5. **Historical Context:** The higher number of males might be reflective of the societal norms of the time, where men were more likely to travel alone for business or emigration purposes, while women often traveled with families.\n\n6. **Data Preparation Considerations:** When preparing the dataset for machine learning, it might be beneficial to consider techniques like stratification to ensure that both genders are adequately represented in the training and validation sets.\n\n \n Here are some comments and interpretations based on the chart:\n\n1. **Significant Gender-Based Survival Disparity:** The bar chart highlights a stark difference in survival rates between females and males. Female passengers had a much higher survival rate of approximately 74.2%, while the survival rate for male passengers was markedly lower at about 18.9%.\n\n \n # 2.3. Age \n Here are some comments and insights based on the chart:\n\n1. **Bimodal Distribution:** The age distribution appears to be bimodal, with two peaks suggesting that younger adults and children were the most common age groups among the passengers.\n\n2. **Higher Survival Rate Among Younger Passengers:** The lighter-colored bars, which represent the passengers who survived, seem more prominent in the lower age groups, suggesting that younger passengers had a higher survival rate.\n\n3. **Declining Survival with Age:** There is a noticeable decline in survival rate as age increases, particularly noticeable in passengers older than 30 years old.\n\n4. **Children's Survival:** The survival rate for very young passengers (children) seems to be high, which could be attributed to the \"women and children first\" policy during lifeboat loading.\n\n5. **Effective Visualization:** This stacked histogram effectively conveys the relationship between age and survival. It allows for easy comparison between the number of survivors and non-survivors within each age group.\n\n6. **Insights for Model Training:** For predictive modeling, this visualization suggests that age could be an important feature, potentially requiring more nuanced treatment such as binning into categorical age groups or creating age-related interaction features.\n\n \n # 2.4. SibSp \n Here are some observations and insights from the chart:\n\n1. **Most Passengers Traveled Alone:** A significant majority of passengers, indicated by the tallest bar with a count of 608, did not have siblings or spouses on board. This suggests that solo travel was common.\n\n2. **Smaller Family Units:** The second bar, with a count of 209, shows that a substantial number of passengers traveled with one sibling or spouse, indicating smaller family units or couples without children.\n\n3. **Rarity of Large Families:** Very few passengers traveled with more than two siblings or spouses. The counts for passengers with three or more siblings/spouses are markedly lower, which highlights the rarity of large families or sibling groups traveling together.\n\n4. **Exceptional Cases:** There are a few exceptional cases of passengers with large numbers of siblings/spouses on board, such as 5 or 8, which are very uncommon. These could potentially represent larger family groups or possibly group tickets.\n\n5. **Potential Impact on Survival:** The number of siblings/spouses could have implications for survival rates, as those with family aboard might have sought one another out during the disaster, potentially affecting their likelihood of reaching the lifeboats.\n\n\nThis chart provides a clear visual representation of the distribution of family sizes aboard the Titanic, with the majority being individuals or couples. \n **Let's examine the survival rate according to the number of siblings or spouses.**\n \n Here are some key takeaways from the chart:\n\n1. **Varied Survival Rates:** The survival rates differ across the number of siblings/spouses. Passengers without any siblings or spouses on board had a survival rate of 34.5%, while those with one sibling/spouse had a higher survival rate of 53.6%.\n\n2. **Decreasing Trend with More Siblings/Spouses:** As the number of siblings/spouses increases, there's a general trend of decreasing survival rates. This is evident from the drop to 46.4% for passengers with two siblings/spouses, 25% for those with three, and even lower for four.\n\n3. **Zero Survival for Larger Families:** There are no survivors among the passengers who had five or eight siblings/spouses on board, as indicated by the 0.0% survival rate for these groups.\n\n4. **Highest Survival for Smaller Families:** The highest survival rate is observed among passengers with one sibling/spouse, which could suggest that those with a single family member to look out for could more easily maneuver and access life-saving resources.\n\n5. **Potential Outliers:** The passengers with a very high number of siblings/spouses (such as 5 and 8) are outliers with a survival rate of 0%. This might reflect the difficulty of larger groups to secure a place on lifeboats or could also indicate data entry errors or exceptional cases that warrant further investigation.\n\n\nThis chart provides insight into the dynamics of survival aboard the Titanic and indicates that the presence of family members could have both aided and hindered survival chances, depending on the size of the family. \n # 2.5. Ticket \n Let's examine the tickets. Individuals who bought identical tickets are regarded as a collective unit and are attributed to a newly created attribute named 'Group_Size'. \n  Here are some observations from the chart:\n\n1. **Solo Travelers:** The largest bar represents individuals traveling alone (group size of 1), with a count of 547. This indicates that the majority of passengers on the Titanic purchased tickets individually rather than as part of a group.\n\n2. **Small Groups:** The second-largest bar represents groups of two, with a count of 188, suggesting that traveling in pairs was also common. This could include couples or two friends/family members traveling together.\n\n3. **Declining Numbers with Larger Groups:** As the group size increases, the number of such groups decreases significantly. For example, there are only 63 groups of size 3, and even fewer as the size increases.\n\n4. **Larger Groups are Less Common:** Very large groups (such as those with sizes 5, 6, or 7) are much less common, as indicated by the relatively small bar heights for these group sizes.\n\n5. **Potential Family or Tour Groups:** Some of the larger group sizes, like 7, with a count of 21, could indicate families traveling together or organized tour groups.\n\n6. **Implications for Survival Analysis:** The group size may have had an impact on survival rates, as those in larger groups might have had different dynamics when it came to evacuation procedures compared to those traveling alone or in pairs.\n\nThis visualization provides a clear representation of how passengers were distributed by group size, which can be a useful feature for understanding social dynamics on the Titanic and for predictive modeling of survival. \n # 2.6. Cabin \n First, the following steps were performed:\n\n1. Missing values in the 'Cabin' column were filled with the string \"Unknown\".\n2. Only the first letter of each cabin entry was retained to categorize the cabins.\n3. A count plot was created to show the count of passengers who did and did not survive, separated by cabin category.\n \n \nHere are some observations based on the count plot in the image:\n\n- The majority of passengers have an unknown cabin designation, denoted as 'U', with a high non-survival rate.\n- Passengers from cabin categories 'C', 'E', 'G', 'D', 'A', 'B', 'F', and 'T' are also represented, with varying counts of survival and non-survival.\n- Cabin 'C' has the second-highest count among those who did not survive and a significant count of survivors.\n- Cabins 'E' and 'D' show a relatively higher survival rate compared to non-survival.\n- The 'T' cabin category has a very low count, which may indicate it's an outlier or a special case.\n\nThis visualization suggests that cabin location may have played a role in the passengers' likelihood of survival, which could be related to the proximity to lifeboats or other escape routes. It's worth noting that the high number of unknown cabins can affect the overall analysis and interpretations drawn from this data. \n # 2.7. Embarked \n It represents the survival of passengers based on the port where they embarked on the Titanic, with \"S\" for Southampton, \"C\" for Cherbourg, and \"Q\" for Queenstown.\n\nHere are some observations from the chart:\n\n- A larger number of passengers embarked from Southampton (S), with a higher count of those who did not survive (0) compared to those who did (1).\n- For passengers who embarked from Cherbourg (C), the survival count is relatively high compared to the non-survival count.\n- Queenstown (Q) had the fewest passengers, with a non-survival rate that appears to be slightly higher than the survival rate.\n- The survival rate of passengers from Cherbourg stands out as being higher than that of the other two ports.\n\nThis chart could suggest that passengers embarking from different ports had different survival rates, possibly due to various factors such as the socioeconomic status of passengers, which could correlate with their point of embarkation, or perhaps the location on the ship where passengers from different ports were accommodated. \n # 2.8. And Target Distribution \n  In this chart:\n\n- The red bar represents passengers who did not survive (0).\n- The blue bar represents passengers who did survive (1).\n\nObservations from the chart are:\n\n- There are more non-survivors than survivors, with the non-survivors' bar being significantly taller.\n- This imbalance in the target variable distribution may suggest a need for stratified sampling or other techniques to address class imbalance when training machine learning models.\n- The visualization gives a clear representation of the binary classification nature of the problem, where the goal is to predict one of these two possible outcomes. \n # 3. Data Cleaning \n `missing_zero_values_table` analyzes the dataframes for zero values and missing values.\n\nHere's a summary of the missing data information provided in the tables:\n\n**Training DataFrame:**\n- Contains 13 columns and 891 rows.\n- Three columns have missing values:\n  - `Cabin`: 687 missing values, which is 77.1% of the total number of rows.\n  - `Age`: 177 missing values, 19.9% of the rows.\n  - `Embarked`: 2 missing values, 0.2% of the rows.\n\n**Test DataFrame:**\n- Contains 11 columns and 418 rows.\n- Three columns have missing values:\n  - `Cabin`: 327 missing values, 78.2% of the rows.\n  - `Age`: 86 missing values, 20.6% of the rows.\n  - `Fare`: 1 missing value, 0.2% of the rows, and also 2 zero values.\n\nFrom this information, we can deduce that:\n\n- The `Cabin` column has a very high percentage of missing values in both datasets, suggesting that it may not be a reliable feature for machine learning models unless some form of imputation or feature engineering is done.\n- The `Age` column has a significant, but much smaller, percentage of missing values. Imputation strategies such as median age could be considered.\n- The `Embarked` column in the training set and the `Fare` column in the test set have a very small number of missing values and could be filled with the most common value or the median, respectively.\n- The presence of two zero values in the `Fare` column of the test set might indicate either free tickets or data entry errors and might require further investigation or a decision on a case-by-case basis.\n\nTo clean this data, you would typically fill in the missing values with appropriate statistics (like the median or mode), or possibly infer missing values based on other data. For categorical data like `Cabin` and `Embarked`, you might consider filling in missing values with the most common category, or creating a new category for missing data. For numerical data like `Age` and `Fare`, you might use a measure of central tendency (mean, median) or employ a model-based imputation method. \n `clean_data`  is written to perform several data cleaning operations on a pandas DataFrame. Below is a description of what each line of code within the function does:\n\n1. `data['Fare'] = data['Fare'].fillna(data['Fare'].dropna().median())`: This line fills any missing (NaN) values in the 'Fare' column with the median fare calculated from the non-missing values.\n\n2. `data['Age'] = data['Age'].fillna(data['Age'].dropna().median())`: This line fills any missing (NaN) values in the 'Age' column with the median age calculated from the non-missing values.\n\n3. `data.loc[data['Sex'] == 'male', 'Sex'] = 0`: This line converts the categorical 'Sex' data into numerical form, replacing 'male' with 0.\n\n4. `data.loc[data['Sex'] == 'female', 'Sex'] = 1`: Similarly, this line replaces 'female' with 1 in the 'Sex' column.\n\n5. `data['Embarked'] = data['Embarked'].fillna('S')`: This line fills any missing values in the 'Embarked' column with 'S', which likely stands for Southampton, the most common port of embarkation.\n\n6. `data.loc[data['Embarked'] == 'S', 'Embarked'] = 0`: This line assigns a numeric value of 0 to all instances where the embarkation port is 'S'.\n\n7. `data.loc[data['Embarked'] == 'C', 'Embarked'] = 1`: This line assigns a numeric value of 1 to all instances where the embarkation port is 'C'.\n\n8. `data.loc[data['Embarked'] == 'Q', 'Embarked'] = 2`: This line assigns a numeric value of 2 to all instances where the embarkation port is 'Q'.\n\n9. `data.drop([\"Cabin\"], axis=1, inplace=True)`: This line removes the 'Cabin' column from the DataFrame entirely, which might be due to the high percentage of missing values as shown in the one, making it potentially less useful for predictive modeling.\n\nOverall, this function handles missing values, converts categorical variables to numerical, and drops a column with excessive missing data, which are common steps in preparing data for machine learning algorithms. \n # 4. Creating a Model \n # 4.1. Train-Test Split \n # 4.2. Hyperparameter search\n\nEach dictionary is named after the classifier it is intended for and includes a set of parameters and the range of values to be tested for each. The classifiers and their respective hyperparameters are as follows:\n\n1. **Decision Tree Classifier (`dt_hyperparameters`)**:\n   - `min_samples_split`: A range of values from 10 to 500, with a step of 20.\n   - `max_depth`: A range of values from 1 to 20, with a step of 2.\n\n2. **Support Vector Machine (`svc_hyperparameters`)**:\n   - `kernel`: A fixed value of 'rbf' indicating the use of the radial basis function kernel.\n   - `gamma`: A list of potential values `[0.001, 0.01, 0.1]`.\n   - `C`: A list of potential regularization parameter values `[1, 10, 50, 100, 250, 500]`.\n\n3. **Random Forest Classifier (`rf_hyperparameters`)**:\n   - `max_depth`: A list of potential values `[1, 3, 5,7]`.\n   - `min_samples_leaf`: A list of potential values `[1, 3, 5]`.\n   - `n_estimators`: The number of trees in the forest with values `[50, 100, 150]`.\n\n4. **K Nearest Neighbors (`knn_hyperparameters`)**:\n   - `n_neighbors`: A list of potential values `[1, 3, 5, 7]`.\n   - `metric`: A single value 'manhattan', which is a type of distance measurement.\n\nFinally, a list called `classifier_param` is defined which aggregates the dictionaries of hyperparameters for each classifier.\n\nThis setup will be used in combination with a grid search cross-validation procedure, where each combination of parameters for each classifier will be tested to find the best performing model based on some evaluation metric.  \n These appear to be the best-performing models as determined by a hyperparameter tuning process such as grid search or random search. Here's a summary of the models and their corresponding best hyperparameters:\n\n1. **DecisionTreeClassifier**: Found to perform best with a maximum depth of 7 (`max_depth=7`) and a minimum number of samples required to split an internal node (`min_samples_split=10`). A `random_state` has been set to 45, which is used for initializing the internal random number generator, ensuring reproducibility of the results.\n\n2. **SVC (Support Vector Classifier)**: The optimal hyperparameters for the support vector machine include a regularization parameter `C` set to 500 and a kernel coefficient `gamma` set to 0.001. The kernel is not explicitly mentioned, but since 'rbf' was part of the search space in the hyperparameter search snippet, it is likely that the radial basis function kernel is used.\n\n3. **RandomForestClassifier**: For the random forest, the best parameters include a maximum depth of 3 (`max_depth=3`), a minimum number of samples required to be at a leaf node (`min_samples_leaf=3`), and the number of trees in the forest (`n_estimators=50`). The `random_state` is again set to 45 for reproducibility.\n\n4. **KNeighborsClassifier**: This model is configured to use 7 neighbors (`n_neighbors=7`) and the Manhattan distance metric for its operation.\n\nThese models are typically stored in a list after the completion of hyperparameter tuning to easily access the best version of each classifier for further evaluation, ensemble methods, or deployment. \n And, the resulting DataFrame cv_results is displayed below the code snippet, showing each classifier along with its corresponding cross-validation mean and test result. The scores are as follows: \n # 4.3. Utilizing Ensemble Learning to Enhance Predictive Accuracy\n\nThe provided code snippet is implementing a voting ensemble machine learning model that combines the predictions from three different classifiers: Decision Tree, Random Forest, and K Nearest Neighbors. Each classifier has been previously tuned to find its best hyperparameters. The ensemble model is trained on a dataset, then used to make predictions on a test set. The accuracy of the model on the test set is calculated and printed, resulting in an accuracy of about 87.77%. This high accuracy indicates that the ensemble method is effective for the given prediction task. \n # 5. Making Predictions on the Original Test Set for the Leaderboard Submission",
    "n_cells": 63,
    "n_code_cells": 28,
    "n_markdown_cells": 35,
    "n_raw_cells": 0,
    "n_outputs": 28,
    "r_code_cells": 0.4444444444444444,
    "r_markdown_cells": 0.5555555555555556,
    "r_raw_cells": 0.0,
    "r_outputs": 1.0,
    "n_exceptions": 0,
    "r_exceptions": 0.0,
    "n_lines": 547,
    "n_lines_code": 242,
    "n_lines_markdown": 305,
    "lines_per_cell": [
        9,
        36,
        1,
        5,
        3,
        26,
        1,
        11,
        14,
        15,
        1,
        14,
        15,
        17,
        5,
        1,
        5,
        15,
        1,
        14,
        14,
        2,
        14,
        14,
        1,
        1,
        1,
        4,
        14,
        15,
        1,
        6,
        5,
        10,
        1,
        2,
        10,
        1,
        2,
        10,
        1,
        18,
        1,
        26,
        13,
        2,
        21,
        1,
        1,
        9,
        1,
        1,
        25,
        20,
        30,
        1,
        11,
        1,
        9,
        3,
        9,
        1,
        5
    ],
    "lines_per_code_cell": [
        9,
        5,
        3,
        14,
        14,
        17,
        5,
        14,
        14,
        1,
        4,
        14,
        5,
        2,
        2,
        18,
        1,
        13,
        2,
        9,
        1,
        1,
        20,
        30,
        1,
        9,
        9,
        5
    ],
    "lines_per_markdown_cell": [
        36,
        1,
        26,
        1,
        11,
        15,
        1,
        15,
        5,
        1,
        15,
        1,
        14,
        2,
        14,
        1,
        1,
        15,
        1,
        6,
        10,
        1,
        10,
        1,
        10,
        1,
        26,
        21,
        1,
        1,
        25,
        11,
        1,
        3,
        1
    ],
    "ave_lines_per_cell": 8.682539682539682,
    "ave_lines_per_code_cell": 8.642857142857142,
    "ave_lines_per_markdown_cell": 8.714285714285714,
    "max_lines_per_cell": 36,
    "max_lines_per_code_cell": 30,
    "max_lines_per_markdown_cell": 36,
    "min_lines_per_cell": 1,
    "min_lines_per_code_cell": 1,
    "min_lines_per_markdown_cell": 1,
    "n_chars": 36497,
    "n_chars_code": 8966,
    "n_chars_markdown": 27531,
    "chars_per_cell": [
        329,
        3167,
        21,
        113,
        110,
        1775,
        36,
        966,
        440,
        2240,
        9,
        425,
        1712,
        533,
        359,
        10,
        182,
        1324,
        12,
        442,
        1414,
        84,
        445,
        1579,
        13,
        169,
        27,
        119,
        450,
        1548,
        12,
        325,
        199,
        948,
        15,
        96,
        1048,
        30,
        96,
        621,
        18,
        966,
        34,
        2020,
        530,
        34,
        1930,
        21,
        23,
        349,
        7,
        7,
        1574,
        658,
        1118,
        15,
        1592,
        195,
        503,
        642,
        479,
        79,
        260
    ],
    "chars_per_code_cell": [
        329,
        113,
        110,
        440,
        425,
        533,
        182,
        442,
        445,
        27,
        119,
        450,
        199,
        96,
        96,
        966,
        34,
        530,
        34,
        349,
        7,
        7,
        658,
        1118,
        15,
        503,
        479,
        260
    ],
    "chars_per_markdown_cell": [
        3167,
        21,
        1775,
        36,
        966,
        2240,
        9,
        1712,
        359,
        10,
        1324,
        12,
        1414,
        84,
        1579,
        13,
        169,
        1548,
        12,
        325,
        948,
        15,
        1048,
        30,
        621,
        18,
        2020,
        1930,
        21,
        23,
        1574,
        1592,
        195,
        642,
        79
    ],
    "ave_chars_per_line": 66.72212065813528,
    "ave_chars_per_cell": 579.3174603174604,
    "ave_chars_per_code_cell": 320.2142857142857,
    "ave_chars_per_markdown_cell": 786.6,
    "max_chars_per_cell": 3167,
    "max_chars_per_code_cell": 1118,
    "max_chars_per_markdownell": 3167,
    "min_chars_per_cell": 7,
    "min_chars_per_code_cell": 7,
    "min_chars_per_markdown_cell": 9,
    "r_lines_code": 0.4424131627056673,
    "r_lines_markdown": 0.5575868372943327,
    "r_chars_markdown": 0.7543359728196838,
    "r_chars_code": 0.24566402718031619,
    "all_cells": [
        {
            "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n",
            "mc_idx": 0,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.1,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.05,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 4
                },
                "Data_Extraction": {
                    "read_csv": 2,
                    "pd.read_": 2
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".join(": 1,
                    ".join": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    0,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n"
                    ]
                },
                "mc_idx": 0,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 0,
                "o_idx": 0
            }
        },
        {
            "source": "# 0. Background\n\n\n## Introduction\nThe Titanic: Machine Learning from Disaster competition represents an engaging challenge that merges historical significance with predictive analytics. It provides an opportunity for data science enthusiasts and experts to apply machine learning techniques to a dataset that is both rich in history and complexity.\n\n## Problem Definition\nThe competition's objective is to predict survival on the Titanic, the passenger liner that sank in 1912 after colliding with an iceberg. The event holds substantial historical significance due to the loss of life, particularly because it reflected the societal norms of the era, such as class distinctions. The task of predicting survival is not merely an academic exercise but also a reflection on the human aspects behind data, underscoring the potential of machine learning in understanding human factors in historical events.\n\n## Expected Outputs\nThe expected output is a predictive model capable of determining the survival outcome for each passenger in the test set. Participants must submit a CSV file with two columns: `PassengerId` and `Survived`. The `Survived` column should contain the binary predictions: 1 for survived and 0 for did not survive. The model's performance is measured based on the accuracy of these predictions.\n\n## Dataset\nThe provided dataset consists of several attributes for each passenger aboard the Titanic:\n\n  - `PassengerId`: Unique identifier for each passenger.\n  - `Survived`: Survival status (0 = No, 1 = Yes).\n  - `Pclass`: Passenger class (1 = 1st, 2 = 2nd, 3 = 3rd).\n  - `Name`: Name of the passenger.\n  - `Sex`: Gender of the passenger (male or female).\n  - `Age`: Age of the passenger. Some entries are NaN, indicating missing values.\n  - `SibSp`: Number of siblings or spouses aboard.\n  - `Parch`: Number of parents or children aboard.\n  - `Ticket`: Ticket number.\n  - `Fare`: Passenger fare.\n  - `Cabin`: Cabin number. Contains NaN values, which represent missing data.\n  - `Embarked`: Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton).\n\nThe dataset will be used to train machine learning models that can discern patterns and associations between the features and the likelihood of survival.\n\n## Problem Type\nThe challenge is a binary classification problem, a type of supervised learning where the aim is to categorize the passengers into two groups: those who survived and those who did not. The nature of the `Survived` variable as a binary indicator makes it a clear case of classification rather than regression, which would predict continuous outcomes.\n\n## Conclusion\nThe Titanic Kaggle competition is a testbed for machine learning methodologies, offering insights into the social fabric of the early 20th century while advancing the field of data science. It presents a problem that is both historically enriching and technically stimulating, with the potential to develop predictive models that are not only accurate but also interpretative of the human stories behind the data.\nI will use a dataset containing information about those on board to develop a machine learning model that attempts to predict who survived.",
            "mc_idx": 1,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 1. Reading the data",
            "mc_idx": 2,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# temel k\u00fct\u00fcphaneler\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns",
            "mc_idx": 3,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.025,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.05,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 4
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "matplotlib": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "matplotlib": 1,
                    "pyplot": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    1,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 3,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 1,
                "o_idx": 0
            }
        },
        {
            "source": "test_df = pd.read_csv('/kaggle/input/titanic/test.csv')\ndf = pd.read_csv('/kaggle/input/titanic/train.csv')\ndf",
            "mc_idx": 4,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 4,
                    "pd.read_": 4
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    2,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "     PassengerId  Survived  Pclass  \\\n0              1         0       3   \n1              2         1       1   \n2              3         1       3   \n3              4         1       1   \n4              5         0       3   \n..           ...       ...     ...   \n886          887         0       2   \n887          888         1       1   \n888          889         0       3   \n889          890         1       1   \n890          891         0       3   \n\n                                                  Name     Sex   Age  SibSp  \\\n0                              Braund, Mr. Owen Harris    male  22.0      1   \n1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                               Heikkinen, Miss. Laina  female  26.0      0   \n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                             Allen, Mr. William Henry    male  35.0      0   \n..                                                 ...     ...   ...    ...   \n886                              Montvila, Rev. Juozas    male  27.0      0   \n887                       Graham, Miss. Margaret Edith  female  19.0      0   \n888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n889                              Behr, Mr. Karl Howell    male  26.0      0   \n890                                Dooley, Mr. Patrick    male  32.0      0   \n\n     Parch            Ticket     Fare Cabin Embarked  \n0        0         A/5 21171   7.2500   NaN        S  \n1        0          PC 17599  71.2833   C85        C  \n2        0  STON/O2. 3101282   7.9250   NaN        S  \n3        0            113803  53.1000  C123        S  \n4        0            373450   8.0500   NaN        S  \n..     ...               ...      ...   ...      ...  \n886      0            211536  13.0000   NaN        S  \n887      0            112053  30.0000   B42        S  \n888      2        W./C. 6607  23.4500   NaN        S  \n889      0            111369  30.0000  C148        C  \n890      0            370376   7.7500   NaN        Q  \n\n[891 rows x 12 columns]"
                    ]
                },
                "mc_idx": 4,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 2,
                "o_idx": 0
            }
        },
        {
            "source": "Here's a description of the data as displayed in the DataFrame:\n\n- **Columns in the DataFrame:**\n  - `PassengerId`: Unique identifier for each passenger.\n  - `Survived`: Survival status (0 = No, 1 = Yes).\n  - `Pclass`: Passenger class (1 = 1st, 2 = 2nd, 3 = 3rd).\n  - `Name`: Name of the passenger.\n  - `Sex`: Gender of the passenger (male or female).\n  - `Age`: Age of the passenger. Some entries are NaN, indicating missing values.\n  - `SibSp`: Number of siblings or spouses aboard.\n  - `Parch`: Number of parents or children aboard.\n  - `Ticket`: Ticket number.\n  - `Fare`: Passenger fare.\n  - `Cabin`: Cabin number. Contains NaN values, which represent missing data.\n  - `Embarked`: Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton).\n\n- **Sample Data:**\n  - The first row corresponds to a male passenger with a `PassengerId` of 1, who did not survive, was in 3rd class, and embarked from Southampton (`Embarked` = S).\n  - The third row shows a female passenger, `PassengerId` 3, who survived, was in 3rd class, and also embarked from Southampton.\n  - There are some missing data points, indicated by `NaN` (not a number), especially in the `Age` and `Cabin` columns, which will require careful handling during data preprocessing for any machine learning tasks.\n\n- **Data Use:**\n  - `Survived` is the target variable for the prediction model.\n  - Other columns serve as features to train machine learning models to predict the target variable. Features like `Name` and `Ticket` might be used for feature engineering, while `Cabin` and `Age` would need to deal with missing values.\n\nThis data is  used to train classification models to predict the `Survived` column, which is a binary outcome indicating whether a passenger survived the Titanic disaster.",
            "mc_idx": 5,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.Exploratory Data Analysis (EDA) ",
            "mc_idx": 6,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.1 Pclass\n\n\"Pclass\" signifies the accommodation category for travelers on the Titanic, reflective of their socio-economic stature. \n\n- 1st Class: This tier was the domain of the affluent and illustrious\u2014magnates, celebrities, or distinguished personas. It offered spacious quarters and superior dining and amenities.\n\n- 2nd Class: Serving as a mid-level option, it was less opulent than 1st Class but provided a comfortable journey for middle-class travelers. The cabins were more compact, and there were fewer luxuries.\n\n- 3rd Class: This was the most basic level of travel, primarily for individuals of modest means, often immigrants or those with lesser financial resources. Accommodations were more confined, with basic amenities.\n\nThe Pclass is indicative of the passengers' financial and social ranking. It is a critical factor in survival analysis due to the potential influence of class on emergency response and evacuation procedures during the disaster.",
            "mc_idx": 7,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "plt.figure(figsize=(8, 6))\nax = sns.countplot(data=df, x='Pclass')\n\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.0f'), \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha = 'center', va = 'center', \n                xytext = (0, 10), \n                textcoords = 'offset points')\n\nplt.title('Distribution of Passenger Classes')\nplt.xlabel('Passenger Class')\nplt.ylabel('Count')\nplt.show()",
            "mc_idx": 8,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.5,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0028_c003_o000_image_0.png",
                    3,
                    0,
                    0
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 800x600 with 1 Axes>"
                    ]
                },
                "mc_idx": 8,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 3,
                "o_idx": 0
            }
        },
        {
            "source": "Here are some observations and comments based on the chart:\n\n1. **Third Class is the Most Populous:** With 491 passengers, the Third Class had the highest number of passengers compared to the other classes. This reflects the economic demographics of the time, where a larger portion of the population were of lower socio-economic status, which also correlates with the common practice of ships carrying more third-class passengers to maximize ticket sales.\n\n2. **First Class has More Passengers than Second:** There were 216 passengers in First Class and slightly fewer, 184, in Second Class. This could indicate that the Titanic was quite luxurious and attracted a significant number of affluent passengers who could afford the higher fare for better accommodations and services.\n\n3. **Economic Implications:** The distribution shows the economic stratification of society at the time. A substantial number of people were traveling in Third Class, possibly in hope of starting a new life in America, which was a common reason for travel among immigrants during that period.\n\n4. **Implications for Survival Analysis:** Given the larger number of Third Class passengers, if resources and lifeboats were limited and preferentially allocated to higher classes, this could have significantly influenced survival rates. Historical accounts suggest that First Class passengers had better access to lifeboats, which is an important aspect to consider in survival analysis.\n\n5. **Data Visualization Insights:** The bar chart effectively communicates the difference in class sizes, which is crucial for data exploration in predictive modeling. It's a good practice to visualize data this way to understand the underlying distributions before applying machine learning algorithms.\n\n6. **Potential Bias in Model Training:** When training machine learning models on this data, the imbalance in class distribution may introduce bias. Models might perform better at predicting survival for Third Class passengers simply because there are more data points for that class.\n\nOverall, the visualization underscores the importance of considering passenger class as a feature in predictive models and as a factor in historical analyses of the Titanic disaster.",
            "mc_idx": 9,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.2 Sex",
            "mc_idx": 10,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "plt.figure(figsize=(8, 6))\nax = sns.countplot(data=df, x='Sex')\n\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.0f'), \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha = 'center', va = 'center', \n                xytext = (0, 10), \n                textcoords = 'offset points')\n\nplt.title('Distribution of Sex')\nplt.xlabel('Sex of Passengers')\nplt.ylabel('Count')\nplt.show()",
            "mc_idx": 11,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.5,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0028_c004_o000_image_1.png",
                    4,
                    0,
                    1
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 800x600 with 1 Axes>"
                    ]
                },
                "mc_idx": 11,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 4,
                "o_idx": 0
            }
        },
        {
            "source": " Here are some insights and comments regarding the chart:\n\n1. **Gender Disparity:** The chart illustrates that there were considerably more male passengers (577) than female passengers (314) on the Titanic. This reflects the gender demographics of passengers who were traveling at that time.\n\n2. **Implications for Survival Predictions:** Historical records indicate that the protocol of \"women and children first\" was often followed during maritime disasters. Therefore, despite being outnumbered, female passengers might have had a higher survival rate compared to males, which is a critical consideration for predictive modeling.\n\n3. **Visualization Effectiveness:** The bar chart clearly demonstrates the disparity in numbers between male and female passengers. Such visualizations are important in exploratory data analysis as they provide immediate insights into the dataset's structure before any statistical modeling.\n\n4. **Influence on Model Training:** The imbalance shown here may influence the performance of machine learning models. If the model is not adjusted to account for this imbalance, it may become biased towards predicting the survival of males, simply because there are more male passengers in the dataset.\n\n5. **Historical Context:** The higher number of males might be reflective of the societal norms of the time, where men were more likely to travel alone for business or emigration purposes, while women often traveled with families.\n\n6. **Data Preparation Considerations:** When preparing the dataset for machine learning, it might be beneficial to consider techniques like stratification to ensure that both genders are adequately represented in the training and validation sets.\n\n",
            "mc_idx": 12,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Calculate the mean survival rates by sex\nsurvival_rates = df.groupby('Sex')['Survived'].mean().reset_index()\n\n# Create the bar plot\nsns.barplot(x='Sex', y='Survived', data=survival_rates)\n\n# Adding the actual survival rates on top of the bars\nfor index, value in enumerate(survival_rates['Survived']):\n    plt.text(index, value, f'{value:.4f}', ha='center', va='bottom')\n\n# Set the title and labels for the plot\nplt.title('Survival Rates by Sex')\nplt.ylabel('Average Survival Rate')\nplt.xlabel('Sex')\n\n# Display the plot\nplt.show()",
            "mc_idx": 13,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.25,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.5,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.25,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    "sns.": 1,
                    ".mean": 1,
                    ".groupby": 1
                },
                "Data_Transform": {
                    ".groupby(": 1,
                    ".reset_index": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0028_c005_o000_image_2.png",
                    5,
                    0,
                    2
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 13,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 5,
                "o_idx": 0
            }
        },
        {
            "source": "Here are some comments and interpretations based on the chart:\n\n1. **Significant Gender-Based Survival Disparity:** The bar chart highlights a stark difference in survival rates between females and males. Female passengers had a much higher survival rate of approximately 74.2%, while the survival rate for male passengers was markedly lower at about 18.9%.\n\n",
            "mc_idx": 14,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.3. Age",
            "mc_idx": 15,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "sns.histplot(x=\"Age\", hue=\"Survived\", palette=\"mako\", data=df[[\"Age\",\"Survived\"]])\nplt.title(\"Age Distribution\", color='black', fontsize=14) \nplt.yticks([])\nplt.box(False)\nplt.show()",
            "mc_idx": 16,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.5,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0028_c006_o000_image_3.png",
                    6,
                    0,
                    3
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 16,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 6,
                "o_idx": 0
            }
        },
        {
            "source": "Here are some comments and insights based on the chart:\n\n1. **Bimodal Distribution:** The age distribution appears to be bimodal, with two peaks suggesting that younger adults and children were the most common age groups among the passengers.\n\n2. **Higher Survival Rate Among Younger Passengers:** The lighter-colored bars, which represent the passengers who survived, seem more prominent in the lower age groups, suggesting that younger passengers had a higher survival rate.\n\n3. **Declining Survival with Age:** There is a noticeable decline in survival rate as age increases, particularly noticeable in passengers older than 30 years old.\n\n4. **Children's Survival:** The survival rate for very young passengers (children) seems to be high, which could be attributed to the \"women and children first\" policy during lifeboat loading.\n\n5. **Effective Visualization:** This stacked histogram effectively conveys the relationship between age and survival. It allows for easy comparison between the number of survivors and non-survivors within each age group.\n\n6. **Insights for Model Training:** For predictive modeling, this visualization suggests that age could be an important feature, potentially requiring more nuanced treatment such as binning into categorical age groups or creating age-related interaction features.\n\n",
            "mc_idx": 17,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.4. SibSp",
            "mc_idx": 18,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "plt.figure(figsize=(10, 6))\nax = sns.countplot(data=df, x='SibSp')\n\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.0f'), \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha = 'center', va = 'center', \n                xytext = (0, 10), \n                textcoords = 'offset points')\n\nplt.title('Distribution of Siblings Amount')\nplt.xlabel('Title of Passengers')\nplt.ylabel('Count')\nplt.show()",
            "mc_idx": 19,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.5,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0028_c007_o000_image_4.png",
                    7,
                    0,
                    4
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1000x600 with 1 Axes>"
                    ]
                },
                "mc_idx": 19,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 7,
                "o_idx": 0
            }
        },
        {
            "source": "Here are some observations and insights from the chart:\n\n1. **Most Passengers Traveled Alone:** A significant majority of passengers, indicated by the tallest bar with a count of 608, did not have siblings or spouses on board. This suggests that solo travel was common.\n\n2. **Smaller Family Units:** The second bar, with a count of 209, shows that a substantial number of passengers traveled with one sibling or spouse, indicating smaller family units or couples without children.\n\n3. **Rarity of Large Families:** Very few passengers traveled with more than two siblings or spouses. The counts for passengers with three or more siblings/spouses are markedly lower, which highlights the rarity of large families or sibling groups traveling together.\n\n4. **Exceptional Cases:** There are a few exceptional cases of passengers with large numbers of siblings/spouses on board, such as 5 or 8, which are very uncommon. These could potentially represent larger family groups or possibly group tickets.\n\n5. **Potential Impact on Survival:** The number of siblings/spouses could have implications for survival rates, as those with family aboard might have sought one another out during the disaster, potentially affecting their likelihood of reaching the lifeboats.\n\n\nThis chart provides a clear visual representation of the distribution of family sizes aboard the Titanic, with the majority being individuals or couples.",
            "mc_idx": 20,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Let's examine the survival rate according to the number of siblings or spouses.**\n",
            "mc_idx": 21,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "survival_by_sibsp = df.groupby('SibSp')['Survived'].mean()\n\nplt.figure(figsize=(8, 6))\nax = sns.barplot(x=survival_by_sibsp.index, y=survival_by_sibsp.values)\nplt.title('Survival Rate by SibSp')\nplt.xlabel('Number of Siblings/Spouses')\nplt.ylabel('Survival Rate')\n\ntotal = float(len(df))\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x() + p.get_width() / 2., height + 0.02, '{:.1%}'.format(height), ha=\"center\")\n\nplt.show()",
            "mc_idx": 22,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.2,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    "sns.": 1,
                    "size": 1,
                    ".mean": 1,
                    ".groupby": 1
                },
                "Data_Transform": {
                    ".groupby(": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0028_c008_o000_image_5.png",
                    8,
                    0,
                    5
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 800x600 with 1 Axes>"
                    ]
                },
                "mc_idx": 22,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 8,
                "o_idx": 0
            }
        },
        {
            "source": "Here are some key takeaways from the chart:\n\n1. **Varied Survival Rates:** The survival rates differ across the number of siblings/spouses. Passengers without any siblings or spouses on board had a survival rate of 34.5%, while those with one sibling/spouse had a higher survival rate of 53.6%.\n\n2. **Decreasing Trend with More Siblings/Spouses:** As the number of siblings/spouses increases, there's a general trend of decreasing survival rates. This is evident from the drop to 46.4% for passengers with two siblings/spouses, 25% for those with three, and even lower for four.\n\n3. **Zero Survival for Larger Families:** There are no survivors among the passengers who had five or eight siblings/spouses on board, as indicated by the 0.0% survival rate for these groups.\n\n4. **Highest Survival for Smaller Families:** The highest survival rate is observed among passengers with one sibling/spouse, which could suggest that those with a single family member to look out for could more easily maneuver and access life-saving resources.\n\n5. **Potential Outliers:** The passengers with a very high number of siblings/spouses (such as 5 and 8) are outliers with a survival rate of 0%. This might reflect the difficulty of larger groups to secure a place on lifeboats or could also indicate data entry errors or exceptional cases that warrant further investigation.\n\n\nThis chart provides insight into the dynamics of survival aboard the Titanic and indicates that the presence of family members could have both aided and hindered survival chances, depending on the size of the family.",
            "mc_idx": 23,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.5. Ticket",
            "mc_idx": 24,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Let's examine the tickets. Individuals who bought identical tickets are regarded as a collective unit and are attributed to a newly created attribute named 'Group_Size'.",
            "mc_idx": 25,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "df[\"Ticket\"].value_counts()",
            "mc_idx": 26,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    9,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Ticket\n347082      7\nCA. 2343    7\n1601        7\n3101295     6\nCA 2144     6\n           ..\n9234        1\n19988       1\n2693        1\nPC 17612    1\n370376      1\nName: count, Length: 681, dtype: int64"
                    ]
                },
                "mc_idx": 26,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 9,
                "o_idx": 0
            }
        },
        {
            "source": "newdf = df.copy()\n\nnewdf[\"Group_Size\"] = newdf.groupby(\"Ticket\")[\"PassengerId\"].transform(\"count\")\nnewdf[\"Group_Size\"] ",
            "mc_idx": 27,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.6666666666666666,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 2,
                    ".groupby": 1
                },
                "Data_Transform": {
                    ".groupby(": 1,
                    "transform": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    10,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0      1\n1      1\n2      1\n3      2\n4      1\n      ..\n886    1\n887    1\n888    2\n889    1\n890    1\nName: Group_Size, Length: 891, dtype: int64"
                    ]
                },
                "mc_idx": 27,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 10,
                "o_idx": 0
            }
        },
        {
            "source": "plt.figure(figsize=(10, 6))\nax = sns.countplot(data=newdf, x='Group_Size')\n\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.0f'), \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha = 'center', va = 'center', \n                xytext = (0, 10), \n                textcoords = 'offset points')\n\nplt.title('Distribution of Group Size')\nplt.xlabel('Group Size of Passengers')\nplt.ylabel('Count')\nplt.show()",
            "mc_idx": 28,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 4
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0028_c011_o000_image_6.png",
                    11,
                    0,
                    6
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1000x600 with 1 Axes>"
                    ]
                },
                "mc_idx": 28,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 11,
                "o_idx": 0
            }
        },
        {
            "source": " Here are some observations from the chart:\n\n1. **Solo Travelers:** The largest bar represents individuals traveling alone (group size of 1), with a count of 547. This indicates that the majority of passengers on the Titanic purchased tickets individually rather than as part of a group.\n\n2. **Small Groups:** The second-largest bar represents groups of two, with a count of 188, suggesting that traveling in pairs was also common. This could include couples or two friends/family members traveling together.\n\n3. **Declining Numbers with Larger Groups:** As the group size increases, the number of such groups decreases significantly. For example, there are only 63 groups of size 3, and even fewer as the size increases.\n\n4. **Larger Groups are Less Common:** Very large groups (such as those with sizes 5, 6, or 7) are much less common, as indicated by the relatively small bar heights for these group sizes.\n\n5. **Potential Family or Tour Groups:** Some of the larger group sizes, like 7, with a count of 21, could indicate families traveling together or organized tour groups.\n\n6. **Implications for Survival Analysis:** The group size may have had an impact on survival rates, as those in larger groups might have had different dynamics when it came to evacuation procedures compared to those traveling alone or in pairs.\n\nThis visualization provides a clear representation of how passengers were distributed by group size, which can be a useful feature for understanding social dynamics on the Titanic and for predictive modeling of survival.",
            "mc_idx": 29,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.6. Cabin",
            "mc_idx": 30,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "First, the following steps were performed:\n\n1. Missing values in the 'Cabin' column were filled with the string \"Unknown\".\n2. Only the first letter of each cabin entry was retained to categorize the cabins.\n3. A count plot was created to show the count of passengers who did and did not survive, separated by cabin category.\n",
            "mc_idx": 31,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "newdf = df.copy()\nnewdf[\"Cabin\"].fillna(\"Unknown\",inplace=True)\nnewdf[\"Cabin\"] = newdf[\"Cabin\"].str[0]\nsns.set(style=\"darkgrid\")\nsns.countplot( x='Survived', data=newdf, hue=\"Cabin\", palette=\"Set1\");",
            "mc_idx": 32,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 2
                },
                "Data_Transform": {
                    ".fillna(": 1,
                    ".fillna": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0028_c012_o000_image_7.png",
                    12,
                    0,
                    7
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 32,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 12,
                "o_idx": 0
            }
        },
        {
            "source": "\nHere are some observations based on the count plot in the image:\n\n- The majority of passengers have an unknown cabin designation, denoted as 'U', with a high non-survival rate.\n- Passengers from cabin categories 'C', 'E', 'G', 'D', 'A', 'B', 'F', and 'T' are also represented, with varying counts of survival and non-survival.\n- Cabin 'C' has the second-highest count among those who did not survive and a significant count of survivors.\n- Cabins 'E' and 'D' show a relatively higher survival rate compared to non-survival.\n- The 'T' cabin category has a very low count, which may indicate it's an outlier or a special case.\n\nThis visualization suggests that cabin location may have played a role in the passengers' likelihood of survival, which could be related to the proximity to lifeboats or other escape routes. It's worth noting that the high number of unknown cabins can affect the overall analysis and interpretations drawn from this data.",
            "mc_idx": 33,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.7. Embarked",
            "mc_idx": 34,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "sns.set(style=\"darkgrid\")\nsns.countplot( x='Survived', data=df, hue=\"Embarked\", palette=\"Set1\");",
            "mc_idx": 35,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0028_c013_o000_image_8.png",
                    13,
                    0,
                    8
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 35,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 13,
                "o_idx": 0
            }
        },
        {
            "source": "It represents the survival of passengers based on the port where they embarked on the Titanic, with \"S\" for Southampton, \"C\" for Cherbourg, and \"Q\" for Queenstown.\n\nHere are some observations from the chart:\n\n- A larger number of passengers embarked from Southampton (S), with a higher count of those who did not survive (0) compared to those who did (1).\n- For passengers who embarked from Cherbourg (C), the survival count is relatively high compared to the non-survival count.\n- Queenstown (Q) had the fewest passengers, with a non-survival rate that appears to be slightly higher than the survival rate.\n- The survival rate of passengers from Cherbourg stands out as being higher than that of the other two ports.\n\nThis chart could suggest that passengers embarking from different ports had different survival rates, possibly due to various factors such as the socioeconomic status of passengers, which could correlate with their point of embarkation, or perhaps the location on the ship where passengers from different ports were accommodated.",
            "mc_idx": 36,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.8. And Target Distribution",
            "mc_idx": 37,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "sns.set(style=\"darkgrid\")\nsns.countplot( x='Survived', data=df, hue=\"Survived\", palette=\"Set1\");",
            "mc_idx": 38,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0028_c014_o000_image_9.png",
                    14,
                    0,
                    9
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 38,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 14,
                "o_idx": 0
            }
        },
        {
            "source": " In this chart:\n\n- The red bar represents passengers who did not survive (0).\n- The blue bar represents passengers who did survive (1).\n\nObservations from the chart are:\n\n- There are more non-survivors than survivors, with the non-survivors' bar being significantly taller.\n- This imbalance in the target variable distribution may suggest a need for stratified sampling or other techniques to address class imbalance when training machine learning models.\n- The visualization gives a clear representation of the binary classification nature of the problem, where the goal is to predict one of these two possible outcomes.",
            "mc_idx": 39,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 3. Data Cleaning",
            "mc_idx": 40,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "def missing_zero_values_table(df):\n    zero_val = (df == 0.00).astype(int).sum(axis=0)\n    mis_val = df.isnull().sum()\n    mis_val_percent = 100 * df.isnull().sum() / len(df)\n    mz_table = pd.concat([zero_val, mis_val, mis_val_percent], axis=1)\n    mz_table = mz_table.rename(\n    columns = {0 : 'Zero Values', 1 : 'Missing Values', 2 : '% of Total Values'})\n    mz_table['Total Zero Missing Values'] = mz_table['Zero Values'] + mz_table['Missing Values']\n    mz_table['% Total Zero Missing Values'] = 100 * mz_table['Total Zero Missing Values'] / len(df)\n    mz_table['Data Type'] = df.dtypes\n    mz_table = mz_table[ mz_table.iloc[:,1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns and \" + str(df.shape[0]) + \" Rows.\\n\"\n           \"There are \" + str(mz_table.shape[0]) +\n            \"columns that have missing values.\")\n    return mz_table\n\n\nmissing_zero_values_table(df)",
            "mc_idx": 41,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.3,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.15,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "df.isnull().sum": 2,
                    "missing values": 6,
                    "dtypes": 1,
                    "columns": 3,
                    "shape": 3,
                    ".isnull": 2,
                    ".sum": 3
                },
                "Data_Transform": {
                    ".concat(": 1,
                    ".astype(": 1,
                    ".sort_values": 1,
                    ".rename": 1,
                    ".concat": 1,
                    ".round": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    15,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Your selected dataframe has 12 columns and 891 Rows.\nThere are 3columns that have missing values.\n",
                        "          Zero Values  Missing Values  % of Total Values  \\\nCabin               0             687               77.1   \nAge                 0             177               19.9   \nEmbarked            0               2                0.2   \n\n          Total Zero Missing Values  % Total Zero Missing Values Data Type  \nCabin                           687                         77.1    object  \nAge                             177                         19.9   float64  \nEmbarked                          2                          0.2    object  "
                    ]
                },
                "mc_idx": 41,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 15,
                "o_idx": 1
            }
        },
        {
            "source": "missing_zero_values_table(test_df)",
            "mc_idx": 42,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    16,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Your selected dataframe has 11 columns and 418 Rows.\nThere are 3columns that have missing values.\n",
                        "       Zero Values  Missing Values  % of Total Values  \\\nCabin            0             327               78.2   \nAge              0              86               20.6   \nFare             2               1                0.2   \n\n       Total Zero Missing Values  % Total Zero Missing Values Data Type  \nCabin                        327                         78.2    object  \nAge                           86                         20.6   float64  \nFare                           3                          0.7   float64  "
                    ]
                },
                "mc_idx": 42,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 16,
                "o_idx": 1
            }
        },
        {
            "source": "`missing_zero_values_table` analyzes the dataframes for zero values and missing values.\n\nHere's a summary of the missing data information provided in the tables:\n\n**Training DataFrame:**\n- Contains 13 columns and 891 rows.\n- Three columns have missing values:\n  - `Cabin`: 687 missing values, which is 77.1% of the total number of rows.\n  - `Age`: 177 missing values, 19.9% of the rows.\n  - `Embarked`: 2 missing values, 0.2% of the rows.\n\n**Test DataFrame:**\n- Contains 11 columns and 418 rows.\n- Three columns have missing values:\n  - `Cabin`: 327 missing values, 78.2% of the rows.\n  - `Age`: 86 missing values, 20.6% of the rows.\n  - `Fare`: 1 missing value, 0.2% of the rows, and also 2 zero values.\n\nFrom this information, we can deduce that:\n\n- The `Cabin` column has a very high percentage of missing values in both datasets, suggesting that it may not be a reliable feature for machine learning models unless some form of imputation or feature engineering is done.\n- The `Age` column has a significant, but much smaller, percentage of missing values. Imputation strategies such as median age could be considered.\n- The `Embarked` column in the training set and the `Fare` column in the test set have a very small number of missing values and could be filled with the most common value or the median, respectively.\n- The presence of two zero values in the `Fare` column of the test set might indicate either free tickets or data entry errors and might require further investigation or a decision on a case-by-case basis.\n\nTo clean this data, you would typically fill in the missing values with appropriate statistics (like the median or mode), or possibly infer missing values based on other data. For categorical data like `Cabin` and `Embarked`, you might consider filling in missing values with the most common category, or creating a new category for missing data. For numerical data like `Age` and `Fare`, you might use a measure of central tendency (mean, median) or employ a model-based imputation method.",
            "mc_idx": 43,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "def clean_data(data):\n    data['Fare'] = data['Fare'].fillna(data['Fare'].dropna().median())\n    data['Age'] =  data['Age'].fillna(data['Age'].dropna().median())\n    \n    data.loc[data['Sex'] == 'male', 'Sex'] = 0\n    data.loc[data['Sex'] =='female',  'Sex'] = 1\n    \n    data['Embarked'] = data['Embarked'].fillna('S')\n    data.loc[data[\"Embarked\"] == 'S', 'Embarked'] = 0\n    data.loc[data['Embarked'] == 'C', 'Embarked'] = 1\n    data.loc[data['Embarked'] == 'Q', 'Embarked'] =2\n    \n    data.drop([\"Cabin\"],axis=1,inplace=True)",
            "mc_idx": 44,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3076923076923077,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".median": 4
                },
                "Data_Transform": {
                    ".fillna(": 3,
                    ".dropna(": 2,
                    ".drop": 3,
                    ".dropna": 2,
                    ".fillna": 3
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    17,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 44,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 17,
                "o_idx": 0
            }
        },
        {
            "source": "clean_data(df)\nclean_data(test_df)",
            "mc_idx": 45,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    18,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 45,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 18,
                "o_idx": 0
            }
        },
        {
            "source": "`clean_data`  is written to perform several data cleaning operations on a pandas DataFrame. Below is a description of what each line of code within the function does:\n\n1. `data['Fare'] = data['Fare'].fillna(data['Fare'].dropna().median())`: This line fills any missing (NaN) values in the 'Fare' column with the median fare calculated from the non-missing values.\n\n2. `data['Age'] = data['Age'].fillna(data['Age'].dropna().median())`: This line fills any missing (NaN) values in the 'Age' column with the median age calculated from the non-missing values.\n\n3. `data.loc[data['Sex'] == 'male', 'Sex'] = 0`: This line converts the categorical 'Sex' data into numerical form, replacing 'male' with 0.\n\n4. `data.loc[data['Sex'] == 'female', 'Sex'] = 1`: Similarly, this line replaces 'female' with 1 in the 'Sex' column.\n\n5. `data['Embarked'] = data['Embarked'].fillna('S')`: This line fills any missing values in the 'Embarked' column with 'S', which likely stands for Southampton, the most common port of embarkation.\n\n6. `data.loc[data['Embarked'] == 'S', 'Embarked'] = 0`: This line assigns a numeric value of 0 to all instances where the embarkation port is 'S'.\n\n7. `data.loc[data['Embarked'] == 'C', 'Embarked'] = 1`: This line assigns a numeric value of 1 to all instances where the embarkation port is 'C'.\n\n8. `data.loc[data['Embarked'] == 'Q', 'Embarked'] = 2`: This line assigns a numeric value of 2 to all instances where the embarkation port is 'Q'.\n\n9. `data.drop([\"Cabin\"], axis=1, inplace=True)`: This line removes the 'Cabin' column from the DataFrame entirely, which might be due to the high percentage of missing values as shown in the one, making it potentially less useful for predictive modeling.\n\nOverall, this function handles missing values, converts categorical variables to numerical, and drops a column with excessive missing data, which are common steps in preparing data for machine learning algorithms.",
            "mc_idx": 46,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 4. Creating a Model",
            "mc_idx": 47,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 4.1. Train-Test Split",
            "mc_idx": 48,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\ndf[\"Survived\"] = df[\"Survived\"].astype(int)\nX = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']].values\ny = df[\"Survived\"].values\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1,stratify=y, random_state = 105)",
            "mc_idx": 49,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.1,
                "Data_Transform": 0.1,
                "Model_Train": 0.2,
                "Model_Evaluation": 0.15,
                "Model_Interpretation": 0.05,
                "Hyperparameter_Tuning": 0.1,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 20
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1,
                    ".mode": 1
                },
                "Data_Transform": {
                    ".astype(": 1,
                    ".mod": 1
                },
                "Model_Train": {
                    "train_test_split": 2,
                    "model": 1,
                    "model_selection": 1
                },
                "Model_Evaluation": {
                    "accuracy_score": 2,
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {
                    "train_test_split": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    19,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 49,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 19,
                "o_idx": 0
            }
        },
        {
            "source": "X_train",
            "mc_idx": 50,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    20,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([[2, 1, 17.0, ..., 0, 10.5, 0],\n       [3, 1, 14.0, ..., 0, 11.2417, 1],\n       [1, 0, 51.0, ..., 0, 26.55, 0],\n       ...,\n       [1, 0, 45.0, ..., 0, 26.55, 0],\n       [3, 0, 27.0, ..., 0, 6.975, 0],\n       [3, 0, 21.0, ..., 0, 8.4333, 0]], dtype=object)"
                    ]
                },
                "mc_idx": 50,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 20,
                "o_idx": 0
            }
        },
        {
            "source": "y_train",
            "mc_idx": 51,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    21,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n       0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n       1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n       0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n       0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n       1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n       1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n       0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n       0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n       0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n       1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n       0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n       1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n       1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n       0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n       0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n       0, 0, 1, 0, 1, 0, 1, 1, 0])"
                    ]
                },
                "mc_idx": 51,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 21,
                "o_idx": 0
            }
        },
        {
            "source": "# 4.2. Hyperparameter search\n\nEach dictionary is named after the classifier it is intended for and includes a set of parameters and the range of values to be tested for each. The classifiers and their respective hyperparameters are as follows:\n\n1. **Decision Tree Classifier (`dt_hyperparameters`)**:\n   - `min_samples_split`: A range of values from 10 to 500, with a step of 20.\n   - `max_depth`: A range of values from 1 to 20, with a step of 2.\n\n2. **Support Vector Machine (`svc_hyperparameters`)**:\n   - `kernel`: A fixed value of 'rbf' indicating the use of the radial basis function kernel.\n   - `gamma`: A list of potential values `[0.001, 0.01, 0.1]`.\n   - `C`: A list of potential regularization parameter values `[1, 10, 50, 100, 250, 500]`.\n\n3. **Random Forest Classifier (`rf_hyperparameters`)**:\n   - `max_depth`: A list of potential values `[1, 3, 5,7]`.\n   - `min_samples_leaf`: A list of potential values `[1, 3, 5]`.\n   - `n_estimators`: The number of trees in the forest with values `[50, 100, 150]`.\n\n4. **K Nearest Neighbors (`knn_hyperparameters`)**:\n   - `n_neighbors`: A list of potential values `[1, 3, 5, 7]`.\n   - `metric`: A single value 'manhattan', which is a type of distance measurement.\n\nFinally, a list called `classifier_param` is defined which aggregates the dictionaries of hyperparameters for each classifier.\n\nThis setup will be used in combination with a grid search cross-validation procedure, where each combination of parameters for each classifier will be tested to find the best performing model based on some evaluation metric. ",
            "mc_idx": 52,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "dt_hyperparameters= {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_hyperparameters= {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1],\n                 \"C\": [1,10,50,100,250,500]}\n\n\nrf_hyperparameters= {\"max_depth\":[1,3,5,7],\n                \"min_samples_leaf\":[1,3,5],\n                \"n_estimators\":[50,100,150]}\n\nknn_hyperparameters= {\"n_neighbors\": [1,3,5,7],\n                 \"metric\":[\"manhattan\"]} \n             \nclassifier_param = [\n                    dt_hyperparameters,\n                   svc_hyperparameters,\n                   rf_hyperparameters,\n                   knn_hyperparameters]",
            "mc_idx": 53,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.08,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "svc": 2
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 9,
                    "hyperparameter": 8,
                    "hyperparameters": 8
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    22,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 53,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 22,
                "o_idx": 0
            }
        },
        {
            "source": "# e\u011fitim i\u00e7in\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.exceptions import ConvergenceWarning\n# Suppress ConvergenceWarning\nwarnings.simplefilter('ignore', ConvergenceWarning)\n\nrandom_state=45\nclassifier = [\n             DecisionTreeClassifier(random_state = random_state),\n             SVC(),\n             RandomForestClassifier(random_state = random_state),\n             KNeighborsClassifier()]\n\n\ncv_result = []\nreal_test_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    real_test_result.append(clf.score(X_test, y_test)) ",
            "mc_idx": 54,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.03614457831325301,
                "Data_Transform": 0.03614457831325301,
                "Model_Train": 0.21686746987951808,
                "Model_Evaluation": 0.04819277108433735,
                "Model_Interpretation": 0.03614457831325301,
                "Hyperparameter_Tuning": 0.1686746987951807,
                "Visualization": 0.0,
                "Debug": 0.012048192771084338,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 8
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mode": 3
                },
                "Data_Transform": {
                    ".mod": 3
                },
                "Model_Train": {
                    "train_test_split": 1,
                    ".fit(": 1,
                    "model": 3,
                    "randomforestclassifier": 4,
                    "model_selection": 3,
                    "decisiontreeclassifier": 2,
                    "kneighborsclassifier": 2,
                    "svc": 2
                },
                "Model_Evaluation": {
                    "model": 3,
                    ".score(": 1
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 6,
                    "param_grid": 1,
                    "param": 2,
                    "kfold": 2,
                    "stratifiedkfold": 2,
                    "train_test_split": 1
                },
                "Visualization": {},
                "Debug": {
                    "exception": 1
                },
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    23,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Fitting 10 folds for each of 250 candidates, totalling 2500 fits\nFitting 10 folds for each of 18 candidates, totalling 180 fits\nFitting 10 folds for each of 36 candidates, totalling 360 fits\nFitting 10 folds for each of 4 candidates, totalling 40 fits\n"
                    ]
                },
                "mc_idx": 54,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 23,
                "o_idx": 0
            }
        },
        {
            "source": "best_estimators",
            "mc_idx": 55,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    24,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "[DecisionTreeClassifier(max_depth=7, min_samples_split=10, random_state=45),\n SVC(C=500, gamma=0.001),\n RandomForestClassifier(max_depth=3, min_samples_leaf=3, n_estimators=50,\n                        random_state=45),\n KNeighborsClassifier(metric='manhattan', n_neighbors=7)]"
                    ]
                },
                "mc_idx": 55,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 24,
                "o_idx": 0
            }
        },
        {
            "source": "These appear to be the best-performing models as determined by a hyperparameter tuning process such as grid search or random search. Here's a summary of the models and their corresponding best hyperparameters:\n\n1. **DecisionTreeClassifier**: Found to perform best with a maximum depth of 7 (`max_depth=7`) and a minimum number of samples required to split an internal node (`min_samples_split=10`). A `random_state` has been set to 45, which is used for initializing the internal random number generator, ensuring reproducibility of the results.\n\n2. **SVC (Support Vector Classifier)**: The optimal hyperparameters for the support vector machine include a regularization parameter `C` set to 500 and a kernel coefficient `gamma` set to 0.001. The kernel is not explicitly mentioned, but since 'rbf' was part of the search space in the hyperparameter search snippet, it is likely that the radial basis function kernel is used.\n\n3. **RandomForestClassifier**: For the random forest, the best parameters include a maximum depth of 3 (`max_depth=3`), a minimum number of samples required to be at a leaf node (`min_samples_leaf=3`), and the number of trees in the forest (`n_estimators=50`). The `random_state` is again set to 45 for reproducibility.\n\n4. **KNeighborsClassifier**: This model is configured to use 7 neighbors (`n_neighbors=7`) and the Manhattan distance metric for its operation.\n\nThese models are typically stored in a list after the completion of hyperparameter tuning to easily access the best version of each classifier for further evaluation, ensemble methods, or deployment.",
            "mc_idx": 56,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "And, the resulting DataFrame cv_results is displayed below the code snippet, showing each classifier along with its corresponding cross-validation mean and test result. The scores are as follows:",
            "mc_idx": 57,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "cv_results = pd.DataFrame({ \"Machine Learning Models\":\n                                               [\"Decision Tree Classifier\", \n                                                \"Support Vector Machines\",\n                                                \"Random Forest Classifier\",\n                                                 \"K Nearest Neighbors Classifier\"],\n                           \"Cross Validation Mean\": cv_result, \n                           \"Test Result\": real_test_result})\ncv_results\n",
            "mc_idx": 58,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1,
                    "learning models": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    25,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "          Machine Learning Models  Cross Validation Mean  Test Result\n0        Decision Tree Classifier               0.820293     0.866667\n1         Support Vector Machines               0.806512     0.833333\n2        Random Forest Classifier               0.824012     0.844444\n3  K Nearest Neighbors Classifier               0.744136     0.744444"
                    ]
                },
                "mc_idx": 58,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 25,
                "o_idx": 0
            }
        },
        {
            "source": "# 4.3. Utilizing Ensemble Learning to Enhance Predictive Accuracy\n\nThe provided code snippet is implementing a voting ensemble machine learning model that combines the predictions from three different classifiers: Decision Tree, Random Forest, and K Nearest Neighbors. Each classifier has been previously tuned to find its best hyperparameters. The ensemble model is trained on a dataset, then used to make predictions on a test set. The accuracy of the model on the test set is calculated and printed, resulting in an accuracy of about 87.77%. This high accuracy indicates that the ensemble method is effective for the given prediction task.",
            "mc_idx": 59,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "from sklearn.ensemble import VotingClassifier\nvoting = VotingClassifier(estimators=[\n                                      ('Decision Tree Classifier', best_estimators[0]), \n                                      ('Random Forest Classifier', best_estimators[2]),\n                                      ('K Nearest Neighbors Classifier', best_estimators[3])])\nvoting.fit(X_train,y_train)\nvoting_pred = voting.predict(X_test)\n\nprint('Accuracy: ', accuracy_score(y_test, voting_pred))",
            "mc_idx": 60,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.3,
                "Model_Evaluation": 0.3,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 10
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "votingclassifier": 2
                },
                "Model_Evaluation": {
                    "accuracy_score": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    26,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Accuracy:  0.8777777777777778\n"
                    ]
                },
                "mc_idx": 60,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 26,
                "o_idx": 0
            }
        },
        {
            "source": "# 5. Making Predictions on the Original Test Set for the Leaderboard Submission",
            "mc_idx": 61,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "submission= pd.read_csv(\"/kaggle/input/titanic/gender_submission.csv\")\ntest =  test_df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']].values\nsubmission[\"Survived\"]=voting.predict(test)\nsubmission.to_csv('submission.csv',index=False)\nsubmission",
            "mc_idx": 62,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.25,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.5,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 2,
                    "pd.read_": 2
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    27,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "     PassengerId  Survived\n0            892         0\n1            893         0\n2            894         0\n3            895         0\n4            896         1\n..           ...       ...\n413         1305         0\n414         1306         1\n415         1307         0\n416         1308         0\n417         1309         0\n\n[418 rows x 2 columns]"
                    ]
                },
                "mc_idx": 62,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 27,
                "o_idx": 0
            }
        }
    ],
    "code_cells": [
        {
            "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n",
            "mc_idx": 0,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.1,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.05,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 4
                },
                "Data_Extraction": {
                    "read_csv": 2,
                    "pd.read_": 2
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".join(": 1,
                    ".join": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    0,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n"
                    ]
                },
                "mc_idx": 0,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 0,
                "o_idx": 0
            }
        },
        {
            "source": "# temel k\u00fct\u00fcphaneler\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns",
            "mc_idx": 3,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.025,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.05,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 4
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "matplotlib": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "matplotlib": 1,
                    "pyplot": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    1,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 3,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 1,
                "o_idx": 0
            }
        },
        {
            "source": "test_df = pd.read_csv('/kaggle/input/titanic/test.csv')\ndf = pd.read_csv('/kaggle/input/titanic/train.csv')\ndf",
            "mc_idx": 4,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 4,
                    "pd.read_": 4
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    2,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "     PassengerId  Survived  Pclass  \\\n0              1         0       3   \n1              2         1       1   \n2              3         1       3   \n3              4         1       1   \n4              5         0       3   \n..           ...       ...     ...   \n886          887         0       2   \n887          888         1       1   \n888          889         0       3   \n889          890         1       1   \n890          891         0       3   \n\n                                                  Name     Sex   Age  SibSp  \\\n0                              Braund, Mr. Owen Harris    male  22.0      1   \n1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                               Heikkinen, Miss. Laina  female  26.0      0   \n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                             Allen, Mr. William Henry    male  35.0      0   \n..                                                 ...     ...   ...    ...   \n886                              Montvila, Rev. Juozas    male  27.0      0   \n887                       Graham, Miss. Margaret Edith  female  19.0      0   \n888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n889                              Behr, Mr. Karl Howell    male  26.0      0   \n890                                Dooley, Mr. Patrick    male  32.0      0   \n\n     Parch            Ticket     Fare Cabin Embarked  \n0        0         A/5 21171   7.2500   NaN        S  \n1        0          PC 17599  71.2833   C85        C  \n2        0  STON/O2. 3101282   7.9250   NaN        S  \n3        0            113803  53.1000  C123        S  \n4        0            373450   8.0500   NaN        S  \n..     ...               ...      ...   ...      ...  \n886      0            211536  13.0000   NaN        S  \n887      0            112053  30.0000   B42        S  \n888      2        W./C. 6607  23.4500   NaN        S  \n889      0            111369  30.0000  C148        C  \n890      0            370376   7.7500   NaN        Q  \n\n[891 rows x 12 columns]"
                    ]
                },
                "mc_idx": 4,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 2,
                "o_idx": 0
            }
        },
        {
            "source": "plt.figure(figsize=(8, 6))\nax = sns.countplot(data=df, x='Pclass')\n\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.0f'), \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha = 'center', va = 'center', \n                xytext = (0, 10), \n                textcoords = 'offset points')\n\nplt.title('Distribution of Passenger Classes')\nplt.xlabel('Passenger Class')\nplt.ylabel('Count')\nplt.show()",
            "mc_idx": 8,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.5,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0028_c003_o000_image_0.png",
                    3,
                    0,
                    0
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 800x600 with 1 Axes>"
                    ]
                },
                "mc_idx": 8,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 3,
                "o_idx": 0
            }
        },
        {
            "source": "plt.figure(figsize=(8, 6))\nax = sns.countplot(data=df, x='Sex')\n\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.0f'), \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha = 'center', va = 'center', \n                xytext = (0, 10), \n                textcoords = 'offset points')\n\nplt.title('Distribution of Sex')\nplt.xlabel('Sex of Passengers')\nplt.ylabel('Count')\nplt.show()",
            "mc_idx": 11,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.5,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0028_c004_o000_image_1.png",
                    4,
                    0,
                    1
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 800x600 with 1 Axes>"
                    ]
                },
                "mc_idx": 11,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 4,
                "o_idx": 0
            }
        },
        {
            "source": "# Calculate the mean survival rates by sex\nsurvival_rates = df.groupby('Sex')['Survived'].mean().reset_index()\n\n# Create the bar plot\nsns.barplot(x='Sex', y='Survived', data=survival_rates)\n\n# Adding the actual survival rates on top of the bars\nfor index, value in enumerate(survival_rates['Survived']):\n    plt.text(index, value, f'{value:.4f}', ha='center', va='bottom')\n\n# Set the title and labels for the plot\nplt.title('Survival Rates by Sex')\nplt.ylabel('Average Survival Rate')\nplt.xlabel('Sex')\n\n# Display the plot\nplt.show()",
            "mc_idx": 13,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.25,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.5,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.25,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    "sns.": 1,
                    ".mean": 1,
                    ".groupby": 1
                },
                "Data_Transform": {
                    ".groupby(": 1,
                    ".reset_index": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0028_c005_o000_image_2.png",
                    5,
                    0,
                    2
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 13,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 5,
                "o_idx": 0
            }
        },
        {
            "source": "sns.histplot(x=\"Age\", hue=\"Survived\", palette=\"mako\", data=df[[\"Age\",\"Survived\"]])\nplt.title(\"Age Distribution\", color='black', fontsize=14) \nplt.yticks([])\nplt.box(False)\nplt.show()",
            "mc_idx": 16,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.5,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0028_c006_o000_image_3.png",
                    6,
                    0,
                    3
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 16,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 6,
                "o_idx": 0
            }
        },
        {
            "source": "plt.figure(figsize=(10, 6))\nax = sns.countplot(data=df, x='SibSp')\n\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.0f'), \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha = 'center', va = 'center', \n                xytext = (0, 10), \n                textcoords = 'offset points')\n\nplt.title('Distribution of Siblings Amount')\nplt.xlabel('Title of Passengers')\nplt.ylabel('Count')\nplt.show()",
            "mc_idx": 19,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.5,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0028_c007_o000_image_4.png",
                    7,
                    0,
                    4
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1000x600 with 1 Axes>"
                    ]
                },
                "mc_idx": 19,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 7,
                "o_idx": 0
            }
        },
        {
            "source": "survival_by_sibsp = df.groupby('SibSp')['Survived'].mean()\n\nplt.figure(figsize=(8, 6))\nax = sns.barplot(x=survival_by_sibsp.index, y=survival_by_sibsp.values)\nplt.title('Survival Rate by SibSp')\nplt.xlabel('Number of Siblings/Spouses')\nplt.ylabel('Survival Rate')\n\ntotal = float(len(df))\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x() + p.get_width() / 2., height + 0.02, '{:.1%}'.format(height), ha=\"center\")\n\nplt.show()",
            "mc_idx": 22,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.2,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    "sns.": 1,
                    "size": 1,
                    ".mean": 1,
                    ".groupby": 1
                },
                "Data_Transform": {
                    ".groupby(": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0028_c008_o000_image_5.png",
                    8,
                    0,
                    5
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 800x600 with 1 Axes>"
                    ]
                },
                "mc_idx": 22,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 8,
                "o_idx": 0
            }
        },
        {
            "source": "df[\"Ticket\"].value_counts()",
            "mc_idx": 26,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    9,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Ticket\n347082      7\nCA. 2343    7\n1601        7\n3101295     6\nCA 2144     6\n           ..\n9234        1\n19988       1\n2693        1\nPC 17612    1\n370376      1\nName: count, Length: 681, dtype: int64"
                    ]
                },
                "mc_idx": 26,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 9,
                "o_idx": 0
            }
        },
        {
            "source": "newdf = df.copy()\n\nnewdf[\"Group_Size\"] = newdf.groupby(\"Ticket\")[\"PassengerId\"].transform(\"count\")\nnewdf[\"Group_Size\"] ",
            "mc_idx": 27,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.6666666666666666,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 2,
                    ".groupby": 1
                },
                "Data_Transform": {
                    ".groupby(": 1,
                    "transform": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    10,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0      1\n1      1\n2      1\n3      2\n4      1\n      ..\n886    1\n887    1\n888    2\n889    1\n890    1\nName: Group_Size, Length: 891, dtype: int64"
                    ]
                },
                "mc_idx": 27,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 10,
                "o_idx": 0
            }
        },
        {
            "source": "plt.figure(figsize=(10, 6))\nax = sns.countplot(data=newdf, x='Group_Size')\n\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.0f'), \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha = 'center', va = 'center', \n                xytext = (0, 10), \n                textcoords = 'offset points')\n\nplt.title('Distribution of Group Size')\nplt.xlabel('Group Size of Passengers')\nplt.ylabel('Count')\nplt.show()",
            "mc_idx": 28,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 4
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0028_c011_o000_image_6.png",
                    11,
                    0,
                    6
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1000x600 with 1 Axes>"
                    ]
                },
                "mc_idx": 28,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 11,
                "o_idx": 0
            }
        },
        {
            "source": "newdf = df.copy()\nnewdf[\"Cabin\"].fillna(\"Unknown\",inplace=True)\nnewdf[\"Cabin\"] = newdf[\"Cabin\"].str[0]\nsns.set(style=\"darkgrid\")\nsns.countplot( x='Survived', data=newdf, hue=\"Cabin\", palette=\"Set1\");",
            "mc_idx": 32,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 2
                },
                "Data_Transform": {
                    ".fillna(": 1,
                    ".fillna": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0028_c012_o000_image_7.png",
                    12,
                    0,
                    7
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 32,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 12,
                "o_idx": 0
            }
        },
        {
            "source": "sns.set(style=\"darkgrid\")\nsns.countplot( x='Survived', data=df, hue=\"Embarked\", palette=\"Set1\");",
            "mc_idx": 35,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0028_c013_o000_image_8.png",
                    13,
                    0,
                    8
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 35,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 13,
                "o_idx": 0
            }
        },
        {
            "source": "sns.set(style=\"darkgrid\")\nsns.countplot( x='Survived', data=df, hue=\"Survived\", palette=\"Set1\");",
            "mc_idx": 38,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0028_c014_o000_image_9.png",
                    14,
                    0,
                    9
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 38,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 14,
                "o_idx": 0
            }
        },
        {
            "source": "def missing_zero_values_table(df):\n    zero_val = (df == 0.00).astype(int).sum(axis=0)\n    mis_val = df.isnull().sum()\n    mis_val_percent = 100 * df.isnull().sum() / len(df)\n    mz_table = pd.concat([zero_val, mis_val, mis_val_percent], axis=1)\n    mz_table = mz_table.rename(\n    columns = {0 : 'Zero Values', 1 : 'Missing Values', 2 : '% of Total Values'})\n    mz_table['Total Zero Missing Values'] = mz_table['Zero Values'] + mz_table['Missing Values']\n    mz_table['% Total Zero Missing Values'] = 100 * mz_table['Total Zero Missing Values'] / len(df)\n    mz_table['Data Type'] = df.dtypes\n    mz_table = mz_table[ mz_table.iloc[:,1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns and \" + str(df.shape[0]) + \" Rows.\\n\"\n           \"There are \" + str(mz_table.shape[0]) +\n            \"columns that have missing values.\")\n    return mz_table\n\n\nmissing_zero_values_table(df)",
            "mc_idx": 41,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.3,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.15,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "df.isnull().sum": 2,
                    "missing values": 6,
                    "dtypes": 1,
                    "columns": 3,
                    "shape": 3,
                    ".isnull": 2,
                    ".sum": 3
                },
                "Data_Transform": {
                    ".concat(": 1,
                    ".astype(": 1,
                    ".sort_values": 1,
                    ".rename": 1,
                    ".concat": 1,
                    ".round": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    15,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Your selected dataframe has 12 columns and 891 Rows.\nThere are 3columns that have missing values.\n",
                        "          Zero Values  Missing Values  % of Total Values  \\\nCabin               0             687               77.1   \nAge                 0             177               19.9   \nEmbarked            0               2                0.2   \n\n          Total Zero Missing Values  % Total Zero Missing Values Data Type  \nCabin                           687                         77.1    object  \nAge                             177                         19.9   float64  \nEmbarked                          2                          0.2    object  "
                    ]
                },
                "mc_idx": 41,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 15,
                "o_idx": 1
            }
        },
        {
            "source": "missing_zero_values_table(test_df)",
            "mc_idx": 42,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    16,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Your selected dataframe has 11 columns and 418 Rows.\nThere are 3columns that have missing values.\n",
                        "       Zero Values  Missing Values  % of Total Values  \\\nCabin            0             327               78.2   \nAge              0              86               20.6   \nFare             2               1                0.2   \n\n       Total Zero Missing Values  % Total Zero Missing Values Data Type  \nCabin                        327                         78.2    object  \nAge                           86                         20.6   float64  \nFare                           3                          0.7   float64  "
                    ]
                },
                "mc_idx": 42,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 16,
                "o_idx": 1
            }
        },
        {
            "source": "def clean_data(data):\n    data['Fare'] = data['Fare'].fillna(data['Fare'].dropna().median())\n    data['Age'] =  data['Age'].fillna(data['Age'].dropna().median())\n    \n    data.loc[data['Sex'] == 'male', 'Sex'] = 0\n    data.loc[data['Sex'] =='female',  'Sex'] = 1\n    \n    data['Embarked'] = data['Embarked'].fillna('S')\n    data.loc[data[\"Embarked\"] == 'S', 'Embarked'] = 0\n    data.loc[data['Embarked'] == 'C', 'Embarked'] = 1\n    data.loc[data['Embarked'] == 'Q', 'Embarked'] =2\n    \n    data.drop([\"Cabin\"],axis=1,inplace=True)",
            "mc_idx": 44,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3076923076923077,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".median": 4
                },
                "Data_Transform": {
                    ".fillna(": 3,
                    ".dropna(": 2,
                    ".drop": 3,
                    ".dropna": 2,
                    ".fillna": 3
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    17,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 44,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 17,
                "o_idx": 0
            }
        },
        {
            "source": "clean_data(df)\nclean_data(test_df)",
            "mc_idx": 45,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    18,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 45,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 18,
                "o_idx": 0
            }
        },
        {
            "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\ndf[\"Survived\"] = df[\"Survived\"].astype(int)\nX = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']].values\ny = df[\"Survived\"].values\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1,stratify=y, random_state = 105)",
            "mc_idx": 49,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.1,
                "Data_Transform": 0.1,
                "Model_Train": 0.2,
                "Model_Evaluation": 0.15,
                "Model_Interpretation": 0.05,
                "Hyperparameter_Tuning": 0.1,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 20
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1,
                    ".mode": 1
                },
                "Data_Transform": {
                    ".astype(": 1,
                    ".mod": 1
                },
                "Model_Train": {
                    "train_test_split": 2,
                    "model": 1,
                    "model_selection": 1
                },
                "Model_Evaluation": {
                    "accuracy_score": 2,
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {
                    "train_test_split": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    19,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 49,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 19,
                "o_idx": 0
            }
        },
        {
            "source": "X_train",
            "mc_idx": 50,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    20,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([[2, 1, 17.0, ..., 0, 10.5, 0],\n       [3, 1, 14.0, ..., 0, 11.2417, 1],\n       [1, 0, 51.0, ..., 0, 26.55, 0],\n       ...,\n       [1, 0, 45.0, ..., 0, 26.55, 0],\n       [3, 0, 27.0, ..., 0, 6.975, 0],\n       [3, 0, 21.0, ..., 0, 8.4333, 0]], dtype=object)"
                    ]
                },
                "mc_idx": 50,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 20,
                "o_idx": 0
            }
        },
        {
            "source": "y_train",
            "mc_idx": 51,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    21,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n       0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n       1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n       0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n       0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n       1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n       1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n       0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n       0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n       0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n       1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n       0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n       1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n       1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n       0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n       0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n       0, 0, 1, 0, 1, 0, 1, 1, 0])"
                    ]
                },
                "mc_idx": 51,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 21,
                "o_idx": 0
            }
        },
        {
            "source": "dt_hyperparameters= {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_hyperparameters= {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1],\n                 \"C\": [1,10,50,100,250,500]}\n\n\nrf_hyperparameters= {\"max_depth\":[1,3,5,7],\n                \"min_samples_leaf\":[1,3,5],\n                \"n_estimators\":[50,100,150]}\n\nknn_hyperparameters= {\"n_neighbors\": [1,3,5,7],\n                 \"metric\":[\"manhattan\"]} \n             \nclassifier_param = [\n                    dt_hyperparameters,\n                   svc_hyperparameters,\n                   rf_hyperparameters,\n                   knn_hyperparameters]",
            "mc_idx": 53,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.08,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "svc": 2
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 9,
                    "hyperparameter": 8,
                    "hyperparameters": 8
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    22,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 53,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 22,
                "o_idx": 0
            }
        },
        {
            "source": "# e\u011fitim i\u00e7in\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.exceptions import ConvergenceWarning\n# Suppress ConvergenceWarning\nwarnings.simplefilter('ignore', ConvergenceWarning)\n\nrandom_state=45\nclassifier = [\n             DecisionTreeClassifier(random_state = random_state),\n             SVC(),\n             RandomForestClassifier(random_state = random_state),\n             KNeighborsClassifier()]\n\n\ncv_result = []\nreal_test_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    real_test_result.append(clf.score(X_test, y_test)) ",
            "mc_idx": 54,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.03614457831325301,
                "Data_Transform": 0.03614457831325301,
                "Model_Train": 0.21686746987951808,
                "Model_Evaluation": 0.04819277108433735,
                "Model_Interpretation": 0.03614457831325301,
                "Hyperparameter_Tuning": 0.1686746987951807,
                "Visualization": 0.0,
                "Debug": 0.012048192771084338,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 8
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mode": 3
                },
                "Data_Transform": {
                    ".mod": 3
                },
                "Model_Train": {
                    "train_test_split": 1,
                    ".fit(": 1,
                    "model": 3,
                    "randomforestclassifier": 4,
                    "model_selection": 3,
                    "decisiontreeclassifier": 2,
                    "kneighborsclassifier": 2,
                    "svc": 2
                },
                "Model_Evaluation": {
                    "model": 3,
                    ".score(": 1
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 6,
                    "param_grid": 1,
                    "param": 2,
                    "kfold": 2,
                    "stratifiedkfold": 2,
                    "train_test_split": 1
                },
                "Visualization": {},
                "Debug": {
                    "exception": 1
                },
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    23,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Fitting 10 folds for each of 250 candidates, totalling 2500 fits\nFitting 10 folds for each of 18 candidates, totalling 180 fits\nFitting 10 folds for each of 36 candidates, totalling 360 fits\nFitting 10 folds for each of 4 candidates, totalling 40 fits\n"
                    ]
                },
                "mc_idx": 54,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 23,
                "o_idx": 0
            }
        },
        {
            "source": "best_estimators",
            "mc_idx": 55,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    24,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "[DecisionTreeClassifier(max_depth=7, min_samples_split=10, random_state=45),\n SVC(C=500, gamma=0.001),\n RandomForestClassifier(max_depth=3, min_samples_leaf=3, n_estimators=50,\n                        random_state=45),\n KNeighborsClassifier(metric='manhattan', n_neighbors=7)]"
                    ]
                },
                "mc_idx": 55,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 24,
                "o_idx": 0
            }
        },
        {
            "source": "cv_results = pd.DataFrame({ \"Machine Learning Models\":\n                                               [\"Decision Tree Classifier\", \n                                                \"Support Vector Machines\",\n                                                \"Random Forest Classifier\",\n                                                 \"K Nearest Neighbors Classifier\"],\n                           \"Cross Validation Mean\": cv_result, \n                           \"Test Result\": real_test_result})\ncv_results\n",
            "mc_idx": 58,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1,
                    "learning models": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    25,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "          Machine Learning Models  Cross Validation Mean  Test Result\n0        Decision Tree Classifier               0.820293     0.866667\n1         Support Vector Machines               0.806512     0.833333\n2        Random Forest Classifier               0.824012     0.844444\n3  K Nearest Neighbors Classifier               0.744136     0.744444"
                    ]
                },
                "mc_idx": 58,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 25,
                "o_idx": 0
            }
        },
        {
            "source": "from sklearn.ensemble import VotingClassifier\nvoting = VotingClassifier(estimators=[\n                                      ('Decision Tree Classifier', best_estimators[0]), \n                                      ('Random Forest Classifier', best_estimators[2]),\n                                      ('K Nearest Neighbors Classifier', best_estimators[3])])\nvoting.fit(X_train,y_train)\nvoting_pred = voting.predict(X_test)\n\nprint('Accuracy: ', accuracy_score(y_test, voting_pred))",
            "mc_idx": 60,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.3,
                "Model_Evaluation": 0.3,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 10
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "votingclassifier": 2
                },
                "Model_Evaluation": {
                    "accuracy_score": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    26,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Accuracy:  0.8777777777777778\n"
                    ]
                },
                "mc_idx": 60,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 26,
                "o_idx": 0
            }
        },
        {
            "source": "submission= pd.read_csv(\"/kaggle/input/titanic/gender_submission.csv\")\ntest =  test_df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']].values\nsubmission[\"Survived\"]=voting.predict(test)\nsubmission.to_csv('submission.csv',index=False)\nsubmission",
            "mc_idx": 62,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.25,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.5,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 2,
                    "pd.read_": 2
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    27,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "     PassengerId  Survived\n0            892         0\n1            893         0\n2            894         0\n3            895         0\n4            896         1\n..           ...       ...\n413         1305         0\n414         1306         1\n415         1307         0\n416         1308         0\n417         1309         0\n\n[418 rows x 2 columns]"
                    ]
                },
                "mc_idx": 62,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 27,
                "o_idx": 0
            }
        }
    ],
    "markdown_cells": [
        {
            "source": "# 0. Background\n\n\n## Introduction\nThe Titanic: Machine Learning from Disaster competition represents an engaging challenge that merges historical significance with predictive analytics. It provides an opportunity for data science enthusiasts and experts to apply machine learning techniques to a dataset that is both rich in history and complexity.\n\n## Problem Definition\nThe competition's objective is to predict survival on the Titanic, the passenger liner that sank in 1912 after colliding with an iceberg. The event holds substantial historical significance due to the loss of life, particularly because it reflected the societal norms of the era, such as class distinctions. The task of predicting survival is not merely an academic exercise but also a reflection on the human aspects behind data, underscoring the potential of machine learning in understanding human factors in historical events.\n\n## Expected Outputs\nThe expected output is a predictive model capable of determining the survival outcome for each passenger in the test set. Participants must submit a CSV file with two columns: `PassengerId` and `Survived`. The `Survived` column should contain the binary predictions: 1 for survived and 0 for did not survive. The model's performance is measured based on the accuracy of these predictions.\n\n## Dataset\nThe provided dataset consists of several attributes for each passenger aboard the Titanic:\n\n  - `PassengerId`: Unique identifier for each passenger.\n  - `Survived`: Survival status (0 = No, 1 = Yes).\n  - `Pclass`: Passenger class (1 = 1st, 2 = 2nd, 3 = 3rd).\n  - `Name`: Name of the passenger.\n  - `Sex`: Gender of the passenger (male or female).\n  - `Age`: Age of the passenger. Some entries are NaN, indicating missing values.\n  - `SibSp`: Number of siblings or spouses aboard.\n  - `Parch`: Number of parents or children aboard.\n  - `Ticket`: Ticket number.\n  - `Fare`: Passenger fare.\n  - `Cabin`: Cabin number. Contains NaN values, which represent missing data.\n  - `Embarked`: Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton).\n\nThe dataset will be used to train machine learning models that can discern patterns and associations between the features and the likelihood of survival.\n\n## Problem Type\nThe challenge is a binary classification problem, a type of supervised learning where the aim is to categorize the passengers into two groups: those who survived and those who did not. The nature of the `Survived` variable as a binary indicator makes it a clear case of classification rather than regression, which would predict continuous outcomes.\n\n## Conclusion\nThe Titanic Kaggle competition is a testbed for machine learning methodologies, offering insights into the social fabric of the early 20th century while advancing the field of data science. It presents a problem that is both historically enriching and technically stimulating, with the potential to develop predictive models that are not only accurate but also interpretative of the human stories behind the data.\nI will use a dataset containing information about those on board to develop a machine learning model that attempts to predict who survived.",
            "mc_idx": 1,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 1. Reading the data",
            "mc_idx": 2,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Here's a description of the data as displayed in the DataFrame:\n\n- **Columns in the DataFrame:**\n  - `PassengerId`: Unique identifier for each passenger.\n  - `Survived`: Survival status (0 = No, 1 = Yes).\n  - `Pclass`: Passenger class (1 = 1st, 2 = 2nd, 3 = 3rd).\n  - `Name`: Name of the passenger.\n  - `Sex`: Gender of the passenger (male or female).\n  - `Age`: Age of the passenger. Some entries are NaN, indicating missing values.\n  - `SibSp`: Number of siblings or spouses aboard.\n  - `Parch`: Number of parents or children aboard.\n  - `Ticket`: Ticket number.\n  - `Fare`: Passenger fare.\n  - `Cabin`: Cabin number. Contains NaN values, which represent missing data.\n  - `Embarked`: Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton).\n\n- **Sample Data:**\n  - The first row corresponds to a male passenger with a `PassengerId` of 1, who did not survive, was in 3rd class, and embarked from Southampton (`Embarked` = S).\n  - The third row shows a female passenger, `PassengerId` 3, who survived, was in 3rd class, and also embarked from Southampton.\n  - There are some missing data points, indicated by `NaN` (not a number), especially in the `Age` and `Cabin` columns, which will require careful handling during data preprocessing for any machine learning tasks.\n\n- **Data Use:**\n  - `Survived` is the target variable for the prediction model.\n  - Other columns serve as features to train machine learning models to predict the target variable. Features like `Name` and `Ticket` might be used for feature engineering, while `Cabin` and `Age` would need to deal with missing values.\n\nThis data is  used to train classification models to predict the `Survived` column, which is a binary outcome indicating whether a passenger survived the Titanic disaster.",
            "mc_idx": 5,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.Exploratory Data Analysis (EDA) ",
            "mc_idx": 6,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.1 Pclass\n\n\"Pclass\" signifies the accommodation category for travelers on the Titanic, reflective of their socio-economic stature. \n\n- 1st Class: This tier was the domain of the affluent and illustrious\u2014magnates, celebrities, or distinguished personas. It offered spacious quarters and superior dining and amenities.\n\n- 2nd Class: Serving as a mid-level option, it was less opulent than 1st Class but provided a comfortable journey for middle-class travelers. The cabins were more compact, and there were fewer luxuries.\n\n- 3rd Class: This was the most basic level of travel, primarily for individuals of modest means, often immigrants or those with lesser financial resources. Accommodations were more confined, with basic amenities.\n\nThe Pclass is indicative of the passengers' financial and social ranking. It is a critical factor in survival analysis due to the potential influence of class on emergency response and evacuation procedures during the disaster.",
            "mc_idx": 7,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Here are some observations and comments based on the chart:\n\n1. **Third Class is the Most Populous:** With 491 passengers, the Third Class had the highest number of passengers compared to the other classes. This reflects the economic demographics of the time, where a larger portion of the population were of lower socio-economic status, which also correlates with the common practice of ships carrying more third-class passengers to maximize ticket sales.\n\n2. **First Class has More Passengers than Second:** There were 216 passengers in First Class and slightly fewer, 184, in Second Class. This could indicate that the Titanic was quite luxurious and attracted a significant number of affluent passengers who could afford the higher fare for better accommodations and services.\n\n3. **Economic Implications:** The distribution shows the economic stratification of society at the time. A substantial number of people were traveling in Third Class, possibly in hope of starting a new life in America, which was a common reason for travel among immigrants during that period.\n\n4. **Implications for Survival Analysis:** Given the larger number of Third Class passengers, if resources and lifeboats were limited and preferentially allocated to higher classes, this could have significantly influenced survival rates. Historical accounts suggest that First Class passengers had better access to lifeboats, which is an important aspect to consider in survival analysis.\n\n5. **Data Visualization Insights:** The bar chart effectively communicates the difference in class sizes, which is crucial for data exploration in predictive modeling. It's a good practice to visualize data this way to understand the underlying distributions before applying machine learning algorithms.\n\n6. **Potential Bias in Model Training:** When training machine learning models on this data, the imbalance in class distribution may introduce bias. Models might perform better at predicting survival for Third Class passengers simply because there are more data points for that class.\n\nOverall, the visualization underscores the importance of considering passenger class as a feature in predictive models and as a factor in historical analyses of the Titanic disaster.",
            "mc_idx": 9,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.2 Sex",
            "mc_idx": 10,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": " Here are some insights and comments regarding the chart:\n\n1. **Gender Disparity:** The chart illustrates that there were considerably more male passengers (577) than female passengers (314) on the Titanic. This reflects the gender demographics of passengers who were traveling at that time.\n\n2. **Implications for Survival Predictions:** Historical records indicate that the protocol of \"women and children first\" was often followed during maritime disasters. Therefore, despite being outnumbered, female passengers might have had a higher survival rate compared to males, which is a critical consideration for predictive modeling.\n\n3. **Visualization Effectiveness:** The bar chart clearly demonstrates the disparity in numbers between male and female passengers. Such visualizations are important in exploratory data analysis as they provide immediate insights into the dataset's structure before any statistical modeling.\n\n4. **Influence on Model Training:** The imbalance shown here may influence the performance of machine learning models. If the model is not adjusted to account for this imbalance, it may become biased towards predicting the survival of males, simply because there are more male passengers in the dataset.\n\n5. **Historical Context:** The higher number of males might be reflective of the societal norms of the time, where men were more likely to travel alone for business or emigration purposes, while women often traveled with families.\n\n6. **Data Preparation Considerations:** When preparing the dataset for machine learning, it might be beneficial to consider techniques like stratification to ensure that both genders are adequately represented in the training and validation sets.\n\n",
            "mc_idx": 12,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Here are some comments and interpretations based on the chart:\n\n1. **Significant Gender-Based Survival Disparity:** The bar chart highlights a stark difference in survival rates between females and males. Female passengers had a much higher survival rate of approximately 74.2%, while the survival rate for male passengers was markedly lower at about 18.9%.\n\n",
            "mc_idx": 14,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.3. Age",
            "mc_idx": 15,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Here are some comments and insights based on the chart:\n\n1. **Bimodal Distribution:** The age distribution appears to be bimodal, with two peaks suggesting that younger adults and children were the most common age groups among the passengers.\n\n2. **Higher Survival Rate Among Younger Passengers:** The lighter-colored bars, which represent the passengers who survived, seem more prominent in the lower age groups, suggesting that younger passengers had a higher survival rate.\n\n3. **Declining Survival with Age:** There is a noticeable decline in survival rate as age increases, particularly noticeable in passengers older than 30 years old.\n\n4. **Children's Survival:** The survival rate for very young passengers (children) seems to be high, which could be attributed to the \"women and children first\" policy during lifeboat loading.\n\n5. **Effective Visualization:** This stacked histogram effectively conveys the relationship between age and survival. It allows for easy comparison between the number of survivors and non-survivors within each age group.\n\n6. **Insights for Model Training:** For predictive modeling, this visualization suggests that age could be an important feature, potentially requiring more nuanced treatment such as binning into categorical age groups or creating age-related interaction features.\n\n",
            "mc_idx": 17,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.4. SibSp",
            "mc_idx": 18,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Here are some observations and insights from the chart:\n\n1. **Most Passengers Traveled Alone:** A significant majority of passengers, indicated by the tallest bar with a count of 608, did not have siblings or spouses on board. This suggests that solo travel was common.\n\n2. **Smaller Family Units:** The second bar, with a count of 209, shows that a substantial number of passengers traveled with one sibling or spouse, indicating smaller family units or couples without children.\n\n3. **Rarity of Large Families:** Very few passengers traveled with more than two siblings or spouses. The counts for passengers with three or more siblings/spouses are markedly lower, which highlights the rarity of large families or sibling groups traveling together.\n\n4. **Exceptional Cases:** There are a few exceptional cases of passengers with large numbers of siblings/spouses on board, such as 5 or 8, which are very uncommon. These could potentially represent larger family groups or possibly group tickets.\n\n5. **Potential Impact on Survival:** The number of siblings/spouses could have implications for survival rates, as those with family aboard might have sought one another out during the disaster, potentially affecting their likelihood of reaching the lifeboats.\n\n\nThis chart provides a clear visual representation of the distribution of family sizes aboard the Titanic, with the majority being individuals or couples.",
            "mc_idx": 20,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Let's examine the survival rate according to the number of siblings or spouses.**\n",
            "mc_idx": 21,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Here are some key takeaways from the chart:\n\n1. **Varied Survival Rates:** The survival rates differ across the number of siblings/spouses. Passengers without any siblings or spouses on board had a survival rate of 34.5%, while those with one sibling/spouse had a higher survival rate of 53.6%.\n\n2. **Decreasing Trend with More Siblings/Spouses:** As the number of siblings/spouses increases, there's a general trend of decreasing survival rates. This is evident from the drop to 46.4% for passengers with two siblings/spouses, 25% for those with three, and even lower for four.\n\n3. **Zero Survival for Larger Families:** There are no survivors among the passengers who had five or eight siblings/spouses on board, as indicated by the 0.0% survival rate for these groups.\n\n4. **Highest Survival for Smaller Families:** The highest survival rate is observed among passengers with one sibling/spouse, which could suggest that those with a single family member to look out for could more easily maneuver and access life-saving resources.\n\n5. **Potential Outliers:** The passengers with a very high number of siblings/spouses (such as 5 and 8) are outliers with a survival rate of 0%. This might reflect the difficulty of larger groups to secure a place on lifeboats or could also indicate data entry errors or exceptional cases that warrant further investigation.\n\n\nThis chart provides insight into the dynamics of survival aboard the Titanic and indicates that the presence of family members could have both aided and hindered survival chances, depending on the size of the family.",
            "mc_idx": 23,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.5. Ticket",
            "mc_idx": 24,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Let's examine the tickets. Individuals who bought identical tickets are regarded as a collective unit and are attributed to a newly created attribute named 'Group_Size'.",
            "mc_idx": 25,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": " Here are some observations from the chart:\n\n1. **Solo Travelers:** The largest bar represents individuals traveling alone (group size of 1), with a count of 547. This indicates that the majority of passengers on the Titanic purchased tickets individually rather than as part of a group.\n\n2. **Small Groups:** The second-largest bar represents groups of two, with a count of 188, suggesting that traveling in pairs was also common. This could include couples or two friends/family members traveling together.\n\n3. **Declining Numbers with Larger Groups:** As the group size increases, the number of such groups decreases significantly. For example, there are only 63 groups of size 3, and even fewer as the size increases.\n\n4. **Larger Groups are Less Common:** Very large groups (such as those with sizes 5, 6, or 7) are much less common, as indicated by the relatively small bar heights for these group sizes.\n\n5. **Potential Family or Tour Groups:** Some of the larger group sizes, like 7, with a count of 21, could indicate families traveling together or organized tour groups.\n\n6. **Implications for Survival Analysis:** The group size may have had an impact on survival rates, as those in larger groups might have had different dynamics when it came to evacuation procedures compared to those traveling alone or in pairs.\n\nThis visualization provides a clear representation of how passengers were distributed by group size, which can be a useful feature for understanding social dynamics on the Titanic and for predictive modeling of survival.",
            "mc_idx": 29,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.6. Cabin",
            "mc_idx": 30,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "First, the following steps were performed:\n\n1. Missing values in the 'Cabin' column were filled with the string \"Unknown\".\n2. Only the first letter of each cabin entry was retained to categorize the cabins.\n3. A count plot was created to show the count of passengers who did and did not survive, separated by cabin category.\n",
            "mc_idx": 31,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\nHere are some observations based on the count plot in the image:\n\n- The majority of passengers have an unknown cabin designation, denoted as 'U', with a high non-survival rate.\n- Passengers from cabin categories 'C', 'E', 'G', 'D', 'A', 'B', 'F', and 'T' are also represented, with varying counts of survival and non-survival.\n- Cabin 'C' has the second-highest count among those who did not survive and a significant count of survivors.\n- Cabins 'E' and 'D' show a relatively higher survival rate compared to non-survival.\n- The 'T' cabin category has a very low count, which may indicate it's an outlier or a special case.\n\nThis visualization suggests that cabin location may have played a role in the passengers' likelihood of survival, which could be related to the proximity to lifeboats or other escape routes. It's worth noting that the high number of unknown cabins can affect the overall analysis and interpretations drawn from this data.",
            "mc_idx": 33,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.7. Embarked",
            "mc_idx": 34,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "It represents the survival of passengers based on the port where they embarked on the Titanic, with \"S\" for Southampton, \"C\" for Cherbourg, and \"Q\" for Queenstown.\n\nHere are some observations from the chart:\n\n- A larger number of passengers embarked from Southampton (S), with a higher count of those who did not survive (0) compared to those who did (1).\n- For passengers who embarked from Cherbourg (C), the survival count is relatively high compared to the non-survival count.\n- Queenstown (Q) had the fewest passengers, with a non-survival rate that appears to be slightly higher than the survival rate.\n- The survival rate of passengers from Cherbourg stands out as being higher than that of the other two ports.\n\nThis chart could suggest that passengers embarking from different ports had different survival rates, possibly due to various factors such as the socioeconomic status of passengers, which could correlate with their point of embarkation, or perhaps the location on the ship where passengers from different ports were accommodated.",
            "mc_idx": 36,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.8. And Target Distribution",
            "mc_idx": 37,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": " In this chart:\n\n- The red bar represents passengers who did not survive (0).\n- The blue bar represents passengers who did survive (1).\n\nObservations from the chart are:\n\n- There are more non-survivors than survivors, with the non-survivors' bar being significantly taller.\n- This imbalance in the target variable distribution may suggest a need for stratified sampling or other techniques to address class imbalance when training machine learning models.\n- The visualization gives a clear representation of the binary classification nature of the problem, where the goal is to predict one of these two possible outcomes.",
            "mc_idx": 39,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 3. Data Cleaning",
            "mc_idx": 40,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "`missing_zero_values_table` analyzes the dataframes for zero values and missing values.\n\nHere's a summary of the missing data information provided in the tables:\n\n**Training DataFrame:**\n- Contains 13 columns and 891 rows.\n- Three columns have missing values:\n  - `Cabin`: 687 missing values, which is 77.1% of the total number of rows.\n  - `Age`: 177 missing values, 19.9% of the rows.\n  - `Embarked`: 2 missing values, 0.2% of the rows.\n\n**Test DataFrame:**\n- Contains 11 columns and 418 rows.\n- Three columns have missing values:\n  - `Cabin`: 327 missing values, 78.2% of the rows.\n  - `Age`: 86 missing values, 20.6% of the rows.\n  - `Fare`: 1 missing value, 0.2% of the rows, and also 2 zero values.\n\nFrom this information, we can deduce that:\n\n- The `Cabin` column has a very high percentage of missing values in both datasets, suggesting that it may not be a reliable feature for machine learning models unless some form of imputation or feature engineering is done.\n- The `Age` column has a significant, but much smaller, percentage of missing values. Imputation strategies such as median age could be considered.\n- The `Embarked` column in the training set and the `Fare` column in the test set have a very small number of missing values and could be filled with the most common value or the median, respectively.\n- The presence of two zero values in the `Fare` column of the test set might indicate either free tickets or data entry errors and might require further investigation or a decision on a case-by-case basis.\n\nTo clean this data, you would typically fill in the missing values with appropriate statistics (like the median or mode), or possibly infer missing values based on other data. For categorical data like `Cabin` and `Embarked`, you might consider filling in missing values with the most common category, or creating a new category for missing data. For numerical data like `Age` and `Fare`, you might use a measure of central tendency (mean, median) or employ a model-based imputation method.",
            "mc_idx": 43,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "`clean_data`  is written to perform several data cleaning operations on a pandas DataFrame. Below is a description of what each line of code within the function does:\n\n1. `data['Fare'] = data['Fare'].fillna(data['Fare'].dropna().median())`: This line fills any missing (NaN) values in the 'Fare' column with the median fare calculated from the non-missing values.\n\n2. `data['Age'] = data['Age'].fillna(data['Age'].dropna().median())`: This line fills any missing (NaN) values in the 'Age' column with the median age calculated from the non-missing values.\n\n3. `data.loc[data['Sex'] == 'male', 'Sex'] = 0`: This line converts the categorical 'Sex' data into numerical form, replacing 'male' with 0.\n\n4. `data.loc[data['Sex'] == 'female', 'Sex'] = 1`: Similarly, this line replaces 'female' with 1 in the 'Sex' column.\n\n5. `data['Embarked'] = data['Embarked'].fillna('S')`: This line fills any missing values in the 'Embarked' column with 'S', which likely stands for Southampton, the most common port of embarkation.\n\n6. `data.loc[data['Embarked'] == 'S', 'Embarked'] = 0`: This line assigns a numeric value of 0 to all instances where the embarkation port is 'S'.\n\n7. `data.loc[data['Embarked'] == 'C', 'Embarked'] = 1`: This line assigns a numeric value of 1 to all instances where the embarkation port is 'C'.\n\n8. `data.loc[data['Embarked'] == 'Q', 'Embarked'] = 2`: This line assigns a numeric value of 2 to all instances where the embarkation port is 'Q'.\n\n9. `data.drop([\"Cabin\"], axis=1, inplace=True)`: This line removes the 'Cabin' column from the DataFrame entirely, which might be due to the high percentage of missing values as shown in the one, making it potentially less useful for predictive modeling.\n\nOverall, this function handles missing values, converts categorical variables to numerical, and drops a column with excessive missing data, which are common steps in preparing data for machine learning algorithms.",
            "mc_idx": 46,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 4. Creating a Model",
            "mc_idx": 47,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 4.1. Train-Test Split",
            "mc_idx": 48,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 4.2. Hyperparameter search\n\nEach dictionary is named after the classifier it is intended for and includes a set of parameters and the range of values to be tested for each. The classifiers and their respective hyperparameters are as follows:\n\n1. **Decision Tree Classifier (`dt_hyperparameters`)**:\n   - `min_samples_split`: A range of values from 10 to 500, with a step of 20.\n   - `max_depth`: A range of values from 1 to 20, with a step of 2.\n\n2. **Support Vector Machine (`svc_hyperparameters`)**:\n   - `kernel`: A fixed value of 'rbf' indicating the use of the radial basis function kernel.\n   - `gamma`: A list of potential values `[0.001, 0.01, 0.1]`.\n   - `C`: A list of potential regularization parameter values `[1, 10, 50, 100, 250, 500]`.\n\n3. **Random Forest Classifier (`rf_hyperparameters`)**:\n   - `max_depth`: A list of potential values `[1, 3, 5,7]`.\n   - `min_samples_leaf`: A list of potential values `[1, 3, 5]`.\n   - `n_estimators`: The number of trees in the forest with values `[50, 100, 150]`.\n\n4. **K Nearest Neighbors (`knn_hyperparameters`)**:\n   - `n_neighbors`: A list of potential values `[1, 3, 5, 7]`.\n   - `metric`: A single value 'manhattan', which is a type of distance measurement.\n\nFinally, a list called `classifier_param` is defined which aggregates the dictionaries of hyperparameters for each classifier.\n\nThis setup will be used in combination with a grid search cross-validation procedure, where each combination of parameters for each classifier will be tested to find the best performing model based on some evaluation metric. ",
            "mc_idx": 52,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "These appear to be the best-performing models as determined by a hyperparameter tuning process such as grid search or random search. Here's a summary of the models and their corresponding best hyperparameters:\n\n1. **DecisionTreeClassifier**: Found to perform best with a maximum depth of 7 (`max_depth=7`) and a minimum number of samples required to split an internal node (`min_samples_split=10`). A `random_state` has been set to 45, which is used for initializing the internal random number generator, ensuring reproducibility of the results.\n\n2. **SVC (Support Vector Classifier)**: The optimal hyperparameters for the support vector machine include a regularization parameter `C` set to 500 and a kernel coefficient `gamma` set to 0.001. The kernel is not explicitly mentioned, but since 'rbf' was part of the search space in the hyperparameter search snippet, it is likely that the radial basis function kernel is used.\n\n3. **RandomForestClassifier**: For the random forest, the best parameters include a maximum depth of 3 (`max_depth=3`), a minimum number of samples required to be at a leaf node (`min_samples_leaf=3`), and the number of trees in the forest (`n_estimators=50`). The `random_state` is again set to 45 for reproducibility.\n\n4. **KNeighborsClassifier**: This model is configured to use 7 neighbors (`n_neighbors=7`) and the Manhattan distance metric for its operation.\n\nThese models are typically stored in a list after the completion of hyperparameter tuning to easily access the best version of each classifier for further evaluation, ensemble methods, or deployment.",
            "mc_idx": 56,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "And, the resulting DataFrame cv_results is displayed below the code snippet, showing each classifier along with its corresponding cross-validation mean and test result. The scores are as follows:",
            "mc_idx": 57,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 4.3. Utilizing Ensemble Learning to Enhance Predictive Accuracy\n\nThe provided code snippet is implementing a voting ensemble machine learning model that combines the predictions from three different classifiers: Decision Tree, Random Forest, and K Nearest Neighbors. Each classifier has been previously tuned to find its best hyperparameters. The ensemble model is trained on a dataset, then used to make predictions on a test set. The accuracy of the model on the test set is calculated and printed, resulting in an accuracy of about 87.77%. This high accuracy indicates that the ensemble method is effective for the given prediction task.",
            "mc_idx": 59,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 5. Making Predictions on the Original Test Set for the Leaderboard Submission",
            "mc_idx": 61,
            "nb_idx": 28,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        }
    ],
    "sim_matrix": [],
    "cell_sim_matrix": [],
    "nb_order": [],
    "summary_data_VA": null
}