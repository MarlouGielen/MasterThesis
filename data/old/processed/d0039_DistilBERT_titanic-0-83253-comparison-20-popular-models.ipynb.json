{
    "nb_idx": 39,
    "nb_name": "d0039",
    "filename": "titanic-0-83253-comparison-20-popular-models.ipynb",
    "filepath": "data/data_Kaggle/raw/titanic-0-83253-comparison-20-popular-models.ipynb",
    "source": "<a class=\"anchor\" id=\"0\"></a>\n\n## FE, tuning and comparison of the 20 popular models with  predictions on the example of competition \"Titanic: Machine Learning from Disaster\" \n Features engineering (FE) from Titanic Top 3%\n\nBuild of the 20 most popular models, the most complex models from them are tuned (optimized)\n\nComparison of the optimal for each type models by CV and LB \n ## Acknowledgements \n Thanks for most popular models to:\n* https://www.kaggle.com/kabure/titanic-eda-model-pipeline-keras-nn\n* https://www.kaggle.com/startupsci/titanic-data-science-solutions \n* https://www.kaggle.com/nhlr21/complete-titanic-tutorial-with-ml-nn-ensembling\n\nThanks for FE:\n* https://www.kaggle.com/vbmokin/three-lines-of-code-for-titanic-top-15\n* https://www.kaggle.com/vbmokin/three-lines-of-code-for-titanic-top-20\n* https://www.kaggle.com/mauricef/titanic\n* https://www.kaggle.com/kpacocha/top-6-titanic-machine-learning-from-disaster\n* https://www.kaggle.com/erinsweet/simpledetect \n <a class=\"anchor\" id=\"0.1\"></a>\n\n## Table of Contents\n\n1. [Import libraries](#1)\n1. [Download datasets](#2)\n1. [Features engineering (FE)](#3)\n1. [Preparing to modeling](#4)\n    -  [Encoding categorical features](#4.1)\n    -  [Creation of training and validation sets](#4.2)\n1. [Tuning models and test for all 16 features](#5)\n    -  [Logistic Regression](#5.1)\n    -  [Support Vector Machines](#5.2)\n    -  [Linear SVC](#5.3)\n    -  [k-Nearest Neighbors algorithm with GridSearchCV](#5.4)\n    -  [Naive Bayes](#5.5)\n    -  [Perceptron](#5.6)\n    -  [Stochastic Gradient Descent](#5.7)\n    -  [Decision Tree Classifier](#5.8)\n    -  [Random Forests with GridSearchCV](#5.9)\n    -  [XGB Classifier with HyperOpt](#5.10)\n    -  [LGBM Classifier with HyperOpt](#5.11)\n    -  [GradientBoostingClassifier with HyperOpt](#5.12)\n    -  [RidgeClassifier](#5.13)\n    -  [BaggingClassifier](#5.14)\n    -  [ExtraTreesClassifier with HyperOpt](#5.15)\n    -  [Neural Network 1](#5.16)\n    -  [Neural Network 2](#5.17)\n    -  [VotingClassifier (hard voting)](#5.18)\n    -  [VotingClassifier (soft voting) with GridSearchCV](#5.19)\n    -  [The simple rule in one line](#5.20)\n1. [Tuning models and test for 3 features](#6)\n1. [Models evaluation](#7)\n1. [Conclusion](#8)\n \n ## 1. Import libraries <a class=\"anchor\" id=\"1\"></a>\n\n[Back to Table of Contents](#0.1) \n import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n\n# models\nfrom sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier \nfrom sklearn.ensemble import BaggingClassifier, VotingClassifier \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\n# NN models\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras import optimizers\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# model tuning\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe, space_eval\n\n# import warnings filter\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning) \n cv_number = 5 \n ## 2. Download datasets <a class=\"anchor\" id=\"2\"></a>\n\n[Back to Table of Contents](#0.1) \n traindf = pd.read_csv('../input/titanic/train.csv').set_index('PassengerId')\ntestdf = pd.read_csv('../input/titanic/test.csv').set_index('PassengerId')\nsubmission = pd.read_csv('../input/titanic/gender_submission.csv') \n ## 3. Features engineering (FE) <a class=\"anchor\" id=\"3\"></a>\n\n[Back to Table of Contents](#0.1) \n #Thanks to:\n# https://www.kaggle.com/mauricef/titanic\n# https://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code\n#\ndf = pd.concat([traindf, testdf], axis=0, sort=False)\ndf['Title'] = df.Name.str.split(',').str[1].str.split('.').str[0].str.strip()\ndf['Title'] = df.Name.str.split(',').str[1].str.split('.').str[0].str.strip()\ndf['IsWomanOrBoy'] = ((df.Title == 'Master') | (df.Sex == 'female'))\ndf['LastName'] = df.Name.str.split(',').str[0]\nfamily = df.groupby(df.LastName).Survived\ndf['WomanOrBoyCount'] = family.transform(lambda s: s[df.IsWomanOrBoy].fillna(0).count())\ndf['WomanOrBoyCount'] = df.mask(df.IsWomanOrBoy, df.WomanOrBoyCount - 1, axis=0)\ndf['FamilySurvivedCount'] = family.transform(lambda s: s[df.IsWomanOrBoy].fillna(0).sum())\ndf['FamilySurvivedCount'] = df.mask(df.IsWomanOrBoy, df.FamilySurvivedCount - \\\n                                    df.Survived.fillna(0), axis=0)\ndf['WomanOrBoySurvived'] = df.FamilySurvivedCount / df.WomanOrBoyCount.replace(0, np.nan)\ndf.WomanOrBoyCount = df.WomanOrBoyCount.replace(np.nan, 0)\ndf['Alone'] = (df.WomanOrBoyCount == 0)\n\n#Thanks to https://www.kaggle.com/kpacocha/top-6-titanic-machine-learning-from-disaster\n#\"Title\" improvement\ndf['Title'] = df['Title'].replace('Ms','Miss')\ndf['Title'] = df['Title'].replace('Mlle','Miss')\ndf['Title'] = df['Title'].replace('Mme','Mrs')\n# Embarked\ndf['Embarked'] = df['Embarked'].fillna('S')\n# Cabin, Deck\ndf['Deck'] = df['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\ndf.loc[(df['Deck'] == 'T'), 'Deck'] = 'A'\n\n# Thanks to https://www.kaggle.com/erinsweet/simpledetect\n# Fare\nmed_fare = df.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]\ndf['Fare'] = df['Fare'].fillna(med_fare)\n#Age\ndf['Age'] = df.groupby(['Sex', 'Pclass', 'Title'])['Age'].apply(lambda x: x.fillna(x.median()))\n# Family_Size\ndf['Family_Size'] = df['SibSp'] + df['Parch'] + 1\n\n# Thanks to https://www.kaggle.com/vbmokin/titanic-top-3-cluster-analysis\ncols_to_drop = ['Name','Ticket','Cabin']\ndf = df.drop(cols_to_drop, axis=1)\n\ndf.WomanOrBoySurvived = df.WomanOrBoySurvived.fillna(0)\ndf.WomanOrBoyCount = df.WomanOrBoyCount.fillna(0)\ndf.FamilySurvivedCount = df.FamilySurvivedCount.fillna(0)\ndf.Alone = df.Alone.fillna(0) \n target = df.Survived.loc[traindf.index]\ndf = df.drop(['Survived'], axis=1)\ntrain, test = df.loc[traindf.index], df.loc[testdf.index] \n train.head(3) \n test.head(3) \n target[:3] \n All models were tuned for a complete set of 16 features, solutions were calculated, that were uploaded to the competition, which made it possible to determine the error LB_all.\nAfter which the decision was taken into account\n* https://www.kaggle.com/mauricef/titanic\n* https://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code\n\ncalculated on only three features ('WomanOrBoySurvived', 'Alone', 'Sex') - an error LB is defined for this option. \n ## 4. Preparing to modeling <a class=\"anchor\" id=\"4\"></a>\n\n[Back to Table of Contents](#0.1) \n ### 4.1 Encoding categorical features <a class=\"anchor\" id=\"4.1\"></a> \n # Determination categorical features\nnumerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ncategorical_columns = []\nfeatures = train.columns.values.tolist()\nfor col in features:\n    if train[col].dtype in numerics: continue\n    categorical_columns.append(col)\ncategorical_columns \n # Encoding categorical features\nfor col in categorical_columns:\n    if col in train.columns:\n        le = LabelEncoder()\n        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n        train[col] = le.transform(list(train[col].astype(str).values))\n        test[col] = le.transform(list(test[col].astype(str).values))    \n train.info() \n test.info() \n ### 4.2 Creation of training and validation sets <a class=\"anchor\" id=\"4.2\"></a>\n\n[Back to Table of Contents](#0.1) \n #%% split training set to validation set\nSEED = 100\nXtrain, Xval, Ztrain, Zval = train_test_split(train, target, test_size=0.3, random_state=SEED) \n ## 5. Tuning models and test for all 16 features <a class=\"anchor\" id=\"5\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions\n\nNow we are ready to train a model and predict the required solution. There are 60+ predictive modelling algorithms to choose from. We must understand the type of problem and solution requirement to narrow down to a select few models which we can evaluate. Our problem is a classification and regression problem. We want to identify relationship between output (Survived or not) with other variables or features (Gender, Age, Port...). We are also perfoming a category of machine learning which is called supervised learning as we are training our model with a given dataset. With these two criteria - Supervised Learning plus Classification and Regression, we can narrow down our choice of models to a few. These include:\n\n- Logistic Regression\n- Support Vector Machines and Linear SVC\n- KNN or k-Nearest Neighbors\n- Naive Bayes Classifier or Gaussian Naive Bayes\n- Stochastic Gradient Descent, GradientBoostingClassifier, RidgeClassifier, BaggingClassifier\n- Decision Tree Classifier, Random Forest, XGB Classifier, LGBM Classifier, ExtraTreesClassifier\n- Perceptron, Neural Networks with different archictures (Deep Learning)\n- VotingClassifier (hard or soft voting) \n ### 5.1 Logistic Regression <a class=\"anchor\" id=\"5.1\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions \n **Logistic Regression** is a useful model to run early in the workflow. Logistic regression measures the relationship between the categorical dependent variable (feature) and one or more independent variables (features) by estimating probabilities using a logistic function, which is the cumulative logistic distribution. Reference [Wikipedia](https://en.wikipedia.org/wiki/Logistic_regression).\n\nNote the confidence score generated by the model based on our training dataset. \n # Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(train, target)\nY_pred = logreg.predict(test).astype(int)\nacc_log = round(logreg.score(train, target) * 100, 2)\nacc_log \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_logreg.csv', index=False)\nLB_log_all = 0.79904  # old version \n We can use Logistic Regression to validate our assumptions and decisions for feature creating and completing goals. This can be done by calculating the coefficient of the features in the decision function.\n\nPositive coefficients increase the log-odds of the response (and thus increase the probability), and negative coefficients decrease the log-odds of the response (and thus decrease the probability).\n\n- Alone is highest positivie coefficient, implying as the Alone value increases (0 to 1), the probability of Survived=1 increases the most.\n- Inversely as Sex increases (male: 0 to female: 1), probability of Survived=1 decreases the most.\n- This way Age has second highest negative correlation with Survived.\n- So is LastName as second highest positive correlation. \n coeff_df = pd.DataFrame(train.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False) \n ### 5.2 Support Vector Machines <a class=\"anchor\" id=\"5.2\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions \n **Support Vector Machines** are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. Given a set of training samples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new test samples to one category or the other, making it a non-probabilistic binary linear classifier. Reference [Wikipedia](https://en.wikipedia.org/wiki/Support_vector_machine). \n # Support Vector Machines\n\nsvc = SVC()\nsvc.fit(train, target)\nY_pred = svc.predict(test).astype(int)\nacc_svc = round(svc.score(train, target) * 100, 2)\nacc_svc \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_svm.csv', index=False)\nLB_svc_all = 0.62200  # old version \n ### 5.3 Linear SVC <a class=\"anchor\" id=\"5.3\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions \n **SVC** is a similar to SVM method. Its also builds on kernel functions but is appropriate for unsupervised learning. Reference [Wikipedia](https://en.wikipedia.org/wiki/Support-vector_machine#Support-vector_clustering_(SVC). \n # Linear SVC\n\nlinear_svc = LinearSVC(dual=False)  # dual=False when n_samples > n_features.\nlinear_svc.fit(train, target)\nY_pred = linear_svc.predict(test).astype(int)\nacc_linear_svc = round(linear_svc.score(train, target) * 100, 2)\nacc_linear_svc \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_linear_svc.csv', index=False)\nLB_linear_svc_all = 0.81339  # old version \n ### 5.4 k-Nearest Neighbors algorithm <a class=\"anchor\" id=\"5.4\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions \n In pattern recognition, the **k-Nearest Neighbors algorithm** (or k-NN for short) is a non-parametric method used for classification and regression. A sample is classified by a majority vote of its neighbors, with the sample being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). Reference [Wikipedia](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm). \n # k-Nearest Neighbors algorithm\n\nknn = GridSearchCV(estimator=KNeighborsClassifier(), param_grid={'n_neighbors': [2, 3, 4]}, cv=cv_number).fit(train, target)\nY_pred = knn.predict(test).astype(int)\nacc_knn = round(knn.score(train, target) * 100, 2)\nprint(acc_knn, knn.best_params_) \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_knn.csv', index=False)\nLB_knn_all = 0.62679  # old version \n ### 5.5 Naive Bayes <a class=\"anchor\" id=\"5.5\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions \n In machine learning, **Naive Bayes classifiers** are a family of simple probabilistic classifiers based on applying Bayes' theorem with strong (naive) independence assumptions between the features. Naive Bayes classifiers are highly scalable, requiring a number of parameters linear in the number of variables (features) in a learning problem. Reference [Wikipedia](https://en.wikipedia.org/wiki/Naive_Bayes_classifier). \n # Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(train, target)\nY_pred = gaussian.predict(test).astype(int)\nacc_gaussian = round(gaussian.score(train, target) * 100, 2)\nacc_gaussian \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_GaussianNB.csv', index=False)\nLB_gaussian_all = 0.73205  # old version \n ### 5.6 Perceptron <a class=\"anchor\" id=\"5.6\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions \n The **Perceptron** is an algorithm for supervised learning of binary classifiers (functions that can decide whether an input, represented by a vector of numbers, belongs to some specific class or not). It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector. The algorithm allows for online learning, in that it processes elements in the training set one at a time. Reference [Wikipedia](https://en.wikipedia.org/wiki/Perceptron). \n # Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(train, target)\nY_pred = perceptron.predict(test).astype(int)\nacc_perceptron = round(perceptron.score(train, target) * 100, 2)\nacc_perceptron \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_perceptron.csv', index=False)\nLB_perceptron_all = 0.46889  # old version \n ### 5.7 Stochastic Gradient Descent <a class=\"anchor\" id=\"5.7\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions \n **Stochastic gradient descent** (often abbreviated **SGD**) is an iterative method for optimizing an objective function with suitable smoothness properties (e.g. differentiable or subdifferentiable). It can be regarded as a stochastic approximation of gradient descent optimization, since it replaces the actual gradient (calculated from the entire data set) by an estimate thereof (calculated from a randomly selected subset of the data). Especially in big data applications this reduces the computational burden, achieving faster iterations in trade for a slightly lower convergence rate. Reference [Wikipedia](https://en.wikipedia.org/wiki/Stochastic_gradient_descent). \n # Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(train, target)\nY_pred = sgd.predict(test).astype(int)\nacc_sgd = round(sgd.score(train, target) * 100, 2)\nacc_sgd \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_sgd.csv', index=False)\nLB_sgd_all = 0.64593  # old version \n ### 5.8 Decision Tree Classifier <a class=\"anchor\" id=\"5.8\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions \n This model uses a **Decision Tree** as a predictive model which maps features (tree branches) to conclusions about the target value (tree leaves). Tree models where the target variable can take a finite set of values are called classification trees; in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. Reference [Wikipedia](https://en.wikipedia.org/wiki/Decision_tree_learning). \n # Decision Tree Classifier\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(train, target)\nY_pred = decision_tree.predict(test).astype(int)\nacc_decision_tree = round(decision_tree.score(train, target) * 100, 2)\nacc_decision_tree \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_decision_tree.csv', index=False)\nLB_decision_tree_all = 0.77990  # old version \n ### 5.9 Random Forests <a class=\"anchor\" id=\"5.9\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions \n **Random Forests** is one of the most popular model. Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees (n_estimators= [100, 300]) at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Reference [Wikipedia](https://en.wikipedia.org/wiki/Random_forest). \n # Random Forest\n\nrandom_forest = GridSearchCV(estimator=RandomForestClassifier(), param_grid={'n_estimators': [200, 300, 400, 500]}, cv=cv_number).fit(train, target)\nrandom_forest.fit(train, target)\nY_pred = random_forest.predict(test).astype(int)\nrandom_forest.score(train, target)\nacc_random_forest = round(random_forest.score(train, target) * 100, 2)\nprint(acc_random_forest,random_forest.best_params_) \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_random_forest.csv', index=False)\nLB_random_forest_all = 0.81339  # old version \n ### 5.10 XGB Classifier <a class=\"anchor\" id=\"5.10\"></a>\n\n[Back to Table of Contents](#0.1) \n XGBoost is an ensemble tree method that apply the principle of boosting weak learners (CARTs generally) using the gradient descent architecture. XGBoost improves upon the base Gradient Boosting Machines (GBM) framework through systems optimization and algorithmic enhancements. Reference [Towards Data Science.](https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d) \n We will tuning the hyperparameters of the XGBClassifier model using the HyperOpt and 10-fold crossvalidation \n %%time\ndef hyperopt_xgb_score(params):\n    clf = XGBClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_xgb = {\n            'learning_rate': hp.quniform('learning_rate', 0, 0.05, 0.0001),\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_depth':  hp.choice('max_depth', np.arange(5, 8, dtype=int)),\n            'min_child_weight': hp.quniform('min_child_weight', 1, 9, 0.025),\n            'subsample': hp.quniform('subsample', 0.5, 1, 0.005),\n            'gamma': hp.quniform('gamma', 0.5, 1, 0.005),\n            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.005),\n            'eval_metric': 'auc',\n            'objective': 'binary:logistic',\n            'booster': 'gbtree',\n            'tree_method': 'exact',\n            'silent': 1,\n            'missing': None\n        }\n \nbest = fmin(fn=hyperopt_xgb_score, space=space_xgb, algo=tpe.suggest, max_evals=10)\nprint('best:')\nprint(best) \n params = space_eval(space_xgb, best)\nparams \n XGB_Classifier = XGBClassifier(**params)\nXGB_Classifier.fit(train, target)\nY_pred = XGB_Classifier.predict(test).astype(int)\nXGB_Classifier.score(train, target)\nacc_XGB_Classifier = round(XGB_Classifier.score(train, target) * 100, 2)\nacc_XGB_Classifier \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_XGB_Classifier.csv', index=False)\nLB_XGB_Classifier_all = 0.80861  # old version \n fig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nxgb.plot_importance(XGB_Classifier,ax = axes,height =0.5)\nplt.show();\nplt.close() \n ### 5.11 LGBM Classifier <a class=\"anchor\" id=\"5.11\"></a>\n\n[Back to Table of Contents](#0.1) \n Light GBM is a fast, distributed, high-performance gradient boosting framework based on decision tree algorithms. It splits the tree leaf wise with the best fit whereas other boosting algorithms split the tree depth wise or level wise rather than leaf-wise. So when growing on the same leaf in Light GBM, the leaf-wise algorithm can reduce more loss than the level-wise algorithm and hence results in much better accuracy which can rarely be achieved by any of the existing boosting algorithms. Also, it is surprisingly very fast, hence the word \u2018Light\u2019. Reference [Analytics Vidhya](https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/). \n We will tuning the hyperparameters of the LGBMClassifier model using the HyperOpt and 10-fold crossvalidation \n %%time\ndef hyperopt_lgb_score(params):\n    clf = LGBMClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_lgb = {\n            'learning_rate': hp.quniform('learning_rate', 0, 0.05, 0.0001),\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_depth':  hp.choice('max_depth', np.arange(4, 7, dtype=int)),\n            'num_leaves': hp.choice('num_leaves', 2*np.arange(20, 2**6, dtype=int)),\n            'min_child_weight': hp.quniform('min_child_weight', 1, 9, 0.025),\n            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.005),\n            'objective': 'binary',\n            'boosting_type': 'gbdt',\n            }\n \nbest = fmin(fn=hyperopt_lgb_score, space=space_lgb, algo=tpe.suggest, max_evals=10)\nprint('best:')\nprint(best) \n params = space_eval(space_lgb, best)\nparams \n LGB_Classifier = LGBMClassifier(**params)\nLGB_Classifier.fit(train, target)\nY_pred = LGB_Classifier.predict(test).astype(int)\nLGB_Classifier.score(train, target)\nacc_LGB_Classifier = round(LGB_Classifier.score(train, target) * 100, 2)\nacc_LGB_Classifier \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_LGB_Classifier.csv', index=False)\nLB_LGB_Classifier_all = 0.82296  # old version \n fig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nlgb.plot_importance(LGB_Classifier,ax = axes,height = 0.5)\nplt.show();\nplt.close() \n ### 5.12 GradientBoostingClassifier <a class=\"anchor\" id=\"5.12\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/kabure/titanic-eda-model-pipeline-keras-nn \n **Gradient Boosting** builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage n_classes_ regression trees are fit on the negative gradient of the binomial or multinomial deviance loss function. Binary classification is a special case where only a single regression tree is induced. The features are always randomly permuted at each split. Therefore, the best found split may vary, even with the same training data and max_features=n_features, if the improvement of the criterion is identical for several splits enumerated during the search of the best split. To obtain a deterministic behaviour during fitting, random_state has to be fixed. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html). \n %%time\ndef hyperopt_gb_score(params):\n    clf = GradientBoostingClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_gb = {\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_depth': hp.choice('max_depth', np.arange(5, 8, dtype=int))            \n        }\n \nbest = fmin(fn=hyperopt_gb_score, space=space_gb, algo=tpe.suggest, max_evals=10)\nprint('best:')\nprint(best) \n params = space_eval(space_gb, best)\nparams \n # Gradient Boosting Classifier\n\ngradient_boosting = GradientBoostingClassifier(**params)\ngradient_boosting.fit(train, target)\nY_pred = gradient_boosting.predict(test).astype(int)\ngradient_boosting.score(train, target)\nacc_gradient_boosting = round(gradient_boosting.score(train, target) * 100, 2)\nacc_gradient_boosting \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_gradient_boosting.csv', index=False)\nLB_GBC_all = 0.82296  # old version \n ### 5.13 RidgeClassifier <a class=\"anchor\" id=\"5.13\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/kabure/titanic-eda-model-pipeline-keras-nn \n Tikhonov Regularization, colloquially known as **Ridge Regression**, is the most commonly used regression algorithm to approximate an answer for an equation with no unique solution. This type of problem is very common in machine learning tasks, where the \"best\" solution must be chosen using limited data. If a unique solution exists, algorithm will return the optimal value. However, if multiple solutions exist, it may choose any of them. Reference [Brilliant.org](https://brilliant.org/wiki/ridge-regression/). \n # Ridge Classifier\n\nridge_classifier = RidgeClassifier()\nridge_classifier.fit(train, target)\nY_pred = ridge_classifier.predict(test).astype(int)\nridge_classifier.score(train, target)\nacc_ridge_classifier = round(ridge_classifier.score(train, target) * 100, 2)\nacc_ridge_classifier \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_ridge_classifier.csv', index=False)\nLB_RidgeClassifier_all = 0.80861  # old version \n ### 5.14 BaggingClassifier <a class=\"anchor\" id=\"5.14\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/kabure/titanic-eda-model-pipeline-keras-nn \n Bootstrap aggregating, also called **bagging**, is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It also reduces variance and helps to avoid overfitting. Although it is usually applied to decision tree methods, it can be used with any type of method. Bagging is a special case of the model averaging approach. Bagging leads to \"improvements for unstable procedures\", which include, for example, artificial neural networks, classification and regression trees, and subset selection in linear regression. On the other hand, it can mildly degrade the performance of stable methods such as K-nearest neighbors. Reference [Wikipedia](https://en.wikipedia.org/wiki/Bootstrap_aggregating).\n\nA **Bagging classifier** is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html). \n # Bagging Classifier\n\nbagging_classifier = BaggingClassifier()\nbagging_classifier.fit(train, target)\nY_pred = bagging_classifier.predict(test).astype(int)\nbagging_classifier.score(train, target)\nacc_bagging_classifier = round(bagging_classifier.score(train, target) * 100, 2)\nacc_bagging_classifier \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_bagging_classifier.csv', index=False)\nLB_bagging_classifier_all = 0.80861  # old version \n ### 5.15 ExtraTreesClassifier <a class=\"anchor\" id=\"5.15\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/kabure/titanic-eda-model-pipeline-keras-nn \n **ExtraTreesClassifier** implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The default values for the parameters controlling the size of the trees (e.g. max_depth, min_samples_leaf, etc.) lead to fully grown and unpruned trees which can potentially be very large on some data sets. To reduce memory consumption, the complexity and size of the trees should be controlled by setting those parameter values. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html). \n\nIn extremely randomized trees, randomness goes one step further in the way splits are computed. As in random forests, a random subset of candidate features is used, but instead of looking for the most discriminative thresholds, thresholds are drawn at random for each candidate feature and the best of these randomly-generated thresholds is picked as the splitting rule. This usually allows to reduce the variance of the model a bit more, at the expense of a slightly greater increase in bias. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/ensemble.html#Extremely%20Randomized%20Trees). \n def hyperopt_etc_score(params):\n    clf = ExtraTreesClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_etc = {\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_features': hp.choice('max_features', np.arange(2, 10, dtype=int)),\n            'min_samples_leaf': hp.choice('min_samples_leaf', np.arange(1, 5, dtype=int)),\n            'max_depth':  hp.choice('max_depth', np.arange(4, 8, dtype=int)),\n        }\n \nbest = fmin(fn=hyperopt_etc_score, space=space_etc, algo=tpe.suggest, max_evals=10)\nprint('best:')\nprint(best) \n params = space_eval(space_etc, best)\nparams \n # Extra Trees Classifier\n\nextra_trees_classifier = ExtraTreesClassifier(**params)\nextra_trees_classifier.fit(train, target)\nY_pred = extra_trees_classifier.predict(test).astype(int)\nextra_trees_classifier.score(train, target)\nacc_etc = round(extra_trees_classifier.score(train, target) * 100, 2)\nacc_etc \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_etc.csv', index=False)\nLB_ETC_all = 0.80861  # old version \n ### 5.16 Neural Network 1 <a class=\"anchor\" id=\"5.16\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/nhlr21/complete-titanic-tutorial-with-ml-nn-ensembling \n **Neural networks** are more complex and more powerful algorithm than standars machine learning, it belongs to deep learning models. To build a neural network use Keras. Keras is a high level API for tensorflow, which is a tensor-manipulation framework made by google. Keras allows you to build neural networks by assembling blocks (which are the layers of neural network).  \n def build_ann(optimizer='adam'):\n    \n    # Initializing the ANN\n    ann = Sequential()\n    \n    # Adding the input layer and the first hidden layer of the ANN with dropout\n    ann.add(Dense(units=32, kernel_initializer='glorot_uniform', activation='relu', input_shape=(16,)))\n    \n    # Add other layers, it is not necessary to pass the shape because there is a layer before\n    ann.add(Dense(units=64, kernel_initializer='glorot_uniform', activation='relu'))\n    ann.add(Dropout(rate=0.5))\n    ann.add(Dense(units=64, kernel_initializer='glorot_uniform', activation='relu'))\n    ann.add(Dropout(rate=0.5))\n    \n    # Adding the output layer\n    ann.add(Dense(units=1, kernel_initializer='glorot_uniform', activation='sigmoid'))\n    \n    # Compiling the ANN\n    ann.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return ann \n opt = optimizers.Adam(lr=0.001)\nann = build_ann(opt)\n# Training the ANN\nhistory = ann.fit(Xtrain, Ztrain, batch_size=16, epochs=100, validation_data=(Xval, Zval)) \n # Predicting the Test set results\nY_pred = ann.predict(test)\nY_pred = (Y_pred > 0.5)*1 # convert probabilities to binary output \n # Predicting the Train set results\nann_prediction = ann.predict(train)\nann_prediction = (ann_prediction > 0.5)*1 # convert probabilities to binary output\n\n# Compute error between predicted data and true response and display it in confusion matrix\nacc_ann1 = round(metrics.accuracy_score(target, ann_prediction) * 100, 2)\nacc_ann1 \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": np.reshape(Y_pred, len(Y_pred))})\n#submission.to_csv('output/submission_ann1.csv', index=False)\nLB_ann1_all = 0.59330  # old version \n ### 5.17 Neural Network 2 <a class=\"anchor\" id=\"5.17\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/junheeshin/titanic-analyze-and-predict-nn \n # Model\nmodel = Sequential()\nmodel.add(Dense(16, input_dim = train.shape[1], init = 'he_normal', activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64, init = 'he_normal', activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(32, init = 'he_normal', activation = 'relu'))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.summary() \n model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n es = EarlyStopping(monitor='val_accuracy', patience=20, mode='max')\nhist = model.fit(train, target, batch_size=64, validation_data=(Xval, Zval), \n               epochs=500, verbose=1, callbacks=[es]) \n plt.plot(hist.history['accuracy'], label='acc')\nplt.plot(hist.history['val_accuracy'], label='val_acc')\n# plt.plot(hist.history['acc'], label='acc')\n# plt.plot(hist.history['val_acc'], label='val_acc')\nplt.ylim((0, 1))\nplt.legend() \n # Predicting the Test set results\nY_pred = model.predict(test)\nY_pred = (Y_pred > 0.5)*1 # convert probabilities to binary output \n # Predicting the Train set results\nnn_prediction = model.predict(train)\nnn_prediction = (nn_prediction > 0.5)*1 # convert probabilities to binary output\n\n# Compute error between predicted data and true response\nacc_ann2 = round(metrics.accuracy_score(target, nn_prediction) * 100, 2)\nacc_ann2 \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": np.reshape(Y_pred, len(Y_pred))})\n#submission.to_csv('output/submission_ann2.csv', index=False)\nLB_ann2_all = 0.64114  # old version \n ### 5.18 VotingClassifier (hard voting) <a class=\"anchor\" id=\"5.18\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks for the example of ensemling different models from \nhttps://scikit-learn.org/stable/modules/ensemble.html#Extremely%20Randomized%20Trees \n The idea behind the **VotingClassifier** is to combine conceptually different machine learning classifiers and use a majority vote (hard vote) or the average predicted probabilities (soft vote) to predict the class labels. Such a classifier can be useful for a set of equally well performing model in order to balance out their individual weaknesses. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/ensemble.html#Voting%20Classifier). \n The VotingClassifier (with **hard voting**) would classify the sample as \u201cclass 1\u201d based on the **majority class label**. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/ensemble.html#Voting%20Classifier). \n Voting_Classifier_hard = VotingClassifier(estimators=[('lr', logreg), ('rf', random_forest), ('gbc', gradient_boosting)], voting='hard')\nfor clf, label in zip([logreg, random_forest, gradient_boosting, Voting_Classifier_hard], \n                      ['Logistic Regression', 'Random Forest', 'Gradient Boosting Classifier', 'Ensemble']):\n    scores = cross_val_score(clf, train, target, cv=cv_number, scoring='accuracy')\n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label)) \n Voting_Classifier_hard.fit(train, target)\nY_pred = Voting_Classifier_hard.predict(test).astype(int)\nVoting_Classifier_hard.score(train, target)\nacc_VC_hard = round(Voting_Classifier_hard.score(train, target) * 100, 2)\nacc_VC_hard \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_VC_hard.csv', index=False)\nLB_VC_hard_all = 0.81339  # old version \n ### 5.19 VotingClassifier (soft voting) <a class=\"anchor\" id=\"5.19\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks for the example of ensemling different models from \nhttps://scikit-learn.org/stable/modules/ensemble.html#Extremely%20Randomized%20Trees \n In contrast to majority voting (hard voting), **soft voting** returns the class label as argmax of the **sum of predicted probabilities**.\nSpecific weights can be assigned to each classifier via the weights parameter. When weights are provided, the predicted class probabilities for each classifier are collected, multiplied by the classifier weight, and averaged. The final class label is then derived from the class label with the highest average probability. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/ensemble.html#Voting%20Classifier). \n eclf = VotingClassifier(estimators=[('lr', logreg), ('rf', random_forest), ('gbc', gradient_boosting)], voting='soft')\nparams = {'lr__C': [1.0, 100.0], 'gbc__learning_rate': [0.05, 1]}\nVoting_Classifier_soft = GridSearchCV(estimator=eclf, param_grid=params, cv=cv_number)\nVoting_Classifier_soft.fit(train, target)\nY_pred = Voting_Classifier_soft.predict(test).astype(int)\nVoting_Classifier_soft.score(train, target)\nacc_VC_soft = round(Voting_Classifier_soft.score(train, target) * 100, 2)\nacc_VC_soft \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_VC_soft.csv', index=False)\nLB_VC_soft_all = 0.81339  # old version \n ### 5.20 The simple rule in one line <a class=\"anchor\" id=\"5.20\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to:\n* https://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code\n* https://www.kaggle.com/vbmokin/titanic-top-3-cluster-analysis\n* https://www.kaggle.com/mauricef/titanic \n Y_pred = (((test.WomanOrBoySurvived <= 0.238) & (test.Sex > 0.5) & (test.Alone > 0.5)) | \\\n          ((test.WomanOrBoySurvived > 0.238) & \\\n           ~((test.WomanOrBoySurvived > 0.55) & (test.WomanOrBoySurvived <= 0.633)))) \n It's solution generate tuned DecisionTreeClassifier by the GridSearchCV from kernels:\nhttps://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code \n simple_rule_model = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n                       max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort=False,\n                       random_state=1118, splitter='best') \nsimple_rule_model.fit(train, target)\nY_pred = simple_rule_model.predict(test).astype(int)\nsimple_rule_model.score(train, target)\nacc_simple_rule = round(simple_rule_model.score(train, target) * 100, 2)\nacc_simple_rule \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_simple_rule.csv', index=False)\nLB_simple_rule_all = 0.83253  # old version \n ## 6. Tuning models and test for 3 features <a class=\"anchor\" id=\"6\"></a>\n\n[Back to Table of Contents](#0.1) \n My kernels\n\n* [Titanic : one line of the prediction code](https://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code)\n* [Titanic : cluster analysis](https://www.kaggle.com/vbmokin/titanic-top-3-cluster-analysis)\n\npresents a solutions using a simple rule and only 3 features ('WomanOrBoySurvived', 'Sex', 'Alone'). Let's look at how all these models are tuned for those 3 features and whether we can find an even better solution. \n # Preparing datasets for only 3 features ('WomanOrBoySurvived', 'Sex', 'Alone')\ncols_to_drop3 = ['SibSp', 'Parch', 'Fare', 'LastName', 'Deck',\n               'Pclass', 'Age', 'Embarked', 'Title', 'IsWomanOrBoy',\n               'WomanOrBoyCount', 'FamilySurvivedCount', 'Family_Size']\ntrain = train.drop(cols_to_drop3, axis=1)\ntest = test.drop(cols_to_drop3, axis=1)\nXtrain, Xval, Ztrain, Zval = train_test_split(train, target, test_size=0.3, random_state=SEED)\ntrain.info() \n # 1. Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(train, target)\nY_pred = logreg.predict(test).astype(int)\nacc3_log = round(logreg.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_logreg3.csv', index=False)\nLB_log = 0.77033 \n # 2. Support Vector Machines\n\nsvc = SVC()\nsvc.fit(train, target)\nY_pred = svc.predict(test).astype(int)\nacc3_svc = round(svc.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_svm3.csv', index=False)\nLB_svc = 0.79904 \n # 3. Linear SVC\n\nlinear_svc = LinearSVC(dual=False)\nlinear_svc.fit(train, target)\nY_pred = linear_svc.predict(test).astype(int)\nacc3_linear_svc = round(linear_svc.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_linear_svc3.csv', index=False)\nLB_linear_svc = 0.77033 \n # 4. k-Nearest Neighbors algorithm\n\nknn = GridSearchCV(estimator=KNeighborsClassifier(), param_grid={'n_neighbors': [2, 3, 4]}, cv=cv_number).fit(train, target)\nY_pred = knn.predict(test).astype(int)\nacc3_knn = round(knn.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_knn3.csv', index=False)\nLB_knn = 0.77751 \n # 5. Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(train, target)\nY_pred = gaussian.predict(test).astype(int)\nacc3_gaussian = round(gaussian.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_GaussianNB3.csv', index=False)\nLB_gaussian = 0.68899 \n # 6. Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(train, target)\nY_pred = perceptron.predict(test).astype(int)\nacc3_perceptron = round(perceptron.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_perceptron3.csv', index=False)\nLB_perceptron = 0.77511 \n # 7. Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(train, target)\nY_pred = sgd.predict(test).astype(int)\nacc3_sgd = round(sgd.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_sgd3.csv', index=False)\nLB_sgd = 0.77511 \n # 8. Decision Tree Classifier\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(train, target)\nY_pred = decision_tree.predict(test).astype(int)\nacc3_decision_tree = round(decision_tree.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_decision_tree3.csv', index=False)\nLB_decision_tree = 0.80382 \n # 9. Random Forest\n\nrandom_forest = GridSearchCV(estimator=RandomForestClassifier(), param_grid={'n_estimators': [200, 300, 400, 500]}, cv=cv_number).fit(train, target)\nrandom_forest.fit(train, target)\nY_pred = random_forest.predict(test).astype(int)\nrandom_forest.score(train, target)\nacc3_random_forest = round(random_forest.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_random_forest3.csv', index=False)\nLB_random_forest = 0.80382 \n # 10. XGB_Classifier\n\ndef hyperopt_xgb_score(params):\n    clf = XGBClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_xgb = {\n            'learning_rate': hp.quniform('learning_rate', 0, 0.05, 0.0001),\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'eta': hp.quniform('eta', 0.025, 0.5, 0.005),\n            'max_depth':  hp.choice('max_depth', np.arange(4, 8, dtype=int)),\n            'min_child_weight': hp.quniform('min_child_weight', 1, 9, 0.025),\n            'subsample': hp.quniform('subsample', 0.5, 1, 0.005),\n            'gamma': hp.quniform('gamma', 0.5, 1, 0.005),\n            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.005),\n            'eval_metric': 'auc',\n            'objective': 'binary:logistic',\n            'booster': 'gbtree',\n            'tree_method': 'exact',\n            'silent': 1,\n            'missing': None\n        }\n \nbest = fmin(fn=hyperopt_xgb_score, space=space_xgb, algo=tpe.suggest, max_evals=10)\nparams = space_eval(space_xgb, best)\nXGB_Classifier = XGBClassifier(**params)\nXGB_Classifier.fit(train, target)\nY_pred = XGB_Classifier.predict(test).astype(int)\nXGB_Classifier.score(train, target)\nacc3_XGB_Classifier = round(XGB_Classifier.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_XGB_Classifier3.csv', index=False)\nLB_XGB_Classifier = 0.68899\nprint(params) \n # 11. LGBM_Classifier\n\ndef hyperopt_lgb_score(params):\n    clf = LGBMClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_lgb = {\n            'learning_rate': hp.quniform('learning_rate', 0, 0.05, 0.0001),\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_depth':  hp.choice('max_depth', np.arange(4, 7, dtype=int)),\n            'num_leaves': hp.choice('num_leaves', 2*np.arange(20, 2**6, dtype=int)),\n            'min_child_weight': hp.quniform('min_child_weight', 1, 9, 0.025),\n            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.005),\n            'objective': 'binary',\n            'boosting_type': 'gbdt',\n            }\n \nbest = fmin(fn=hyperopt_lgb_score, space=space_lgb, algo=tpe.suggest, max_evals=10)\nparams = space_eval(space_lgb, best)\nLGB_Classifier = LGBMClassifier(**params)\nLGB_Classifier.fit(train, target)\nY_pred = LGB_Classifier.predict(test).astype(int)\nLGB_Classifier.score(train, target)\nacc3_LGB_Classifier = round(LGB_Classifier.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_LGB_Classifier3.csv', index=False)\nLB_LGB_Classifier = 0.62200\nprint(params) \n # 12. GradientBoostingClassifier\n\ndef hyperopt_gb_score(params):\n    clf = GradientBoostingClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_gb = {\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_depth': hp.choice('max_depth', np.arange(4, 8, dtype=int)),\n            'max_features': None\n        }\n \nbest = fmin(fn=hyperopt_gb_score, space=space_gb, algo=tpe.suggest, max_evals=5)\nparams = space_eval(space_gb, best)\ngradient_boosting = GradientBoostingClassifier(**params)\ngradient_boosting.fit(train, target)\nY_pred = gradient_boosting.predict(test).astype(int)\ngradient_boosting.score(train, target)\nacc3_gradient_boosting = round(gradient_boosting.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_gradient_boosting3.csv', index=False)\nLB_GBC = 0.80382\nprint(params) \n # 13. Ridge Classifier\n\nridge_classifier = RidgeClassifier()\nridge_classifier.fit(train, target)\nY_pred = ridge_classifier.predict(test).astype(int)\nridge_classifier.score(train, target)\nacc3_ridge_classifier = round(ridge_classifier.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_ridge_classifier3.csv', index=False)\nLB_RidgeClassifier = 0.77511 \n # 14. Bagging Classifier\n\nbagging_classifier = BaggingClassifier()\nbagging_classifier.fit(train, target)\nY_pred = bagging_classifier.predict(test).astype(int)\nbagging_classifier.score(train, target)\nacc3_bagging_classifier = round(bagging_classifier.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_bagging_classifier3.csv', index=False)\nLB_bagging_classifier = 0.80382 \n # 15. Extra Trees Classifier\n\ndef hyperopt_etc_score(params):\n    clf = ExtraTreesClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_etc = {\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_features': hp.choice('max_features', np.arange(2, 10, dtype=int)),\n            'min_samples_leaf': hp.choice('min_samples_leaf', np.arange(1, 5, dtype=int)),\n            'max_depth':  hp.choice('max_depth', np.arange(2, 8, dtype=int)),\n            'max_features': None\n        }\n \nbest = fmin(fn=hyperopt_etc_score, space=space_etc, algo=tpe.suggest, max_evals=5)\nparams = space_eval(space_etc, best)\nextra_trees_classifier = ExtraTreesClassifier(**params)\nextra_trees_classifier.fit(train, target)\nY_pred = extra_trees_classifier.predict(test).astype(int)\nextra_trees_classifier.score(train, target)\nacc3_etc = round(extra_trees_classifier.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_etc3.csv', index=False)\nLB_ETC = 0.79904\nprint(params) \n # 16. Neural Network 1 \n\ndef build_ann(optimizer='adam'):\n    \n    # Initializing the ANN\n    ann = Sequential()\n    \n    # Adding the input layer and the first hidden layer of the ANN with dropout\n    ann.add(Dense(units=32, kernel_initializer='glorot_uniform', activation='relu', input_shape=(3,)))\n    \n    # Add other layers, it is not necessary to pass the shape because there is a layer before\n    ann.add(Dense(units=64, kernel_initializer='glorot_uniform', activation='relu'))\n    ann.add(Dropout(rate=0.5))\n    ann.add(Dense(units=64, kernel_initializer='glorot_uniform', activation='relu'))\n    ann.add(Dropout(rate=0.5))\n    \n    # Adding the output layer\n    ann.add(Dense(units=1, kernel_initializer='glorot_uniform', activation='sigmoid'))\n    \n    # Compiling the ANN\n    ann.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return ann\nopt = optimizers.Adam(lr=0.001)\nann = build_ann(opt)\nhistory = ann.fit(Xtrain, Ztrain, batch_size=16, epochs=100, validation_data=(Xval, Zval))\nY_pred = ann.predict(test)\nY_pred = (Y_pred > 0.5)*1 # convert probabilities to binary output\nann_prediction = ann.predict(train)\nann_prediction = (ann_prediction > 0.5)*1 # convert probabilities to binary output\nacc3_ann1 = round(metrics.accuracy_score(target, ann_prediction) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": np.reshape(Y_pred, len(Y_pred))})\nsubmission.to_csv('submission_ann1_3.csv', index=False)\nLB_ann1 = 0.79904 \n # 17. Neural Network 2\n\n# Model\nmodel = Sequential()\nmodel.add(Dense(16, input_dim = train.shape[1], init = 'he_normal', activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64, init = 'he_normal', activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(32, init = 'he_normal', activation = 'relu'))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nes = EarlyStopping(monitor='val_accuracy', patience=20, mode='max')\nhist = model.fit(train, target, batch_size=64, validation_data=(Xval, Zval), \n               epochs=500, verbose=1, callbacks=[es])\nY_pred = model.predict(test)\nY_pred = (Y_pred > 0.5)*1 # convert probabilities to binary output\nnn_prediction = model.predict(train)\nnn_prediction = (nn_prediction > 0.5)*1 # convert probabilities to binary output\nacc3_ann2 = round(metrics.accuracy_score(target, nn_prediction) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": np.reshape(Y_pred, len(Y_pred))})\nsubmission.to_csv('submission_ann2_3.csv', index=False)\nLB_ann2 = 0.79665 \n # 5.18 VotingClassifier (hard voting)\n\nVoting_Classifier_hard = VotingClassifier(estimators=[('lr', logreg), ('rf', random_forest), ('gbc', gradient_boosting)], voting='hard')\nfor clf, label in zip([logreg, random_forest, gradient_boosting, Voting_Classifier_hard], \n                      ['Logistic Regression', 'Random Forest', 'Gradient Boosting Classifier', 'Ensemble']):\n    scores = cross_val_score(clf, train, target, cv=cv_number, scoring='accuracy')\n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\nVoting_Classifier_hard.fit(train, target)\nY_pred = Voting_Classifier_hard.predict(test).astype(int)\nVoting_Classifier_hard.score(train, target)\nacc3_VC_hard = round(Voting_Classifier_hard.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_VC_hard3.csv', index=False)\nLB_VC_hard = 0.80382 \n # 5.19 VotingClassifier (soft voting)\n\neclf = VotingClassifier(estimators=[('lr', logreg), ('rf', random_forest), ('gbc', gradient_boosting)], voting='soft')\nparams = {'lr__C': [1.0, 100.0], 'gbc__learning_rate': [0.05, 1]}\nVoting_Classifier_soft = GridSearchCV(estimator=eclf, param_grid=params, cv=cv_number)\nVoting_Classifier_soft.fit(train, target)\nY_pred = Voting_Classifier_soft.predict(test).astype(int)\nVoting_Classifier_soft.score(train, target)\nacc3_VC_soft = round(Voting_Classifier_soft.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_VC_soft3.csv', index=False)\nLB_VC_soft = 0.80382 \n # 5.20 The simple rule in one line\nY_pred = (((test.WomanOrBoySurvived <= 0.238) & (test.Sex > 0.5) & (test.Alone > 0.5)) | \\\n          ((test.WomanOrBoySurvived > 0.238) & \\\n           ~((test.WomanOrBoySurvived > 0.55) & (test.WomanOrBoySurvived <= 0.633))))\nacc3_simple_rule = acc_simple_rule\nLB_simple_rule = 0.80382 \n ## 7. Models evaluation <a class=\"anchor\" id=\"7\"></a>\n\n[Back to Table of Contents](#0.1) \n We can now rank our evaluation of all the models to choose the best one for our problem. \n models = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Support Vector Machines', 'Linear SVC', 'k-Nearest Neighbors', 'Naive Bayes', \n              'Perceptron', 'Stochastic Gradient Decent', \n              'Decision Tree Classifier', 'Random Forest',  'XGBClassifier', 'LGBMClassifier',\n              'GradientBoostingClassifier', 'RidgeClassifier', 'BaggingClassifier', 'ExtraTreesClassifier', \n              'Neural Network 1', 'Neural Network 2', \n              'VotingClassifier-hard voiting', 'VotingClassifier-soft voting',\n              'Simple rule'],\n    \n    'Score16': [acc_log, acc_svc, acc_linear_svc, acc_knn, acc_gaussian, \n              acc_perceptron, acc_sgd, \n              acc_decision_tree, acc_random_forest, acc_XGB_Classifier, acc_LGB_Classifier,\n              acc_gradient_boosting, acc_ridge_classifier, acc_bagging_classifier, acc_etc, \n              acc_ann1, acc_ann2, \n              acc_VC_hard, acc_VC_soft,\n              acc_simple_rule],\n\n    'Score3': [acc3_log, acc3_svc, acc3_linear_svc, acc3_knn, acc3_gaussian, \n              acc3_perceptron, acc3_sgd, \n              acc3_decision_tree, acc3_random_forest, acc3_XGB_Classifier, acc3_LGB_Classifier,\n              acc3_gradient_boosting, acc3_ridge_classifier, acc3_bagging_classifier, acc3_etc, \n              acc3_ann1, acc3_ann2, \n              acc3_VC_hard, acc3_VC_soft,\n              acc3_simple_rule],\n\n    'LB_all': [LB_log_all, LB_svc_all, LB_linear_svc_all, LB_knn_all, LB_gaussian_all, \n              LB_perceptron_all, LB_sgd_all, \n              LB_decision_tree_all, LB_random_forest_all, LB_XGB_Classifier_all, LB_LGB_Classifier_all,\n              LB_GBC_all, LB_RidgeClassifier_all, LB_bagging_classifier_all, LB_ETC_all, \n              LB_ann1_all, LB_ann2_all, \n              LB_VC_hard_all, LB_VC_soft_all,\n              LB_simple_rule_all],\n    \n    'LB':    [LB_log, LB_svc, LB_linear_svc, LB_knn, LB_gaussian, \n              LB_perceptron, LB_sgd, \n              LB_decision_tree, LB_random_forest, LB_XGB_Classifier, LB_LGB_Classifier,\n              LB_GBC, LB_RidgeClassifier, LB_bagging_classifier, LB_ETC, \n              LB_ann1, LB_ann2, \n              LB_VC_hard, LB_VC_soft,\n              LB_simple_rule]}) \n models.sort_values(by=['Score16', 'LB_all', 'LB'], ascending=False) \n models.sort_values(by=['Score3', 'LB_all', 'LB'], ascending=False) \n models.sort_values(by=['LB_all', 'LB', 'Score3'], ascending=False) \n models.sort_values(by=['LB', 'LB_all', 'Score3'], ascending=False) \n ## 8. Conclusion <a class=\"anchor\" id=\"8\"></a>\n\n[Back to Table of Contents](#0.1) \n - The best model is the **simple rule in one line** from [\"Titanic Top 3% : one line of the prediction code\"](https://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code). Surprisingly, that the simple rule in one line gives the best result. This once again proves the enormous value of features engineering. The optimal selection of features is the key to success!\n\n- Models **GradientBoostingClassifier, Random Forests, VotingClassifiers, BaggingClassifier, Decision Tree Classifier** have provided the same accuracy LB on the test dataset as the simple rule, although on the training dataset they are much more accurate up to 100%.\n\n- The **VotingClassifier** for both voting options (\"*hard*\" and \"*soft*\") aggregation gave the same result for all the variants of features, that is, the solution found is indeed optimal, although a **Logistic Regression**, which is not one of the best, was selected for voting. This confirms the high efficiency of this method of aggregating (ensembling) predictions.\n\n- The models **GradientBoostingClassifier, BaggingClassifier, Random Forests, VotingClassifiers** did a good job of optimizing the features themselves, providing comparable accuracy for the different number of features in the test dataset, but the models **Decision Tree Classifier, Stochastic Gradient Descent, Support Vector Machines, Perceptron, Neural Networks, k-Nearest Neighbors algorithm** are very sensitive to the feature sets, because the accuracy of LB_all and LB is very different. Models **XGB Classifier, LGBM Classifier, ExtraTreesClassifier, Logistic Regression, Linear SVC, Naive Bayes, RidgeClassifier** depend on FE, but not so significantly.\n\n- The methods **LGBM Classifier, Perceptron, Neural Networks, Linear SVC, Naive Bayes, Logistic Regression, k-Nearest Neighbors algorithm, RidgeClassifier** have low accuracy LB, especially methods **Naive Bayes, Logistic Regression, Linear SVC**, compared to other models, although the \"***Titanic: Machine Learning from Disaster***\" contest is not indicative for the machine learning tasks because it contains too little data.\n\n- In all models, except **LGBM Classifier, Linear SVC, RidgeClassifier, Logistic Regression, Naive Bayes**, the prediction of test dataset based on 3 features yielded a more accurate result, possibly because these models perform worse under conditions of low number of features or under conditions of significant data dependence (in fact, feature \"*WomanOrBoySurvived*\" is, in part derived from others features \"*Sex*\" and \"*Alone*\") or with a small number of points (millions of points may vary greatly). Particularly interesting is that the **LGBM Classifier** model and method gave comparatively low accuracy on both the training and test datasets for the variant with three features, unlike **XGB Classifier** and other decision tree-based methods in which LB > LB_all.\n\n- To increase the accuracy of predictions, its need to increase the number of features and further improve their processing, that is FE (for example, add the processed feature \"**Tickets**\" - context is consist of a good kernels with have examples of such processing ([\"Advanced Feature Engineering Tutorial with Titanic\"](https://www.kaggle.com/gunesevitan/advanced-feature-engineering-tutorial-with-titanic) etc.). \n I hope you find this kernel useful and enjoyable. \n Your comments and feedback are most welcome. \n [Go to Top](#0)",
    "code_source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n\n# models\nfrom sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier \nfrom sklearn.ensemble import BaggingClassifier, VotingClassifier \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\n# NN models\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras import optimizers\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# model tuning\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe, space_eval\n\n# import warnings filter\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning) \n cv_number = 5 \n traindf = pd.read_csv('../input/titanic/train.csv').set_index('PassengerId')\ntestdf = pd.read_csv('../input/titanic/test.csv').set_index('PassengerId')\nsubmission = pd.read_csv('../input/titanic/gender_submission.csv') \n #Thanks to:\n# https://www.kaggle.com/mauricef/titanic\n# https://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code\n#\ndf = pd.concat([traindf, testdf], axis=0, sort=False)\ndf['Title'] = df.Name.str.split(',').str[1].str.split('.').str[0].str.strip()\ndf['Title'] = df.Name.str.split(',').str[1].str.split('.').str[0].str.strip()\ndf['IsWomanOrBoy'] = ((df.Title == 'Master') | (df.Sex == 'female'))\ndf['LastName'] = df.Name.str.split(',').str[0]\nfamily = df.groupby(df.LastName).Survived\ndf['WomanOrBoyCount'] = family.transform(lambda s: s[df.IsWomanOrBoy].fillna(0).count())\ndf['WomanOrBoyCount'] = df.mask(df.IsWomanOrBoy, df.WomanOrBoyCount - 1, axis=0)\ndf['FamilySurvivedCount'] = family.transform(lambda s: s[df.IsWomanOrBoy].fillna(0).sum())\ndf['FamilySurvivedCount'] = df.mask(df.IsWomanOrBoy, df.FamilySurvivedCount - \\\n                                    df.Survived.fillna(0), axis=0)\ndf['WomanOrBoySurvived'] = df.FamilySurvivedCount / df.WomanOrBoyCount.replace(0, np.nan)\ndf.WomanOrBoyCount = df.WomanOrBoyCount.replace(np.nan, 0)\ndf['Alone'] = (df.WomanOrBoyCount == 0)\n\n#Thanks to https://www.kaggle.com/kpacocha/top-6-titanic-machine-learning-from-disaster\n#\"Title\" improvement\ndf['Title'] = df['Title'].replace('Ms','Miss')\ndf['Title'] = df['Title'].replace('Mlle','Miss')\ndf['Title'] = df['Title'].replace('Mme','Mrs')\n# Embarked\ndf['Embarked'] = df['Embarked'].fillna('S')\n# Cabin, Deck\ndf['Deck'] = df['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\ndf.loc[(df['Deck'] == 'T'), 'Deck'] = 'A'\n\n# Thanks to https://www.kaggle.com/erinsweet/simpledetect\n# Fare\nmed_fare = df.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]\ndf['Fare'] = df['Fare'].fillna(med_fare)\n#Age\ndf['Age'] = df.groupby(['Sex', 'Pclass', 'Title'])['Age'].apply(lambda x: x.fillna(x.median()))\n# Family_Size\ndf['Family_Size'] = df['SibSp'] + df['Parch'] + 1\n\n# Thanks to https://www.kaggle.com/vbmokin/titanic-top-3-cluster-analysis\ncols_to_drop = ['Name','Ticket','Cabin']\ndf = df.drop(cols_to_drop, axis=1)\n\ndf.WomanOrBoySurvived = df.WomanOrBoySurvived.fillna(0)\ndf.WomanOrBoyCount = df.WomanOrBoyCount.fillna(0)\ndf.FamilySurvivedCount = df.FamilySurvivedCount.fillna(0)\ndf.Alone = df.Alone.fillna(0) \n target = df.Survived.loc[traindf.index]\ndf = df.drop(['Survived'], axis=1)\ntrain, test = df.loc[traindf.index], df.loc[testdf.index] \n train.head(3) \n test.head(3) \n target[:3] \n # Determination categorical features\nnumerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ncategorical_columns = []\nfeatures = train.columns.values.tolist()\nfor col in features:\n    if train[col].dtype in numerics: continue\n    categorical_columns.append(col)\ncategorical_columns \n # Encoding categorical features\nfor col in categorical_columns:\n    if col in train.columns:\n        le = LabelEncoder()\n        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n        train[col] = le.transform(list(train[col].astype(str).values))\n        test[col] = le.transform(list(test[col].astype(str).values))    \n train.info() \n test.info() \n #%% split training set to validation set\nSEED = 100\nXtrain, Xval, Ztrain, Zval = train_test_split(train, target, test_size=0.3, random_state=SEED) \n # Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(train, target)\nY_pred = logreg.predict(test).astype(int)\nacc_log = round(logreg.score(train, target) * 100, 2)\nacc_log \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_logreg.csv', index=False)\nLB_log_all = 0.79904  # old version \n coeff_df = pd.DataFrame(train.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False) \n # Support Vector Machines\n\nsvc = SVC()\nsvc.fit(train, target)\nY_pred = svc.predict(test).astype(int)\nacc_svc = round(svc.score(train, target) * 100, 2)\nacc_svc \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_svm.csv', index=False)\nLB_svc_all = 0.62200  # old version \n # Linear SVC\n\nlinear_svc = LinearSVC(dual=False)  # dual=False when n_samples > n_features.\nlinear_svc.fit(train, target)\nY_pred = linear_svc.predict(test).astype(int)\nacc_linear_svc = round(linear_svc.score(train, target) * 100, 2)\nacc_linear_svc \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_linear_svc.csv', index=False)\nLB_linear_svc_all = 0.81339  # old version \n # k-Nearest Neighbors algorithm\n\nknn = GridSearchCV(estimator=KNeighborsClassifier(), param_grid={'n_neighbors': [2, 3, 4]}, cv=cv_number).fit(train, target)\nY_pred = knn.predict(test).astype(int)\nacc_knn = round(knn.score(train, target) * 100, 2)\nprint(acc_knn, knn.best_params_) \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_knn.csv', index=False)\nLB_knn_all = 0.62679  # old version \n # Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(train, target)\nY_pred = gaussian.predict(test).astype(int)\nacc_gaussian = round(gaussian.score(train, target) * 100, 2)\nacc_gaussian \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_GaussianNB.csv', index=False)\nLB_gaussian_all = 0.73205  # old version \n # Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(train, target)\nY_pred = perceptron.predict(test).astype(int)\nacc_perceptron = round(perceptron.score(train, target) * 100, 2)\nacc_perceptron \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_perceptron.csv', index=False)\nLB_perceptron_all = 0.46889  # old version \n # Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(train, target)\nY_pred = sgd.predict(test).astype(int)\nacc_sgd = round(sgd.score(train, target) * 100, 2)\nacc_sgd \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_sgd.csv', index=False)\nLB_sgd_all = 0.64593  # old version \n # Decision Tree Classifier\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(train, target)\nY_pred = decision_tree.predict(test).astype(int)\nacc_decision_tree = round(decision_tree.score(train, target) * 100, 2)\nacc_decision_tree \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_decision_tree.csv', index=False)\nLB_decision_tree_all = 0.77990  # old version \n # Random Forest\n\nrandom_forest = GridSearchCV(estimator=RandomForestClassifier(), param_grid={'n_estimators': [200, 300, 400, 500]}, cv=cv_number).fit(train, target)\nrandom_forest.fit(train, target)\nY_pred = random_forest.predict(test).astype(int)\nrandom_forest.score(train, target)\nacc_random_forest = round(random_forest.score(train, target) * 100, 2)\nprint(acc_random_forest,random_forest.best_params_) \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_random_forest.csv', index=False)\nLB_random_forest_all = 0.81339  # old version \n %%time\ndef hyperopt_xgb_score(params):\n    clf = XGBClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_xgb = {\n            'learning_rate': hp.quniform('learning_rate', 0, 0.05, 0.0001),\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_depth':  hp.choice('max_depth', np.arange(5, 8, dtype=int)),\n            'min_child_weight': hp.quniform('min_child_weight', 1, 9, 0.025),\n            'subsample': hp.quniform('subsample', 0.5, 1, 0.005),\n            'gamma': hp.quniform('gamma', 0.5, 1, 0.005),\n            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.005),\n            'eval_metric': 'auc',\n            'objective': 'binary:logistic',\n            'booster': 'gbtree',\n            'tree_method': 'exact',\n            'silent': 1,\n            'missing': None\n        }\n \nbest = fmin(fn=hyperopt_xgb_score, space=space_xgb, algo=tpe.suggest, max_evals=10)\nprint('best:')\nprint(best) \n params = space_eval(space_xgb, best)\nparams \n XGB_Classifier = XGBClassifier(**params)\nXGB_Classifier.fit(train, target)\nY_pred = XGB_Classifier.predict(test).astype(int)\nXGB_Classifier.score(train, target)\nacc_XGB_Classifier = round(XGB_Classifier.score(train, target) * 100, 2)\nacc_XGB_Classifier \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_XGB_Classifier.csv', index=False)\nLB_XGB_Classifier_all = 0.80861  # old version \n fig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nxgb.plot_importance(XGB_Classifier,ax = axes,height =0.5)\nplt.show();\nplt.close() \n %%time\ndef hyperopt_lgb_score(params):\n    clf = LGBMClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_lgb = {\n            'learning_rate': hp.quniform('learning_rate', 0, 0.05, 0.0001),\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_depth':  hp.choice('max_depth', np.arange(4, 7, dtype=int)),\n            'num_leaves': hp.choice('num_leaves', 2*np.arange(20, 2**6, dtype=int)),\n            'min_child_weight': hp.quniform('min_child_weight', 1, 9, 0.025),\n            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.005),\n            'objective': 'binary',\n            'boosting_type': 'gbdt',\n            }\n \nbest = fmin(fn=hyperopt_lgb_score, space=space_lgb, algo=tpe.suggest, max_evals=10)\nprint('best:')\nprint(best) \n params = space_eval(space_lgb, best)\nparams \n LGB_Classifier = LGBMClassifier(**params)\nLGB_Classifier.fit(train, target)\nY_pred = LGB_Classifier.predict(test).astype(int)\nLGB_Classifier.score(train, target)\nacc_LGB_Classifier = round(LGB_Classifier.score(train, target) * 100, 2)\nacc_LGB_Classifier \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_LGB_Classifier.csv', index=False)\nLB_LGB_Classifier_all = 0.82296  # old version \n fig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nlgb.plot_importance(LGB_Classifier,ax = axes,height = 0.5)\nplt.show();\nplt.close() \n %%time\ndef hyperopt_gb_score(params):\n    clf = GradientBoostingClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_gb = {\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_depth': hp.choice('max_depth', np.arange(5, 8, dtype=int))            \n        }\n \nbest = fmin(fn=hyperopt_gb_score, space=space_gb, algo=tpe.suggest, max_evals=10)\nprint('best:')\nprint(best) \n params = space_eval(space_gb, best)\nparams \n # Gradient Boosting Classifier\n\ngradient_boosting = GradientBoostingClassifier(**params)\ngradient_boosting.fit(train, target)\nY_pred = gradient_boosting.predict(test).astype(int)\ngradient_boosting.score(train, target)\nacc_gradient_boosting = round(gradient_boosting.score(train, target) * 100, 2)\nacc_gradient_boosting \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_gradient_boosting.csv', index=False)\nLB_GBC_all = 0.82296  # old version \n # Ridge Classifier\n\nridge_classifier = RidgeClassifier()\nridge_classifier.fit(train, target)\nY_pred = ridge_classifier.predict(test).astype(int)\nridge_classifier.score(train, target)\nacc_ridge_classifier = round(ridge_classifier.score(train, target) * 100, 2)\nacc_ridge_classifier \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_ridge_classifier.csv', index=False)\nLB_RidgeClassifier_all = 0.80861  # old version \n # Bagging Classifier\n\nbagging_classifier = BaggingClassifier()\nbagging_classifier.fit(train, target)\nY_pred = bagging_classifier.predict(test).astype(int)\nbagging_classifier.score(train, target)\nacc_bagging_classifier = round(bagging_classifier.score(train, target) * 100, 2)\nacc_bagging_classifier \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_bagging_classifier.csv', index=False)\nLB_bagging_classifier_all = 0.80861  # old version \n def hyperopt_etc_score(params):\n    clf = ExtraTreesClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_etc = {\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_features': hp.choice('max_features', np.arange(2, 10, dtype=int)),\n            'min_samples_leaf': hp.choice('min_samples_leaf', np.arange(1, 5, dtype=int)),\n            'max_depth':  hp.choice('max_depth', np.arange(4, 8, dtype=int)),\n        }\n \nbest = fmin(fn=hyperopt_etc_score, space=space_etc, algo=tpe.suggest, max_evals=10)\nprint('best:')\nprint(best) \n params = space_eval(space_etc, best)\nparams \n # Extra Trees Classifier\n\nextra_trees_classifier = ExtraTreesClassifier(**params)\nextra_trees_classifier.fit(train, target)\nY_pred = extra_trees_classifier.predict(test).astype(int)\nextra_trees_classifier.score(train, target)\nacc_etc = round(extra_trees_classifier.score(train, target) * 100, 2)\nacc_etc \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_etc.csv', index=False)\nLB_ETC_all = 0.80861  # old version \n def build_ann(optimizer='adam'):\n    \n    # Initializing the ANN\n    ann = Sequential()\n    \n    # Adding the input layer and the first hidden layer of the ANN with dropout\n    ann.add(Dense(units=32, kernel_initializer='glorot_uniform', activation='relu', input_shape=(16,)))\n    \n    # Add other layers, it is not necessary to pass the shape because there is a layer before\n    ann.add(Dense(units=64, kernel_initializer='glorot_uniform', activation='relu'))\n    ann.add(Dropout(rate=0.5))\n    ann.add(Dense(units=64, kernel_initializer='glorot_uniform', activation='relu'))\n    ann.add(Dropout(rate=0.5))\n    \n    # Adding the output layer\n    ann.add(Dense(units=1, kernel_initializer='glorot_uniform', activation='sigmoid'))\n    \n    # Compiling the ANN\n    ann.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return ann \n opt = optimizers.Adam(lr=0.001)\nann = build_ann(opt)\n# Training the ANN\nhistory = ann.fit(Xtrain, Ztrain, batch_size=16, epochs=100, validation_data=(Xval, Zval)) \n # Predicting the Test set results\nY_pred = ann.predict(test)\nY_pred = (Y_pred > 0.5)*1 # convert probabilities to binary output \n # Predicting the Train set results\nann_prediction = ann.predict(train)\nann_prediction = (ann_prediction > 0.5)*1 # convert probabilities to binary output\n\n# Compute error between predicted data and true response and display it in confusion matrix\nacc_ann1 = round(metrics.accuracy_score(target, ann_prediction) * 100, 2)\nacc_ann1 \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": np.reshape(Y_pred, len(Y_pred))})\n#submission.to_csv('output/submission_ann1.csv', index=False)\nLB_ann1_all = 0.59330  # old version \n # Model\nmodel = Sequential()\nmodel.add(Dense(16, input_dim = train.shape[1], init = 'he_normal', activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64, init = 'he_normal', activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(32, init = 'he_normal', activation = 'relu'))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.summary() \n model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n es = EarlyStopping(monitor='val_accuracy', patience=20, mode='max')\nhist = model.fit(train, target, batch_size=64, validation_data=(Xval, Zval), \n               epochs=500, verbose=1, callbacks=[es]) \n plt.plot(hist.history['accuracy'], label='acc')\nplt.plot(hist.history['val_accuracy'], label='val_acc')\n# plt.plot(hist.history['acc'], label='acc')\n# plt.plot(hist.history['val_acc'], label='val_acc')\nplt.ylim((0, 1))\nplt.legend() \n # Predicting the Test set results\nY_pred = model.predict(test)\nY_pred = (Y_pred > 0.5)*1 # convert probabilities to binary output \n # Predicting the Train set results\nnn_prediction = model.predict(train)\nnn_prediction = (nn_prediction > 0.5)*1 # convert probabilities to binary output\n\n# Compute error between predicted data and true response\nacc_ann2 = round(metrics.accuracy_score(target, nn_prediction) * 100, 2)\nacc_ann2 \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": np.reshape(Y_pred, len(Y_pred))})\n#submission.to_csv('output/submission_ann2.csv', index=False)\nLB_ann2_all = 0.64114  # old version \n Voting_Classifier_hard = VotingClassifier(estimators=[('lr', logreg), ('rf', random_forest), ('gbc', gradient_boosting)], voting='hard')\nfor clf, label in zip([logreg, random_forest, gradient_boosting, Voting_Classifier_hard], \n                      ['Logistic Regression', 'Random Forest', 'Gradient Boosting Classifier', 'Ensemble']):\n    scores = cross_val_score(clf, train, target, cv=cv_number, scoring='accuracy')\n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label)) \n Voting_Classifier_hard.fit(train, target)\nY_pred = Voting_Classifier_hard.predict(test).astype(int)\nVoting_Classifier_hard.score(train, target)\nacc_VC_hard = round(Voting_Classifier_hard.score(train, target) * 100, 2)\nacc_VC_hard \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_VC_hard.csv', index=False)\nLB_VC_hard_all = 0.81339  # old version \n eclf = VotingClassifier(estimators=[('lr', logreg), ('rf', random_forest), ('gbc', gradient_boosting)], voting='soft')\nparams = {'lr__C': [1.0, 100.0], 'gbc__learning_rate': [0.05, 1]}\nVoting_Classifier_soft = GridSearchCV(estimator=eclf, param_grid=params, cv=cv_number)\nVoting_Classifier_soft.fit(train, target)\nY_pred = Voting_Classifier_soft.predict(test).astype(int)\nVoting_Classifier_soft.score(train, target)\nacc_VC_soft = round(Voting_Classifier_soft.score(train, target) * 100, 2)\nacc_VC_soft \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_VC_soft.csv', index=False)\nLB_VC_soft_all = 0.81339  # old version \n Y_pred = (((test.WomanOrBoySurvived <= 0.238) & (test.Sex > 0.5) & (test.Alone > 0.5)) | \\\n          ((test.WomanOrBoySurvived > 0.238) & \\\n           ~((test.WomanOrBoySurvived > 0.55) & (test.WomanOrBoySurvived <= 0.633)))) \n simple_rule_model = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n                       max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort=False,\n                       random_state=1118, splitter='best') \nsimple_rule_model.fit(train, target)\nY_pred = simple_rule_model.predict(test).astype(int)\nsimple_rule_model.score(train, target)\nacc_simple_rule = round(simple_rule_model.score(train, target) * 100, 2)\nacc_simple_rule \n submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_simple_rule.csv', index=False)\nLB_simple_rule_all = 0.83253  # old version \n # Preparing datasets for only 3 features ('WomanOrBoySurvived', 'Sex', 'Alone')\ncols_to_drop3 = ['SibSp', 'Parch', 'Fare', 'LastName', 'Deck',\n               'Pclass', 'Age', 'Embarked', 'Title', 'IsWomanOrBoy',\n               'WomanOrBoyCount', 'FamilySurvivedCount', 'Family_Size']\ntrain = train.drop(cols_to_drop3, axis=1)\ntest = test.drop(cols_to_drop3, axis=1)\nXtrain, Xval, Ztrain, Zval = train_test_split(train, target, test_size=0.3, random_state=SEED)\ntrain.info() \n # 1. Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(train, target)\nY_pred = logreg.predict(test).astype(int)\nacc3_log = round(logreg.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_logreg3.csv', index=False)\nLB_log = 0.77033 \n # 2. Support Vector Machines\n\nsvc = SVC()\nsvc.fit(train, target)\nY_pred = svc.predict(test).astype(int)\nacc3_svc = round(svc.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_svm3.csv', index=False)\nLB_svc = 0.79904 \n # 3. Linear SVC\n\nlinear_svc = LinearSVC(dual=False)\nlinear_svc.fit(train, target)\nY_pred = linear_svc.predict(test).astype(int)\nacc3_linear_svc = round(linear_svc.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_linear_svc3.csv', index=False)\nLB_linear_svc = 0.77033 \n # 4. k-Nearest Neighbors algorithm\n\nknn = GridSearchCV(estimator=KNeighborsClassifier(), param_grid={'n_neighbors': [2, 3, 4]}, cv=cv_number).fit(train, target)\nY_pred = knn.predict(test).astype(int)\nacc3_knn = round(knn.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_knn3.csv', index=False)\nLB_knn = 0.77751 \n # 5. Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(train, target)\nY_pred = gaussian.predict(test).astype(int)\nacc3_gaussian = round(gaussian.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_GaussianNB3.csv', index=False)\nLB_gaussian = 0.68899 \n # 6. Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(train, target)\nY_pred = perceptron.predict(test).astype(int)\nacc3_perceptron = round(perceptron.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_perceptron3.csv', index=False)\nLB_perceptron = 0.77511 \n # 7. Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(train, target)\nY_pred = sgd.predict(test).astype(int)\nacc3_sgd = round(sgd.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_sgd3.csv', index=False)\nLB_sgd = 0.77511 \n # 8. Decision Tree Classifier\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(train, target)\nY_pred = decision_tree.predict(test).astype(int)\nacc3_decision_tree = round(decision_tree.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_decision_tree3.csv', index=False)\nLB_decision_tree = 0.80382 \n # 9. Random Forest\n\nrandom_forest = GridSearchCV(estimator=RandomForestClassifier(), param_grid={'n_estimators': [200, 300, 400, 500]}, cv=cv_number).fit(train, target)\nrandom_forest.fit(train, target)\nY_pred = random_forest.predict(test).astype(int)\nrandom_forest.score(train, target)\nacc3_random_forest = round(random_forest.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_random_forest3.csv', index=False)\nLB_random_forest = 0.80382 \n # 10. XGB_Classifier\n\ndef hyperopt_xgb_score(params):\n    clf = XGBClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_xgb = {\n            'learning_rate': hp.quniform('learning_rate', 0, 0.05, 0.0001),\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'eta': hp.quniform('eta', 0.025, 0.5, 0.005),\n            'max_depth':  hp.choice('max_depth', np.arange(4, 8, dtype=int)),\n            'min_child_weight': hp.quniform('min_child_weight', 1, 9, 0.025),\n            'subsample': hp.quniform('subsample', 0.5, 1, 0.005),\n            'gamma': hp.quniform('gamma', 0.5, 1, 0.005),\n            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.005),\n            'eval_metric': 'auc',\n            'objective': 'binary:logistic',\n            'booster': 'gbtree',\n            'tree_method': 'exact',\n            'silent': 1,\n            'missing': None\n        }\n \nbest = fmin(fn=hyperopt_xgb_score, space=space_xgb, algo=tpe.suggest, max_evals=10)\nparams = space_eval(space_xgb, best)\nXGB_Classifier = XGBClassifier(**params)\nXGB_Classifier.fit(train, target)\nY_pred = XGB_Classifier.predict(test).astype(int)\nXGB_Classifier.score(train, target)\nacc3_XGB_Classifier = round(XGB_Classifier.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_XGB_Classifier3.csv', index=False)\nLB_XGB_Classifier = 0.68899\nprint(params) \n # 11. LGBM_Classifier\n\ndef hyperopt_lgb_score(params):\n    clf = LGBMClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_lgb = {\n            'learning_rate': hp.quniform('learning_rate', 0, 0.05, 0.0001),\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_depth':  hp.choice('max_depth', np.arange(4, 7, dtype=int)),\n            'num_leaves': hp.choice('num_leaves', 2*np.arange(20, 2**6, dtype=int)),\n            'min_child_weight': hp.quniform('min_child_weight', 1, 9, 0.025),\n            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.005),\n            'objective': 'binary',\n            'boosting_type': 'gbdt',\n            }\n \nbest = fmin(fn=hyperopt_lgb_score, space=space_lgb, algo=tpe.suggest, max_evals=10)\nparams = space_eval(space_lgb, best)\nLGB_Classifier = LGBMClassifier(**params)\nLGB_Classifier.fit(train, target)\nY_pred = LGB_Classifier.predict(test).astype(int)\nLGB_Classifier.score(train, target)\nacc3_LGB_Classifier = round(LGB_Classifier.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_LGB_Classifier3.csv', index=False)\nLB_LGB_Classifier = 0.62200\nprint(params) \n # 12. GradientBoostingClassifier\n\ndef hyperopt_gb_score(params):\n    clf = GradientBoostingClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_gb = {\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_depth': hp.choice('max_depth', np.arange(4, 8, dtype=int)),\n            'max_features': None\n        }\n \nbest = fmin(fn=hyperopt_gb_score, space=space_gb, algo=tpe.suggest, max_evals=5)\nparams = space_eval(space_gb, best)\ngradient_boosting = GradientBoostingClassifier(**params)\ngradient_boosting.fit(train, target)\nY_pred = gradient_boosting.predict(test).astype(int)\ngradient_boosting.score(train, target)\nacc3_gradient_boosting = round(gradient_boosting.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_gradient_boosting3.csv', index=False)\nLB_GBC = 0.80382\nprint(params) \n # 13. Ridge Classifier\n\nridge_classifier = RidgeClassifier()\nridge_classifier.fit(train, target)\nY_pred = ridge_classifier.predict(test).astype(int)\nridge_classifier.score(train, target)\nacc3_ridge_classifier = round(ridge_classifier.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_ridge_classifier3.csv', index=False)\nLB_RidgeClassifier = 0.77511 \n # 14. Bagging Classifier\n\nbagging_classifier = BaggingClassifier()\nbagging_classifier.fit(train, target)\nY_pred = bagging_classifier.predict(test).astype(int)\nbagging_classifier.score(train, target)\nacc3_bagging_classifier = round(bagging_classifier.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_bagging_classifier3.csv', index=False)\nLB_bagging_classifier = 0.80382 \n # 15. Extra Trees Classifier\n\ndef hyperopt_etc_score(params):\n    clf = ExtraTreesClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_etc = {\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_features': hp.choice('max_features', np.arange(2, 10, dtype=int)),\n            'min_samples_leaf': hp.choice('min_samples_leaf', np.arange(1, 5, dtype=int)),\n            'max_depth':  hp.choice('max_depth', np.arange(2, 8, dtype=int)),\n            'max_features': None\n        }\n \nbest = fmin(fn=hyperopt_etc_score, space=space_etc, algo=tpe.suggest, max_evals=5)\nparams = space_eval(space_etc, best)\nextra_trees_classifier = ExtraTreesClassifier(**params)\nextra_trees_classifier.fit(train, target)\nY_pred = extra_trees_classifier.predict(test).astype(int)\nextra_trees_classifier.score(train, target)\nacc3_etc = round(extra_trees_classifier.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_etc3.csv', index=False)\nLB_ETC = 0.79904\nprint(params) \n # 16. Neural Network 1 \n\ndef build_ann(optimizer='adam'):\n    \n    # Initializing the ANN\n    ann = Sequential()\n    \n    # Adding the input layer and the first hidden layer of the ANN with dropout\n    ann.add(Dense(units=32, kernel_initializer='glorot_uniform', activation='relu', input_shape=(3,)))\n    \n    # Add other layers, it is not necessary to pass the shape because there is a layer before\n    ann.add(Dense(units=64, kernel_initializer='glorot_uniform', activation='relu'))\n    ann.add(Dropout(rate=0.5))\n    ann.add(Dense(units=64, kernel_initializer='glorot_uniform', activation='relu'))\n    ann.add(Dropout(rate=0.5))\n    \n    # Adding the output layer\n    ann.add(Dense(units=1, kernel_initializer='glorot_uniform', activation='sigmoid'))\n    \n    # Compiling the ANN\n    ann.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return ann\nopt = optimizers.Adam(lr=0.001)\nann = build_ann(opt)\nhistory = ann.fit(Xtrain, Ztrain, batch_size=16, epochs=100, validation_data=(Xval, Zval))\nY_pred = ann.predict(test)\nY_pred = (Y_pred > 0.5)*1 # convert probabilities to binary output\nann_prediction = ann.predict(train)\nann_prediction = (ann_prediction > 0.5)*1 # convert probabilities to binary output\nacc3_ann1 = round(metrics.accuracy_score(target, ann_prediction) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": np.reshape(Y_pred, len(Y_pred))})\nsubmission.to_csv('submission_ann1_3.csv', index=False)\nLB_ann1 = 0.79904 \n # 17. Neural Network 2\n\n# Model\nmodel = Sequential()\nmodel.add(Dense(16, input_dim = train.shape[1], init = 'he_normal', activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64, init = 'he_normal', activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(32, init = 'he_normal', activation = 'relu'))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nes = EarlyStopping(monitor='val_accuracy', patience=20, mode='max')\nhist = model.fit(train, target, batch_size=64, validation_data=(Xval, Zval), \n               epochs=500, verbose=1, callbacks=[es])\nY_pred = model.predict(test)\nY_pred = (Y_pred > 0.5)*1 # convert probabilities to binary output\nnn_prediction = model.predict(train)\nnn_prediction = (nn_prediction > 0.5)*1 # convert probabilities to binary output\nacc3_ann2 = round(metrics.accuracy_score(target, nn_prediction) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": np.reshape(Y_pred, len(Y_pred))})\nsubmission.to_csv('submission_ann2_3.csv', index=False)\nLB_ann2 = 0.79665 \n # 5.18 VotingClassifier (hard voting)\n\nVoting_Classifier_hard = VotingClassifier(estimators=[('lr', logreg), ('rf', random_forest), ('gbc', gradient_boosting)], voting='hard')\nfor clf, label in zip([logreg, random_forest, gradient_boosting, Voting_Classifier_hard], \n                      ['Logistic Regression', 'Random Forest', 'Gradient Boosting Classifier', 'Ensemble']):\n    scores = cross_val_score(clf, train, target, cv=cv_number, scoring='accuracy')\n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\nVoting_Classifier_hard.fit(train, target)\nY_pred = Voting_Classifier_hard.predict(test).astype(int)\nVoting_Classifier_hard.score(train, target)\nacc3_VC_hard = round(Voting_Classifier_hard.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_VC_hard3.csv', index=False)\nLB_VC_hard = 0.80382 \n # 5.19 VotingClassifier (soft voting)\n\neclf = VotingClassifier(estimators=[('lr', logreg), ('rf', random_forest), ('gbc', gradient_boosting)], voting='soft')\nparams = {'lr__C': [1.0, 100.0], 'gbc__learning_rate': [0.05, 1]}\nVoting_Classifier_soft = GridSearchCV(estimator=eclf, param_grid=params, cv=cv_number)\nVoting_Classifier_soft.fit(train, target)\nY_pred = Voting_Classifier_soft.predict(test).astype(int)\nVoting_Classifier_soft.score(train, target)\nacc3_VC_soft = round(Voting_Classifier_soft.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_VC_soft3.csv', index=False)\nLB_VC_soft = 0.80382 \n # 5.20 The simple rule in one line\nY_pred = (((test.WomanOrBoySurvived <= 0.238) & (test.Sex > 0.5) & (test.Alone > 0.5)) | \\\n          ((test.WomanOrBoySurvived > 0.238) & \\\n           ~((test.WomanOrBoySurvived > 0.55) & (test.WomanOrBoySurvived <= 0.633))))\nacc3_simple_rule = acc_simple_rule\nLB_simple_rule = 0.80382 \n models = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Support Vector Machines', 'Linear SVC', 'k-Nearest Neighbors', 'Naive Bayes', \n              'Perceptron', 'Stochastic Gradient Decent', \n              'Decision Tree Classifier', 'Random Forest',  'XGBClassifier', 'LGBMClassifier',\n              'GradientBoostingClassifier', 'RidgeClassifier', 'BaggingClassifier', 'ExtraTreesClassifier', \n              'Neural Network 1', 'Neural Network 2', \n              'VotingClassifier-hard voiting', 'VotingClassifier-soft voting',\n              'Simple rule'],\n    \n    'Score16': [acc_log, acc_svc, acc_linear_svc, acc_knn, acc_gaussian, \n              acc_perceptron, acc_sgd, \n              acc_decision_tree, acc_random_forest, acc_XGB_Classifier, acc_LGB_Classifier,\n              acc_gradient_boosting, acc_ridge_classifier, acc_bagging_classifier, acc_etc, \n              acc_ann1, acc_ann2, \n              acc_VC_hard, acc_VC_soft,\n              acc_simple_rule],\n\n    'Score3': [acc3_log, acc3_svc, acc3_linear_svc, acc3_knn, acc3_gaussian, \n              acc3_perceptron, acc3_sgd, \n              acc3_decision_tree, acc3_random_forest, acc3_XGB_Classifier, acc3_LGB_Classifier,\n              acc3_gradient_boosting, acc3_ridge_classifier, acc3_bagging_classifier, acc3_etc, \n              acc3_ann1, acc3_ann2, \n              acc3_VC_hard, acc3_VC_soft,\n              acc3_simple_rule],\n\n    'LB_all': [LB_log_all, LB_svc_all, LB_linear_svc_all, LB_knn_all, LB_gaussian_all, \n              LB_perceptron_all, LB_sgd_all, \n              LB_decision_tree_all, LB_random_forest_all, LB_XGB_Classifier_all, LB_LGB_Classifier_all,\n              LB_GBC_all, LB_RidgeClassifier_all, LB_bagging_classifier_all, LB_ETC_all, \n              LB_ann1_all, LB_ann2_all, \n              LB_VC_hard_all, LB_VC_soft_all,\n              LB_simple_rule_all],\n    \n    'LB':    [LB_log, LB_svc, LB_linear_svc, LB_knn, LB_gaussian, \n              LB_perceptron, LB_sgd, \n              LB_decision_tree, LB_random_forest, LB_XGB_Classifier, LB_LGB_Classifier,\n              LB_GBC, LB_RidgeClassifier, LB_bagging_classifier, LB_ETC, \n              LB_ann1, LB_ann2, \n              LB_VC_hard, LB_VC_soft,\n              LB_simple_rule]}) \n models.sort_values(by=['Score16', 'LB_all', 'LB'], ascending=False) \n models.sort_values(by=['Score3', 'LB_all', 'LB'], ascending=False) \n models.sort_values(by=['LB_all', 'LB', 'Score3'], ascending=False) \n models.sort_values(by=['LB', 'LB_all', 'Score3'], ascending=False)",
    "markdown_source": "<a class=\"anchor\" id=\"0\"></a>\n\n## FE, tuning and comparison of the 20 popular models with  predictions on the example of competition \"Titanic: Machine Learning from Disaster\" \n Features engineering (FE) from Titanic Top 3%\n\nBuild of the 20 most popular models, the most complex models from them are tuned (optimized)\n\nComparison of the optimal for each type models by CV and LB \n ## Acknowledgements \n Thanks for most popular models to:\n* https://www.kaggle.com/kabure/titanic-eda-model-pipeline-keras-nn\n* https://www.kaggle.com/startupsci/titanic-data-science-solutions \n* https://www.kaggle.com/nhlr21/complete-titanic-tutorial-with-ml-nn-ensembling\n\nThanks for FE:\n* https://www.kaggle.com/vbmokin/three-lines-of-code-for-titanic-top-15\n* https://www.kaggle.com/vbmokin/three-lines-of-code-for-titanic-top-20\n* https://www.kaggle.com/mauricef/titanic\n* https://www.kaggle.com/kpacocha/top-6-titanic-machine-learning-from-disaster\n* https://www.kaggle.com/erinsweet/simpledetect \n <a class=\"anchor\" id=\"0.1\"></a>\n\n## Table of Contents\n\n1. [Import libraries](#1)\n1. [Download datasets](#2)\n1. [Features engineering (FE)](#3)\n1. [Preparing to modeling](#4)\n    -  [Encoding categorical features](#4.1)\n    -  [Creation of training and validation sets](#4.2)\n1. [Tuning models and test for all 16 features](#5)\n    -  [Logistic Regression](#5.1)\n    -  [Support Vector Machines](#5.2)\n    -  [Linear SVC](#5.3)\n    -  [k-Nearest Neighbors algorithm with GridSearchCV](#5.4)\n    -  [Naive Bayes](#5.5)\n    -  [Perceptron](#5.6)\n    -  [Stochastic Gradient Descent](#5.7)\n    -  [Decision Tree Classifier](#5.8)\n    -  [Random Forests with GridSearchCV](#5.9)\n    -  [XGB Classifier with HyperOpt](#5.10)\n    -  [LGBM Classifier with HyperOpt](#5.11)\n    -  [GradientBoostingClassifier with HyperOpt](#5.12)\n    -  [RidgeClassifier](#5.13)\n    -  [BaggingClassifier](#5.14)\n    -  [ExtraTreesClassifier with HyperOpt](#5.15)\n    -  [Neural Network 1](#5.16)\n    -  [Neural Network 2](#5.17)\n    -  [VotingClassifier (hard voting)](#5.18)\n    -  [VotingClassifier (soft voting) with GridSearchCV](#5.19)\n    -  [The simple rule in one line](#5.20)\n1. [Tuning models and test for 3 features](#6)\n1. [Models evaluation](#7)\n1. [Conclusion](#8)\n \n ## 1. Import libraries <a class=\"anchor\" id=\"1\"></a>\n\n[Back to Table of Contents](#0.1) \n ## 2. Download datasets <a class=\"anchor\" id=\"2\"></a>\n\n[Back to Table of Contents](#0.1) \n ## 3. Features engineering (FE) <a class=\"anchor\" id=\"3\"></a>\n\n[Back to Table of Contents](#0.1) \n All models were tuned for a complete set of 16 features, solutions were calculated, that were uploaded to the competition, which made it possible to determine the error LB_all.\nAfter which the decision was taken into account\n* https://www.kaggle.com/mauricef/titanic\n* https://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code\n\ncalculated on only three features ('WomanOrBoySurvived', 'Alone', 'Sex') - an error LB is defined for this option. \n ## 4. Preparing to modeling <a class=\"anchor\" id=\"4\"></a>\n\n[Back to Table of Contents](#0.1) \n ### 4.1 Encoding categorical features <a class=\"anchor\" id=\"4.1\"></a> \n ### 4.2 Creation of training and validation sets <a class=\"anchor\" id=\"4.2\"></a>\n\n[Back to Table of Contents](#0.1) \n ## 5. Tuning models and test for all 16 features <a class=\"anchor\" id=\"5\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions\n\nNow we are ready to train a model and predict the required solution. There are 60+ predictive modelling algorithms to choose from. We must understand the type of problem and solution requirement to narrow down to a select few models which we can evaluate. Our problem is a classification and regression problem. We want to identify relationship between output (Survived or not) with other variables or features (Gender, Age, Port...). We are also perfoming a category of machine learning which is called supervised learning as we are training our model with a given dataset. With these two criteria - Supervised Learning plus Classification and Regression, we can narrow down our choice of models to a few. These include:\n\n- Logistic Regression\n- Support Vector Machines and Linear SVC\n- KNN or k-Nearest Neighbors\n- Naive Bayes Classifier or Gaussian Naive Bayes\n- Stochastic Gradient Descent, GradientBoostingClassifier, RidgeClassifier, BaggingClassifier\n- Decision Tree Classifier, Random Forest, XGB Classifier, LGBM Classifier, ExtraTreesClassifier\n- Perceptron, Neural Networks with different archictures (Deep Learning)\n- VotingClassifier (hard or soft voting) \n ### 5.1 Logistic Regression <a class=\"anchor\" id=\"5.1\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions \n **Logistic Regression** is a useful model to run early in the workflow. Logistic regression measures the relationship between the categorical dependent variable (feature) and one or more independent variables (features) by estimating probabilities using a logistic function, which is the cumulative logistic distribution. Reference [Wikipedia](https://en.wikipedia.org/wiki/Logistic_regression).\n\nNote the confidence score generated by the model based on our training dataset. \n We can use Logistic Regression to validate our assumptions and decisions for feature creating and completing goals. This can be done by calculating the coefficient of the features in the decision function.\n\nPositive coefficients increase the log-odds of the response (and thus increase the probability), and negative coefficients decrease the log-odds of the response (and thus decrease the probability).\n\n- Alone is highest positivie coefficient, implying as the Alone value increases (0 to 1), the probability of Survived=1 increases the most.\n- Inversely as Sex increases (male: 0 to female: 1), probability of Survived=1 decreases the most.\n- This way Age has second highest negative correlation with Survived.\n- So is LastName as second highest positive correlation. \n ### 5.2 Support Vector Machines <a class=\"anchor\" id=\"5.2\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions \n **Support Vector Machines** are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. Given a set of training samples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new test samples to one category or the other, making it a non-probabilistic binary linear classifier. Reference [Wikipedia](https://en.wikipedia.org/wiki/Support_vector_machine). \n ### 5.3 Linear SVC <a class=\"anchor\" id=\"5.3\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions \n **SVC** is a similar to SVM method. Its also builds on kernel functions but is appropriate for unsupervised learning. Reference [Wikipedia](https://en.wikipedia.org/wiki/Support-vector_machine#Support-vector_clustering_(SVC). \n ### 5.4 k-Nearest Neighbors algorithm <a class=\"anchor\" id=\"5.4\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions \n In pattern recognition, the **k-Nearest Neighbors algorithm** (or k-NN for short) is a non-parametric method used for classification and regression. A sample is classified by a majority vote of its neighbors, with the sample being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). Reference [Wikipedia](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm). \n ### 5.5 Naive Bayes <a class=\"anchor\" id=\"5.5\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions \n In machine learning, **Naive Bayes classifiers** are a family of simple probabilistic classifiers based on applying Bayes' theorem with strong (naive) independence assumptions between the features. Naive Bayes classifiers are highly scalable, requiring a number of parameters linear in the number of variables (features) in a learning problem. Reference [Wikipedia](https://en.wikipedia.org/wiki/Naive_Bayes_classifier). \n ### 5.6 Perceptron <a class=\"anchor\" id=\"5.6\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions \n The **Perceptron** is an algorithm for supervised learning of binary classifiers (functions that can decide whether an input, represented by a vector of numbers, belongs to some specific class or not). It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector. The algorithm allows for online learning, in that it processes elements in the training set one at a time. Reference [Wikipedia](https://en.wikipedia.org/wiki/Perceptron). \n ### 5.7 Stochastic Gradient Descent <a class=\"anchor\" id=\"5.7\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions \n **Stochastic gradient descent** (often abbreviated **SGD**) is an iterative method for optimizing an objective function with suitable smoothness properties (e.g. differentiable or subdifferentiable). It can be regarded as a stochastic approximation of gradient descent optimization, since it replaces the actual gradient (calculated from the entire data set) by an estimate thereof (calculated from a randomly selected subset of the data). Especially in big data applications this reduces the computational burden, achieving faster iterations in trade for a slightly lower convergence rate. Reference [Wikipedia](https://en.wikipedia.org/wiki/Stochastic_gradient_descent). \n ### 5.8 Decision Tree Classifier <a class=\"anchor\" id=\"5.8\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions \n This model uses a **Decision Tree** as a predictive model which maps features (tree branches) to conclusions about the target value (tree leaves). Tree models where the target variable can take a finite set of values are called classification trees; in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. Reference [Wikipedia](https://en.wikipedia.org/wiki/Decision_tree_learning). \n ### 5.9 Random Forests <a class=\"anchor\" id=\"5.9\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions \n **Random Forests** is one of the most popular model. Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees (n_estimators= [100, 300]) at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Reference [Wikipedia](https://en.wikipedia.org/wiki/Random_forest). \n ### 5.10 XGB Classifier <a class=\"anchor\" id=\"5.10\"></a>\n\n[Back to Table of Contents](#0.1) \n XGBoost is an ensemble tree method that apply the principle of boosting weak learners (CARTs generally) using the gradient descent architecture. XGBoost improves upon the base Gradient Boosting Machines (GBM) framework through systems optimization and algorithmic enhancements. Reference [Towards Data Science.](https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d) \n We will tuning the hyperparameters of the XGBClassifier model using the HyperOpt and 10-fold crossvalidation \n ### 5.11 LGBM Classifier <a class=\"anchor\" id=\"5.11\"></a>\n\n[Back to Table of Contents](#0.1) \n Light GBM is a fast, distributed, high-performance gradient boosting framework based on decision tree algorithms. It splits the tree leaf wise with the best fit whereas other boosting algorithms split the tree depth wise or level wise rather than leaf-wise. So when growing on the same leaf in Light GBM, the leaf-wise algorithm can reduce more loss than the level-wise algorithm and hence results in much better accuracy which can rarely be achieved by any of the existing boosting algorithms. Also, it is surprisingly very fast, hence the word \u2018Light\u2019. Reference [Analytics Vidhya](https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/). \n We will tuning the hyperparameters of the LGBMClassifier model using the HyperOpt and 10-fold crossvalidation \n ### 5.12 GradientBoostingClassifier <a class=\"anchor\" id=\"5.12\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/kabure/titanic-eda-model-pipeline-keras-nn \n **Gradient Boosting** builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage n_classes_ regression trees are fit on the negative gradient of the binomial or multinomial deviance loss function. Binary classification is a special case where only a single regression tree is induced. The features are always randomly permuted at each split. Therefore, the best found split may vary, even with the same training data and max_features=n_features, if the improvement of the criterion is identical for several splits enumerated during the search of the best split. To obtain a deterministic behaviour during fitting, random_state has to be fixed. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html). \n ### 5.13 RidgeClassifier <a class=\"anchor\" id=\"5.13\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/kabure/titanic-eda-model-pipeline-keras-nn \n Tikhonov Regularization, colloquially known as **Ridge Regression**, is the most commonly used regression algorithm to approximate an answer for an equation with no unique solution. This type of problem is very common in machine learning tasks, where the \"best\" solution must be chosen using limited data. If a unique solution exists, algorithm will return the optimal value. However, if multiple solutions exist, it may choose any of them. Reference [Brilliant.org](https://brilliant.org/wiki/ridge-regression/). \n ### 5.14 BaggingClassifier <a class=\"anchor\" id=\"5.14\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/kabure/titanic-eda-model-pipeline-keras-nn \n Bootstrap aggregating, also called **bagging**, is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It also reduces variance and helps to avoid overfitting. Although it is usually applied to decision tree methods, it can be used with any type of method. Bagging is a special case of the model averaging approach. Bagging leads to \"improvements for unstable procedures\", which include, for example, artificial neural networks, classification and regression trees, and subset selection in linear regression. On the other hand, it can mildly degrade the performance of stable methods such as K-nearest neighbors. Reference [Wikipedia](https://en.wikipedia.org/wiki/Bootstrap_aggregating).\n\nA **Bagging classifier** is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html). \n ### 5.15 ExtraTreesClassifier <a class=\"anchor\" id=\"5.15\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/kabure/titanic-eda-model-pipeline-keras-nn \n **ExtraTreesClassifier** implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The default values for the parameters controlling the size of the trees (e.g. max_depth, min_samples_leaf, etc.) lead to fully grown and unpruned trees which can potentially be very large on some data sets. To reduce memory consumption, the complexity and size of the trees should be controlled by setting those parameter values. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html). \n\nIn extremely randomized trees, randomness goes one step further in the way splits are computed. As in random forests, a random subset of candidate features is used, but instead of looking for the most discriminative thresholds, thresholds are drawn at random for each candidate feature and the best of these randomly-generated thresholds is picked as the splitting rule. This usually allows to reduce the variance of the model a bit more, at the expense of a slightly greater increase in bias. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/ensemble.html#Extremely%20Randomized%20Trees). \n ### 5.16 Neural Network 1 <a class=\"anchor\" id=\"5.16\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/nhlr21/complete-titanic-tutorial-with-ml-nn-ensembling \n **Neural networks** are more complex and more powerful algorithm than standars machine learning, it belongs to deep learning models. To build a neural network use Keras. Keras is a high level API for tensorflow, which is a tensor-manipulation framework made by google. Keras allows you to build neural networks by assembling blocks (which are the layers of neural network).  \n ### 5.17 Neural Network 2 <a class=\"anchor\" id=\"5.17\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to https://www.kaggle.com/junheeshin/titanic-analyze-and-predict-nn \n ### 5.18 VotingClassifier (hard voting) <a class=\"anchor\" id=\"5.18\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks for the example of ensemling different models from \nhttps://scikit-learn.org/stable/modules/ensemble.html#Extremely%20Randomized%20Trees \n The idea behind the **VotingClassifier** is to combine conceptually different machine learning classifiers and use a majority vote (hard vote) or the average predicted probabilities (soft vote) to predict the class labels. Such a classifier can be useful for a set of equally well performing model in order to balance out their individual weaknesses. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/ensemble.html#Voting%20Classifier). \n The VotingClassifier (with **hard voting**) would classify the sample as \u201cclass 1\u201d based on the **majority class label**. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/ensemble.html#Voting%20Classifier). \n ### 5.19 VotingClassifier (soft voting) <a class=\"anchor\" id=\"5.19\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks for the example of ensemling different models from \nhttps://scikit-learn.org/stable/modules/ensemble.html#Extremely%20Randomized%20Trees \n In contrast to majority voting (hard voting), **soft voting** returns the class label as argmax of the **sum of predicted probabilities**.\nSpecific weights can be assigned to each classifier via the weights parameter. When weights are provided, the predicted class probabilities for each classifier are collected, multiplied by the classifier weight, and averaged. The final class label is then derived from the class label with the highest average probability. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/ensemble.html#Voting%20Classifier). \n ### 5.20 The simple rule in one line <a class=\"anchor\" id=\"5.20\"></a>\n\n[Back to Table of Contents](#0.1) \n Thanks to:\n* https://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code\n* https://www.kaggle.com/vbmokin/titanic-top-3-cluster-analysis\n* https://www.kaggle.com/mauricef/titanic \n It's solution generate tuned DecisionTreeClassifier by the GridSearchCV from kernels:\nhttps://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code \n ## 6. Tuning models and test for 3 features <a class=\"anchor\" id=\"6\"></a>\n\n[Back to Table of Contents](#0.1) \n My kernels\n\n* [Titanic : one line of the prediction code](https://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code)\n* [Titanic : cluster analysis](https://www.kaggle.com/vbmokin/titanic-top-3-cluster-analysis)\n\npresents a solutions using a simple rule and only 3 features ('WomanOrBoySurvived', 'Sex', 'Alone'). Let's look at how all these models are tuned for those 3 features and whether we can find an even better solution. \n ## 7. Models evaluation <a class=\"anchor\" id=\"7\"></a>\n\n[Back to Table of Contents](#0.1) \n We can now rank our evaluation of all the models to choose the best one for our problem. \n ## 8. Conclusion <a class=\"anchor\" id=\"8\"></a>\n\n[Back to Table of Contents](#0.1) \n - The best model is the **simple rule in one line** from [\"Titanic Top 3% : one line of the prediction code\"](https://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code). Surprisingly, that the simple rule in one line gives the best result. This once again proves the enormous value of features engineering. The optimal selection of features is the key to success!\n\n- Models **GradientBoostingClassifier, Random Forests, VotingClassifiers, BaggingClassifier, Decision Tree Classifier** have provided the same accuracy LB on the test dataset as the simple rule, although on the training dataset they are much more accurate up to 100%.\n\n- The **VotingClassifier** for both voting options (\"*hard*\" and \"*soft*\") aggregation gave the same result for all the variants of features, that is, the solution found is indeed optimal, although a **Logistic Regression**, which is not one of the best, was selected for voting. This confirms the high efficiency of this method of aggregating (ensembling) predictions.\n\n- The models **GradientBoostingClassifier, BaggingClassifier, Random Forests, VotingClassifiers** did a good job of optimizing the features themselves, providing comparable accuracy for the different number of features in the test dataset, but the models **Decision Tree Classifier, Stochastic Gradient Descent, Support Vector Machines, Perceptron, Neural Networks, k-Nearest Neighbors algorithm** are very sensitive to the feature sets, because the accuracy of LB_all and LB is very different. Models **XGB Classifier, LGBM Classifier, ExtraTreesClassifier, Logistic Regression, Linear SVC, Naive Bayes, RidgeClassifier** depend on FE, but not so significantly.\n\n- The methods **LGBM Classifier, Perceptron, Neural Networks, Linear SVC, Naive Bayes, Logistic Regression, k-Nearest Neighbors algorithm, RidgeClassifier** have low accuracy LB, especially methods **Naive Bayes, Logistic Regression, Linear SVC**, compared to other models, although the \"***Titanic: Machine Learning from Disaster***\" contest is not indicative for the machine learning tasks because it contains too little data.\n\n- In all models, except **LGBM Classifier, Linear SVC, RidgeClassifier, Logistic Regression, Naive Bayes**, the prediction of test dataset based on 3 features yielded a more accurate result, possibly because these models perform worse under conditions of low number of features or under conditions of significant data dependence (in fact, feature \"*WomanOrBoySurvived*\" is, in part derived from others features \"*Sex*\" and \"*Alone*\") or with a small number of points (millions of points may vary greatly). Particularly interesting is that the **LGBM Classifier** model and method gave comparatively low accuracy on both the training and test datasets for the variant with three features, unlike **XGB Classifier** and other decision tree-based methods in which LB > LB_all.\n\n- To increase the accuracy of predictions, its need to increase the number of features and further improve their processing, that is FE (for example, add the processed feature \"**Tickets**\" - context is consist of a good kernels with have examples of such processing ([\"Advanced Feature Engineering Tutorial with Titanic\"](https://www.kaggle.com/gunesevitan/advanced-feature-engineering-tutorial-with-titanic) etc.). \n I hope you find this kernel useful and enjoyable. \n Your comments and feedback are most welcome. \n [Go to Top](#0)",
    "n_cells": 184,
    "n_code_cells": 100,
    "n_markdown_cells": 84,
    "n_raw_cells": 0,
    "n_outputs": 100,
    "r_code_cells": 0.5434782608695652,
    "r_markdown_cells": 0.45652173913043476,
    "r_raw_cells": 0.0,
    "r_outputs": 1.0,
    "n_exceptions": 0,
    "r_exceptions": 0.0,
    "n_lines": 1083,
    "n_lines_code": 838,
    "n_lines_markdown": 245,
    "lines_per_cell": [
        3,
        5,
        1,
        11,
        35,
        3,
        38,
        1,
        3,
        3,
        3,
        47,
        3,
        1,
        1,
        1,
        6,
        3,
        1,
        8,
        7,
        1,
        1,
        3,
        3,
        3,
        12,
        3,
        1,
        3,
        7,
        3,
        8,
        5,
        3,
        1,
        1,
        7,
        3,
        3,
        1,
        1,
        7,
        3,
        3,
        1,
        1,
        6,
        3,
        3,
        1,
        1,
        7,
        3,
        3,
        1,
        1,
        7,
        3,
        3,
        1,
        1,
        7,
        3,
        3,
        1,
        1,
        7,
        3,
        3,
        1,
        1,
        8,
        3,
        3,
        1,
        1,
        26,
        2,
        6,
        3,
        5,
        3,
        1,
        1,
        21,
        2,
        6,
        3,
        5,
        3,
        1,
        1,
        15,
        2,
        8,
        3,
        3,
        1,
        1,
        8,
        3,
        3,
        1,
        3,
        8,
        3,
        3,
        1,
        3,
        16,
        2,
        8,
        3,
        3,
        1,
        1,
        21,
        4,
        3,
        7,
        3,
        3,
        1,
        9,
        1,
        3,
        6,
        3,
        7,
        3,
        3,
        2,
        1,
        1,
        5,
        5,
        3,
        3,
        2,
        2,
        8,
        3,
        3,
        4,
        3,
        2,
        11,
        3,
        3,
        6,
        8,
        9,
        9,
        9,
        8,
        9,
        9,
        9,
        9,
        10,
        36,
        30,
        25,
        10,
        10,
        27,
        34,
        22,
        14,
        12,
        6,
        3,
        1,
        40,
        1,
        1,
        1,
        1,
        3,
        13,
        1,
        1,
        1
    ],
    "lines_per_code_cell": [
        38,
        1,
        3,
        47,
        3,
        1,
        1,
        1,
        8,
        7,
        1,
        1,
        3,
        7,
        3,
        5,
        7,
        3,
        7,
        3,
        6,
        3,
        7,
        3,
        7,
        3,
        7,
        3,
        7,
        3,
        8,
        3,
        26,
        2,
        6,
        3,
        5,
        21,
        2,
        6,
        3,
        5,
        15,
        2,
        8,
        3,
        8,
        3,
        8,
        3,
        16,
        2,
        8,
        3,
        21,
        4,
        3,
        7,
        3,
        9,
        1,
        3,
        6,
        3,
        7,
        3,
        5,
        5,
        3,
        8,
        3,
        3,
        11,
        3,
        8,
        9,
        9,
        9,
        8,
        9,
        9,
        9,
        9,
        10,
        36,
        30,
        25,
        10,
        10,
        27,
        34,
        22,
        14,
        12,
        6,
        40,
        1,
        1,
        1,
        1
    ],
    "lines_per_markdown_cell": [
        3,
        5,
        1,
        11,
        35,
        3,
        3,
        3,
        6,
        3,
        1,
        3,
        3,
        12,
        3,
        1,
        3,
        8,
        3,
        1,
        1,
        3,
        1,
        1,
        3,
        1,
        1,
        3,
        1,
        1,
        3,
        1,
        1,
        3,
        1,
        1,
        3,
        1,
        1,
        3,
        1,
        1,
        3,
        1,
        1,
        3,
        1,
        1,
        3,
        1,
        1,
        3,
        1,
        1,
        3,
        1,
        3,
        3,
        1,
        3,
        3,
        1,
        1,
        3,
        1,
        3,
        2,
        1,
        1,
        3,
        2,
        2,
        3,
        4,
        2,
        3,
        6,
        3,
        1,
        3,
        13,
        1,
        1,
        1
    ],
    "ave_lines_per_cell": 5.885869565217392,
    "ave_lines_per_code_cell": 8.38,
    "ave_lines_per_markdown_cell": 2.9166666666666665,
    "max_lines_per_cell": 47,
    "max_lines_per_code_cell": 47,
    "max_lines_per_markdown_cell": 35,
    "min_lines_per_cell": 1,
    "min_lines_per_code_cell": 1,
    "min_lines_per_markdown_cell": 1,
    "n_chars": 62847,
    "n_chars_code": 38194,
    "n_chars_markdown": 24653,
    "chars_per_cell": [
        174,
        200,
        19,
        579,
        1255,
        87,
        1307,
        13,
        88,
        218,
        96,
        2229,
        132,
        13,
        12,
        10,
        461,
        92,
        69,
        305,
        352,
        12,
        11,
        115,
        146,
        113,
        1244,
        94,
        74,
        476,
        182,
        188,
        771,
        189,
        98,
        74,
        492,
        159,
        185,
        85,
        74,
        225,
        247,
        199,
        104,
        74,
        422,
        280,
        185,
        86,
        74,
        420,
        193,
        197,
        85,
        74,
        556,
        195,
        199,
        102,
        74,
        672,
        173,
        185,
        99,
        74,
        585,
        239,
        205,
        89,
        74,
        476,
        405,
        205,
        91,
        421,
        108,
        1056,
        43,
        252,
        207,
        146,
        92,
        684,
        109,
        894,
        43,
        253,
        207,
        147,
        103,
        75,
        866,
        517,
        42,
        318,
        199,
        92,
        75,
        513,
        280,
        210,
        94,
        75,
        1401,
        298,
        215,
        97,
        75,
        1315,
        673,
        43,
        303,
        185,
        93,
        87,
        374,
        865,
        162,
        127,
        329,
        212,
        93,
        74,
        350,
        81,
        199,
        231,
        129,
        292,
        212,
        107,
        143,
        460,
        231,
        504,
        229,
        193,
        107,
        143,
        571,
        501,
        193,
        104,
        195,
        225,
        162,
        640,
        201,
        108,
        446,
        473,
        341,
        315,
        367,
        411,
        356,
        358,
        329,
        405,
        537,
        1570,
        1352,
        1028,
        449,
        470,
        1190,
        1509,
        1116,
        930,
        697,
        320,
        88,
        88,
        2230,
        67,
        66,
        66,
        66,
        81,
        3309,
        49,
        44,
        15
    ],
    "chars_per_code_cell": [
        1307,
        13,
        218,
        2229,
        132,
        13,
        12,
        10,
        305,
        352,
        12,
        11,
        146,
        182,
        188,
        189,
        159,
        185,
        247,
        199,
        280,
        185,
        193,
        197,
        195,
        199,
        173,
        185,
        239,
        205,
        405,
        205,
        1056,
        43,
        252,
        207,
        146,
        894,
        43,
        253,
        207,
        147,
        517,
        42,
        318,
        199,
        280,
        210,
        298,
        215,
        673,
        43,
        303,
        185,
        865,
        162,
        127,
        329,
        212,
        350,
        81,
        199,
        231,
        129,
        292,
        212,
        504,
        229,
        193,
        501,
        193,
        225,
        640,
        201,
        473,
        341,
        315,
        367,
        411,
        356,
        358,
        329,
        405,
        537,
        1570,
        1352,
        1028,
        449,
        470,
        1190,
        1509,
        1116,
        930,
        697,
        320,
        2230,
        67,
        66,
        66,
        66
    ],
    "chars_per_markdown_cell": [
        174,
        200,
        19,
        579,
        1255,
        87,
        88,
        96,
        461,
        92,
        69,
        115,
        113,
        1244,
        94,
        74,
        476,
        771,
        98,
        74,
        492,
        85,
        74,
        225,
        104,
        74,
        422,
        86,
        74,
        420,
        85,
        74,
        556,
        102,
        74,
        672,
        99,
        74,
        585,
        89,
        74,
        476,
        91,
        421,
        108,
        92,
        684,
        109,
        103,
        75,
        866,
        92,
        75,
        513,
        94,
        75,
        1401,
        97,
        75,
        1315,
        93,
        87,
        374,
        93,
        74,
        107,
        143,
        460,
        231,
        107,
        143,
        571,
        104,
        195,
        162,
        108,
        446,
        88,
        88,
        81,
        3309,
        49,
        44,
        15
    ],
    "ave_chars_per_line": 58.03047091412743,
    "ave_chars_per_cell": 341.5597826086956,
    "ave_chars_per_code_cell": 381.94,
    "ave_chars_per_markdown_cell": 293.48809523809524,
    "max_chars_per_cell": 3309,
    "max_chars_per_code_cell": 2230,
    "max_chars_per_markdownell": 3309,
    "min_chars_per_cell": 10,
    "min_chars_per_code_cell": 10,
    "min_chars_per_markdown_cell": 15,
    "r_lines_code": 0.7737765466297323,
    "r_lines_markdown": 0.22622345337026778,
    "r_chars_markdown": 0.3922701163142234,
    "r_chars_code": 0.6077298836857765,
    "all_cells": [
        {
            "source": "<a class=\"anchor\" id=\"0\"></a>\n\n## FE, tuning and comparison of the 20 popular models with  predictions on the example of competition \"Titanic: Machine Learning from Disaster\"",
            "mc_idx": 0,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Features engineering (FE) from Titanic Top 3%\n\nBuild of the 20 most popular models, the most complex models from them are tuned (optimized)\n\nComparison of the optimal for each type models by CV and LB",
            "mc_idx": 1,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## Acknowledgements",
            "mc_idx": 2,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks for most popular models to:\n* https://www.kaggle.com/kabure/titanic-eda-model-pipeline-keras-nn\n* https://www.kaggle.com/startupsci/titanic-data-science-solutions \n* https://www.kaggle.com/nhlr21/complete-titanic-tutorial-with-ml-nn-ensembling\n\nThanks for FE:\n* https://www.kaggle.com/vbmokin/three-lines-of-code-for-titanic-top-15\n* https://www.kaggle.com/vbmokin/three-lines-of-code-for-titanic-top-20\n* https://www.kaggle.com/mauricef/titanic\n* https://www.kaggle.com/kpacocha/top-6-titanic-machine-learning-from-disaster\n* https://www.kaggle.com/erinsweet/simpledetect",
            "mc_idx": 3,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<a class=\"anchor\" id=\"0.1\"></a>\n\n## Table of Contents\n\n1. [Import libraries](#1)\n1. [Download datasets](#2)\n1. [Features engineering (FE)](#3)\n1. [Preparing to modeling](#4)\n    -  [Encoding categorical features](#4.1)\n    -  [Creation of training and validation sets](#4.2)\n1. [Tuning models and test for all 16 features](#5)\n    -  [Logistic Regression](#5.1)\n    -  [Support Vector Machines](#5.2)\n    -  [Linear SVC](#5.3)\n    -  [k-Nearest Neighbors algorithm with GridSearchCV](#5.4)\n    -  [Naive Bayes](#5.5)\n    -  [Perceptron](#5.6)\n    -  [Stochastic Gradient Descent](#5.7)\n    -  [Decision Tree Classifier](#5.8)\n    -  [Random Forests with GridSearchCV](#5.9)\n    -  [XGB Classifier with HyperOpt](#5.10)\n    -  [LGBM Classifier with HyperOpt](#5.11)\n    -  [GradientBoostingClassifier with HyperOpt](#5.12)\n    -  [RidgeClassifier](#5.13)\n    -  [BaggingClassifier](#5.14)\n    -  [ExtraTreesClassifier with HyperOpt](#5.15)\n    -  [Neural Network 1](#5.16)\n    -  [Neural Network 2](#5.17)\n    -  [VotingClassifier (hard voting)](#5.18)\n    -  [VotingClassifier (soft voting) with GridSearchCV](#5.19)\n    -  [The simple rule in one line](#5.20)\n1. [Tuning models and test for 3 features](#6)\n1. [Models evaluation](#7)\n1. [Conclusion](#8)\n",
            "mc_idx": 4,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 1. Import libraries <a class=\"anchor\" id=\"1\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 5,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n\n# models\nfrom sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier \nfrom sklearn.ensemble import BaggingClassifier, VotingClassifier \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\n# NN models\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras import optimizers\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# model tuning\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe, space_eval\n\n# import warnings filter\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)",
            "mc_idx": 6,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.015384615384615385,
                "Data_Transform": 0.015384615384615385,
                "Model_Train": 0.08461538461538462,
                "Model_Evaluation": 0.03076923076923077,
                "Model_Interpretation": 0.03076923076923077,
                "Hyperparameter_Tuning": 0.026923076923076925,
                "Visualization": 0.011538461538461539,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 26
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "matplotlib": 2,
                    ".mode": 2
                },
                "Data_Transform": {
                    "labelencoder": 2,
                    ".mod": 2
                },
                "Model_Train": {
                    "train_test_split": 1,
                    "model": 7,
                    "randomforestclassifier": 2,
                    "model_selection": 1,
                    "logisticregression": 1,
                    "ridge": 1,
                    "sgdclassifier": 1,
                    "gradientboostingclassifier": 1,
                    "decisiontreeclassifier": 1,
                    "kneighborsclassifier": 1,
                    "svc": 2,
                    "gaussiannb": 1,
                    "votingclassifier": 1,
                    ".linear": 1
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    "model": 7
                },
                "Model_Interpretation": {
                    "model": 7,
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "hyperopt": 1,
                    "model tuning": 1,
                    "cross_val_score": 1,
                    "train_test_split": 1
                },
                "Visualization": {
                    "matplotlib": 2,
                    "pyplot": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    0,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Using TensorFlow backend.\n"
                    ]
                },
                "mc_idx": 6,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 0,
                "o_idx": 0
            }
        },
        {
            "source": "cv_number = 5",
            "mc_idx": 7,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    1,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 7,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 1,
                "o_idx": 0
            }
        },
        {
            "source": "## 2. Download datasets <a class=\"anchor\" id=\"2\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 8,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "traindf = pd.read_csv('../input/titanic/train.csv').set_index('PassengerId')\ntestdf = pd.read_csv('../input/titanic/test.csv').set_index('PassengerId')\nsubmission = pd.read_csv('../input/titanic/gender_submission.csv')",
            "mc_idx": 9,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.16666666666666666,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 6,
                    "pd.read_": 6
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".set_index": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    2,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 9,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 2,
                "o_idx": 0
            }
        },
        {
            "source": "## 3. Features engineering (FE) <a class=\"anchor\" id=\"3\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 10,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#Thanks to:\n# https://www.kaggle.com/mauricef/titanic\n# https://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code\n#\ndf = pd.concat([traindf, testdf], axis=0, sort=False)\ndf['Title'] = df.Name.str.split(',').str[1].str.split('.').str[0].str.strip()\ndf['Title'] = df.Name.str.split(',').str[1].str.split('.').str[0].str.strip()\ndf['IsWomanOrBoy'] = ((df.Title == 'Master') | (df.Sex == 'female'))\ndf['LastName'] = df.Name.str.split(',').str[0]\nfamily = df.groupby(df.LastName).Survived\ndf['WomanOrBoyCount'] = family.transform(lambda s: s[df.IsWomanOrBoy].fillna(0).count())\ndf['WomanOrBoyCount'] = df.mask(df.IsWomanOrBoy, df.WomanOrBoyCount - 1, axis=0)\ndf['FamilySurvivedCount'] = family.transform(lambda s: s[df.IsWomanOrBoy].fillna(0).sum())\ndf['FamilySurvivedCount'] = df.mask(df.IsWomanOrBoy, df.FamilySurvivedCount - \\\n                                    df.Survived.fillna(0), axis=0)\ndf['WomanOrBoySurvived'] = df.FamilySurvivedCount / df.WomanOrBoyCount.replace(0, np.nan)\ndf.WomanOrBoyCount = df.WomanOrBoyCount.replace(np.nan, 0)\ndf['Alone'] = (df.WomanOrBoyCount == 0)\n\n#Thanks to https://www.kaggle.com/kpacocha/top-6-titanic-machine-learning-from-disaster\n#\"Title\" improvement\ndf['Title'] = df['Title'].replace('Ms','Miss')\ndf['Title'] = df['Title'].replace('Mlle','Miss')\ndf['Title'] = df['Title'].replace('Mme','Mrs')\n# Embarked\ndf['Embarked'] = df['Embarked'].fillna('S')\n# Cabin, Deck\ndf['Deck'] = df['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\ndf.loc[(df['Deck'] == 'T'), 'Deck'] = 'A'\n\n# Thanks to https://www.kaggle.com/erinsweet/simpledetect\n# Fare\nmed_fare = df.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]\ndf['Fare'] = df['Fare'].fillna(med_fare)\n#Age\ndf['Age'] = df.groupby(['Sex', 'Pclass', 'Title'])['Age'].apply(lambda x: x.fillna(x.median()))\n# Family_Size\ndf['Family_Size'] = df['SibSp'] + df['Parch'] + 1\n\n# Thanks to https://www.kaggle.com/vbmokin/titanic-top-3-cluster-analysis\ncols_to_drop = ['Name','Ticket','Cabin']\ndf = df.drop(cols_to_drop, axis=1)\n\ndf.WomanOrBoySurvived = df.WomanOrBoySurvived.fillna(0)\ndf.WomanOrBoyCount = df.WomanOrBoyCount.fillna(0)\ndf.FamilySurvivedCount = df.FamilySurvivedCount.fillna(0)\ndf.Alone = df.Alone.fillna(0)",
            "mc_idx": 11,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.23404255319148937,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".median": 4,
                    "size": 2,
                    ".notnull": 1,
                    ".sum": 1,
                    ".groupby": 3
                },
                "Data_Transform": {
                    ".concat(": 1,
                    ".groupby(": 3,
                    ".fillna(": 10,
                    ".apply(": 2,
                    ".replace(": 5,
                    "transform": 2,
                    ".split": 5,
                    ".drop": 1,
                    ".fillna": 10,
                    ".replace": 5,
                    ".apply": 2,
                    ".concat": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    3,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 11,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 3,
                "o_idx": 0
            }
        },
        {
            "source": "target = df.Survived.loc[traindf.index]\ndf = df.drop(['Survived'], axis=1)\ntrain, test = df.loc[traindf.index], df.loc[testdf.index]",
            "mc_idx": 12,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    4,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 12,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 4,
                "o_idx": 0
            }
        },
        {
            "source": "train.head(3)",
            "mc_idx": 13,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    5,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "             Pclass     Sex   Age  SibSp  Parch     Fare Embarked Title  \\\nPassengerId                                                               \n1                 3    male  22.0      1      0   7.2500        S    Mr   \n2                 1  female  38.0      1      0  71.2833        C   Mrs   \n3                 3  female  26.0      0      0   7.9250        S  Miss   \n\n             IsWomanOrBoy   LastName  WomanOrBoyCount  FamilySurvivedCount  \\\nPassengerId                                                                  \n1                   False     Braund              0.0                  0.0   \n2                    True    Cumings              0.0                  0.0   \n3                    True  Heikkinen              0.0                  0.0   \n\n             WomanOrBoySurvived  Alone Deck  Family_Size  \nPassengerId                                               \n1                           0.0   True    M            2  \n2                           0.0   True    C            2  \n3                           0.0   True    M            1  "
                    ]
                },
                "mc_idx": 13,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 5,
                "o_idx": 0
            }
        },
        {
            "source": "test.head(3)",
            "mc_idx": 14,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    6,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "             Pclass     Sex   Age  SibSp  Parch    Fare Embarked Title  \\\nPassengerId                                                              \n892               3    male  34.5      0      0  7.8292        Q    Mr   \n893               3  female  47.0      1      0  7.0000        S   Mrs   \n894               2    male  62.0      0      0  9.6875        Q    Mr   \n\n             IsWomanOrBoy LastName  WomanOrBoyCount  FamilySurvivedCount  \\\nPassengerId                                                                \n892                 False    Kelly              0.0                  0.0   \n893                  True   Wilkes              0.0                  0.0   \n894                 False    Myles              0.0                  0.0   \n\n             WomanOrBoySurvived  Alone Deck  Family_Size  \nPassengerId                                               \n892                         0.0   True    M            1  \n893                         0.0   True    M            2  \n894                         0.0   True    M            1  "
                    ]
                },
                "mc_idx": 14,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 6,
                "o_idx": 0
            }
        },
        {
            "source": "target[:3]",
            "mc_idx": 15,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    7,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "PassengerId\n1    0.0\n2    1.0\n3    1.0\nName: Survived, dtype: float64"
                    ]
                },
                "mc_idx": 15,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 7,
                "o_idx": 0
            }
        },
        {
            "source": "All models were tuned for a complete set of 16 features, solutions were calculated, that were uploaded to the competition, which made it possible to determine the error LB_all.\nAfter which the decision was taken into account\n* https://www.kaggle.com/mauricef/titanic\n* https://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code\n\ncalculated on only three features ('WomanOrBoySurvived', 'Alone', 'Sex') - an error LB is defined for this option.",
            "mc_idx": 16,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 4. Preparing to modeling <a class=\"anchor\" id=\"4\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 17,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 4.1 Encoding categorical features <a class=\"anchor\" id=\"4.1\"></a>",
            "mc_idx": 18,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Determination categorical features\nnumerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ncategorical_columns = []\nfeatures = train.columns.values.tolist()\nfor col in features:\n    if train[col].dtype in numerics: continue\n    categorical_columns.append(col)\ncategorical_columns",
            "mc_idx": 19,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 4
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    8,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Sex', 'Embarked', 'Title', 'IsWomanOrBoy', 'LastName', 'Alone', 'Deck']"
                    ]
                },
                "mc_idx": 19,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 8,
                "o_idx": 0
            }
        },
        {
            "source": "# Encoding categorical features\nfor col in categorical_columns:\n    if col in train.columns:\n        le = LabelEncoder()\n        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n        train[col] = le.transform(list(train[col].astype(str).values))\n        test[col] = le.transform(list(test[col].astype(str).values))   ",
            "mc_idx": 20,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 1.0,
                "Model_Train": 0.125,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 2
                },
                "Data_Transform": {
                    "transform": 2,
                    ".astype(": 4,
                    "labelencoder": 2
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    9,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 20,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 9,
                "o_idx": 0
            }
        },
        {
            "source": "train.info()",
            "mc_idx": 21,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".info(": 1,
                    "info": 1,
                    ".info": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    10,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 891 entries, 1 to 891\nData columns (total 16 columns):\nPclass                 891 non-null int64\nSex                    891 non-null int64\nAge                    891 non-null float64\nSibSp                  891 non-null int64\nParch                  891 non-null int64\nFare                   891 non-null float64\nEmbarked               891 non-null int64\nTitle                  891 non-null int64\nIsWomanOrBoy           891 non-null int64\nLastName               891 non-null int64\nWomanOrBoyCount        891 non-null float64\nFamilySurvivedCount    891 non-null float64\nWomanOrBoySurvived     891 non-null float64\nAlone                  891 non-null int64\nDeck                   891 non-null int64\nFamily_Size            891 non-null int64\ndtypes: float64(5), int64(11)\nmemory usage: 118.3 KB\n"
                    ]
                },
                "mc_idx": 21,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 10,
                "o_idx": 0
            }
        },
        {
            "source": "test.info()",
            "mc_idx": 22,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".info(": 1,
                    "info": 1,
                    ".info": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    11,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 418 entries, 892 to 1309\nData columns (total 16 columns):\nPclass                 418 non-null int64\nSex                    418 non-null int64\nAge                    418 non-null float64\nSibSp                  418 non-null int64\nParch                  418 non-null int64\nFare                   418 non-null float64\nEmbarked               418 non-null int64\nTitle                  418 non-null int64\nIsWomanOrBoy           418 non-null int64\nLastName               418 non-null int64\nWomanOrBoyCount        418 non-null float64\nFamilySurvivedCount    418 non-null float64\nWomanOrBoySurvived     418 non-null float64\nAlone                  418 non-null int64\nDeck                   418 non-null int64\nFamily_Size            418 non-null int64\ndtypes: float64(5), int64(11)\nmemory usage: 55.5 KB\n"
                    ]
                },
                "mc_idx": 22,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 11,
                "o_idx": 0
            }
        },
        {
            "source": "### 4.2 Creation of training and validation sets <a class=\"anchor\" id=\"4.2\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 23,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#%% split training set to validation set\nSEED = 100\nXtrain, Xval, Ztrain, Zval = train_test_split(train, target, test_size=0.3, random_state=SEED)",
            "mc_idx": 24,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "train_test_split": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "train_test_split": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    12,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 24,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 12,
                "o_idx": 0
            }
        },
        {
            "source": "## 5. Tuning models and test for all 16 features <a class=\"anchor\" id=\"5\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 25,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions\n\nNow we are ready to train a model and predict the required solution. There are 60+ predictive modelling algorithms to choose from. We must understand the type of problem and solution requirement to narrow down to a select few models which we can evaluate. Our problem is a classification and regression problem. We want to identify relationship between output (Survived or not) with other variables or features (Gender, Age, Port...). We are also perfoming a category of machine learning which is called supervised learning as we are training our model with a given dataset. With these two criteria - Supervised Learning plus Classification and Regression, we can narrow down our choice of models to a few. These include:\n\n- Logistic Regression\n- Support Vector Machines and Linear SVC\n- KNN or k-Nearest Neighbors\n- Naive Bayes Classifier or Gaussian Naive Bayes\n- Stochastic Gradient Descent, GradientBoostingClassifier, RidgeClassifier, BaggingClassifier\n- Decision Tree Classifier, Random Forest, XGB Classifier, LGBM Classifier, ExtraTreesClassifier\n- Perceptron, Neural Networks with different archictures (Deep Learning)\n- VotingClassifier (hard or soft voting)",
            "mc_idx": 26,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 5.1 Logistic Regression <a class=\"anchor\" id=\"5.1\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 27,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions",
            "mc_idx": 28,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Logistic Regression** is a useful model to run early in the workflow. Logistic regression measures the relationship between the categorical dependent variable (feature) and one or more independent variables (features) by estimating probabilities using a logistic function, which is the cumulative logistic distribution. Reference [Wikipedia](https://en.wikipedia.org/wiki/Logistic_regression).\n\nNote the confidence score generated by the model based on our training dataset.",
            "mc_idx": 29,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(train, target)\nY_pred = logreg.predict(test).astype(int)\nacc_log = round(logreg.score(train, target) * 100, 2)\nacc_log",
            "mc_idx": 30,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "logisticregression": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    13,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "93.6"
                    ]
                },
                "mc_idx": 30,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 13,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_logreg.csv', index=False)\nLB_log_all = 0.79904  # old version",
            "mc_idx": 31,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    14,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 31,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 14,
                "o_idx": 0
            }
        },
        {
            "source": "We can use Logistic Regression to validate our assumptions and decisions for feature creating and completing goals. This can be done by calculating the coefficient of the features in the decision function.\n\nPositive coefficients increase the log-odds of the response (and thus increase the probability), and negative coefficients decrease the log-odds of the response (and thus decrease the probability).\n\n- Alone is highest positivie coefficient, implying as the Alone value increases (0 to 1), the probability of Survived=1 increases the most.\n- Inversely as Sex increases (male: 0 to female: 1), probability of Survived=1 decreases the most.\n- This way Age has second highest negative correlation with Survived.\n- So is LastName as second highest positive correlation.",
            "mc_idx": 32,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "coeff_df = pd.DataFrame(train.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)",
            "mc_idx": 33,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.5,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 2
                },
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "coef_": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    15,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "                Feature  Correlation\n12                Alone     4.806590\n8              LastName     3.836475\n11   WomanOrBoySurvived     1.434728\n7          IsWomanOrBoy     0.168430\n14          Family_Size     0.050806\n5              Embarked     0.001786\n9       WomanOrBoyCount     0.000120\n2                 SibSp    -0.027352\n6                 Title    -0.185026\n3                 Parch    -0.203336\n4                  Fare    -0.260847\n10  FamilySurvivedCount    -0.593419\n13                 Deck    -0.838817\n1                   Age    -1.169061\n0                   Sex    -1.300208"
                    ]
                },
                "mc_idx": 33,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 15,
                "o_idx": 0
            }
        },
        {
            "source": "### 5.2 Support Vector Machines <a class=\"anchor\" id=\"5.2\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 34,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions",
            "mc_idx": 35,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Support Vector Machines** are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. Given a set of training samples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new test samples to one category or the other, making it a non-probabilistic binary linear classifier. Reference [Wikipedia](https://en.wikipedia.org/wiki/Support_vector_machine).",
            "mc_idx": 36,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Support Vector Machines\n\nsvc = SVC()\nsvc.fit(train, target)\nY_pred = svc.predict(test).astype(int)\nacc_svc = round(svc.score(train, target) * 100, 2)\nacc_svc",
            "mc_idx": 37,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.125,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.25,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "svc": 7
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    16,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "98.99"
                    ]
                },
                "mc_idx": 37,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 16,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_svm.csv', index=False)\nLB_svc_all = 0.62200  # old version",
            "mc_idx": 38,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.5,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "svc": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    17,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 38,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 17,
                "o_idx": 0
            }
        },
        {
            "source": "### 5.3 Linear SVC <a class=\"anchor\" id=\"5.3\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 39,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions",
            "mc_idx": 40,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**SVC** is a similar to SVM method. Its also builds on kernel functions but is appropriate for unsupervised learning. Reference [Wikipedia](https://en.wikipedia.org/wiki/Support-vector_machine#Support-vector_clustering_(SVC).",
            "mc_idx": 41,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Linear SVC\n\nlinear_svc = LinearSVC(dual=False)  # dual=False when n_samples > n_features.\nlinear_svc.fit(train, target)\nY_pred = linear_svc.predict(test).astype(int)\nacc_linear_svc = round(linear_svc.score(train, target) * 100, 2)\nacc_linear_svc",
            "mc_idx": 42,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.1111111111111111,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.2222222222222222,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "svc": 8
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    18,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "94.61"
                    ]
                },
                "mc_idx": 42,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 18,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_linear_svc.csv', index=False)\nLB_linear_svc_all = 0.81339  # old version",
            "mc_idx": 43,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "svc": 2
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    19,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 43,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 19,
                "o_idx": 0
            }
        },
        {
            "source": "### 5.4 k-Nearest Neighbors algorithm <a class=\"anchor\" id=\"5.4\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 44,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions",
            "mc_idx": 45,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "In pattern recognition, the **k-Nearest Neighbors algorithm** (or k-NN for short) is a non-parametric method used for classification and regression. A sample is classified by a majority vote of its neighbors, with the sample being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). Reference [Wikipedia](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm).",
            "mc_idx": 46,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# k-Nearest Neighbors algorithm\n\nknn = GridSearchCV(estimator=KNeighborsClassifier(), param_grid={'n_neighbors': [2, 3, 4]}, cv=cv_number).fit(train, target)\nY_pred = knn.predict(test).astype(int)\nacc_knn = round(knn.score(train, target) * 100, 2)\nprint(acc_knn, knn.best_params_)",
            "mc_idx": 47,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.16666666666666666,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "kneighborsclassifier": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "param_grid": 1,
                    "param": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    20,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "76.32 {'n_neighbors': 4}\n"
                    ]
                },
                "mc_idx": 47,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 20,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_knn.csv', index=False)\nLB_knn_all = 0.62679  # old version",
            "mc_idx": 48,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    21,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 48,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 21,
                "o_idx": 0
            }
        },
        {
            "source": "### 5.5 Naive Bayes <a class=\"anchor\" id=\"5.5\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 49,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions",
            "mc_idx": 50,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "In machine learning, **Naive Bayes classifiers** are a family of simple probabilistic classifiers based on applying Bayes' theorem with strong (naive) independence assumptions between the features. Naive Bayes classifiers are highly scalable, requiring a number of parameters linear in the number of variables (features) in a learning problem. Reference [Wikipedia](https://en.wikipedia.org/wiki/Naive_Bayes_classifier).",
            "mc_idx": 51,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(train, target)\nY_pred = gaussian.predict(test).astype(int)\nacc_gaussian = round(gaussian.score(train, target) * 100, 2)\nacc_gaussian",
            "mc_idx": 52,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "gaussiannb": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    22,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "86.53"
                    ]
                },
                "mc_idx": 52,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 22,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_GaussianNB.csv', index=False)\nLB_gaussian_all = 0.73205  # old version",
            "mc_idx": 53,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.5,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "gaussiannb": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    23,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 53,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 23,
                "o_idx": 0
            }
        },
        {
            "source": "### 5.6 Perceptron <a class=\"anchor\" id=\"5.6\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 54,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions",
            "mc_idx": 55,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "The **Perceptron** is an algorithm for supervised learning of binary classifiers (functions that can decide whether an input, represented by a vector of numbers, belongs to some specific class or not). It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector. The algorithm allows for online learning, in that it processes elements in the training set one at a time. Reference [Wikipedia](https://en.wikipedia.org/wiki/Perceptron).",
            "mc_idx": 56,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(train, target)\nY_pred = perceptron.predict(test).astype(int)\nacc_perceptron = round(perceptron.score(train, target) * 100, 2)\nacc_perceptron",
            "mc_idx": 57,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 0.5,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    24,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "50.73"
                    ]
                },
                "mc_idx": 57,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 24,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_perceptron.csv', index=False)\nLB_perceptron_all = 0.46889  # old version",
            "mc_idx": 58,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    25,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 58,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 25,
                "o_idx": 0
            }
        },
        {
            "source": "### 5.7 Stochastic Gradient Descent <a class=\"anchor\" id=\"5.7\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 59,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions",
            "mc_idx": 60,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Stochastic gradient descent** (often abbreviated **SGD**) is an iterative method for optimizing an objective function with suitable smoothness properties (e.g. differentiable or subdifferentiable). It can be regarded as a stochastic approximation of gradient descent optimization, since it replaces the actual gradient (calculated from the entire data set) by an estimate thereof (calculated from a randomly selected subset of the data). Especially in big data applications this reduces the computational burden, achieving faster iterations in trade for a slightly lower convergence rate. Reference [Wikipedia](https://en.wikipedia.org/wiki/Stochastic_gradient_descent).",
            "mc_idx": 61,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(train, target)\nY_pred = sgd.predict(test).astype(int)\nacc_sgd = round(sgd.score(train, target) * 100, 2)\nacc_sgd",
            "mc_idx": 62,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "sgdclassifier": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    26,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "72.17"
                    ]
                },
                "mc_idx": 62,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 26,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_sgd.csv', index=False)\nLB_sgd_all = 0.64593  # old version",
            "mc_idx": 63,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    27,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 63,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 27,
                "o_idx": 0
            }
        },
        {
            "source": "### 5.8 Decision Tree Classifier <a class=\"anchor\" id=\"5.8\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 64,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions",
            "mc_idx": 65,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "This model uses a **Decision Tree** as a predictive model which maps features (tree branches) to conclusions about the target value (tree leaves). Tree models where the target variable can take a finite set of values are called classification trees; in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. Reference [Wikipedia](https://en.wikipedia.org/wiki/Decision_tree_learning).",
            "mc_idx": 66,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Decision Tree Classifier\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(train, target)\nY_pred = decision_tree.predict(test).astype(int)\nacc_decision_tree = round(decision_tree.score(train, target) * 100, 2)\nacc_decision_tree",
            "mc_idx": 67,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "decisiontreeclassifier": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    28,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "100.0"
                    ]
                },
                "mc_idx": 67,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 28,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_decision_tree.csv', index=False)\nLB_decision_tree_all = 0.77990  # old version",
            "mc_idx": 68,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    29,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 68,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 29,
                "o_idx": 0
            }
        },
        {
            "source": "### 5.9 Random Forests <a class=\"anchor\" id=\"5.9\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 69,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions",
            "mc_idx": 70,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Random Forests** is one of the most popular model. Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees (n_estimators= [100, 300]) at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Reference [Wikipedia](https://en.wikipedia.org/wiki/Random_forest).",
            "mc_idx": 71,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Random Forest\n\nrandom_forest = GridSearchCV(estimator=RandomForestClassifier(), param_grid={'n_estimators': [200, 300, 400, 500]}, cv=cv_number).fit(train, target)\nrandom_forest.fit(train, target)\nY_pred = random_forest.predict(test).astype(int)\nrandom_forest.score(train, target)\nacc_random_forest = round(random_forest.score(train, target) * 100, 2)\nprint(acc_random_forest,random_forest.best_params_)",
            "mc_idx": 72,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.16666666666666666,
                "Model_Train": 0.6666666666666666,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 2,
                    "randomforestclassifier": 2
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "param_grid": 1,
                    "param": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    30,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "100.0 {'n_estimators': 300}\n"
                    ]
                },
                "mc_idx": 72,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 30,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_random_forest.csv', index=False)\nLB_random_forest_all = 0.81339  # old version",
            "mc_idx": 73,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    31,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 73,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 31,
                "o_idx": 0
            }
        },
        {
            "source": "### 5.10 XGB Classifier <a class=\"anchor\" id=\"5.10\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 74,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "XGBoost is an ensemble tree method that apply the principle of boosting weak learners (CARTs generally) using the gradient descent architecture. XGBoost improves upon the base Gradient Boosting Machines (GBM) framework through systems optimization and algorithmic enhancements. Reference [Towards Data Science.](https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d)",
            "mc_idx": 75,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "We will tuning the hyperparameters of the XGBClassifier model using the HyperOpt and 10-fold crossvalidation",
            "mc_idx": 76,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "%%time\ndef hyperopt_xgb_score(params):\n    clf = XGBClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_xgb = {\n            'learning_rate': hp.quniform('learning_rate', 0, 0.05, 0.0001),\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_depth':  hp.choice('max_depth', np.arange(5, 8, dtype=int)),\n            'min_child_weight': hp.quniform('min_child_weight', 1, 9, 0.025),\n            'subsample': hp.quniform('subsample', 0.5, 1, 0.005),\n            'gamma': hp.quniform('gamma', 0.5, 1, 0.005),\n            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.005),\n            'eval_metric': 'auc',\n            'objective': 'binary:logistic',\n            'booster': 'gbtree',\n            'tree_method': 'exact',\n            'silent': 1,\n            'missing': None\n        }\n \nbest = fmin(fn=hyperopt_xgb_score, space=space_xgb, algo=tpe.suggest, max_evals=10)\nprint('best:')\nprint(best)",
            "mc_idx": 77,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.16666666666666666,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {
                    "cross_val_score": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "hyperopt": 2,
                    "param": 3,
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    32,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0.9282083008397443\n{'booster': 'gbtree', 'colsample_bytree': 0.78, 'eval_metric': 'auc', 'gamma': 0.665, 'learning_rate': 0.0088, 'max_depth': 7, 'min_child_weight': 3.8000000000000003, 'missing': None, 'n_estimators': 378, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.595, 'tree_method': 'exact'}\n0.9315791582839413\n{'booster': 'gbtree', 'colsample_bytree': 0.755, 'eval_metric': 'auc', 'gamma': 0.985, 'learning_rate': 0.0304, 'max_depth': 5, 'min_child_weight': 1.925, 'missing': None, 'n_estimators': 112, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.67, 'tree_method': 'exact'}\n0.9338263492951772\n{'booster': 'gbtree', 'colsample_bytree': 0.745, 'eval_metric': 'auc', 'gamma': 0.855, 'learning_rate': 0.0028, 'max_depth': 5, 'min_child_weight': 8.6, 'missing': None, 'n_estimators': 175, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.88, 'tree_method': 'exact'}\n0.9315728812140776\n{'booster': 'gbtree', 'colsample_bytree': 0.6900000000000001, 'eval_metric': 'auc', 'gamma': 0.595, 'learning_rate': 0.0263, 'max_depth': 5, 'min_child_weight': 6.65, 'missing': None, 'n_estimators': 547, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.91, 'tree_method': 'exact'}\n0.9260240223818323\n{'booster': 'gbtree', 'colsample_bytree': 0.8, 'eval_metric': 'auc', 'gamma': 0.595, 'learning_rate': 0.0015, 'max_depth': 7, 'min_child_weight': 8.575000000000001, 'missing': None, 'n_estimators': 970, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.5700000000000001, 'tree_method': 'exact'}\n0.9315602561470069\n{'booster': 'gbtree', 'colsample_bytree': 0.9550000000000001, 'eval_metric': 'auc', 'gamma': 0.66, 'learning_rate': 0.032100000000000004, 'max_depth': 7, 'min_child_weight': 8.450000000000001, 'missing': None, 'n_estimators': 551, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.895, 'tree_method': 'exact'}\n0.9304492147811164\n{'booster': 'gbtree', 'colsample_bytree': 0.985, 'eval_metric': 'auc', 'gamma': 0.855, 'learning_rate': 0.023700000000000002, 'max_depth': 7, 'min_child_weight': 4.0, 'missing': None, 'n_estimators': 723, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.875, 'tree_method': 'exact'}\n0.9293256192754985\n{'booster': 'gbtree', 'colsample_bytree': 0.9550000000000001, 'eval_metric': 'auc', 'gamma': 0.64, 'learning_rate': 0.0218, 'max_depth': 7, 'min_child_weight': 1.6, 'missing': None, 'n_estimators': 552, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.855, 'tree_method': 'exact'}\n0.9338137951554497\n{'booster': 'gbtree', 'colsample_bytree': 0.65, 'eval_metric': 'auc', 'gamma': 0.78, 'learning_rate': 0.0349, 'max_depth': 7, 'min_child_weight': 4.4, 'missing': None, 'n_estimators': 600, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.53, 'tree_method': 'exact'}\n0.9371656795353692\n{'booster': 'gbtree', 'colsample_bytree': 0.9500000000000001, 'eval_metric': 'auc', 'gamma': 0.6900000000000001, 'learning_rate': 0.0325, 'max_depth': 5, 'min_child_weight': 4.4750000000000005, 'missing': None, 'n_estimators': 815, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.685, 'tree_method': 'exact'}\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:20<00:00,  2.07s/it, best loss: 0.9260240223818323]\nbest:\n{'colsample_bytree': 0.8, 'gamma': 0.595, 'learning_rate': 0.0015, 'max_depth': 2, 'min_child_weight': 8.575000000000001, 'n_estimators': 870, 'subsample': 0.5700000000000001}\nCPU times: user 20.8 s, sys: 350 ms, total: 21.1 s\nWall time: 21.1 s\n"
                    ]
                },
                "mc_idx": 77,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 32,
                "o_idx": 0
            }
        },
        {
            "source": "params = space_eval(space_xgb, best)\nparams",
            "mc_idx": 78,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    33,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "{'booster': 'gbtree',\n 'colsample_bytree': 0.8,\n 'eval_metric': 'auc',\n 'gamma': 0.595,\n 'learning_rate': 0.0015,\n 'max_depth': 7,\n 'min_child_weight': 8.575000000000001,\n 'missing': None,\n 'n_estimators': 970,\n 'objective': 'binary:logistic',\n 'silent': 1,\n 'subsample': 0.5700000000000001,\n 'tree_method': 'exact'}"
                    ]
                },
                "mc_idx": 78,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 33,
                "o_idx": 0
            }
        },
        {
            "source": "XGB_Classifier = XGBClassifier(**params)\nXGB_Classifier.fit(train, target)\nY_pred = XGB_Classifier.predict(test).astype(int)\nXGB_Classifier.score(train, target)\nacc_XGB_Classifier = round(XGB_Classifier.score(train, target) * 100, 2)\nacc_XGB_Classifier",
            "mc_idx": 79,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.3333333333333333,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    34,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "94.39"
                    ]
                },
                "mc_idx": 79,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 34,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_XGB_Classifier.csv', index=False)\nLB_XGB_Classifier_all = 0.80861  # old version",
            "mc_idx": 80,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    35,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 80,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 35,
                "o_idx": 0
            }
        },
        {
            "source": "fig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nxgb.plot_importance(XGB_Classifier,ax = axes,height =0.5)\nplt.show();\nplt.close()",
            "mc_idx": 81,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {
                    ".add": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "plot_importance": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0039_c036_o000_image_0.png",
                    36,
                    0,
                    0
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1080x1080 with 1 Axes>"
                    ]
                },
                "mc_idx": 81,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 36,
                "o_idx": 0
            }
        },
        {
            "source": "### 5.11 LGBM Classifier <a class=\"anchor\" id=\"5.11\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 82,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Light GBM is a fast, distributed, high-performance gradient boosting framework based on decision tree algorithms. It splits the tree leaf wise with the best fit whereas other boosting algorithms split the tree depth wise or level wise rather than leaf-wise. So when growing on the same leaf in Light GBM, the leaf-wise algorithm can reduce more loss than the level-wise algorithm and hence results in much better accuracy which can rarely be achieved by any of the existing boosting algorithms. Also, it is surprisingly very fast, hence the word \u2018Light\u2019. Reference [Analytics Vidhya](https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/).",
            "mc_idx": 83,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "We will tuning the hyperparameters of the LGBMClassifier model using the HyperOpt and 10-fold crossvalidation",
            "mc_idx": 84,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "%%time\ndef hyperopt_lgb_score(params):\n    clf = LGBMClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_lgb = {\n            'learning_rate': hp.quniform('learning_rate', 0, 0.05, 0.0001),\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_depth':  hp.choice('max_depth', np.arange(4, 7, dtype=int)),\n            'num_leaves': hp.choice('num_leaves', 2*np.arange(20, 2**6, dtype=int)),\n            'min_child_weight': hp.quniform('min_child_weight', 1, 9, 0.025),\n            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.005),\n            'objective': 'binary',\n            'boosting_type': 'gbdt',\n            }\n \nbest = fmin(fn=hyperopt_lgb_score, space=space_lgb, algo=tpe.suggest, max_evals=10)\nprint('best:')\nprint(best)",
            "mc_idx": 85,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.16666666666666666,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {
                    "cross_val_score": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "hyperopt": 2,
                    "param": 3,
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    37,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0.9315664622895274\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.96, 'learning_rate': 0.0341, 'max_depth': 5, 'min_child_weight': 3.725, 'n_estimators': 488, 'num_leaves': 106, 'objective': 'binary'}\n0.9326964057923524\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.0455, 'max_depth': 6, 'min_child_weight': 3.225, 'n_estimators': 267, 'num_leaves': 62, 'objective': 'binary'}\n0.9259736639682359\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.635, 'learning_rate': 0.015300000000000001, 'max_depth': 6, 'min_child_weight': 4.675, 'n_estimators': 249, 'num_leaves': 116, 'objective': 'binary'}\n0.9315665332168706\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.625, 'learning_rate': 0.039900000000000005, 'max_depth': 6, 'min_child_weight': 5.300000000000001, 'n_estimators': 340, 'num_leaves': 56, 'objective': 'binary'}\n0.9349373906610676\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.59, 'learning_rate': 0.0483, 'max_depth': 6, 'min_child_weight': 5.800000000000001, 'n_estimators': 308, 'num_leaves': 58, 'objective': 'binary'}\n0.9315601852196638\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.0224, 'max_depth': 4, 'min_child_weight': 7.45, 'n_estimators': 697, 'num_leaves': 92, 'objective': 'binary'}\n0.9282146488369512\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.6, 'learning_rate': 0.0047, 'max_depth': 4, 'min_child_weight': 6.875, 'n_estimators': 982, 'num_leaves': 40, 'objective': 'binary'}\n0.9304492857084595\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.845, 'learning_rate': 0.0077, 'max_depth': 4, 'min_child_weight': 8.525, 'n_estimators': 816, 'num_leaves': 40, 'objective': 'binary'}\n0.931591783351012\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.8250000000000001, 'learning_rate': 0.0059, 'max_depth': 5, 'min_child_weight': 2.625, 'n_estimators': 735, 'num_leaves': 98, 'objective': 'binary'}\n0.936048361099615\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.98, 'learning_rate': 0.0281, 'max_depth': 4, 'min_child_weight': 6.8500000000000005, 'n_estimators': 828, 'num_leaves': 44, 'objective': 'binary'}\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:09<00:00,  1.00it/s, best loss: 0.9259736639682359]\nbest:\n{'colsample_bytree': 0.635, 'learning_rate': 0.015300000000000001, 'max_depth': 2, 'min_child_weight': 4.675, 'n_estimators': 149, 'num_leaves': 38}\nCPU times: user 9.68 s, sys: 760 ms, total: 10.4 s\nWall time: 10.4 s\n"
                    ]
                },
                "mc_idx": 85,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 37,
                "o_idx": 0
            }
        },
        {
            "source": "params = space_eval(space_lgb, best)\nparams",
            "mc_idx": 86,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    38,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "{'boosting_type': 'gbdt',\n 'colsample_bytree': 0.635,\n 'learning_rate': 0.015300000000000001,\n 'max_depth': 6,\n 'min_child_weight': 4.675,\n 'n_estimators': 249,\n 'num_leaves': 116,\n 'objective': 'binary'}"
                    ]
                },
                "mc_idx": 86,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 38,
                "o_idx": 0
            }
        },
        {
            "source": "LGB_Classifier = LGBMClassifier(**params)\nLGB_Classifier.fit(train, target)\nY_pred = LGB_Classifier.predict(test).astype(int)\nLGB_Classifier.score(train, target)\nacc_LGB_Classifier = round(LGB_Classifier.score(train, target) * 100, 2)\nacc_LGB_Classifier",
            "mc_idx": 87,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.3333333333333333,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    39,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "96.07"
                    ]
                },
                "mc_idx": 87,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 39,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_LGB_Classifier.csv', index=False)\nLB_LGB_Classifier_all = 0.82296  # old version",
            "mc_idx": 88,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    40,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 88,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 40,
                "o_idx": 0
            }
        },
        {
            "source": "fig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nlgb.plot_importance(LGB_Classifier,ax = axes,height = 0.5)\nplt.show();\nplt.close()",
            "mc_idx": 89,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {
                    ".add": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "plot_importance": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0039_c041_o000_image_1.png",
                    41,
                    0,
                    1
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1080x1080 with 1 Axes>"
                    ]
                },
                "mc_idx": 89,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 41,
                "o_idx": 0
            }
        },
        {
            "source": "### 5.12 GradientBoostingClassifier <a class=\"anchor\" id=\"5.12\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 90,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/kabure/titanic-eda-model-pipeline-keras-nn",
            "mc_idx": 91,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Gradient Boosting** builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage n_classes_ regression trees are fit on the negative gradient of the binomial or multinomial deviance loss function. Binary classification is a special case where only a single regression tree is induced. The features are always randomly permuted at each split. Therefore, the best found split may vary, even with the same training data and max_features=n_features, if the improvement of the criterion is identical for several splits enumerated during the search of the best split. To obtain a deterministic behaviour during fitting, random_state has to be fixed. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html).",
            "mc_idx": 92,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "%%time\ndef hyperopt_gb_score(params):\n    clf = GradientBoostingClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_gb = {\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_depth': hp.choice('max_depth', np.arange(5, 8, dtype=int))            \n        }\n \nbest = fmin(fn=hyperopt_gb_score, space=space_gb, algo=tpe.suggest, max_evals=10)\nprint('best:')\nprint(best)",
            "mc_idx": 93,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 0.0,
                "Model_Train": 0.16666666666666666,
                "Model_Evaluation": 0.16666666666666666,
                "Model_Interpretation": 0.16666666666666666,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "cross_val_score": 1
                },
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {
                    "hyperopt": 2,
                    "param": 3,
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    42,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0.9349372488063814\n{'max_depth': 7, 'n_estimators': 412}\n0.9315664622895274\n{'max_depth': 6, 'n_estimators': 644}\n0.9338073053035565\n{'max_depth': 7, 'n_estimators': 721}\n0.9371466355437486\n{'max_depth': 5, 'n_estimators': 269}\n0.9326837807252817\n{'max_depth': 6, 'n_estimators': 271}\n0.9326900577951454\n{'max_depth': 6, 'n_estimators': 414}\n0.9371593315381623\n{'max_depth': 5, 'n_estimators': 867}\n0.9338073762308996\n{'max_depth': 6, 'n_estimators': 441}\n0.9326837097979386\n{'max_depth': 7, 'n_estimators': 632}\n0.9349309008091746\n{'max_depth': 7, 'n_estimators': 656}\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:32<00:00,  3.28s/it, best loss: 0.9315664622895274]\nbest:\n{'max_depth': 1, 'n_estimators': 544}\nCPU times: user 33.2 s, sys: 72.1 ms, total: 33.2 s\nWall time: 33.2 s\n"
                    ]
                },
                "mc_idx": 93,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 42,
                "o_idx": 0
            }
        },
        {
            "source": "params = space_eval(space_gb, best)\nparams",
            "mc_idx": 94,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    43,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "{'max_depth': 6, 'n_estimators': 644}"
                    ]
                },
                "mc_idx": 94,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 43,
                "o_idx": 0
            }
        },
        {
            "source": "# Gradient Boosting Classifier\n\ngradient_boosting = GradientBoostingClassifier(**params)\ngradient_boosting.fit(train, target)\nY_pred = gradient_boosting.predict(test).astype(int)\ngradient_boosting.score(train, target)\nacc_gradient_boosting = round(gradient_boosting.score(train, target) * 100, 2)\nacc_gradient_boosting",
            "mc_idx": 95,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.1111111111111111,
                "Model_Train": 0.2222222222222222,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.1111111111111111,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "gradient": 9
                },
                "Hyperparameter_Tuning": {
                    "param": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    44,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "100.0"
                    ]
                },
                "mc_idx": 95,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 44,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_gradient_boosting.csv', index=False)\nLB_GBC_all = 0.82296  # old version",
            "mc_idx": 96,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    45,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 96,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 45,
                "o_idx": 0
            }
        },
        {
            "source": "### 5.13 RidgeClassifier <a class=\"anchor\" id=\"5.13\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 97,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/kabure/titanic-eda-model-pipeline-keras-nn",
            "mc_idx": 98,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Tikhonov Regularization, colloquially known as **Ridge Regression**, is the most commonly used regression algorithm to approximate an answer for an equation with no unique solution. This type of problem is very common in machine learning tasks, where the \"best\" solution must be chosen using limited data. If a unique solution exists, algorithm will return the optimal value. However, if multiple solutions exist, it may choose any of them. Reference [Brilliant.org](https://brilliant.org/wiki/ridge-regression/).",
            "mc_idx": 99,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Ridge Classifier\n\nridge_classifier = RidgeClassifier()\nridge_classifier.fit(train, target)\nY_pred = ridge_classifier.predict(test).astype(int)\nridge_classifier.score(train, target)\nacc_ridge_classifier = round(ridge_classifier.score(train, target) * 100, 2)\nacc_ridge_classifier",
            "mc_idx": 100,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.1,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.3,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "ridge": 9
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    46,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "93.15"
                    ]
                },
                "mc_idx": 100,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 46,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_ridge_classifier.csv', index=False)\nLB_RidgeClassifier_all = 0.80861  # old version",
            "mc_idx": 101,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "ridge": 2
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    47,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 101,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 47,
                "o_idx": 0
            }
        },
        {
            "source": "### 5.14 BaggingClassifier <a class=\"anchor\" id=\"5.14\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 102,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/kabure/titanic-eda-model-pipeline-keras-nn",
            "mc_idx": 103,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Bootstrap aggregating, also called **bagging**, is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It also reduces variance and helps to avoid overfitting. Although it is usually applied to decision tree methods, it can be used with any type of method. Bagging is a special case of the model averaging approach. Bagging leads to \"improvements for unstable procedures\", which include, for example, artificial neural networks, classification and regression trees, and subset selection in linear regression. On the other hand, it can mildly degrade the performance of stable methods such as K-nearest neighbors. Reference [Wikipedia](https://en.wikipedia.org/wiki/Bootstrap_aggregating).\n\nA **Bagging classifier** is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html).",
            "mc_idx": 104,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Bagging Classifier\n\nbagging_classifier = BaggingClassifier()\nbagging_classifier.fit(train, target)\nY_pred = bagging_classifier.predict(test).astype(int)\nbagging_classifier.score(train, target)\nacc_bagging_classifier = round(bagging_classifier.score(train, target) * 100, 2)\nacc_bagging_classifier",
            "mc_idx": 105,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    48,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "99.66"
                    ]
                },
                "mc_idx": 105,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 48,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_bagging_classifier.csv', index=False)\nLB_bagging_classifier_all = 0.80861  # old version",
            "mc_idx": 106,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    49,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 106,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 49,
                "o_idx": 0
            }
        },
        {
            "source": "### 5.15 ExtraTreesClassifier <a class=\"anchor\" id=\"5.15\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 107,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/kabure/titanic-eda-model-pipeline-keras-nn",
            "mc_idx": 108,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**ExtraTreesClassifier** implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The default values for the parameters controlling the size of the trees (e.g. max_depth, min_samples_leaf, etc.) lead to fully grown and unpruned trees which can potentially be very large on some data sets. To reduce memory consumption, the complexity and size of the trees should be controlled by setting those parameter values. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html). \n\nIn extremely randomized trees, randomness goes one step further in the way splits are computed. As in random forests, a random subset of candidate features is used, but instead of looking for the most discriminative thresholds, thresholds are drawn at random for each candidate feature and the best of these randomly-generated thresholds is picked as the splitting rule. This usually allows to reduce the variance of the model a bit more, at the expense of a slightly greater increase in bias. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/ensemble.html#Extremely%20Randomized%20Trees).",
            "mc_idx": 109,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "def hyperopt_etc_score(params):\n    clf = ExtraTreesClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_etc = {\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_features': hp.choice('max_features', np.arange(2, 10, dtype=int)),\n            'min_samples_leaf': hp.choice('min_samples_leaf', np.arange(1, 5, dtype=int)),\n            'max_depth':  hp.choice('max_depth', np.arange(4, 8, dtype=int)),\n        }\n \nbest = fmin(fn=hyperopt_etc_score, space=space_etc, algo=tpe.suggest, max_evals=10)\nprint('best:')\nprint(best)",
            "mc_idx": 110,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.16666666666666666,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {
                    "cross_val_score": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "hyperopt": 2,
                    "param": 3,
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    50,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0.9293508694096397\n{'max_depth': 5, 'max_features': 3, 'min_samples_leaf': 4, 'n_estimators': 699}\n0.9372098318064449\n{'max_depth': 7, 'max_features': 8, 'min_samples_leaf': 2, 'n_estimators': 181}\n0.9383145961024715\n{'max_depth': 5, 'max_features': 8, 'min_samples_leaf': 3, 'n_estimators': 671}\n0.9405617871137075\n{'max_depth': 6, 'max_features': 4, 'min_samples_leaf': 1, 'n_estimators': 662}\n0.9394444686779533\n{'max_depth': 7, 'max_features': 4, 'min_samples_leaf': 2, 'n_estimators': 440}\n0.9349626407952091\n{'max_depth': 7, 'max_features': 9, 'min_samples_leaf': 2, 'n_estimators': 838}\n0.932715449783973\n{'max_depth': 4, 'max_features': 6, 'min_samples_leaf': 3, 'n_estimators': 742}\n0.9383208731723354\n{'max_depth': 6, 'max_features': 5, 'min_samples_leaf': 2, 'n_estimators': 336}\n0.9315981313482189\n{'max_depth': 4, 'max_features': 6, 'min_samples_leaf': 3, 'n_estimators': 191}\n0.928220925906815\n{'max_depth': 4, 'max_features': 4, 'min_samples_leaf': 3, 'n_estimators': 622}\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:27<00:00,  2.80s/it, best loss: 0.928220925906815]\nbest:\n{'max_depth': 0, 'max_features': 2, 'min_samples_leaf': 2, 'n_estimators': 522}\n"
                    ]
                },
                "mc_idx": 110,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 50,
                "o_idx": 0
            }
        },
        {
            "source": "params = space_eval(space_etc, best)\nparams",
            "mc_idx": 111,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    51,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "{'max_depth': 4, 'max_features': 4, 'min_samples_leaf': 3, 'n_estimators': 622}"
                    ]
                },
                "mc_idx": 111,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 51,
                "o_idx": 0
            }
        },
        {
            "source": "# Extra Trees Classifier\n\nextra_trees_classifier = ExtraTreesClassifier(**params)\nextra_trees_classifier.fit(train, target)\nY_pred = extra_trees_classifier.predict(test).astype(int)\nextra_trees_classifier.score(train, target)\nacc_etc = round(extra_trees_classifier.score(train, target) * 100, 2)\nacc_etc",
            "mc_idx": 112,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.3333333333333333,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    52,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "93.38"
                    ]
                },
                "mc_idx": 112,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 52,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_etc.csv', index=False)\nLB_ETC_all = 0.80861  # old version",
            "mc_idx": 113,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    53,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 113,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 53,
                "o_idx": 0
            }
        },
        {
            "source": "### 5.16 Neural Network 1 <a class=\"anchor\" id=\"5.16\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 114,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/nhlr21/complete-titanic-tutorial-with-ml-nn-ensembling",
            "mc_idx": 115,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Neural networks** are more complex and more powerful algorithm than standars machine learning, it belongs to deep learning models. To build a neural network use Keras. Keras is a high level API for tensorflow, which is a tensor-manipulation framework made by google. Keras allows you to build neural networks by assembling blocks (which are the layers of neural network). ",
            "mc_idx": 116,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "def build_ann(optimizer='adam'):\n    \n    # Initializing the ANN\n    ann = Sequential()\n    \n    # Adding the input layer and the first hidden layer of the ANN with dropout\n    ann.add(Dense(units=32, kernel_initializer='glorot_uniform', activation='relu', input_shape=(16,)))\n    \n    # Add other layers, it is not necessary to pass the shape because there is a layer before\n    ann.add(Dense(units=64, kernel_initializer='glorot_uniform', activation='relu'))\n    ann.add(Dropout(rate=0.5))\n    ann.add(Dense(units=64, kernel_initializer='glorot_uniform', activation='relu'))\n    ann.add(Dropout(rate=0.5))\n    \n    # Adding the output layer\n    ann.add(Dense(units=1, kernel_initializer='glorot_uniform', activation='sigmoid'))\n    \n    # Compiling the ANN\n    ann.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return ann",
            "mc_idx": 117,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 1.0,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.3333333333333333,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "shape": 2
                },
                "Data_Transform": {
                    ".add": 6
                },
                "Model_Train": {
                    "sequential(": 1,
                    "compile": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    54,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 117,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 54,
                "o_idx": 0
            }
        },
        {
            "source": "opt = optimizers.Adam(lr=0.001)\nann = build_ann(opt)\n# Training the ANN\nhistory = ann.fit(Xtrain, Ztrain, batch_size=16, epochs=100, validation_data=(Xval, Zval))",
            "mc_idx": 118,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    55,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Train on 623 samples, validate on 268 samples\nEpoch 1/100\n623/623 [==============================] - 0s 748us/step - loss: 11.0590 - accuracy: 0.5457 - val_loss: 4.8565 - val_accuracy: 0.5933\nEpoch 2/100\n623/623 [==============================] - 0s 206us/step - loss: 5.2457 - accuracy: 0.5201 - val_loss: 2.2716 - val_accuracy: 0.6194\nEpoch 3/100\n623/623 [==============================] - 0s 176us/step - loss: 3.1837 - accuracy: 0.5409 - val_loss: 1.0874 - val_accuracy: 0.6530\nEpoch 4/100\n623/623 [==============================] - 0s 169us/step - loss: 1.6270 - accuracy: 0.5730 - val_loss: 0.7815 - val_accuracy: 0.6530\nEpoch 5/100\n623/623 [==============================] - 0s 166us/step - loss: 1.1755 - accuracy: 0.5827 - val_loss: 0.6427 - val_accuracy: 0.6604\nEpoch 6/100\n623/623 [==============================] - 0s 183us/step - loss: 0.8752 - accuracy: 0.5618 - val_loss: 0.6425 - val_accuracy: 0.6716\nEpoch 7/100\n623/623 [==============================] - 0s 174us/step - loss: 0.8974 - accuracy: 0.6260 - val_loss: 0.6614 - val_accuracy: 0.6455\nEpoch 8/100\n623/623 [==============================] - 0s 169us/step - loss: 0.7519 - accuracy: 0.6356 - val_loss: 0.6508 - val_accuracy: 0.6493\nEpoch 9/100\n623/623 [==============================] - 0s 169us/step - loss: 0.6961 - accuracy: 0.6388 - val_loss: 0.6594 - val_accuracy: 0.6306\nEpoch 10/100\n623/623 [==============================] - 0s 171us/step - loss: 0.6912 - accuracy: 0.6517 - val_loss: 0.6613 - val_accuracy: 0.6231\nEpoch 11/100\n623/623 [==============================] - 0s 165us/step - loss: 0.6821 - accuracy: 0.6549 - val_loss: 0.6417 - val_accuracy: 0.6493\nEpoch 12/100\n623/623 [==============================] - 0s 172us/step - loss: 0.6512 - accuracy: 0.6501 - val_loss: 0.6608 - val_accuracy: 0.6306\nEpoch 13/100\n623/623 [==============================] - 0s 170us/step - loss: 0.6699 - accuracy: 0.6453 - val_loss: 0.6591 - val_accuracy: 0.6157\nEpoch 14/100\n623/623 [==============================] - 0s 167us/step - loss: 0.6647 - accuracy: 0.6372 - val_loss: 0.6449 - val_accuracy: 0.6269\nEpoch 15/100\n623/623 [==============================] - 0s 167us/step - loss: 0.6707 - accuracy: 0.6404 - val_loss: 0.6637 - val_accuracy: 0.6269\nEpoch 16/100\n623/623 [==============================] - 0s 163us/step - loss: 0.6492 - accuracy: 0.6437 - val_loss: 0.6473 - val_accuracy: 0.6269\nEpoch 17/100\n623/623 [==============================] - 0s 162us/step - loss: 0.6424 - accuracy: 0.6469 - val_loss: 0.6348 - val_accuracy: 0.6269\nEpoch 18/100\n623/623 [==============================] - 0s 168us/step - loss: 0.6774 - accuracy: 0.6485 - val_loss: 0.6330 - val_accuracy: 0.6343\nEpoch 19/100\n623/623 [==============================] - 0s 170us/step - loss: 0.6586 - accuracy: 0.6485 - val_loss: 0.6482 - val_accuracy: 0.6343\nEpoch 20/100\n623/623 [==============================] - 0s 174us/step - loss: 0.6413 - accuracy: 0.6421 - val_loss: 0.6609 - val_accuracy: 0.6343\nEpoch 21/100\n623/623 [==============================] - 0s 162us/step - loss: 0.6555 - accuracy: 0.6421 - val_loss: 0.6599 - val_accuracy: 0.6269\nEpoch 22/100\n623/623 [==============================] - 0s 165us/step - loss: 0.6493 - accuracy: 0.6501 - val_loss: 0.6624 - val_accuracy: 0.6269\nEpoch 23/100\n623/623 [==============================] - 0s 171us/step - loss: 0.6365 - accuracy: 0.6485 - val_loss: 0.6577 - val_accuracy: 0.6231\nEpoch 24/100\n623/623 [==============================] - 0s 164us/step - loss: 0.6527 - accuracy: 0.6421 - val_loss: 0.6573 - val_accuracy: 0.6269\nEpoch 25/100\n623/623 [==============================] - 0s 156us/step - loss: 0.6244 - accuracy: 0.6581 - val_loss: 0.6487 - val_accuracy: 0.6306\nEpoch 26/100\n623/623 [==============================] - 0s 165us/step - loss: 0.6698 - accuracy: 0.6292 - val_loss: 0.6261 - val_accuracy: 0.6231\nEpoch 27/100\n623/623 [==============================] - 0s 162us/step - loss: 0.6253 - accuracy: 0.6421 - val_loss: 0.6424 - val_accuracy: 0.6231\nEpoch 28/100\n623/623 [==============================] - 0s 164us/step - loss: 0.6429 - accuracy: 0.6469 - val_loss: 0.6655 - val_accuracy: 0.6269\nEpoch 29/100\n623/623 [==============================] - 0s 161us/step - loss: 0.6374 - accuracy: 0.6581 - val_loss: 0.6632 - val_accuracy: 0.6343\nEpoch 30/100\n623/623 [==============================] - 0s 158us/step - loss: 0.6436 - accuracy: 0.6565 - val_loss: 0.6608 - val_accuracy: 0.6343\nEpoch 31/100\n623/623 [==============================] - 0s 164us/step - loss: 0.6333 - accuracy: 0.6661 - val_loss: 0.6528 - val_accuracy: 0.6418\nEpoch 32/100\n623/623 [==============================] - 0s 167us/step - loss: 0.6457 - accuracy: 0.6404 - val_loss: 0.6433 - val_accuracy: 0.6306\nEpoch 33/100\n623/623 [==============================] - 0s 165us/step - loss: 0.6389 - accuracy: 0.6485 - val_loss: 0.6252 - val_accuracy: 0.6269\nEpoch 34/100\n623/623 [==============================] - 0s 168us/step - loss: 0.6245 - accuracy: 0.6693 - val_loss: 0.6086 - val_accuracy: 0.6604\nEpoch 35/100\n623/623 [==============================] - 0s 156us/step - loss: 0.6418 - accuracy: 0.6629 - val_loss: 0.6431 - val_accuracy: 0.6381\nEpoch 36/100\n623/623 [==============================] - 0s 164us/step - loss: 0.6253 - accuracy: 0.6709 - val_loss: 0.5964 - val_accuracy: 0.6567\nEpoch 37/100\n623/623 [==============================] - 0s 164us/step - loss: 0.6105 - accuracy: 0.6613 - val_loss: 0.5954 - val_accuracy: 0.6530\nEpoch 38/100\n623/623 [==============================] - 0s 157us/step - loss: 0.6199 - accuracy: 0.6581 - val_loss: 0.6227 - val_accuracy: 0.6381\nEpoch 39/100\n623/623 [==============================] - 0s 164us/step - loss: 0.6284 - accuracy: 0.6629 - val_loss: 0.6481 - val_accuracy: 0.6418\nEpoch 40/100\n623/623 [==============================] - 0s 157us/step - loss: 0.6320 - accuracy: 0.6581 - val_loss: 0.6233 - val_accuracy: 0.6530\nEpoch 41/100\n623/623 [==============================] - 0s 169us/step - loss: 0.5928 - accuracy: 0.6597 - val_loss: 0.6018 - val_accuracy: 0.6455\nEpoch 42/100\n623/623 [==============================] - 0s 167us/step - loss: 0.6154 - accuracy: 0.6565 - val_loss: 0.6165 - val_accuracy: 0.6306\nEpoch 43/100\n623/623 [==============================] - 0s 164us/step - loss: 0.5999 - accuracy: 0.6581 - val_loss: 0.6204 - val_accuracy: 0.6381\nEpoch 44/100\n623/623 [==============================] - 0s 170us/step - loss: 0.6221 - accuracy: 0.6613 - val_loss: 0.6560 - val_accuracy: 0.6306\nEpoch 45/100\n623/623 [==============================] - 0s 164us/step - loss: 0.6177 - accuracy: 0.6870 - val_loss: 0.6413 - val_accuracy: 0.6604\nEpoch 46/100\n623/623 [==============================] - 0s 201us/step - loss: 0.6250 - accuracy: 0.6645 - val_loss: 0.6308 - val_accuracy: 0.6567\nEpoch 47/100\n623/623 [==============================] - 0s 186us/step - loss: 0.6188 - accuracy: 0.6661 - val_loss: 0.5917 - val_accuracy: 0.6493\nEpoch 48/100\n623/623 [==============================] - 0s 193us/step - loss: 0.6194 - accuracy: 0.6677 - val_loss: 0.6603 - val_accuracy: 0.6418\nEpoch 49/100\n623/623 [==============================] - 0s 183us/step - loss: 0.6269 - accuracy: 0.6693 - val_loss: 0.6581 - val_accuracy: 0.6269\nEpoch 50/100\n623/623 [==============================] - 0s 183us/step - loss: 0.6161 - accuracy: 0.6629 - val_loss: 0.5938 - val_accuracy: 0.6716\nEpoch 51/100\n623/623 [==============================] - 0s 181us/step - loss: 0.5908 - accuracy: 0.6726 - val_loss: 0.6082 - val_accuracy: 0.6418\nEpoch 52/100\n623/623 [==============================] - 0s 191us/step - loss: 0.5905 - accuracy: 0.6661 - val_loss: 0.6110 - val_accuracy: 0.6530\nEpoch 53/100\n623/623 [==============================] - 0s 181us/step - loss: 0.6012 - accuracy: 0.6726 - val_loss: 0.6438 - val_accuracy: 0.6642\nEpoch 54/100\n623/623 [==============================] - 0s 182us/step - loss: 0.6238 - accuracy: 0.6806 - val_loss: 0.6298 - val_accuracy: 0.6791\nEpoch 55/100\n623/623 [==============================] - 0s 167us/step - loss: 0.6283 - accuracy: 0.6790 - val_loss: 0.5868 - val_accuracy: 0.6530\nEpoch 56/100\n623/623 [==============================] - 0s 159us/step - loss: 0.5815 - accuracy: 0.6693 - val_loss: 0.6013 - val_accuracy: 0.6455\nEpoch 57/100\n623/623 [==============================] - 0s 167us/step - loss: 0.6193 - accuracy: 0.6613 - val_loss: 0.6136 - val_accuracy: 0.6269\nEpoch 58/100\n623/623 [==============================] - 0s 163us/step - loss: 0.6023 - accuracy: 0.6677 - val_loss: 0.5653 - val_accuracy: 0.6679\nEpoch 59/100\n623/623 [==============================] - 0s 159us/step - loss: 0.5933 - accuracy: 0.6902 - val_loss: 0.5942 - val_accuracy: 0.6530\nEpoch 60/100\n623/623 [==============================] - 0s 156us/step - loss: 0.5916 - accuracy: 0.6677 - val_loss: 0.5656 - val_accuracy: 0.6791\nEpoch 61/100\n623/623 [==============================] - 0s 168us/step - loss: 0.5677 - accuracy: 0.6758 - val_loss: 0.6210 - val_accuracy: 0.6716\nEpoch 62/100\n623/623 [==============================] - 0s 166us/step - loss: 0.5659 - accuracy: 0.6950 - val_loss: 0.5651 - val_accuracy: 0.6493\nEpoch 63/100\n623/623 [==============================] - 0s 160us/step - loss: 0.5551 - accuracy: 0.6806 - val_loss: 0.5672 - val_accuracy: 0.6791\nEpoch 64/100\n623/623 [==============================] - 0s 159us/step - loss: 0.5967 - accuracy: 0.7014 - val_loss: 0.6415 - val_accuracy: 0.6493\nEpoch 65/100\n623/623 [==============================] - 0s 162us/step - loss: 0.5943 - accuracy: 0.6838 - val_loss: 0.6288 - val_accuracy: 0.6418\nEpoch 66/100\n623/623 [==============================] - 0s 169us/step - loss: 0.5929 - accuracy: 0.6902 - val_loss: 0.6604 - val_accuracy: 0.6418\nEpoch 67/100\n623/623 [==============================] - 0s 159us/step - loss: 0.6062 - accuracy: 0.6581 - val_loss: 0.5817 - val_accuracy: 0.6642\nEpoch 68/100\n623/623 [==============================] - 0s 163us/step - loss: 0.5646 - accuracy: 0.7159 - val_loss: 0.5792 - val_accuracy: 0.6679\nEpoch 69/100\n623/623 [==============================] - 0s 158us/step - loss: 0.5813 - accuracy: 0.7159 - val_loss: 0.6136 - val_accuracy: 0.8134\nEpoch 70/100\n623/623 [==============================] - 0s 160us/step - loss: 0.5916 - accuracy: 0.7030 - val_loss: 0.5700 - val_accuracy: 0.6567\nEpoch 71/100\n623/623 [==============================] - 0s 165us/step - loss: 0.5584 - accuracy: 0.7014 - val_loss: 0.5374 - val_accuracy: 0.6903\nEpoch 72/100\n623/623 [==============================] - 0s 165us/step - loss: 0.5562 - accuracy: 0.7287 - val_loss: 0.5613 - val_accuracy: 0.6828\nEpoch 73/100\n623/623 [==============================] - 0s 160us/step - loss: 0.5631 - accuracy: 0.6742 - val_loss: 0.6013 - val_accuracy: 0.6343\nEpoch 74/100\n623/623 [==============================] - 0s 175us/step - loss: 0.5841 - accuracy: 0.7014 - val_loss: 0.5745 - val_accuracy: 0.7836\nEpoch 75/100\n623/623 [==============================] - 0s 159us/step - loss: 0.5783 - accuracy: 0.7063 - val_loss: 0.5170 - val_accuracy: 0.7425\nEpoch 76/100\n623/623 [==============================] - 0s 169us/step - loss: 0.5433 - accuracy: 0.6838 - val_loss: 0.5659 - val_accuracy: 0.6567\nEpoch 77/100\n623/623 [==============================] - 0s 159us/step - loss: 0.5299 - accuracy: 0.7255 - val_loss: 0.5275 - val_accuracy: 0.8060\nEpoch 78/100\n623/623 [==============================] - 0s 159us/step - loss: 0.5303 - accuracy: 0.7287 - val_loss: 0.5114 - val_accuracy: 0.7239\nEpoch 79/100\n623/623 [==============================] - 0s 170us/step - loss: 0.5322 - accuracy: 0.7127 - val_loss: 0.4695 - val_accuracy: 0.7612\nEpoch 80/100\n623/623 [==============================] - 0s 169us/step - loss: 0.4957 - accuracy: 0.7496 - val_loss: 0.4377 - val_accuracy: 0.8507\nEpoch 81/100\n623/623 [==============================] - 0s 173us/step - loss: 0.5046 - accuracy: 0.7448 - val_loss: 0.4392 - val_accuracy: 0.8246\nEpoch 82/100\n623/623 [==============================] - 0s 159us/step - loss: 0.4840 - accuracy: 0.7368 - val_loss: 0.4791 - val_accuracy: 0.7948\nEpoch 83/100\n623/623 [==============================] - 0s 174us/step - loss: 0.5155 - accuracy: 0.7512 - val_loss: 0.3824 - val_accuracy: 0.8358\nEpoch 84/100\n623/623 [==============================] - 0s 161us/step - loss: 0.5019 - accuracy: 0.7223 - val_loss: 0.4909 - val_accuracy: 0.7164\nEpoch 85/100\n623/623 [==============================] - 0s 218us/step - loss: 0.5393 - accuracy: 0.7239 - val_loss: 0.6398 - val_accuracy: 0.6940\nEpoch 86/100\n623/623 [==============================] - 0s 178us/step - loss: 0.5693 - accuracy: 0.7416 - val_loss: 0.5782 - val_accuracy: 0.7612\nEpoch 87/100\n623/623 [==============================] - 0s 159us/step - loss: 0.5785 - accuracy: 0.7191 - val_loss: 0.5697 - val_accuracy: 0.7425\nEpoch 88/100\n623/623 [==============================] - 0s 170us/step - loss: 0.5150 - accuracy: 0.7223 - val_loss: 0.4088 - val_accuracy: 0.8209\nEpoch 89/100\n623/623 [==============================] - 0s 169us/step - loss: 0.4400 - accuracy: 0.7881 - val_loss: 0.3991 - val_accuracy: 0.8955\nEpoch 90/100\n623/623 [==============================] - 0s 169us/step - loss: 0.5006 - accuracy: 0.7528 - val_loss: 0.6254 - val_accuracy: 0.6716\nEpoch 91/100\n623/623 [==============================] - 0s 152us/step - loss: 0.5478 - accuracy: 0.6934 - val_loss: 0.3992 - val_accuracy: 0.8694\nEpoch 92/100\n623/623 [==============================] - 0s 155us/step - loss: 0.5405 - accuracy: 0.7030 - val_loss: 0.6259 - val_accuracy: 0.6567\nEpoch 93/100\n623/623 [==============================] - 0s 158us/step - loss: 0.5793 - accuracy: 0.6806 - val_loss: 0.5835 - val_accuracy: 0.7052\nEpoch 94/100\n623/623 [==============================] - 0s 162us/step - loss: 0.5030 - accuracy: 0.7368 - val_loss: 0.4124 - val_accuracy: 0.8396\nEpoch 95/100\n623/623 [==============================] - 0s 172us/step - loss: 0.4738 - accuracy: 0.7384 - val_loss: 0.3676 - val_accuracy: 0.8955\nEpoch 96/100\n623/623 [==============================] - 0s 158us/step - loss: 0.4600 - accuracy: 0.7560 - val_loss: 0.4546 - val_accuracy: 0.8246\nEpoch 97/100\n623/623 [==============================] - 0s 159us/step - loss: 0.4367 - accuracy: 0.7592 - val_loss: 0.4510 - val_accuracy: 0.7313\nEpoch 98/100\n623/623 [==============================] - 0s 160us/step - loss: 0.4647 - accuracy: 0.7464 - val_loss: 0.4317 - val_accuracy: 0.7127\nEpoch 99/100\n623/623 [==============================] - 0s 157us/step - loss: 0.4410 - accuracy: 0.7560 - val_loss: 0.4406 - val_accuracy: 0.7873\nEpoch 100/100\n623/623 [==============================] - 0s 162us/step - loss: 0.4995 - accuracy: 0.7544 - val_loss: 0.4734 - val_accuracy: 0.8881\n"
                    ]
                },
                "mc_idx": 118,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 55,
                "o_idx": 0
            }
        },
        {
            "source": "# Predicting the Test set results\nY_pred = ann.predict(test)\nY_pred = (Y_pred > 0.5)*1 # convert probabilities to binary output",
            "mc_idx": 119,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    56,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 119,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 56,
                "o_idx": 0
            }
        },
        {
            "source": "# Predicting the Train set results\nann_prediction = ann.predict(train)\nann_prediction = (ann_prediction > 0.5)*1 # convert probabilities to binary output\n\n# Compute error between predicted data and true response and display it in confusion matrix\nacc_ann1 = round(metrics.accuracy_score(target, ann_prediction) * 100, 2)\nacc_ann1",
            "mc_idx": 120,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {
                    "accuracy_score": 2,
                    ".predict(": 1,
                    ".accuracy": 1,
                    "metrics.accuracy": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    57,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "90.35"
                    ]
                },
                "mc_idx": 120,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 57,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": np.reshape(Y_pred, len(Y_pred))})\n#submission.to_csv('output/submission_ann1.csv', index=False)\nLB_ann1_all = 0.59330  # old version",
            "mc_idx": 121,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 0.5,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "shape": 1
                },
                "Data_Transform": {
                    ".reshape": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    58,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 121,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 58,
                "o_idx": 0
            }
        },
        {
            "source": "### 5.17 Neural Network 2 <a class=\"anchor\" id=\"5.17\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 122,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/junheeshin/titanic-analyze-and-predict-nn",
            "mc_idx": 123,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Model\nmodel = Sequential()\nmodel.add(Dense(16, input_dim = train.shape[1], init = 'he_normal', activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64, init = 'he_normal', activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(32, init = 'he_normal', activation = 'relu'))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.summary()",
            "mc_idx": 124,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.18181818181818182,
                "Data_Transform": 0.5454545454545454,
                "Model_Train": 0.9090909090909091,
                "Model_Evaluation": 0.8181818181818182,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "shape": 1,
                    ".sum": 1
                },
                "Data_Transform": {
                    ".add": 6
                },
                "Model_Train": {
                    "sequential(": 1,
                    "model": 9
                },
                "Model_Evaluation": {
                    "model": 9
                },
                "Model_Interpretation": {
                    "shap": 1,
                    "model": 9,
                    "summary": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    59,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_5 (Dense)              (None, 16)                272       \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 16)                0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 64)                1088      \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 64)                0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 32)                2080      \n_________________________________________________________________\ndense_8 (Dense)              (None, 1)                 33        \n=================================================================\nTotal params: 3,473\nTrainable params: 3,473\nNon-trainable params: 0\n_________________________________________________________________\n",
                        "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, input_dim=16, activation=\"relu\", kernel_initializer=\"he_normal\")`\n  This is separate from the ipykernel package so we can avoid doing imports until\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")`\n  \"\"\"\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")`\n  import sys\n"
                    ]
                },
                "mc_idx": 124,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 59,
                "o_idx": 1
            }
        },
        {
            "source": "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])",
            "mc_idx": 125,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "compile": 1,
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    60,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 125,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 60,
                "o_idx": 0
            }
        },
        {
            "source": "es = EarlyStopping(monitor='val_accuracy', patience=20, mode='max')\nhist = model.fit(train, target, batch_size=64, validation_data=(Xval, Zval), \n               epochs=500, verbose=1, callbacks=[es])",
            "mc_idx": 126,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 0.3333333333333333,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model.fit": 1,
                    ".fit(": 1,
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    61,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Train on 891 samples, validate on 268 samples\nEpoch 1/500\n891/891 [==============================] - 0s 374us/step - loss: 25.0711 - accuracy: 0.5309 - val_loss: 9.7298 - val_accuracy: 0.3806\nEpoch 2/500\n891/891 [==============================] - 0s 52us/step - loss: 18.0006 - accuracy: 0.5477 - val_loss: 2.6885 - val_accuracy: 0.5075\nEpoch 3/500\n891/891 [==============================] - 0s 51us/step - loss: 12.9629 - accuracy: 0.5387 - val_loss: 1.2955 - val_accuracy: 0.6455\nEpoch 4/500\n891/891 [==============================] - 0s 48us/step - loss: 12.3413 - accuracy: 0.5230 - val_loss: 3.8303 - val_accuracy: 0.4925\nEpoch 5/500\n891/891 [==============================] - 0s 49us/step - loss: 10.6057 - accuracy: 0.5668 - val_loss: 4.7341 - val_accuracy: 0.4925\nEpoch 6/500\n891/891 [==============================] - 0s 48us/step - loss: 8.8485 - accuracy: 0.5511 - val_loss: 1.0228 - val_accuracy: 0.6455\nEpoch 7/500\n891/891 [==============================] - 0s 56us/step - loss: 8.1929 - accuracy: 0.5657 - val_loss: 0.8268 - val_accuracy: 0.6940\nEpoch 8/500\n891/891 [==============================] - 0s 46us/step - loss: 7.2472 - accuracy: 0.5859 - val_loss: 4.6903 - val_accuracy: 0.4739\nEpoch 9/500\n891/891 [==============================] - 0s 49us/step - loss: 8.0046 - accuracy: 0.5488 - val_loss: 4.4030 - val_accuracy: 0.4851\nEpoch 10/500\n891/891 [==============================] - 0s 49us/step - loss: 6.5279 - accuracy: 0.5421 - val_loss: 1.1221 - val_accuracy: 0.5597\nEpoch 11/500\n891/891 [==============================] - 0s 44us/step - loss: 5.3860 - accuracy: 0.5780 - val_loss: 0.7990 - val_accuracy: 0.6418\nEpoch 12/500\n891/891 [==============================] - 0s 46us/step - loss: 5.9367 - accuracy: 0.5443 - val_loss: 1.7462 - val_accuracy: 0.5112\nEpoch 13/500\n891/891 [==============================] - 0s 47us/step - loss: 5.2609 - accuracy: 0.5499 - val_loss: 1.9253 - val_accuracy: 0.5037\nEpoch 14/500\n891/891 [==============================] - 0s 45us/step - loss: 5.0915 - accuracy: 0.5432 - val_loss: 1.2492 - val_accuracy: 0.5112\nEpoch 15/500\n891/891 [==============================] - 0s 47us/step - loss: 4.4295 - accuracy: 0.5600 - val_loss: 1.2512 - val_accuracy: 0.4813\nEpoch 16/500\n891/891 [==============================] - 0s 50us/step - loss: 4.1835 - accuracy: 0.5668 - val_loss: 1.0897 - val_accuracy: 0.4888\nEpoch 17/500\n891/891 [==============================] - 0s 50us/step - loss: 4.4014 - accuracy: 0.5443 - val_loss: 0.7713 - val_accuracy: 0.4963\nEpoch 18/500\n891/891 [==============================] - 0s 44us/step - loss: 3.7271 - accuracy: 0.5657 - val_loss: 0.7754 - val_accuracy: 0.6082\nEpoch 19/500\n891/891 [==============================] - 0s 45us/step - loss: 3.7165 - accuracy: 0.5724 - val_loss: 1.0677 - val_accuracy: 0.6679\nEpoch 20/500\n891/891 [==============================] - 0s 50us/step - loss: 3.6902 - accuracy: 0.5544 - val_loss: 0.8156 - val_accuracy: 0.6716\nEpoch 21/500\n891/891 [==============================] - 0s 43us/step - loss: 3.4103 - accuracy: 0.5511 - val_loss: 0.7478 - val_accuracy: 0.6716\nEpoch 22/500\n891/891 [==============================] - 0s 42us/step - loss: 2.9781 - accuracy: 0.5634 - val_loss: 0.8204 - val_accuracy: 0.4813\nEpoch 23/500\n891/891 [==============================] - 0s 46us/step - loss: 3.0719 - accuracy: 0.5421 - val_loss: 0.6711 - val_accuracy: 0.6679\nEpoch 24/500\n891/891 [==============================] - 0s 45us/step - loss: 2.8862 - accuracy: 0.5398 - val_loss: 0.6914 - val_accuracy: 0.6604\nEpoch 25/500\n891/891 [==============================] - 0s 45us/step - loss: 2.9357 - accuracy: 0.5477 - val_loss: 0.6391 - val_accuracy: 0.6978\nEpoch 26/500\n891/891 [==============================] - 0s 47us/step - loss: 3.0120 - accuracy: 0.5264 - val_loss: 0.7198 - val_accuracy: 0.5896\nEpoch 27/500\n891/891 [==============================] - 0s 49us/step - loss: 2.6170 - accuracy: 0.5556 - val_loss: 0.8151 - val_accuracy: 0.6716\nEpoch 28/500\n891/891 [==============================] - 0s 48us/step - loss: 2.2656 - accuracy: 0.5511 - val_loss: 0.8254 - val_accuracy: 0.5000\nEpoch 29/500\n891/891 [==============================] - 0s 48us/step - loss: 2.6968 - accuracy: 0.5354 - val_loss: 0.6864 - val_accuracy: 0.6791\nEpoch 30/500\n891/891 [==============================] - 0s 52us/step - loss: 2.4431 - accuracy: 0.5432 - val_loss: 0.6882 - val_accuracy: 0.6716\nEpoch 31/500\n891/891 [==============================] - 0s 53us/step - loss: 2.0363 - accuracy: 0.5836 - val_loss: 0.6479 - val_accuracy: 0.6567\nEpoch 32/500\n891/891 [==============================] - 0s 46us/step - loss: 1.9775 - accuracy: 0.5634 - val_loss: 0.6794 - val_accuracy: 0.6791\nEpoch 33/500\n891/891 [==============================] - 0s 48us/step - loss: 2.0414 - accuracy: 0.5376 - val_loss: 0.6435 - val_accuracy: 0.7015\nEpoch 34/500\n891/891 [==============================] - 0s 48us/step - loss: 1.8541 - accuracy: 0.5713 - val_loss: 0.7289 - val_accuracy: 0.6269\nEpoch 35/500\n891/891 [==============================] - 0s 48us/step - loss: 1.9536 - accuracy: 0.5679 - val_loss: 0.8198 - val_accuracy: 0.6418\nEpoch 36/500\n891/891 [==============================] - 0s 43us/step - loss: 2.0477 - accuracy: 0.5275 - val_loss: 0.6507 - val_accuracy: 0.6679\nEpoch 37/500\n891/891 [==============================] - 0s 45us/step - loss: 1.7126 - accuracy: 0.5780 - val_loss: 0.6971 - val_accuracy: 0.6866\nEpoch 38/500\n891/891 [==============================] - 0s 43us/step - loss: 1.7558 - accuracy: 0.5701 - val_loss: 0.6974 - val_accuracy: 0.5821\nEpoch 39/500\n891/891 [==============================] - 0s 44us/step - loss: 1.7265 - accuracy: 0.5533 - val_loss: 0.6542 - val_accuracy: 0.6791\nEpoch 40/500\n891/891 [==============================] - 0s 48us/step - loss: 1.6784 - accuracy: 0.5802 - val_loss: 0.6252 - val_accuracy: 0.6978\nEpoch 41/500\n891/891 [==============================] - 0s 43us/step - loss: 1.6809 - accuracy: 0.5499 - val_loss: 0.6418 - val_accuracy: 0.6791\nEpoch 42/500\n891/891 [==============================] - 0s 42us/step - loss: 1.5274 - accuracy: 0.5398 - val_loss: 0.6621 - val_accuracy: 0.6493\nEpoch 43/500\n891/891 [==============================] - 0s 48us/step - loss: 1.5074 - accuracy: 0.5937 - val_loss: 0.7801 - val_accuracy: 0.6455\nEpoch 44/500\n891/891 [==============================] - 0s 48us/step - loss: 1.4387 - accuracy: 0.5769 - val_loss: 0.8564 - val_accuracy: 0.4664\nEpoch 45/500\n891/891 [==============================] - 0s 49us/step - loss: 1.4446 - accuracy: 0.5657 - val_loss: 0.6611 - val_accuracy: 0.6418\nEpoch 46/500\n891/891 [==============================] - 0s 46us/step - loss: 1.3542 - accuracy: 0.6016 - val_loss: 0.6254 - val_accuracy: 0.6866\nEpoch 47/500\n891/891 [==============================] - 0s 45us/step - loss: 1.3040 - accuracy: 0.6072 - val_loss: 0.6598 - val_accuracy: 0.6530\nEpoch 48/500\n891/891 [==============================] - 0s 46us/step - loss: 1.4123 - accuracy: 0.5410 - val_loss: 0.6227 - val_accuracy: 0.7090\nEpoch 49/500\n891/891 [==============================] - 0s 43us/step - loss: 1.3642 - accuracy: 0.5634 - val_loss: 0.6391 - val_accuracy: 0.6978\nEpoch 50/500\n891/891 [==============================] - 0s 47us/step - loss: 1.5352 - accuracy: 0.5859 - val_loss: 0.6239 - val_accuracy: 0.6903\nEpoch 51/500\n891/891 [==============================] - 0s 41us/step - loss: 1.2741 - accuracy: 0.5634 - val_loss: 0.6239 - val_accuracy: 0.7127\nEpoch 52/500\n891/891 [==============================] - 0s 49us/step - loss: 1.4157 - accuracy: 0.5477 - val_loss: 0.6762 - val_accuracy: 0.5896\nEpoch 53/500\n891/891 [==============================] - 0s 50us/step - loss: 1.3279 - accuracy: 0.5533 - val_loss: 0.6497 - val_accuracy: 0.6269\nEpoch 54/500\n891/891 [==============================] - 0s 47us/step - loss: 1.1089 - accuracy: 0.5836 - val_loss: 0.6643 - val_accuracy: 0.6045\nEpoch 55/500\n891/891 [==============================] - 0s 47us/step - loss: 1.1347 - accuracy: 0.5802 - val_loss: 0.6867 - val_accuracy: 0.6381\nEpoch 56/500\n891/891 [==============================] - 0s 43us/step - loss: 1.2473 - accuracy: 0.5657 - val_loss: 0.6880 - val_accuracy: 0.5970\nEpoch 57/500\n891/891 [==============================] - 0s 45us/step - loss: 1.1294 - accuracy: 0.5746 - val_loss: 0.6410 - val_accuracy: 0.6754\nEpoch 58/500\n891/891 [==============================] - 0s 45us/step - loss: 1.1752 - accuracy: 0.5825 - val_loss: 0.6467 - val_accuracy: 0.6716\nEpoch 59/500\n891/891 [==============================] - 0s 43us/step - loss: 1.1029 - accuracy: 0.5488 - val_loss: 0.6810 - val_accuracy: 0.6530\nEpoch 60/500\n891/891 [==============================] - 0s 40us/step - loss: 1.2477 - accuracy: 0.5881 - val_loss: 0.7116 - val_accuracy: 0.4664\nEpoch 61/500\n891/891 [==============================] - 0s 53us/step - loss: 1.2835 - accuracy: 0.5140 - val_loss: 0.6520 - val_accuracy: 0.6567\nEpoch 62/500\n891/891 [==============================] - 0s 51us/step - loss: 1.0730 - accuracy: 0.5903 - val_loss: 0.6515 - val_accuracy: 0.6866\nEpoch 63/500\n891/891 [==============================] - 0s 46us/step - loss: 1.0383 - accuracy: 0.5758 - val_loss: 0.6618 - val_accuracy: 0.6567\nEpoch 64/500\n891/891 [==============================] - 0s 44us/step - loss: 1.0639 - accuracy: 0.5881 - val_loss: 0.6917 - val_accuracy: 0.6231\nEpoch 65/500\n891/891 [==============================] - 0s 46us/step - loss: 1.0511 - accuracy: 0.5634 - val_loss: 0.6566 - val_accuracy: 0.6493\nEpoch 66/500\n891/891 [==============================] - 0s 44us/step - loss: 0.9867 - accuracy: 0.5589 - val_loss: 0.6490 - val_accuracy: 0.6866\nEpoch 67/500\n891/891 [==============================] - 0s 44us/step - loss: 0.9466 - accuracy: 0.5814 - val_loss: 0.6543 - val_accuracy: 0.6567\nEpoch 68/500\n891/891 [==============================] - 0s 46us/step - loss: 1.0188 - accuracy: 0.5926 - val_loss: 0.6491 - val_accuracy: 0.6418\nEpoch 69/500\n891/891 [==============================] - 0s 44us/step - loss: 1.0083 - accuracy: 0.5690 - val_loss: 0.6599 - val_accuracy: 0.6791\nEpoch 70/500\n891/891 [==============================] - 0s 43us/step - loss: 0.9858 - accuracy: 0.6027 - val_loss: 0.7501 - val_accuracy: 0.6306\nEpoch 71/500\n891/891 [==============================] - 0s 43us/step - loss: 1.0165 - accuracy: 0.5769 - val_loss: 0.6677 - val_accuracy: 0.6679\n"
                    ]
                },
                "mc_idx": 126,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 61,
                "o_idx": 0
            }
        },
        {
            "source": "plt.plot(hist.history['accuracy'], label='acc')\nplt.plot(hist.history['val_accuracy'], label='val_acc')\n# plt.plot(hist.history['acc'], label='acc')\n# plt.plot(hist.history['val_acc'], label='val_acc')\nplt.ylim((0, 1))\nplt.legend()",
            "mc_idx": 127,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.6666666666666666,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plt.plot": 4,
                    ".plot(": 8
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "plt.plot": 4,
                    ".plot(": 4
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0039_c062_o001_image_2.png",
                    62,
                    1,
                    2
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<matplotlib.legend.Legend at 0x7f7bcc5b7358>",
                        "<Figure size 432x288 with 1 Axes>"
                    ]
                },
                "mc_idx": 127,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 62,
                "o_idx": 1
            }
        },
        {
            "source": "# Predicting the Test set results\nY_pred = model.predict(test)\nY_pred = (Y_pred > 0.5)*1 # convert probabilities to binary output",
            "mc_idx": 128,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.5,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    63,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 128,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 63,
                "o_idx": 0
            }
        },
        {
            "source": "# Predicting the Train set results\nnn_prediction = model.predict(train)\nnn_prediction = (nn_prediction > 0.5)*1 # convert probabilities to binary output\n\n# Compute error between predicted data and true response\nacc_ann2 = round(metrics.accuracy_score(target, nn_prediction) * 100, 2)\nacc_ann2",
            "mc_idx": 129,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.16666666666666666,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.16666666666666666,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "accuracy_score": 2,
                    "model": 1,
                    ".predict(": 1,
                    ".accuracy": 1,
                    "metrics.accuracy": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    64,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "61.17"
                    ]
                },
                "mc_idx": 129,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 64,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": np.reshape(Y_pred, len(Y_pred))})\n#submission.to_csv('output/submission_ann2.csv', index=False)\nLB_ann2_all = 0.64114  # old version",
            "mc_idx": 130,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 0.5,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "shape": 1
                },
                "Data_Transform": {
                    ".reshape": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    65,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 130,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 65,
                "o_idx": 0
            }
        },
        {
            "source": "### 5.18 VotingClassifier (hard voting) <a class=\"anchor\" id=\"5.18\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 131,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks for the example of ensemling different models from \nhttps://scikit-learn.org/stable/modules/ensemble.html#Extremely%20Randomized%20Trees",
            "mc_idx": 132,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "The idea behind the **VotingClassifier** is to combine conceptually different machine learning classifiers and use a majority vote (hard vote) or the average predicted probabilities (soft vote) to predict the class labels. Such a classifier can be useful for a set of equally well performing model in order to balance out their individual weaknesses. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/ensemble.html#Voting%20Classifier).",
            "mc_idx": 133,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "The VotingClassifier (with **hard voting**) would classify the sample as \u201cclass 1\u201d based on the **majority class label**. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/ensemble.html#Voting%20Classifier).",
            "mc_idx": 134,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Voting_Classifier_hard = VotingClassifier(estimators=[('lr', logreg), ('rf', random_forest), ('gbc', gradient_boosting)], voting='hard')\nfor clf, label in zip([logreg, random_forest, gradient_boosting, Voting_Classifier_hard], \n                      ['Logistic Regression', 'Random Forest', 'Gradient Boosting Classifier', 'Ensemble']):\n    scores = cross_val_score(clf, train, target, cv=cv_number, scoring='accuracy')\n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))",
            "mc_idx": 135,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.25,
                "Model_Evaluation": 0.25,
                "Model_Interpretation": 0.75,
                "Hyperparameter_Tuning": 0.25,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".std(": 1,
                    ".mean": 1,
                    ".std": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "votingclassifier": 1
                },
                "Model_Evaluation": {
                    "cross_val_score": 1
                },
                "Model_Interpretation": {
                    "gradient": 3
                },
                "Hyperparameter_Tuning": {
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    66,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Accuracy: 0.93 (+/- 0.01) [Logistic Regression]\nAccuracy: 0.94 (+/- 0.02) [Random Forest]\nAccuracy: 0.93 (+/- 0.02) [Gradient Boosting Classifier]\nAccuracy: 0.93 (+/- 0.02) [Ensemble]\n"
                    ]
                },
                "mc_idx": 135,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 66,
                "o_idx": 0
            }
        },
        {
            "source": "Voting_Classifier_hard.fit(train, target)\nY_pred = Voting_Classifier_hard.predict(test).astype(int)\nVoting_Classifier_hard.score(train, target)\nacc_VC_hard = round(Voting_Classifier_hard.score(train, target) * 100, 2)\nacc_VC_hard",
            "mc_idx": 136,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    67,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "100.0"
                    ]
                },
                "mc_idx": 136,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 67,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_VC_hard.csv', index=False)\nLB_VC_hard_all = 0.81339  # old version",
            "mc_idx": 137,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    68,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 137,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 68,
                "o_idx": 0
            }
        },
        {
            "source": "### 5.19 VotingClassifier (soft voting) <a class=\"anchor\" id=\"5.19\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 138,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks for the example of ensemling different models from \nhttps://scikit-learn.org/stable/modules/ensemble.html#Extremely%20Randomized%20Trees",
            "mc_idx": 139,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "In contrast to majority voting (hard voting), **soft voting** returns the class label as argmax of the **sum of predicted probabilities**.\nSpecific weights can be assigned to each classifier via the weights parameter. When weights are provided, the predicted class probabilities for each classifier are collected, multiplied by the classifier weight, and averaged. The final class label is then derived from the class label with the highest average probability. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/ensemble.html#Voting%20Classifier).",
            "mc_idx": 140,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "eclf = VotingClassifier(estimators=[('lr', logreg), ('rf', random_forest), ('gbc', gradient_boosting)], voting='soft')\nparams = {'lr__C': [1.0, 100.0], 'gbc__learning_rate': [0.05, 1]}\nVoting_Classifier_soft = GridSearchCV(estimator=eclf, param_grid=params, cv=cv_number)\nVoting_Classifier_soft.fit(train, target)\nY_pred = Voting_Classifier_soft.predict(test).astype(int)\nVoting_Classifier_soft.score(train, target)\nacc_VC_soft = round(Voting_Classifier_soft.score(train, target) * 100, 2)\nacc_VC_soft",
            "mc_idx": 141,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.14285714285714285,
                "Model_Train": 0.2857142857142857,
                "Model_Evaluation": 0.42857142857142855,
                "Model_Interpretation": 0.14285714285714285,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "votingclassifier": 1
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "param_grid": 1,
                    "param": 3
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    69,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "100.0"
                    ]
                },
                "mc_idx": 141,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 69,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_VC_soft.csv', index=False)\nLB_VC_soft_all = 0.81339  # old version",
            "mc_idx": 142,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    70,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 142,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 70,
                "o_idx": 0
            }
        },
        {
            "source": "### 5.20 The simple rule in one line <a class=\"anchor\" id=\"5.20\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 143,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to:\n* https://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code\n* https://www.kaggle.com/vbmokin/titanic-top-3-cluster-analysis\n* https://www.kaggle.com/mauricef/titanic",
            "mc_idx": 144,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Y_pred = (((test.WomanOrBoySurvived <= 0.238) & (test.Sex > 0.5) & (test.Alone > 0.5)) | \\\n          ((test.WomanOrBoySurvived > 0.238) & \\\n           ~((test.WomanOrBoySurvived > 0.55) & (test.WomanOrBoySurvived <= 0.633))))",
            "mc_idx": 145,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    71,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 145,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 71,
                "o_idx": 0
            }
        },
        {
            "source": "It's solution generate tuned DecisionTreeClassifier by the GridSearchCV from kernels:\nhttps://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code",
            "mc_idx": 146,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "simple_rule_model = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n                       max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort=False,\n                       random_state=1118, splitter='best') \nsimple_rule_model.fit(train, target)\nY_pred = simple_rule_model.predict(test).astype(int)\nsimple_rule_model.score(train, target)\nacc_simple_rule = round(simple_rule_model.score(train, target) * 100, 2)\nacc_simple_rule",
            "mc_idx": 147,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.125,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.625,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    "model.fit": 1,
                    ".fit(": 1,
                    "model": 5,
                    "decisiontreeclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 5,
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "model": 5
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    72,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "92.7"
                    ]
                },
                "mc_idx": 147,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 72,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_simple_rule.csv', index=False)\nLB_simple_rule_all = 0.83253  # old version",
            "mc_idx": 148,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    73,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 148,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 73,
                "o_idx": 0
            }
        },
        {
            "source": "## 6. Tuning models and test for 3 features <a class=\"anchor\" id=\"6\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 149,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "My kernels\n\n* [Titanic : one line of the prediction code](https://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code)\n* [Titanic : cluster analysis](https://www.kaggle.com/vbmokin/titanic-top-3-cluster-analysis)\n\npresents a solutions using a simple rule and only 3 features ('WomanOrBoySurvived', 'Sex', 'Alone'). Let's look at how all these models are tuned for those 3 features and whether we can find an even better solution.",
            "mc_idx": 150,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Preparing datasets for only 3 features ('WomanOrBoySurvived', 'Sex', 'Alone')\ncols_to_drop3 = ['SibSp', 'Parch', 'Fare', 'LastName', 'Deck',\n               'Pclass', 'Age', 'Embarked', 'Title', 'IsWomanOrBoy',\n               'WomanOrBoyCount', 'FamilySurvivedCount', 'Family_Size']\ntrain = train.drop(cols_to_drop3, axis=1)\ntest = test.drop(cols_to_drop3, axis=1)\nXtrain, Xval, Ztrain, Zval = train_test_split(train, target, test_size=0.3, random_state=SEED)\ntrain.info()",
            "mc_idx": 151,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.2,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.4,
                "Model_Train": 0.2,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.2,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "dataset": 1
                },
                "Exploratory_Data_Analysis": {
                    ".info(": 1,
                    "info": 1,
                    "size": 2,
                    ".info": 1
                },
                "Data_Transform": {
                    ".drop": 2
                },
                "Model_Train": {
                    "train_test_split": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "train_test_split": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    74,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 891 entries, 1 to 891\nData columns (total 3 columns):\nSex                   891 non-null int64\nWomanOrBoySurvived    891 non-null float64\nAlone                 891 non-null int64\ndtypes: float64(1), int64(2)\nmemory usage: 27.8 KB\n"
                    ]
                },
                "mc_idx": 151,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 74,
                "o_idx": 0
            }
        },
        {
            "source": "# 1. Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(train, target)\nY_pred = logreg.predict(test).astype(int)\nacc3_log = round(logreg.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_logreg3.csv', index=False)\nLB_log = 0.77033",
            "mc_idx": 152,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "logisticregression": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    75,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 152,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 75,
                "o_idx": 0
            }
        },
        {
            "source": "# 2. Support Vector Machines\n\nsvc = SVC()\nsvc.fit(train, target)\nY_pred = svc.predict(test).astype(int)\nacc3_svc = round(svc.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_svm3.csv', index=False)\nLB_svc = 0.79904",
            "mc_idx": 153,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.125,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.25,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.25,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "svc": 7
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    76,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 153,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 76,
                "o_idx": 0
            }
        },
        {
            "source": "# 3. Linear SVC\n\nlinear_svc = LinearSVC(dual=False)\nlinear_svc.fit(train, target)\nY_pred = linear_svc.predict(test).astype(int)\nacc3_linear_svc = round(linear_svc.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_linear_svc3.csv', index=False)\nLB_linear_svc = 0.77033",
            "mc_idx": 154,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.1,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.2,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.2,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "svc": 9
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    77,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 154,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 77,
                "o_idx": 0
            }
        },
        {
            "source": "# 4. k-Nearest Neighbors algorithm\n\nknn = GridSearchCV(estimator=KNeighborsClassifier(), param_grid={'n_neighbors': [2, 3, 4]}, cv=cv_number).fit(train, target)\nY_pred = knn.predict(test).astype(int)\nacc3_knn = round(knn.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_knn3.csv', index=False)\nLB_knn = 0.77751",
            "mc_idx": 155,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2,
                "Model_Train": 0.4,
                "Model_Evaluation": 0.4,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.4,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "kneighborsclassifier": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "param_grid": 1,
                    "param": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    78,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 155,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 78,
                "o_idx": 0
            }
        },
        {
            "source": "# 5. Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(train, target)\nY_pred = gaussian.predict(test).astype(int)\nacc3_gaussian = round(gaussian.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_GaussianNB3.csv', index=False)\nLB_gaussian = 0.68899",
            "mc_idx": 156,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.6666666666666666,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.6666666666666666,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "gaussiannb": 2
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    79,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 156,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 79,
                "o_idx": 0
            }
        },
        {
            "source": "# 6. Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(train, target)\nY_pred = perceptron.predict(test).astype(int)\nacc3_perceptron = round(perceptron.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_perceptron3.csv', index=False)\nLB_perceptron = 0.77511",
            "mc_idx": 157,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 0.5,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    80,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 157,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 80,
                "o_idx": 0
            }
        },
        {
            "source": "# 7. Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(train, target)\nY_pred = sgd.predict(test).astype(int)\nacc3_sgd = round(sgd.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_sgd3.csv', index=False)\nLB_sgd = 0.77511",
            "mc_idx": 158,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "sgdclassifier": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    81,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 158,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 81,
                "o_idx": 0
            }
        },
        {
            "source": "# 8. Decision Tree Classifier\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(train, target)\nY_pred = decision_tree.predict(test).astype(int)\nacc3_decision_tree = round(decision_tree.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_decision_tree3.csv', index=False)\nLB_decision_tree = 0.80382",
            "mc_idx": 159,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "decisiontreeclassifier": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    82,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 159,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 82,
                "o_idx": 0
            }
        },
        {
            "source": "# 9. Random Forest\n\nrandom_forest = GridSearchCV(estimator=RandomForestClassifier(), param_grid={'n_estimators': [200, 300, 400, 500]}, cv=cv_number).fit(train, target)\nrandom_forest.fit(train, target)\nY_pred = random_forest.predict(test).astype(int)\nrandom_forest.score(train, target)\nacc3_random_forest = round(random_forest.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_random_forest3.csv', index=False)\nLB_random_forest = 0.80382",
            "mc_idx": 160,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2,
                "Model_Train": 0.8,
                "Model_Evaluation": 0.6,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.4,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 2,
                    "randomforestclassifier": 2
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "param_grid": 1,
                    "param": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    83,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 160,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 83,
                "o_idx": 0
            }
        },
        {
            "source": "# 10. XGB_Classifier\n\ndef hyperopt_xgb_score(params):\n    clf = XGBClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_xgb = {\n            'learning_rate': hp.quniform('learning_rate', 0, 0.05, 0.0001),\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'eta': hp.quniform('eta', 0.025, 0.5, 0.005),\n            'max_depth':  hp.choice('max_depth', np.arange(4, 8, dtype=int)),\n            'min_child_weight': hp.quniform('min_child_weight', 1, 9, 0.025),\n            'subsample': hp.quniform('subsample', 0.5, 1, 0.005),\n            'gamma': hp.quniform('gamma', 0.5, 1, 0.005),\n            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.005),\n            'eval_metric': 'auc',\n            'objective': 'binary:logistic',\n            'booster': 'gbtree',\n            'tree_method': 'exact',\n            'silent': 1,\n            'missing': None\n        }\n \nbest = fmin(fn=hyperopt_xgb_score, space=space_xgb, algo=tpe.suggest, max_evals=10)\nparams = space_eval(space_xgb, best)\nXGB_Classifier = XGBClassifier(**params)\nXGB_Classifier.fit(train, target)\nY_pred = XGB_Classifier.predict(test).astype(int)\nXGB_Classifier.score(train, target)\nacc3_XGB_Classifier = round(XGB_Classifier.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_XGB_Classifier3.csv', index=False)\nLB_XGB_Classifier = 0.68899\nprint(params)",
            "mc_idx": 161,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2222222222222222,
                "Data_Transform": 0.1111111111111111,
                "Model_Train": 0.1111111111111111,
                "Model_Evaluation": 0.4444444444444444,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.2222222222222222,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1
                },
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "hyperopt": 2,
                    "param": 6,
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    84,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0.777744808384463\n{'booster': 'gbtree', 'colsample_bytree': 0.525, 'eta': 0.45, 'eval_metric': 'auc', 'gamma': 0.935, 'learning_rate': 0.0015, 'max_depth': 4, 'min_child_weight': 7.300000000000001, 'missing': None, 'n_estimators': 948, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.995, 'tree_method': 'exact'}\n0.9091068935348663\n{'booster': 'gbtree', 'colsample_bytree': 0.67, 'eta': 0.315, 'eval_metric': 'auc', 'gamma': 0.665, 'learning_rate': 0.047, 'max_depth': 5, 'min_child_weight': 6.625, 'missing': None, 'n_estimators': 452, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.555, 'tree_method': 'exact'}\n0.9214665150240071\n{'booster': 'gbtree', 'colsample_bytree': 0.86, 'eta': 0.35000000000000003, 'eval_metric': 'auc', 'gamma': 0.875, 'learning_rate': 0.0358, 'max_depth': 6, 'min_child_weight': 6.0, 'missing': None, 'n_estimators': 408, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.9400000000000001, 'tree_method': 'exact'}\n0.9158484665685741\n{'booster': 'gbtree', 'colsample_bytree': 0.975, 'eta': 0.115, 'eval_metric': 'auc', 'gamma': 0.6900000000000001, 'learning_rate': 0.0402, 'max_depth': 7, 'min_child_weight': 8.375, 'missing': None, 'n_estimators': 494, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.965, 'tree_method': 'exact'}\n0.8989817670625477\n{'booster': 'gbtree', 'colsample_bytree': 0.61, 'eta': 0.365, 'eval_metric': 'auc', 'gamma': 0.91, 'learning_rate': 0.0342, 'max_depth': 7, 'min_child_weight': 1.75, 'missing': None, 'n_estimators': 399, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.6, 'tree_method': 'exact'}\n0.9214665150240071\n{'booster': 'gbtree', 'colsample_bytree': 0.79, 'eta': 0.275, 'eval_metric': 'auc', 'gamma': 0.875, 'learning_rate': 0.041600000000000005, 'max_depth': 4, 'min_child_weight': 1.2750000000000001, 'missing': None, 'n_estimators': 704, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.795, 'tree_method': 'exact'}\n0.89675975525811\n{'booster': 'gbtree', 'colsample_bytree': 0.715, 'eta': 0.335, 'eval_metric': 'auc', 'gamma': 0.775, 'learning_rate': 0.003, 'max_depth': 6, 'min_child_weight': 7.825, 'missing': None, 'n_estimators': 805, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.58, 'tree_method': 'exact'}\n0.9180957285071532\n{'booster': 'gbtree', 'colsample_bytree': 0.885, 'eta': 0.085, 'eval_metric': 'auc', 'gamma': 0.635, 'learning_rate': 0.0368, 'max_depth': 5, 'min_child_weight': 5.125, 'missing': None, 'n_estimators': 726, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.8150000000000001, 'tree_method': 'exact'}\n0.9012290290011267\n{'booster': 'gbtree', 'colsample_bytree': 0.96, 'eta': 0.28500000000000003, 'eval_metric': 'auc', 'gamma': 0.73, 'learning_rate': 0.0004, 'max_depth': 7, 'min_child_weight': 8.0, 'missing': None, 'n_estimators': 960, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.89, 'tree_method': 'exact'}\n0.9214665150240071\n{'booster': 'gbtree', 'colsample_bytree': 0.8150000000000001, 'eta': 0.48, 'eval_metric': 'auc', 'gamma': 0.6950000000000001, 'learning_rate': 0.0291, 'max_depth': 4, 'min_child_weight': 2.5, 'missing': None, 'n_estimators': 788, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.925, 'tree_method': 'exact'}\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:10<00:00,  1.01s/it, best loss: 0.777744808384463]\n{'booster': 'gbtree', 'colsample_bytree': 0.525, 'eta': 0.45, 'eval_metric': 'auc', 'gamma': 0.935, 'learning_rate': 0.0015, 'max_depth': 4, 'min_child_weight': 7.300000000000001, 'missing': None, 'n_estimators': 948, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.995, 'tree_method': 'exact'}\n"
                    ]
                },
                "mc_idx": 161,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 84,
                "o_idx": 0
            }
        },
        {
            "source": "# 11. LGBM_Classifier\n\ndef hyperopt_lgb_score(params):\n    clf = LGBMClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_lgb = {\n            'learning_rate': hp.quniform('learning_rate', 0, 0.05, 0.0001),\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_depth':  hp.choice('max_depth', np.arange(4, 7, dtype=int)),\n            'num_leaves': hp.choice('num_leaves', 2*np.arange(20, 2**6, dtype=int)),\n            'min_child_weight': hp.quniform('min_child_weight', 1, 9, 0.025),\n            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.005),\n            'objective': 'binary',\n            'boosting_type': 'gbdt',\n            }\n \nbest = fmin(fn=hyperopt_lgb_score, space=space_lgb, algo=tpe.suggest, max_evals=10)\nparams = space_eval(space_lgb, best)\nLGB_Classifier = LGBMClassifier(**params)\nLGB_Classifier.fit(train, target)\nY_pred = LGB_Classifier.predict(test).astype(int)\nLGB_Classifier.score(train, target)\nacc3_LGB_Classifier = round(LGB_Classifier.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_LGB_Classifier3.csv', index=False)\nLB_LGB_Classifier = 0.62200\nprint(params)",
            "mc_idx": 162,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2222222222222222,
                "Data_Transform": 0.1111111111111111,
                "Model_Train": 0.1111111111111111,
                "Model_Evaluation": 0.4444444444444444,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.2222222222222222,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1
                },
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "hyperopt": 2,
                    "param": 6,
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    85,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0.8710614312357636\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.0083, 'max_depth': 5, 'min_child_weight': 3.575, 'n_estimators': 546, 'num_leaves': 88, 'objective': 'binary'}\n0.9214665150240071\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.77, 'learning_rate': 0.0179, 'max_depth': 5, 'min_child_weight': 5.3500000000000005, 'n_estimators': 815, 'num_leaves': 92, 'objective': 'binary'}\n0.9001495857665847\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.885, 'learning_rate': 0.013800000000000002, 'max_depth': 5, 'min_child_weight': 6.0, 'n_estimators': 130, 'num_leaves': 120, 'objective': 'binary'}\n0.9012290290011267\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.53, 'learning_rate': 0.009600000000000001, 'max_depth': 6, 'min_child_weight': 1.75, 'n_estimators': 962, 'num_leaves': 90, 'objective': 'binary'}\n0.9091068935348663\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.725, 'learning_rate': 0.019200000000000002, 'max_depth': 4, 'min_child_weight': 8.9, 'n_estimators': 952, 'num_leaves': 96, 'objective': 'binary'}\n0.9214665150240071\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.685, 'learning_rate': 0.012100000000000001, 'max_depth': 4, 'min_child_weight': 3.3000000000000003, 'n_estimators': 918, 'num_leaves': 86, 'objective': 'binary'}\n0.9024030538476844\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.54, 'learning_rate': 0.0494, 'max_depth': 4, 'min_child_weight': 1.75, 'n_estimators': 666, 'num_leaves': 44, 'objective': 'binary'}\n0.8990196422637597\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.54, 'learning_rate': 0.0379, 'max_depth': 6, 'min_child_weight': 7.9, 'n_estimators': 827, 'num_leaves': 60, 'objective': 'binary'}\n0.9214665150240071\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.865, 'learning_rate': 0.0076, 'max_depth': 4, 'min_child_weight': 6.800000000000001, 'n_estimators': 639, 'num_leaves': 54, 'objective': 'binary'}\n0.9214665150240071\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.8300000000000001, 'learning_rate': 0.017, 'max_depth': 5, 'min_child_weight': 4.325, 'n_estimators': 548, 'num_leaves': 60, 'objective': 'binary'}\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:05<00:00,  1.73it/s, best loss: 0.8710614312357636]\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.0083, 'max_depth': 5, 'min_child_weight': 3.575, 'n_estimators': 546, 'num_leaves': 88, 'objective': 'binary'}\n"
                    ]
                },
                "mc_idx": 162,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 85,
                "o_idx": 0
            }
        },
        {
            "source": "# 12. GradientBoostingClassifier\n\ndef hyperopt_gb_score(params):\n    clf = GradientBoostingClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_gb = {\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_depth': hp.choice('max_depth', np.arange(4, 8, dtype=int)),\n            'max_features': None\n        }\n \nbest = fmin(fn=hyperopt_gb_score, space=space_gb, algo=tpe.suggest, max_evals=5)\nparams = space_eval(space_gb, best)\ngradient_boosting = GradientBoostingClassifier(**params)\ngradient_boosting.fit(train, target)\nY_pred = gradient_boosting.predict(test).astype(int)\ngradient_boosting.score(train, target)\nacc3_gradient_boosting = round(gradient_boosting.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_gradient_boosting3.csv', index=False)\nLB_GBC = 0.80382\nprint(params)",
            "mc_idx": 163,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2,
                "Data_Transform": 0.1,
                "Model_Train": 0.4,
                "Model_Evaluation": 0.4,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.9,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.2,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1
                },
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "gradientboostingclassifier": 3
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "gradient": 10
                },
                "Hyperparameter_Tuning": {
                    "hyperopt": 2,
                    "param": 6,
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    86,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0.9214665150240071\n{'max_depth': 5, 'max_features': None, 'n_estimators': 360}\n0.9214665150240071\n{'max_depth': 6, 'max_features': None, 'n_estimators': 324}\n0.9214665150240071\n{'max_depth': 6, 'max_features': None, 'n_estimators': 603}\n0.9214665150240071\n{'max_depth': 7, 'max_features': None, 'n_estimators': 288}\n0.9214665150240071\n{'max_depth': 4, 'max_features': None, 'n_estimators': 739}\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:09<00:00,  1.92s/it, best loss: 0.9214665150240071]\n{'max_depth': 5, 'max_features': None, 'n_estimators': 360}\n"
                    ]
                },
                "mc_idx": 163,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 86,
                "o_idx": 0
            }
        },
        {
            "source": "# 13. Ridge Classifier\n\nridge_classifier = RidgeClassifier()\nridge_classifier.fit(train, target)\nY_pred = ridge_classifier.predict(test).astype(int)\nridge_classifier.score(train, target)\nacc3_ridge_classifier = round(ridge_classifier.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_ridge_classifier3.csv', index=False)\nLB_RidgeClassifier = 0.77511",
            "mc_idx": 164,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.09090909090909091,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.2727272727272727,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.18181818181818182,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "ridge": 10
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    87,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 164,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 87,
                "o_idx": 0
            }
        },
        {
            "source": "# 14. Bagging Classifier\n\nbagging_classifier = BaggingClassifier()\nbagging_classifier.fit(train, target)\nY_pred = bagging_classifier.predict(test).astype(int)\nbagging_classifier.score(train, target)\nacc3_bagging_classifier = round(bagging_classifier.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_bagging_classifier3.csv', index=False)\nLB_bagging_classifier = 0.80382",
            "mc_idx": 165,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.6666666666666666,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    88,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 165,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 88,
                "o_idx": 0
            }
        },
        {
            "source": "# 15. Extra Trees Classifier\n\ndef hyperopt_etc_score(params):\n    clf = ExtraTreesClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_etc = {\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_features': hp.choice('max_features', np.arange(2, 10, dtype=int)),\n            'min_samples_leaf': hp.choice('min_samples_leaf', np.arange(1, 5, dtype=int)),\n            'max_depth':  hp.choice('max_depth', np.arange(2, 8, dtype=int)),\n            'max_features': None\n        }\n \nbest = fmin(fn=hyperopt_etc_score, space=space_etc, algo=tpe.suggest, max_evals=5)\nparams = space_eval(space_etc, best)\nextra_trees_classifier = ExtraTreesClassifier(**params)\nextra_trees_classifier.fit(train, target)\nY_pred = extra_trees_classifier.predict(test).astype(int)\nextra_trees_classifier.score(train, target)\nacc3_etc = round(extra_trees_classifier.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_etc3.csv', index=False)\nLB_ETC = 0.79904\nprint(params)",
            "mc_idx": 166,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2222222222222222,
                "Data_Transform": 0.1111111111111111,
                "Model_Train": 0.1111111111111111,
                "Model_Evaluation": 0.4444444444444444,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.2222222222222222,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1
                },
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "hyperopt": 2,
                    "param": 6,
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    89,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0.9180957285071532\n{'max_depth': 3, 'max_features': None, 'min_samples_leaf': 1, 'n_estimators': 211}\n0.9180957285071532\n{'max_depth': 3, 'max_features': None, 'min_samples_leaf': 4, 'n_estimators': 719}\n0.9214665150240071\n{'max_depth': 5, 'max_features': None, 'min_samples_leaf': 2, 'n_estimators': 668}\n0.9180957285071532\n{'max_depth': 3, 'max_features': None, 'min_samples_leaf': 4, 'n_estimators': 469}\n0.9180957285071532\n{'max_depth': 4, 'max_features': None, 'min_samples_leaf': 3, 'n_estimators': 850}\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:13<00:00,  2.70s/it, best loss: 0.9180957285071532]\n{'max_depth': 3, 'max_features': None, 'min_samples_leaf': 1, 'n_estimators': 211}\n"
                    ]
                },
                "mc_idx": 166,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 89,
                "o_idx": 0
            }
        },
        {
            "source": "# 16. Neural Network 1 \n\ndef build_ann(optimizer='adam'):\n    \n    # Initializing the ANN\n    ann = Sequential()\n    \n    # Adding the input layer and the first hidden layer of the ANN with dropout\n    ann.add(Dense(units=32, kernel_initializer='glorot_uniform', activation='relu', input_shape=(3,)))\n    \n    # Add other layers, it is not necessary to pass the shape because there is a layer before\n    ann.add(Dense(units=64, kernel_initializer='glorot_uniform', activation='relu'))\n    ann.add(Dropout(rate=0.5))\n    ann.add(Dense(units=64, kernel_initializer='glorot_uniform', activation='relu'))\n    ann.add(Dropout(rate=0.5))\n    \n    # Adding the output layer\n    ann.add(Dense(units=1, kernel_initializer='glorot_uniform', activation='sigmoid'))\n    \n    # Compiling the ANN\n    ann.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return ann\nopt = optimizers.Adam(lr=0.001)\nann = build_ann(opt)\nhistory = ann.fit(Xtrain, Ztrain, batch_size=16, epochs=100, validation_data=(Xval, Zval))\nY_pred = ann.predict(test)\nY_pred = (Y_pred > 0.5)*1 # convert probabilities to binary output\nann_prediction = ann.predict(train)\nann_prediction = (ann_prediction > 0.5)*1 # convert probabilities to binary output\nacc3_ann1 = round(metrics.accuracy_score(target, ann_prediction) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": np.reshape(Y_pred, len(Y_pred))})\nsubmission.to_csv('submission_ann1_3.csv', index=False)\nLB_ann1 = 0.79904",
            "mc_idx": 167,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5714285714285714,
                "Data_Transform": 1.0,
                "Model_Train": 0.42857142857142855,
                "Model_Evaluation": 0.8571428571428571,
                "Model_Interpretation": 0.42857142857142855,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.2857142857142857,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "shape": 3,
                    "size": 1
                },
                "Data_Transform": {
                    ".reshape": 1,
                    ".add": 6
                },
                "Model_Train": {
                    "sequential(": 1,
                    "compile": 1,
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    "accuracy_score": 2,
                    ".predict(": 2,
                    ".accuracy": 1,
                    "metrics.accuracy": 1
                },
                "Model_Interpretation": {
                    "shap": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    90,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Train on 623 samples, validate on 268 samples\nEpoch 1/100\n623/623 [==============================] - 0s 642us/step - loss: 0.6393 - accuracy: 0.6838 - val_loss: 0.5469 - val_accuracy: 0.7910\nEpoch 2/100\n623/623 [==============================] - 0s 166us/step - loss: 0.4670 - accuracy: 0.8074 - val_loss: 0.3263 - val_accuracy: 0.9030\nEpoch 3/100\n623/623 [==============================] - 0s 186us/step - loss: 0.2969 - accuracy: 0.8748 - val_loss: 0.2122 - val_accuracy: 0.9030\nEpoch 4/100\n623/623 [==============================] - 0s 175us/step - loss: 0.2476 - accuracy: 0.8925 - val_loss: 0.1987 - val_accuracy: 0.9030\nEpoch 5/100\n623/623 [==============================] - 0s 167us/step - loss: 0.2209 - accuracy: 0.8957 - val_loss: 0.1929 - val_accuracy: 0.9030\nEpoch 6/100\n623/623 [==============================] - 0s 164us/step - loss: 0.2270 - accuracy: 0.9021 - val_loss: 0.1989 - val_accuracy: 0.9142\nEpoch 7/100\n623/623 [==============================] - 0s 161us/step - loss: 0.2202 - accuracy: 0.9021 - val_loss: 0.1889 - val_accuracy: 0.9142\nEpoch 8/100\n623/623 [==============================] - 0s 170us/step - loss: 0.2114 - accuracy: 0.9165 - val_loss: 0.1925 - val_accuracy: 0.9142\nEpoch 9/100\n623/623 [==============================] - 0s 172us/step - loss: 0.2081 - accuracy: 0.9181 - val_loss: 0.1889 - val_accuracy: 0.9142\nEpoch 10/100\n623/623 [==============================] - 0s 162us/step - loss: 0.1994 - accuracy: 0.9037 - val_loss: 0.1867 - val_accuracy: 0.9142\nEpoch 11/100\n623/623 [==============================] - 0s 167us/step - loss: 0.1969 - accuracy: 0.9133 - val_loss: 0.1904 - val_accuracy: 0.9142\nEpoch 12/100\n623/623 [==============================] - 0s 194us/step - loss: 0.2035 - accuracy: 0.9133 - val_loss: 0.1861 - val_accuracy: 0.9142\nEpoch 13/100\n623/623 [==============================] - 0s 189us/step - loss: 0.2035 - accuracy: 0.9149 - val_loss: 0.1935 - val_accuracy: 0.9142\nEpoch 14/100\n623/623 [==============================] - 0s 172us/step - loss: 0.2016 - accuracy: 0.9165 - val_loss: 0.1918 - val_accuracy: 0.9142\nEpoch 15/100\n623/623 [==============================] - 0s 159us/step - loss: 0.2067 - accuracy: 0.9133 - val_loss: 0.1874 - val_accuracy: 0.9142\nEpoch 16/100\n623/623 [==============================] - 0s 169us/step - loss: 0.2053 - accuracy: 0.9149 - val_loss: 0.1833 - val_accuracy: 0.9142\nEpoch 17/100\n623/623 [==============================] - 0s 161us/step - loss: 0.1914 - accuracy: 0.9181 - val_loss: 0.1851 - val_accuracy: 0.9142\nEpoch 18/100\n623/623 [==============================] - 0s 167us/step - loss: 0.1938 - accuracy: 0.9197 - val_loss: 0.1871 - val_accuracy: 0.9142\nEpoch 19/100\n623/623 [==============================] - 0s 167us/step - loss: 0.1946 - accuracy: 0.9181 - val_loss: 0.1920 - val_accuracy: 0.9142\nEpoch 20/100\n623/623 [==============================] - 0s 182us/step - loss: 0.1956 - accuracy: 0.9149 - val_loss: 0.1851 - val_accuracy: 0.9142\nEpoch 21/100\n623/623 [==============================] - 0s 172us/step - loss: 0.1981 - accuracy: 0.9181 - val_loss: 0.1840 - val_accuracy: 0.9142\nEpoch 22/100\n623/623 [==============================] - 0s 173us/step - loss: 0.2087 - accuracy: 0.9149 - val_loss: 0.1894 - val_accuracy: 0.9179\nEpoch 23/100\n623/623 [==============================] - 0s 170us/step - loss: 0.1985 - accuracy: 0.9197 - val_loss: 0.1883 - val_accuracy: 0.9179\nEpoch 24/100\n623/623 [==============================] - 0s 164us/step - loss: 0.1955 - accuracy: 0.9165 - val_loss: 0.1927 - val_accuracy: 0.9179\nEpoch 25/100\n623/623 [==============================] - 0s 160us/step - loss: 0.2001 - accuracy: 0.9197 - val_loss: 0.1900 - val_accuracy: 0.9179\nEpoch 26/100\n623/623 [==============================] - 0s 157us/step - loss: 0.2025 - accuracy: 0.9230 - val_loss: 0.1881 - val_accuracy: 0.9179\nEpoch 27/100\n623/623 [==============================] - 0s 179us/step - loss: 0.1952 - accuracy: 0.9230 - val_loss: 0.1919 - val_accuracy: 0.9179\nEpoch 28/100\n623/623 [==============================] - 0s 167us/step - loss: 0.1936 - accuracy: 0.9197 - val_loss: 0.1910 - val_accuracy: 0.9179\nEpoch 29/100\n623/623 [==============================] - 0s 168us/step - loss: 0.1849 - accuracy: 0.9230 - val_loss: 0.1876 - val_accuracy: 0.9179\nEpoch 30/100\n623/623 [==============================] - 0s 162us/step - loss: 0.1930 - accuracy: 0.9213 - val_loss: 0.1876 - val_accuracy: 0.9179\nEpoch 31/100\n623/623 [==============================] - 0s 179us/step - loss: 0.2008 - accuracy: 0.9197 - val_loss: 0.1865 - val_accuracy: 0.9179\nEpoch 32/100\n623/623 [==============================] - 0s 165us/step - loss: 0.1915 - accuracy: 0.9230 - val_loss: 0.1835 - val_accuracy: 0.9142\nEpoch 33/100\n623/623 [==============================] - 0s 173us/step - loss: 0.1867 - accuracy: 0.9213 - val_loss: 0.1914 - val_accuracy: 0.9179\nEpoch 34/100\n623/623 [==============================] - 0s 166us/step - loss: 0.1884 - accuracy: 0.9230 - val_loss: 0.1902 - val_accuracy: 0.9179\nEpoch 35/100\n623/623 [==============================] - 0s 169us/step - loss: 0.1963 - accuracy: 0.9230 - val_loss: 0.1897 - val_accuracy: 0.9179\nEpoch 36/100\n623/623 [==============================] - 0s 170us/step - loss: 0.1844 - accuracy: 0.9230 - val_loss: 0.1914 - val_accuracy: 0.9179\nEpoch 37/100\n623/623 [==============================] - 0s 178us/step - loss: 0.1835 - accuracy: 0.9213 - val_loss: 0.1896 - val_accuracy: 0.9179\nEpoch 38/100\n623/623 [==============================] - 0s 169us/step - loss: 0.1992 - accuracy: 0.9213 - val_loss: 0.1888 - val_accuracy: 0.9179\nEpoch 39/100\n623/623 [==============================] - 0s 181us/step - loss: 0.2007 - accuracy: 0.9230 - val_loss: 0.1877 - val_accuracy: 0.9179\nEpoch 40/100\n623/623 [==============================] - 0s 185us/step - loss: 0.1947 - accuracy: 0.9230 - val_loss: 0.1858 - val_accuracy: 0.9179\nEpoch 41/100\n623/623 [==============================] - 0s 171us/step - loss: 0.1938 - accuracy: 0.9230 - val_loss: 0.1856 - val_accuracy: 0.9179\nEpoch 42/100\n623/623 [==============================] - 0s 166us/step - loss: 0.1929 - accuracy: 0.9230 - val_loss: 0.1857 - val_accuracy: 0.9179\nEpoch 43/100\n623/623 [==============================] - 0s 171us/step - loss: 0.1841 - accuracy: 0.9246 - val_loss: 0.1879 - val_accuracy: 0.9179\nEpoch 44/100\n623/623 [==============================] - 0s 187us/step - loss: 0.1858 - accuracy: 0.9213 - val_loss: 0.1915 - val_accuracy: 0.9179\nEpoch 45/100\n623/623 [==============================] - 0s 176us/step - loss: 0.1966 - accuracy: 0.9230 - val_loss: 0.1863 - val_accuracy: 0.9179\nEpoch 46/100\n623/623 [==============================] - 0s 157us/step - loss: 0.1961 - accuracy: 0.9230 - val_loss: 0.1863 - val_accuracy: 0.9179\nEpoch 47/100\n623/623 [==============================] - 0s 169us/step - loss: 0.1841 - accuracy: 0.9230 - val_loss: 0.1848 - val_accuracy: 0.9179\nEpoch 48/100\n623/623 [==============================] - 0s 170us/step - loss: 0.1816 - accuracy: 0.9246 - val_loss: 0.1821 - val_accuracy: 0.9179\nEpoch 49/100\n623/623 [==============================] - 0s 188us/step - loss: 0.1853 - accuracy: 0.9197 - val_loss: 0.1873 - val_accuracy: 0.9179\nEpoch 50/100\n623/623 [==============================] - 0s 168us/step - loss: 0.1916 - accuracy: 0.9230 - val_loss: 0.1857 - val_accuracy: 0.9179\nEpoch 51/100\n623/623 [==============================] - 0s 173us/step - loss: 0.1881 - accuracy: 0.9230 - val_loss: 0.1938 - val_accuracy: 0.9179\nEpoch 52/100\n623/623 [==============================] - 0s 166us/step - loss: 0.1910 - accuracy: 0.9213 - val_loss: 0.1895 - val_accuracy: 0.9179\nEpoch 53/100\n623/623 [==============================] - 0s 167us/step - loss: 0.1959 - accuracy: 0.9230 - val_loss: 0.1850 - val_accuracy: 0.9179\nEpoch 54/100\n623/623 [==============================] - 0s 167us/step - loss: 0.1987 - accuracy: 0.9213 - val_loss: 0.1875 - val_accuracy: 0.9179\nEpoch 55/100\n623/623 [==============================] - 0s 166us/step - loss: 0.1983 - accuracy: 0.9230 - val_loss: 0.1862 - val_accuracy: 0.9179\nEpoch 56/100\n623/623 [==============================] - 0s 186us/step - loss: 0.1889 - accuracy: 0.9230 - val_loss: 0.1824 - val_accuracy: 0.9142\nEpoch 57/100\n623/623 [==============================] - 0s 168us/step - loss: 0.1879 - accuracy: 0.9230 - val_loss: 0.1871 - val_accuracy: 0.9179\nEpoch 58/100\n623/623 [==============================] - 0s 161us/step - loss: 0.1868 - accuracy: 0.9230 - val_loss: 0.1870 - val_accuracy: 0.9179\nEpoch 59/100\n623/623 [==============================] - 0s 165us/step - loss: 0.1928 - accuracy: 0.9213 - val_loss: 0.1867 - val_accuracy: 0.9179\nEpoch 60/100\n623/623 [==============================] - 0s 170us/step - loss: 0.1976 - accuracy: 0.9213 - val_loss: 0.1888 - val_accuracy: 0.9179\nEpoch 61/100\n623/623 [==============================] - 0s 163us/step - loss: 0.1888 - accuracy: 0.9230 - val_loss: 0.1882 - val_accuracy: 0.9179\nEpoch 62/100\n623/623 [==============================] - 0s 171us/step - loss: 0.1886 - accuracy: 0.9230 - val_loss: 0.1868 - val_accuracy: 0.9179\nEpoch 63/100\n623/623 [==============================] - 0s 179us/step - loss: 0.1921 - accuracy: 0.9230 - val_loss: 0.1847 - val_accuracy: 0.9142\nEpoch 64/100\n623/623 [==============================] - 0s 164us/step - loss: 0.1943 - accuracy: 0.9230 - val_loss: 0.1851 - val_accuracy: 0.9179\nEpoch 65/100\n623/623 [==============================] - 0s 165us/step - loss: 0.1941 - accuracy: 0.9197 - val_loss: 0.1806 - val_accuracy: 0.9142\nEpoch 66/100\n623/623 [==============================] - 0s 168us/step - loss: 0.1867 - accuracy: 0.9213 - val_loss: 0.1837 - val_accuracy: 0.9179\nEpoch 67/100\n623/623 [==============================] - 0s 163us/step - loss: 0.1898 - accuracy: 0.9213 - val_loss: 0.1856 - val_accuracy: 0.9179\nEpoch 68/100\n623/623 [==============================] - 0s 180us/step - loss: 0.1895 - accuracy: 0.9230 - val_loss: 0.1850 - val_accuracy: 0.9179\nEpoch 69/100\n623/623 [==============================] - 0s 161us/step - loss: 0.1895 - accuracy: 0.9230 - val_loss: 0.1857 - val_accuracy: 0.9179\nEpoch 70/100\n623/623 [==============================] - 0s 157us/step - loss: 0.1904 - accuracy: 0.9213 - val_loss: 0.1881 - val_accuracy: 0.9179\nEpoch 71/100\n623/623 [==============================] - 0s 179us/step - loss: 0.1853 - accuracy: 0.9230 - val_loss: 0.1823 - val_accuracy: 0.9142\nEpoch 72/100\n623/623 [==============================] - 0s 163us/step - loss: 0.1860 - accuracy: 0.9213 - val_loss: 0.1850 - val_accuracy: 0.9179\nEpoch 73/100\n623/623 [==============================] - 0s 169us/step - loss: 0.1831 - accuracy: 0.9230 - val_loss: 0.1852 - val_accuracy: 0.9179\nEpoch 74/100\n623/623 [==============================] - 0s 170us/step - loss: 0.1951 - accuracy: 0.9230 - val_loss: 0.1820 - val_accuracy: 0.9142\nEpoch 75/100\n623/623 [==============================] - 0s 162us/step - loss: 0.1903 - accuracy: 0.9230 - val_loss: 0.1820 - val_accuracy: 0.9142\nEpoch 76/100\n623/623 [==============================] - 0s 174us/step - loss: 0.1939 - accuracy: 0.9230 - val_loss: 0.1887 - val_accuracy: 0.9179\nEpoch 77/100\n623/623 [==============================] - 0s 175us/step - loss: 0.1853 - accuracy: 0.9262 - val_loss: 0.1833 - val_accuracy: 0.9179\nEpoch 78/100\n623/623 [==============================] - 0s 160us/step - loss: 0.2056 - accuracy: 0.9213 - val_loss: 0.1870 - val_accuracy: 0.9179\nEpoch 79/100\n623/623 [==============================] - 0s 169us/step - loss: 0.1917 - accuracy: 0.9213 - val_loss: 0.1817 - val_accuracy: 0.9142\nEpoch 80/100\n623/623 [==============================] - 0s 168us/step - loss: 0.1871 - accuracy: 0.9197 - val_loss: 0.1813 - val_accuracy: 0.9142\nEpoch 81/100\n623/623 [==============================] - 0s 170us/step - loss: 0.1832 - accuracy: 0.9246 - val_loss: 0.1824 - val_accuracy: 0.9142\nEpoch 82/100\n623/623 [==============================] - 0s 164us/step - loss: 0.1880 - accuracy: 0.9213 - val_loss: 0.1841 - val_accuracy: 0.9179\nEpoch 83/100\n623/623 [==============================] - 0s 165us/step - loss: 0.1813 - accuracy: 0.9197 - val_loss: 0.1833 - val_accuracy: 0.9179\nEpoch 84/100\n623/623 [==============================] - 0s 187us/step - loss: 0.1977 - accuracy: 0.9230 - val_loss: 0.1869 - val_accuracy: 0.9179\nEpoch 85/100\n623/623 [==============================] - 0s 165us/step - loss: 0.1940 - accuracy: 0.9230 - val_loss: 0.1826 - val_accuracy: 0.9179\nEpoch 86/100\n623/623 [==============================] - 0s 173us/step - loss: 0.1934 - accuracy: 0.9213 - val_loss: 0.1845 - val_accuracy: 0.9179\nEpoch 87/100\n623/623 [==============================] - 0s 168us/step - loss: 0.1857 - accuracy: 0.9181 - val_loss: 0.1849 - val_accuracy: 0.9179\nEpoch 88/100\n623/623 [==============================] - 0s 160us/step - loss: 0.1878 - accuracy: 0.9262 - val_loss: 0.1833 - val_accuracy: 0.9179\nEpoch 89/100\n623/623 [==============================] - 0s 164us/step - loss: 0.1908 - accuracy: 0.9197 - val_loss: 0.1854 - val_accuracy: 0.9179\nEpoch 90/100\n623/623 [==============================] - 0s 168us/step - loss: 0.1931 - accuracy: 0.9181 - val_loss: 0.1848 - val_accuracy: 0.9179\nEpoch 91/100\n623/623 [==============================] - 0s 169us/step - loss: 0.1959 - accuracy: 0.9230 - val_loss: 0.1829 - val_accuracy: 0.9179\nEpoch 92/100\n623/623 [==============================] - 0s 174us/step - loss: 0.1815 - accuracy: 0.9262 - val_loss: 0.1848 - val_accuracy: 0.9179\nEpoch 93/100\n623/623 [==============================] - 0s 167us/step - loss: 0.1864 - accuracy: 0.9246 - val_loss: 0.1854 - val_accuracy: 0.9179\nEpoch 94/100\n623/623 [==============================] - 0s 173us/step - loss: 0.1905 - accuracy: 0.9230 - val_loss: 0.1863 - val_accuracy: 0.9179\nEpoch 95/100\n623/623 [==============================] - 0s 173us/step - loss: 0.1850 - accuracy: 0.9213 - val_loss: 0.1830 - val_accuracy: 0.9179\nEpoch 96/100\n623/623 [==============================] - 0s 187us/step - loss: 0.1991 - accuracy: 0.9197 - val_loss: 0.1837 - val_accuracy: 0.9179\nEpoch 97/100\n623/623 [==============================] - 0s 170us/step - loss: 0.1968 - accuracy: 0.9230 - val_loss: 0.1877 - val_accuracy: 0.9179\nEpoch 98/100\n623/623 [==============================] - 0s 162us/step - loss: 0.1853 - accuracy: 0.9230 - val_loss: 0.1854 - val_accuracy: 0.9179\nEpoch 99/100\n623/623 [==============================] - 0s 163us/step - loss: 0.1891 - accuracy: 0.9213 - val_loss: 0.1837 - val_accuracy: 0.9179\nEpoch 100/100\n623/623 [==============================] - 0s 181us/step - loss: 0.1958 - accuracy: 0.9213 - val_loss: 0.1843 - val_accuracy: 0.9179\n"
                    ]
                },
                "mc_idx": 167,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 90,
                "o_idx": 0
            }
        },
        {
            "source": "# 17. Neural Network 2\n\n# Model\nmodel = Sequential()\nmodel.add(Dense(16, input_dim = train.shape[1], init = 'he_normal', activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64, init = 'he_normal', activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(32, init = 'he_normal', activation = 'relu'))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nes = EarlyStopping(monitor='val_accuracy', patience=20, mode='max')\nhist = model.fit(train, target, batch_size=64, validation_data=(Xval, Zval), \n               epochs=500, verbose=1, callbacks=[es])\nY_pred = model.predict(test)\nY_pred = (Y_pred > 0.5)*1 # convert probabilities to binary output\nnn_prediction = model.predict(train)\nnn_prediction = (nn_prediction > 0.5)*1 # convert probabilities to binary output\nacc3_ann2 = round(metrics.accuracy_score(target, nn_prediction) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": np.reshape(Y_pred, len(Y_pred))})\nsubmission.to_csv('submission_ann2_3.csv', index=False)\nLB_ann2 = 0.79665",
            "mc_idx": 168,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.16666666666666666,
                "Data_Transform": 0.3888888888888889,
                "Model_Train": 0.8888888888888888,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.7777777777777778,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.1111111111111111,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "shape": 2,
                    "size": 1
                },
                "Data_Transform": {
                    ".reshape": 1,
                    ".add": 6
                },
                "Model_Train": {
                    "model.fit": 1,
                    "sequential(": 1,
                    "compile": 1,
                    ".fit(": 1,
                    "model": 12
                },
                "Model_Evaluation": {
                    "accuracy_score": 2,
                    "model": 12,
                    ".predict(": 2,
                    ".accuracy": 1,
                    "metrics.accuracy": 1
                },
                "Model_Interpretation": {
                    "shap": 2,
                    "model": 12
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    91,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, input_dim=3, activation=\"relu\", kernel_initializer=\"he_normal\")`\n  \"\"\"\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")`\n  import sys\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")`\n  if __name__ == '__main__':\n",
                        "Train on 891 samples, validate on 268 samples\nEpoch 1/500\n891/891 [==============================] - 0s 470us/step - loss: 0.6562 - accuracy: 0.6330 - val_loss: 0.5167 - val_accuracy: 0.7724\nEpoch 2/500\n891/891 [==============================] - 0s 71us/step - loss: 0.5283 - accuracy: 0.7262 - val_loss: 0.4046 - val_accuracy: 0.7799\nEpoch 3/500\n891/891 [==============================] - 0s 46us/step - loss: 0.4659 - accuracy: 0.7654 - val_loss: 0.3357 - val_accuracy: 0.8955\nEpoch 4/500\n891/891 [==============================] - 0s 60us/step - loss: 0.4176 - accuracy: 0.7856 - val_loss: 0.2857 - val_accuracy: 0.8955\nEpoch 5/500\n891/891 [==============================] - 0s 57us/step - loss: 0.3676 - accuracy: 0.8148 - val_loss: 0.2524 - val_accuracy: 0.8955\nEpoch 6/500\n891/891 [==============================] - 0s 49us/step - loss: 0.3430 - accuracy: 0.8182 - val_loss: 0.2312 - val_accuracy: 0.8955\nEpoch 7/500\n891/891 [==============================] - 0s 46us/step - loss: 0.3360 - accuracy: 0.8238 - val_loss: 0.2177 - val_accuracy: 0.8955\nEpoch 8/500\n891/891 [==============================] - 0s 56us/step - loss: 0.3144 - accuracy: 0.8406 - val_loss: 0.2103 - val_accuracy: 0.8955\nEpoch 9/500\n891/891 [==============================] - 0s 50us/step - loss: 0.3260 - accuracy: 0.8328 - val_loss: 0.2039 - val_accuracy: 0.8955\nEpoch 10/500\n891/891 [==============================] - 0s 49us/step - loss: 0.2881 - accuracy: 0.8552 - val_loss: 0.2003 - val_accuracy: 0.8955\nEpoch 11/500\n891/891 [==============================] - 0s 48us/step - loss: 0.2965 - accuracy: 0.8608 - val_loss: 0.1964 - val_accuracy: 0.9067\nEpoch 12/500\n891/891 [==============================] - 0s 47us/step - loss: 0.2671 - accuracy: 0.8844 - val_loss: 0.1929 - val_accuracy: 0.9067\nEpoch 13/500\n891/891 [==============================] - 0s 44us/step - loss: 0.2642 - accuracy: 0.8765 - val_loss: 0.1923 - val_accuracy: 0.9067\nEpoch 14/500\n891/891 [==============================] - 0s 50us/step - loss: 0.2531 - accuracy: 0.8855 - val_loss: 0.1892 - val_accuracy: 0.9067\nEpoch 15/500\n891/891 [==============================] - 0s 45us/step - loss: 0.2659 - accuracy: 0.8765 - val_loss: 0.1868 - val_accuracy: 0.9067\nEpoch 16/500\n891/891 [==============================] - 0s 41us/step - loss: 0.2476 - accuracy: 0.9035 - val_loss: 0.1856 - val_accuracy: 0.9067\nEpoch 17/500\n891/891 [==============================] - 0s 44us/step - loss: 0.2601 - accuracy: 0.8799 - val_loss: 0.1856 - val_accuracy: 0.9067\nEpoch 18/500\n891/891 [==============================] - 0s 46us/step - loss: 0.2499 - accuracy: 0.8934 - val_loss: 0.1849 - val_accuracy: 0.9067\nEpoch 19/500\n891/891 [==============================] - 0s 42us/step - loss: 0.2418 - accuracy: 0.8923 - val_loss: 0.1838 - val_accuracy: 0.9067\nEpoch 20/500\n891/891 [==============================] - 0s 48us/step - loss: 0.2469 - accuracy: 0.8889 - val_loss: 0.1829 - val_accuracy: 0.9104\nEpoch 21/500\n891/891 [==============================] - 0s 48us/step - loss: 0.2563 - accuracy: 0.8967 - val_loss: 0.1829 - val_accuracy: 0.9104\nEpoch 22/500\n891/891 [==============================] - 0s 45us/step - loss: 0.2461 - accuracy: 0.8923 - val_loss: 0.1822 - val_accuracy: 0.9104\nEpoch 23/500\n891/891 [==============================] - 0s 44us/step - loss: 0.2277 - accuracy: 0.9035 - val_loss: 0.1826 - val_accuracy: 0.9104\nEpoch 24/500\n891/891 [==============================] - 0s 46us/step - loss: 0.2346 - accuracy: 0.8945 - val_loss: 0.1818 - val_accuracy: 0.9104\nEpoch 25/500\n891/891 [==============================] - 0s 45us/step - loss: 0.2470 - accuracy: 0.8945 - val_loss: 0.1819 - val_accuracy: 0.9104\nEpoch 26/500\n891/891 [==============================] - 0s 48us/step - loss: 0.2282 - accuracy: 0.8979 - val_loss: 0.1822 - val_accuracy: 0.9104\nEpoch 27/500\n891/891 [==============================] - 0s 43us/step - loss: 0.2340 - accuracy: 0.9024 - val_loss: 0.1820 - val_accuracy: 0.9104\nEpoch 28/500\n891/891 [==============================] - 0s 49us/step - loss: 0.2372 - accuracy: 0.8967 - val_loss: 0.1818 - val_accuracy: 0.9104\nEpoch 29/500\n891/891 [==============================] - 0s 46us/step - loss: 0.2320 - accuracy: 0.8979 - val_loss: 0.1820 - val_accuracy: 0.9142\nEpoch 30/500\n891/891 [==============================] - 0s 46us/step - loss: 0.2182 - accuracy: 0.9102 - val_loss: 0.1818 - val_accuracy: 0.9104\nEpoch 31/500\n891/891 [==============================] - 0s 48us/step - loss: 0.2225 - accuracy: 0.8967 - val_loss: 0.1807 - val_accuracy: 0.9104\nEpoch 32/500\n891/891 [==============================] - 0s 47us/step - loss: 0.2382 - accuracy: 0.8934 - val_loss: 0.1816 - val_accuracy: 0.9104\nEpoch 33/500\n891/891 [==============================] - 0s 47us/step - loss: 0.2271 - accuracy: 0.8979 - val_loss: 0.1817 - val_accuracy: 0.9104\nEpoch 34/500\n891/891 [==============================] - 0s 45us/step - loss: 0.2143 - accuracy: 0.9192 - val_loss: 0.1817 - val_accuracy: 0.9104\nEpoch 35/500\n891/891 [==============================] - 0s 48us/step - loss: 0.2230 - accuracy: 0.9113 - val_loss: 0.1813 - val_accuracy: 0.9104\nEpoch 36/500\n891/891 [==============================] - 0s 46us/step - loss: 0.2234 - accuracy: 0.9068 - val_loss: 0.1813 - val_accuracy: 0.9104\nEpoch 37/500\n891/891 [==============================] - 0s 46us/step - loss: 0.2214 - accuracy: 0.9102 - val_loss: 0.1807 - val_accuracy: 0.9104\nEpoch 38/500\n891/891 [==============================] - 0s 44us/step - loss: 0.2134 - accuracy: 0.9068 - val_loss: 0.1811 - val_accuracy: 0.9104\nEpoch 39/500\n891/891 [==============================] - 0s 43us/step - loss: 0.2218 - accuracy: 0.9113 - val_loss: 0.1818 - val_accuracy: 0.9104\nEpoch 40/500\n891/891 [==============================] - 0s 46us/step - loss: 0.2221 - accuracy: 0.9046 - val_loss: 0.1821 - val_accuracy: 0.9104\nEpoch 41/500\n891/891 [==============================] - 0s 45us/step - loss: 0.2053 - accuracy: 0.9091 - val_loss: 0.1814 - val_accuracy: 0.9104\nEpoch 42/500\n891/891 [==============================] - 0s 42us/step - loss: 0.2216 - accuracy: 0.9046 - val_loss: 0.1808 - val_accuracy: 0.9104\nEpoch 43/500\n891/891 [==============================] - 0s 41us/step - loss: 0.2132 - accuracy: 0.9091 - val_loss: 0.1825 - val_accuracy: 0.9142\nEpoch 44/500\n891/891 [==============================] - 0s 45us/step - loss: 0.2044 - accuracy: 0.9136 - val_loss: 0.1820 - val_accuracy: 0.9142\nEpoch 45/500\n891/891 [==============================] - 0s 47us/step - loss: 0.2045 - accuracy: 0.9091 - val_loss: 0.1810 - val_accuracy: 0.9142\nEpoch 46/500\n891/891 [==============================] - 0s 50us/step - loss: 0.2048 - accuracy: 0.9136 - val_loss: 0.1796 - val_accuracy: 0.9142\nEpoch 47/500\n891/891 [==============================] - 0s 47us/step - loss: 0.2058 - accuracy: 0.9102 - val_loss: 0.1815 - val_accuracy: 0.9142\nEpoch 48/500\n891/891 [==============================] - 0s 46us/step - loss: 0.2164 - accuracy: 0.9091 - val_loss: 0.1823 - val_accuracy: 0.9142\nEpoch 49/500\n891/891 [==============================] - 0s 46us/step - loss: 0.2249 - accuracy: 0.9035 - val_loss: 0.1810 - val_accuracy: 0.9104\n"
                    ]
                },
                "mc_idx": 168,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 91,
                "o_idx": 1
            }
        },
        {
            "source": "# 5.18 VotingClassifier (hard voting)\n\nVoting_Classifier_hard = VotingClassifier(estimators=[('lr', logreg), ('rf', random_forest), ('gbc', gradient_boosting)], voting='hard')\nfor clf, label in zip([logreg, random_forest, gradient_boosting, Voting_Classifier_hard], \n                      ['Logistic Regression', 'Random Forest', 'Gradient Boosting Classifier', 'Ensemble']):\n    scores = cross_val_score(clf, train, target, cv=cv_number, scoring='accuracy')\n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\nVoting_Classifier_hard.fit(train, target)\nY_pred = Voting_Classifier_hard.predict(test).astype(int)\nVoting_Classifier_hard.score(train, target)\nacc3_VC_hard = round(Voting_Classifier_hard.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_VC_hard3.csv', index=False)\nLB_VC_hard = 0.80382",
            "mc_idx": 169,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.75,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.75,
                "Hyperparameter_Tuning": 0.25,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.5,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".std(": 1,
                    ".mean": 1,
                    ".std": 1
                },
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "votingclassifier": 2
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "gradient": 3
                },
                "Hyperparameter_Tuning": {
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    92,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Accuracy: 0.90 (+/- 0.00) [Logistic Regression]\nAccuracy: 0.92 (+/- 0.03) [Random Forest]\nAccuracy: 0.92 (+/- 0.03) [Gradient Boosting Classifier]\nAccuracy: 0.92 (+/- 0.03) [Ensemble]\n"
                    ]
                },
                "mc_idx": 169,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 92,
                "o_idx": 0
            }
        },
        {
            "source": "# 5.19 VotingClassifier (soft voting)\n\neclf = VotingClassifier(estimators=[('lr', logreg), ('rf', random_forest), ('gbc', gradient_boosting)], voting='soft')\nparams = {'lr__C': [1.0, 100.0], 'gbc__learning_rate': [0.05, 1]}\nVoting_Classifier_soft = GridSearchCV(estimator=eclf, param_grid=params, cv=cv_number)\nVoting_Classifier_soft.fit(train, target)\nY_pred = Voting_Classifier_soft.predict(test).astype(int)\nVoting_Classifier_soft.score(train, target)\nacc3_VC_soft = round(Voting_Classifier_soft.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_VC_soft3.csv', index=False)\nLB_VC_soft = 0.80382",
            "mc_idx": 170,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.14285714285714285,
                "Model_Train": 0.42857142857142855,
                "Model_Evaluation": 0.42857142857142855,
                "Model_Interpretation": 0.14285714285714285,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.2857142857142857,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "votingclassifier": 2
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "param_grid": 1,
                    "param": 3
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    93,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 170,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 93,
                "o_idx": 0
            }
        },
        {
            "source": "# 5.20 The simple rule in one line\nY_pred = (((test.WomanOrBoySurvived <= 0.238) & (test.Sex > 0.5) & (test.Alone > 0.5)) | \\\n          ((test.WomanOrBoySurvived > 0.238) & \\\n           ~((test.WomanOrBoySurvived > 0.55) & (test.WomanOrBoySurvived <= 0.633))))\nacc3_simple_rule = acc_simple_rule\nLB_simple_rule = 0.80382",
            "mc_idx": 171,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    94,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 171,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 94,
                "o_idx": 0
            }
        },
        {
            "source": "## 7. Models evaluation <a class=\"anchor\" id=\"7\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 172,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "We can now rank our evaluation of all the models to choose the best one for our problem.",
            "mc_idx": 173,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "models = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Support Vector Machines', 'Linear SVC', 'k-Nearest Neighbors', 'Naive Bayes', \n              'Perceptron', 'Stochastic Gradient Decent', \n              'Decision Tree Classifier', 'Random Forest',  'XGBClassifier', 'LGBMClassifier',\n              'GradientBoostingClassifier', 'RidgeClassifier', 'BaggingClassifier', 'ExtraTreesClassifier', \n              'Neural Network 1', 'Neural Network 2', \n              'VotingClassifier-hard voiting', 'VotingClassifier-soft voting',\n              'Simple rule'],\n    \n    'Score16': [acc_log, acc_svc, acc_linear_svc, acc_knn, acc_gaussian, \n              acc_perceptron, acc_sgd, \n              acc_decision_tree, acc_random_forest, acc_XGB_Classifier, acc_LGB_Classifier,\n              acc_gradient_boosting, acc_ridge_classifier, acc_bagging_classifier, acc_etc, \n              acc_ann1, acc_ann2, \n              acc_VC_hard, acc_VC_soft,\n              acc_simple_rule],\n\n    'Score3': [acc3_log, acc3_svc, acc3_linear_svc, acc3_knn, acc3_gaussian, \n              acc3_perceptron, acc3_sgd, \n              acc3_decision_tree, acc3_random_forest, acc3_XGB_Classifier, acc3_LGB_Classifier,\n              acc3_gradient_boosting, acc3_ridge_classifier, acc3_bagging_classifier, acc3_etc, \n              acc3_ann1, acc3_ann2, \n              acc3_VC_hard, acc3_VC_soft,\n              acc3_simple_rule],\n\n    'LB_all': [LB_log_all, LB_svc_all, LB_linear_svc_all, LB_knn_all, LB_gaussian_all, \n              LB_perceptron_all, LB_sgd_all, \n              LB_decision_tree_all, LB_random_forest_all, LB_XGB_Classifier_all, LB_LGB_Classifier_all,\n              LB_GBC_all, LB_RidgeClassifier_all, LB_bagging_classifier_all, LB_ETC_all, \n              LB_ann1_all, LB_ann2_all, \n              LB_VC_hard_all, LB_VC_soft_all,\n              LB_simple_rule_all],\n    \n    'LB':    [LB_log, LB_svc, LB_linear_svc, LB_knn, LB_gaussian, \n              LB_perceptron, LB_sgd, \n              LB_decision_tree, LB_random_forest, LB_XGB_Classifier, LB_LGB_Classifier,\n              LB_GBC, LB_RidgeClassifier, LB_bagging_classifier, LB_ETC, \n              LB_ann1, LB_ann2, \n              LB_VC_hard, LB_VC_soft,\n              LB_simple_rule]})",
            "mc_idx": 174,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.10526315789473684,
                "Model_Interpretation": 0.3157894736842105,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 2,
                    "ridge": 5,
                    "gradientboostingclassifier": 1,
                    "svc": 9,
                    "votingclassifier": 2
                },
                "Model_Evaluation": {
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2,
                    "gradient": 4
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    95,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 174,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 95,
                "o_idx": 0
            }
        },
        {
            "source": "models.sort_values(by=['Score16', 'LB_all', 'LB'], ascending=False)",
            "mc_idx": 175,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    96,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "                            Model  Score16  Score3   LB_all       LB\n11     GradientBoostingClassifier   100.00   92.26  0.82296  0.80382\n8                   Random Forest   100.00   92.26  0.81339  0.80382\n17  VotingClassifier-hard voiting   100.00   92.26  0.81339  0.80382\n18   VotingClassifier-soft voting   100.00   92.26  0.81339  0.80382\n7        Decision Tree Classifier   100.00   92.26  0.77990  0.80382\n13              BaggingClassifier    99.66   92.26  0.80861  0.80382\n1         Support Vector Machines    98.99   92.14  0.62200  0.79904\n10                 LGBMClassifier    96.07   90.12  0.82296  0.62200\n2                      Linear SVC    94.61   89.45  0.81339  0.77033\n9                   XGBClassifier    94.39   77.78  0.80861  0.68899\n0             Logistic Regression    93.60   89.45  0.79904  0.77033\n14           ExtraTreesClassifier    93.38   92.14  0.80861  0.79904\n12                RidgeClassifier    93.15   89.56  0.80861  0.77511\n19                    Simple rule    92.70   92.70  0.83253  0.80382\n15               Neural Network 1    90.35   92.14  0.59330  0.79904\n4                     Naive Bayes    86.53   77.67  0.73205  0.68899\n3             k-Nearest Neighbors    76.32   90.68  0.62679  0.77751\n6      Stochastic Gradient Decent    72.17   91.36  0.64593  0.77511\n16               Neural Network 2    61.17   91.47  0.64114  0.79665\n5                      Perceptron    50.73   89.90  0.46889  0.77511"
                    ]
                },
                "mc_idx": 175,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 96,
                "o_idx": 0
            }
        },
        {
            "source": "models.sort_values(by=['Score3', 'LB_all', 'LB'], ascending=False)",
            "mc_idx": 176,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    97,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "                            Model  Score16  Score3   LB_all       LB\n19                    Simple rule    92.70   92.70  0.83253  0.80382\n11     GradientBoostingClassifier   100.00   92.26  0.82296  0.80382\n8                   Random Forest   100.00   92.26  0.81339  0.80382\n17  VotingClassifier-hard voiting   100.00   92.26  0.81339  0.80382\n18   VotingClassifier-soft voting   100.00   92.26  0.81339  0.80382\n13              BaggingClassifier    99.66   92.26  0.80861  0.80382\n7        Decision Tree Classifier   100.00   92.26  0.77990  0.80382\n14           ExtraTreesClassifier    93.38   92.14  0.80861  0.79904\n1         Support Vector Machines    98.99   92.14  0.62200  0.79904\n15               Neural Network 1    90.35   92.14  0.59330  0.79904\n16               Neural Network 2    61.17   91.47  0.64114  0.79665\n6      Stochastic Gradient Decent    72.17   91.36  0.64593  0.77511\n3             k-Nearest Neighbors    76.32   90.68  0.62679  0.77751\n10                 LGBMClassifier    96.07   90.12  0.82296  0.62200\n5                      Perceptron    50.73   89.90  0.46889  0.77511\n12                RidgeClassifier    93.15   89.56  0.80861  0.77511\n2                      Linear SVC    94.61   89.45  0.81339  0.77033\n0             Logistic Regression    93.60   89.45  0.79904  0.77033\n9                   XGBClassifier    94.39   77.78  0.80861  0.68899\n4                     Naive Bayes    86.53   77.67  0.73205  0.68899"
                    ]
                },
                "mc_idx": 176,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 97,
                "o_idx": 0
            }
        },
        {
            "source": "models.sort_values(by=['LB_all', 'LB', 'Score3'], ascending=False)",
            "mc_idx": 177,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    98,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "                            Model  Score16  Score3   LB_all       LB\n19                    Simple rule    92.70   92.70  0.83253  0.80382\n11     GradientBoostingClassifier   100.00   92.26  0.82296  0.80382\n10                 LGBMClassifier    96.07   90.12  0.82296  0.62200\n8                   Random Forest   100.00   92.26  0.81339  0.80382\n17  VotingClassifier-hard voiting   100.00   92.26  0.81339  0.80382\n18   VotingClassifier-soft voting   100.00   92.26  0.81339  0.80382\n2                      Linear SVC    94.61   89.45  0.81339  0.77033\n13              BaggingClassifier    99.66   92.26  0.80861  0.80382\n14           ExtraTreesClassifier    93.38   92.14  0.80861  0.79904\n12                RidgeClassifier    93.15   89.56  0.80861  0.77511\n9                   XGBClassifier    94.39   77.78  0.80861  0.68899\n0             Logistic Regression    93.60   89.45  0.79904  0.77033\n7        Decision Tree Classifier   100.00   92.26  0.77990  0.80382\n4                     Naive Bayes    86.53   77.67  0.73205  0.68899\n6      Stochastic Gradient Decent    72.17   91.36  0.64593  0.77511\n16               Neural Network 2    61.17   91.47  0.64114  0.79665\n3             k-Nearest Neighbors    76.32   90.68  0.62679  0.77751\n1         Support Vector Machines    98.99   92.14  0.62200  0.79904\n15               Neural Network 1    90.35   92.14  0.59330  0.79904\n5                      Perceptron    50.73   89.90  0.46889  0.77511"
                    ]
                },
                "mc_idx": 177,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 98,
                "o_idx": 0
            }
        },
        {
            "source": "models.sort_values(by=['LB', 'LB_all', 'Score3'], ascending=False)",
            "mc_idx": 178,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    99,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "                            Model  Score16  Score3   LB_all       LB\n19                    Simple rule    92.70   92.70  0.83253  0.80382\n11     GradientBoostingClassifier   100.00   92.26  0.82296  0.80382\n8                   Random Forest   100.00   92.26  0.81339  0.80382\n17  VotingClassifier-hard voiting   100.00   92.26  0.81339  0.80382\n18   VotingClassifier-soft voting   100.00   92.26  0.81339  0.80382\n13              BaggingClassifier    99.66   92.26  0.80861  0.80382\n7        Decision Tree Classifier   100.00   92.26  0.77990  0.80382\n14           ExtraTreesClassifier    93.38   92.14  0.80861  0.79904\n1         Support Vector Machines    98.99   92.14  0.62200  0.79904\n15               Neural Network 1    90.35   92.14  0.59330  0.79904\n16               Neural Network 2    61.17   91.47  0.64114  0.79665\n3             k-Nearest Neighbors    76.32   90.68  0.62679  0.77751\n12                RidgeClassifier    93.15   89.56  0.80861  0.77511\n6      Stochastic Gradient Decent    72.17   91.36  0.64593  0.77511\n5                      Perceptron    50.73   89.90  0.46889  0.77511\n2                      Linear SVC    94.61   89.45  0.81339  0.77033\n0             Logistic Regression    93.60   89.45  0.79904  0.77033\n9                   XGBClassifier    94.39   77.78  0.80861  0.68899\n4                     Naive Bayes    86.53   77.67  0.73205  0.68899\n10                 LGBMClassifier    96.07   90.12  0.82296  0.62200"
                    ]
                },
                "mc_idx": 178,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 99,
                "o_idx": 0
            }
        },
        {
            "source": "## 8. Conclusion <a class=\"anchor\" id=\"8\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 179,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "- The best model is the **simple rule in one line** from [\"Titanic Top 3% : one line of the prediction code\"](https://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code). Surprisingly, that the simple rule in one line gives the best result. This once again proves the enormous value of features engineering. The optimal selection of features is the key to success!\n\n- Models **GradientBoostingClassifier, Random Forests, VotingClassifiers, BaggingClassifier, Decision Tree Classifier** have provided the same accuracy LB on the test dataset as the simple rule, although on the training dataset they are much more accurate up to 100%.\n\n- The **VotingClassifier** for both voting options (\"*hard*\" and \"*soft*\") aggregation gave the same result for all the variants of features, that is, the solution found is indeed optimal, although a **Logistic Regression**, which is not one of the best, was selected for voting. This confirms the high efficiency of this method of aggregating (ensembling) predictions.\n\n- The models **GradientBoostingClassifier, BaggingClassifier, Random Forests, VotingClassifiers** did a good job of optimizing the features themselves, providing comparable accuracy for the different number of features in the test dataset, but the models **Decision Tree Classifier, Stochastic Gradient Descent, Support Vector Machines, Perceptron, Neural Networks, k-Nearest Neighbors algorithm** are very sensitive to the feature sets, because the accuracy of LB_all and LB is very different. Models **XGB Classifier, LGBM Classifier, ExtraTreesClassifier, Logistic Regression, Linear SVC, Naive Bayes, RidgeClassifier** depend on FE, but not so significantly.\n\n- The methods **LGBM Classifier, Perceptron, Neural Networks, Linear SVC, Naive Bayes, Logistic Regression, k-Nearest Neighbors algorithm, RidgeClassifier** have low accuracy LB, especially methods **Naive Bayes, Logistic Regression, Linear SVC**, compared to other models, although the \"***Titanic: Machine Learning from Disaster***\" contest is not indicative for the machine learning tasks because it contains too little data.\n\n- In all models, except **LGBM Classifier, Linear SVC, RidgeClassifier, Logistic Regression, Naive Bayes**, the prediction of test dataset based on 3 features yielded a more accurate result, possibly because these models perform worse under conditions of low number of features or under conditions of significant data dependence (in fact, feature \"*WomanOrBoySurvived*\" is, in part derived from others features \"*Sex*\" and \"*Alone*\") or with a small number of points (millions of points may vary greatly). Particularly interesting is that the **LGBM Classifier** model and method gave comparatively low accuracy on both the training and test datasets for the variant with three features, unlike **XGB Classifier** and other decision tree-based methods in which LB > LB_all.\n\n- To increase the accuracy of predictions, its need to increase the number of features and further improve their processing, that is FE (for example, add the processed feature \"**Tickets**\" - context is consist of a good kernels with have examples of such processing ([\"Advanced Feature Engineering Tutorial with Titanic\"](https://www.kaggle.com/gunesevitan/advanced-feature-engineering-tutorial-with-titanic) etc.).",
            "mc_idx": 180,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "I hope you find this kernel useful and enjoyable.",
            "mc_idx": 181,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Your comments and feedback are most welcome.",
            "mc_idx": 182,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "[Go to Top](#0)",
            "mc_idx": 183,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        }
    ],
    "code_cells": [
        {
            "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n\n# models\nfrom sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier \nfrom sklearn.ensemble import BaggingClassifier, VotingClassifier \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\n# NN models\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras import optimizers\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# model tuning\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe, space_eval\n\n# import warnings filter\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)",
            "mc_idx": 6,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.015384615384615385,
                "Data_Transform": 0.015384615384615385,
                "Model_Train": 0.08461538461538462,
                "Model_Evaluation": 0.03076923076923077,
                "Model_Interpretation": 0.03076923076923077,
                "Hyperparameter_Tuning": 0.026923076923076925,
                "Visualization": 0.011538461538461539,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 26
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "matplotlib": 2,
                    ".mode": 2
                },
                "Data_Transform": {
                    "labelencoder": 2,
                    ".mod": 2
                },
                "Model_Train": {
                    "train_test_split": 1,
                    "model": 7,
                    "randomforestclassifier": 2,
                    "model_selection": 1,
                    "logisticregression": 1,
                    "ridge": 1,
                    "sgdclassifier": 1,
                    "gradientboostingclassifier": 1,
                    "decisiontreeclassifier": 1,
                    "kneighborsclassifier": 1,
                    "svc": 2,
                    "gaussiannb": 1,
                    "votingclassifier": 1,
                    ".linear": 1
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    "model": 7
                },
                "Model_Interpretation": {
                    "model": 7,
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "hyperopt": 1,
                    "model tuning": 1,
                    "cross_val_score": 1,
                    "train_test_split": 1
                },
                "Visualization": {
                    "matplotlib": 2,
                    "pyplot": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    0,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Using TensorFlow backend.\n"
                    ]
                },
                "mc_idx": 6,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 0,
                "o_idx": 0
            }
        },
        {
            "source": "cv_number = 5",
            "mc_idx": 7,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    1,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 7,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 1,
                "o_idx": 0
            }
        },
        {
            "source": "traindf = pd.read_csv('../input/titanic/train.csv').set_index('PassengerId')\ntestdf = pd.read_csv('../input/titanic/test.csv').set_index('PassengerId')\nsubmission = pd.read_csv('../input/titanic/gender_submission.csv')",
            "mc_idx": 9,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.16666666666666666,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 6,
                    "pd.read_": 6
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".set_index": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    2,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 9,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 2,
                "o_idx": 0
            }
        },
        {
            "source": "#Thanks to:\n# https://www.kaggle.com/mauricef/titanic\n# https://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code\n#\ndf = pd.concat([traindf, testdf], axis=0, sort=False)\ndf['Title'] = df.Name.str.split(',').str[1].str.split('.').str[0].str.strip()\ndf['Title'] = df.Name.str.split(',').str[1].str.split('.').str[0].str.strip()\ndf['IsWomanOrBoy'] = ((df.Title == 'Master') | (df.Sex == 'female'))\ndf['LastName'] = df.Name.str.split(',').str[0]\nfamily = df.groupby(df.LastName).Survived\ndf['WomanOrBoyCount'] = family.transform(lambda s: s[df.IsWomanOrBoy].fillna(0).count())\ndf['WomanOrBoyCount'] = df.mask(df.IsWomanOrBoy, df.WomanOrBoyCount - 1, axis=0)\ndf['FamilySurvivedCount'] = family.transform(lambda s: s[df.IsWomanOrBoy].fillna(0).sum())\ndf['FamilySurvivedCount'] = df.mask(df.IsWomanOrBoy, df.FamilySurvivedCount - \\\n                                    df.Survived.fillna(0), axis=0)\ndf['WomanOrBoySurvived'] = df.FamilySurvivedCount / df.WomanOrBoyCount.replace(0, np.nan)\ndf.WomanOrBoyCount = df.WomanOrBoyCount.replace(np.nan, 0)\ndf['Alone'] = (df.WomanOrBoyCount == 0)\n\n#Thanks to https://www.kaggle.com/kpacocha/top-6-titanic-machine-learning-from-disaster\n#\"Title\" improvement\ndf['Title'] = df['Title'].replace('Ms','Miss')\ndf['Title'] = df['Title'].replace('Mlle','Miss')\ndf['Title'] = df['Title'].replace('Mme','Mrs')\n# Embarked\ndf['Embarked'] = df['Embarked'].fillna('S')\n# Cabin, Deck\ndf['Deck'] = df['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\ndf.loc[(df['Deck'] == 'T'), 'Deck'] = 'A'\n\n# Thanks to https://www.kaggle.com/erinsweet/simpledetect\n# Fare\nmed_fare = df.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]\ndf['Fare'] = df['Fare'].fillna(med_fare)\n#Age\ndf['Age'] = df.groupby(['Sex', 'Pclass', 'Title'])['Age'].apply(lambda x: x.fillna(x.median()))\n# Family_Size\ndf['Family_Size'] = df['SibSp'] + df['Parch'] + 1\n\n# Thanks to https://www.kaggle.com/vbmokin/titanic-top-3-cluster-analysis\ncols_to_drop = ['Name','Ticket','Cabin']\ndf = df.drop(cols_to_drop, axis=1)\n\ndf.WomanOrBoySurvived = df.WomanOrBoySurvived.fillna(0)\ndf.WomanOrBoyCount = df.WomanOrBoyCount.fillna(0)\ndf.FamilySurvivedCount = df.FamilySurvivedCount.fillna(0)\ndf.Alone = df.Alone.fillna(0)",
            "mc_idx": 11,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.23404255319148937,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".median": 4,
                    "size": 2,
                    ".notnull": 1,
                    ".sum": 1,
                    ".groupby": 3
                },
                "Data_Transform": {
                    ".concat(": 1,
                    ".groupby(": 3,
                    ".fillna(": 10,
                    ".apply(": 2,
                    ".replace(": 5,
                    "transform": 2,
                    ".split": 5,
                    ".drop": 1,
                    ".fillna": 10,
                    ".replace": 5,
                    ".apply": 2,
                    ".concat": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    3,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 11,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 3,
                "o_idx": 0
            }
        },
        {
            "source": "target = df.Survived.loc[traindf.index]\ndf = df.drop(['Survived'], axis=1)\ntrain, test = df.loc[traindf.index], df.loc[testdf.index]",
            "mc_idx": 12,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    4,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 12,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 4,
                "o_idx": 0
            }
        },
        {
            "source": "train.head(3)",
            "mc_idx": 13,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    5,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "             Pclass     Sex   Age  SibSp  Parch     Fare Embarked Title  \\\nPassengerId                                                               \n1                 3    male  22.0      1      0   7.2500        S    Mr   \n2                 1  female  38.0      1      0  71.2833        C   Mrs   \n3                 3  female  26.0      0      0   7.9250        S  Miss   \n\n             IsWomanOrBoy   LastName  WomanOrBoyCount  FamilySurvivedCount  \\\nPassengerId                                                                  \n1                   False     Braund              0.0                  0.0   \n2                    True    Cumings              0.0                  0.0   \n3                    True  Heikkinen              0.0                  0.0   \n\n             WomanOrBoySurvived  Alone Deck  Family_Size  \nPassengerId                                               \n1                           0.0   True    M            2  \n2                           0.0   True    C            2  \n3                           0.0   True    M            1  "
                    ]
                },
                "mc_idx": 13,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 5,
                "o_idx": 0
            }
        },
        {
            "source": "test.head(3)",
            "mc_idx": 14,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    6,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "             Pclass     Sex   Age  SibSp  Parch    Fare Embarked Title  \\\nPassengerId                                                              \n892               3    male  34.5      0      0  7.8292        Q    Mr   \n893               3  female  47.0      1      0  7.0000        S   Mrs   \n894               2    male  62.0      0      0  9.6875        Q    Mr   \n\n             IsWomanOrBoy LastName  WomanOrBoyCount  FamilySurvivedCount  \\\nPassengerId                                                                \n892                 False    Kelly              0.0                  0.0   \n893                  True   Wilkes              0.0                  0.0   \n894                 False    Myles              0.0                  0.0   \n\n             WomanOrBoySurvived  Alone Deck  Family_Size  \nPassengerId                                               \n892                         0.0   True    M            1  \n893                         0.0   True    M            2  \n894                         0.0   True    M            1  "
                    ]
                },
                "mc_idx": 14,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 6,
                "o_idx": 0
            }
        },
        {
            "source": "target[:3]",
            "mc_idx": 15,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    7,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "PassengerId\n1    0.0\n2    1.0\n3    1.0\nName: Survived, dtype: float64"
                    ]
                },
                "mc_idx": 15,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 7,
                "o_idx": 0
            }
        },
        {
            "source": "# Determination categorical features\nnumerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ncategorical_columns = []\nfeatures = train.columns.values.tolist()\nfor col in features:\n    if train[col].dtype in numerics: continue\n    categorical_columns.append(col)\ncategorical_columns",
            "mc_idx": 19,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 4
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    8,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Sex', 'Embarked', 'Title', 'IsWomanOrBoy', 'LastName', 'Alone', 'Deck']"
                    ]
                },
                "mc_idx": 19,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 8,
                "o_idx": 0
            }
        },
        {
            "source": "# Encoding categorical features\nfor col in categorical_columns:\n    if col in train.columns:\n        le = LabelEncoder()\n        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n        train[col] = le.transform(list(train[col].astype(str).values))\n        test[col] = le.transform(list(test[col].astype(str).values))   ",
            "mc_idx": 20,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 1.0,
                "Model_Train": 0.125,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 2
                },
                "Data_Transform": {
                    "transform": 2,
                    ".astype(": 4,
                    "labelencoder": 2
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    9,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 20,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 9,
                "o_idx": 0
            }
        },
        {
            "source": "train.info()",
            "mc_idx": 21,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".info(": 1,
                    "info": 1,
                    ".info": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    10,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 891 entries, 1 to 891\nData columns (total 16 columns):\nPclass                 891 non-null int64\nSex                    891 non-null int64\nAge                    891 non-null float64\nSibSp                  891 non-null int64\nParch                  891 non-null int64\nFare                   891 non-null float64\nEmbarked               891 non-null int64\nTitle                  891 non-null int64\nIsWomanOrBoy           891 non-null int64\nLastName               891 non-null int64\nWomanOrBoyCount        891 non-null float64\nFamilySurvivedCount    891 non-null float64\nWomanOrBoySurvived     891 non-null float64\nAlone                  891 non-null int64\nDeck                   891 non-null int64\nFamily_Size            891 non-null int64\ndtypes: float64(5), int64(11)\nmemory usage: 118.3 KB\n"
                    ]
                },
                "mc_idx": 21,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 10,
                "o_idx": 0
            }
        },
        {
            "source": "test.info()",
            "mc_idx": 22,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".info(": 1,
                    "info": 1,
                    ".info": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    11,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 418 entries, 892 to 1309\nData columns (total 16 columns):\nPclass                 418 non-null int64\nSex                    418 non-null int64\nAge                    418 non-null float64\nSibSp                  418 non-null int64\nParch                  418 non-null int64\nFare                   418 non-null float64\nEmbarked               418 non-null int64\nTitle                  418 non-null int64\nIsWomanOrBoy           418 non-null int64\nLastName               418 non-null int64\nWomanOrBoyCount        418 non-null float64\nFamilySurvivedCount    418 non-null float64\nWomanOrBoySurvived     418 non-null float64\nAlone                  418 non-null int64\nDeck                   418 non-null int64\nFamily_Size            418 non-null int64\ndtypes: float64(5), int64(11)\nmemory usage: 55.5 KB\n"
                    ]
                },
                "mc_idx": 22,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 11,
                "o_idx": 0
            }
        },
        {
            "source": "#%% split training set to validation set\nSEED = 100\nXtrain, Xval, Ztrain, Zval = train_test_split(train, target, test_size=0.3, random_state=SEED)",
            "mc_idx": 24,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "train_test_split": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "train_test_split": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    12,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 24,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 12,
                "o_idx": 0
            }
        },
        {
            "source": "# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(train, target)\nY_pred = logreg.predict(test).astype(int)\nacc_log = round(logreg.score(train, target) * 100, 2)\nacc_log",
            "mc_idx": 30,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "logisticregression": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    13,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "93.6"
                    ]
                },
                "mc_idx": 30,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 13,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_logreg.csv', index=False)\nLB_log_all = 0.79904  # old version",
            "mc_idx": 31,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    14,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 31,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 14,
                "o_idx": 0
            }
        },
        {
            "source": "coeff_df = pd.DataFrame(train.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)",
            "mc_idx": 33,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.5,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 2
                },
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "coef_": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    15,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "                Feature  Correlation\n12                Alone     4.806590\n8              LastName     3.836475\n11   WomanOrBoySurvived     1.434728\n7          IsWomanOrBoy     0.168430\n14          Family_Size     0.050806\n5              Embarked     0.001786\n9       WomanOrBoyCount     0.000120\n2                 SibSp    -0.027352\n6                 Title    -0.185026\n3                 Parch    -0.203336\n4                  Fare    -0.260847\n10  FamilySurvivedCount    -0.593419\n13                 Deck    -0.838817\n1                   Age    -1.169061\n0                   Sex    -1.300208"
                    ]
                },
                "mc_idx": 33,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 15,
                "o_idx": 0
            }
        },
        {
            "source": "# Support Vector Machines\n\nsvc = SVC()\nsvc.fit(train, target)\nY_pred = svc.predict(test).astype(int)\nacc_svc = round(svc.score(train, target) * 100, 2)\nacc_svc",
            "mc_idx": 37,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.125,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.25,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "svc": 7
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    16,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "98.99"
                    ]
                },
                "mc_idx": 37,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 16,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_svm.csv', index=False)\nLB_svc_all = 0.62200  # old version",
            "mc_idx": 38,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.5,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "svc": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    17,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 38,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 17,
                "o_idx": 0
            }
        },
        {
            "source": "# Linear SVC\n\nlinear_svc = LinearSVC(dual=False)  # dual=False when n_samples > n_features.\nlinear_svc.fit(train, target)\nY_pred = linear_svc.predict(test).astype(int)\nacc_linear_svc = round(linear_svc.score(train, target) * 100, 2)\nacc_linear_svc",
            "mc_idx": 42,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.1111111111111111,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.2222222222222222,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "svc": 8
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    18,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "94.61"
                    ]
                },
                "mc_idx": 42,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 18,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_linear_svc.csv', index=False)\nLB_linear_svc_all = 0.81339  # old version",
            "mc_idx": 43,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "svc": 2
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    19,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 43,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 19,
                "o_idx": 0
            }
        },
        {
            "source": "# k-Nearest Neighbors algorithm\n\nknn = GridSearchCV(estimator=KNeighborsClassifier(), param_grid={'n_neighbors': [2, 3, 4]}, cv=cv_number).fit(train, target)\nY_pred = knn.predict(test).astype(int)\nacc_knn = round(knn.score(train, target) * 100, 2)\nprint(acc_knn, knn.best_params_)",
            "mc_idx": 47,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.16666666666666666,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "kneighborsclassifier": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "param_grid": 1,
                    "param": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    20,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "76.32 {'n_neighbors': 4}\n"
                    ]
                },
                "mc_idx": 47,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 20,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_knn.csv', index=False)\nLB_knn_all = 0.62679  # old version",
            "mc_idx": 48,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    21,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 48,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 21,
                "o_idx": 0
            }
        },
        {
            "source": "# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(train, target)\nY_pred = gaussian.predict(test).astype(int)\nacc_gaussian = round(gaussian.score(train, target) * 100, 2)\nacc_gaussian",
            "mc_idx": 52,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "gaussiannb": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    22,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "86.53"
                    ]
                },
                "mc_idx": 52,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 22,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_GaussianNB.csv', index=False)\nLB_gaussian_all = 0.73205  # old version",
            "mc_idx": 53,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.5,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "gaussiannb": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    23,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 53,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 23,
                "o_idx": 0
            }
        },
        {
            "source": "# Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(train, target)\nY_pred = perceptron.predict(test).astype(int)\nacc_perceptron = round(perceptron.score(train, target) * 100, 2)\nacc_perceptron",
            "mc_idx": 57,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 0.5,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    24,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "50.73"
                    ]
                },
                "mc_idx": 57,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 24,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_perceptron.csv', index=False)\nLB_perceptron_all = 0.46889  # old version",
            "mc_idx": 58,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    25,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 58,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 25,
                "o_idx": 0
            }
        },
        {
            "source": "# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(train, target)\nY_pred = sgd.predict(test).astype(int)\nacc_sgd = round(sgd.score(train, target) * 100, 2)\nacc_sgd",
            "mc_idx": 62,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "sgdclassifier": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    26,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "72.17"
                    ]
                },
                "mc_idx": 62,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 26,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_sgd.csv', index=False)\nLB_sgd_all = 0.64593  # old version",
            "mc_idx": 63,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    27,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 63,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 27,
                "o_idx": 0
            }
        },
        {
            "source": "# Decision Tree Classifier\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(train, target)\nY_pred = decision_tree.predict(test).astype(int)\nacc_decision_tree = round(decision_tree.score(train, target) * 100, 2)\nacc_decision_tree",
            "mc_idx": 67,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "decisiontreeclassifier": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    28,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "100.0"
                    ]
                },
                "mc_idx": 67,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 28,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_decision_tree.csv', index=False)\nLB_decision_tree_all = 0.77990  # old version",
            "mc_idx": 68,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    29,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 68,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 29,
                "o_idx": 0
            }
        },
        {
            "source": "# Random Forest\n\nrandom_forest = GridSearchCV(estimator=RandomForestClassifier(), param_grid={'n_estimators': [200, 300, 400, 500]}, cv=cv_number).fit(train, target)\nrandom_forest.fit(train, target)\nY_pred = random_forest.predict(test).astype(int)\nrandom_forest.score(train, target)\nacc_random_forest = round(random_forest.score(train, target) * 100, 2)\nprint(acc_random_forest,random_forest.best_params_)",
            "mc_idx": 72,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.16666666666666666,
                "Model_Train": 0.6666666666666666,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 2,
                    "randomforestclassifier": 2
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "param_grid": 1,
                    "param": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    30,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "100.0 {'n_estimators': 300}\n"
                    ]
                },
                "mc_idx": 72,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 30,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_random_forest.csv', index=False)\nLB_random_forest_all = 0.81339  # old version",
            "mc_idx": 73,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    31,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 73,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 31,
                "o_idx": 0
            }
        },
        {
            "source": "%%time\ndef hyperopt_xgb_score(params):\n    clf = XGBClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_xgb = {\n            'learning_rate': hp.quniform('learning_rate', 0, 0.05, 0.0001),\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_depth':  hp.choice('max_depth', np.arange(5, 8, dtype=int)),\n            'min_child_weight': hp.quniform('min_child_weight', 1, 9, 0.025),\n            'subsample': hp.quniform('subsample', 0.5, 1, 0.005),\n            'gamma': hp.quniform('gamma', 0.5, 1, 0.005),\n            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.005),\n            'eval_metric': 'auc',\n            'objective': 'binary:logistic',\n            'booster': 'gbtree',\n            'tree_method': 'exact',\n            'silent': 1,\n            'missing': None\n        }\n \nbest = fmin(fn=hyperopt_xgb_score, space=space_xgb, algo=tpe.suggest, max_evals=10)\nprint('best:')\nprint(best)",
            "mc_idx": 77,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.16666666666666666,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {
                    "cross_val_score": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "hyperopt": 2,
                    "param": 3,
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    32,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0.9282083008397443\n{'booster': 'gbtree', 'colsample_bytree': 0.78, 'eval_metric': 'auc', 'gamma': 0.665, 'learning_rate': 0.0088, 'max_depth': 7, 'min_child_weight': 3.8000000000000003, 'missing': None, 'n_estimators': 378, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.595, 'tree_method': 'exact'}\n0.9315791582839413\n{'booster': 'gbtree', 'colsample_bytree': 0.755, 'eval_metric': 'auc', 'gamma': 0.985, 'learning_rate': 0.0304, 'max_depth': 5, 'min_child_weight': 1.925, 'missing': None, 'n_estimators': 112, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.67, 'tree_method': 'exact'}\n0.9338263492951772\n{'booster': 'gbtree', 'colsample_bytree': 0.745, 'eval_metric': 'auc', 'gamma': 0.855, 'learning_rate': 0.0028, 'max_depth': 5, 'min_child_weight': 8.6, 'missing': None, 'n_estimators': 175, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.88, 'tree_method': 'exact'}\n0.9315728812140776\n{'booster': 'gbtree', 'colsample_bytree': 0.6900000000000001, 'eval_metric': 'auc', 'gamma': 0.595, 'learning_rate': 0.0263, 'max_depth': 5, 'min_child_weight': 6.65, 'missing': None, 'n_estimators': 547, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.91, 'tree_method': 'exact'}\n0.9260240223818323\n{'booster': 'gbtree', 'colsample_bytree': 0.8, 'eval_metric': 'auc', 'gamma': 0.595, 'learning_rate': 0.0015, 'max_depth': 7, 'min_child_weight': 8.575000000000001, 'missing': None, 'n_estimators': 970, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.5700000000000001, 'tree_method': 'exact'}\n0.9315602561470069\n{'booster': 'gbtree', 'colsample_bytree': 0.9550000000000001, 'eval_metric': 'auc', 'gamma': 0.66, 'learning_rate': 0.032100000000000004, 'max_depth': 7, 'min_child_weight': 8.450000000000001, 'missing': None, 'n_estimators': 551, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.895, 'tree_method': 'exact'}\n0.9304492147811164\n{'booster': 'gbtree', 'colsample_bytree': 0.985, 'eval_metric': 'auc', 'gamma': 0.855, 'learning_rate': 0.023700000000000002, 'max_depth': 7, 'min_child_weight': 4.0, 'missing': None, 'n_estimators': 723, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.875, 'tree_method': 'exact'}\n0.9293256192754985\n{'booster': 'gbtree', 'colsample_bytree': 0.9550000000000001, 'eval_metric': 'auc', 'gamma': 0.64, 'learning_rate': 0.0218, 'max_depth': 7, 'min_child_weight': 1.6, 'missing': None, 'n_estimators': 552, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.855, 'tree_method': 'exact'}\n0.9338137951554497\n{'booster': 'gbtree', 'colsample_bytree': 0.65, 'eval_metric': 'auc', 'gamma': 0.78, 'learning_rate': 0.0349, 'max_depth': 7, 'min_child_weight': 4.4, 'missing': None, 'n_estimators': 600, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.53, 'tree_method': 'exact'}\n0.9371656795353692\n{'booster': 'gbtree', 'colsample_bytree': 0.9500000000000001, 'eval_metric': 'auc', 'gamma': 0.6900000000000001, 'learning_rate': 0.0325, 'max_depth': 5, 'min_child_weight': 4.4750000000000005, 'missing': None, 'n_estimators': 815, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.685, 'tree_method': 'exact'}\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:20<00:00,  2.07s/it, best loss: 0.9260240223818323]\nbest:\n{'colsample_bytree': 0.8, 'gamma': 0.595, 'learning_rate': 0.0015, 'max_depth': 2, 'min_child_weight': 8.575000000000001, 'n_estimators': 870, 'subsample': 0.5700000000000001}\nCPU times: user 20.8 s, sys: 350 ms, total: 21.1 s\nWall time: 21.1 s\n"
                    ]
                },
                "mc_idx": 77,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 32,
                "o_idx": 0
            }
        },
        {
            "source": "params = space_eval(space_xgb, best)\nparams",
            "mc_idx": 78,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    33,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "{'booster': 'gbtree',\n 'colsample_bytree': 0.8,\n 'eval_metric': 'auc',\n 'gamma': 0.595,\n 'learning_rate': 0.0015,\n 'max_depth': 7,\n 'min_child_weight': 8.575000000000001,\n 'missing': None,\n 'n_estimators': 970,\n 'objective': 'binary:logistic',\n 'silent': 1,\n 'subsample': 0.5700000000000001,\n 'tree_method': 'exact'}"
                    ]
                },
                "mc_idx": 78,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 33,
                "o_idx": 0
            }
        },
        {
            "source": "XGB_Classifier = XGBClassifier(**params)\nXGB_Classifier.fit(train, target)\nY_pred = XGB_Classifier.predict(test).astype(int)\nXGB_Classifier.score(train, target)\nacc_XGB_Classifier = round(XGB_Classifier.score(train, target) * 100, 2)\nacc_XGB_Classifier",
            "mc_idx": 79,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.3333333333333333,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    34,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "94.39"
                    ]
                },
                "mc_idx": 79,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 34,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_XGB_Classifier.csv', index=False)\nLB_XGB_Classifier_all = 0.80861  # old version",
            "mc_idx": 80,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    35,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 80,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 35,
                "o_idx": 0
            }
        },
        {
            "source": "fig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nxgb.plot_importance(XGB_Classifier,ax = axes,height =0.5)\nplt.show();\nplt.close()",
            "mc_idx": 81,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {
                    ".add": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "plot_importance": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0039_c036_o000_image_0.png",
                    36,
                    0,
                    0
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1080x1080 with 1 Axes>"
                    ]
                },
                "mc_idx": 81,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 36,
                "o_idx": 0
            }
        },
        {
            "source": "%%time\ndef hyperopt_lgb_score(params):\n    clf = LGBMClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_lgb = {\n            'learning_rate': hp.quniform('learning_rate', 0, 0.05, 0.0001),\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_depth':  hp.choice('max_depth', np.arange(4, 7, dtype=int)),\n            'num_leaves': hp.choice('num_leaves', 2*np.arange(20, 2**6, dtype=int)),\n            'min_child_weight': hp.quniform('min_child_weight', 1, 9, 0.025),\n            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.005),\n            'objective': 'binary',\n            'boosting_type': 'gbdt',\n            }\n \nbest = fmin(fn=hyperopt_lgb_score, space=space_lgb, algo=tpe.suggest, max_evals=10)\nprint('best:')\nprint(best)",
            "mc_idx": 85,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.16666666666666666,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {
                    "cross_val_score": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "hyperopt": 2,
                    "param": 3,
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    37,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0.9315664622895274\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.96, 'learning_rate': 0.0341, 'max_depth': 5, 'min_child_weight': 3.725, 'n_estimators': 488, 'num_leaves': 106, 'objective': 'binary'}\n0.9326964057923524\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.0455, 'max_depth': 6, 'min_child_weight': 3.225, 'n_estimators': 267, 'num_leaves': 62, 'objective': 'binary'}\n0.9259736639682359\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.635, 'learning_rate': 0.015300000000000001, 'max_depth': 6, 'min_child_weight': 4.675, 'n_estimators': 249, 'num_leaves': 116, 'objective': 'binary'}\n0.9315665332168706\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.625, 'learning_rate': 0.039900000000000005, 'max_depth': 6, 'min_child_weight': 5.300000000000001, 'n_estimators': 340, 'num_leaves': 56, 'objective': 'binary'}\n0.9349373906610676\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.59, 'learning_rate': 0.0483, 'max_depth': 6, 'min_child_weight': 5.800000000000001, 'n_estimators': 308, 'num_leaves': 58, 'objective': 'binary'}\n0.9315601852196638\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.0224, 'max_depth': 4, 'min_child_weight': 7.45, 'n_estimators': 697, 'num_leaves': 92, 'objective': 'binary'}\n0.9282146488369512\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.6, 'learning_rate': 0.0047, 'max_depth': 4, 'min_child_weight': 6.875, 'n_estimators': 982, 'num_leaves': 40, 'objective': 'binary'}\n0.9304492857084595\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.845, 'learning_rate': 0.0077, 'max_depth': 4, 'min_child_weight': 8.525, 'n_estimators': 816, 'num_leaves': 40, 'objective': 'binary'}\n0.931591783351012\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.8250000000000001, 'learning_rate': 0.0059, 'max_depth': 5, 'min_child_weight': 2.625, 'n_estimators': 735, 'num_leaves': 98, 'objective': 'binary'}\n0.936048361099615\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.98, 'learning_rate': 0.0281, 'max_depth': 4, 'min_child_weight': 6.8500000000000005, 'n_estimators': 828, 'num_leaves': 44, 'objective': 'binary'}\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:09<00:00,  1.00it/s, best loss: 0.9259736639682359]\nbest:\n{'colsample_bytree': 0.635, 'learning_rate': 0.015300000000000001, 'max_depth': 2, 'min_child_weight': 4.675, 'n_estimators': 149, 'num_leaves': 38}\nCPU times: user 9.68 s, sys: 760 ms, total: 10.4 s\nWall time: 10.4 s\n"
                    ]
                },
                "mc_idx": 85,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 37,
                "o_idx": 0
            }
        },
        {
            "source": "params = space_eval(space_lgb, best)\nparams",
            "mc_idx": 86,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    38,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "{'boosting_type': 'gbdt',\n 'colsample_bytree': 0.635,\n 'learning_rate': 0.015300000000000001,\n 'max_depth': 6,\n 'min_child_weight': 4.675,\n 'n_estimators': 249,\n 'num_leaves': 116,\n 'objective': 'binary'}"
                    ]
                },
                "mc_idx": 86,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 38,
                "o_idx": 0
            }
        },
        {
            "source": "LGB_Classifier = LGBMClassifier(**params)\nLGB_Classifier.fit(train, target)\nY_pred = LGB_Classifier.predict(test).astype(int)\nLGB_Classifier.score(train, target)\nacc_LGB_Classifier = round(LGB_Classifier.score(train, target) * 100, 2)\nacc_LGB_Classifier",
            "mc_idx": 87,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.3333333333333333,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    39,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "96.07"
                    ]
                },
                "mc_idx": 87,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 39,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_LGB_Classifier.csv', index=False)\nLB_LGB_Classifier_all = 0.82296  # old version",
            "mc_idx": 88,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    40,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 88,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 40,
                "o_idx": 0
            }
        },
        {
            "source": "fig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nlgb.plot_importance(LGB_Classifier,ax = axes,height = 0.5)\nplt.show();\nplt.close()",
            "mc_idx": 89,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {
                    ".add": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "plot_importance": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0039_c041_o000_image_1.png",
                    41,
                    0,
                    1
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1080x1080 with 1 Axes>"
                    ]
                },
                "mc_idx": 89,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 41,
                "o_idx": 0
            }
        },
        {
            "source": "%%time\ndef hyperopt_gb_score(params):\n    clf = GradientBoostingClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_gb = {\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_depth': hp.choice('max_depth', np.arange(5, 8, dtype=int))            \n        }\n \nbest = fmin(fn=hyperopt_gb_score, space=space_gb, algo=tpe.suggest, max_evals=10)\nprint('best:')\nprint(best)",
            "mc_idx": 93,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 0.0,
                "Model_Train": 0.16666666666666666,
                "Model_Evaluation": 0.16666666666666666,
                "Model_Interpretation": 0.16666666666666666,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "cross_val_score": 1
                },
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {
                    "hyperopt": 2,
                    "param": 3,
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    42,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0.9349372488063814\n{'max_depth': 7, 'n_estimators': 412}\n0.9315664622895274\n{'max_depth': 6, 'n_estimators': 644}\n0.9338073053035565\n{'max_depth': 7, 'n_estimators': 721}\n0.9371466355437486\n{'max_depth': 5, 'n_estimators': 269}\n0.9326837807252817\n{'max_depth': 6, 'n_estimators': 271}\n0.9326900577951454\n{'max_depth': 6, 'n_estimators': 414}\n0.9371593315381623\n{'max_depth': 5, 'n_estimators': 867}\n0.9338073762308996\n{'max_depth': 6, 'n_estimators': 441}\n0.9326837097979386\n{'max_depth': 7, 'n_estimators': 632}\n0.9349309008091746\n{'max_depth': 7, 'n_estimators': 656}\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:32<00:00,  3.28s/it, best loss: 0.9315664622895274]\nbest:\n{'max_depth': 1, 'n_estimators': 544}\nCPU times: user 33.2 s, sys: 72.1 ms, total: 33.2 s\nWall time: 33.2 s\n"
                    ]
                },
                "mc_idx": 93,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 42,
                "o_idx": 0
            }
        },
        {
            "source": "params = space_eval(space_gb, best)\nparams",
            "mc_idx": 94,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    43,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "{'max_depth': 6, 'n_estimators': 644}"
                    ]
                },
                "mc_idx": 94,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 43,
                "o_idx": 0
            }
        },
        {
            "source": "# Gradient Boosting Classifier\n\ngradient_boosting = GradientBoostingClassifier(**params)\ngradient_boosting.fit(train, target)\nY_pred = gradient_boosting.predict(test).astype(int)\ngradient_boosting.score(train, target)\nacc_gradient_boosting = round(gradient_boosting.score(train, target) * 100, 2)\nacc_gradient_boosting",
            "mc_idx": 95,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.1111111111111111,
                "Model_Train": 0.2222222222222222,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.1111111111111111,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "gradient": 9
                },
                "Hyperparameter_Tuning": {
                    "param": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    44,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "100.0"
                    ]
                },
                "mc_idx": 95,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 44,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_gradient_boosting.csv', index=False)\nLB_GBC_all = 0.82296  # old version",
            "mc_idx": 96,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    45,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 96,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 45,
                "o_idx": 0
            }
        },
        {
            "source": "# Ridge Classifier\n\nridge_classifier = RidgeClassifier()\nridge_classifier.fit(train, target)\nY_pred = ridge_classifier.predict(test).astype(int)\nridge_classifier.score(train, target)\nacc_ridge_classifier = round(ridge_classifier.score(train, target) * 100, 2)\nacc_ridge_classifier",
            "mc_idx": 100,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.1,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.3,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "ridge": 9
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    46,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "93.15"
                    ]
                },
                "mc_idx": 100,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 46,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_ridge_classifier.csv', index=False)\nLB_RidgeClassifier_all = 0.80861  # old version",
            "mc_idx": 101,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "ridge": 2
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    47,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 101,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 47,
                "o_idx": 0
            }
        },
        {
            "source": "# Bagging Classifier\n\nbagging_classifier = BaggingClassifier()\nbagging_classifier.fit(train, target)\nY_pred = bagging_classifier.predict(test).astype(int)\nbagging_classifier.score(train, target)\nacc_bagging_classifier = round(bagging_classifier.score(train, target) * 100, 2)\nacc_bagging_classifier",
            "mc_idx": 105,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    48,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "99.66"
                    ]
                },
                "mc_idx": 105,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 48,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_bagging_classifier.csv', index=False)\nLB_bagging_classifier_all = 0.80861  # old version",
            "mc_idx": 106,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    49,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 106,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 49,
                "o_idx": 0
            }
        },
        {
            "source": "def hyperopt_etc_score(params):\n    clf = ExtraTreesClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_etc = {\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_features': hp.choice('max_features', np.arange(2, 10, dtype=int)),\n            'min_samples_leaf': hp.choice('min_samples_leaf', np.arange(1, 5, dtype=int)),\n            'max_depth':  hp.choice('max_depth', np.arange(4, 8, dtype=int)),\n        }\n \nbest = fmin(fn=hyperopt_etc_score, space=space_etc, algo=tpe.suggest, max_evals=10)\nprint('best:')\nprint(best)",
            "mc_idx": 110,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.16666666666666666,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {
                    "cross_val_score": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "hyperopt": 2,
                    "param": 3,
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    50,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0.9293508694096397\n{'max_depth': 5, 'max_features': 3, 'min_samples_leaf': 4, 'n_estimators': 699}\n0.9372098318064449\n{'max_depth': 7, 'max_features': 8, 'min_samples_leaf': 2, 'n_estimators': 181}\n0.9383145961024715\n{'max_depth': 5, 'max_features': 8, 'min_samples_leaf': 3, 'n_estimators': 671}\n0.9405617871137075\n{'max_depth': 6, 'max_features': 4, 'min_samples_leaf': 1, 'n_estimators': 662}\n0.9394444686779533\n{'max_depth': 7, 'max_features': 4, 'min_samples_leaf': 2, 'n_estimators': 440}\n0.9349626407952091\n{'max_depth': 7, 'max_features': 9, 'min_samples_leaf': 2, 'n_estimators': 838}\n0.932715449783973\n{'max_depth': 4, 'max_features': 6, 'min_samples_leaf': 3, 'n_estimators': 742}\n0.9383208731723354\n{'max_depth': 6, 'max_features': 5, 'min_samples_leaf': 2, 'n_estimators': 336}\n0.9315981313482189\n{'max_depth': 4, 'max_features': 6, 'min_samples_leaf': 3, 'n_estimators': 191}\n0.928220925906815\n{'max_depth': 4, 'max_features': 4, 'min_samples_leaf': 3, 'n_estimators': 622}\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:27<00:00,  2.80s/it, best loss: 0.928220925906815]\nbest:\n{'max_depth': 0, 'max_features': 2, 'min_samples_leaf': 2, 'n_estimators': 522}\n"
                    ]
                },
                "mc_idx": 110,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 50,
                "o_idx": 0
            }
        },
        {
            "source": "params = space_eval(space_etc, best)\nparams",
            "mc_idx": 111,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    51,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "{'max_depth': 4, 'max_features': 4, 'min_samples_leaf': 3, 'n_estimators': 622}"
                    ]
                },
                "mc_idx": 111,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 51,
                "o_idx": 0
            }
        },
        {
            "source": "# Extra Trees Classifier\n\nextra_trees_classifier = ExtraTreesClassifier(**params)\nextra_trees_classifier.fit(train, target)\nY_pred = extra_trees_classifier.predict(test).astype(int)\nextra_trees_classifier.score(train, target)\nacc_etc = round(extra_trees_classifier.score(train, target) * 100, 2)\nacc_etc",
            "mc_idx": 112,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.3333333333333333,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    52,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "93.38"
                    ]
                },
                "mc_idx": 112,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 52,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_etc.csv', index=False)\nLB_ETC_all = 0.80861  # old version",
            "mc_idx": 113,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    53,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 113,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 53,
                "o_idx": 0
            }
        },
        {
            "source": "def build_ann(optimizer='adam'):\n    \n    # Initializing the ANN\n    ann = Sequential()\n    \n    # Adding the input layer and the first hidden layer of the ANN with dropout\n    ann.add(Dense(units=32, kernel_initializer='glorot_uniform', activation='relu', input_shape=(16,)))\n    \n    # Add other layers, it is not necessary to pass the shape because there is a layer before\n    ann.add(Dense(units=64, kernel_initializer='glorot_uniform', activation='relu'))\n    ann.add(Dropout(rate=0.5))\n    ann.add(Dense(units=64, kernel_initializer='glorot_uniform', activation='relu'))\n    ann.add(Dropout(rate=0.5))\n    \n    # Adding the output layer\n    ann.add(Dense(units=1, kernel_initializer='glorot_uniform', activation='sigmoid'))\n    \n    # Compiling the ANN\n    ann.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return ann",
            "mc_idx": 117,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 1.0,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.3333333333333333,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "shape": 2
                },
                "Data_Transform": {
                    ".add": 6
                },
                "Model_Train": {
                    "sequential(": 1,
                    "compile": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    54,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 117,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 54,
                "o_idx": 0
            }
        },
        {
            "source": "opt = optimizers.Adam(lr=0.001)\nann = build_ann(opt)\n# Training the ANN\nhistory = ann.fit(Xtrain, Ztrain, batch_size=16, epochs=100, validation_data=(Xval, Zval))",
            "mc_idx": 118,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    55,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Train on 623 samples, validate on 268 samples\nEpoch 1/100\n623/623 [==============================] - 0s 748us/step - loss: 11.0590 - accuracy: 0.5457 - val_loss: 4.8565 - val_accuracy: 0.5933\nEpoch 2/100\n623/623 [==============================] - 0s 206us/step - loss: 5.2457 - accuracy: 0.5201 - val_loss: 2.2716 - val_accuracy: 0.6194\nEpoch 3/100\n623/623 [==============================] - 0s 176us/step - loss: 3.1837 - accuracy: 0.5409 - val_loss: 1.0874 - val_accuracy: 0.6530\nEpoch 4/100\n623/623 [==============================] - 0s 169us/step - loss: 1.6270 - accuracy: 0.5730 - val_loss: 0.7815 - val_accuracy: 0.6530\nEpoch 5/100\n623/623 [==============================] - 0s 166us/step - loss: 1.1755 - accuracy: 0.5827 - val_loss: 0.6427 - val_accuracy: 0.6604\nEpoch 6/100\n623/623 [==============================] - 0s 183us/step - loss: 0.8752 - accuracy: 0.5618 - val_loss: 0.6425 - val_accuracy: 0.6716\nEpoch 7/100\n623/623 [==============================] - 0s 174us/step - loss: 0.8974 - accuracy: 0.6260 - val_loss: 0.6614 - val_accuracy: 0.6455\nEpoch 8/100\n623/623 [==============================] - 0s 169us/step - loss: 0.7519 - accuracy: 0.6356 - val_loss: 0.6508 - val_accuracy: 0.6493\nEpoch 9/100\n623/623 [==============================] - 0s 169us/step - loss: 0.6961 - accuracy: 0.6388 - val_loss: 0.6594 - val_accuracy: 0.6306\nEpoch 10/100\n623/623 [==============================] - 0s 171us/step - loss: 0.6912 - accuracy: 0.6517 - val_loss: 0.6613 - val_accuracy: 0.6231\nEpoch 11/100\n623/623 [==============================] - 0s 165us/step - loss: 0.6821 - accuracy: 0.6549 - val_loss: 0.6417 - val_accuracy: 0.6493\nEpoch 12/100\n623/623 [==============================] - 0s 172us/step - loss: 0.6512 - accuracy: 0.6501 - val_loss: 0.6608 - val_accuracy: 0.6306\nEpoch 13/100\n623/623 [==============================] - 0s 170us/step - loss: 0.6699 - accuracy: 0.6453 - val_loss: 0.6591 - val_accuracy: 0.6157\nEpoch 14/100\n623/623 [==============================] - 0s 167us/step - loss: 0.6647 - accuracy: 0.6372 - val_loss: 0.6449 - val_accuracy: 0.6269\nEpoch 15/100\n623/623 [==============================] - 0s 167us/step - loss: 0.6707 - accuracy: 0.6404 - val_loss: 0.6637 - val_accuracy: 0.6269\nEpoch 16/100\n623/623 [==============================] - 0s 163us/step - loss: 0.6492 - accuracy: 0.6437 - val_loss: 0.6473 - val_accuracy: 0.6269\nEpoch 17/100\n623/623 [==============================] - 0s 162us/step - loss: 0.6424 - accuracy: 0.6469 - val_loss: 0.6348 - val_accuracy: 0.6269\nEpoch 18/100\n623/623 [==============================] - 0s 168us/step - loss: 0.6774 - accuracy: 0.6485 - val_loss: 0.6330 - val_accuracy: 0.6343\nEpoch 19/100\n623/623 [==============================] - 0s 170us/step - loss: 0.6586 - accuracy: 0.6485 - val_loss: 0.6482 - val_accuracy: 0.6343\nEpoch 20/100\n623/623 [==============================] - 0s 174us/step - loss: 0.6413 - accuracy: 0.6421 - val_loss: 0.6609 - val_accuracy: 0.6343\nEpoch 21/100\n623/623 [==============================] - 0s 162us/step - loss: 0.6555 - accuracy: 0.6421 - val_loss: 0.6599 - val_accuracy: 0.6269\nEpoch 22/100\n623/623 [==============================] - 0s 165us/step - loss: 0.6493 - accuracy: 0.6501 - val_loss: 0.6624 - val_accuracy: 0.6269\nEpoch 23/100\n623/623 [==============================] - 0s 171us/step - loss: 0.6365 - accuracy: 0.6485 - val_loss: 0.6577 - val_accuracy: 0.6231\nEpoch 24/100\n623/623 [==============================] - 0s 164us/step - loss: 0.6527 - accuracy: 0.6421 - val_loss: 0.6573 - val_accuracy: 0.6269\nEpoch 25/100\n623/623 [==============================] - 0s 156us/step - loss: 0.6244 - accuracy: 0.6581 - val_loss: 0.6487 - val_accuracy: 0.6306\nEpoch 26/100\n623/623 [==============================] - 0s 165us/step - loss: 0.6698 - accuracy: 0.6292 - val_loss: 0.6261 - val_accuracy: 0.6231\nEpoch 27/100\n623/623 [==============================] - 0s 162us/step - loss: 0.6253 - accuracy: 0.6421 - val_loss: 0.6424 - val_accuracy: 0.6231\nEpoch 28/100\n623/623 [==============================] - 0s 164us/step - loss: 0.6429 - accuracy: 0.6469 - val_loss: 0.6655 - val_accuracy: 0.6269\nEpoch 29/100\n623/623 [==============================] - 0s 161us/step - loss: 0.6374 - accuracy: 0.6581 - val_loss: 0.6632 - val_accuracy: 0.6343\nEpoch 30/100\n623/623 [==============================] - 0s 158us/step - loss: 0.6436 - accuracy: 0.6565 - val_loss: 0.6608 - val_accuracy: 0.6343\nEpoch 31/100\n623/623 [==============================] - 0s 164us/step - loss: 0.6333 - accuracy: 0.6661 - val_loss: 0.6528 - val_accuracy: 0.6418\nEpoch 32/100\n623/623 [==============================] - 0s 167us/step - loss: 0.6457 - accuracy: 0.6404 - val_loss: 0.6433 - val_accuracy: 0.6306\nEpoch 33/100\n623/623 [==============================] - 0s 165us/step - loss: 0.6389 - accuracy: 0.6485 - val_loss: 0.6252 - val_accuracy: 0.6269\nEpoch 34/100\n623/623 [==============================] - 0s 168us/step - loss: 0.6245 - accuracy: 0.6693 - val_loss: 0.6086 - val_accuracy: 0.6604\nEpoch 35/100\n623/623 [==============================] - 0s 156us/step - loss: 0.6418 - accuracy: 0.6629 - val_loss: 0.6431 - val_accuracy: 0.6381\nEpoch 36/100\n623/623 [==============================] - 0s 164us/step - loss: 0.6253 - accuracy: 0.6709 - val_loss: 0.5964 - val_accuracy: 0.6567\nEpoch 37/100\n623/623 [==============================] - 0s 164us/step - loss: 0.6105 - accuracy: 0.6613 - val_loss: 0.5954 - val_accuracy: 0.6530\nEpoch 38/100\n623/623 [==============================] - 0s 157us/step - loss: 0.6199 - accuracy: 0.6581 - val_loss: 0.6227 - val_accuracy: 0.6381\nEpoch 39/100\n623/623 [==============================] - 0s 164us/step - loss: 0.6284 - accuracy: 0.6629 - val_loss: 0.6481 - val_accuracy: 0.6418\nEpoch 40/100\n623/623 [==============================] - 0s 157us/step - loss: 0.6320 - accuracy: 0.6581 - val_loss: 0.6233 - val_accuracy: 0.6530\nEpoch 41/100\n623/623 [==============================] - 0s 169us/step - loss: 0.5928 - accuracy: 0.6597 - val_loss: 0.6018 - val_accuracy: 0.6455\nEpoch 42/100\n623/623 [==============================] - 0s 167us/step - loss: 0.6154 - accuracy: 0.6565 - val_loss: 0.6165 - val_accuracy: 0.6306\nEpoch 43/100\n623/623 [==============================] - 0s 164us/step - loss: 0.5999 - accuracy: 0.6581 - val_loss: 0.6204 - val_accuracy: 0.6381\nEpoch 44/100\n623/623 [==============================] - 0s 170us/step - loss: 0.6221 - accuracy: 0.6613 - val_loss: 0.6560 - val_accuracy: 0.6306\nEpoch 45/100\n623/623 [==============================] - 0s 164us/step - loss: 0.6177 - accuracy: 0.6870 - val_loss: 0.6413 - val_accuracy: 0.6604\nEpoch 46/100\n623/623 [==============================] - 0s 201us/step - loss: 0.6250 - accuracy: 0.6645 - val_loss: 0.6308 - val_accuracy: 0.6567\nEpoch 47/100\n623/623 [==============================] - 0s 186us/step - loss: 0.6188 - accuracy: 0.6661 - val_loss: 0.5917 - val_accuracy: 0.6493\nEpoch 48/100\n623/623 [==============================] - 0s 193us/step - loss: 0.6194 - accuracy: 0.6677 - val_loss: 0.6603 - val_accuracy: 0.6418\nEpoch 49/100\n623/623 [==============================] - 0s 183us/step - loss: 0.6269 - accuracy: 0.6693 - val_loss: 0.6581 - val_accuracy: 0.6269\nEpoch 50/100\n623/623 [==============================] - 0s 183us/step - loss: 0.6161 - accuracy: 0.6629 - val_loss: 0.5938 - val_accuracy: 0.6716\nEpoch 51/100\n623/623 [==============================] - 0s 181us/step - loss: 0.5908 - accuracy: 0.6726 - val_loss: 0.6082 - val_accuracy: 0.6418\nEpoch 52/100\n623/623 [==============================] - 0s 191us/step - loss: 0.5905 - accuracy: 0.6661 - val_loss: 0.6110 - val_accuracy: 0.6530\nEpoch 53/100\n623/623 [==============================] - 0s 181us/step - loss: 0.6012 - accuracy: 0.6726 - val_loss: 0.6438 - val_accuracy: 0.6642\nEpoch 54/100\n623/623 [==============================] - 0s 182us/step - loss: 0.6238 - accuracy: 0.6806 - val_loss: 0.6298 - val_accuracy: 0.6791\nEpoch 55/100\n623/623 [==============================] - 0s 167us/step - loss: 0.6283 - accuracy: 0.6790 - val_loss: 0.5868 - val_accuracy: 0.6530\nEpoch 56/100\n623/623 [==============================] - 0s 159us/step - loss: 0.5815 - accuracy: 0.6693 - val_loss: 0.6013 - val_accuracy: 0.6455\nEpoch 57/100\n623/623 [==============================] - 0s 167us/step - loss: 0.6193 - accuracy: 0.6613 - val_loss: 0.6136 - val_accuracy: 0.6269\nEpoch 58/100\n623/623 [==============================] - 0s 163us/step - loss: 0.6023 - accuracy: 0.6677 - val_loss: 0.5653 - val_accuracy: 0.6679\nEpoch 59/100\n623/623 [==============================] - 0s 159us/step - loss: 0.5933 - accuracy: 0.6902 - val_loss: 0.5942 - val_accuracy: 0.6530\nEpoch 60/100\n623/623 [==============================] - 0s 156us/step - loss: 0.5916 - accuracy: 0.6677 - val_loss: 0.5656 - val_accuracy: 0.6791\nEpoch 61/100\n623/623 [==============================] - 0s 168us/step - loss: 0.5677 - accuracy: 0.6758 - val_loss: 0.6210 - val_accuracy: 0.6716\nEpoch 62/100\n623/623 [==============================] - 0s 166us/step - loss: 0.5659 - accuracy: 0.6950 - val_loss: 0.5651 - val_accuracy: 0.6493\nEpoch 63/100\n623/623 [==============================] - 0s 160us/step - loss: 0.5551 - accuracy: 0.6806 - val_loss: 0.5672 - val_accuracy: 0.6791\nEpoch 64/100\n623/623 [==============================] - 0s 159us/step - loss: 0.5967 - accuracy: 0.7014 - val_loss: 0.6415 - val_accuracy: 0.6493\nEpoch 65/100\n623/623 [==============================] - 0s 162us/step - loss: 0.5943 - accuracy: 0.6838 - val_loss: 0.6288 - val_accuracy: 0.6418\nEpoch 66/100\n623/623 [==============================] - 0s 169us/step - loss: 0.5929 - accuracy: 0.6902 - val_loss: 0.6604 - val_accuracy: 0.6418\nEpoch 67/100\n623/623 [==============================] - 0s 159us/step - loss: 0.6062 - accuracy: 0.6581 - val_loss: 0.5817 - val_accuracy: 0.6642\nEpoch 68/100\n623/623 [==============================] - 0s 163us/step - loss: 0.5646 - accuracy: 0.7159 - val_loss: 0.5792 - val_accuracy: 0.6679\nEpoch 69/100\n623/623 [==============================] - 0s 158us/step - loss: 0.5813 - accuracy: 0.7159 - val_loss: 0.6136 - val_accuracy: 0.8134\nEpoch 70/100\n623/623 [==============================] - 0s 160us/step - loss: 0.5916 - accuracy: 0.7030 - val_loss: 0.5700 - val_accuracy: 0.6567\nEpoch 71/100\n623/623 [==============================] - 0s 165us/step - loss: 0.5584 - accuracy: 0.7014 - val_loss: 0.5374 - val_accuracy: 0.6903\nEpoch 72/100\n623/623 [==============================] - 0s 165us/step - loss: 0.5562 - accuracy: 0.7287 - val_loss: 0.5613 - val_accuracy: 0.6828\nEpoch 73/100\n623/623 [==============================] - 0s 160us/step - loss: 0.5631 - accuracy: 0.6742 - val_loss: 0.6013 - val_accuracy: 0.6343\nEpoch 74/100\n623/623 [==============================] - 0s 175us/step - loss: 0.5841 - accuracy: 0.7014 - val_loss: 0.5745 - val_accuracy: 0.7836\nEpoch 75/100\n623/623 [==============================] - 0s 159us/step - loss: 0.5783 - accuracy: 0.7063 - val_loss: 0.5170 - val_accuracy: 0.7425\nEpoch 76/100\n623/623 [==============================] - 0s 169us/step - loss: 0.5433 - accuracy: 0.6838 - val_loss: 0.5659 - val_accuracy: 0.6567\nEpoch 77/100\n623/623 [==============================] - 0s 159us/step - loss: 0.5299 - accuracy: 0.7255 - val_loss: 0.5275 - val_accuracy: 0.8060\nEpoch 78/100\n623/623 [==============================] - 0s 159us/step - loss: 0.5303 - accuracy: 0.7287 - val_loss: 0.5114 - val_accuracy: 0.7239\nEpoch 79/100\n623/623 [==============================] - 0s 170us/step - loss: 0.5322 - accuracy: 0.7127 - val_loss: 0.4695 - val_accuracy: 0.7612\nEpoch 80/100\n623/623 [==============================] - 0s 169us/step - loss: 0.4957 - accuracy: 0.7496 - val_loss: 0.4377 - val_accuracy: 0.8507\nEpoch 81/100\n623/623 [==============================] - 0s 173us/step - loss: 0.5046 - accuracy: 0.7448 - val_loss: 0.4392 - val_accuracy: 0.8246\nEpoch 82/100\n623/623 [==============================] - 0s 159us/step - loss: 0.4840 - accuracy: 0.7368 - val_loss: 0.4791 - val_accuracy: 0.7948\nEpoch 83/100\n623/623 [==============================] - 0s 174us/step - loss: 0.5155 - accuracy: 0.7512 - val_loss: 0.3824 - val_accuracy: 0.8358\nEpoch 84/100\n623/623 [==============================] - 0s 161us/step - loss: 0.5019 - accuracy: 0.7223 - val_loss: 0.4909 - val_accuracy: 0.7164\nEpoch 85/100\n623/623 [==============================] - 0s 218us/step - loss: 0.5393 - accuracy: 0.7239 - val_loss: 0.6398 - val_accuracy: 0.6940\nEpoch 86/100\n623/623 [==============================] - 0s 178us/step - loss: 0.5693 - accuracy: 0.7416 - val_loss: 0.5782 - val_accuracy: 0.7612\nEpoch 87/100\n623/623 [==============================] - 0s 159us/step - loss: 0.5785 - accuracy: 0.7191 - val_loss: 0.5697 - val_accuracy: 0.7425\nEpoch 88/100\n623/623 [==============================] - 0s 170us/step - loss: 0.5150 - accuracy: 0.7223 - val_loss: 0.4088 - val_accuracy: 0.8209\nEpoch 89/100\n623/623 [==============================] - 0s 169us/step - loss: 0.4400 - accuracy: 0.7881 - val_loss: 0.3991 - val_accuracy: 0.8955\nEpoch 90/100\n623/623 [==============================] - 0s 169us/step - loss: 0.5006 - accuracy: 0.7528 - val_loss: 0.6254 - val_accuracy: 0.6716\nEpoch 91/100\n623/623 [==============================] - 0s 152us/step - loss: 0.5478 - accuracy: 0.6934 - val_loss: 0.3992 - val_accuracy: 0.8694\nEpoch 92/100\n623/623 [==============================] - 0s 155us/step - loss: 0.5405 - accuracy: 0.7030 - val_loss: 0.6259 - val_accuracy: 0.6567\nEpoch 93/100\n623/623 [==============================] - 0s 158us/step - loss: 0.5793 - accuracy: 0.6806 - val_loss: 0.5835 - val_accuracy: 0.7052\nEpoch 94/100\n623/623 [==============================] - 0s 162us/step - loss: 0.5030 - accuracy: 0.7368 - val_loss: 0.4124 - val_accuracy: 0.8396\nEpoch 95/100\n623/623 [==============================] - 0s 172us/step - loss: 0.4738 - accuracy: 0.7384 - val_loss: 0.3676 - val_accuracy: 0.8955\nEpoch 96/100\n623/623 [==============================] - 0s 158us/step - loss: 0.4600 - accuracy: 0.7560 - val_loss: 0.4546 - val_accuracy: 0.8246\nEpoch 97/100\n623/623 [==============================] - 0s 159us/step - loss: 0.4367 - accuracy: 0.7592 - val_loss: 0.4510 - val_accuracy: 0.7313\nEpoch 98/100\n623/623 [==============================] - 0s 160us/step - loss: 0.4647 - accuracy: 0.7464 - val_loss: 0.4317 - val_accuracy: 0.7127\nEpoch 99/100\n623/623 [==============================] - 0s 157us/step - loss: 0.4410 - accuracy: 0.7560 - val_loss: 0.4406 - val_accuracy: 0.7873\nEpoch 100/100\n623/623 [==============================] - 0s 162us/step - loss: 0.4995 - accuracy: 0.7544 - val_loss: 0.4734 - val_accuracy: 0.8881\n"
                    ]
                },
                "mc_idx": 118,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 55,
                "o_idx": 0
            }
        },
        {
            "source": "# Predicting the Test set results\nY_pred = ann.predict(test)\nY_pred = (Y_pred > 0.5)*1 # convert probabilities to binary output",
            "mc_idx": 119,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    56,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 119,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 56,
                "o_idx": 0
            }
        },
        {
            "source": "# Predicting the Train set results\nann_prediction = ann.predict(train)\nann_prediction = (ann_prediction > 0.5)*1 # convert probabilities to binary output\n\n# Compute error between predicted data and true response and display it in confusion matrix\nacc_ann1 = round(metrics.accuracy_score(target, ann_prediction) * 100, 2)\nacc_ann1",
            "mc_idx": 120,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {
                    "accuracy_score": 2,
                    ".predict(": 1,
                    ".accuracy": 1,
                    "metrics.accuracy": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    57,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "90.35"
                    ]
                },
                "mc_idx": 120,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 57,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": np.reshape(Y_pred, len(Y_pred))})\n#submission.to_csv('output/submission_ann1.csv', index=False)\nLB_ann1_all = 0.59330  # old version",
            "mc_idx": 121,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 0.5,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "shape": 1
                },
                "Data_Transform": {
                    ".reshape": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    58,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 121,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 58,
                "o_idx": 0
            }
        },
        {
            "source": "# Model\nmodel = Sequential()\nmodel.add(Dense(16, input_dim = train.shape[1], init = 'he_normal', activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64, init = 'he_normal', activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(32, init = 'he_normal', activation = 'relu'))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.summary()",
            "mc_idx": 124,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.18181818181818182,
                "Data_Transform": 0.5454545454545454,
                "Model_Train": 0.9090909090909091,
                "Model_Evaluation": 0.8181818181818182,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "shape": 1,
                    ".sum": 1
                },
                "Data_Transform": {
                    ".add": 6
                },
                "Model_Train": {
                    "sequential(": 1,
                    "model": 9
                },
                "Model_Evaluation": {
                    "model": 9
                },
                "Model_Interpretation": {
                    "shap": 1,
                    "model": 9,
                    "summary": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    59,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_5 (Dense)              (None, 16)                272       \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 16)                0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 64)                1088      \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 64)                0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 32)                2080      \n_________________________________________________________________\ndense_8 (Dense)              (None, 1)                 33        \n=================================================================\nTotal params: 3,473\nTrainable params: 3,473\nNon-trainable params: 0\n_________________________________________________________________\n",
                        "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, input_dim=16, activation=\"relu\", kernel_initializer=\"he_normal\")`\n  This is separate from the ipykernel package so we can avoid doing imports until\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")`\n  \"\"\"\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")`\n  import sys\n"
                    ]
                },
                "mc_idx": 124,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 59,
                "o_idx": 1
            }
        },
        {
            "source": "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])",
            "mc_idx": 125,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "compile": 1,
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    60,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 125,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 60,
                "o_idx": 0
            }
        },
        {
            "source": "es = EarlyStopping(monitor='val_accuracy', patience=20, mode='max')\nhist = model.fit(train, target, batch_size=64, validation_data=(Xval, Zval), \n               epochs=500, verbose=1, callbacks=[es])",
            "mc_idx": 126,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 0.3333333333333333,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model.fit": 1,
                    ".fit(": 1,
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    61,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Train on 891 samples, validate on 268 samples\nEpoch 1/500\n891/891 [==============================] - 0s 374us/step - loss: 25.0711 - accuracy: 0.5309 - val_loss: 9.7298 - val_accuracy: 0.3806\nEpoch 2/500\n891/891 [==============================] - 0s 52us/step - loss: 18.0006 - accuracy: 0.5477 - val_loss: 2.6885 - val_accuracy: 0.5075\nEpoch 3/500\n891/891 [==============================] - 0s 51us/step - loss: 12.9629 - accuracy: 0.5387 - val_loss: 1.2955 - val_accuracy: 0.6455\nEpoch 4/500\n891/891 [==============================] - 0s 48us/step - loss: 12.3413 - accuracy: 0.5230 - val_loss: 3.8303 - val_accuracy: 0.4925\nEpoch 5/500\n891/891 [==============================] - 0s 49us/step - loss: 10.6057 - accuracy: 0.5668 - val_loss: 4.7341 - val_accuracy: 0.4925\nEpoch 6/500\n891/891 [==============================] - 0s 48us/step - loss: 8.8485 - accuracy: 0.5511 - val_loss: 1.0228 - val_accuracy: 0.6455\nEpoch 7/500\n891/891 [==============================] - 0s 56us/step - loss: 8.1929 - accuracy: 0.5657 - val_loss: 0.8268 - val_accuracy: 0.6940\nEpoch 8/500\n891/891 [==============================] - 0s 46us/step - loss: 7.2472 - accuracy: 0.5859 - val_loss: 4.6903 - val_accuracy: 0.4739\nEpoch 9/500\n891/891 [==============================] - 0s 49us/step - loss: 8.0046 - accuracy: 0.5488 - val_loss: 4.4030 - val_accuracy: 0.4851\nEpoch 10/500\n891/891 [==============================] - 0s 49us/step - loss: 6.5279 - accuracy: 0.5421 - val_loss: 1.1221 - val_accuracy: 0.5597\nEpoch 11/500\n891/891 [==============================] - 0s 44us/step - loss: 5.3860 - accuracy: 0.5780 - val_loss: 0.7990 - val_accuracy: 0.6418\nEpoch 12/500\n891/891 [==============================] - 0s 46us/step - loss: 5.9367 - accuracy: 0.5443 - val_loss: 1.7462 - val_accuracy: 0.5112\nEpoch 13/500\n891/891 [==============================] - 0s 47us/step - loss: 5.2609 - accuracy: 0.5499 - val_loss: 1.9253 - val_accuracy: 0.5037\nEpoch 14/500\n891/891 [==============================] - 0s 45us/step - loss: 5.0915 - accuracy: 0.5432 - val_loss: 1.2492 - val_accuracy: 0.5112\nEpoch 15/500\n891/891 [==============================] - 0s 47us/step - loss: 4.4295 - accuracy: 0.5600 - val_loss: 1.2512 - val_accuracy: 0.4813\nEpoch 16/500\n891/891 [==============================] - 0s 50us/step - loss: 4.1835 - accuracy: 0.5668 - val_loss: 1.0897 - val_accuracy: 0.4888\nEpoch 17/500\n891/891 [==============================] - 0s 50us/step - loss: 4.4014 - accuracy: 0.5443 - val_loss: 0.7713 - val_accuracy: 0.4963\nEpoch 18/500\n891/891 [==============================] - 0s 44us/step - loss: 3.7271 - accuracy: 0.5657 - val_loss: 0.7754 - val_accuracy: 0.6082\nEpoch 19/500\n891/891 [==============================] - 0s 45us/step - loss: 3.7165 - accuracy: 0.5724 - val_loss: 1.0677 - val_accuracy: 0.6679\nEpoch 20/500\n891/891 [==============================] - 0s 50us/step - loss: 3.6902 - accuracy: 0.5544 - val_loss: 0.8156 - val_accuracy: 0.6716\nEpoch 21/500\n891/891 [==============================] - 0s 43us/step - loss: 3.4103 - accuracy: 0.5511 - val_loss: 0.7478 - val_accuracy: 0.6716\nEpoch 22/500\n891/891 [==============================] - 0s 42us/step - loss: 2.9781 - accuracy: 0.5634 - val_loss: 0.8204 - val_accuracy: 0.4813\nEpoch 23/500\n891/891 [==============================] - 0s 46us/step - loss: 3.0719 - accuracy: 0.5421 - val_loss: 0.6711 - val_accuracy: 0.6679\nEpoch 24/500\n891/891 [==============================] - 0s 45us/step - loss: 2.8862 - accuracy: 0.5398 - val_loss: 0.6914 - val_accuracy: 0.6604\nEpoch 25/500\n891/891 [==============================] - 0s 45us/step - loss: 2.9357 - accuracy: 0.5477 - val_loss: 0.6391 - val_accuracy: 0.6978\nEpoch 26/500\n891/891 [==============================] - 0s 47us/step - loss: 3.0120 - accuracy: 0.5264 - val_loss: 0.7198 - val_accuracy: 0.5896\nEpoch 27/500\n891/891 [==============================] - 0s 49us/step - loss: 2.6170 - accuracy: 0.5556 - val_loss: 0.8151 - val_accuracy: 0.6716\nEpoch 28/500\n891/891 [==============================] - 0s 48us/step - loss: 2.2656 - accuracy: 0.5511 - val_loss: 0.8254 - val_accuracy: 0.5000\nEpoch 29/500\n891/891 [==============================] - 0s 48us/step - loss: 2.6968 - accuracy: 0.5354 - val_loss: 0.6864 - val_accuracy: 0.6791\nEpoch 30/500\n891/891 [==============================] - 0s 52us/step - loss: 2.4431 - accuracy: 0.5432 - val_loss: 0.6882 - val_accuracy: 0.6716\nEpoch 31/500\n891/891 [==============================] - 0s 53us/step - loss: 2.0363 - accuracy: 0.5836 - val_loss: 0.6479 - val_accuracy: 0.6567\nEpoch 32/500\n891/891 [==============================] - 0s 46us/step - loss: 1.9775 - accuracy: 0.5634 - val_loss: 0.6794 - val_accuracy: 0.6791\nEpoch 33/500\n891/891 [==============================] - 0s 48us/step - loss: 2.0414 - accuracy: 0.5376 - val_loss: 0.6435 - val_accuracy: 0.7015\nEpoch 34/500\n891/891 [==============================] - 0s 48us/step - loss: 1.8541 - accuracy: 0.5713 - val_loss: 0.7289 - val_accuracy: 0.6269\nEpoch 35/500\n891/891 [==============================] - 0s 48us/step - loss: 1.9536 - accuracy: 0.5679 - val_loss: 0.8198 - val_accuracy: 0.6418\nEpoch 36/500\n891/891 [==============================] - 0s 43us/step - loss: 2.0477 - accuracy: 0.5275 - val_loss: 0.6507 - val_accuracy: 0.6679\nEpoch 37/500\n891/891 [==============================] - 0s 45us/step - loss: 1.7126 - accuracy: 0.5780 - val_loss: 0.6971 - val_accuracy: 0.6866\nEpoch 38/500\n891/891 [==============================] - 0s 43us/step - loss: 1.7558 - accuracy: 0.5701 - val_loss: 0.6974 - val_accuracy: 0.5821\nEpoch 39/500\n891/891 [==============================] - 0s 44us/step - loss: 1.7265 - accuracy: 0.5533 - val_loss: 0.6542 - val_accuracy: 0.6791\nEpoch 40/500\n891/891 [==============================] - 0s 48us/step - loss: 1.6784 - accuracy: 0.5802 - val_loss: 0.6252 - val_accuracy: 0.6978\nEpoch 41/500\n891/891 [==============================] - 0s 43us/step - loss: 1.6809 - accuracy: 0.5499 - val_loss: 0.6418 - val_accuracy: 0.6791\nEpoch 42/500\n891/891 [==============================] - 0s 42us/step - loss: 1.5274 - accuracy: 0.5398 - val_loss: 0.6621 - val_accuracy: 0.6493\nEpoch 43/500\n891/891 [==============================] - 0s 48us/step - loss: 1.5074 - accuracy: 0.5937 - val_loss: 0.7801 - val_accuracy: 0.6455\nEpoch 44/500\n891/891 [==============================] - 0s 48us/step - loss: 1.4387 - accuracy: 0.5769 - val_loss: 0.8564 - val_accuracy: 0.4664\nEpoch 45/500\n891/891 [==============================] - 0s 49us/step - loss: 1.4446 - accuracy: 0.5657 - val_loss: 0.6611 - val_accuracy: 0.6418\nEpoch 46/500\n891/891 [==============================] - 0s 46us/step - loss: 1.3542 - accuracy: 0.6016 - val_loss: 0.6254 - val_accuracy: 0.6866\nEpoch 47/500\n891/891 [==============================] - 0s 45us/step - loss: 1.3040 - accuracy: 0.6072 - val_loss: 0.6598 - val_accuracy: 0.6530\nEpoch 48/500\n891/891 [==============================] - 0s 46us/step - loss: 1.4123 - accuracy: 0.5410 - val_loss: 0.6227 - val_accuracy: 0.7090\nEpoch 49/500\n891/891 [==============================] - 0s 43us/step - loss: 1.3642 - accuracy: 0.5634 - val_loss: 0.6391 - val_accuracy: 0.6978\nEpoch 50/500\n891/891 [==============================] - 0s 47us/step - loss: 1.5352 - accuracy: 0.5859 - val_loss: 0.6239 - val_accuracy: 0.6903\nEpoch 51/500\n891/891 [==============================] - 0s 41us/step - loss: 1.2741 - accuracy: 0.5634 - val_loss: 0.6239 - val_accuracy: 0.7127\nEpoch 52/500\n891/891 [==============================] - 0s 49us/step - loss: 1.4157 - accuracy: 0.5477 - val_loss: 0.6762 - val_accuracy: 0.5896\nEpoch 53/500\n891/891 [==============================] - 0s 50us/step - loss: 1.3279 - accuracy: 0.5533 - val_loss: 0.6497 - val_accuracy: 0.6269\nEpoch 54/500\n891/891 [==============================] - 0s 47us/step - loss: 1.1089 - accuracy: 0.5836 - val_loss: 0.6643 - val_accuracy: 0.6045\nEpoch 55/500\n891/891 [==============================] - 0s 47us/step - loss: 1.1347 - accuracy: 0.5802 - val_loss: 0.6867 - val_accuracy: 0.6381\nEpoch 56/500\n891/891 [==============================] - 0s 43us/step - loss: 1.2473 - accuracy: 0.5657 - val_loss: 0.6880 - val_accuracy: 0.5970\nEpoch 57/500\n891/891 [==============================] - 0s 45us/step - loss: 1.1294 - accuracy: 0.5746 - val_loss: 0.6410 - val_accuracy: 0.6754\nEpoch 58/500\n891/891 [==============================] - 0s 45us/step - loss: 1.1752 - accuracy: 0.5825 - val_loss: 0.6467 - val_accuracy: 0.6716\nEpoch 59/500\n891/891 [==============================] - 0s 43us/step - loss: 1.1029 - accuracy: 0.5488 - val_loss: 0.6810 - val_accuracy: 0.6530\nEpoch 60/500\n891/891 [==============================] - 0s 40us/step - loss: 1.2477 - accuracy: 0.5881 - val_loss: 0.7116 - val_accuracy: 0.4664\nEpoch 61/500\n891/891 [==============================] - 0s 53us/step - loss: 1.2835 - accuracy: 0.5140 - val_loss: 0.6520 - val_accuracy: 0.6567\nEpoch 62/500\n891/891 [==============================] - 0s 51us/step - loss: 1.0730 - accuracy: 0.5903 - val_loss: 0.6515 - val_accuracy: 0.6866\nEpoch 63/500\n891/891 [==============================] - 0s 46us/step - loss: 1.0383 - accuracy: 0.5758 - val_loss: 0.6618 - val_accuracy: 0.6567\nEpoch 64/500\n891/891 [==============================] - 0s 44us/step - loss: 1.0639 - accuracy: 0.5881 - val_loss: 0.6917 - val_accuracy: 0.6231\nEpoch 65/500\n891/891 [==============================] - 0s 46us/step - loss: 1.0511 - accuracy: 0.5634 - val_loss: 0.6566 - val_accuracy: 0.6493\nEpoch 66/500\n891/891 [==============================] - 0s 44us/step - loss: 0.9867 - accuracy: 0.5589 - val_loss: 0.6490 - val_accuracy: 0.6866\nEpoch 67/500\n891/891 [==============================] - 0s 44us/step - loss: 0.9466 - accuracy: 0.5814 - val_loss: 0.6543 - val_accuracy: 0.6567\nEpoch 68/500\n891/891 [==============================] - 0s 46us/step - loss: 1.0188 - accuracy: 0.5926 - val_loss: 0.6491 - val_accuracy: 0.6418\nEpoch 69/500\n891/891 [==============================] - 0s 44us/step - loss: 1.0083 - accuracy: 0.5690 - val_loss: 0.6599 - val_accuracy: 0.6791\nEpoch 70/500\n891/891 [==============================] - 0s 43us/step - loss: 0.9858 - accuracy: 0.6027 - val_loss: 0.7501 - val_accuracy: 0.6306\nEpoch 71/500\n891/891 [==============================] - 0s 43us/step - loss: 1.0165 - accuracy: 0.5769 - val_loss: 0.6677 - val_accuracy: 0.6679\n"
                    ]
                },
                "mc_idx": 126,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 61,
                "o_idx": 0
            }
        },
        {
            "source": "plt.plot(hist.history['accuracy'], label='acc')\nplt.plot(hist.history['val_accuracy'], label='val_acc')\n# plt.plot(hist.history['acc'], label='acc')\n# plt.plot(hist.history['val_acc'], label='val_acc')\nplt.ylim((0, 1))\nplt.legend()",
            "mc_idx": 127,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.6666666666666666,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plt.plot": 4,
                    ".plot(": 8
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "plt.plot": 4,
                    ".plot(": 4
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0039_c062_o001_image_2.png",
                    62,
                    1,
                    2
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<matplotlib.legend.Legend at 0x7f7bcc5b7358>",
                        "<Figure size 432x288 with 1 Axes>"
                    ]
                },
                "mc_idx": 127,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 62,
                "o_idx": 1
            }
        },
        {
            "source": "# Predicting the Test set results\nY_pred = model.predict(test)\nY_pred = (Y_pred > 0.5)*1 # convert probabilities to binary output",
            "mc_idx": 128,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.5,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    63,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 128,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 63,
                "o_idx": 0
            }
        },
        {
            "source": "# Predicting the Train set results\nnn_prediction = model.predict(train)\nnn_prediction = (nn_prediction > 0.5)*1 # convert probabilities to binary output\n\n# Compute error between predicted data and true response\nacc_ann2 = round(metrics.accuracy_score(target, nn_prediction) * 100, 2)\nacc_ann2",
            "mc_idx": 129,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.16666666666666666,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.16666666666666666,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "accuracy_score": 2,
                    "model": 1,
                    ".predict(": 1,
                    ".accuracy": 1,
                    "metrics.accuracy": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    64,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "61.17"
                    ]
                },
                "mc_idx": 129,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 64,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": np.reshape(Y_pred, len(Y_pred))})\n#submission.to_csv('output/submission_ann2.csv', index=False)\nLB_ann2_all = 0.64114  # old version",
            "mc_idx": 130,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 0.5,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "shape": 1
                },
                "Data_Transform": {
                    ".reshape": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    65,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 130,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 65,
                "o_idx": 0
            }
        },
        {
            "source": "Voting_Classifier_hard = VotingClassifier(estimators=[('lr', logreg), ('rf', random_forest), ('gbc', gradient_boosting)], voting='hard')\nfor clf, label in zip([logreg, random_forest, gradient_boosting, Voting_Classifier_hard], \n                      ['Logistic Regression', 'Random Forest', 'Gradient Boosting Classifier', 'Ensemble']):\n    scores = cross_val_score(clf, train, target, cv=cv_number, scoring='accuracy')\n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))",
            "mc_idx": 135,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.25,
                "Model_Evaluation": 0.25,
                "Model_Interpretation": 0.75,
                "Hyperparameter_Tuning": 0.25,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".std(": 1,
                    ".mean": 1,
                    ".std": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "votingclassifier": 1
                },
                "Model_Evaluation": {
                    "cross_val_score": 1
                },
                "Model_Interpretation": {
                    "gradient": 3
                },
                "Hyperparameter_Tuning": {
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    66,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Accuracy: 0.93 (+/- 0.01) [Logistic Regression]\nAccuracy: 0.94 (+/- 0.02) [Random Forest]\nAccuracy: 0.93 (+/- 0.02) [Gradient Boosting Classifier]\nAccuracy: 0.93 (+/- 0.02) [Ensemble]\n"
                    ]
                },
                "mc_idx": 135,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 66,
                "o_idx": 0
            }
        },
        {
            "source": "Voting_Classifier_hard.fit(train, target)\nY_pred = Voting_Classifier_hard.predict(test).astype(int)\nVoting_Classifier_hard.score(train, target)\nacc_VC_hard = round(Voting_Classifier_hard.score(train, target) * 100, 2)\nacc_VC_hard",
            "mc_idx": 136,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    67,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "100.0"
                    ]
                },
                "mc_idx": 136,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 67,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_VC_hard.csv', index=False)\nLB_VC_hard_all = 0.81339  # old version",
            "mc_idx": 137,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    68,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 137,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 68,
                "o_idx": 0
            }
        },
        {
            "source": "eclf = VotingClassifier(estimators=[('lr', logreg), ('rf', random_forest), ('gbc', gradient_boosting)], voting='soft')\nparams = {'lr__C': [1.0, 100.0], 'gbc__learning_rate': [0.05, 1]}\nVoting_Classifier_soft = GridSearchCV(estimator=eclf, param_grid=params, cv=cv_number)\nVoting_Classifier_soft.fit(train, target)\nY_pred = Voting_Classifier_soft.predict(test).astype(int)\nVoting_Classifier_soft.score(train, target)\nacc_VC_soft = round(Voting_Classifier_soft.score(train, target) * 100, 2)\nacc_VC_soft",
            "mc_idx": 141,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.14285714285714285,
                "Model_Train": 0.2857142857142857,
                "Model_Evaluation": 0.42857142857142855,
                "Model_Interpretation": 0.14285714285714285,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "votingclassifier": 1
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "param_grid": 1,
                    "param": 3
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    69,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "100.0"
                    ]
                },
                "mc_idx": 141,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 69,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_VC_soft.csv', index=False)\nLB_VC_soft_all = 0.81339  # old version",
            "mc_idx": 142,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    70,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 142,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 70,
                "o_idx": 0
            }
        },
        {
            "source": "Y_pred = (((test.WomanOrBoySurvived <= 0.238) & (test.Sex > 0.5) & (test.Alone > 0.5)) | \\\n          ((test.WomanOrBoySurvived > 0.238) & \\\n           ~((test.WomanOrBoySurvived > 0.55) & (test.WomanOrBoySurvived <= 0.633))))",
            "mc_idx": 145,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    71,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 145,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 71,
                "o_idx": 0
            }
        },
        {
            "source": "simple_rule_model = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n                       max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort=False,\n                       random_state=1118, splitter='best') \nsimple_rule_model.fit(train, target)\nY_pred = simple_rule_model.predict(test).astype(int)\nsimple_rule_model.score(train, target)\nacc_simple_rule = round(simple_rule_model.score(train, target) * 100, 2)\nacc_simple_rule",
            "mc_idx": 147,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.125,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.625,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    "model.fit": 1,
                    ".fit(": 1,
                    "model": 5,
                    "decisiontreeclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 5,
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "model": 5
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    72,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "92.7"
                    ]
                },
                "mc_idx": 147,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 72,
                "o_idx": 0
            }
        },
        {
            "source": "submission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\n#submission.to_csv('output/submission_simple_rule.csv', index=False)\nLB_simple_rule_all = 0.83253  # old version",
            "mc_idx": 148,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    73,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 148,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 73,
                "o_idx": 0
            }
        },
        {
            "source": "# Preparing datasets for only 3 features ('WomanOrBoySurvived', 'Sex', 'Alone')\ncols_to_drop3 = ['SibSp', 'Parch', 'Fare', 'LastName', 'Deck',\n               'Pclass', 'Age', 'Embarked', 'Title', 'IsWomanOrBoy',\n               'WomanOrBoyCount', 'FamilySurvivedCount', 'Family_Size']\ntrain = train.drop(cols_to_drop3, axis=1)\ntest = test.drop(cols_to_drop3, axis=1)\nXtrain, Xval, Ztrain, Zval = train_test_split(train, target, test_size=0.3, random_state=SEED)\ntrain.info()",
            "mc_idx": 151,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.2,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.4,
                "Model_Train": 0.2,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.2,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "dataset": 1
                },
                "Exploratory_Data_Analysis": {
                    ".info(": 1,
                    "info": 1,
                    "size": 2,
                    ".info": 1
                },
                "Data_Transform": {
                    ".drop": 2
                },
                "Model_Train": {
                    "train_test_split": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "train_test_split": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    74,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 891 entries, 1 to 891\nData columns (total 3 columns):\nSex                   891 non-null int64\nWomanOrBoySurvived    891 non-null float64\nAlone                 891 non-null int64\ndtypes: float64(1), int64(2)\nmemory usage: 27.8 KB\n"
                    ]
                },
                "mc_idx": 151,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 74,
                "o_idx": 0
            }
        },
        {
            "source": "# 1. Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(train, target)\nY_pred = logreg.predict(test).astype(int)\nacc3_log = round(logreg.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_logreg3.csv', index=False)\nLB_log = 0.77033",
            "mc_idx": 152,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "logisticregression": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    75,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 152,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 75,
                "o_idx": 0
            }
        },
        {
            "source": "# 2. Support Vector Machines\n\nsvc = SVC()\nsvc.fit(train, target)\nY_pred = svc.predict(test).astype(int)\nacc3_svc = round(svc.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_svm3.csv', index=False)\nLB_svc = 0.79904",
            "mc_idx": 153,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.125,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.25,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.25,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "svc": 7
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    76,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 153,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 76,
                "o_idx": 0
            }
        },
        {
            "source": "# 3. Linear SVC\n\nlinear_svc = LinearSVC(dual=False)\nlinear_svc.fit(train, target)\nY_pred = linear_svc.predict(test).astype(int)\nacc3_linear_svc = round(linear_svc.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_linear_svc3.csv', index=False)\nLB_linear_svc = 0.77033",
            "mc_idx": 154,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.1,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.2,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.2,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "svc": 9
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    77,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 154,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 77,
                "o_idx": 0
            }
        },
        {
            "source": "# 4. k-Nearest Neighbors algorithm\n\nknn = GridSearchCV(estimator=KNeighborsClassifier(), param_grid={'n_neighbors': [2, 3, 4]}, cv=cv_number).fit(train, target)\nY_pred = knn.predict(test).astype(int)\nacc3_knn = round(knn.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_knn3.csv', index=False)\nLB_knn = 0.77751",
            "mc_idx": 155,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2,
                "Model_Train": 0.4,
                "Model_Evaluation": 0.4,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.4,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "kneighborsclassifier": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "param_grid": 1,
                    "param": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    78,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 155,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 78,
                "o_idx": 0
            }
        },
        {
            "source": "# 5. Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(train, target)\nY_pred = gaussian.predict(test).astype(int)\nacc3_gaussian = round(gaussian.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_GaussianNB3.csv', index=False)\nLB_gaussian = 0.68899",
            "mc_idx": 156,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.6666666666666666,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.6666666666666666,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "gaussiannb": 2
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    79,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 156,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 79,
                "o_idx": 0
            }
        },
        {
            "source": "# 6. Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(train, target)\nY_pred = perceptron.predict(test).astype(int)\nacc3_perceptron = round(perceptron.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_perceptron3.csv', index=False)\nLB_perceptron = 0.77511",
            "mc_idx": 157,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 0.5,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    80,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 157,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 80,
                "o_idx": 0
            }
        },
        {
            "source": "# 7. Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(train, target)\nY_pred = sgd.predict(test).astype(int)\nacc3_sgd = round(sgd.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_sgd3.csv', index=False)\nLB_sgd = 0.77511",
            "mc_idx": 158,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "sgdclassifier": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    81,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 158,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 81,
                "o_idx": 0
            }
        },
        {
            "source": "# 8. Decision Tree Classifier\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(train, target)\nY_pred = decision_tree.predict(test).astype(int)\nacc3_decision_tree = round(decision_tree.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_decision_tree3.csv', index=False)\nLB_decision_tree = 0.80382",
            "mc_idx": 159,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "decisiontreeclassifier": 1
                },
                "Model_Evaluation": {
                    ".score(": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    82,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 159,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 82,
                "o_idx": 0
            }
        },
        {
            "source": "# 9. Random Forest\n\nrandom_forest = GridSearchCV(estimator=RandomForestClassifier(), param_grid={'n_estimators': [200, 300, 400, 500]}, cv=cv_number).fit(train, target)\nrandom_forest.fit(train, target)\nY_pred = random_forest.predict(test).astype(int)\nrandom_forest.score(train, target)\nacc3_random_forest = round(random_forest.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_random_forest3.csv', index=False)\nLB_random_forest = 0.80382",
            "mc_idx": 160,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2,
                "Model_Train": 0.8,
                "Model_Evaluation": 0.6,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.4,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 2,
                    "randomforestclassifier": 2
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "param_grid": 1,
                    "param": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    83,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 160,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 83,
                "o_idx": 0
            }
        },
        {
            "source": "# 10. XGB_Classifier\n\ndef hyperopt_xgb_score(params):\n    clf = XGBClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_xgb = {\n            'learning_rate': hp.quniform('learning_rate', 0, 0.05, 0.0001),\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'eta': hp.quniform('eta', 0.025, 0.5, 0.005),\n            'max_depth':  hp.choice('max_depth', np.arange(4, 8, dtype=int)),\n            'min_child_weight': hp.quniform('min_child_weight', 1, 9, 0.025),\n            'subsample': hp.quniform('subsample', 0.5, 1, 0.005),\n            'gamma': hp.quniform('gamma', 0.5, 1, 0.005),\n            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.005),\n            'eval_metric': 'auc',\n            'objective': 'binary:logistic',\n            'booster': 'gbtree',\n            'tree_method': 'exact',\n            'silent': 1,\n            'missing': None\n        }\n \nbest = fmin(fn=hyperopt_xgb_score, space=space_xgb, algo=tpe.suggest, max_evals=10)\nparams = space_eval(space_xgb, best)\nXGB_Classifier = XGBClassifier(**params)\nXGB_Classifier.fit(train, target)\nY_pred = XGB_Classifier.predict(test).astype(int)\nXGB_Classifier.score(train, target)\nacc3_XGB_Classifier = round(XGB_Classifier.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_XGB_Classifier3.csv', index=False)\nLB_XGB_Classifier = 0.68899\nprint(params)",
            "mc_idx": 161,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2222222222222222,
                "Data_Transform": 0.1111111111111111,
                "Model_Train": 0.1111111111111111,
                "Model_Evaluation": 0.4444444444444444,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.2222222222222222,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1
                },
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "hyperopt": 2,
                    "param": 6,
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    84,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0.777744808384463\n{'booster': 'gbtree', 'colsample_bytree': 0.525, 'eta': 0.45, 'eval_metric': 'auc', 'gamma': 0.935, 'learning_rate': 0.0015, 'max_depth': 4, 'min_child_weight': 7.300000000000001, 'missing': None, 'n_estimators': 948, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.995, 'tree_method': 'exact'}\n0.9091068935348663\n{'booster': 'gbtree', 'colsample_bytree': 0.67, 'eta': 0.315, 'eval_metric': 'auc', 'gamma': 0.665, 'learning_rate': 0.047, 'max_depth': 5, 'min_child_weight': 6.625, 'missing': None, 'n_estimators': 452, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.555, 'tree_method': 'exact'}\n0.9214665150240071\n{'booster': 'gbtree', 'colsample_bytree': 0.86, 'eta': 0.35000000000000003, 'eval_metric': 'auc', 'gamma': 0.875, 'learning_rate': 0.0358, 'max_depth': 6, 'min_child_weight': 6.0, 'missing': None, 'n_estimators': 408, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.9400000000000001, 'tree_method': 'exact'}\n0.9158484665685741\n{'booster': 'gbtree', 'colsample_bytree': 0.975, 'eta': 0.115, 'eval_metric': 'auc', 'gamma': 0.6900000000000001, 'learning_rate': 0.0402, 'max_depth': 7, 'min_child_weight': 8.375, 'missing': None, 'n_estimators': 494, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.965, 'tree_method': 'exact'}\n0.8989817670625477\n{'booster': 'gbtree', 'colsample_bytree': 0.61, 'eta': 0.365, 'eval_metric': 'auc', 'gamma': 0.91, 'learning_rate': 0.0342, 'max_depth': 7, 'min_child_weight': 1.75, 'missing': None, 'n_estimators': 399, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.6, 'tree_method': 'exact'}\n0.9214665150240071\n{'booster': 'gbtree', 'colsample_bytree': 0.79, 'eta': 0.275, 'eval_metric': 'auc', 'gamma': 0.875, 'learning_rate': 0.041600000000000005, 'max_depth': 4, 'min_child_weight': 1.2750000000000001, 'missing': None, 'n_estimators': 704, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.795, 'tree_method': 'exact'}\n0.89675975525811\n{'booster': 'gbtree', 'colsample_bytree': 0.715, 'eta': 0.335, 'eval_metric': 'auc', 'gamma': 0.775, 'learning_rate': 0.003, 'max_depth': 6, 'min_child_weight': 7.825, 'missing': None, 'n_estimators': 805, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.58, 'tree_method': 'exact'}\n0.9180957285071532\n{'booster': 'gbtree', 'colsample_bytree': 0.885, 'eta': 0.085, 'eval_metric': 'auc', 'gamma': 0.635, 'learning_rate': 0.0368, 'max_depth': 5, 'min_child_weight': 5.125, 'missing': None, 'n_estimators': 726, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.8150000000000001, 'tree_method': 'exact'}\n0.9012290290011267\n{'booster': 'gbtree', 'colsample_bytree': 0.96, 'eta': 0.28500000000000003, 'eval_metric': 'auc', 'gamma': 0.73, 'learning_rate': 0.0004, 'max_depth': 7, 'min_child_weight': 8.0, 'missing': None, 'n_estimators': 960, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.89, 'tree_method': 'exact'}\n0.9214665150240071\n{'booster': 'gbtree', 'colsample_bytree': 0.8150000000000001, 'eta': 0.48, 'eval_metric': 'auc', 'gamma': 0.6950000000000001, 'learning_rate': 0.0291, 'max_depth': 4, 'min_child_weight': 2.5, 'missing': None, 'n_estimators': 788, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.925, 'tree_method': 'exact'}\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:10<00:00,  1.01s/it, best loss: 0.777744808384463]\n{'booster': 'gbtree', 'colsample_bytree': 0.525, 'eta': 0.45, 'eval_metric': 'auc', 'gamma': 0.935, 'learning_rate': 0.0015, 'max_depth': 4, 'min_child_weight': 7.300000000000001, 'missing': None, 'n_estimators': 948, 'objective': 'binary:logistic', 'silent': 1, 'subsample': 0.995, 'tree_method': 'exact'}\n"
                    ]
                },
                "mc_idx": 161,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 84,
                "o_idx": 0
            }
        },
        {
            "source": "# 11. LGBM_Classifier\n\ndef hyperopt_lgb_score(params):\n    clf = LGBMClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_lgb = {\n            'learning_rate': hp.quniform('learning_rate', 0, 0.05, 0.0001),\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_depth':  hp.choice('max_depth', np.arange(4, 7, dtype=int)),\n            'num_leaves': hp.choice('num_leaves', 2*np.arange(20, 2**6, dtype=int)),\n            'min_child_weight': hp.quniform('min_child_weight', 1, 9, 0.025),\n            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.005),\n            'objective': 'binary',\n            'boosting_type': 'gbdt',\n            }\n \nbest = fmin(fn=hyperopt_lgb_score, space=space_lgb, algo=tpe.suggest, max_evals=10)\nparams = space_eval(space_lgb, best)\nLGB_Classifier = LGBMClassifier(**params)\nLGB_Classifier.fit(train, target)\nY_pred = LGB_Classifier.predict(test).astype(int)\nLGB_Classifier.score(train, target)\nacc3_LGB_Classifier = round(LGB_Classifier.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_LGB_Classifier3.csv', index=False)\nLB_LGB_Classifier = 0.62200\nprint(params)",
            "mc_idx": 162,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2222222222222222,
                "Data_Transform": 0.1111111111111111,
                "Model_Train": 0.1111111111111111,
                "Model_Evaluation": 0.4444444444444444,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.2222222222222222,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1
                },
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "hyperopt": 2,
                    "param": 6,
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    85,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0.8710614312357636\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.0083, 'max_depth': 5, 'min_child_weight': 3.575, 'n_estimators': 546, 'num_leaves': 88, 'objective': 'binary'}\n0.9214665150240071\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.77, 'learning_rate': 0.0179, 'max_depth': 5, 'min_child_weight': 5.3500000000000005, 'n_estimators': 815, 'num_leaves': 92, 'objective': 'binary'}\n0.9001495857665847\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.885, 'learning_rate': 0.013800000000000002, 'max_depth': 5, 'min_child_weight': 6.0, 'n_estimators': 130, 'num_leaves': 120, 'objective': 'binary'}\n0.9012290290011267\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.53, 'learning_rate': 0.009600000000000001, 'max_depth': 6, 'min_child_weight': 1.75, 'n_estimators': 962, 'num_leaves': 90, 'objective': 'binary'}\n0.9091068935348663\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.725, 'learning_rate': 0.019200000000000002, 'max_depth': 4, 'min_child_weight': 8.9, 'n_estimators': 952, 'num_leaves': 96, 'objective': 'binary'}\n0.9214665150240071\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.685, 'learning_rate': 0.012100000000000001, 'max_depth': 4, 'min_child_weight': 3.3000000000000003, 'n_estimators': 918, 'num_leaves': 86, 'objective': 'binary'}\n0.9024030538476844\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.54, 'learning_rate': 0.0494, 'max_depth': 4, 'min_child_weight': 1.75, 'n_estimators': 666, 'num_leaves': 44, 'objective': 'binary'}\n0.8990196422637597\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.54, 'learning_rate': 0.0379, 'max_depth': 6, 'min_child_weight': 7.9, 'n_estimators': 827, 'num_leaves': 60, 'objective': 'binary'}\n0.9214665150240071\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.865, 'learning_rate': 0.0076, 'max_depth': 4, 'min_child_weight': 6.800000000000001, 'n_estimators': 639, 'num_leaves': 54, 'objective': 'binary'}\n0.9214665150240071\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.8300000000000001, 'learning_rate': 0.017, 'max_depth': 5, 'min_child_weight': 4.325, 'n_estimators': 548, 'num_leaves': 60, 'objective': 'binary'}\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:05<00:00,  1.73it/s, best loss: 0.8710614312357636]\n{'boosting_type': 'gbdt', 'colsample_bytree': 0.64, 'learning_rate': 0.0083, 'max_depth': 5, 'min_child_weight': 3.575, 'n_estimators': 546, 'num_leaves': 88, 'objective': 'binary'}\n"
                    ]
                },
                "mc_idx": 162,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 85,
                "o_idx": 0
            }
        },
        {
            "source": "# 12. GradientBoostingClassifier\n\ndef hyperopt_gb_score(params):\n    clf = GradientBoostingClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_gb = {\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_depth': hp.choice('max_depth', np.arange(4, 8, dtype=int)),\n            'max_features': None\n        }\n \nbest = fmin(fn=hyperopt_gb_score, space=space_gb, algo=tpe.suggest, max_evals=5)\nparams = space_eval(space_gb, best)\ngradient_boosting = GradientBoostingClassifier(**params)\ngradient_boosting.fit(train, target)\nY_pred = gradient_boosting.predict(test).astype(int)\ngradient_boosting.score(train, target)\nacc3_gradient_boosting = round(gradient_boosting.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_gradient_boosting3.csv', index=False)\nLB_GBC = 0.80382\nprint(params)",
            "mc_idx": 163,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2,
                "Data_Transform": 0.1,
                "Model_Train": 0.4,
                "Model_Evaluation": 0.4,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.9,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.2,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1
                },
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "gradientboostingclassifier": 3
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "gradient": 10
                },
                "Hyperparameter_Tuning": {
                    "hyperopt": 2,
                    "param": 6,
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    86,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0.9214665150240071\n{'max_depth': 5, 'max_features': None, 'n_estimators': 360}\n0.9214665150240071\n{'max_depth': 6, 'max_features': None, 'n_estimators': 324}\n0.9214665150240071\n{'max_depth': 6, 'max_features': None, 'n_estimators': 603}\n0.9214665150240071\n{'max_depth': 7, 'max_features': None, 'n_estimators': 288}\n0.9214665150240071\n{'max_depth': 4, 'max_features': None, 'n_estimators': 739}\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:09<00:00,  1.92s/it, best loss: 0.9214665150240071]\n{'max_depth': 5, 'max_features': None, 'n_estimators': 360}\n"
                    ]
                },
                "mc_idx": 163,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 86,
                "o_idx": 0
            }
        },
        {
            "source": "# 13. Ridge Classifier\n\nridge_classifier = RidgeClassifier()\nridge_classifier.fit(train, target)\nY_pred = ridge_classifier.predict(test).astype(int)\nridge_classifier.score(train, target)\nacc3_ridge_classifier = round(ridge_classifier.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_ridge_classifier3.csv', index=False)\nLB_RidgeClassifier = 0.77511",
            "mc_idx": 164,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.09090909090909091,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.2727272727272727,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.18181818181818182,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "ridge": 10
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    87,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 164,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 87,
                "o_idx": 0
            }
        },
        {
            "source": "# 14. Bagging Classifier\n\nbagging_classifier = BaggingClassifier()\nbagging_classifier.fit(train, target)\nY_pred = bagging_classifier.predict(test).astype(int)\nbagging_classifier.score(train, target)\nacc3_bagging_classifier = round(bagging_classifier.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_bagging_classifier3.csv', index=False)\nLB_bagging_classifier = 0.80382",
            "mc_idx": 165,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.6666666666666666,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    88,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 165,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 88,
                "o_idx": 0
            }
        },
        {
            "source": "# 15. Extra Trees Classifier\n\ndef hyperopt_etc_score(params):\n    clf = ExtraTreesClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=cv_number).mean()\n    print(current_score, params)\n    return current_score \n \nspace_etc = {\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'max_features': hp.choice('max_features', np.arange(2, 10, dtype=int)),\n            'min_samples_leaf': hp.choice('min_samples_leaf', np.arange(1, 5, dtype=int)),\n            'max_depth':  hp.choice('max_depth', np.arange(2, 8, dtype=int)),\n            'max_features': None\n        }\n \nbest = fmin(fn=hyperopt_etc_score, space=space_etc, algo=tpe.suggest, max_evals=5)\nparams = space_eval(space_etc, best)\nextra_trees_classifier = ExtraTreesClassifier(**params)\nextra_trees_classifier.fit(train, target)\nY_pred = extra_trees_classifier.predict(test).astype(int)\nextra_trees_classifier.score(train, target)\nacc3_etc = round(extra_trees_classifier.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_etc3.csv', index=False)\nLB_ETC = 0.79904\nprint(params)",
            "mc_idx": 166,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2222222222222222,
                "Data_Transform": 0.1111111111111111,
                "Model_Train": 0.1111111111111111,
                "Model_Evaluation": 0.4444444444444444,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.2222222222222222,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1
                },
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "hyperopt": 2,
                    "param": 6,
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    89,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0.9180957285071532\n{'max_depth': 3, 'max_features': None, 'min_samples_leaf': 1, 'n_estimators': 211}\n0.9180957285071532\n{'max_depth': 3, 'max_features': None, 'min_samples_leaf': 4, 'n_estimators': 719}\n0.9214665150240071\n{'max_depth': 5, 'max_features': None, 'min_samples_leaf': 2, 'n_estimators': 668}\n0.9180957285071532\n{'max_depth': 3, 'max_features': None, 'min_samples_leaf': 4, 'n_estimators': 469}\n0.9180957285071532\n{'max_depth': 4, 'max_features': None, 'min_samples_leaf': 3, 'n_estimators': 850}\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:13<00:00,  2.70s/it, best loss: 0.9180957285071532]\n{'max_depth': 3, 'max_features': None, 'min_samples_leaf': 1, 'n_estimators': 211}\n"
                    ]
                },
                "mc_idx": 166,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 89,
                "o_idx": 0
            }
        },
        {
            "source": "# 16. Neural Network 1 \n\ndef build_ann(optimizer='adam'):\n    \n    # Initializing the ANN\n    ann = Sequential()\n    \n    # Adding the input layer and the first hidden layer of the ANN with dropout\n    ann.add(Dense(units=32, kernel_initializer='glorot_uniform', activation='relu', input_shape=(3,)))\n    \n    # Add other layers, it is not necessary to pass the shape because there is a layer before\n    ann.add(Dense(units=64, kernel_initializer='glorot_uniform', activation='relu'))\n    ann.add(Dropout(rate=0.5))\n    ann.add(Dense(units=64, kernel_initializer='glorot_uniform', activation='relu'))\n    ann.add(Dropout(rate=0.5))\n    \n    # Adding the output layer\n    ann.add(Dense(units=1, kernel_initializer='glorot_uniform', activation='sigmoid'))\n    \n    # Compiling the ANN\n    ann.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return ann\nopt = optimizers.Adam(lr=0.001)\nann = build_ann(opt)\nhistory = ann.fit(Xtrain, Ztrain, batch_size=16, epochs=100, validation_data=(Xval, Zval))\nY_pred = ann.predict(test)\nY_pred = (Y_pred > 0.5)*1 # convert probabilities to binary output\nann_prediction = ann.predict(train)\nann_prediction = (ann_prediction > 0.5)*1 # convert probabilities to binary output\nacc3_ann1 = round(metrics.accuracy_score(target, ann_prediction) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": np.reshape(Y_pred, len(Y_pred))})\nsubmission.to_csv('submission_ann1_3.csv', index=False)\nLB_ann1 = 0.79904",
            "mc_idx": 167,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5714285714285714,
                "Data_Transform": 1.0,
                "Model_Train": 0.42857142857142855,
                "Model_Evaluation": 0.8571428571428571,
                "Model_Interpretation": 0.42857142857142855,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.2857142857142857,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "shape": 3,
                    "size": 1
                },
                "Data_Transform": {
                    ".reshape": 1,
                    ".add": 6
                },
                "Model_Train": {
                    "sequential(": 1,
                    "compile": 1,
                    ".fit(": 1
                },
                "Model_Evaluation": {
                    "accuracy_score": 2,
                    ".predict(": 2,
                    ".accuracy": 1,
                    "metrics.accuracy": 1
                },
                "Model_Interpretation": {
                    "shap": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    90,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Train on 623 samples, validate on 268 samples\nEpoch 1/100\n623/623 [==============================] - 0s 642us/step - loss: 0.6393 - accuracy: 0.6838 - val_loss: 0.5469 - val_accuracy: 0.7910\nEpoch 2/100\n623/623 [==============================] - 0s 166us/step - loss: 0.4670 - accuracy: 0.8074 - val_loss: 0.3263 - val_accuracy: 0.9030\nEpoch 3/100\n623/623 [==============================] - 0s 186us/step - loss: 0.2969 - accuracy: 0.8748 - val_loss: 0.2122 - val_accuracy: 0.9030\nEpoch 4/100\n623/623 [==============================] - 0s 175us/step - loss: 0.2476 - accuracy: 0.8925 - val_loss: 0.1987 - val_accuracy: 0.9030\nEpoch 5/100\n623/623 [==============================] - 0s 167us/step - loss: 0.2209 - accuracy: 0.8957 - val_loss: 0.1929 - val_accuracy: 0.9030\nEpoch 6/100\n623/623 [==============================] - 0s 164us/step - loss: 0.2270 - accuracy: 0.9021 - val_loss: 0.1989 - val_accuracy: 0.9142\nEpoch 7/100\n623/623 [==============================] - 0s 161us/step - loss: 0.2202 - accuracy: 0.9021 - val_loss: 0.1889 - val_accuracy: 0.9142\nEpoch 8/100\n623/623 [==============================] - 0s 170us/step - loss: 0.2114 - accuracy: 0.9165 - val_loss: 0.1925 - val_accuracy: 0.9142\nEpoch 9/100\n623/623 [==============================] - 0s 172us/step - loss: 0.2081 - accuracy: 0.9181 - val_loss: 0.1889 - val_accuracy: 0.9142\nEpoch 10/100\n623/623 [==============================] - 0s 162us/step - loss: 0.1994 - accuracy: 0.9037 - val_loss: 0.1867 - val_accuracy: 0.9142\nEpoch 11/100\n623/623 [==============================] - 0s 167us/step - loss: 0.1969 - accuracy: 0.9133 - val_loss: 0.1904 - val_accuracy: 0.9142\nEpoch 12/100\n623/623 [==============================] - 0s 194us/step - loss: 0.2035 - accuracy: 0.9133 - val_loss: 0.1861 - val_accuracy: 0.9142\nEpoch 13/100\n623/623 [==============================] - 0s 189us/step - loss: 0.2035 - accuracy: 0.9149 - val_loss: 0.1935 - val_accuracy: 0.9142\nEpoch 14/100\n623/623 [==============================] - 0s 172us/step - loss: 0.2016 - accuracy: 0.9165 - val_loss: 0.1918 - val_accuracy: 0.9142\nEpoch 15/100\n623/623 [==============================] - 0s 159us/step - loss: 0.2067 - accuracy: 0.9133 - val_loss: 0.1874 - val_accuracy: 0.9142\nEpoch 16/100\n623/623 [==============================] - 0s 169us/step - loss: 0.2053 - accuracy: 0.9149 - val_loss: 0.1833 - val_accuracy: 0.9142\nEpoch 17/100\n623/623 [==============================] - 0s 161us/step - loss: 0.1914 - accuracy: 0.9181 - val_loss: 0.1851 - val_accuracy: 0.9142\nEpoch 18/100\n623/623 [==============================] - 0s 167us/step - loss: 0.1938 - accuracy: 0.9197 - val_loss: 0.1871 - val_accuracy: 0.9142\nEpoch 19/100\n623/623 [==============================] - 0s 167us/step - loss: 0.1946 - accuracy: 0.9181 - val_loss: 0.1920 - val_accuracy: 0.9142\nEpoch 20/100\n623/623 [==============================] - 0s 182us/step - loss: 0.1956 - accuracy: 0.9149 - val_loss: 0.1851 - val_accuracy: 0.9142\nEpoch 21/100\n623/623 [==============================] - 0s 172us/step - loss: 0.1981 - accuracy: 0.9181 - val_loss: 0.1840 - val_accuracy: 0.9142\nEpoch 22/100\n623/623 [==============================] - 0s 173us/step - loss: 0.2087 - accuracy: 0.9149 - val_loss: 0.1894 - val_accuracy: 0.9179\nEpoch 23/100\n623/623 [==============================] - 0s 170us/step - loss: 0.1985 - accuracy: 0.9197 - val_loss: 0.1883 - val_accuracy: 0.9179\nEpoch 24/100\n623/623 [==============================] - 0s 164us/step - loss: 0.1955 - accuracy: 0.9165 - val_loss: 0.1927 - val_accuracy: 0.9179\nEpoch 25/100\n623/623 [==============================] - 0s 160us/step - loss: 0.2001 - accuracy: 0.9197 - val_loss: 0.1900 - val_accuracy: 0.9179\nEpoch 26/100\n623/623 [==============================] - 0s 157us/step - loss: 0.2025 - accuracy: 0.9230 - val_loss: 0.1881 - val_accuracy: 0.9179\nEpoch 27/100\n623/623 [==============================] - 0s 179us/step - loss: 0.1952 - accuracy: 0.9230 - val_loss: 0.1919 - val_accuracy: 0.9179\nEpoch 28/100\n623/623 [==============================] - 0s 167us/step - loss: 0.1936 - accuracy: 0.9197 - val_loss: 0.1910 - val_accuracy: 0.9179\nEpoch 29/100\n623/623 [==============================] - 0s 168us/step - loss: 0.1849 - accuracy: 0.9230 - val_loss: 0.1876 - val_accuracy: 0.9179\nEpoch 30/100\n623/623 [==============================] - 0s 162us/step - loss: 0.1930 - accuracy: 0.9213 - val_loss: 0.1876 - val_accuracy: 0.9179\nEpoch 31/100\n623/623 [==============================] - 0s 179us/step - loss: 0.2008 - accuracy: 0.9197 - val_loss: 0.1865 - val_accuracy: 0.9179\nEpoch 32/100\n623/623 [==============================] - 0s 165us/step - loss: 0.1915 - accuracy: 0.9230 - val_loss: 0.1835 - val_accuracy: 0.9142\nEpoch 33/100\n623/623 [==============================] - 0s 173us/step - loss: 0.1867 - accuracy: 0.9213 - val_loss: 0.1914 - val_accuracy: 0.9179\nEpoch 34/100\n623/623 [==============================] - 0s 166us/step - loss: 0.1884 - accuracy: 0.9230 - val_loss: 0.1902 - val_accuracy: 0.9179\nEpoch 35/100\n623/623 [==============================] - 0s 169us/step - loss: 0.1963 - accuracy: 0.9230 - val_loss: 0.1897 - val_accuracy: 0.9179\nEpoch 36/100\n623/623 [==============================] - 0s 170us/step - loss: 0.1844 - accuracy: 0.9230 - val_loss: 0.1914 - val_accuracy: 0.9179\nEpoch 37/100\n623/623 [==============================] - 0s 178us/step - loss: 0.1835 - accuracy: 0.9213 - val_loss: 0.1896 - val_accuracy: 0.9179\nEpoch 38/100\n623/623 [==============================] - 0s 169us/step - loss: 0.1992 - accuracy: 0.9213 - val_loss: 0.1888 - val_accuracy: 0.9179\nEpoch 39/100\n623/623 [==============================] - 0s 181us/step - loss: 0.2007 - accuracy: 0.9230 - val_loss: 0.1877 - val_accuracy: 0.9179\nEpoch 40/100\n623/623 [==============================] - 0s 185us/step - loss: 0.1947 - accuracy: 0.9230 - val_loss: 0.1858 - val_accuracy: 0.9179\nEpoch 41/100\n623/623 [==============================] - 0s 171us/step - loss: 0.1938 - accuracy: 0.9230 - val_loss: 0.1856 - val_accuracy: 0.9179\nEpoch 42/100\n623/623 [==============================] - 0s 166us/step - loss: 0.1929 - accuracy: 0.9230 - val_loss: 0.1857 - val_accuracy: 0.9179\nEpoch 43/100\n623/623 [==============================] - 0s 171us/step - loss: 0.1841 - accuracy: 0.9246 - val_loss: 0.1879 - val_accuracy: 0.9179\nEpoch 44/100\n623/623 [==============================] - 0s 187us/step - loss: 0.1858 - accuracy: 0.9213 - val_loss: 0.1915 - val_accuracy: 0.9179\nEpoch 45/100\n623/623 [==============================] - 0s 176us/step - loss: 0.1966 - accuracy: 0.9230 - val_loss: 0.1863 - val_accuracy: 0.9179\nEpoch 46/100\n623/623 [==============================] - 0s 157us/step - loss: 0.1961 - accuracy: 0.9230 - val_loss: 0.1863 - val_accuracy: 0.9179\nEpoch 47/100\n623/623 [==============================] - 0s 169us/step - loss: 0.1841 - accuracy: 0.9230 - val_loss: 0.1848 - val_accuracy: 0.9179\nEpoch 48/100\n623/623 [==============================] - 0s 170us/step - loss: 0.1816 - accuracy: 0.9246 - val_loss: 0.1821 - val_accuracy: 0.9179\nEpoch 49/100\n623/623 [==============================] - 0s 188us/step - loss: 0.1853 - accuracy: 0.9197 - val_loss: 0.1873 - val_accuracy: 0.9179\nEpoch 50/100\n623/623 [==============================] - 0s 168us/step - loss: 0.1916 - accuracy: 0.9230 - val_loss: 0.1857 - val_accuracy: 0.9179\nEpoch 51/100\n623/623 [==============================] - 0s 173us/step - loss: 0.1881 - accuracy: 0.9230 - val_loss: 0.1938 - val_accuracy: 0.9179\nEpoch 52/100\n623/623 [==============================] - 0s 166us/step - loss: 0.1910 - accuracy: 0.9213 - val_loss: 0.1895 - val_accuracy: 0.9179\nEpoch 53/100\n623/623 [==============================] - 0s 167us/step - loss: 0.1959 - accuracy: 0.9230 - val_loss: 0.1850 - val_accuracy: 0.9179\nEpoch 54/100\n623/623 [==============================] - 0s 167us/step - loss: 0.1987 - accuracy: 0.9213 - val_loss: 0.1875 - val_accuracy: 0.9179\nEpoch 55/100\n623/623 [==============================] - 0s 166us/step - loss: 0.1983 - accuracy: 0.9230 - val_loss: 0.1862 - val_accuracy: 0.9179\nEpoch 56/100\n623/623 [==============================] - 0s 186us/step - loss: 0.1889 - accuracy: 0.9230 - val_loss: 0.1824 - val_accuracy: 0.9142\nEpoch 57/100\n623/623 [==============================] - 0s 168us/step - loss: 0.1879 - accuracy: 0.9230 - val_loss: 0.1871 - val_accuracy: 0.9179\nEpoch 58/100\n623/623 [==============================] - 0s 161us/step - loss: 0.1868 - accuracy: 0.9230 - val_loss: 0.1870 - val_accuracy: 0.9179\nEpoch 59/100\n623/623 [==============================] - 0s 165us/step - loss: 0.1928 - accuracy: 0.9213 - val_loss: 0.1867 - val_accuracy: 0.9179\nEpoch 60/100\n623/623 [==============================] - 0s 170us/step - loss: 0.1976 - accuracy: 0.9213 - val_loss: 0.1888 - val_accuracy: 0.9179\nEpoch 61/100\n623/623 [==============================] - 0s 163us/step - loss: 0.1888 - accuracy: 0.9230 - val_loss: 0.1882 - val_accuracy: 0.9179\nEpoch 62/100\n623/623 [==============================] - 0s 171us/step - loss: 0.1886 - accuracy: 0.9230 - val_loss: 0.1868 - val_accuracy: 0.9179\nEpoch 63/100\n623/623 [==============================] - 0s 179us/step - loss: 0.1921 - accuracy: 0.9230 - val_loss: 0.1847 - val_accuracy: 0.9142\nEpoch 64/100\n623/623 [==============================] - 0s 164us/step - loss: 0.1943 - accuracy: 0.9230 - val_loss: 0.1851 - val_accuracy: 0.9179\nEpoch 65/100\n623/623 [==============================] - 0s 165us/step - loss: 0.1941 - accuracy: 0.9197 - val_loss: 0.1806 - val_accuracy: 0.9142\nEpoch 66/100\n623/623 [==============================] - 0s 168us/step - loss: 0.1867 - accuracy: 0.9213 - val_loss: 0.1837 - val_accuracy: 0.9179\nEpoch 67/100\n623/623 [==============================] - 0s 163us/step - loss: 0.1898 - accuracy: 0.9213 - val_loss: 0.1856 - val_accuracy: 0.9179\nEpoch 68/100\n623/623 [==============================] - 0s 180us/step - loss: 0.1895 - accuracy: 0.9230 - val_loss: 0.1850 - val_accuracy: 0.9179\nEpoch 69/100\n623/623 [==============================] - 0s 161us/step - loss: 0.1895 - accuracy: 0.9230 - val_loss: 0.1857 - val_accuracy: 0.9179\nEpoch 70/100\n623/623 [==============================] - 0s 157us/step - loss: 0.1904 - accuracy: 0.9213 - val_loss: 0.1881 - val_accuracy: 0.9179\nEpoch 71/100\n623/623 [==============================] - 0s 179us/step - loss: 0.1853 - accuracy: 0.9230 - val_loss: 0.1823 - val_accuracy: 0.9142\nEpoch 72/100\n623/623 [==============================] - 0s 163us/step - loss: 0.1860 - accuracy: 0.9213 - val_loss: 0.1850 - val_accuracy: 0.9179\nEpoch 73/100\n623/623 [==============================] - 0s 169us/step - loss: 0.1831 - accuracy: 0.9230 - val_loss: 0.1852 - val_accuracy: 0.9179\nEpoch 74/100\n623/623 [==============================] - 0s 170us/step - loss: 0.1951 - accuracy: 0.9230 - val_loss: 0.1820 - val_accuracy: 0.9142\nEpoch 75/100\n623/623 [==============================] - 0s 162us/step - loss: 0.1903 - accuracy: 0.9230 - val_loss: 0.1820 - val_accuracy: 0.9142\nEpoch 76/100\n623/623 [==============================] - 0s 174us/step - loss: 0.1939 - accuracy: 0.9230 - val_loss: 0.1887 - val_accuracy: 0.9179\nEpoch 77/100\n623/623 [==============================] - 0s 175us/step - loss: 0.1853 - accuracy: 0.9262 - val_loss: 0.1833 - val_accuracy: 0.9179\nEpoch 78/100\n623/623 [==============================] - 0s 160us/step - loss: 0.2056 - accuracy: 0.9213 - val_loss: 0.1870 - val_accuracy: 0.9179\nEpoch 79/100\n623/623 [==============================] - 0s 169us/step - loss: 0.1917 - accuracy: 0.9213 - val_loss: 0.1817 - val_accuracy: 0.9142\nEpoch 80/100\n623/623 [==============================] - 0s 168us/step - loss: 0.1871 - accuracy: 0.9197 - val_loss: 0.1813 - val_accuracy: 0.9142\nEpoch 81/100\n623/623 [==============================] - 0s 170us/step - loss: 0.1832 - accuracy: 0.9246 - val_loss: 0.1824 - val_accuracy: 0.9142\nEpoch 82/100\n623/623 [==============================] - 0s 164us/step - loss: 0.1880 - accuracy: 0.9213 - val_loss: 0.1841 - val_accuracy: 0.9179\nEpoch 83/100\n623/623 [==============================] - 0s 165us/step - loss: 0.1813 - accuracy: 0.9197 - val_loss: 0.1833 - val_accuracy: 0.9179\nEpoch 84/100\n623/623 [==============================] - 0s 187us/step - loss: 0.1977 - accuracy: 0.9230 - val_loss: 0.1869 - val_accuracy: 0.9179\nEpoch 85/100\n623/623 [==============================] - 0s 165us/step - loss: 0.1940 - accuracy: 0.9230 - val_loss: 0.1826 - val_accuracy: 0.9179\nEpoch 86/100\n623/623 [==============================] - 0s 173us/step - loss: 0.1934 - accuracy: 0.9213 - val_loss: 0.1845 - val_accuracy: 0.9179\nEpoch 87/100\n623/623 [==============================] - 0s 168us/step - loss: 0.1857 - accuracy: 0.9181 - val_loss: 0.1849 - val_accuracy: 0.9179\nEpoch 88/100\n623/623 [==============================] - 0s 160us/step - loss: 0.1878 - accuracy: 0.9262 - val_loss: 0.1833 - val_accuracy: 0.9179\nEpoch 89/100\n623/623 [==============================] - 0s 164us/step - loss: 0.1908 - accuracy: 0.9197 - val_loss: 0.1854 - val_accuracy: 0.9179\nEpoch 90/100\n623/623 [==============================] - 0s 168us/step - loss: 0.1931 - accuracy: 0.9181 - val_loss: 0.1848 - val_accuracy: 0.9179\nEpoch 91/100\n623/623 [==============================] - 0s 169us/step - loss: 0.1959 - accuracy: 0.9230 - val_loss: 0.1829 - val_accuracy: 0.9179\nEpoch 92/100\n623/623 [==============================] - 0s 174us/step - loss: 0.1815 - accuracy: 0.9262 - val_loss: 0.1848 - val_accuracy: 0.9179\nEpoch 93/100\n623/623 [==============================] - 0s 167us/step - loss: 0.1864 - accuracy: 0.9246 - val_loss: 0.1854 - val_accuracy: 0.9179\nEpoch 94/100\n623/623 [==============================] - 0s 173us/step - loss: 0.1905 - accuracy: 0.9230 - val_loss: 0.1863 - val_accuracy: 0.9179\nEpoch 95/100\n623/623 [==============================] - 0s 173us/step - loss: 0.1850 - accuracy: 0.9213 - val_loss: 0.1830 - val_accuracy: 0.9179\nEpoch 96/100\n623/623 [==============================] - 0s 187us/step - loss: 0.1991 - accuracy: 0.9197 - val_loss: 0.1837 - val_accuracy: 0.9179\nEpoch 97/100\n623/623 [==============================] - 0s 170us/step - loss: 0.1968 - accuracy: 0.9230 - val_loss: 0.1877 - val_accuracy: 0.9179\nEpoch 98/100\n623/623 [==============================] - 0s 162us/step - loss: 0.1853 - accuracy: 0.9230 - val_loss: 0.1854 - val_accuracy: 0.9179\nEpoch 99/100\n623/623 [==============================] - 0s 163us/step - loss: 0.1891 - accuracy: 0.9213 - val_loss: 0.1837 - val_accuracy: 0.9179\nEpoch 100/100\n623/623 [==============================] - 0s 181us/step - loss: 0.1958 - accuracy: 0.9213 - val_loss: 0.1843 - val_accuracy: 0.9179\n"
                    ]
                },
                "mc_idx": 167,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 90,
                "o_idx": 0
            }
        },
        {
            "source": "# 17. Neural Network 2\n\n# Model\nmodel = Sequential()\nmodel.add(Dense(16, input_dim = train.shape[1], init = 'he_normal', activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64, init = 'he_normal', activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(32, init = 'he_normal', activation = 'relu'))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nes = EarlyStopping(monitor='val_accuracy', patience=20, mode='max')\nhist = model.fit(train, target, batch_size=64, validation_data=(Xval, Zval), \n               epochs=500, verbose=1, callbacks=[es])\nY_pred = model.predict(test)\nY_pred = (Y_pred > 0.5)*1 # convert probabilities to binary output\nnn_prediction = model.predict(train)\nnn_prediction = (nn_prediction > 0.5)*1 # convert probabilities to binary output\nacc3_ann2 = round(metrics.accuracy_score(target, nn_prediction) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": np.reshape(Y_pred, len(Y_pred))})\nsubmission.to_csv('submission_ann2_3.csv', index=False)\nLB_ann2 = 0.79665",
            "mc_idx": 168,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.16666666666666666,
                "Data_Transform": 0.3888888888888889,
                "Model_Train": 0.8888888888888888,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.7777777777777778,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.1111111111111111,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "shape": 2,
                    "size": 1
                },
                "Data_Transform": {
                    ".reshape": 1,
                    ".add": 6
                },
                "Model_Train": {
                    "model.fit": 1,
                    "sequential(": 1,
                    "compile": 1,
                    ".fit(": 1,
                    "model": 12
                },
                "Model_Evaluation": {
                    "accuracy_score": 2,
                    "model": 12,
                    ".predict(": 2,
                    ".accuracy": 1,
                    "metrics.accuracy": 1
                },
                "Model_Interpretation": {
                    "shap": 2,
                    "model": 12
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    91,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, input_dim=3, activation=\"relu\", kernel_initializer=\"he_normal\")`\n  \"\"\"\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")`\n  import sys\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")`\n  if __name__ == '__main__':\n",
                        "Train on 891 samples, validate on 268 samples\nEpoch 1/500\n891/891 [==============================] - 0s 470us/step - loss: 0.6562 - accuracy: 0.6330 - val_loss: 0.5167 - val_accuracy: 0.7724\nEpoch 2/500\n891/891 [==============================] - 0s 71us/step - loss: 0.5283 - accuracy: 0.7262 - val_loss: 0.4046 - val_accuracy: 0.7799\nEpoch 3/500\n891/891 [==============================] - 0s 46us/step - loss: 0.4659 - accuracy: 0.7654 - val_loss: 0.3357 - val_accuracy: 0.8955\nEpoch 4/500\n891/891 [==============================] - 0s 60us/step - loss: 0.4176 - accuracy: 0.7856 - val_loss: 0.2857 - val_accuracy: 0.8955\nEpoch 5/500\n891/891 [==============================] - 0s 57us/step - loss: 0.3676 - accuracy: 0.8148 - val_loss: 0.2524 - val_accuracy: 0.8955\nEpoch 6/500\n891/891 [==============================] - 0s 49us/step - loss: 0.3430 - accuracy: 0.8182 - val_loss: 0.2312 - val_accuracy: 0.8955\nEpoch 7/500\n891/891 [==============================] - 0s 46us/step - loss: 0.3360 - accuracy: 0.8238 - val_loss: 0.2177 - val_accuracy: 0.8955\nEpoch 8/500\n891/891 [==============================] - 0s 56us/step - loss: 0.3144 - accuracy: 0.8406 - val_loss: 0.2103 - val_accuracy: 0.8955\nEpoch 9/500\n891/891 [==============================] - 0s 50us/step - loss: 0.3260 - accuracy: 0.8328 - val_loss: 0.2039 - val_accuracy: 0.8955\nEpoch 10/500\n891/891 [==============================] - 0s 49us/step - loss: 0.2881 - accuracy: 0.8552 - val_loss: 0.2003 - val_accuracy: 0.8955\nEpoch 11/500\n891/891 [==============================] - 0s 48us/step - loss: 0.2965 - accuracy: 0.8608 - val_loss: 0.1964 - val_accuracy: 0.9067\nEpoch 12/500\n891/891 [==============================] - 0s 47us/step - loss: 0.2671 - accuracy: 0.8844 - val_loss: 0.1929 - val_accuracy: 0.9067\nEpoch 13/500\n891/891 [==============================] - 0s 44us/step - loss: 0.2642 - accuracy: 0.8765 - val_loss: 0.1923 - val_accuracy: 0.9067\nEpoch 14/500\n891/891 [==============================] - 0s 50us/step - loss: 0.2531 - accuracy: 0.8855 - val_loss: 0.1892 - val_accuracy: 0.9067\nEpoch 15/500\n891/891 [==============================] - 0s 45us/step - loss: 0.2659 - accuracy: 0.8765 - val_loss: 0.1868 - val_accuracy: 0.9067\nEpoch 16/500\n891/891 [==============================] - 0s 41us/step - loss: 0.2476 - accuracy: 0.9035 - val_loss: 0.1856 - val_accuracy: 0.9067\nEpoch 17/500\n891/891 [==============================] - 0s 44us/step - loss: 0.2601 - accuracy: 0.8799 - val_loss: 0.1856 - val_accuracy: 0.9067\nEpoch 18/500\n891/891 [==============================] - 0s 46us/step - loss: 0.2499 - accuracy: 0.8934 - val_loss: 0.1849 - val_accuracy: 0.9067\nEpoch 19/500\n891/891 [==============================] - 0s 42us/step - loss: 0.2418 - accuracy: 0.8923 - val_loss: 0.1838 - val_accuracy: 0.9067\nEpoch 20/500\n891/891 [==============================] - 0s 48us/step - loss: 0.2469 - accuracy: 0.8889 - val_loss: 0.1829 - val_accuracy: 0.9104\nEpoch 21/500\n891/891 [==============================] - 0s 48us/step - loss: 0.2563 - accuracy: 0.8967 - val_loss: 0.1829 - val_accuracy: 0.9104\nEpoch 22/500\n891/891 [==============================] - 0s 45us/step - loss: 0.2461 - accuracy: 0.8923 - val_loss: 0.1822 - val_accuracy: 0.9104\nEpoch 23/500\n891/891 [==============================] - 0s 44us/step - loss: 0.2277 - accuracy: 0.9035 - val_loss: 0.1826 - val_accuracy: 0.9104\nEpoch 24/500\n891/891 [==============================] - 0s 46us/step - loss: 0.2346 - accuracy: 0.8945 - val_loss: 0.1818 - val_accuracy: 0.9104\nEpoch 25/500\n891/891 [==============================] - 0s 45us/step - loss: 0.2470 - accuracy: 0.8945 - val_loss: 0.1819 - val_accuracy: 0.9104\nEpoch 26/500\n891/891 [==============================] - 0s 48us/step - loss: 0.2282 - accuracy: 0.8979 - val_loss: 0.1822 - val_accuracy: 0.9104\nEpoch 27/500\n891/891 [==============================] - 0s 43us/step - loss: 0.2340 - accuracy: 0.9024 - val_loss: 0.1820 - val_accuracy: 0.9104\nEpoch 28/500\n891/891 [==============================] - 0s 49us/step - loss: 0.2372 - accuracy: 0.8967 - val_loss: 0.1818 - val_accuracy: 0.9104\nEpoch 29/500\n891/891 [==============================] - 0s 46us/step - loss: 0.2320 - accuracy: 0.8979 - val_loss: 0.1820 - val_accuracy: 0.9142\nEpoch 30/500\n891/891 [==============================] - 0s 46us/step - loss: 0.2182 - accuracy: 0.9102 - val_loss: 0.1818 - val_accuracy: 0.9104\nEpoch 31/500\n891/891 [==============================] - 0s 48us/step - loss: 0.2225 - accuracy: 0.8967 - val_loss: 0.1807 - val_accuracy: 0.9104\nEpoch 32/500\n891/891 [==============================] - 0s 47us/step - loss: 0.2382 - accuracy: 0.8934 - val_loss: 0.1816 - val_accuracy: 0.9104\nEpoch 33/500\n891/891 [==============================] - 0s 47us/step - loss: 0.2271 - accuracy: 0.8979 - val_loss: 0.1817 - val_accuracy: 0.9104\nEpoch 34/500\n891/891 [==============================] - 0s 45us/step - loss: 0.2143 - accuracy: 0.9192 - val_loss: 0.1817 - val_accuracy: 0.9104\nEpoch 35/500\n891/891 [==============================] - 0s 48us/step - loss: 0.2230 - accuracy: 0.9113 - val_loss: 0.1813 - val_accuracy: 0.9104\nEpoch 36/500\n891/891 [==============================] - 0s 46us/step - loss: 0.2234 - accuracy: 0.9068 - val_loss: 0.1813 - val_accuracy: 0.9104\nEpoch 37/500\n891/891 [==============================] - 0s 46us/step - loss: 0.2214 - accuracy: 0.9102 - val_loss: 0.1807 - val_accuracy: 0.9104\nEpoch 38/500\n891/891 [==============================] - 0s 44us/step - loss: 0.2134 - accuracy: 0.9068 - val_loss: 0.1811 - val_accuracy: 0.9104\nEpoch 39/500\n891/891 [==============================] - 0s 43us/step - loss: 0.2218 - accuracy: 0.9113 - val_loss: 0.1818 - val_accuracy: 0.9104\nEpoch 40/500\n891/891 [==============================] - 0s 46us/step - loss: 0.2221 - accuracy: 0.9046 - val_loss: 0.1821 - val_accuracy: 0.9104\nEpoch 41/500\n891/891 [==============================] - 0s 45us/step - loss: 0.2053 - accuracy: 0.9091 - val_loss: 0.1814 - val_accuracy: 0.9104\nEpoch 42/500\n891/891 [==============================] - 0s 42us/step - loss: 0.2216 - accuracy: 0.9046 - val_loss: 0.1808 - val_accuracy: 0.9104\nEpoch 43/500\n891/891 [==============================] - 0s 41us/step - loss: 0.2132 - accuracy: 0.9091 - val_loss: 0.1825 - val_accuracy: 0.9142\nEpoch 44/500\n891/891 [==============================] - 0s 45us/step - loss: 0.2044 - accuracy: 0.9136 - val_loss: 0.1820 - val_accuracy: 0.9142\nEpoch 45/500\n891/891 [==============================] - 0s 47us/step - loss: 0.2045 - accuracy: 0.9091 - val_loss: 0.1810 - val_accuracy: 0.9142\nEpoch 46/500\n891/891 [==============================] - 0s 50us/step - loss: 0.2048 - accuracy: 0.9136 - val_loss: 0.1796 - val_accuracy: 0.9142\nEpoch 47/500\n891/891 [==============================] - 0s 47us/step - loss: 0.2058 - accuracy: 0.9102 - val_loss: 0.1815 - val_accuracy: 0.9142\nEpoch 48/500\n891/891 [==============================] - 0s 46us/step - loss: 0.2164 - accuracy: 0.9091 - val_loss: 0.1823 - val_accuracy: 0.9142\nEpoch 49/500\n891/891 [==============================] - 0s 46us/step - loss: 0.2249 - accuracy: 0.9035 - val_loss: 0.1810 - val_accuracy: 0.9104\n"
                    ]
                },
                "mc_idx": 168,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 91,
                "o_idx": 1
            }
        },
        {
            "source": "# 5.18 VotingClassifier (hard voting)\n\nVoting_Classifier_hard = VotingClassifier(estimators=[('lr', logreg), ('rf', random_forest), ('gbc', gradient_boosting)], voting='hard')\nfor clf, label in zip([logreg, random_forest, gradient_boosting, Voting_Classifier_hard], \n                      ['Logistic Regression', 'Random Forest', 'Gradient Boosting Classifier', 'Ensemble']):\n    scores = cross_val_score(clf, train, target, cv=cv_number, scoring='accuracy')\n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\nVoting_Classifier_hard.fit(train, target)\nY_pred = Voting_Classifier_hard.predict(test).astype(int)\nVoting_Classifier_hard.score(train, target)\nacc3_VC_hard = round(Voting_Classifier_hard.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_VC_hard3.csv', index=False)\nLB_VC_hard = 0.80382",
            "mc_idx": 169,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.75,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.75,
                "Hyperparameter_Tuning": 0.25,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.5,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".std(": 1,
                    ".mean": 1,
                    ".std": 1
                },
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "votingclassifier": 2
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "gradient": 3
                },
                "Hyperparameter_Tuning": {
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    92,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Accuracy: 0.90 (+/- 0.00) [Logistic Regression]\nAccuracy: 0.92 (+/- 0.03) [Random Forest]\nAccuracy: 0.92 (+/- 0.03) [Gradient Boosting Classifier]\nAccuracy: 0.92 (+/- 0.03) [Ensemble]\n"
                    ]
                },
                "mc_idx": 169,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 92,
                "o_idx": 0
            }
        },
        {
            "source": "# 5.19 VotingClassifier (soft voting)\n\neclf = VotingClassifier(estimators=[('lr', logreg), ('rf', random_forest), ('gbc', gradient_boosting)], voting='soft')\nparams = {'lr__C': [1.0, 100.0], 'gbc__learning_rate': [0.05, 1]}\nVoting_Classifier_soft = GridSearchCV(estimator=eclf, param_grid=params, cv=cv_number)\nVoting_Classifier_soft.fit(train, target)\nY_pred = Voting_Classifier_soft.predict(test).astype(int)\nVoting_Classifier_soft.score(train, target)\nacc3_VC_soft = round(Voting_Classifier_soft.score(train, target) * 100, 2)\nsubmission = pd.DataFrame({\"PassengerId\": submission[\"PassengerId\"],\"Survived\": Y_pred})\nsubmission.to_csv('submission_VC_soft3.csv', index=False)\nLB_VC_soft = 0.80382",
            "mc_idx": 170,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.14285714285714285,
                "Model_Train": 0.42857142857142855,
                "Model_Evaluation": 0.42857142857142855,
                "Model_Interpretation": 0.14285714285714285,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.2857142857142857,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "votingclassifier": 2
                },
                "Model_Evaluation": {
                    ".score(": 2,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "param_grid": 1,
                    "param": 3
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    93,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 170,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 93,
                "o_idx": 0
            }
        },
        {
            "source": "# 5.20 The simple rule in one line\nY_pred = (((test.WomanOrBoySurvived <= 0.238) & (test.Sex > 0.5) & (test.Alone > 0.5)) | \\\n          ((test.WomanOrBoySurvived > 0.238) & \\\n           ~((test.WomanOrBoySurvived > 0.55) & (test.WomanOrBoySurvived <= 0.633))))\nacc3_simple_rule = acc_simple_rule\nLB_simple_rule = 0.80382",
            "mc_idx": 171,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    94,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 171,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 94,
                "o_idx": 0
            }
        },
        {
            "source": "models = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Support Vector Machines', 'Linear SVC', 'k-Nearest Neighbors', 'Naive Bayes', \n              'Perceptron', 'Stochastic Gradient Decent', \n              'Decision Tree Classifier', 'Random Forest',  'XGBClassifier', 'LGBMClassifier',\n              'GradientBoostingClassifier', 'RidgeClassifier', 'BaggingClassifier', 'ExtraTreesClassifier', \n              'Neural Network 1', 'Neural Network 2', \n              'VotingClassifier-hard voiting', 'VotingClassifier-soft voting',\n              'Simple rule'],\n    \n    'Score16': [acc_log, acc_svc, acc_linear_svc, acc_knn, acc_gaussian, \n              acc_perceptron, acc_sgd, \n              acc_decision_tree, acc_random_forest, acc_XGB_Classifier, acc_LGB_Classifier,\n              acc_gradient_boosting, acc_ridge_classifier, acc_bagging_classifier, acc_etc, \n              acc_ann1, acc_ann2, \n              acc_VC_hard, acc_VC_soft,\n              acc_simple_rule],\n\n    'Score3': [acc3_log, acc3_svc, acc3_linear_svc, acc3_knn, acc3_gaussian, \n              acc3_perceptron, acc3_sgd, \n              acc3_decision_tree, acc3_random_forest, acc3_XGB_Classifier, acc3_LGB_Classifier,\n              acc3_gradient_boosting, acc3_ridge_classifier, acc3_bagging_classifier, acc3_etc, \n              acc3_ann1, acc3_ann2, \n              acc3_VC_hard, acc3_VC_soft,\n              acc3_simple_rule],\n\n    'LB_all': [LB_log_all, LB_svc_all, LB_linear_svc_all, LB_knn_all, LB_gaussian_all, \n              LB_perceptron_all, LB_sgd_all, \n              LB_decision_tree_all, LB_random_forest_all, LB_XGB_Classifier_all, LB_LGB_Classifier_all,\n              LB_GBC_all, LB_RidgeClassifier_all, LB_bagging_classifier_all, LB_ETC_all, \n              LB_ann1_all, LB_ann2_all, \n              LB_VC_hard_all, LB_VC_soft_all,\n              LB_simple_rule_all],\n    \n    'LB':    [LB_log, LB_svc, LB_linear_svc, LB_knn, LB_gaussian, \n              LB_perceptron, LB_sgd, \n              LB_decision_tree, LB_random_forest, LB_XGB_Classifier, LB_LGB_Classifier,\n              LB_GBC, LB_RidgeClassifier, LB_bagging_classifier, LB_ETC, \n              LB_ann1, LB_ann2, \n              LB_VC_hard, LB_VC_soft,\n              LB_simple_rule]})",
            "mc_idx": 174,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.10526315789473684,
                "Model_Interpretation": 0.3157894736842105,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 2,
                    "ridge": 5,
                    "gradientboostingclassifier": 1,
                    "svc": 9,
                    "votingclassifier": 2
                },
                "Model_Evaluation": {
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2,
                    "gradient": 4
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    95,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 174,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 95,
                "o_idx": 0
            }
        },
        {
            "source": "models.sort_values(by=['Score16', 'LB_all', 'LB'], ascending=False)",
            "mc_idx": 175,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    96,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "                            Model  Score16  Score3   LB_all       LB\n11     GradientBoostingClassifier   100.00   92.26  0.82296  0.80382\n8                   Random Forest   100.00   92.26  0.81339  0.80382\n17  VotingClassifier-hard voiting   100.00   92.26  0.81339  0.80382\n18   VotingClassifier-soft voting   100.00   92.26  0.81339  0.80382\n7        Decision Tree Classifier   100.00   92.26  0.77990  0.80382\n13              BaggingClassifier    99.66   92.26  0.80861  0.80382\n1         Support Vector Machines    98.99   92.14  0.62200  0.79904\n10                 LGBMClassifier    96.07   90.12  0.82296  0.62200\n2                      Linear SVC    94.61   89.45  0.81339  0.77033\n9                   XGBClassifier    94.39   77.78  0.80861  0.68899\n0             Logistic Regression    93.60   89.45  0.79904  0.77033\n14           ExtraTreesClassifier    93.38   92.14  0.80861  0.79904\n12                RidgeClassifier    93.15   89.56  0.80861  0.77511\n19                    Simple rule    92.70   92.70  0.83253  0.80382\n15               Neural Network 1    90.35   92.14  0.59330  0.79904\n4                     Naive Bayes    86.53   77.67  0.73205  0.68899\n3             k-Nearest Neighbors    76.32   90.68  0.62679  0.77751\n6      Stochastic Gradient Decent    72.17   91.36  0.64593  0.77511\n16               Neural Network 2    61.17   91.47  0.64114  0.79665\n5                      Perceptron    50.73   89.90  0.46889  0.77511"
                    ]
                },
                "mc_idx": 175,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 96,
                "o_idx": 0
            }
        },
        {
            "source": "models.sort_values(by=['Score3', 'LB_all', 'LB'], ascending=False)",
            "mc_idx": 176,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    97,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "                            Model  Score16  Score3   LB_all       LB\n19                    Simple rule    92.70   92.70  0.83253  0.80382\n11     GradientBoostingClassifier   100.00   92.26  0.82296  0.80382\n8                   Random Forest   100.00   92.26  0.81339  0.80382\n17  VotingClassifier-hard voiting   100.00   92.26  0.81339  0.80382\n18   VotingClassifier-soft voting   100.00   92.26  0.81339  0.80382\n13              BaggingClassifier    99.66   92.26  0.80861  0.80382\n7        Decision Tree Classifier   100.00   92.26  0.77990  0.80382\n14           ExtraTreesClassifier    93.38   92.14  0.80861  0.79904\n1         Support Vector Machines    98.99   92.14  0.62200  0.79904\n15               Neural Network 1    90.35   92.14  0.59330  0.79904\n16               Neural Network 2    61.17   91.47  0.64114  0.79665\n6      Stochastic Gradient Decent    72.17   91.36  0.64593  0.77511\n3             k-Nearest Neighbors    76.32   90.68  0.62679  0.77751\n10                 LGBMClassifier    96.07   90.12  0.82296  0.62200\n5                      Perceptron    50.73   89.90  0.46889  0.77511\n12                RidgeClassifier    93.15   89.56  0.80861  0.77511\n2                      Linear SVC    94.61   89.45  0.81339  0.77033\n0             Logistic Regression    93.60   89.45  0.79904  0.77033\n9                   XGBClassifier    94.39   77.78  0.80861  0.68899\n4                     Naive Bayes    86.53   77.67  0.73205  0.68899"
                    ]
                },
                "mc_idx": 176,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 97,
                "o_idx": 0
            }
        },
        {
            "source": "models.sort_values(by=['LB_all', 'LB', 'Score3'], ascending=False)",
            "mc_idx": 177,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    98,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "                            Model  Score16  Score3   LB_all       LB\n19                    Simple rule    92.70   92.70  0.83253  0.80382\n11     GradientBoostingClassifier   100.00   92.26  0.82296  0.80382\n10                 LGBMClassifier    96.07   90.12  0.82296  0.62200\n8                   Random Forest   100.00   92.26  0.81339  0.80382\n17  VotingClassifier-hard voiting   100.00   92.26  0.81339  0.80382\n18   VotingClassifier-soft voting   100.00   92.26  0.81339  0.80382\n2                      Linear SVC    94.61   89.45  0.81339  0.77033\n13              BaggingClassifier    99.66   92.26  0.80861  0.80382\n14           ExtraTreesClassifier    93.38   92.14  0.80861  0.79904\n12                RidgeClassifier    93.15   89.56  0.80861  0.77511\n9                   XGBClassifier    94.39   77.78  0.80861  0.68899\n0             Logistic Regression    93.60   89.45  0.79904  0.77033\n7        Decision Tree Classifier   100.00   92.26  0.77990  0.80382\n4                     Naive Bayes    86.53   77.67  0.73205  0.68899\n6      Stochastic Gradient Decent    72.17   91.36  0.64593  0.77511\n16               Neural Network 2    61.17   91.47  0.64114  0.79665\n3             k-Nearest Neighbors    76.32   90.68  0.62679  0.77751\n1         Support Vector Machines    98.99   92.14  0.62200  0.79904\n15               Neural Network 1    90.35   92.14  0.59330  0.79904\n5                      Perceptron    50.73   89.90  0.46889  0.77511"
                    ]
                },
                "mc_idx": 177,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 98,
                "o_idx": 0
            }
        },
        {
            "source": "models.sort_values(by=['LB', 'LB_all', 'Score3'], ascending=False)",
            "mc_idx": 178,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    99,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "                            Model  Score16  Score3   LB_all       LB\n19                    Simple rule    92.70   92.70  0.83253  0.80382\n11     GradientBoostingClassifier   100.00   92.26  0.82296  0.80382\n8                   Random Forest   100.00   92.26  0.81339  0.80382\n17  VotingClassifier-hard voiting   100.00   92.26  0.81339  0.80382\n18   VotingClassifier-soft voting   100.00   92.26  0.81339  0.80382\n13              BaggingClassifier    99.66   92.26  0.80861  0.80382\n7        Decision Tree Classifier   100.00   92.26  0.77990  0.80382\n14           ExtraTreesClassifier    93.38   92.14  0.80861  0.79904\n1         Support Vector Machines    98.99   92.14  0.62200  0.79904\n15               Neural Network 1    90.35   92.14  0.59330  0.79904\n16               Neural Network 2    61.17   91.47  0.64114  0.79665\n3             k-Nearest Neighbors    76.32   90.68  0.62679  0.77751\n12                RidgeClassifier    93.15   89.56  0.80861  0.77511\n6      Stochastic Gradient Decent    72.17   91.36  0.64593  0.77511\n5                      Perceptron    50.73   89.90  0.46889  0.77511\n2                      Linear SVC    94.61   89.45  0.81339  0.77033\n0             Logistic Regression    93.60   89.45  0.79904  0.77033\n9                   XGBClassifier    94.39   77.78  0.80861  0.68899\n4                     Naive Bayes    86.53   77.67  0.73205  0.68899\n10                 LGBMClassifier    96.07   90.12  0.82296  0.62200"
                    ]
                },
                "mc_idx": 178,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 99,
                "o_idx": 0
            }
        }
    ],
    "markdown_cells": [
        {
            "source": "<a class=\"anchor\" id=\"0\"></a>\n\n## FE, tuning and comparison of the 20 popular models with  predictions on the example of competition \"Titanic: Machine Learning from Disaster\"",
            "mc_idx": 0,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Features engineering (FE) from Titanic Top 3%\n\nBuild of the 20 most popular models, the most complex models from them are tuned (optimized)\n\nComparison of the optimal for each type models by CV and LB",
            "mc_idx": 1,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## Acknowledgements",
            "mc_idx": 2,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks for most popular models to:\n* https://www.kaggle.com/kabure/titanic-eda-model-pipeline-keras-nn\n* https://www.kaggle.com/startupsci/titanic-data-science-solutions \n* https://www.kaggle.com/nhlr21/complete-titanic-tutorial-with-ml-nn-ensembling\n\nThanks for FE:\n* https://www.kaggle.com/vbmokin/three-lines-of-code-for-titanic-top-15\n* https://www.kaggle.com/vbmokin/three-lines-of-code-for-titanic-top-20\n* https://www.kaggle.com/mauricef/titanic\n* https://www.kaggle.com/kpacocha/top-6-titanic-machine-learning-from-disaster\n* https://www.kaggle.com/erinsweet/simpledetect",
            "mc_idx": 3,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<a class=\"anchor\" id=\"0.1\"></a>\n\n## Table of Contents\n\n1. [Import libraries](#1)\n1. [Download datasets](#2)\n1. [Features engineering (FE)](#3)\n1. [Preparing to modeling](#4)\n    -  [Encoding categorical features](#4.1)\n    -  [Creation of training and validation sets](#4.2)\n1. [Tuning models and test for all 16 features](#5)\n    -  [Logistic Regression](#5.1)\n    -  [Support Vector Machines](#5.2)\n    -  [Linear SVC](#5.3)\n    -  [k-Nearest Neighbors algorithm with GridSearchCV](#5.4)\n    -  [Naive Bayes](#5.5)\n    -  [Perceptron](#5.6)\n    -  [Stochastic Gradient Descent](#5.7)\n    -  [Decision Tree Classifier](#5.8)\n    -  [Random Forests with GridSearchCV](#5.9)\n    -  [XGB Classifier with HyperOpt](#5.10)\n    -  [LGBM Classifier with HyperOpt](#5.11)\n    -  [GradientBoostingClassifier with HyperOpt](#5.12)\n    -  [RidgeClassifier](#5.13)\n    -  [BaggingClassifier](#5.14)\n    -  [ExtraTreesClassifier with HyperOpt](#5.15)\n    -  [Neural Network 1](#5.16)\n    -  [Neural Network 2](#5.17)\n    -  [VotingClassifier (hard voting)](#5.18)\n    -  [VotingClassifier (soft voting) with GridSearchCV](#5.19)\n    -  [The simple rule in one line](#5.20)\n1. [Tuning models and test for 3 features](#6)\n1. [Models evaluation](#7)\n1. [Conclusion](#8)\n",
            "mc_idx": 4,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 1. Import libraries <a class=\"anchor\" id=\"1\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 5,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 2. Download datasets <a class=\"anchor\" id=\"2\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 8,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 3. Features engineering (FE) <a class=\"anchor\" id=\"3\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 10,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "All models were tuned for a complete set of 16 features, solutions were calculated, that were uploaded to the competition, which made it possible to determine the error LB_all.\nAfter which the decision was taken into account\n* https://www.kaggle.com/mauricef/titanic\n* https://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code\n\ncalculated on only three features ('WomanOrBoySurvived', 'Alone', 'Sex') - an error LB is defined for this option.",
            "mc_idx": 16,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 4. Preparing to modeling <a class=\"anchor\" id=\"4\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 17,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 4.1 Encoding categorical features <a class=\"anchor\" id=\"4.1\"></a>",
            "mc_idx": 18,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 4.2 Creation of training and validation sets <a class=\"anchor\" id=\"4.2\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 23,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 5. Tuning models and test for all 16 features <a class=\"anchor\" id=\"5\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 25,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions\n\nNow we are ready to train a model and predict the required solution. There are 60+ predictive modelling algorithms to choose from. We must understand the type of problem and solution requirement to narrow down to a select few models which we can evaluate. Our problem is a classification and regression problem. We want to identify relationship between output (Survived or not) with other variables or features (Gender, Age, Port...). We are also perfoming a category of machine learning which is called supervised learning as we are training our model with a given dataset. With these two criteria - Supervised Learning plus Classification and Regression, we can narrow down our choice of models to a few. These include:\n\n- Logistic Regression\n- Support Vector Machines and Linear SVC\n- KNN or k-Nearest Neighbors\n- Naive Bayes Classifier or Gaussian Naive Bayes\n- Stochastic Gradient Descent, GradientBoostingClassifier, RidgeClassifier, BaggingClassifier\n- Decision Tree Classifier, Random Forest, XGB Classifier, LGBM Classifier, ExtraTreesClassifier\n- Perceptron, Neural Networks with different archictures (Deep Learning)\n- VotingClassifier (hard or soft voting)",
            "mc_idx": 26,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 5.1 Logistic Regression <a class=\"anchor\" id=\"5.1\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 27,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions",
            "mc_idx": 28,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Logistic Regression** is a useful model to run early in the workflow. Logistic regression measures the relationship between the categorical dependent variable (feature) and one or more independent variables (features) by estimating probabilities using a logistic function, which is the cumulative logistic distribution. Reference [Wikipedia](https://en.wikipedia.org/wiki/Logistic_regression).\n\nNote the confidence score generated by the model based on our training dataset.",
            "mc_idx": 29,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "We can use Logistic Regression to validate our assumptions and decisions for feature creating and completing goals. This can be done by calculating the coefficient of the features in the decision function.\n\nPositive coefficients increase the log-odds of the response (and thus increase the probability), and negative coefficients decrease the log-odds of the response (and thus decrease the probability).\n\n- Alone is highest positivie coefficient, implying as the Alone value increases (0 to 1), the probability of Survived=1 increases the most.\n- Inversely as Sex increases (male: 0 to female: 1), probability of Survived=1 decreases the most.\n- This way Age has second highest negative correlation with Survived.\n- So is LastName as second highest positive correlation.",
            "mc_idx": 32,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 5.2 Support Vector Machines <a class=\"anchor\" id=\"5.2\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 34,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions",
            "mc_idx": 35,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Support Vector Machines** are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. Given a set of training samples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new test samples to one category or the other, making it a non-probabilistic binary linear classifier. Reference [Wikipedia](https://en.wikipedia.org/wiki/Support_vector_machine).",
            "mc_idx": 36,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 5.3 Linear SVC <a class=\"anchor\" id=\"5.3\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 39,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions",
            "mc_idx": 40,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**SVC** is a similar to SVM method. Its also builds on kernel functions but is appropriate for unsupervised learning. Reference [Wikipedia](https://en.wikipedia.org/wiki/Support-vector_machine#Support-vector_clustering_(SVC).",
            "mc_idx": 41,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 5.4 k-Nearest Neighbors algorithm <a class=\"anchor\" id=\"5.4\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 44,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions",
            "mc_idx": 45,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "In pattern recognition, the **k-Nearest Neighbors algorithm** (or k-NN for short) is a non-parametric method used for classification and regression. A sample is classified by a majority vote of its neighbors, with the sample being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). Reference [Wikipedia](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm).",
            "mc_idx": 46,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 5.5 Naive Bayes <a class=\"anchor\" id=\"5.5\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 49,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions",
            "mc_idx": 50,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "In machine learning, **Naive Bayes classifiers** are a family of simple probabilistic classifiers based on applying Bayes' theorem with strong (naive) independence assumptions between the features. Naive Bayes classifiers are highly scalable, requiring a number of parameters linear in the number of variables (features) in a learning problem. Reference [Wikipedia](https://en.wikipedia.org/wiki/Naive_Bayes_classifier).",
            "mc_idx": 51,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 5.6 Perceptron <a class=\"anchor\" id=\"5.6\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 54,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions",
            "mc_idx": 55,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "The **Perceptron** is an algorithm for supervised learning of binary classifiers (functions that can decide whether an input, represented by a vector of numbers, belongs to some specific class or not). It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector. The algorithm allows for online learning, in that it processes elements in the training set one at a time. Reference [Wikipedia](https://en.wikipedia.org/wiki/Perceptron).",
            "mc_idx": 56,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 5.7 Stochastic Gradient Descent <a class=\"anchor\" id=\"5.7\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 59,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions",
            "mc_idx": 60,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Stochastic gradient descent** (often abbreviated **SGD**) is an iterative method for optimizing an objective function with suitable smoothness properties (e.g. differentiable or subdifferentiable). It can be regarded as a stochastic approximation of gradient descent optimization, since it replaces the actual gradient (calculated from the entire data set) by an estimate thereof (calculated from a randomly selected subset of the data). Especially in big data applications this reduces the computational burden, achieving faster iterations in trade for a slightly lower convergence rate. Reference [Wikipedia](https://en.wikipedia.org/wiki/Stochastic_gradient_descent).",
            "mc_idx": 61,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 5.8 Decision Tree Classifier <a class=\"anchor\" id=\"5.8\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 64,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions",
            "mc_idx": 65,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "This model uses a **Decision Tree** as a predictive model which maps features (tree branches) to conclusions about the target value (tree leaves). Tree models where the target variable can take a finite set of values are called classification trees; in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. Reference [Wikipedia](https://en.wikipedia.org/wiki/Decision_tree_learning).",
            "mc_idx": 66,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 5.9 Random Forests <a class=\"anchor\" id=\"5.9\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 69,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/startupsci/titanic-data-science-solutions",
            "mc_idx": 70,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Random Forests** is one of the most popular model. Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees (n_estimators= [100, 300]) at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Reference [Wikipedia](https://en.wikipedia.org/wiki/Random_forest).",
            "mc_idx": 71,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 5.10 XGB Classifier <a class=\"anchor\" id=\"5.10\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 74,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "XGBoost is an ensemble tree method that apply the principle of boosting weak learners (CARTs generally) using the gradient descent architecture. XGBoost improves upon the base Gradient Boosting Machines (GBM) framework through systems optimization and algorithmic enhancements. Reference [Towards Data Science.](https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d)",
            "mc_idx": 75,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "We will tuning the hyperparameters of the XGBClassifier model using the HyperOpt and 10-fold crossvalidation",
            "mc_idx": 76,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 5.11 LGBM Classifier <a class=\"anchor\" id=\"5.11\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 82,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Light GBM is a fast, distributed, high-performance gradient boosting framework based on decision tree algorithms. It splits the tree leaf wise with the best fit whereas other boosting algorithms split the tree depth wise or level wise rather than leaf-wise. So when growing on the same leaf in Light GBM, the leaf-wise algorithm can reduce more loss than the level-wise algorithm and hence results in much better accuracy which can rarely be achieved by any of the existing boosting algorithms. Also, it is surprisingly very fast, hence the word \u2018Light\u2019. Reference [Analytics Vidhya](https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/).",
            "mc_idx": 83,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "We will tuning the hyperparameters of the LGBMClassifier model using the HyperOpt and 10-fold crossvalidation",
            "mc_idx": 84,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 5.12 GradientBoostingClassifier <a class=\"anchor\" id=\"5.12\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 90,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/kabure/titanic-eda-model-pipeline-keras-nn",
            "mc_idx": 91,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Gradient Boosting** builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage n_classes_ regression trees are fit on the negative gradient of the binomial or multinomial deviance loss function. Binary classification is a special case where only a single regression tree is induced. The features are always randomly permuted at each split. Therefore, the best found split may vary, even with the same training data and max_features=n_features, if the improvement of the criterion is identical for several splits enumerated during the search of the best split. To obtain a deterministic behaviour during fitting, random_state has to be fixed. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html).",
            "mc_idx": 92,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 5.13 RidgeClassifier <a class=\"anchor\" id=\"5.13\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 97,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/kabure/titanic-eda-model-pipeline-keras-nn",
            "mc_idx": 98,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Tikhonov Regularization, colloquially known as **Ridge Regression**, is the most commonly used regression algorithm to approximate an answer for an equation with no unique solution. This type of problem is very common in machine learning tasks, where the \"best\" solution must be chosen using limited data. If a unique solution exists, algorithm will return the optimal value. However, if multiple solutions exist, it may choose any of them. Reference [Brilliant.org](https://brilliant.org/wiki/ridge-regression/).",
            "mc_idx": 99,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 5.14 BaggingClassifier <a class=\"anchor\" id=\"5.14\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 102,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/kabure/titanic-eda-model-pipeline-keras-nn",
            "mc_idx": 103,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Bootstrap aggregating, also called **bagging**, is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It also reduces variance and helps to avoid overfitting. Although it is usually applied to decision tree methods, it can be used with any type of method. Bagging is a special case of the model averaging approach. Bagging leads to \"improvements for unstable procedures\", which include, for example, artificial neural networks, classification and regression trees, and subset selection in linear regression. On the other hand, it can mildly degrade the performance of stable methods such as K-nearest neighbors. Reference [Wikipedia](https://en.wikipedia.org/wiki/Bootstrap_aggregating).\n\nA **Bagging classifier** is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html).",
            "mc_idx": 104,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 5.15 ExtraTreesClassifier <a class=\"anchor\" id=\"5.15\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 107,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/kabure/titanic-eda-model-pipeline-keras-nn",
            "mc_idx": 108,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**ExtraTreesClassifier** implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The default values for the parameters controlling the size of the trees (e.g. max_depth, min_samples_leaf, etc.) lead to fully grown and unpruned trees which can potentially be very large on some data sets. To reduce memory consumption, the complexity and size of the trees should be controlled by setting those parameter values. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html). \n\nIn extremely randomized trees, randomness goes one step further in the way splits are computed. As in random forests, a random subset of candidate features is used, but instead of looking for the most discriminative thresholds, thresholds are drawn at random for each candidate feature and the best of these randomly-generated thresholds is picked as the splitting rule. This usually allows to reduce the variance of the model a bit more, at the expense of a slightly greater increase in bias. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/ensemble.html#Extremely%20Randomized%20Trees).",
            "mc_idx": 109,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 5.16 Neural Network 1 <a class=\"anchor\" id=\"5.16\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 114,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/nhlr21/complete-titanic-tutorial-with-ml-nn-ensembling",
            "mc_idx": 115,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Neural networks** are more complex and more powerful algorithm than standars machine learning, it belongs to deep learning models. To build a neural network use Keras. Keras is a high level API for tensorflow, which is a tensor-manipulation framework made by google. Keras allows you to build neural networks by assembling blocks (which are the layers of neural network). ",
            "mc_idx": 116,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 5.17 Neural Network 2 <a class=\"anchor\" id=\"5.17\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 122,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to https://www.kaggle.com/junheeshin/titanic-analyze-and-predict-nn",
            "mc_idx": 123,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 5.18 VotingClassifier (hard voting) <a class=\"anchor\" id=\"5.18\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 131,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks for the example of ensemling different models from \nhttps://scikit-learn.org/stable/modules/ensemble.html#Extremely%20Randomized%20Trees",
            "mc_idx": 132,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "The idea behind the **VotingClassifier** is to combine conceptually different machine learning classifiers and use a majority vote (hard vote) or the average predicted probabilities (soft vote) to predict the class labels. Such a classifier can be useful for a set of equally well performing model in order to balance out their individual weaknesses. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/ensemble.html#Voting%20Classifier).",
            "mc_idx": 133,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "The VotingClassifier (with **hard voting**) would classify the sample as \u201cclass 1\u201d based on the **majority class label**. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/ensemble.html#Voting%20Classifier).",
            "mc_idx": 134,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 5.19 VotingClassifier (soft voting) <a class=\"anchor\" id=\"5.19\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 138,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks for the example of ensemling different models from \nhttps://scikit-learn.org/stable/modules/ensemble.html#Extremely%20Randomized%20Trees",
            "mc_idx": 139,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "In contrast to majority voting (hard voting), **soft voting** returns the class label as argmax of the **sum of predicted probabilities**.\nSpecific weights can be assigned to each classifier via the weights parameter. When weights are provided, the predicted class probabilities for each classifier are collected, multiplied by the classifier weight, and averaged. The final class label is then derived from the class label with the highest average probability. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/ensemble.html#Voting%20Classifier).",
            "mc_idx": 140,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 5.20 The simple rule in one line <a class=\"anchor\" id=\"5.20\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 143,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Thanks to:\n* https://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code\n* https://www.kaggle.com/vbmokin/titanic-top-3-cluster-analysis\n* https://www.kaggle.com/mauricef/titanic",
            "mc_idx": 144,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "It's solution generate tuned DecisionTreeClassifier by the GridSearchCV from kernels:\nhttps://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code",
            "mc_idx": 146,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 6. Tuning models and test for 3 features <a class=\"anchor\" id=\"6\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 149,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "My kernels\n\n* [Titanic : one line of the prediction code](https://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code)\n* [Titanic : cluster analysis](https://www.kaggle.com/vbmokin/titanic-top-3-cluster-analysis)\n\npresents a solutions using a simple rule and only 3 features ('WomanOrBoySurvived', 'Sex', 'Alone'). Let's look at how all these models are tuned for those 3 features and whether we can find an even better solution.",
            "mc_idx": 150,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 7. Models evaluation <a class=\"anchor\" id=\"7\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 172,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "We can now rank our evaluation of all the models to choose the best one for our problem.",
            "mc_idx": 173,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 8. Conclusion <a class=\"anchor\" id=\"8\"></a>\n\n[Back to Table of Contents](#0.1)",
            "mc_idx": 179,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "- The best model is the **simple rule in one line** from [\"Titanic Top 3% : one line of the prediction code\"](https://www.kaggle.com/vbmokin/titanic-top-3-one-line-of-the-prediction-code). Surprisingly, that the simple rule in one line gives the best result. This once again proves the enormous value of features engineering. The optimal selection of features is the key to success!\n\n- Models **GradientBoostingClassifier, Random Forests, VotingClassifiers, BaggingClassifier, Decision Tree Classifier** have provided the same accuracy LB on the test dataset as the simple rule, although on the training dataset they are much more accurate up to 100%.\n\n- The **VotingClassifier** for both voting options (\"*hard*\" and \"*soft*\") aggregation gave the same result for all the variants of features, that is, the solution found is indeed optimal, although a **Logistic Regression**, which is not one of the best, was selected for voting. This confirms the high efficiency of this method of aggregating (ensembling) predictions.\n\n- The models **GradientBoostingClassifier, BaggingClassifier, Random Forests, VotingClassifiers** did a good job of optimizing the features themselves, providing comparable accuracy for the different number of features in the test dataset, but the models **Decision Tree Classifier, Stochastic Gradient Descent, Support Vector Machines, Perceptron, Neural Networks, k-Nearest Neighbors algorithm** are very sensitive to the feature sets, because the accuracy of LB_all and LB is very different. Models **XGB Classifier, LGBM Classifier, ExtraTreesClassifier, Logistic Regression, Linear SVC, Naive Bayes, RidgeClassifier** depend on FE, but not so significantly.\n\n- The methods **LGBM Classifier, Perceptron, Neural Networks, Linear SVC, Naive Bayes, Logistic Regression, k-Nearest Neighbors algorithm, RidgeClassifier** have low accuracy LB, especially methods **Naive Bayes, Logistic Regression, Linear SVC**, compared to other models, although the \"***Titanic: Machine Learning from Disaster***\" contest is not indicative for the machine learning tasks because it contains too little data.\n\n- In all models, except **LGBM Classifier, Linear SVC, RidgeClassifier, Logistic Regression, Naive Bayes**, the prediction of test dataset based on 3 features yielded a more accurate result, possibly because these models perform worse under conditions of low number of features or under conditions of significant data dependence (in fact, feature \"*WomanOrBoySurvived*\" is, in part derived from others features \"*Sex*\" and \"*Alone*\") or with a small number of points (millions of points may vary greatly). Particularly interesting is that the **LGBM Classifier** model and method gave comparatively low accuracy on both the training and test datasets for the variant with three features, unlike **XGB Classifier** and other decision tree-based methods in which LB > LB_all.\n\n- To increase the accuracy of predictions, its need to increase the number of features and further improve their processing, that is FE (for example, add the processed feature \"**Tickets**\" - context is consist of a good kernels with have examples of such processing ([\"Advanced Feature Engineering Tutorial with Titanic\"](https://www.kaggle.com/gunesevitan/advanced-feature-engineering-tutorial-with-titanic) etc.).",
            "mc_idx": 180,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "I hope you find this kernel useful and enjoyable.",
            "mc_idx": 181,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Your comments and feedback are most welcome.",
            "mc_idx": 182,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "[Go to Top](#0)",
            "mc_idx": 183,
            "nb_idx": 39,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        }
    ],
    "sim_matrix": [],
    "cell_sim_matrix": [],
    "nb_order": [],
    "summary_data_VA": null
}