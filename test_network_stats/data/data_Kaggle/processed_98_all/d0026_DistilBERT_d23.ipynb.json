{
    "nb_idx": 26,
    "nb_name": "d0026",
    "filename": "d23.ipynb",
    "filepath": "data/data_Kaggle/raw/d23.ipynb",
    "source": "**Introduction:** While this notebook is intended to be beginner-friendly, it won't be feasible to explain every concept in detail to keep it a reasonable size. However, if you have the required prerequisites and basic understanding of Machine Learning, we hope it will be beneficial to you.\n\n**We would also like to express our gratitude to the Kaggle community as a whole for their efforts in making knowledge accessible to everyone. Thank you.** \n # Titanic: \"Women and Children First!\" - A beginner-friendly guide to applying Data Science and Machine Learning to the Titanic disaster.\n\n![1920px-Titanic_Starboard_View_1912.gif](attachment:4c681ad5-db7b-4d2b-884c-ed28c68819ef.gif) \n ### Table of Contents\n\n* [1. \"Women and children first,\" really? ](#1)\n    * [1.1 Brief Overview of the Sequence of Events.](#1.1)\n    * [1.2 Some Anecdotes and Notable Facts](#1.2)\n    * [1.3 Getting to the Heart of the Matter](#1.3)\n* [2. Exploratory Data Analysis (EDA)](#2)\n    * [2.1 Data Loading and Verification](#2.1)\n        * [2.1.1 Data Dictionary](#2.1.1)\n        * [2.1.2 The pandas.describe Function](#2.1.2)\n        * [2.1.3 The pandas.info Function](#2.1.3)\n    * [2.2 Data Visualization: A picture is worth a thousand words!](#2.2)\n        * [2.2.1 Visualization of the Age and Fare Distributions Using Histograms](#2.2.1)\n        * [2.2.2 Visualization and Analysis of Data Using a \"Swarm\" Plot](#2.2.2)\n        * [2.2.3 Visualization and Analysis of Boarding Data](#2.2.3)\n    * [2.3 A Dash of Feature Engineering](#2.3)\n        * [2.3.1 Family Size](#2.3.1)\n        * [2.3.2 Title and Last Name](#2.3.2)\n        * [2.3.3 Identifying and grouping women and children from the same family](#2.3.3)\n    * [2.4 Back to exploration...](#2.4)\n* [3. Data modeling](#3)\n    * [3.1 Decision tree 'women and children first'](#3.1)    \n* [4. Machine Learning](#4)\n    * [4.1 Feature engineering and data preprocessing.](#4.1)\n        * [4.1.1 creation of the 'isMaster' feature.](#4.1.1)\n        * [4.1.2 Data preprocessing](#4.1.2)\n    * [4.2 XGBoost and GridSearchCV](#4.2)\n        * [4.2.1 Definition of the hyperparameters to test](#4.2.1)\n        * [4.2.2 Definition of the xgb_classifier function](#4.2.2)\n        * [4.2.3 Feature Selection](#4.2.3)\n        * [4.2.4 training](#4.2.4)\n        * [4.2.5 Submitting our predictions to Kaggle and scoring](#4.2.5)\n* [5. Recap and How to Go Further...](#5)\n    * [5.1 How good is your score](#5.1)\n    * [5.2 How to go further?](#5.2)\n        \n         \n # 1.\"Women and children first,\" really? <a class=\"anchor\"  id=\"1\"></a>\n\n\"The women and children first\" principle is a concept that involves prioritizing the rescue of women and children before adult men in the face of a threat. During the 19th and early 20th centuries, ships with a tonnage of less than 10,000 tons did not have enough lifeboats to save all passengers. The idea of saving women and children during a shipwreck became particularly prominent in history during the Titanic disaster in 1912, perhaps the most famous maritime catastrophe of all time.\n\n\"However, according to the 2012 Swedish study titled 'Gender Social Norms and Survival in Maritime Disaster,' the survival rate of women and children is determined to be low. Analyzing 18 major maritime disasters that occurred between 1852 and 2011 and involved over 15,000 individuals from more than 30 different nationalities, the study reveals that the survival rate of the crew and captain surpasses that of the passengers. Men have a survival rate twice that of women, while children's survival rate reaches only 15%. This research posits the Titanic disaster as an exception, one of the few shipwrecks in the modern era where this principle was adhered to.\"\n\n> (en) M. Elinder et O. Erixson, \u00ab Gender, social norms, and survival in maritime disasters \u00bb, Proceedings of the National Academy of Sciences,\u200e 2 mai 2012 https://www.pnas.org/doi/full/10.1073/pnas.1207156109\n\nThe gender gap in survival rates has decreased since World War I, and women are more disadvantaged in British shipwrecks. The study asserts, \"Taken together, our results show that human behavior in life or death situations is better described by the expression 'every man for himself' or 'every person for themselves.'\"\n\nHowever, the study specifies that the Titanic disaster is an exception, and we will explore what the data analysis can tell us. Here, we will solely use the dataset provided by Kaggle as part of the friendly competition themed around the Titanic. We will stick to this dataset and refrain from introducing external structured data to play the game fairly.\n\n# 1.1 Brief Overview of the Sequence of Events. <a class=\"anchor\"  id=\"1.1\"></a>\n\nEven though this shipwreck is well-known, particularly through James Cameron's 1997 film, it seems useful to provide a brief overview of the events.\n\nThe sinking of the Titanic marked the end of the maiden voyage of the RMS Titanic, a ship intended to connect Southampton to New York. The Titanic was equipped with sixteen watertight compartments designed to protect the ship from significant damage. The media portrayed it as a reliable and even \"unsinkable\" vessel. However, contrary to this legend, historians emphasize that it was not considered \"unsinkable\" by its builders.\n\n> Source: Richard Howells, \"The Myth of the Titanic,\" Palgrave Macmillan, 2012.\n\nThe sinking unfolded on the night of April 14 to April 15, 1912, in the North Atlantic Ocean off the coast of Newfoundland. The ship struck an iceberg on the starboard side on Sunday, April 14, 1912, at 11:40 PM and sank in less than three hours, at 2:20 AM. Between 1,490 and 1,520 people perished, making this disaster one of the greatest maritime tragedies of all time.\n\nThe Titanic is a British transatlantic liner of the White Star Line, built at the initiative of Bruce Ismay and designed by the architect Thomas Andrews of the Harland & Wolff shipyards. Its construction began in 1909 in Belfast and was completed in 1912. At the time of its launch, it was the most luxurious and largest ship ever built. Its construction followed that of a nearly identical ship, the Olympic.\n\n# 1.2 Some Anecdotes and Notable Facts. <a class=\"anchor\"  id=\"1.2\"></a>\n\n* The ship did not have a sufficient number of lifeboats, and the crew had never been trained to handle this type of event.\n\n* The stewards then went to the cabins to invite passengers to put on warm clothes and a life jacket, asking them to go to the lifeboat deck. In order to reassure the passengers, the crew assured them that it was just a drill.\n\n* As a result, due to its reputation as unsinkable and the reassuring statements, disbelief prevailed.\n\n* Only a few passengers made their way to the lifeboat deck to board a lifeboat, and the majority did not worry and stayed inside the ship for a long time.\n\n* The first-class passengers were informed first, followed by the second class. The third-class passengers were prevented from accessing the deck until a later hour.\n\n* At 12:25 AM, the order is given to load women and children first into the lifeboats. At the same moment, the orchestra starts playing at the front of the lifeboat deck, following the command of Captain Smith, who aims to prevent any onset of panic.\n\n* Due to continued disbelief, many passengers were reluctant to board the lifeboats.\n\n* Regarding the first lifeboats, the officers on the port side only allowed women and children to board, while on the starboard side, each lifeboat was loaded with women and children first, followed by men. The pragmatism on the starboard side led to launching fully loaded lifeboats and better survivability for men, while on the port side, idealism and strict adherence to orders resulted in lifeboats with many vacant seats. This fact is very interesting, although it may be challenging to utilize with the data provided by Kaggle.\n\n* From 1:15 onwards, water began to flood the bow of the ship, and passengers, who were previously in disbelief, started to come to terms with the reality of the sinking. The evacuation accelerated from this point. Additionally, third-class passengers started arriving in larger numbers on the lifeboat deck.\n\n# 1.3 Getting to the Heart of the Matter <a class=\"anchor\"  id=\"1.3\"></a>\n\nIt's time to get to the heart of the matter, and to start, in the next cell, we will import all the libraries that will be useful to us. For practical reasons, we will centralize all imports here.\n\n\n\n\n\n \n # import\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Modelization\nimport xgboost as xgb\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold, GridSearchCV\n\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.preprocessing import OneHotEncoder \n print(\"hello, world\") \n # 2. Exploratory Data Analysis (EDA) <a class=\"anchor\"  id=\"2\"></a>\n\nIn summary, exploratory data analysis will help us understand the data patterns, check for integrity, and summarize relevant information for predictive models.\n\n> Exploratory data analysis (EDA) is used by data scientists to analyze and investigate data sets and summarize their main characteristics, often employing data visualization methods. It helps determine how best to manipulate data sources to get the answers you need, making it easier for data scientists to discover patterns, spot anomalies, test a hypothesis, or check assumptions.\n\n> source : https://www.ibm.com/topics/exploratory-data-analysis\n\n# 2.1 Data Loading and Verification <a class=\"anchor\"  id=\"2.1\"></a>\n\nIn this section, we will load the data provided by Kaggle and take a first look. \n # Load Data\ntrain = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest = pd.read_csv('/kaggle/input/titanic/test.csv')\n\ngender_submission = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\n# combine All Data\nall_data = pd.concat([train, test], axis=0).reset_index().drop('index', axis=1) \n # Have a look on data\ndisplay(train.head(3))\ndisplay(test.head(3))\ndisplay(all_data.head(3)) \n # 2.1.1 Data Dictionary <a class=\"anchor\"  id=\"2.1.1\"></a>\n\nEstablishing a data dictionary is essential as a reference to interpret the data without ambiguity regarding its meaning. Here is a good definition of what a data dictionary is:\n\n> A Data Dictionary is a collection of names, definitions, and attributes about data elements that are being used or captured in a database, information system, or part of a research project. It describes the meanings and purposes of data elements within the context of a project, and provides guidance on interpretation, accepted meanings and representation. A Data Dictionary also provides metadata about data elements. The metadata included in a Data Dictionary can assist in defining the scope and characteristics of data elements, as well the rules for their usage and application. \n\n> source: https://library.ucmerced.edu/data-dictionaries#:~:text=A%20Data%20Dictionary%20is%20a,part%20of%20a%20research%20project\n\n* **survival:** survival\n    * 0 = No,\n    * 1 = Yes\n* **pclass:** ticket class\n    * 1 = 1st,\n    * 2 = 2nd,\n    * 3 = 3rd\n* **sex:** sex\n* **Age:** age in years\n* **sibsp:** number of siblings / spouses aboard the Titanic\n* **parch:** number of parents / children aboard the Titanic\n* **ticket:** ticket number\n* **fare:** passenger fare\n* **cabin:** cabin number\n* **embarked:** Port of Embarkation\n    * C = Cherbourg,\n    * Q = Queenstown,\n    * S = Southampton\n\n\n\n# 2.1.2 The pandas.describe Function <a class=\"anchor\"  id=\"2.1.2\"></a>   \n\nFirstly, below is a description of the entire dataset using the 'describe' function provided by pandas.\n\n> The pandas.describe function is used to get a descriptive statistics summary of a given dataframe. This includes mean, count, std deviation, percentiles, and min-max values of all the features.\n\n> source : https://www.machinelearningplus.com/pandas/pandas-describe/ \n display(all_data.drop(['PassengerId', 'Survived', 'Pclass'] , axis=1).describe()) \n # 2.1.3 The pandas.info Function <a class=\"anchor\"  id=\"2.1.3\"></a>\n\n> The info() method prints information about the DataFrame. The information contains the number of columns, column labels, column data types, memory usage, range index, and the number of cells in each column (non-null values).\n\n> source : https://www.w3schools.com/python/pandas/ref_df_info.asp \n\n \n display(all_data.info()) \n # 2.2 Data Visualization: A picture is worth a thousand words! <a class=\"anchor\"  id=\"2.2\"></a>\n\nTo start, let's take a quick look at the distribution of age and the \"Fare\" feature. In the next cell, we will build a function to visualize them so that we don't have to repeat code unnecessarily. We will observe these two features on the entire available dataset.\n\n# 2.2.1 Visualization of the Age and Fare Distributions Using Histograms. <a class=\"anchor\"  id=\"2.2.1\"></a>\n\n> A histogram is a statistical graph that represents the distribution of a continuous dataset through plotted bars, each representing a particular category or class interval. The bar height reflects the frequency or count of data points within each group.\n\n> source : https://www.jaspersoft.com/articles/what-is-a-histogram-chart\n \n def plot_hist(features, data):\n    plt.figure(figsize = (10,4))\n    plt.hist(data[features], bins = 50)\n    plt.xlabel(features)\n    plt.ylabel(\"Frequency\")\n    plt.title(f\"{features} distribution\")\n    plt.show() \n Of course, in observing the age distribution, we are mindful that we have 263 missing values across all data. Here, we won't attempt to fill these gaps using the mean or median, etc., to avoid creating a 'spike' in the graph that doesn't reflect reality. We will, therefore, work with the information we have.\n\n \n print(\"Number of missing value for Age in all data : \",all_data['Age'].isnull().sum()) \n plot_hist(\"Age\", all_data) \n Regarding the fares (Fare), unsurprisingly, the lower values are more numerous.\n \n plot_hist(\"Fare\", all_data) \n # 2.2.2 Visualization and Analysis of Data Using a \"Swarm\" Plot <a class=\"anchor\"  id=\"2.2.2\"></a>\n\nWe will generate \"swarm\" plot graphs from the training data provided by Kaggle using the code below. These plots involve creating a scatter plot for each category with points adjusted to avoid overlap, providing a better representation of the distribution of values. We will use the \"seaborn\" library built on top of \"matplotlib\". If you want to learn more about this type of plot and how to implement it, I encourage you to consult the documentation.\n\n> https://seaborn.pydata.org/generated/seaborn.swarmplot.html\n\nIn our case, we will place the \"Sex\" category on the x-axis, with \"Age\" on the y-axis, and each point will be colored according to survival, specifically 'Survived'. We will extend this organization by distributing it over three columns representing each class.\n\nThis graph allows us to grasp a lot of information at a glance, and we will draw some initial insights from it. We will refer back to it later as well.\n\nAt first glance, it's evident that the survival rate for women is much higher, especially in the first and second classes, where the vast majority of women survive. However, in the third class, things are more mixed.\n\nFor men, it's a disaster, with still a better chance of survival in the first class. However, men in the second and third classes are literally decimated.\n\nRegarding the number of men and women, we observe that men are much more numerous. This imbalance is primarily due to the presence of a large number of men in the prime of life in the third class, perhaps in search of a better future. The destination being New York, and this city attracting many migrants, the idea of the \"American dream\" is prevalent at this time. In the first and second classes, things are a bit more balanced.\n\nRegarding children, taking into account that there are missing values (since we have the age of only 714 passengers out of 891), there seems to be relatively few children. Could some children be \"hidden\" among the 177 missing values?\n\nChildren seem to have a better survival rate. We can even observe that boys under 12 years old have survived much better than older men. Boys in the first and second classes seem to have all survived according to the data we have. These observations confirm the \"women and children first\" hypothesis, although once again, the chances of survival are more mixed in the third class.\n\nIndeed, there are likely more insights to gain from these graphs.\n\n \n sns.set_theme(style=\"whitegrid\")\npalette = ['darkslategray', 'goldenrod']\nsns.catplot(data=train,x=\"Sex\",y=\"Age\",hue=\"Survived\",height=5, aspect=2, kind=\"swarm\", palette=palette)\nsns.catplot(data=train, col=\"Pclass\",x = \"Sex\" ,y=\"Age\",hue=\"Survived\",height=5, aspect=1, kind=\"swarm\", palette=palette) \n # 2.2.3 Visualization and Analysis of Boarding Data <a class=\"anchor\"  id=\"2.2.3\"></a>\n\nAt first glance at the graph showing the relationship between the city of embarkation and the probability of survival, we might think there is a useful correlation. However, using the \"strip plot\" graph highlighting embarkations and class, we can explain this by the fact that third-class passengers are much fewer in number. Therefore, it's the survival probability based on class that is significant rather than the city of embarkation.\n\nHere, we will use a bar chart :\n\n> A bar plot or bar chart is a graph that represents the category of data with rectangular bars with lengths and heights that is proportional to the values which they represent. The bar plots can be plotted horizontally or vertically.\n\n> source : https://www.geeksforgeeks.org/bar-plot-in-matplotlib/\n\nAnd a 'strip plot' graph :\n\n> It is basically a scatter plot that differentiates different categories. So, all the data that corresponds to each category is shown as a scatter plot, and all the observations and collected data that are visualized are shown, side-by-side on a single graph.\n\n> source : https://www.educative.io/answers/what-is-seabornstripplot\n\n \n def cat_plot(feature_x, feature_y, data, label, kind = \"bar\"):\n    g = sns.catplot(x = feature_x, y = feature_y, data = data, kind = kind)\n    g.set_ylabels(label)\n    plt.show()\n    return g\n\ncat_plot(\"Embarked\", \"Survived\", train, \"Survived Probability\")\n\npalette_2 = [\"#3A0CA3\", \"#4361EE\", \"#4CC9F0\"]\nsns.stripplot(data=train.dropna(subset = ['Embarked']), x=\"Age\", y=\"Embarked\", hue=\"Pclass\", dodge=\"true\", size=2.7, palette = list(reversed(palette_2)))\nplt.show() \n # 2.3 A Dash of Feature Engineering <a class=\"anchor\"  id=\"2.3\"></a>\n\nBefore delving further into data exploration, we will create new features from the existing ones that will be necessary for a better understanding of the context, making them more usable.\n\n> Feature engineering is the process of selecting, manipulating, and transforming raw data into features that can be used in supervised learning. In order to make machine learning work well on new tasks, it might be necessary to design and train better features.\n\n> source : https://towardsdatascience.com/what-is-feature-engineering-importance-tools-and-techniques-for-machine-learning-2080b0269f10\n\nWe will just initiate this process at this early stage to facilitate data exploration, but we will revisit it later to prepare the data for machine learning model usage.\n\n# 2.3.1 Family Size <a class=\"anchor\"  id=\"2.3.1\"></a>\n\nHere, we will create the \"family_size\" feature since the two features:\n\n* sibsp: the number of siblings, spouses aboard the Titanic.\n* parch: the number of parents and children aboard the Titanic.\n\nWhile they provide a better understanding of family composition, they do not immediately capture the total. Therefore, we will add these two features together to obtain the total size of an individual's family.\n\n \n # craft new features \"Family Size\" \nall_data[\"FamilySize\"] = 1 + all_data[\"SibSp\"] + all_data[\"Parch\"]\ndisplay(all_data.head(3))\n \n # 2.3.2 Title and Last Name <a class=\"anchor\"  id=\"2.3.2\"></a>\n\nStill, for a better understanding of the family, we will process the 'Name' feature to extract the last name. At the same time, we will extract the title, which can provide valuable information.\n\n \n # craft 2 features 'Surname' and 'Title'\nall_data['Surname'] = all_data['Name'].apply(lambda x: x.split(',')[0]) \nall_data['Title'] = all_data['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0]) \ndisplay(all_data.head(3)) \n \nAfter some research to understand the meaning of these different titles, one thing seems very interesting: the significance of the title \"Master,\" which was used at that time to designate boys too young to be called \"Mister.\" This might help us identify boys whose age is not specified. \n sns.countplot(y=\"Title\", data = all_data, orient = 'v')\nplt.show() \n The script, while effective in the vast majority of cases in extracting the title from the name, made an error by assigning 'the' instead of 'Countess.' for passenger 760. We correct this error below.\n \n display(all_data[all_data.Title=='the'])\n#Correcting the Title for passenger 760\nall_data.loc[(all_data.PassengerId==760), 'Title'] = 'Countess.'\ndisplay(all_data[all_data.PassengerId==760]) \n Indeed, several boys with the title \"Master\" did not have the age specified!\n \n display(all_data.loc[(all_data.Title == 'Master.') & (all_data.Age.isnull())]) \n All boys under 12 have the title \"Master,\" except passenger 732. Let's correct that quickly...\n \n all_data.loc[(all_data.Age < 12) & (all_data.Sex == 'male') & (all_data.Title != 'Master.')]\n#Correcting the Title for passenger 760\nall_data.loc[(all_data.PassengerId==732), 'Title'] = 'Master.'\ndisplay(all_data[all_data.PassengerId==732])\n \n # 2.3.3 Identifying and grouping women and children from the same family <a class=\"anchor\"  id=\"2.3.3\"></a>\n\nHere, we will create new features that seem essential to capture the reality by grouping women and children from the same family.\n\nWe will define the 'WomenChild' feature as the membership in a group of women accompanied by children from the same family. Then, with the 'WomenChildNameSurvival' feature, we will assign a survival rate based on the training data for each of these families containing women and children. \n # Craft a dictionnary of surname for the women & children group \nwomen_child = all_data.loc[(all_data.Sex == 'female') | (all_data.Title == 'Master.')]\nwomen_child_surname_dic = women_child.groupby('Surname')['PassengerId'].count().to_dict()\n\n# craft a new feature 'WomenChildNameFreq' by mapping Surname to the dictionary\nall_data.loc[(all_data.Sex == 'female') | (all_data.Title == 'Master.'), 'WomenChildNameFreq'] = all_data.Surname.map(women_child_surname_dic) \n\n# Craft a feature 'woman_child' for grouping woman and child... 1 for true if a passenger belong to this group \nall_data.loc[(all_data.WomenChildNameFreq>1), 'WomenChild'] = 1\n\n# with the train data only, craft a dictionnary with an indice of survival\nonly_train = all_data[0:891]\nwomen_child_survivor_dic = only_train[(only_train.WomenChild==1)].groupby('Surname')['Survived'].mean().to_dict()\n\n# craft a new feature 'women_child_surname_survival'\nall_data.loc[(all_data.WomenChild==1), 'WomenChildNameSurvival']=all_data.Surname.map(women_child_survivor_dic) \n An important point to note here is that if we observe the survival rate of women and children groups based on the last name, according to the training data, 66 families from the 'women and children' group survived entirely, 22 families perished entirely, and only 4 families had a mixed outcome.\n\nThis leads us to believe that it is indeed wise to group women and children by family, and these families tend to either all survive or all perish together. \n dic_value = list(women_child_survivor_dic.values())\nprint(dic_value.count(0))\nprint(dic_value.count(1))\nprint(sum(1 for i in dic_value if 0 < i < 1 )) \n And this phenomenon is especially noticeable for the third class, as we can see in the following graph. \n sns.catplot(data=only_train[only_train.WomenChild == 1], x=\"Pclass\",y=\"Age\",hue=\"Survived\",height=5, aspect=2, kind=\"swarm\", palette=palette) \n Before continuing, since we made these changes to all_data, the original train and test data do not have the new features. To preserve the original data if needed, we will create new dataframes, only_train and only_test, containing the new features. \n only_train = all_data[0:891]\nonly_test = all_data[891:1309] \n # 2.4 Back to exploration... <a class=\"anchor\"  id=\"2.4\"></a>\n\nWe observe that family size seems to correlate with better survival, although for families with more than 4 members, the margin of error is too large to draw conclusions. As a hypothesis, following the \"women and children first\" principle, we can suggest that men traveling alone contribute to the drop in the survival rate of passengers traveling alone. \n cat_plot(\"FamilySize\", \"Survived\", only_train, \"Survived Probability\") \n Through this 'swarmplot' chart below, correlating survival, age, and family size for each passenger, we also observe that children from larger families in the third class appear to have a significantly lower survival rate. (However, as mentioned earlier, the data for large families is limited, resulting in a significant margin of error.) \n sns.swarmplot(data=only_train, x=\"Survived\", y=\"Age\", hue=\"FamilySize\", size=3.5, legend='full', palette='Spectral')\nsns.catplot(data=only_train, kind=\"swarm\", x=\"Survived\", y=\"Age\", hue=\"FamilySize\", legend='full', col=\"Pclass\", palette='Spectral') \n # 3. Data modeling <a class=\"anchor\"  id=\"3\"></a>\n\nIn the files provided by Kaggle, aside from the training and test data, there is a 'gender_submission' file that represents the predictions of a very simple model: all women survive, all men die.\n\nBy providing this file, Kaggle is clearly inviting us to try this model. That's what we'll do in the next cell.\n\nNote that this model does not use machine learning but a very simple and rudimentary decision tree: \"if it's a woman, then survive; if it's a man, then not.\"\n\n> A decision tree is a decision support hierarchical model that uses a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements.\n\n> source : https://en.wikipedia.org/wiki/Decision_tree \n # Have a look on gender_submission and output for submission\ndisplay(gender_submission.head(3))\n\n# and save the output formated for submission\ngender_submission.to_csv('gender_submission.csv', index=False)\n\n# And submit ... \n# score for gender_submission = 0.76555 \n Despite its simplicity, this model manages to capture a significant part of reality with a score of 0.76555! So, we will continue to model manually, i.e., without machine learning, to see if we can beat this score, which will serve as a reference to assess the relevance of our subsequent models.\n\nWe will check our basic assumption, \"women and children first,\" by building another model that predicts only women and children survive, and no men.\n\nAs we saw during the data exploration, there are many missing ages. While this is not a problem for girls, who will be included in the model among the surviving women, it's a different story for boys. Relying solely on gender and age, we will likely miss some boys.\n\n\nFortunately, during the data exploration, we determined that the title \"Master\" allows us to identify boys with certainty. We will use this feature. Also, it seems that children in the third class have less chance of survival if their family is large. \n # 3.1 Decision tree \"women and children first.\" <a class=\"anchor\"  id=\"3.1\"></a>\n\nLet's see if we can improve this score by testing our basic hypothesis, 'women and children first,' adjusted by the observation that children from large families in the third class seem to have much lower chances of survival.\n\nHere is our decision tree: \"if it's a man, then no-survival; if it's a woman, then survival; if it's a boy from the first and second class, then survival; if it's a boy from the third class and a small family, then survival.\" \n test_women_child = only_test\ntest_women_child = test_women_child.drop('Survived', axis=1)  \n # Gender Model\ntest_women_child.loc[(test_women_child.Sex == 'female' ), 'Survived'] = 1\ntest_women_child.loc[(test_women_child.Sex == 'male'), 'Survived'] = 0\n\n# Children \ntest_women_child.loc[(test_women_child.Title == 'Master.') & (test_women_child.Pclass == 1), 'Survived'] = 1\ntest_women_child.loc[(test_women_child.Title == 'Master.') & (test_women_child.Pclass == 2), 'Survived'] = 1\n\ntest_women_child.loc[(test_women_child.Title == 'Master.') & (test_women_child.Pclass == 3) & (test_women_child.FamilySize < 3) , 'Survived'] = 1\n\ntest_women_child['Survived'] = test_women_child['Survived'].astype(int) \n submission = test_women_child[['PassengerId', 'Survived']]\nsubmission.to_csv('women_child_model.csv', index=False)\n#Score : 0.77751 !!!!  \n Score : 0.77751\n\nWe have already significantly improved the score. However, we have not yet used some of our observations, such as the possibility of grouping women and children by family, and that these families tend to survive or not survive together, etc.\n\nEven though it is still possible to create a decision tree manually, things are starting to get more complex. It seems that now is the time to turn to 'machine learning.' \n # 4. Machine Learning <a class=\"anchor\"  id=\"4\"></a>\n\nAlthough this concept is probably already familiar to you, here is a definition of Machine Learning :\n\n> The use and development of computer systems capable of learning and adapting without following explicit instructions, using algorithms and statistical models to analyze and draw conclusions from patterns in data.\n\n> source : https://www.oed.com/?tl=true \n # 4.1 Feature engineering and data preprocessing. <a class=\"anchor\"  id=\"4.1\"></a>\n\n\"We have already encountered the concept of feature engineering in this notebook.\n\nData preprocessing refers to the preliminary processing steps performed on the data before using it in an analysis or model. Preprocessing may include activities such as data cleaning, normalization, dimensionality reduction, etc.\"\n\n# 4.1.1 creation of the 'isMaster' feature. <a class=\"anchor\"  id=\"4.1.1\"></a>\n\nHere we are going to create the 'isMaster' feature, as, as we have seen, the title 'Master' is much more reliable for identifying boys than gender and age, due to many missing values concerning age. \n all_data.loc[(all_data.Title == 'Master.'), 'isMaster'] = 1 \n # 4.1.2 Data preprocessing. <a class=\"anchor\"  id=\"4.1.2\"></a>\n\nWe will first set aside the features that we will not use for this instance: 'PassengerId', 'Name', 'Ticket', 'Cabin', 'Surname', 'Title', 'Embarked'.\"We will first set aside the features that we will not use for this instance: 'PassengerId', 'Name', 'Ticket', 'Cabin', 'Surname', 'Title', 'Embarked'.\"\n\n* 'PassengerId': This unique identifier is not useful for the model's learning.\n\n* 'Name': The unique name of each passenger neither.\n\n* 'Ticket': We set it aside for now because, at the outset, we consider the class to be a more significant feature.\n\n* Cabin': Many missing values; here too, we currently consider this feature as redundant since, indeed, only passengers in the first and second class have a cabin, indicating a higher socio-economic status, which is already captured by the 'Pclass' feature.\n\n* 'Surname': This feature allowed us to group women and children from the same family, but for now, it is not useful.\n\n* 'Title': This feature allowed us to identify boys reliably with the title 'Master', and we have created the 'isMaster' feature for that purpose, which we will use.\n\n* 'Embarked': We observed that the embarkation city alone is not really useful for determining a chance of survival, but rather the proportion of each class at embarkation matters.\" \n dropped_features = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'Surname', 'Title', 'Embarked']\n\nall_data_machine = all_data.drop(dropped_features, axis = 1)\n\ndisplay(all_data_machine.head(3)) \n Only the 'Sex' feature is a categorical variable. We will now encode it with OneHotEncoder\n\n> One-hot encoding is the process by which categorical data are converted into numerical data for use in machine learning. Categorical features are turned into binary features that are \u201cone-hot\u201d encoded, meaning that if a feature is represented by that column, it receives a 1. Otherwise, it receives a 0.\n\n> source : https://datagy.io/sklearn-one-hot-encode/ \n # Get list of categorical variables\ns = (all_data_machine.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols) \n # Apply one-hot encoder to each column with categorical data\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_all_data = pd.DataFrame(OH_encoder.fit_transform(all_data_machine[object_cols]))\n\n# One-hot encoding removed index; put it back\nOH_all_data.index = all_data_machine.index\n\n# Remove categorical columns (will replace with one-hot encoding)\nnum_all_data = all_data_machine.drop(object_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nOH_all_data = pd.concat([num_all_data, OH_all_data], axis=1)\n\n# Ensure all columns have string type\nOH_all_data.columns = OH_all_data.columns.astype(str) \n display(OH_all_data.head(3)) \n # 4.2 XGBoost and GridSearchCV <a class=\"anchor\"  id=\"4.2\"></a>\n\nHere we will use XGBoost.\n\n> XGBoost, which stands for Extreme Gradient Boosting, is a scalable, distributed gradient-boosted decision tree (GBDT) machine learning library. It provides parallel tree boosting and is the leading machine learning library for regression, classification, and ranking problems.\n\n> source : https://www.nvidia.com/en-us/glossary/data-science/xgboost/\n\nWhat is 'gradient boosting'?\n\n> Gradient boosting is a machine learning technique used in regression and classification tasks, among others. It gives a prediction model in the form of an ensemble of weak prediction models, i.e., models that make very few assumptions about the data, which are typically simple decision trees.\n\n> source : https://en.wikipedia.org/wiki/Gradient_boosting\n\nWe will therefore use this algorithm using the 'GridSearchCV' technique.\n\n> GridSearchCV is the process of performing hyperparameter tuning in order to determine the optimal values for a given model. As mentioned above, the performance of a model significantly depends on the value of hyperparameters. Note that there is no way to know in advance the best values for hyperparameters so ideally, we need to try all possible values to know the optimal values. Doing this manually could take a considerable amount of time and resources and thus we use GridSearchCV to automate the tuning of hyperparameters.\n\n> source : https://www.mygreatlearning.com/blog/gridsearchcv/\n\nFinally, we will take advantage of a very interesting feature of XGBoost.\n\n> XGBoost supports missing values by default. In tree algorithms, branch directions for missing values are learned during training.\n\n> source : https://xgboost.readthedocs.io/en/stable/faq.html\n\n\n# 4.2.1 Definition of the hyperparameters to test <a class=\"anchor\"  id=\"4.2.1\"></a> \n params = {\n 'learning_rate': [0.01, 0.05, 0.07, 0.1],\n 'subsample': [1],\n 'colsample_bylevel': [1],\n 'colsample_bynode': [1],\n 'colsample_bytree': [0.5],\n 'gamma': [0, 1, 2],\n 'max_delta_step': [0],\n 'max_depth': [2, 3, 4, 5],\n 'min_child_weight': [1.6],\n 'n_estimators': [70, 80, 90, 100], \n 'random_state': [42],\n 'scale_pos_weight': [1],\n 'seed': [42],\n 'n_jobs': [-1],\n 'reg_lambda': [1, 2, 4, 16]\n} \n # 4.2.2 Definition of the xgb_classifier function <a class=\"anchor\"  id=\"4.2.2\"></a>\n\nAlthough for this specific public notebook, we will not perform multiple tests, it is however considered good practice to gather all instructions within a function so that this function can be reused at will during various experiments. \n def xgb_classifier(data, target, params):\n      \n    # Create X and y\n    X = data.drop(target, axis=1)\n    y = data[target]\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X)\n    X_scaled = scaler.transform(X)\n    \n    # Create a XGBoost classifier (scikit-learn API wrapper)\n    xgb_clf = XGBClassifier()\n    \n    # Perform a gridsearch with sklearn\n    kf = KFold(n_splits=10, random_state=42, shuffle=True)\n    gridsearch = GridSearchCV(xgb_clf, param_grid=params, scoring=\"accuracy\", cv=kf, return_train_score=True)\n    gridsearch.fit(X_scaled, y)\n    \n    # Return the gridsearch results plus the scaler\n    return gridsearch, scaler \n # 4.2.3 Feature Selection <a class=\"anchor\"  id=\"4.2.3\"></a>\n\nWe will discard some features:\n\n* 'Age': too many missing values, we exclude it for this experiment...\n* 'SibSp' and 'Parch': redundant with FamilySize\n* 'Fare': we exclude it for this experiment as we consider that the class is sufficient\n* 'WomenChildNameFreq': this feature would have been useful for grouping women and children from the same family, but it does not seem useful for this experiment. \n dropped_features = ['Age', 'SibSp', 'Parch', 'Fare', 'WomenChildNameFreq']\n\ndata_for_XG = OH_all_data.drop(dropped_features, axis = 1)\ndisplay(data_for_XG.head(3))  \n # 4.2.4 training <a class=\"anchor\"  id=\"4.2.4\"></a> \n \ntrain_XG = data_for_XG[0:891]\n\ntest_XG = data_for_XG[891:1309]\ntest_XG = test_XG.drop('Survived', axis = 1)\n\ngridsearch, scaler = xgb_classifier(train_XG, \"Survived\", params)\n\ndisplay(gridsearch.best_params_)\n \n # 4.2.5 Submitting our predictions to Kaggle and scoring <a class=\"anchor\"  id=\"4.2.5\"></a> \n \ntest_XG_scaled = scaler.transform(test_XG)\n\npredictions = gridsearch.predict(test_XG_scaled)\n\noutput = pd.DataFrame({'PassengerId': PassengerId, 'Survived': predictions})\noutput.to_csv('gridsearch_xgboost.csv', index=False)\nprint(\"Your submission was successfully saved!\") \n\n### Score : 0.80382 \n # 5. Recap and How to Go Further... <a class=\"anchor\"  id=\"5\"></a> \n # 5.1 How good is your score  <a class=\"anchor\"  id=\"5.1\"></a>\n\nIt is well known that cheating is very prevalent in this friendly competition, for the simple reason that the complete data regarding the Titanic is public, and we already know the fate of each passenger. The only way to learn something from this challenge is to play the game honestly. As Carl McBride Ellis emphasizes in this notebook : \n\n> https://www.kaggle.com/code/carlmcbrideellis/titanic-leaderboard-a-score-0-8-is-great\n\nSo the only way to get a good way to evaluate your own score is to compare it with public notebooks that explain the entire method used to obtain a score in a transparent manner.\n\nHowever, be careful, the scoring system on the Titanic friendly competition has evolved over time, which changes the score of a notebook depending on whether it was submitted before or after this update, as explained here:\n\n> The first update (which many of you may already be aware of) is that the leaderboard scores are not permanent, and the scores will be removed after 2 months. The second update is that the calculation of the final score - which was previously performed on a percentage of the test data - has now changed. Scores are calculated on the entire test data. Now, ideally, this should not have changed the scoring model or changed it very little, on the order of a fraction of a percentage. But did you know that the scoring model is now such that you get a score between 1 and 3% LOWER than what could have been achieved previously!\n\nand to continue :\n\n> Scores of 79% and above are GOOD: Previously, 80% was considered very good. According to the new scoring model, this is equivalent to a score of about 79% and above. So, anything above that is a GOOD performance. Don't be disappointed if you don't reach 80%, which, according to the previous scoring model, was a benchmark score.\n\n> https://www.kaggle.com/competitions/titanic/discussion/177265\n\n# 5.2  How to go further? <a class=\"anchor\"  id=\"5.2\"></a>\n\nI recommend first reading this notebook where OSCAR TAKESHITA has done an excellent job of inventorying all possible approaches as well as raising questions about paths to explore\n\n> https://www.kaggle.com/code/pliptor/how-am-i-doing-with-my-score\n\nThen you will find here the notebooks with well-documented methods and providing the best scores, both in Python and R. I want to thank especially the authors for generously sharing their knowledge and expertise.\n\n(beware that the scores indicated are those before the update of the scoring system explained above)\n\n* Divide and Conquer \n> https://www.kaggle.com/code/pliptor/divide-and-conquer-0-82296/report\n    * Score : 0.82296\n* Lasso Ridge by Bisaria\n> https://www.kaggle.com/code/bisaria/titanic-lasso-ridge-implementation/report\n    * Score : 0.82296\n* Titanic using Name only Chris Deotte achieves this great score using nothing but the Name feature! (Note from his kernel: 0.81818 with Name only and 0.82296 by adding Ticket).\n> https://www.kaggle.com/code/cdeotte/titanic-using-name-only-0-81818/notebook\n    * Score : 0.82296\n* Titanic Deep Net by Chris Deotte\n> https://www.kaggle.com/code/cdeotte/titanic-deep-net-0-82296/notebook\n    * Score : 0.82296\n* Konstantin brings attention to feature scaling, which is essential when working with the kNN algorithm.\n> https://www.kaggle.com/code/konstantinmasich/titanic-0-82-0-83/notebook\n    * Score : 0.83253\n* Titanic Mega Model Chris Deotte ensembles Kaggle\u2019s top 6 models. It starts with a neat ensembling diagram.\n> https://www.kaggle.com/code/cdeotte/titantic-mega-model-0-84210/notebook\n    * Score : 0.84210\n* Titanic WCG+XGBoost Chris Deotte Is this the ultimate Titanic model?\n> https://www.kaggle.com/code/cdeotte/titanic-wcg-xgboost-0-84688/notebook\n    * Score : 0.84688  \n\n\n\n**I would like to thank the readers of this notebook as well as all the members of the Kaggle community. Thank you all!**",
    "code_source": "# import\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Modelization\nimport xgboost as xgb\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold, GridSearchCV\n\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.preprocessing import OneHotEncoder \n print(\"hello, world\") \n # Load Data\ntrain = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest = pd.read_csv('/kaggle/input/titanic/test.csv')\n\ngender_submission = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\n# combine All Data\nall_data = pd.concat([train, test], axis=0).reset_index().drop('index', axis=1) \n # Have a look on data\ndisplay(train.head(3))\ndisplay(test.head(3))\ndisplay(all_data.head(3)) \n display(all_data.drop(['PassengerId', 'Survived', 'Pclass'] , axis=1).describe()) \n display(all_data.info()) \n def plot_hist(features, data):\n    plt.figure(figsize = (10,4))\n    plt.hist(data[features], bins = 50)\n    plt.xlabel(features)\n    plt.ylabel(\"Frequency\")\n    plt.title(f\"{features} distribution\")\n    plt.show() \n print(\"Number of missing value for Age in all data : \",all_data['Age'].isnull().sum()) \n plot_hist(\"Age\", all_data) \n plot_hist(\"Fare\", all_data) \n sns.set_theme(style=\"whitegrid\")\npalette = ['darkslategray', 'goldenrod']\nsns.catplot(data=train,x=\"Sex\",y=\"Age\",hue=\"Survived\",height=5, aspect=2, kind=\"swarm\", palette=palette)\nsns.catplot(data=train, col=\"Pclass\",x = \"Sex\" ,y=\"Age\",hue=\"Survived\",height=5, aspect=1, kind=\"swarm\", palette=palette) \n def cat_plot(feature_x, feature_y, data, label, kind = \"bar\"):\n    g = sns.catplot(x = feature_x, y = feature_y, data = data, kind = kind)\n    g.set_ylabels(label)\n    plt.show()\n    return g\n\ncat_plot(\"Embarked\", \"Survived\", train, \"Survived Probability\")\n\npalette_2 = [\"#3A0CA3\", \"#4361EE\", \"#4CC9F0\"]\nsns.stripplot(data=train.dropna(subset = ['Embarked']), x=\"Age\", y=\"Embarked\", hue=\"Pclass\", dodge=\"true\", size=2.7, palette = list(reversed(palette_2)))\nplt.show() \n # craft new features \"Family Size\" \nall_data[\"FamilySize\"] = 1 + all_data[\"SibSp\"] + all_data[\"Parch\"]\ndisplay(all_data.head(3))\n \n # craft 2 features 'Surname' and 'Title'\nall_data['Surname'] = all_data['Name'].apply(lambda x: x.split(',')[0]) \nall_data['Title'] = all_data['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0]) \ndisplay(all_data.head(3)) \n sns.countplot(y=\"Title\", data = all_data, orient = 'v')\nplt.show() \n display(all_data[all_data.Title=='the'])\n#Correcting the Title for passenger 760\nall_data.loc[(all_data.PassengerId==760), 'Title'] = 'Countess.'\ndisplay(all_data[all_data.PassengerId==760]) \n display(all_data.loc[(all_data.Title == 'Master.') & (all_data.Age.isnull())]) \n all_data.loc[(all_data.Age < 12) & (all_data.Sex == 'male') & (all_data.Title != 'Master.')]\n#Correcting the Title for passenger 760\nall_data.loc[(all_data.PassengerId==732), 'Title'] = 'Master.'\ndisplay(all_data[all_data.PassengerId==732])\n \n # Craft a dictionnary of surname for the women & children group \nwomen_child = all_data.loc[(all_data.Sex == 'female') | (all_data.Title == 'Master.')]\nwomen_child_surname_dic = women_child.groupby('Surname')['PassengerId'].count().to_dict()\n\n# craft a new feature 'WomenChildNameFreq' by mapping Surname to the dictionary\nall_data.loc[(all_data.Sex == 'female') | (all_data.Title == 'Master.'), 'WomenChildNameFreq'] = all_data.Surname.map(women_child_surname_dic) \n\n# Craft a feature 'woman_child' for grouping woman and child... 1 for true if a passenger belong to this group \nall_data.loc[(all_data.WomenChildNameFreq>1), 'WomenChild'] = 1\n\n# with the train data only, craft a dictionnary with an indice of survival\nonly_train = all_data[0:891]\nwomen_child_survivor_dic = only_train[(only_train.WomenChild==1)].groupby('Surname')['Survived'].mean().to_dict()\n\n# craft a new feature 'women_child_surname_survival'\nall_data.loc[(all_data.WomenChild==1), 'WomenChildNameSurvival']=all_data.Surname.map(women_child_survivor_dic) \n dic_value = list(women_child_survivor_dic.values())\nprint(dic_value.count(0))\nprint(dic_value.count(1))\nprint(sum(1 for i in dic_value if 0 < i < 1 )) \n sns.catplot(data=only_train[only_train.WomenChild == 1], x=\"Pclass\",y=\"Age\",hue=\"Survived\",height=5, aspect=2, kind=\"swarm\", palette=palette) \n only_train = all_data[0:891]\nonly_test = all_data[891:1309] \n cat_plot(\"FamilySize\", \"Survived\", only_train, \"Survived Probability\") \n sns.swarmplot(data=only_train, x=\"Survived\", y=\"Age\", hue=\"FamilySize\", size=3.5, legend='full', palette='Spectral')\nsns.catplot(data=only_train, kind=\"swarm\", x=\"Survived\", y=\"Age\", hue=\"FamilySize\", legend='full', col=\"Pclass\", palette='Spectral') \n # Have a look on gender_submission and output for submission\ndisplay(gender_submission.head(3))\n\n# and save the output formated for submission\ngender_submission.to_csv('gender_submission.csv', index=False)\n\n# And submit ... \n# score for gender_submission = 0.76555 \n test_women_child = only_test\ntest_women_child = test_women_child.drop('Survived', axis=1)  \n # Gender Model\ntest_women_child.loc[(test_women_child.Sex == 'female' ), 'Survived'] = 1\ntest_women_child.loc[(test_women_child.Sex == 'male'), 'Survived'] = 0\n\n# Children \ntest_women_child.loc[(test_women_child.Title == 'Master.') & (test_women_child.Pclass == 1), 'Survived'] = 1\ntest_women_child.loc[(test_women_child.Title == 'Master.') & (test_women_child.Pclass == 2), 'Survived'] = 1\n\ntest_women_child.loc[(test_women_child.Title == 'Master.') & (test_women_child.Pclass == 3) & (test_women_child.FamilySize < 3) , 'Survived'] = 1\n\ntest_women_child['Survived'] = test_women_child['Survived'].astype(int) \n submission = test_women_child[['PassengerId', 'Survived']]\nsubmission.to_csv('women_child_model.csv', index=False)\n#Score : 0.77751 !!!!  \n all_data.loc[(all_data.Title == 'Master.'), 'isMaster'] = 1 \n dropped_features = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'Surname', 'Title', 'Embarked']\n\nall_data_machine = all_data.drop(dropped_features, axis = 1)\n\ndisplay(all_data_machine.head(3)) \n # Get list of categorical variables\ns = (all_data_machine.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols) \n # Apply one-hot encoder to each column with categorical data\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_all_data = pd.DataFrame(OH_encoder.fit_transform(all_data_machine[object_cols]))\n\n# One-hot encoding removed index; put it back\nOH_all_data.index = all_data_machine.index\n\n# Remove categorical columns (will replace with one-hot encoding)\nnum_all_data = all_data_machine.drop(object_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nOH_all_data = pd.concat([num_all_data, OH_all_data], axis=1)\n\n# Ensure all columns have string type\nOH_all_data.columns = OH_all_data.columns.astype(str) \n display(OH_all_data.head(3)) \n params = {\n 'learning_rate': [0.01, 0.05, 0.07, 0.1],\n 'subsample': [1],\n 'colsample_bylevel': [1],\n 'colsample_bynode': [1],\n 'colsample_bytree': [0.5],\n 'gamma': [0, 1, 2],\n 'max_delta_step': [0],\n 'max_depth': [2, 3, 4, 5],\n 'min_child_weight': [1.6],\n 'n_estimators': [70, 80, 90, 100], \n 'random_state': [42],\n 'scale_pos_weight': [1],\n 'seed': [42],\n 'n_jobs': [-1],\n 'reg_lambda': [1, 2, 4, 16]\n} \n def xgb_classifier(data, target, params):\n      \n    # Create X and y\n    X = data.drop(target, axis=1)\n    y = data[target]\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X)\n    X_scaled = scaler.transform(X)\n    \n    # Create a XGBoost classifier (scikit-learn API wrapper)\n    xgb_clf = XGBClassifier()\n    \n    # Perform a gridsearch with sklearn\n    kf = KFold(n_splits=10, random_state=42, shuffle=True)\n    gridsearch = GridSearchCV(xgb_clf, param_grid=params, scoring=\"accuracy\", cv=kf, return_train_score=True)\n    gridsearch.fit(X_scaled, y)\n    \n    # Return the gridsearch results plus the scaler\n    return gridsearch, scaler \n dropped_features = ['Age', 'SibSp', 'Parch', 'Fare', 'WomenChildNameFreq']\n\ndata_for_XG = OH_all_data.drop(dropped_features, axis = 1)\ndisplay(data_for_XG.head(3))  \n \ntrain_XG = data_for_XG[0:891]\n\ntest_XG = data_for_XG[891:1309]\ntest_XG = test_XG.drop('Survived', axis = 1)\n\ngridsearch, scaler = xgb_classifier(train_XG, \"Survived\", params)\n\ndisplay(gridsearch.best_params_)\n \n \ntest_XG_scaled = scaler.transform(test_XG)\n\npredictions = gridsearch.predict(test_XG_scaled)\n\noutput = pd.DataFrame({'PassengerId': PassengerId, 'Survived': predictions})\noutput.to_csv('gridsearch_xgboost.csv', index=False)\nprint(\"Your submission was successfully saved!\") \n\n### Score : 0.80382",
    "markdown_source": "**Introduction:** While this notebook is intended to be beginner-friendly, it won't be feasible to explain every concept in detail to keep it a reasonable size. However, if you have the required prerequisites and basic understanding of Machine Learning, we hope it will be beneficial to you.\n\n**We would also like to express our gratitude to the Kaggle community as a whole for their efforts in making knowledge accessible to everyone. Thank you.** \n # Titanic: \"Women and Children First!\" - A beginner-friendly guide to applying Data Science and Machine Learning to the Titanic disaster.\n\n![1920px-Titanic_Starboard_View_1912.gif](attachment:4c681ad5-db7b-4d2b-884c-ed28c68819ef.gif) \n ### Table of Contents\n\n* [1. \"Women and children first,\" really? ](#1)\n    * [1.1 Brief Overview of the Sequence of Events.](#1.1)\n    * [1.2 Some Anecdotes and Notable Facts](#1.2)\n    * [1.3 Getting to the Heart of the Matter](#1.3)\n* [2. Exploratory Data Analysis (EDA)](#2)\n    * [2.1 Data Loading and Verification](#2.1)\n        * [2.1.1 Data Dictionary](#2.1.1)\n        * [2.1.2 The pandas.describe Function](#2.1.2)\n        * [2.1.3 The pandas.info Function](#2.1.3)\n    * [2.2 Data Visualization: A picture is worth a thousand words!](#2.2)\n        * [2.2.1 Visualization of the Age and Fare Distributions Using Histograms](#2.2.1)\n        * [2.2.2 Visualization and Analysis of Data Using a \"Swarm\" Plot](#2.2.2)\n        * [2.2.3 Visualization and Analysis of Boarding Data](#2.2.3)\n    * [2.3 A Dash of Feature Engineering](#2.3)\n        * [2.3.1 Family Size](#2.3.1)\n        * [2.3.2 Title and Last Name](#2.3.2)\n        * [2.3.3 Identifying and grouping women and children from the same family](#2.3.3)\n    * [2.4 Back to exploration...](#2.4)\n* [3. Data modeling](#3)\n    * [3.1 Decision tree 'women and children first'](#3.1)    \n* [4. Machine Learning](#4)\n    * [4.1 Feature engineering and data preprocessing.](#4.1)\n        * [4.1.1 creation of the 'isMaster' feature.](#4.1.1)\n        * [4.1.2 Data preprocessing](#4.1.2)\n    * [4.2 XGBoost and GridSearchCV](#4.2)\n        * [4.2.1 Definition of the hyperparameters to test](#4.2.1)\n        * [4.2.2 Definition of the xgb_classifier function](#4.2.2)\n        * [4.2.3 Feature Selection](#4.2.3)\n        * [4.2.4 training](#4.2.4)\n        * [4.2.5 Submitting our predictions to Kaggle and scoring](#4.2.5)\n* [5. Recap and How to Go Further...](#5)\n    * [5.1 How good is your score](#5.1)\n    * [5.2 How to go further?](#5.2)\n        \n         \n # 1.\"Women and children first,\" really? <a class=\"anchor\"  id=\"1\"></a>\n\n\"The women and children first\" principle is a concept that involves prioritizing the rescue of women and children before adult men in the face of a threat. During the 19th and early 20th centuries, ships with a tonnage of less than 10,000 tons did not have enough lifeboats to save all passengers. The idea of saving women and children during a shipwreck became particularly prominent in history during the Titanic disaster in 1912, perhaps the most famous maritime catastrophe of all time.\n\n\"However, according to the 2012 Swedish study titled 'Gender Social Norms and Survival in Maritime Disaster,' the survival rate of women and children is determined to be low. Analyzing 18 major maritime disasters that occurred between 1852 and 2011 and involved over 15,000 individuals from more than 30 different nationalities, the study reveals that the survival rate of the crew and captain surpasses that of the passengers. Men have a survival rate twice that of women, while children's survival rate reaches only 15%. This research posits the Titanic disaster as an exception, one of the few shipwrecks in the modern era where this principle was adhered to.\"\n\n> (en) M. Elinder et O. Erixson, \u00ab Gender, social norms, and survival in maritime disasters \u00bb, Proceedings of the National Academy of Sciences,\u200e 2 mai 2012 https://www.pnas.org/doi/full/10.1073/pnas.1207156109\n\nThe gender gap in survival rates has decreased since World War I, and women are more disadvantaged in British shipwrecks. The study asserts, \"Taken together, our results show that human behavior in life or death situations is better described by the expression 'every man for himself' or 'every person for themselves.'\"\n\nHowever, the study specifies that the Titanic disaster is an exception, and we will explore what the data analysis can tell us. Here, we will solely use the dataset provided by Kaggle as part of the friendly competition themed around the Titanic. We will stick to this dataset and refrain from introducing external structured data to play the game fairly.\n\n# 1.1 Brief Overview of the Sequence of Events. <a class=\"anchor\"  id=\"1.1\"></a>\n\nEven though this shipwreck is well-known, particularly through James Cameron's 1997 film, it seems useful to provide a brief overview of the events.\n\nThe sinking of the Titanic marked the end of the maiden voyage of the RMS Titanic, a ship intended to connect Southampton to New York. The Titanic was equipped with sixteen watertight compartments designed to protect the ship from significant damage. The media portrayed it as a reliable and even \"unsinkable\" vessel. However, contrary to this legend, historians emphasize that it was not considered \"unsinkable\" by its builders.\n\n> Source: Richard Howells, \"The Myth of the Titanic,\" Palgrave Macmillan, 2012.\n\nThe sinking unfolded on the night of April 14 to April 15, 1912, in the North Atlantic Ocean off the coast of Newfoundland. The ship struck an iceberg on the starboard side on Sunday, April 14, 1912, at 11:40 PM and sank in less than three hours, at 2:20 AM. Between 1,490 and 1,520 people perished, making this disaster one of the greatest maritime tragedies of all time.\n\nThe Titanic is a British transatlantic liner of the White Star Line, built at the initiative of Bruce Ismay and designed by the architect Thomas Andrews of the Harland & Wolff shipyards. Its construction began in 1909 in Belfast and was completed in 1912. At the time of its launch, it was the most luxurious and largest ship ever built. Its construction followed that of a nearly identical ship, the Olympic.\n\n# 1.2 Some Anecdotes and Notable Facts. <a class=\"anchor\"  id=\"1.2\"></a>\n\n* The ship did not have a sufficient number of lifeboats, and the crew had never been trained to handle this type of event.\n\n* The stewards then went to the cabins to invite passengers to put on warm clothes and a life jacket, asking them to go to the lifeboat deck. In order to reassure the passengers, the crew assured them that it was just a drill.\n\n* As a result, due to its reputation as unsinkable and the reassuring statements, disbelief prevailed.\n\n* Only a few passengers made their way to the lifeboat deck to board a lifeboat, and the majority did not worry and stayed inside the ship for a long time.\n\n* The first-class passengers were informed first, followed by the second class. The third-class passengers were prevented from accessing the deck until a later hour.\n\n* At 12:25 AM, the order is given to load women and children first into the lifeboats. At the same moment, the orchestra starts playing at the front of the lifeboat deck, following the command of Captain Smith, who aims to prevent any onset of panic.\n\n* Due to continued disbelief, many passengers were reluctant to board the lifeboats.\n\n* Regarding the first lifeboats, the officers on the port side only allowed women and children to board, while on the starboard side, each lifeboat was loaded with women and children first, followed by men. The pragmatism on the starboard side led to launching fully loaded lifeboats and better survivability for men, while on the port side, idealism and strict adherence to orders resulted in lifeboats with many vacant seats. This fact is very interesting, although it may be challenging to utilize with the data provided by Kaggle.\n\n* From 1:15 onwards, water began to flood the bow of the ship, and passengers, who were previously in disbelief, started to come to terms with the reality of the sinking. The evacuation accelerated from this point. Additionally, third-class passengers started arriving in larger numbers on the lifeboat deck.\n\n# 1.3 Getting to the Heart of the Matter <a class=\"anchor\"  id=\"1.3\"></a>\n\nIt's time to get to the heart of the matter, and to start, in the next cell, we will import all the libraries that will be useful to us. For practical reasons, we will centralize all imports here.\n\n\n\n\n\n \n # 2. Exploratory Data Analysis (EDA) <a class=\"anchor\"  id=\"2\"></a>\n\nIn summary, exploratory data analysis will help us understand the data patterns, check for integrity, and summarize relevant information for predictive models.\n\n> Exploratory data analysis (EDA) is used by data scientists to analyze and investigate data sets and summarize their main characteristics, often employing data visualization methods. It helps determine how best to manipulate data sources to get the answers you need, making it easier for data scientists to discover patterns, spot anomalies, test a hypothesis, or check assumptions.\n\n> source : https://www.ibm.com/topics/exploratory-data-analysis\n\n# 2.1 Data Loading and Verification <a class=\"anchor\"  id=\"2.1\"></a>\n\nIn this section, we will load the data provided by Kaggle and take a first look. \n # 2.1.1 Data Dictionary <a class=\"anchor\"  id=\"2.1.1\"></a>\n\nEstablishing a data dictionary is essential as a reference to interpret the data without ambiguity regarding its meaning. Here is a good definition of what a data dictionary is:\n\n> A Data Dictionary is a collection of names, definitions, and attributes about data elements that are being used or captured in a database, information system, or part of a research project. It describes the meanings and purposes of data elements within the context of a project, and provides guidance on interpretation, accepted meanings and representation. A Data Dictionary also provides metadata about data elements. The metadata included in a Data Dictionary can assist in defining the scope and characteristics of data elements, as well the rules for their usage and application. \n\n> source: https://library.ucmerced.edu/data-dictionaries#:~:text=A%20Data%20Dictionary%20is%20a,part%20of%20a%20research%20project\n\n* **survival:** survival\n    * 0 = No,\n    * 1 = Yes\n* **pclass:** ticket class\n    * 1 = 1st,\n    * 2 = 2nd,\n    * 3 = 3rd\n* **sex:** sex\n* **Age:** age in years\n* **sibsp:** number of siblings / spouses aboard the Titanic\n* **parch:** number of parents / children aboard the Titanic\n* **ticket:** ticket number\n* **fare:** passenger fare\n* **cabin:** cabin number\n* **embarked:** Port of Embarkation\n    * C = Cherbourg,\n    * Q = Queenstown,\n    * S = Southampton\n\n\n\n# 2.1.2 The pandas.describe Function <a class=\"anchor\"  id=\"2.1.2\"></a>   \n\nFirstly, below is a description of the entire dataset using the 'describe' function provided by pandas.\n\n> The pandas.describe function is used to get a descriptive statistics summary of a given dataframe. This includes mean, count, std deviation, percentiles, and min-max values of all the features.\n\n> source : https://www.machinelearningplus.com/pandas/pandas-describe/ \n # 2.1.3 The pandas.info Function <a class=\"anchor\"  id=\"2.1.3\"></a>\n\n> The info() method prints information about the DataFrame. The information contains the number of columns, column labels, column data types, memory usage, range index, and the number of cells in each column (non-null values).\n\n> source : https://www.w3schools.com/python/pandas/ref_df_info.asp \n\n \n # 2.2 Data Visualization: A picture is worth a thousand words! <a class=\"anchor\"  id=\"2.2\"></a>\n\nTo start, let's take a quick look at the distribution of age and the \"Fare\" feature. In the next cell, we will build a function to visualize them so that we don't have to repeat code unnecessarily. We will observe these two features on the entire available dataset.\n\n# 2.2.1 Visualization of the Age and Fare Distributions Using Histograms. <a class=\"anchor\"  id=\"2.2.1\"></a>\n\n> A histogram is a statistical graph that represents the distribution of a continuous dataset through plotted bars, each representing a particular category or class interval. The bar height reflects the frequency or count of data points within each group.\n\n> source : https://www.jaspersoft.com/articles/what-is-a-histogram-chart\n \n Of course, in observing the age distribution, we are mindful that we have 263 missing values across all data. Here, we won't attempt to fill these gaps using the mean or median, etc., to avoid creating a 'spike' in the graph that doesn't reflect reality. We will, therefore, work with the information we have.\n\n \n Regarding the fares (Fare), unsurprisingly, the lower values are more numerous.\n \n # 2.2.2 Visualization and Analysis of Data Using a \"Swarm\" Plot <a class=\"anchor\"  id=\"2.2.2\"></a>\n\nWe will generate \"swarm\" plot graphs from the training data provided by Kaggle using the code below. These plots involve creating a scatter plot for each category with points adjusted to avoid overlap, providing a better representation of the distribution of values. We will use the \"seaborn\" library built on top of \"matplotlib\". If you want to learn more about this type of plot and how to implement it, I encourage you to consult the documentation.\n\n> https://seaborn.pydata.org/generated/seaborn.swarmplot.html\n\nIn our case, we will place the \"Sex\" category on the x-axis, with \"Age\" on the y-axis, and each point will be colored according to survival, specifically 'Survived'. We will extend this organization by distributing it over three columns representing each class.\n\nThis graph allows us to grasp a lot of information at a glance, and we will draw some initial insights from it. We will refer back to it later as well.\n\nAt first glance, it's evident that the survival rate for women is much higher, especially in the first and second classes, where the vast majority of women survive. However, in the third class, things are more mixed.\n\nFor men, it's a disaster, with still a better chance of survival in the first class. However, men in the second and third classes are literally decimated.\n\nRegarding the number of men and women, we observe that men are much more numerous. This imbalance is primarily due to the presence of a large number of men in the prime of life in the third class, perhaps in search of a better future. The destination being New York, and this city attracting many migrants, the idea of the \"American dream\" is prevalent at this time. In the first and second classes, things are a bit more balanced.\n\nRegarding children, taking into account that there are missing values (since we have the age of only 714 passengers out of 891), there seems to be relatively few children. Could some children be \"hidden\" among the 177 missing values?\n\nChildren seem to have a better survival rate. We can even observe that boys under 12 years old have survived much better than older men. Boys in the first and second classes seem to have all survived according to the data we have. These observations confirm the \"women and children first\" hypothesis, although once again, the chances of survival are more mixed in the third class.\n\nIndeed, there are likely more insights to gain from these graphs.\n\n \n # 2.2.3 Visualization and Analysis of Boarding Data <a class=\"anchor\"  id=\"2.2.3\"></a>\n\nAt first glance at the graph showing the relationship between the city of embarkation and the probability of survival, we might think there is a useful correlation. However, using the \"strip plot\" graph highlighting embarkations and class, we can explain this by the fact that third-class passengers are much fewer in number. Therefore, it's the survival probability based on class that is significant rather than the city of embarkation.\n\nHere, we will use a bar chart :\n\n> A bar plot or bar chart is a graph that represents the category of data with rectangular bars with lengths and heights that is proportional to the values which they represent. The bar plots can be plotted horizontally or vertically.\n\n> source : https://www.geeksforgeeks.org/bar-plot-in-matplotlib/\n\nAnd a 'strip plot' graph :\n\n> It is basically a scatter plot that differentiates different categories. So, all the data that corresponds to each category is shown as a scatter plot, and all the observations and collected data that are visualized are shown, side-by-side on a single graph.\n\n> source : https://www.educative.io/answers/what-is-seabornstripplot\n\n \n # 2.3 A Dash of Feature Engineering <a class=\"anchor\"  id=\"2.3\"></a>\n\nBefore delving further into data exploration, we will create new features from the existing ones that will be necessary for a better understanding of the context, making them more usable.\n\n> Feature engineering is the process of selecting, manipulating, and transforming raw data into features that can be used in supervised learning. In order to make machine learning work well on new tasks, it might be necessary to design and train better features.\n\n> source : https://towardsdatascience.com/what-is-feature-engineering-importance-tools-and-techniques-for-machine-learning-2080b0269f10\n\nWe will just initiate this process at this early stage to facilitate data exploration, but we will revisit it later to prepare the data for machine learning model usage.\n\n# 2.3.1 Family Size <a class=\"anchor\"  id=\"2.3.1\"></a>\n\nHere, we will create the \"family_size\" feature since the two features:\n\n* sibsp: the number of siblings, spouses aboard the Titanic.\n* parch: the number of parents and children aboard the Titanic.\n\nWhile they provide a better understanding of family composition, they do not immediately capture the total. Therefore, we will add these two features together to obtain the total size of an individual's family.\n\n \n # 2.3.2 Title and Last Name <a class=\"anchor\"  id=\"2.3.2\"></a>\n\nStill, for a better understanding of the family, we will process the 'Name' feature to extract the last name. At the same time, we will extract the title, which can provide valuable information.\n\n \n \nAfter some research to understand the meaning of these different titles, one thing seems very interesting: the significance of the title \"Master,\" which was used at that time to designate boys too young to be called \"Mister.\" This might help us identify boys whose age is not specified. \n The script, while effective in the vast majority of cases in extracting the title from the name, made an error by assigning 'the' instead of 'Countess.' for passenger 760. We correct this error below.\n \n Indeed, several boys with the title \"Master\" did not have the age specified!\n \n All boys under 12 have the title \"Master,\" except passenger 732. Let's correct that quickly...\n \n # 2.3.3 Identifying and grouping women and children from the same family <a class=\"anchor\"  id=\"2.3.3\"></a>\n\nHere, we will create new features that seem essential to capture the reality by grouping women and children from the same family.\n\nWe will define the 'WomenChild' feature as the membership in a group of women accompanied by children from the same family. Then, with the 'WomenChildNameSurvival' feature, we will assign a survival rate based on the training data for each of these families containing women and children. \n An important point to note here is that if we observe the survival rate of women and children groups based on the last name, according to the training data, 66 families from the 'women and children' group survived entirely, 22 families perished entirely, and only 4 families had a mixed outcome.\n\nThis leads us to believe that it is indeed wise to group women and children by family, and these families tend to either all survive or all perish together. \n And this phenomenon is especially noticeable for the third class, as we can see in the following graph. \n Before continuing, since we made these changes to all_data, the original train and test data do not have the new features. To preserve the original data if needed, we will create new dataframes, only_train and only_test, containing the new features. \n # 2.4 Back to exploration... <a class=\"anchor\"  id=\"2.4\"></a>\n\nWe observe that family size seems to correlate with better survival, although for families with more than 4 members, the margin of error is too large to draw conclusions. As a hypothesis, following the \"women and children first\" principle, we can suggest that men traveling alone contribute to the drop in the survival rate of passengers traveling alone. \n Through this 'swarmplot' chart below, correlating survival, age, and family size for each passenger, we also observe that children from larger families in the third class appear to have a significantly lower survival rate. (However, as mentioned earlier, the data for large families is limited, resulting in a significant margin of error.) \n # 3. Data modeling <a class=\"anchor\"  id=\"3\"></a>\n\nIn the files provided by Kaggle, aside from the training and test data, there is a 'gender_submission' file that represents the predictions of a very simple model: all women survive, all men die.\n\nBy providing this file, Kaggle is clearly inviting us to try this model. That's what we'll do in the next cell.\n\nNote that this model does not use machine learning but a very simple and rudimentary decision tree: \"if it's a woman, then survive; if it's a man, then not.\"\n\n> A decision tree is a decision support hierarchical model that uses a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements.\n\n> source : https://en.wikipedia.org/wiki/Decision_tree \n Despite its simplicity, this model manages to capture a significant part of reality with a score of 0.76555! So, we will continue to model manually, i.e., without machine learning, to see if we can beat this score, which will serve as a reference to assess the relevance of our subsequent models.\n\nWe will check our basic assumption, \"women and children first,\" by building another model that predicts only women and children survive, and no men.\n\nAs we saw during the data exploration, there are many missing ages. While this is not a problem for girls, who will be included in the model among the surviving women, it's a different story for boys. Relying solely on gender and age, we will likely miss some boys.\n\n\nFortunately, during the data exploration, we determined that the title \"Master\" allows us to identify boys with certainty. We will use this feature. Also, it seems that children in the third class have less chance of survival if their family is large. \n # 3.1 Decision tree \"women and children first.\" <a class=\"anchor\"  id=\"3.1\"></a>\n\nLet's see if we can improve this score by testing our basic hypothesis, 'women and children first,' adjusted by the observation that children from large families in the third class seem to have much lower chances of survival.\n\nHere is our decision tree: \"if it's a man, then no-survival; if it's a woman, then survival; if it's a boy from the first and second class, then survival; if it's a boy from the third class and a small family, then survival.\" \n Score : 0.77751\n\nWe have already significantly improved the score. However, we have not yet used some of our observations, such as the possibility of grouping women and children by family, and that these families tend to survive or not survive together, etc.\n\nEven though it is still possible to create a decision tree manually, things are starting to get more complex. It seems that now is the time to turn to 'machine learning.' \n # 4. Machine Learning <a class=\"anchor\"  id=\"4\"></a>\n\nAlthough this concept is probably already familiar to you, here is a definition of Machine Learning :\n\n> The use and development of computer systems capable of learning and adapting without following explicit instructions, using algorithms and statistical models to analyze and draw conclusions from patterns in data.\n\n> source : https://www.oed.com/?tl=true \n # 4.1 Feature engineering and data preprocessing. <a class=\"anchor\"  id=\"4.1\"></a>\n\n\"We have already encountered the concept of feature engineering in this notebook.\n\nData preprocessing refers to the preliminary processing steps performed on the data before using it in an analysis or model. Preprocessing may include activities such as data cleaning, normalization, dimensionality reduction, etc.\"\n\n# 4.1.1 creation of the 'isMaster' feature. <a class=\"anchor\"  id=\"4.1.1\"></a>\n\nHere we are going to create the 'isMaster' feature, as, as we have seen, the title 'Master' is much more reliable for identifying boys than gender and age, due to many missing values concerning age. \n # 4.1.2 Data preprocessing. <a class=\"anchor\"  id=\"4.1.2\"></a>\n\nWe will first set aside the features that we will not use for this instance: 'PassengerId', 'Name', 'Ticket', 'Cabin', 'Surname', 'Title', 'Embarked'.\"We will first set aside the features that we will not use for this instance: 'PassengerId', 'Name', 'Ticket', 'Cabin', 'Surname', 'Title', 'Embarked'.\"\n\n* 'PassengerId': This unique identifier is not useful for the model's learning.\n\n* 'Name': The unique name of each passenger neither.\n\n* 'Ticket': We set it aside for now because, at the outset, we consider the class to be a more significant feature.\n\n* Cabin': Many missing values; here too, we currently consider this feature as redundant since, indeed, only passengers in the first and second class have a cabin, indicating a higher socio-economic status, which is already captured by the 'Pclass' feature.\n\n* 'Surname': This feature allowed us to group women and children from the same family, but for now, it is not useful.\n\n* 'Title': This feature allowed us to identify boys reliably with the title 'Master', and we have created the 'isMaster' feature for that purpose, which we will use.\n\n* 'Embarked': We observed that the embarkation city alone is not really useful for determining a chance of survival, but rather the proportion of each class at embarkation matters.\" \n Only the 'Sex' feature is a categorical variable. We will now encode it with OneHotEncoder\n\n> One-hot encoding is the process by which categorical data are converted into numerical data for use in machine learning. Categorical features are turned into binary features that are \u201cone-hot\u201d encoded, meaning that if a feature is represented by that column, it receives a 1. Otherwise, it receives a 0.\n\n> source : https://datagy.io/sklearn-one-hot-encode/ \n # 4.2 XGBoost and GridSearchCV <a class=\"anchor\"  id=\"4.2\"></a>\n\nHere we will use XGBoost.\n\n> XGBoost, which stands for Extreme Gradient Boosting, is a scalable, distributed gradient-boosted decision tree (GBDT) machine learning library. It provides parallel tree boosting and is the leading machine learning library for regression, classification, and ranking problems.\n\n> source : https://www.nvidia.com/en-us/glossary/data-science/xgboost/\n\nWhat is 'gradient boosting'?\n\n> Gradient boosting is a machine learning technique used in regression and classification tasks, among others. It gives a prediction model in the form of an ensemble of weak prediction models, i.e., models that make very few assumptions about the data, which are typically simple decision trees.\n\n> source : https://en.wikipedia.org/wiki/Gradient_boosting\n\nWe will therefore use this algorithm using the 'GridSearchCV' technique.\n\n> GridSearchCV is the process of performing hyperparameter tuning in order to determine the optimal values for a given model. As mentioned above, the performance of a model significantly depends on the value of hyperparameters. Note that there is no way to know in advance the best values for hyperparameters so ideally, we need to try all possible values to know the optimal values. Doing this manually could take a considerable amount of time and resources and thus we use GridSearchCV to automate the tuning of hyperparameters.\n\n> source : https://www.mygreatlearning.com/blog/gridsearchcv/\n\nFinally, we will take advantage of a very interesting feature of XGBoost.\n\n> XGBoost supports missing values by default. In tree algorithms, branch directions for missing values are learned during training.\n\n> source : https://xgboost.readthedocs.io/en/stable/faq.html\n\n\n# 4.2.1 Definition of the hyperparameters to test <a class=\"anchor\"  id=\"4.2.1\"></a> \n # 4.2.2 Definition of the xgb_classifier function <a class=\"anchor\"  id=\"4.2.2\"></a>\n\nAlthough for this specific public notebook, we will not perform multiple tests, it is however considered good practice to gather all instructions within a function so that this function can be reused at will during various experiments. \n # 4.2.3 Feature Selection <a class=\"anchor\"  id=\"4.2.3\"></a>\n\nWe will discard some features:\n\n* 'Age': too many missing values, we exclude it for this experiment...\n* 'SibSp' and 'Parch': redundant with FamilySize\n* 'Fare': we exclude it for this experiment as we consider that the class is sufficient\n* 'WomenChildNameFreq': this feature would have been useful for grouping women and children from the same family, but it does not seem useful for this experiment. \n # 4.2.4 training <a class=\"anchor\"  id=\"4.2.4\"></a> \n # 4.2.5 Submitting our predictions to Kaggle and scoring <a class=\"anchor\"  id=\"4.2.5\"></a> \n # 5. Recap and How to Go Further... <a class=\"anchor\"  id=\"5\"></a> \n # 5.1 How good is your score  <a class=\"anchor\"  id=\"5.1\"></a>\n\nIt is well known that cheating is very prevalent in this friendly competition, for the simple reason that the complete data regarding the Titanic is public, and we already know the fate of each passenger. The only way to learn something from this challenge is to play the game honestly. As Carl McBride Ellis emphasizes in this notebook : \n\n> https://www.kaggle.com/code/carlmcbrideellis/titanic-leaderboard-a-score-0-8-is-great\n\nSo the only way to get a good way to evaluate your own score is to compare it with public notebooks that explain the entire method used to obtain a score in a transparent manner.\n\nHowever, be careful, the scoring system on the Titanic friendly competition has evolved over time, which changes the score of a notebook depending on whether it was submitted before or after this update, as explained here:\n\n> The first update (which many of you may already be aware of) is that the leaderboard scores are not permanent, and the scores will be removed after 2 months. The second update is that the calculation of the final score - which was previously performed on a percentage of the test data - has now changed. Scores are calculated on the entire test data. Now, ideally, this should not have changed the scoring model or changed it very little, on the order of a fraction of a percentage. But did you know that the scoring model is now such that you get a score between 1 and 3% LOWER than what could have been achieved previously!\n\nand to continue :\n\n> Scores of 79% and above are GOOD: Previously, 80% was considered very good. According to the new scoring model, this is equivalent to a score of about 79% and above. So, anything above that is a GOOD performance. Don't be disappointed if you don't reach 80%, which, according to the previous scoring model, was a benchmark score.\n\n> https://www.kaggle.com/competitions/titanic/discussion/177265\n\n# 5.2  How to go further? <a class=\"anchor\"  id=\"5.2\"></a>\n\nI recommend first reading this notebook where OSCAR TAKESHITA has done an excellent job of inventorying all possible approaches as well as raising questions about paths to explore\n\n> https://www.kaggle.com/code/pliptor/how-am-i-doing-with-my-score\n\nThen you will find here the notebooks with well-documented methods and providing the best scores, both in Python and R. I want to thank especially the authors for generously sharing their knowledge and expertise.\n\n(beware that the scores indicated are those before the update of the scoring system explained above)\n\n* Divide and Conquer \n> https://www.kaggle.com/code/pliptor/divide-and-conquer-0-82296/report\n    * Score : 0.82296\n* Lasso Ridge by Bisaria\n> https://www.kaggle.com/code/bisaria/titanic-lasso-ridge-implementation/report\n    * Score : 0.82296\n* Titanic using Name only Chris Deotte achieves this great score using nothing but the Name feature! (Note from his kernel: 0.81818 with Name only and 0.82296 by adding Ticket).\n> https://www.kaggle.com/code/cdeotte/titanic-using-name-only-0-81818/notebook\n    * Score : 0.82296\n* Titanic Deep Net by Chris Deotte\n> https://www.kaggle.com/code/cdeotte/titanic-deep-net-0-82296/notebook\n    * Score : 0.82296\n* Konstantin brings attention to feature scaling, which is essential when working with the kNN algorithm.\n> https://www.kaggle.com/code/konstantinmasich/titanic-0-82-0-83/notebook\n    * Score : 0.83253\n* Titanic Mega Model Chris Deotte ensembles Kaggle\u2019s top 6 models. It starts with a neat ensembling diagram.\n> https://www.kaggle.com/code/cdeotte/titantic-mega-model-0-84210/notebook\n    * Score : 0.84210\n* Titanic WCG+XGBoost Chris Deotte Is this the ultimate Titanic model?\n> https://www.kaggle.com/code/cdeotte/titanic-wcg-xgboost-0-84688/notebook\n    * Score : 0.84688  \n\n\n\n**I would like to thank the readers of this notebook as well as all the members of the Kaggle community. Thank you all!**",
    "n_cells": 77,
    "n_code_cells": 38,
    "n_markdown_cells": 39,
    "n_raw_cells": 0,
    "n_outputs": 38,
    "r_code_cells": 0.4935064935064935,
    "r_markdown_cells": 0.5064935064935064,
    "r_raw_cells": 0.0,
    "r_outputs": 1.0,
    "n_exceptions": 0,
    "r_exceptions": 0.0,
    "n_lines": 640,
    "n_lines_code": 226,
    "n_lines_markdown": 414,
    "lines_per_cell": [
        3,
        3,
        37,
        53,
        23,
        1,
        11,
        11,
        4,
        36,
        1,
        7,
        1,
        10,
        7,
        3,
        1,
        1,
        2,
        1,
        23,
        4,
        17,
        11,
        20,
        4,
        5,
        4,
        2,
        2,
        2,
        4,
        2,
        1,
        2,
        5,
        5,
        16,
        3,
        4,
        1,
        1,
        1,
        2,
        3,
        1,
        1,
        2,
        11,
        8,
        8,
        5,
        2,
        11,
        3,
        5,
        7,
        9,
        1,
        17,
        5,
        5,
        6,
        15,
        1,
        28,
        17,
        3,
        21,
        8,
        4,
        1,
        10,
        1,
        10,
        1,
        53
    ],
    "lines_per_code_cell": [
        23,
        1,
        11,
        4,
        1,
        1,
        7,
        1,
        1,
        1,
        4,
        11,
        4,
        4,
        2,
        4,
        1,
        5,
        16,
        4,
        1,
        2,
        1,
        2,
        8,
        2,
        11,
        3,
        1,
        5,
        6,
        15,
        1,
        17,
        21,
        4,
        10,
        10
    ],
    "lines_per_markdown_cell": [
        3,
        3,
        37,
        53,
        11,
        36,
        7,
        10,
        3,
        2,
        23,
        17,
        20,
        5,
        2,
        2,
        2,
        2,
        5,
        3,
        1,
        1,
        3,
        1,
        11,
        8,
        5,
        5,
        7,
        9,
        17,
        5,
        28,
        3,
        8,
        1,
        1,
        1,
        53
    ],
    "ave_lines_per_cell": 8.311688311688311,
    "ave_lines_per_code_cell": 5.947368421052632,
    "ave_lines_per_markdown_cell": 10.615384615384615,
    "max_lines_per_cell": 53,
    "max_lines_per_code_cell": 23,
    "max_lines_per_markdown_cell": 53,
    "min_lines_per_cell": 1,
    "min_lines_per_code_cell": 1,
    "min_lines_per_markdown_cell": 1,
    "n_chars": 42132,
    "n_chars_code": 8909,
    "n_chars_markdown": 33223,
    "chars_per_cell": [
        448,
        233,
        1811,
        5963,
        658,
        21,
        830,
        375,
        92,
        1878,
        81,
        366,
        24,
        804,
        213,
        311,
        86,
        26,
        80,
        27,
        2523,
        300,
        1223,
        468,
        1297,
        129,
        260,
        240,
        287,
        66,
        201,
        190,
        77,
        78,
        95,
        241,
        528,
        1028,
        453,
        150,
        103,
        141,
        249,
        59,
        417,
        70,
        339,
        249,
        859,
        264,
        967,
        534,
        90,
        610,
        137,
        430,
        412,
        678,
        59,
        1346,
        190,
        451,
        160,
        632,
        28,
        1855,
        403,
        321,
        655,
        464,
        164,
        51,
        210,
        91,
        295,
        66,
        3922
    ],
    "chars_per_code_cell": [
        658,
        21,
        375,
        92,
        81,
        24,
        213,
        86,
        26,
        27,
        300,
        468,
        129,
        240,
        66,
        190,
        78,
        241,
        1028,
        150,
        141,
        59,
        70,
        249,
        264,
        90,
        610,
        137,
        59,
        190,
        160,
        632,
        28,
        403,
        655,
        164,
        210,
        295
    ],
    "chars_per_markdown_cell": [
        448,
        233,
        1811,
        5963,
        830,
        1878,
        366,
        804,
        311,
        80,
        2523,
        1223,
        1297,
        260,
        287,
        201,
        77,
        95,
        528,
        453,
        103,
        249,
        417,
        339,
        859,
        967,
        534,
        430,
        412,
        678,
        1346,
        451,
        1855,
        321,
        464,
        51,
        91,
        66,
        3922
    ],
    "ave_chars_per_line": 65.83125,
    "ave_chars_per_cell": 547.1688311688312,
    "ave_chars_per_code_cell": 234.44736842105263,
    "ave_chars_per_markdown_cell": 851.8717948717949,
    "max_chars_per_cell": 5963,
    "max_chars_per_code_cell": 1028,
    "max_chars_per_markdownell": 5963,
    "min_chars_per_cell": 21,
    "min_chars_per_code_cell": 21,
    "min_chars_per_markdown_cell": 51,
    "r_lines_code": 0.353125,
    "r_lines_markdown": 0.646875,
    "r_chars_markdown": 0.7885455235925187,
    "r_chars_code": 0.21145447640748125,
    "all_cells": [
        {
            "source": "**Introduction:** While this notebook is intended to be beginner-friendly, it won't be feasible to explain every concept in detail to keep it a reasonable size. However, if you have the required prerequisites and basic understanding of Machine Learning, we hope it will be beneficial to you.\n\n**We would also like to express our gratitude to the Kaggle community as a whole for their efforts in making knowledge accessible to everyone. Thank you.**",
            "mc_idx": 0,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Titanic: \"Women and Children First!\" - A beginner-friendly guide to applying Data Science and Machine Learning to the Titanic disaster.\n\n![1920px-Titanic_Starboard_View_1912.gif](attachment:4c681ad5-db7b-4d2b-884c-ed28c68819ef.gif)",
            "mc_idx": 1,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### Table of Contents\n\n* [1. \"Women and children first,\" really? ](#1)\n    * [1.1 Brief Overview of the Sequence of Events.](#1.1)\n    * [1.2 Some Anecdotes and Notable Facts](#1.2)\n    * [1.3 Getting to the Heart of the Matter](#1.3)\n* [2. Exploratory Data Analysis (EDA)](#2)\n    * [2.1 Data Loading and Verification](#2.1)\n        * [2.1.1 Data Dictionary](#2.1.1)\n        * [2.1.2 The pandas.describe Function](#2.1.2)\n        * [2.1.3 The pandas.info Function](#2.1.3)\n    * [2.2 Data Visualization: A picture is worth a thousand words!](#2.2)\n        * [2.2.1 Visualization of the Age and Fare Distributions Using Histograms](#2.2.1)\n        * [2.2.2 Visualization and Analysis of Data Using a \"Swarm\" Plot](#2.2.2)\n        * [2.2.3 Visualization and Analysis of Boarding Data](#2.2.3)\n    * [2.3 A Dash of Feature Engineering](#2.3)\n        * [2.3.1 Family Size](#2.3.1)\n        * [2.3.2 Title and Last Name](#2.3.2)\n        * [2.3.3 Identifying and grouping women and children from the same family](#2.3.3)\n    * [2.4 Back to exploration...](#2.4)\n* [3. Data modeling](#3)\n    * [3.1 Decision tree 'women and children first'](#3.1)    \n* [4. Machine Learning](#4)\n    * [4.1 Feature engineering and data preprocessing.](#4.1)\n        * [4.1.1 creation of the 'isMaster' feature.](#4.1.1)\n        * [4.1.2 Data preprocessing](#4.1.2)\n    * [4.2 XGBoost and GridSearchCV](#4.2)\n        * [4.2.1 Definition of the hyperparameters to test](#4.2.1)\n        * [4.2.2 Definition of the xgb_classifier function](#4.2.2)\n        * [4.2.3 Feature Selection](#4.2.3)\n        * [4.2.4 training](#4.2.4)\n        * [4.2.5 Submitting our predictions to Kaggle and scoring](#4.2.5)\n* [5. Recap and How to Go Further...](#5)\n    * [5.1 How good is your score](#5.1)\n    * [5.2 How to go further?](#5.2)\n        \n        ",
            "mc_idx": 2,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 1.\"Women and children first,\" really? <a class=\"anchor\"  id=\"1\"></a>\n\n\"The women and children first\" principle is a concept that involves prioritizing the rescue of women and children before adult men in the face of a threat. During the 19th and early 20th centuries, ships with a tonnage of less than 10,000 tons did not have enough lifeboats to save all passengers. The idea of saving women and children during a shipwreck became particularly prominent in history during the Titanic disaster in 1912, perhaps the most famous maritime catastrophe of all time.\n\n\"However, according to the 2012 Swedish study titled 'Gender Social Norms and Survival in Maritime Disaster,' the survival rate of women and children is determined to be low. Analyzing 18 major maritime disasters that occurred between 1852 and 2011 and involved over 15,000 individuals from more than 30 different nationalities, the study reveals that the survival rate of the crew and captain surpasses that of the passengers. Men have a survival rate twice that of women, while children's survival rate reaches only 15%. This research posits the Titanic disaster as an exception, one of the few shipwrecks in the modern era where this principle was adhered to.\"\n\n> (en) M. Elinder et O. Erixson, \u00ab Gender, social norms, and survival in maritime disasters \u00bb, Proceedings of the National Academy of Sciences,\u200e 2 mai 2012 https://www.pnas.org/doi/full/10.1073/pnas.1207156109\n\nThe gender gap in survival rates has decreased since World War I, and women are more disadvantaged in British shipwrecks. The study asserts, \"Taken together, our results show that human behavior in life or death situations is better described by the expression 'every man for himself' or 'every person for themselves.'\"\n\nHowever, the study specifies that the Titanic disaster is an exception, and we will explore what the data analysis can tell us. Here, we will solely use the dataset provided by Kaggle as part of the friendly competition themed around the Titanic. We will stick to this dataset and refrain from introducing external structured data to play the game fairly.\n\n# 1.1 Brief Overview of the Sequence of Events. <a class=\"anchor\"  id=\"1.1\"></a>\n\nEven though this shipwreck is well-known, particularly through James Cameron's 1997 film, it seems useful to provide a brief overview of the events.\n\nThe sinking of the Titanic marked the end of the maiden voyage of the RMS Titanic, a ship intended to connect Southampton to New York. The Titanic was equipped with sixteen watertight compartments designed to protect the ship from significant damage. The media portrayed it as a reliable and even \"unsinkable\" vessel. However, contrary to this legend, historians emphasize that it was not considered \"unsinkable\" by its builders.\n\n> Source: Richard Howells, \"The Myth of the Titanic,\" Palgrave Macmillan, 2012.\n\nThe sinking unfolded on the night of April 14 to April 15, 1912, in the North Atlantic Ocean off the coast of Newfoundland. The ship struck an iceberg on the starboard side on Sunday, April 14, 1912, at 11:40 PM and sank in less than three hours, at 2:20 AM. Between 1,490 and 1,520 people perished, making this disaster one of the greatest maritime tragedies of all time.\n\nThe Titanic is a British transatlantic liner of the White Star Line, built at the initiative of Bruce Ismay and designed by the architect Thomas Andrews of the Harland & Wolff shipyards. Its construction began in 1909 in Belfast and was completed in 1912. At the time of its launch, it was the most luxurious and largest ship ever built. Its construction followed that of a nearly identical ship, the Olympic.\n\n# 1.2 Some Anecdotes and Notable Facts. <a class=\"anchor\"  id=\"1.2\"></a>\n\n* The ship did not have a sufficient number of lifeboats, and the crew had never been trained to handle this type of event.\n\n* The stewards then went to the cabins to invite passengers to put on warm clothes and a life jacket, asking them to go to the lifeboat deck. In order to reassure the passengers, the crew assured them that it was just a drill.\n\n* As a result, due to its reputation as unsinkable and the reassuring statements, disbelief prevailed.\n\n* Only a few passengers made their way to the lifeboat deck to board a lifeboat, and the majority did not worry and stayed inside the ship for a long time.\n\n* The first-class passengers were informed first, followed by the second class. The third-class passengers were prevented from accessing the deck until a later hour.\n\n* At 12:25 AM, the order is given to load women and children first into the lifeboats. At the same moment, the orchestra starts playing at the front of the lifeboat deck, following the command of Captain Smith, who aims to prevent any onset of panic.\n\n* Due to continued disbelief, many passengers were reluctant to board the lifeboats.\n\n* Regarding the first lifeboats, the officers on the port side only allowed women and children to board, while on the starboard side, each lifeboat was loaded with women and children first, followed by men. The pragmatism on the starboard side led to launching fully loaded lifeboats and better survivability for men, while on the port side, idealism and strict adherence to orders resulted in lifeboats with many vacant seats. This fact is very interesting, although it may be challenging to utilize with the data provided by Kaggle.\n\n* From 1:15 onwards, water began to flood the bow of the ship, and passengers, who were previously in disbelief, started to come to terms with the reality of the sinking. The evacuation accelerated from this point. Additionally, third-class passengers started arriving in larger numbers on the lifeboat deck.\n\n# 1.3 Getting to the Heart of the Matter <a class=\"anchor\"  id=\"1.3\"></a>\n\nIt's time to get to the heart of the matter, and to start, in the next cell, we will import all the libraries that will be useful to us. For practical reasons, we will centralize all imports here.\n\n\n\n\n\n",
            "mc_idx": 3,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# import\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Modelization\nimport xgboost as xgb\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold, GridSearchCV\n\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.preprocessing import OneHotEncoder",
            "mc_idx": 4,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.03333333333333333,
                "Exploratory_Data_Analysis": 0.025,
                "Data_Transform": 0.05,
                "Model_Train": 0.058333333333333334,
                "Model_Evaluation": 0.041666666666666664,
                "Model_Interpretation": 0.025,
                "Hyperparameter_Tuning": 0.05,
                "Visualization": 0.016666666666666666,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 12
                },
                "Data_Extraction": {
                    "read_csv": 2,
                    "pd.read_": 2
                },
                "Exploratory_Data_Analysis": {
                    "matplotlib": 1,
                    ".mode": 2
                },
                "Data_Transform": {
                    ".join(": 1,
                    "standardscaler": 1,
                    "onehotencoder": 1,
                    ".join": 1,
                    ".mod": 2
                },
                "Model_Train": {
                    "train_test_split": 2,
                    "model": 3,
                    "model_selection": 2
                },
                "Model_Evaluation": {
                    "confusion_matrix": 2,
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "kfold": 1,
                    "train_test_split": 2
                },
                "Visualization": {
                    "matplotlib": 1,
                    "pyplot": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    0,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n"
                    ]
                },
                "mc_idx": 4,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 0,
                "o_idx": 0
            }
        },
        {
            "source": "print(\"hello, world\")",
            "mc_idx": 5,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    1,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "hello, world\n"
                    ]
                },
                "mc_idx": 5,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 1,
                "o_idx": 0
            }
        },
        {
            "source": "# 2. Exploratory Data Analysis (EDA) <a class=\"anchor\"  id=\"2\"></a>\n\nIn summary, exploratory data analysis will help us understand the data patterns, check for integrity, and summarize relevant information for predictive models.\n\n> Exploratory data analysis (EDA) is used by data scientists to analyze and investigate data sets and summarize their main characteristics, often employing data visualization methods. It helps determine how best to manipulate data sources to get the answers you need, making it easier for data scientists to discover patterns, spot anomalies, test a hypothesis, or check assumptions.\n\n> source : https://www.ibm.com/topics/exploratory-data-analysis\n\n# 2.1 Data Loading and Verification <a class=\"anchor\"  id=\"2.1\"></a>\n\nIn this section, we will load the data provided by Kaggle and take a first look.",
            "mc_idx": 6,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Load Data\ntrain = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest = pd.read_csv('/kaggle/input/titanic/test.csv')\n\ngender_submission = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\n# combine All Data\nall_data = pd.concat([train, test], axis=0).reset_index().drop('index', axis=1)",
            "mc_idx": 7,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3076923076923077,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.07692307692307693,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 6,
                    "pd.read_": 6,
                    "load data": 1
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".concat(": 1,
                    ".drop": 1,
                    ".reset_index": 1,
                    ".concat": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    "store": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    2,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 7,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 2,
                "o_idx": 0
            }
        },
        {
            "source": "# Have a look on data\ndisplay(train.head(3))\ndisplay(test.head(3))\ndisplay(all_data.head(3))",
            "mc_idx": 8,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 3,
                    "head": 3,
                    ".head": 3
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    3,
                    2,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  ",
                        "   PassengerId  Pclass                              Name     Sex   Age  SibSp  \\\n0          892       3                  Kelly, Mr. James    male  34.5      0   \n1          893       3  Wilkes, Mrs. James (Ellen Needs)  female  47.0      1   \n2          894       2         Myles, Mr. Thomas Francis    male  62.0      0   \n\n   Parch  Ticket    Fare Cabin Embarked  \n0      0  330911  7.8292   NaN        Q  \n1      0  363272  7.0000   NaN        S  \n2      0  240276  9.6875   NaN        Q  ",
                        "   PassengerId  Survived  Pclass  \\\n0            1       0.0       3   \n1            2       1.0       1   \n2            3       1.0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  "
                    ]
                },
                "mc_idx": 8,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 3,
                "o_idx": 2
            }
        },
        {
            "source": "# 2.1.1 Data Dictionary <a class=\"anchor\"  id=\"2.1.1\"></a>\n\nEstablishing a data dictionary is essential as a reference to interpret the data without ambiguity regarding its meaning. Here is a good definition of what a data dictionary is:\n\n> A Data Dictionary is a collection of names, definitions, and attributes about data elements that are being used or captured in a database, information system, or part of a research project. It describes the meanings and purposes of data elements within the context of a project, and provides guidance on interpretation, accepted meanings and representation. A Data Dictionary also provides metadata about data elements. The metadata included in a Data Dictionary can assist in defining the scope and characteristics of data elements, as well the rules for their usage and application. \n\n> source: https://library.ucmerced.edu/data-dictionaries#:~:text=A%20Data%20Dictionary%20is%20a,part%20of%20a%20research%20project\n\n* **survival:** survival\n    * 0 = No,\n    * 1 = Yes\n* **pclass:** ticket class\n    * 1 = 1st,\n    * 2 = 2nd,\n    * 3 = 3rd\n* **sex:** sex\n* **Age:** age in years\n* **sibsp:** number of siblings / spouses aboard the Titanic\n* **parch:** number of parents / children aboard the Titanic\n* **ticket:** ticket number\n* **fare:** passenger fare\n* **cabin:** cabin number\n* **embarked:** Port of Embarkation\n    * C = Cherbourg,\n    * Q = Queenstown,\n    * S = Southampton\n\n\n\n# 2.1.2 The pandas.describe Function <a class=\"anchor\"  id=\"2.1.2\"></a>   \n\nFirstly, below is a description of the entire dataset using the 'describe' function provided by pandas.\n\n> The pandas.describe function is used to get a descriptive statistics summary of a given dataframe. This includes mean, count, std deviation, percentiles, and min-max values of all the features.\n\n> source : https://www.machinelearningplus.com/pandas/pandas-describe/",
            "mc_idx": 9,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "display(all_data.drop(['PassengerId', 'Survived', 'Pclass'] , axis=1).describe())",
            "mc_idx": 10,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".describe(": 1,
                    "describe": 1,
                    ".describe": 1
                },
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    4,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "               Age        SibSp        Parch         Fare\ncount  1046.000000  1309.000000  1309.000000  1308.000000\nmean     29.881138     0.498854     0.385027    33.295479\nstd      14.413493     1.041658     0.865560    51.758668\nmin       0.170000     0.000000     0.000000     0.000000\n25%      21.000000     0.000000     0.000000     7.895800\n50%      28.000000     0.000000     0.000000    14.454200\n75%      39.000000     1.000000     0.000000    31.275000\nmax      80.000000     8.000000     9.000000   512.329200"
                    ]
                },
                "mc_idx": 10,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 4,
                "o_idx": 0
            }
        },
        {
            "source": "# 2.1.3 The pandas.info Function <a class=\"anchor\"  id=\"2.1.3\"></a>\n\n> The info() method prints information about the DataFrame. The information contains the number of columns, column labels, column data types, memory usage, range index, and the number of cells in each column (non-null values).\n\n> source : https://www.w3schools.com/python/pandas/ref_df_info.asp \n\n",
            "mc_idx": 11,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "display(all_data.info())",
            "mc_idx": 12,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".info(": 1,
                    "info": 1,
                    ".info": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    5,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1309 entries, 0 to 1308\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  1309 non-null   int64  \n 1   Survived     891 non-null    float64\n 2   Pclass       1309 non-null   int64  \n 3   Name         1309 non-null   object \n 4   Sex          1309 non-null   object \n 5   Age          1046 non-null   float64\n 6   SibSp        1309 non-null   int64  \n 7   Parch        1309 non-null   int64  \n 8   Ticket       1309 non-null   object \n 9   Fare         1308 non-null   float64\n 10  Cabin        295 non-null    object \n 11  Embarked     1307 non-null   object \ndtypes: float64(3), int64(4), object(5)\nmemory usage: 122.8+ KB\n",
                        "None"
                    ]
                },
                "mc_idx": 12,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 5,
                "o_idx": 1
            }
        },
        {
            "source": "# 2.2 Data Visualization: A picture is worth a thousand words! <a class=\"anchor\"  id=\"2.2\"></a>\n\nTo start, let's take a quick look at the distribution of age and the \"Fare\" feature. In the next cell, we will build a function to visualize them so that we don't have to repeat code unnecessarily. We will observe these two features on the entire available dataset.\n\n# 2.2.1 Visualization of the Age and Fare Distributions Using Histograms. <a class=\"anchor\"  id=\"2.2.1\"></a>\n\n> A histogram is a statistical graph that represents the distribution of a continuous dataset through plotted bars, each representing a particular category or class interval. The bar height reflects the frequency or count of data points within each group.\n\n> source : https://www.jaspersoft.com/articles/what-is-a-histogram-chart\n",
            "mc_idx": 13,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "def plot_hist(features, data):\n    plt.figure(figsize = (10,4))\n    plt.hist(data[features], bins = 50)\n    plt.xlabel(features)\n    plt.ylabel(\"Frequency\")\n    plt.title(f\"{features} distribution\")\n    plt.show()",
            "mc_idx": 14,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.5,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".hist(": 1,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    ".hist(": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    6,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 14,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 6,
                "o_idx": 0
            }
        },
        {
            "source": "Of course, in observing the age distribution, we are mindful that we have 263 missing values across all data. Here, we won't attempt to fill these gaps using the mean or median, etc., to avoid creating a 'spike' in the graph that doesn't reflect reality. We will, therefore, work with the information we have.\n\n",
            "mc_idx": 15,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "print(\"Number of missing value for Age in all data : \",all_data['Age'].isnull().sum())",
            "mc_idx": 16,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".isnull": 1,
                    ".sum": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    7,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Number of missing value for Age in all data :  263\n"
                    ]
                },
                "mc_idx": 16,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 7,
                "o_idx": 0
            }
        },
        {
            "source": "plot_hist(\"Age\", all_data)",
            "mc_idx": 17,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0026_c008_o000_image_0.png",
                    8,
                    0,
                    0
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1000x400 with 1 Axes>"
                    ]
                },
                "mc_idx": 17,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 8,
                "o_idx": 0
            }
        },
        {
            "source": "Regarding the fares (Fare), unsurprisingly, the lower values are more numerous.\n",
            "mc_idx": 18,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "plot_hist(\"Fare\", all_data)",
            "mc_idx": 19,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0026_c009_o000_image_1.png",
                    9,
                    0,
                    1
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1000x400 with 1 Axes>"
                    ]
                },
                "mc_idx": 19,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 9,
                "o_idx": 0
            }
        },
        {
            "source": "# 2.2.2 Visualization and Analysis of Data Using a \"Swarm\" Plot <a class=\"anchor\"  id=\"2.2.2\"></a>\n\nWe will generate \"swarm\" plot graphs from the training data provided by Kaggle using the code below. These plots involve creating a scatter plot for each category with points adjusted to avoid overlap, providing a better representation of the distribution of values. We will use the \"seaborn\" library built on top of \"matplotlib\". If you want to learn more about this type of plot and how to implement it, I encourage you to consult the documentation.\n\n> https://seaborn.pydata.org/generated/seaborn.swarmplot.html\n\nIn our case, we will place the \"Sex\" category on the x-axis, with \"Age\" on the y-axis, and each point will be colored according to survival, specifically 'Survived'. We will extend this organization by distributing it over three columns representing each class.\n\nThis graph allows us to grasp a lot of information at a glance, and we will draw some initial insights from it. We will refer back to it later as well.\n\nAt first glance, it's evident that the survival rate for women is much higher, especially in the first and second classes, where the vast majority of women survive. However, in the third class, things are more mixed.\n\nFor men, it's a disaster, with still a better chance of survival in the first class. However, men in the second and third classes are literally decimated.\n\nRegarding the number of men and women, we observe that men are much more numerous. This imbalance is primarily due to the presence of a large number of men in the prime of life in the third class, perhaps in search of a better future. The destination being New York, and this city attracting many migrants, the idea of the \"American dream\" is prevalent at this time. In the first and second classes, things are a bit more balanced.\n\nRegarding children, taking into account that there are missing values (since we have the age of only 714 passengers out of 891), there seems to be relatively few children. Could some children be \"hidden\" among the 177 missing values?\n\nChildren seem to have a better survival rate. We can even observe that boys under 12 years old have survived much better than older men. Boys in the first and second classes seem to have all survived according to the data we have. These observations confirm the \"women and children first\" hypothesis, although once again, the chances of survival are more mixed in the third class.\n\nIndeed, there are likely more insights to gain from these graphs.\n\n",
            "mc_idx": 20,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "sns.set_theme(style=\"whitegrid\")\npalette = ['darkslategray', 'goldenrod']\nsns.catplot(data=train,x=\"Sex\",y=\"Age\",hue=\"Survived\",height=5, aspect=2, kind=\"swarm\", palette=palette)\nsns.catplot(data=train, col=\"Pclass\",x = \"Sex\" ,y=\"Age\",hue=\"Survived\",height=5, aspect=1, kind=\"swarm\", palette=palette)",
            "mc_idx": 21,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 3
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 3
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0026_c010_o002_image_3.png",
                    10,
                    2,
                    3
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<seaborn.axisgrid.FacetGrid at 0x7d33e6054790>",
                        "<Figure size 1085.22x500 with 1 Axes>",
                        "<Figure size 1585.22x500 with 3 Axes>"
                    ]
                },
                "mc_idx": 21,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 10,
                "o_idx": 2
            }
        },
        {
            "source": "# 2.2.3 Visualization and Analysis of Boarding Data <a class=\"anchor\"  id=\"2.2.3\"></a>\n\nAt first glance at the graph showing the relationship between the city of embarkation and the probability of survival, we might think there is a useful correlation. However, using the \"strip plot\" graph highlighting embarkations and class, we can explain this by the fact that third-class passengers are much fewer in number. Therefore, it's the survival probability based on class that is significant rather than the city of embarkation.\n\nHere, we will use a bar chart :\n\n> A bar plot or bar chart is a graph that represents the category of data with rectangular bars with lengths and heights that is proportional to the values which they represent. The bar plots can be plotted horizontally or vertically.\n\n> source : https://www.geeksforgeeks.org/bar-plot-in-matplotlib/\n\nAnd a 'strip plot' graph :\n\n> It is basically a scatter plot that differentiates different categories. So, all the data that corresponds to each category is shown as a scatter plot, and all the observations and collected data that are visualized are shown, side-by-side on a single graph.\n\n> source : https://www.educative.io/answers/what-is-seabornstripplot\n\n",
            "mc_idx": 22,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "def cat_plot(feature_x, feature_y, data, label, kind = \"bar\"):\n    g = sns.catplot(x = feature_x, y = feature_y, data = data, kind = kind)\n    g.set_ylabels(label)\n    plt.show()\n    return g\n\ncat_plot(\"Embarked\", \"Survived\", train, \"Survived Probability\")\n\npalette_2 = [\"#3A0CA3\", \"#4361EE\", \"#4CC9F0\"]\nsns.stripplot(data=train.dropna(subset = ['Embarked']), x=\"Age\", y=\"Embarked\", hue=\"Pclass\", dodge=\"true\", size=2.7, palette = list(reversed(palette_2)))\nplt.show()",
            "mc_idx": 23,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.6666666666666666,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.6666666666666666,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 2
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 2,
                    "size": 1
                },
                "Data_Transform": {
                    ".dropna(": 1,
                    ".drop": 1,
                    ".dropna": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0026_c011_o001_image_5.png",
                    11,
                    1,
                    5
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 500x500 with 1 Axes>",
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 23,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 11,
                "o_idx": 1
            }
        },
        {
            "source": "# 2.3 A Dash of Feature Engineering <a class=\"anchor\"  id=\"2.3\"></a>\n\nBefore delving further into data exploration, we will create new features from the existing ones that will be necessary for a better understanding of the context, making them more usable.\n\n> Feature engineering is the process of selecting, manipulating, and transforming raw data into features that can be used in supervised learning. In order to make machine learning work well on new tasks, it might be necessary to design and train better features.\n\n> source : https://towardsdatascience.com/what-is-feature-engineering-importance-tools-and-techniques-for-machine-learning-2080b0269f10\n\nWe will just initiate this process at this early stage to facilitate data exploration, but we will revisit it later to prepare the data for machine learning model usage.\n\n# 2.3.1 Family Size <a class=\"anchor\"  id=\"2.3.1\"></a>\n\nHere, we will create the \"family_size\" feature since the two features:\n\n* sibsp: the number of siblings, spouses aboard the Titanic.\n* parch: the number of parents and children aboard the Titanic.\n\nWhile they provide a better understanding of family composition, they do not immediately capture the total. Therefore, we will add these two features together to obtain the total size of an individual's family.\n\n",
            "mc_idx": 24,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# craft new features \"Family Size\" \nall_data[\"FamilySize\"] = 1 + all_data[\"SibSp\"] + all_data[\"Parch\"]\ndisplay(all_data.head(3))\n",
            "mc_idx": 25,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    "size": 2,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    12,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived  Pclass  \\\n0            1       0.0       3   \n1            2       1.0       1   \n2            3       1.0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  FamilySize  \n0      0         A/5 21171   7.2500   NaN        S           2  \n1      0          PC 17599  71.2833   C85        C           2  \n2      0  STON/O2. 3101282   7.9250   NaN        S           1  "
                    ]
                },
                "mc_idx": 25,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 12,
                "o_idx": 0
            }
        },
        {
            "source": "# 2.3.2 Title and Last Name <a class=\"anchor\"  id=\"2.3.2\"></a>\n\nStill, for a better understanding of the family, we will process the 'Name' feature to extract the last name. At the same time, we will extract the title, which can provide valuable information.\n\n",
            "mc_idx": 26,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# craft 2 features 'Surname' and 'Title'\nall_data['Surname'] = all_data['Name'].apply(lambda x: x.split(',')[0]) \nall_data['Title'] = all_data['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0]) \ndisplay(all_data.head(3))",
            "mc_idx": 27,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".apply(": 3,
                    ".split": 3,
                    ".apply": 3
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    13,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived  Pclass  \\\n0            1       0.0       3   \n1            2       1.0       1   \n2            3       1.0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  FamilySize    Surname  \\\n0      0         A/5 21171   7.2500   NaN        S           2     Braund   \n1      0          PC 17599  71.2833   C85        C           2    Cumings   \n2      0  STON/O2. 3101282   7.9250   NaN        S           1  Heikkinen   \n\n   Title  \n0    Mr.  \n1   Mrs.  \n2  Miss.  "
                    ]
                },
                "mc_idx": 27,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 13,
                "o_idx": 0
            }
        },
        {
            "source": "\nAfter some research to understand the meaning of these different titles, one thing seems very interesting: the significance of the title \"Master,\" which was used at that time to designate boys too young to be called \"Mister.\" This might help us identify boys whose age is not specified.",
            "mc_idx": 28,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "sns.countplot(y=\"Title\", data = all_data, orient = 'v')\nplt.show()",
            "mc_idx": 29,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0026_c014_o000_image_6.png",
                    14,
                    0,
                    6
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 29,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 14,
                "o_idx": 0
            }
        },
        {
            "source": "The script, while effective in the vast majority of cases in extracting the title from the name, made an error by assigning 'the' instead of 'Countess.' for passenger 760. We correct this error below.\n",
            "mc_idx": 30,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "display(all_data[all_data.Title=='the'])\n#Correcting the Title for passenger 760\nall_data.loc[(all_data.PassengerId==760), 'Title'] = 'Countess.'\ndisplay(all_data[all_data.PassengerId==760])",
            "mc_idx": 31,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    15,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "     PassengerId  Survived  Pclass  \\\n759          760       1.0       1   \n\n                                                  Name     Sex   Age  SibSp  \\\n759  Rothes, the Countess. of (Lucy Noel Martha Dye...  female  33.0      0   \n\n     Parch  Ticket  Fare Cabin Embarked  FamilySize Surname Title  \n759      0  110152  86.5   B77        S           1  Rothes   the  ",
                        "     PassengerId  Survived  Pclass  \\\n759          760       1.0       1   \n\n                                                  Name     Sex   Age  SibSp  \\\n759  Rothes, the Countess. of (Lucy Noel Martha Dye...  female  33.0      0   \n\n     Parch  Ticket  Fare Cabin Embarked  FamilySize Surname      Title  \n759      0  110152  86.5   B77        S           1  Rothes  Countess.  "
                    ]
                },
                "mc_idx": 31,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 15,
                "o_idx": 1
            }
        },
        {
            "source": "Indeed, several boys with the title \"Master\" did not have the age specified!\n",
            "mc_idx": 32,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "display(all_data.loc[(all_data.Title == 'Master.') & (all_data.Age.isnull())])",
            "mc_idx": 33,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".isnull": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    16,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "      PassengerId  Survived  Pclass  \\\n65             66       1.0       3   \n159           160       0.0       3   \n176           177       0.0       3   \n709           710       1.0       3   \n1135         1136       NaN       3   \n1230         1231       NaN       3   \n1235         1236       NaN       3   \n1308         1309       NaN       3   \n\n                                                   Name   Sex  Age  SibSp  \\\n65                             Moubarek, Master. Gerios  male  NaN      1   \n159                          Sage, Master. Thomas Henry  male  NaN      8   \n176                       Lefebre, Master. Henry Forbes  male  NaN      3   \n709   Moubarek, Master. Halim Gonios (\"William George\")  male  NaN      1   \n1135          Johnston, Master. William Arthur Willie\"\"  male  NaN      1   \n1230                              Betros, Master. Seman  male  NaN      0   \n1235                van Billiard, Master. James William  male  NaN      1   \n1308                           Peter, Master. Michael J  male  NaN      1   \n\n      Parch      Ticket     Fare Cabin Embarked  FamilySize       Surname  \\\n65        1        2661  15.2458   NaN        C           3      Moubarek   \n159       2    CA. 2343  69.5500   NaN        S          11          Sage   \n176       1        4133  25.4667   NaN        S           5       Lefebre   \n709       1        2661  15.2458   NaN        C           3      Moubarek   \n1135      2  W./C. 6607  23.4500   NaN        S           4      Johnston   \n1230      0        2622   7.2292   NaN        C           1        Betros   \n1235      1    A/5. 851  14.5000   NaN        S           3  van Billiard   \n1308      1        2668  22.3583   NaN        C           3         Peter   \n\n        Title  \n65    Master.  \n159   Master.  \n176   Master.  \n709   Master.  \n1135  Master.  \n1230  Master.  \n1235  Master.  \n1308  Master.  "
                    ]
                },
                "mc_idx": 33,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 16,
                "o_idx": 0
            }
        },
        {
            "source": "All boys under 12 have the title \"Master,\" except passenger 732. Let's correct that quickly...\n",
            "mc_idx": 34,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "all_data.loc[(all_data.Age < 12) & (all_data.Sex == 'male') & (all_data.Title != 'Master.')]\n#Correcting the Title for passenger 760\nall_data.loc[(all_data.PassengerId==732), 'Title'] = 'Master.'\ndisplay(all_data[all_data.PassengerId==732])\n",
            "mc_idx": 35,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    17,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "     PassengerId  Survived  Pclass                      Name   Sex   Age  \\\n731          732       0.0       3  Hassan, Mr. Houssein G N  male  11.0   \n\n     SibSp  Parch Ticket     Fare Cabin Embarked  FamilySize Surname    Title  \n731      0      0   2699  18.7875   NaN        C           1  Hassan  Master.  "
                    ]
                },
                "mc_idx": 35,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 17,
                "o_idx": 0
            }
        },
        {
            "source": "# 2.3.3 Identifying and grouping women and children from the same family <a class=\"anchor\"  id=\"2.3.3\"></a>\n\nHere, we will create new features that seem essential to capture the reality by grouping women and children from the same family.\n\nWe will define the 'WomenChild' feature as the membership in a group of women accompanied by children from the same family. Then, with the 'WomenChildNameSurvival' feature, we will assign a survival rate based on the training data for each of these families containing women and children.",
            "mc_idx": 36,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Craft a dictionnary of surname for the women & children group \nwomen_child = all_data.loc[(all_data.Sex == 'female') | (all_data.Title == 'Master.')]\nwomen_child_surname_dic = women_child.groupby('Surname')['PassengerId'].count().to_dict()\n\n# craft a new feature 'WomenChildNameFreq' by mapping Surname to the dictionary\nall_data.loc[(all_data.Sex == 'female') | (all_data.Title == 'Master.'), 'WomenChildNameFreq'] = all_data.Surname.map(women_child_surname_dic) \n\n# Craft a feature 'woman_child' for grouping woman and child... 1 for true if a passenger belong to this group \nall_data.loc[(all_data.WomenChildNameFreq>1), 'WomenChild'] = 1\n\n# with the train data only, craft a dictionnary with an indice of survival\nonly_train = all_data[0:891]\nwomen_child_survivor_dic = only_train[(only_train.WomenChild==1)].groupby('Surname')['Survived'].mean().to_dict()\n\n# craft a new feature 'women_child_surname_survival'\nall_data.loc[(all_data.WomenChild==1), 'WomenChildNameSurvival']=all_data.Surname.map(women_child_survivor_dic)",
            "mc_idx": 37,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.6666666666666666,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.6666666666666666,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1,
                    ".groupby": 2
                },
                "Data_Transform": {
                    ".groupby(": 2,
                    ".map(": 2,
                    ".map": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    "to_dict": 2,
                    ".to_dict": 2
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    18,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 37,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 18,
                "o_idx": 0
            }
        },
        {
            "source": "An important point to note here is that if we observe the survival rate of women and children groups based on the last name, according to the training data, 66 families from the 'women and children' group survived entirely, 22 families perished entirely, and only 4 families had a mixed outcome.\n\nThis leads us to believe that it is indeed wise to group women and children by family, and these families tend to either all survive or all perish together.",
            "mc_idx": 38,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "dic_value = list(women_child_survivor_dic.values())\nprint(dic_value.count(0))\nprint(dic_value.count(1))\nprint(sum(1 for i in dic_value if 0 < i < 1 ))",
            "mc_idx": 39,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    19,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "22\n66\n4\n"
                    ]
                },
                "mc_idx": 39,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 19,
                "o_idx": 0
            }
        },
        {
            "source": "And this phenomenon is especially noticeable for the third class, as we can see in the following graph.",
            "mc_idx": 40,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "sns.catplot(data=only_train[only_train.WomenChild == 1], x=\"Pclass\",y=\"Age\",hue=\"Survived\",height=5, aspect=2, kind=\"swarm\", palette=palette)",
            "mc_idx": 41,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0026_c020_o001_image_7.png",
                    20,
                    1,
                    7
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<seaborn.axisgrid.FacetGrid at 0x7d33e6157be0>",
                        "<Figure size 1085.22x500 with 1 Axes>"
                    ]
                },
                "mc_idx": 41,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 20,
                "o_idx": 1
            }
        },
        {
            "source": "Before continuing, since we made these changes to all_data, the original train and test data do not have the new features. To preserve the original data if needed, we will create new dataframes, only_train and only_test, containing the new features.",
            "mc_idx": 42,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "only_train = all_data[0:891]\nonly_test = all_data[891:1309]",
            "mc_idx": 43,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    21,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 43,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 21,
                "o_idx": 0
            }
        },
        {
            "source": "# 2.4 Back to exploration... <a class=\"anchor\"  id=\"2.4\"></a>\n\nWe observe that family size seems to correlate with better survival, although for families with more than 4 members, the margin of error is too large to draw conclusions. As a hypothesis, following the \"women and children first\" principle, we can suggest that men traveling alone contribute to the drop in the survival rate of passengers traveling alone.",
            "mc_idx": 44,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "cat_plot(\"FamilySize\", \"Survived\", only_train, \"Survived Probability\")",
            "mc_idx": 45,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    22,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 500x500 with 1 Axes>",
                        "<seaborn.axisgrid.FacetGrid at 0x7d34302c7700>"
                    ]
                },
                "mc_idx": 45,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 22,
                "o_idx": 1
            }
        },
        {
            "source": "Through this 'swarmplot' chart below, correlating survival, age, and family size for each passenger, we also observe that children from larger families in the third class appear to have a significantly lower survival rate. (However, as mentioned earlier, the data for large families is limited, resulting in a significant margin of error.)",
            "mc_idx": 46,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "sns.swarmplot(data=only_train, x=\"Survived\", y=\"Age\", hue=\"FamilySize\", size=3.5, legend='full', palette='Spectral')\nsns.catplot(data=only_train, kind=\"swarm\", x=\"Survived\", y=\"Age\", hue=\"FamilySize\", legend='full', col=\"Pclass\", palette='Spectral')",
            "mc_idx": 47,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.4,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 2,
                    "size": 3
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0026_c023_o002_image_10.png",
                    23,
                    2,
                    10
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<seaborn.axisgrid.FacetGrid at 0x7d33e60c66e0>",
                        "<Figure size 640x480 with 1 Axes>",
                        "<Figure size 1599.85x500 with 3 Axes>"
                    ]
                },
                "mc_idx": 47,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 23,
                "o_idx": 2
            }
        },
        {
            "source": "# 3. Data modeling <a class=\"anchor\"  id=\"3\"></a>\n\nIn the files provided by Kaggle, aside from the training and test data, there is a 'gender_submission' file that represents the predictions of a very simple model: all women survive, all men die.\n\nBy providing this file, Kaggle is clearly inviting us to try this model. That's what we'll do in the next cell.\n\nNote that this model does not use machine learning but a very simple and rudimentary decision tree: \"if it's a woman, then survive; if it's a man, then not.\"\n\n> A decision tree is a decision support hierarchical model that uses a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements.\n\n> source : https://en.wikipedia.org/wiki/Decision_tree",
            "mc_idx": 48,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Have a look on gender_submission and output for submission\ndisplay(gender_submission.head(3))\n\n# and save the output formated for submission\ngender_submission.to_csv('gender_submission.csv', index=False)\n\n# And submit ... \n# score for gender_submission = 0.76555",
            "mc_idx": 49,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "save": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    24,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived\n0          892         0\n1          893         1\n2          894         0"
                    ]
                },
                "mc_idx": 49,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 24,
                "o_idx": 0
            }
        },
        {
            "source": "Despite its simplicity, this model manages to capture a significant part of reality with a score of 0.76555! So, we will continue to model manually, i.e., without machine learning, to see if we can beat this score, which will serve as a reference to assess the relevance of our subsequent models.\n\nWe will check our basic assumption, \"women and children first,\" by building another model that predicts only women and children survive, and no men.\n\nAs we saw during the data exploration, there are many missing ages. While this is not a problem for girls, who will be included in the model among the surviving women, it's a different story for boys. Relying solely on gender and age, we will likely miss some boys.\n\n\nFortunately, during the data exploration, we determined that the title \"Master\" allows us to identify boys with certainty. We will use this feature. Also, it seems that children in the third class have less chance of survival if their family is large.",
            "mc_idx": 50,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 3.1 Decision tree \"women and children first.\" <a class=\"anchor\"  id=\"3.1\"></a>\n\nLet's see if we can improve this score by testing our basic hypothesis, 'women and children first,' adjusted by the observation that children from large families in the third class seem to have much lower chances of survival.\n\nHere is our decision tree: \"if it's a man, then no-survival; if it's a woman, then survival; if it's a boy from the first and second class, then survival; if it's a boy from the third class and a small family, then survival.\"",
            "mc_idx": 51,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "test_women_child = only_test\ntest_women_child = test_women_child.drop('Survived', axis=1) ",
            "mc_idx": 52,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    25,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 52,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 25,
                "o_idx": 0
            }
        },
        {
            "source": "# Gender Model\ntest_women_child.loc[(test_women_child.Sex == 'female' ), 'Survived'] = 1\ntest_women_child.loc[(test_women_child.Sex == 'male'), 'Survived'] = 0\n\n# Children \ntest_women_child.loc[(test_women_child.Title == 'Master.') & (test_women_child.Pclass == 1), 'Survived'] = 1\ntest_women_child.loc[(test_women_child.Title == 'Master.') & (test_women_child.Pclass == 2), 'Survived'] = 1\n\ntest_women_child.loc[(test_women_child.Title == 'Master.') & (test_women_child.Pclass == 3) & (test_women_child.FamilySize < 3) , 'Survived'] = 1\n\ntest_women_child['Survived'] = test_women_child['Survived'].astype(int)",
            "mc_idx": 53,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    26,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 53,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 26,
                "o_idx": 0
            }
        },
        {
            "source": "submission = test_women_child[['PassengerId', 'Survived']]\nsubmission.to_csv('women_child_model.csv', index=False)\n#Score : 0.77751 !!!! ",
            "mc_idx": 54,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.5,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    27,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 54,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 27,
                "o_idx": 0
            }
        },
        {
            "source": "Score : 0.77751\n\nWe have already significantly improved the score. However, we have not yet used some of our observations, such as the possibility of grouping women and children by family, and that these families tend to survive or not survive together, etc.\n\nEven though it is still possible to create a decision tree manually, things are starting to get more complex. It seems that now is the time to turn to 'machine learning.'",
            "mc_idx": 55,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 4. Machine Learning <a class=\"anchor\"  id=\"4\"></a>\n\nAlthough this concept is probably already familiar to you, here is a definition of Machine Learning :\n\n> The use and development of computer systems capable of learning and adapting without following explicit instructions, using algorithms and statistical models to analyze and draw conclusions from patterns in data.\n\n> source : https://www.oed.com/?tl=true",
            "mc_idx": 56,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 4.1 Feature engineering and data preprocessing. <a class=\"anchor\"  id=\"4.1\"></a>\n\n\"We have already encountered the concept of feature engineering in this notebook.\n\nData preprocessing refers to the preliminary processing steps performed on the data before using it in an analysis or model. Preprocessing may include activities such as data cleaning, normalization, dimensionality reduction, etc.\"\n\n# 4.1.1 creation of the 'isMaster' feature. <a class=\"anchor\"  id=\"4.1.1\"></a>\n\nHere we are going to create the 'isMaster' feature, as, as we have seen, the title 'Master' is much more reliable for identifying boys than gender and age, due to many missing values concerning age.",
            "mc_idx": 57,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "all_data.loc[(all_data.Title == 'Master.'), 'isMaster'] = 1",
            "mc_idx": 58,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    28,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 58,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 28,
                "o_idx": 0
            }
        },
        {
            "source": "# 4.1.2 Data preprocessing. <a class=\"anchor\"  id=\"4.1.2\"></a>\n\nWe will first set aside the features that we will not use for this instance: 'PassengerId', 'Name', 'Ticket', 'Cabin', 'Surname', 'Title', 'Embarked'.\"We will first set aside the features that we will not use for this instance: 'PassengerId', 'Name', 'Ticket', 'Cabin', 'Surname', 'Title', 'Embarked'.\"\n\n* 'PassengerId': This unique identifier is not useful for the model's learning.\n\n* 'Name': The unique name of each passenger neither.\n\n* 'Ticket': We set it aside for now because, at the outset, we consider the class to be a more significant feature.\n\n* Cabin': Many missing values; here too, we currently consider this feature as redundant since, indeed, only passengers in the first and second class have a cabin, indicating a higher socio-economic status, which is already captured by the 'Pclass' feature.\n\n* 'Surname': This feature allowed us to group women and children from the same family, but for now, it is not useful.\n\n* 'Title': This feature allowed us to identify boys reliably with the title 'Master', and we have created the 'isMaster' feature for that purpose, which we will use.\n\n* 'Embarked': We observed that the embarkation city alone is not really useful for determining a chance of survival, but rather the proportion of each class at embarkation matters.\"",
            "mc_idx": 59,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "dropped_features = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'Surname', 'Title', 'Embarked']\n\nall_data_machine = all_data.drop(dropped_features, axis = 1)\n\ndisplay(all_data_machine.head(3))",
            "mc_idx": 60,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    29,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare  FamilySize  \\\n0       0.0       3    male  22.0      1      0   7.2500           2   \n1       1.0       1  female  38.0      1      0  71.2833           2   \n2       1.0       3  female  26.0      0      0   7.9250           1   \n\n   WomenChildNameFreq  WomenChild  WomenChildNameSurvival  isMaster  \n0                 NaN         NaN                     NaN       NaN  \n1                 1.0         NaN                     NaN       NaN  \n2                 1.0         NaN                     NaN       NaN  "
                    ]
                },
                "mc_idx": 60,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 29,
                "o_idx": 0
            }
        },
        {
            "source": "Only the 'Sex' feature is a categorical variable. We will now encode it with OneHotEncoder\n\n> One-hot encoding is the process by which categorical data are converted into numerical data for use in machine learning. Categorical features are turned into binary features that are \u201cone-hot\u201d encoded, meaning that if a feature is represented by that column, it receives a 1. Otherwise, it receives a 0.\n\n> source : https://datagy.io/sklearn-one-hot-encode/",
            "mc_idx": 61,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Get list of categorical variables\ns = (all_data_machine.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols)",
            "mc_idx": 62,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 2
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "dtypes": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    30,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Categorical variables:\n['Sex']\n"
                    ]
                },
                "mc_idx": 62,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 30,
                "o_idx": 0
            }
        },
        {
            "source": "# Apply one-hot encoder to each column with categorical data\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_all_data = pd.DataFrame(OH_encoder.fit_transform(all_data_machine[object_cols]))\n\n# One-hot encoding removed index; put it back\nOH_all_data.index = all_data_machine.index\n\n# Remove categorical columns (will replace with one-hot encoding)\nnum_all_data = all_data_machine.drop(object_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nOH_all_data = pd.concat([num_all_data, OH_all_data], axis=1)\n\n# Ensure all columns have string type\nOH_all_data.columns = OH_all_data.columns.astype(str)",
            "mc_idx": 63,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.7142857142857143,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 5
                },
                "Data_Transform": {
                    ".concat(": 1,
                    "fit_transform": 1,
                    "transform": 1,
                    ".astype(": 1,
                    "onehotencoder": 1,
                    ".drop": 1,
                    ".concat": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    31,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n"
                    ]
                },
                "mc_idx": 63,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 31,
                "o_idx": 0
            }
        },
        {
            "source": "display(OH_all_data.head(3))",
            "mc_idx": 64,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    32,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   Survived  Pclass   Age  SibSp  Parch     Fare  FamilySize  \\\n0       0.0       3  22.0      1      0   7.2500           2   \n1       1.0       1  38.0      1      0  71.2833           2   \n2       1.0       3  26.0      0      0   7.9250           1   \n\n   WomenChildNameFreq  WomenChild  WomenChildNameSurvival  isMaster    0    1  \n0                 NaN         NaN                     NaN       NaN  0.0  1.0  \n1                 1.0         NaN                     NaN       NaN  1.0  0.0  \n2                 1.0         NaN                     NaN       NaN  1.0  0.0  "
                    ]
                },
                "mc_idx": 64,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 32,
                "o_idx": 0
            }
        },
        {
            "source": "# 4.2 XGBoost and GridSearchCV <a class=\"anchor\"  id=\"4.2\"></a>\n\nHere we will use XGBoost.\n\n> XGBoost, which stands for Extreme Gradient Boosting, is a scalable, distributed gradient-boosted decision tree (GBDT) machine learning library. It provides parallel tree boosting and is the leading machine learning library for regression, classification, and ranking problems.\n\n> source : https://www.nvidia.com/en-us/glossary/data-science/xgboost/\n\nWhat is 'gradient boosting'?\n\n> Gradient boosting is a machine learning technique used in regression and classification tasks, among others. It gives a prediction model in the form of an ensemble of weak prediction models, i.e., models that make very few assumptions about the data, which are typically simple decision trees.\n\n> source : https://en.wikipedia.org/wiki/Gradient_boosting\n\nWe will therefore use this algorithm using the 'GridSearchCV' technique.\n\n> GridSearchCV is the process of performing hyperparameter tuning in order to determine the optimal values for a given model. As mentioned above, the performance of a model significantly depends on the value of hyperparameters. Note that there is no way to know in advance the best values for hyperparameters so ideally, we need to try all possible values to know the optimal values. Doing this manually could take a considerable amount of time and resources and thus we use GridSearchCV to automate the tuning of hyperparameters.\n\n> source : https://www.mygreatlearning.com/blog/gridsearchcv/\n\nFinally, we will take advantage of a very interesting feature of XGBoost.\n\n> XGBoost supports missing values by default. In tree algorithms, branch directions for missing values are learned during training.\n\n> source : https://xgboost.readthedocs.io/en/stable/faq.html\n\n\n# 4.2.1 Definition of the hyperparameters to test <a class=\"anchor\"  id=\"4.2.1\"></a>",
            "mc_idx": 65,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "params = {\n 'learning_rate': [0.01, 0.05, 0.07, 0.1],\n 'subsample': [1],\n 'colsample_bylevel': [1],\n 'colsample_bynode': [1],\n 'colsample_bytree': [0.5],\n 'gamma': [0, 1, 2],\n 'max_delta_step': [0],\n 'max_depth': [2, 3, 4, 5],\n 'min_child_weight': [1.6],\n 'n_estimators': [70, 80, 90, 100], \n 'random_state': [42],\n 'scale_pos_weight': [1],\n 'seed': [42],\n 'n_jobs': [-1],\n 'reg_lambda': [1, 2, 4, 16]\n}",
            "mc_idx": 66,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    33,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 66,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 33,
                "o_idx": 0
            }
        },
        {
            "source": "# 4.2.2 Definition of the xgb_classifier function <a class=\"anchor\"  id=\"4.2.2\"></a>\n\nAlthough for this specific public notebook, we will not perform multiple tests, it is however considered good practice to gather all instructions within a function so that this function can be reused at will during various experiments.",
            "mc_idx": 67,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "def xgb_classifier(data, target, params):\n      \n    # Create X and y\n    X = data.drop(target, axis=1)\n    y = data[target]\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X)\n    X_scaled = scaler.transform(X)\n    \n    # Create a XGBoost classifier (scikit-learn API wrapper)\n    xgb_clf = XGBClassifier()\n    \n    # Perform a gridsearch with sklearn\n    kf = KFold(n_splits=10, random_state=42, shuffle=True)\n    gridsearch = GridSearchCV(xgb_clf, param_grid=params, scoring=\"accuracy\", cv=kf, return_train_score=True)\n    gridsearch.fit(X_scaled, y)\n    \n    # Return the gridsearch results plus the scaler\n    return gridsearch, scaler",
            "mc_idx": 68,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.375,
                "Model_Train": 0.25,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "transform": 1,
                    "standardscaler": 1,
                    ".drop": 1
                },
                "Model_Train": {
                    ".fit(": 2
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "param_grid": 1,
                    "param": 3,
                    "kfold": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    34,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 68,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 34,
                "o_idx": 0
            }
        },
        {
            "source": "# 4.2.3 Feature Selection <a class=\"anchor\"  id=\"4.2.3\"></a>\n\nWe will discard some features:\n\n* 'Age': too many missing values, we exclude it for this experiment...\n* 'SibSp' and 'Parch': redundant with FamilySize\n* 'Fare': we exclude it for this experiment as we consider that the class is sufficient\n* 'WomenChildNameFreq': this feature would have been useful for grouping women and children from the same family, but it does not seem useful for this experiment.",
            "mc_idx": 69,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "dropped_features = ['Age', 'SibSp', 'Parch', 'Fare', 'WomenChildNameFreq']\n\ndata_for_XG = OH_all_data.drop(dropped_features, axis = 1)\ndisplay(data_for_XG.head(3)) ",
            "mc_idx": 70,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    35,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   Survived  Pclass  FamilySize  WomenChild  WomenChildNameSurvival  isMaster  \\\n0       0.0       3           2         NaN                     NaN       NaN   \n1       1.0       1           2         NaN                     NaN       NaN   \n2       1.0       3           1         NaN                     NaN       NaN   \n\n     0    1  \n0  0.0  1.0  \n1  1.0  0.0  \n2  1.0  0.0  "
                    ]
                },
                "mc_idx": 70,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 35,
                "o_idx": 0
            }
        },
        {
            "source": "# 4.2.4 training <a class=\"anchor\"  id=\"4.2.4\"></a>",
            "mc_idx": 71,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\ntrain_XG = data_for_XG[0:891]\n\ntest_XG = data_for_XG[891:1309]\ntest_XG = test_XG.drop('Survived', axis = 1)\n\ngridsearch, scaler = xgb_classifier(train_XG, \"Survived\", params)\n\ndisplay(gridsearch.best_params_)\n",
            "mc_idx": 72,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    36,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "{'colsample_bylevel': 1,\n 'colsample_bynode': 1,\n 'colsample_bytree': 0.5,\n 'gamma': 0,\n 'learning_rate': 0.01,\n 'max_delta_step': 0,\n 'max_depth': 3,\n 'min_child_weight': 1.6,\n 'n_estimators': 80,\n 'n_jobs': -1,\n 'random_state': 42,\n 'reg_lambda': 4,\n 'scale_pos_weight': 1,\n 'seed': 42,\n 'subsample': 1}"
                    ]
                },
                "mc_idx": 72,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 36,
                "o_idx": 0
            }
        },
        {
            "source": "# 4.2.5 Submitting our predictions to Kaggle and scoring <a class=\"anchor\"  id=\"4.2.5\"></a>",
            "mc_idx": 73,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\ntest_XG_scaled = scaler.transform(test_XG)\n\npredictions = gridsearch.predict(test_XG_scaled)\n\noutput = pd.DataFrame({'PassengerId': PassengerId, 'Survived': predictions})\noutput.to_csv('gridsearch_xgboost.csv', index=False)\nprint(\"Your submission was successfully saved!\") \n\n### Score : 0.80382",
            "mc_idx": 74,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "transform": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "save": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    37,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Your submission was successfully saved!\n"
                    ]
                },
                "mc_idx": 74,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 37,
                "o_idx": 0
            }
        },
        {
            "source": "# 5. Recap and How to Go Further... <a class=\"anchor\"  id=\"5\"></a>",
            "mc_idx": 75,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 5.1 How good is your score  <a class=\"anchor\"  id=\"5.1\"></a>\n\nIt is well known that cheating is very prevalent in this friendly competition, for the simple reason that the complete data regarding the Titanic is public, and we already know the fate of each passenger. The only way to learn something from this challenge is to play the game honestly. As Carl McBride Ellis emphasizes in this notebook : \n\n> https://www.kaggle.com/code/carlmcbrideellis/titanic-leaderboard-a-score-0-8-is-great\n\nSo the only way to get a good way to evaluate your own score is to compare it with public notebooks that explain the entire method used to obtain a score in a transparent manner.\n\nHowever, be careful, the scoring system on the Titanic friendly competition has evolved over time, which changes the score of a notebook depending on whether it was submitted before or after this update, as explained here:\n\n> The first update (which many of you may already be aware of) is that the leaderboard scores are not permanent, and the scores will be removed after 2 months. The second update is that the calculation of the final score - which was previously performed on a percentage of the test data - has now changed. Scores are calculated on the entire test data. Now, ideally, this should not have changed the scoring model or changed it very little, on the order of a fraction of a percentage. But did you know that the scoring model is now such that you get a score between 1 and 3% LOWER than what could have been achieved previously!\n\nand to continue :\n\n> Scores of 79% and above are GOOD: Previously, 80% was considered very good. According to the new scoring model, this is equivalent to a score of about 79% and above. So, anything above that is a GOOD performance. Don't be disappointed if you don't reach 80%, which, according to the previous scoring model, was a benchmark score.\n\n> https://www.kaggle.com/competitions/titanic/discussion/177265\n\n# 5.2  How to go further? <a class=\"anchor\"  id=\"5.2\"></a>\n\nI recommend first reading this notebook where OSCAR TAKESHITA has done an excellent job of inventorying all possible approaches as well as raising questions about paths to explore\n\n> https://www.kaggle.com/code/pliptor/how-am-i-doing-with-my-score\n\nThen you will find here the notebooks with well-documented methods and providing the best scores, both in Python and R. I want to thank especially the authors for generously sharing their knowledge and expertise.\n\n(beware that the scores indicated are those before the update of the scoring system explained above)\n\n* Divide and Conquer \n> https://www.kaggle.com/code/pliptor/divide-and-conquer-0-82296/report\n    * Score : 0.82296\n* Lasso Ridge by Bisaria\n> https://www.kaggle.com/code/bisaria/titanic-lasso-ridge-implementation/report\n    * Score : 0.82296\n* Titanic using Name only Chris Deotte achieves this great score using nothing but the Name feature! (Note from his kernel: 0.81818 with Name only and 0.82296 by adding Ticket).\n> https://www.kaggle.com/code/cdeotte/titanic-using-name-only-0-81818/notebook\n    * Score : 0.82296\n* Titanic Deep Net by Chris Deotte\n> https://www.kaggle.com/code/cdeotte/titanic-deep-net-0-82296/notebook\n    * Score : 0.82296\n* Konstantin brings attention to feature scaling, which is essential when working with the kNN algorithm.\n> https://www.kaggle.com/code/konstantinmasich/titanic-0-82-0-83/notebook\n    * Score : 0.83253\n* Titanic Mega Model Chris Deotte ensembles Kaggle\u2019s top 6 models. It starts with a neat ensembling diagram.\n> https://www.kaggle.com/code/cdeotte/titantic-mega-model-0-84210/notebook\n    * Score : 0.84210\n* Titanic WCG+XGBoost Chris Deotte Is this the ultimate Titanic model?\n> https://www.kaggle.com/code/cdeotte/titanic-wcg-xgboost-0-84688/notebook\n    * Score : 0.84688  \n\n\n\n**I would like to thank the readers of this notebook as well as all the members of the Kaggle community. Thank you all!**",
            "mc_idx": 76,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        }
    ],
    "code_cells": [
        {
            "source": "# import\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Modelization\nimport xgboost as xgb\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold, GridSearchCV\n\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.preprocessing import OneHotEncoder",
            "mc_idx": 4,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.03333333333333333,
                "Exploratory_Data_Analysis": 0.025,
                "Data_Transform": 0.05,
                "Model_Train": 0.058333333333333334,
                "Model_Evaluation": 0.041666666666666664,
                "Model_Interpretation": 0.025,
                "Hyperparameter_Tuning": 0.05,
                "Visualization": 0.016666666666666666,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 12
                },
                "Data_Extraction": {
                    "read_csv": 2,
                    "pd.read_": 2
                },
                "Exploratory_Data_Analysis": {
                    "matplotlib": 1,
                    ".mode": 2
                },
                "Data_Transform": {
                    ".join(": 1,
                    "standardscaler": 1,
                    "onehotencoder": 1,
                    ".join": 1,
                    ".mod": 2
                },
                "Model_Train": {
                    "train_test_split": 2,
                    "model": 3,
                    "model_selection": 2
                },
                "Model_Evaluation": {
                    "confusion_matrix": 2,
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "kfold": 1,
                    "train_test_split": 2
                },
                "Visualization": {
                    "matplotlib": 1,
                    "pyplot": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    0,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n"
                    ]
                },
                "mc_idx": 4,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 0,
                "o_idx": 0
            }
        },
        {
            "source": "print(\"hello, world\")",
            "mc_idx": 5,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    1,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "hello, world\n"
                    ]
                },
                "mc_idx": 5,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 1,
                "o_idx": 0
            }
        },
        {
            "source": "# Load Data\ntrain = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest = pd.read_csv('/kaggle/input/titanic/test.csv')\n\ngender_submission = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\n# combine All Data\nall_data = pd.concat([train, test], axis=0).reset_index().drop('index', axis=1)",
            "mc_idx": 7,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3076923076923077,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.07692307692307693,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 6,
                    "pd.read_": 6,
                    "load data": 1
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".concat(": 1,
                    ".drop": 1,
                    ".reset_index": 1,
                    ".concat": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    "store": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    2,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 7,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 2,
                "o_idx": 0
            }
        },
        {
            "source": "# Have a look on data\ndisplay(train.head(3))\ndisplay(test.head(3))\ndisplay(all_data.head(3))",
            "mc_idx": 8,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 3,
                    "head": 3,
                    ".head": 3
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    3,
                    2,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  ",
                        "   PassengerId  Pclass                              Name     Sex   Age  SibSp  \\\n0          892       3                  Kelly, Mr. James    male  34.5      0   \n1          893       3  Wilkes, Mrs. James (Ellen Needs)  female  47.0      1   \n2          894       2         Myles, Mr. Thomas Francis    male  62.0      0   \n\n   Parch  Ticket    Fare Cabin Embarked  \n0      0  330911  7.8292   NaN        Q  \n1      0  363272  7.0000   NaN        S  \n2      0  240276  9.6875   NaN        Q  ",
                        "   PassengerId  Survived  Pclass  \\\n0            1       0.0       3   \n1            2       1.0       1   \n2            3       1.0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  "
                    ]
                },
                "mc_idx": 8,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 3,
                "o_idx": 2
            }
        },
        {
            "source": "display(all_data.drop(['PassengerId', 'Survived', 'Pclass'] , axis=1).describe())",
            "mc_idx": 10,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".describe(": 1,
                    "describe": 1,
                    ".describe": 1
                },
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    4,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "               Age        SibSp        Parch         Fare\ncount  1046.000000  1309.000000  1309.000000  1308.000000\nmean     29.881138     0.498854     0.385027    33.295479\nstd      14.413493     1.041658     0.865560    51.758668\nmin       0.170000     0.000000     0.000000     0.000000\n25%      21.000000     0.000000     0.000000     7.895800\n50%      28.000000     0.000000     0.000000    14.454200\n75%      39.000000     1.000000     0.000000    31.275000\nmax      80.000000     8.000000     9.000000   512.329200"
                    ]
                },
                "mc_idx": 10,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 4,
                "o_idx": 0
            }
        },
        {
            "source": "display(all_data.info())",
            "mc_idx": 12,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".info(": 1,
                    "info": 1,
                    ".info": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    5,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1309 entries, 0 to 1308\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  1309 non-null   int64  \n 1   Survived     891 non-null    float64\n 2   Pclass       1309 non-null   int64  \n 3   Name         1309 non-null   object \n 4   Sex          1309 non-null   object \n 5   Age          1046 non-null   float64\n 6   SibSp        1309 non-null   int64  \n 7   Parch        1309 non-null   int64  \n 8   Ticket       1309 non-null   object \n 9   Fare         1308 non-null   float64\n 10  Cabin        295 non-null    object \n 11  Embarked     1307 non-null   object \ndtypes: float64(3), int64(4), object(5)\nmemory usage: 122.8+ KB\n",
                        "None"
                    ]
                },
                "mc_idx": 12,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 5,
                "o_idx": 1
            }
        },
        {
            "source": "def plot_hist(features, data):\n    plt.figure(figsize = (10,4))\n    plt.hist(data[features], bins = 50)\n    plt.xlabel(features)\n    plt.ylabel(\"Frequency\")\n    plt.title(f\"{features} distribution\")\n    plt.show()",
            "mc_idx": 14,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.5,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".hist(": 1,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    ".hist(": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    6,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 14,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 6,
                "o_idx": 0
            }
        },
        {
            "source": "print(\"Number of missing value for Age in all data : \",all_data['Age'].isnull().sum())",
            "mc_idx": 16,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".isnull": 1,
                    ".sum": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    7,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Number of missing value for Age in all data :  263\n"
                    ]
                },
                "mc_idx": 16,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 7,
                "o_idx": 0
            }
        },
        {
            "source": "plot_hist(\"Age\", all_data)",
            "mc_idx": 17,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0026_c008_o000_image_0.png",
                    8,
                    0,
                    0
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1000x400 with 1 Axes>"
                    ]
                },
                "mc_idx": 17,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 8,
                "o_idx": 0
            }
        },
        {
            "source": "plot_hist(\"Fare\", all_data)",
            "mc_idx": 19,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0026_c009_o000_image_1.png",
                    9,
                    0,
                    1
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1000x400 with 1 Axes>"
                    ]
                },
                "mc_idx": 19,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 9,
                "o_idx": 0
            }
        },
        {
            "source": "sns.set_theme(style=\"whitegrid\")\npalette = ['darkslategray', 'goldenrod']\nsns.catplot(data=train,x=\"Sex\",y=\"Age\",hue=\"Survived\",height=5, aspect=2, kind=\"swarm\", palette=palette)\nsns.catplot(data=train, col=\"Pclass\",x = \"Sex\" ,y=\"Age\",hue=\"Survived\",height=5, aspect=1, kind=\"swarm\", palette=palette)",
            "mc_idx": 21,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 3
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 3
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0026_c010_o002_image_3.png",
                    10,
                    2,
                    3
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<seaborn.axisgrid.FacetGrid at 0x7d33e6054790>",
                        "<Figure size 1085.22x500 with 1 Axes>",
                        "<Figure size 1585.22x500 with 3 Axes>"
                    ]
                },
                "mc_idx": 21,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 10,
                "o_idx": 2
            }
        },
        {
            "source": "def cat_plot(feature_x, feature_y, data, label, kind = \"bar\"):\n    g = sns.catplot(x = feature_x, y = feature_y, data = data, kind = kind)\n    g.set_ylabels(label)\n    plt.show()\n    return g\n\ncat_plot(\"Embarked\", \"Survived\", train, \"Survived Probability\")\n\npalette_2 = [\"#3A0CA3\", \"#4361EE\", \"#4CC9F0\"]\nsns.stripplot(data=train.dropna(subset = ['Embarked']), x=\"Age\", y=\"Embarked\", hue=\"Pclass\", dodge=\"true\", size=2.7, palette = list(reversed(palette_2)))\nplt.show()",
            "mc_idx": 23,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.6666666666666666,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.6666666666666666,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 2
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 2,
                    "size": 1
                },
                "Data_Transform": {
                    ".dropna(": 1,
                    ".drop": 1,
                    ".dropna": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0026_c011_o001_image_5.png",
                    11,
                    1,
                    5
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 500x500 with 1 Axes>",
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 23,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 11,
                "o_idx": 1
            }
        },
        {
            "source": "# craft new features \"Family Size\" \nall_data[\"FamilySize\"] = 1 + all_data[\"SibSp\"] + all_data[\"Parch\"]\ndisplay(all_data.head(3))\n",
            "mc_idx": 25,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    "size": 2,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    12,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived  Pclass  \\\n0            1       0.0       3   \n1            2       1.0       1   \n2            3       1.0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  FamilySize  \n0      0         A/5 21171   7.2500   NaN        S           2  \n1      0          PC 17599  71.2833   C85        C           2  \n2      0  STON/O2. 3101282   7.9250   NaN        S           1  "
                    ]
                },
                "mc_idx": 25,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 12,
                "o_idx": 0
            }
        },
        {
            "source": "# craft 2 features 'Surname' and 'Title'\nall_data['Surname'] = all_data['Name'].apply(lambda x: x.split(',')[0]) \nall_data['Title'] = all_data['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0]) \ndisplay(all_data.head(3))",
            "mc_idx": 27,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".apply(": 3,
                    ".split": 3,
                    ".apply": 3
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    13,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived  Pclass  \\\n0            1       0.0       3   \n1            2       1.0       1   \n2            3       1.0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  FamilySize    Surname  \\\n0      0         A/5 21171   7.2500   NaN        S           2     Braund   \n1      0          PC 17599  71.2833   C85        C           2    Cumings   \n2      0  STON/O2. 3101282   7.9250   NaN        S           1  Heikkinen   \n\n   Title  \n0    Mr.  \n1   Mrs.  \n2  Miss.  "
                    ]
                },
                "mc_idx": 27,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 13,
                "o_idx": 0
            }
        },
        {
            "source": "sns.countplot(y=\"Title\", data = all_data, orient = 'v')\nplt.show()",
            "mc_idx": 29,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0026_c014_o000_image_6.png",
                    14,
                    0,
                    6
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 29,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 14,
                "o_idx": 0
            }
        },
        {
            "source": "display(all_data[all_data.Title=='the'])\n#Correcting the Title for passenger 760\nall_data.loc[(all_data.PassengerId==760), 'Title'] = 'Countess.'\ndisplay(all_data[all_data.PassengerId==760])",
            "mc_idx": 31,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    15,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "     PassengerId  Survived  Pclass  \\\n759          760       1.0       1   \n\n                                                  Name     Sex   Age  SibSp  \\\n759  Rothes, the Countess. of (Lucy Noel Martha Dye...  female  33.0      0   \n\n     Parch  Ticket  Fare Cabin Embarked  FamilySize Surname Title  \n759      0  110152  86.5   B77        S           1  Rothes   the  ",
                        "     PassengerId  Survived  Pclass  \\\n759          760       1.0       1   \n\n                                                  Name     Sex   Age  SibSp  \\\n759  Rothes, the Countess. of (Lucy Noel Martha Dye...  female  33.0      0   \n\n     Parch  Ticket  Fare Cabin Embarked  FamilySize Surname      Title  \n759      0  110152  86.5   B77        S           1  Rothes  Countess.  "
                    ]
                },
                "mc_idx": 31,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 15,
                "o_idx": 1
            }
        },
        {
            "source": "display(all_data.loc[(all_data.Title == 'Master.') & (all_data.Age.isnull())])",
            "mc_idx": 33,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".isnull": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    16,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "      PassengerId  Survived  Pclass  \\\n65             66       1.0       3   \n159           160       0.0       3   \n176           177       0.0       3   \n709           710       1.0       3   \n1135         1136       NaN       3   \n1230         1231       NaN       3   \n1235         1236       NaN       3   \n1308         1309       NaN       3   \n\n                                                   Name   Sex  Age  SibSp  \\\n65                             Moubarek, Master. Gerios  male  NaN      1   \n159                          Sage, Master. Thomas Henry  male  NaN      8   \n176                       Lefebre, Master. Henry Forbes  male  NaN      3   \n709   Moubarek, Master. Halim Gonios (\"William George\")  male  NaN      1   \n1135          Johnston, Master. William Arthur Willie\"\"  male  NaN      1   \n1230                              Betros, Master. Seman  male  NaN      0   \n1235                van Billiard, Master. James William  male  NaN      1   \n1308                           Peter, Master. Michael J  male  NaN      1   \n\n      Parch      Ticket     Fare Cabin Embarked  FamilySize       Surname  \\\n65        1        2661  15.2458   NaN        C           3      Moubarek   \n159       2    CA. 2343  69.5500   NaN        S          11          Sage   \n176       1        4133  25.4667   NaN        S           5       Lefebre   \n709       1        2661  15.2458   NaN        C           3      Moubarek   \n1135      2  W./C. 6607  23.4500   NaN        S           4      Johnston   \n1230      0        2622   7.2292   NaN        C           1        Betros   \n1235      1    A/5. 851  14.5000   NaN        S           3  van Billiard   \n1308      1        2668  22.3583   NaN        C           3         Peter   \n\n        Title  \n65    Master.  \n159   Master.  \n176   Master.  \n709   Master.  \n1135  Master.  \n1230  Master.  \n1235  Master.  \n1308  Master.  "
                    ]
                },
                "mc_idx": 33,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 16,
                "o_idx": 0
            }
        },
        {
            "source": "all_data.loc[(all_data.Age < 12) & (all_data.Sex == 'male') & (all_data.Title != 'Master.')]\n#Correcting the Title for passenger 760\nall_data.loc[(all_data.PassengerId==732), 'Title'] = 'Master.'\ndisplay(all_data[all_data.PassengerId==732])\n",
            "mc_idx": 35,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    17,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "     PassengerId  Survived  Pclass                      Name   Sex   Age  \\\n731          732       0.0       3  Hassan, Mr. Houssein G N  male  11.0   \n\n     SibSp  Parch Ticket     Fare Cabin Embarked  FamilySize Surname    Title  \n731      0      0   2699  18.7875   NaN        C           1  Hassan  Master.  "
                    ]
                },
                "mc_idx": 35,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 17,
                "o_idx": 0
            }
        },
        {
            "source": "# Craft a dictionnary of surname for the women & children group \nwomen_child = all_data.loc[(all_data.Sex == 'female') | (all_data.Title == 'Master.')]\nwomen_child_surname_dic = women_child.groupby('Surname')['PassengerId'].count().to_dict()\n\n# craft a new feature 'WomenChildNameFreq' by mapping Surname to the dictionary\nall_data.loc[(all_data.Sex == 'female') | (all_data.Title == 'Master.'), 'WomenChildNameFreq'] = all_data.Surname.map(women_child_surname_dic) \n\n# Craft a feature 'woman_child' for grouping woman and child... 1 for true if a passenger belong to this group \nall_data.loc[(all_data.WomenChildNameFreq>1), 'WomenChild'] = 1\n\n# with the train data only, craft a dictionnary with an indice of survival\nonly_train = all_data[0:891]\nwomen_child_survivor_dic = only_train[(only_train.WomenChild==1)].groupby('Surname')['Survived'].mean().to_dict()\n\n# craft a new feature 'women_child_surname_survival'\nall_data.loc[(all_data.WomenChild==1), 'WomenChildNameSurvival']=all_data.Surname.map(women_child_survivor_dic)",
            "mc_idx": 37,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.6666666666666666,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.6666666666666666,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1,
                    ".groupby": 2
                },
                "Data_Transform": {
                    ".groupby(": 2,
                    ".map(": 2,
                    ".map": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    "to_dict": 2,
                    ".to_dict": 2
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    18,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 37,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 18,
                "o_idx": 0
            }
        },
        {
            "source": "dic_value = list(women_child_survivor_dic.values())\nprint(dic_value.count(0))\nprint(dic_value.count(1))\nprint(sum(1 for i in dic_value if 0 < i < 1 ))",
            "mc_idx": 39,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    19,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "22\n66\n4\n"
                    ]
                },
                "mc_idx": 39,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 19,
                "o_idx": 0
            }
        },
        {
            "source": "sns.catplot(data=only_train[only_train.WomenChild == 1], x=\"Pclass\",y=\"Age\",hue=\"Survived\",height=5, aspect=2, kind=\"swarm\", palette=palette)",
            "mc_idx": 41,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0026_c020_o001_image_7.png",
                    20,
                    1,
                    7
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<seaborn.axisgrid.FacetGrid at 0x7d33e6157be0>",
                        "<Figure size 1085.22x500 with 1 Axes>"
                    ]
                },
                "mc_idx": 41,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 20,
                "o_idx": 1
            }
        },
        {
            "source": "only_train = all_data[0:891]\nonly_test = all_data[891:1309]",
            "mc_idx": 43,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    21,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 43,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 21,
                "o_idx": 0
            }
        },
        {
            "source": "cat_plot(\"FamilySize\", \"Survived\", only_train, \"Survived Probability\")",
            "mc_idx": 45,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    22,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 500x500 with 1 Axes>",
                        "<seaborn.axisgrid.FacetGrid at 0x7d34302c7700>"
                    ]
                },
                "mc_idx": 45,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 22,
                "o_idx": 1
            }
        },
        {
            "source": "sns.swarmplot(data=only_train, x=\"Survived\", y=\"Age\", hue=\"FamilySize\", size=3.5, legend='full', palette='Spectral')\nsns.catplot(data=only_train, kind=\"swarm\", x=\"Survived\", y=\"Age\", hue=\"FamilySize\", legend='full', col=\"Pclass\", palette='Spectral')",
            "mc_idx": 47,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.4,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 2,
                    "size": 3
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0026_c023_o002_image_10.png",
                    23,
                    2,
                    10
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<seaborn.axisgrid.FacetGrid at 0x7d33e60c66e0>",
                        "<Figure size 640x480 with 1 Axes>",
                        "<Figure size 1599.85x500 with 3 Axes>"
                    ]
                },
                "mc_idx": 47,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 23,
                "o_idx": 2
            }
        },
        {
            "source": "# Have a look on gender_submission and output for submission\ndisplay(gender_submission.head(3))\n\n# and save the output formated for submission\ngender_submission.to_csv('gender_submission.csv', index=False)\n\n# And submit ... \n# score for gender_submission = 0.76555",
            "mc_idx": 49,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "save": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    24,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived\n0          892         0\n1          893         1\n2          894         0"
                    ]
                },
                "mc_idx": 49,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 24,
                "o_idx": 0
            }
        },
        {
            "source": "test_women_child = only_test\ntest_women_child = test_women_child.drop('Survived', axis=1) ",
            "mc_idx": 52,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    25,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 52,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 25,
                "o_idx": 0
            }
        },
        {
            "source": "# Gender Model\ntest_women_child.loc[(test_women_child.Sex == 'female' ), 'Survived'] = 1\ntest_women_child.loc[(test_women_child.Sex == 'male'), 'Survived'] = 0\n\n# Children \ntest_women_child.loc[(test_women_child.Title == 'Master.') & (test_women_child.Pclass == 1), 'Survived'] = 1\ntest_women_child.loc[(test_women_child.Title == 'Master.') & (test_women_child.Pclass == 2), 'Survived'] = 1\n\ntest_women_child.loc[(test_women_child.Title == 'Master.') & (test_women_child.Pclass == 3) & (test_women_child.FamilySize < 3) , 'Survived'] = 1\n\ntest_women_child['Survived'] = test_women_child['Survived'].astype(int)",
            "mc_idx": 53,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    26,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 53,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 26,
                "o_idx": 0
            }
        },
        {
            "source": "submission = test_women_child[['PassengerId', 'Survived']]\nsubmission.to_csv('women_child_model.csv', index=False)\n#Score : 0.77751 !!!! ",
            "mc_idx": 54,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.5,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    27,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 54,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 27,
                "o_idx": 0
            }
        },
        {
            "source": "all_data.loc[(all_data.Title == 'Master.'), 'isMaster'] = 1",
            "mc_idx": 58,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    28,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 58,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 28,
                "o_idx": 0
            }
        },
        {
            "source": "dropped_features = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'Surname', 'Title', 'Embarked']\n\nall_data_machine = all_data.drop(dropped_features, axis = 1)\n\ndisplay(all_data_machine.head(3))",
            "mc_idx": 60,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    29,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare  FamilySize  \\\n0       0.0       3    male  22.0      1      0   7.2500           2   \n1       1.0       1  female  38.0      1      0  71.2833           2   \n2       1.0       3  female  26.0      0      0   7.9250           1   \n\n   WomenChildNameFreq  WomenChild  WomenChildNameSurvival  isMaster  \n0                 NaN         NaN                     NaN       NaN  \n1                 1.0         NaN                     NaN       NaN  \n2                 1.0         NaN                     NaN       NaN  "
                    ]
                },
                "mc_idx": 60,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 29,
                "o_idx": 0
            }
        },
        {
            "source": "# Get list of categorical variables\ns = (all_data_machine.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols)",
            "mc_idx": 62,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 2
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "dtypes": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    30,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Categorical variables:\n['Sex']\n"
                    ]
                },
                "mc_idx": 62,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 30,
                "o_idx": 0
            }
        },
        {
            "source": "# Apply one-hot encoder to each column with categorical data\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_all_data = pd.DataFrame(OH_encoder.fit_transform(all_data_machine[object_cols]))\n\n# One-hot encoding removed index; put it back\nOH_all_data.index = all_data_machine.index\n\n# Remove categorical columns (will replace with one-hot encoding)\nnum_all_data = all_data_machine.drop(object_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nOH_all_data = pd.concat([num_all_data, OH_all_data], axis=1)\n\n# Ensure all columns have string type\nOH_all_data.columns = OH_all_data.columns.astype(str)",
            "mc_idx": 63,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.7142857142857143,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 5
                },
                "Data_Transform": {
                    ".concat(": 1,
                    "fit_transform": 1,
                    "transform": 1,
                    ".astype(": 1,
                    "onehotencoder": 1,
                    ".drop": 1,
                    ".concat": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    31,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n"
                    ]
                },
                "mc_idx": 63,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 31,
                "o_idx": 0
            }
        },
        {
            "source": "display(OH_all_data.head(3))",
            "mc_idx": 64,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    32,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   Survived  Pclass   Age  SibSp  Parch     Fare  FamilySize  \\\n0       0.0       3  22.0      1      0   7.2500           2   \n1       1.0       1  38.0      1      0  71.2833           2   \n2       1.0       3  26.0      0      0   7.9250           1   \n\n   WomenChildNameFreq  WomenChild  WomenChildNameSurvival  isMaster    0    1  \n0                 NaN         NaN                     NaN       NaN  0.0  1.0  \n1                 1.0         NaN                     NaN       NaN  1.0  0.0  \n2                 1.0         NaN                     NaN       NaN  1.0  0.0  "
                    ]
                },
                "mc_idx": 64,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 32,
                "o_idx": 0
            }
        },
        {
            "source": "params = {\n 'learning_rate': [0.01, 0.05, 0.07, 0.1],\n 'subsample': [1],\n 'colsample_bylevel': [1],\n 'colsample_bynode': [1],\n 'colsample_bytree': [0.5],\n 'gamma': [0, 1, 2],\n 'max_delta_step': [0],\n 'max_depth': [2, 3, 4, 5],\n 'min_child_weight': [1.6],\n 'n_estimators': [70, 80, 90, 100], \n 'random_state': [42],\n 'scale_pos_weight': [1],\n 'seed': [42],\n 'n_jobs': [-1],\n 'reg_lambda': [1, 2, 4, 16]\n}",
            "mc_idx": 66,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    33,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 66,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 33,
                "o_idx": 0
            }
        },
        {
            "source": "def xgb_classifier(data, target, params):\n      \n    # Create X and y\n    X = data.drop(target, axis=1)\n    y = data[target]\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X)\n    X_scaled = scaler.transform(X)\n    \n    # Create a XGBoost classifier (scikit-learn API wrapper)\n    xgb_clf = XGBClassifier()\n    \n    # Perform a gridsearch with sklearn\n    kf = KFold(n_splits=10, random_state=42, shuffle=True)\n    gridsearch = GridSearchCV(xgb_clf, param_grid=params, scoring=\"accuracy\", cv=kf, return_train_score=True)\n    gridsearch.fit(X_scaled, y)\n    \n    # Return the gridsearch results plus the scaler\n    return gridsearch, scaler",
            "mc_idx": 68,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.375,
                "Model_Train": 0.25,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "transform": 1,
                    "standardscaler": 1,
                    ".drop": 1
                },
                "Model_Train": {
                    ".fit(": 2
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "param_grid": 1,
                    "param": 3,
                    "kfold": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    34,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 68,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 34,
                "o_idx": 0
            }
        },
        {
            "source": "dropped_features = ['Age', 'SibSp', 'Parch', 'Fare', 'WomenChildNameFreq']\n\ndata_for_XG = OH_all_data.drop(dropped_features, axis = 1)\ndisplay(data_for_XG.head(3)) ",
            "mc_idx": 70,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    35,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   Survived  Pclass  FamilySize  WomenChild  WomenChildNameSurvival  isMaster  \\\n0       0.0       3           2         NaN                     NaN       NaN   \n1       1.0       1           2         NaN                     NaN       NaN   \n2       1.0       3           1         NaN                     NaN       NaN   \n\n     0    1  \n0  0.0  1.0  \n1  1.0  0.0  \n2  1.0  0.0  "
                    ]
                },
                "mc_idx": 70,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 35,
                "o_idx": 0
            }
        },
        {
            "source": "\ntrain_XG = data_for_XG[0:891]\n\ntest_XG = data_for_XG[891:1309]\ntest_XG = test_XG.drop('Survived', axis = 1)\n\ngridsearch, scaler = xgb_classifier(train_XG, \"Survived\", params)\n\ndisplay(gridsearch.best_params_)\n",
            "mc_idx": 72,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    36,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "{'colsample_bylevel': 1,\n 'colsample_bynode': 1,\n 'colsample_bytree': 0.5,\n 'gamma': 0,\n 'learning_rate': 0.01,\n 'max_delta_step': 0,\n 'max_depth': 3,\n 'min_child_weight': 1.6,\n 'n_estimators': 80,\n 'n_jobs': -1,\n 'random_state': 42,\n 'reg_lambda': 4,\n 'scale_pos_weight': 1,\n 'seed': 42,\n 'subsample': 1}"
                    ]
                },
                "mc_idx": 72,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 36,
                "o_idx": 0
            }
        },
        {
            "source": "\ntest_XG_scaled = scaler.transform(test_XG)\n\npredictions = gridsearch.predict(test_XG_scaled)\n\noutput = pd.DataFrame({'PassengerId': PassengerId, 'Survived': predictions})\noutput.to_csv('gridsearch_xgboost.csv', index=False)\nprint(\"Your submission was successfully saved!\") \n\n### Score : 0.80382",
            "mc_idx": 74,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "transform": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "save": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    37,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Your submission was successfully saved!\n"
                    ]
                },
                "mc_idx": 74,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 37,
                "o_idx": 0
            }
        }
    ],
    "markdown_cells": [
        {
            "source": "**Introduction:** While this notebook is intended to be beginner-friendly, it won't be feasible to explain every concept in detail to keep it a reasonable size. However, if you have the required prerequisites and basic understanding of Machine Learning, we hope it will be beneficial to you.\n\n**We would also like to express our gratitude to the Kaggle community as a whole for their efforts in making knowledge accessible to everyone. Thank you.**",
            "mc_idx": 0,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Titanic: \"Women and Children First!\" - A beginner-friendly guide to applying Data Science and Machine Learning to the Titanic disaster.\n\n![1920px-Titanic_Starboard_View_1912.gif](attachment:4c681ad5-db7b-4d2b-884c-ed28c68819ef.gif)",
            "mc_idx": 1,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### Table of Contents\n\n* [1. \"Women and children first,\" really? ](#1)\n    * [1.1 Brief Overview of the Sequence of Events.](#1.1)\n    * [1.2 Some Anecdotes and Notable Facts](#1.2)\n    * [1.3 Getting to the Heart of the Matter](#1.3)\n* [2. Exploratory Data Analysis (EDA)](#2)\n    * [2.1 Data Loading and Verification](#2.1)\n        * [2.1.1 Data Dictionary](#2.1.1)\n        * [2.1.2 The pandas.describe Function](#2.1.2)\n        * [2.1.3 The pandas.info Function](#2.1.3)\n    * [2.2 Data Visualization: A picture is worth a thousand words!](#2.2)\n        * [2.2.1 Visualization of the Age and Fare Distributions Using Histograms](#2.2.1)\n        * [2.2.2 Visualization and Analysis of Data Using a \"Swarm\" Plot](#2.2.2)\n        * [2.2.3 Visualization and Analysis of Boarding Data](#2.2.3)\n    * [2.3 A Dash of Feature Engineering](#2.3)\n        * [2.3.1 Family Size](#2.3.1)\n        * [2.3.2 Title and Last Name](#2.3.2)\n        * [2.3.3 Identifying and grouping women and children from the same family](#2.3.3)\n    * [2.4 Back to exploration...](#2.4)\n* [3. Data modeling](#3)\n    * [3.1 Decision tree 'women and children first'](#3.1)    \n* [4. Machine Learning](#4)\n    * [4.1 Feature engineering and data preprocessing.](#4.1)\n        * [4.1.1 creation of the 'isMaster' feature.](#4.1.1)\n        * [4.1.2 Data preprocessing](#4.1.2)\n    * [4.2 XGBoost and GridSearchCV](#4.2)\n        * [4.2.1 Definition of the hyperparameters to test](#4.2.1)\n        * [4.2.2 Definition of the xgb_classifier function](#4.2.2)\n        * [4.2.3 Feature Selection](#4.2.3)\n        * [4.2.4 training](#4.2.4)\n        * [4.2.5 Submitting our predictions to Kaggle and scoring](#4.2.5)\n* [5. Recap and How to Go Further...](#5)\n    * [5.1 How good is your score](#5.1)\n    * [5.2 How to go further?](#5.2)\n        \n        ",
            "mc_idx": 2,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 1.\"Women and children first,\" really? <a class=\"anchor\"  id=\"1\"></a>\n\n\"The women and children first\" principle is a concept that involves prioritizing the rescue of women and children before adult men in the face of a threat. During the 19th and early 20th centuries, ships with a tonnage of less than 10,000 tons did not have enough lifeboats to save all passengers. The idea of saving women and children during a shipwreck became particularly prominent in history during the Titanic disaster in 1912, perhaps the most famous maritime catastrophe of all time.\n\n\"However, according to the 2012 Swedish study titled 'Gender Social Norms and Survival in Maritime Disaster,' the survival rate of women and children is determined to be low. Analyzing 18 major maritime disasters that occurred between 1852 and 2011 and involved over 15,000 individuals from more than 30 different nationalities, the study reveals that the survival rate of the crew and captain surpasses that of the passengers. Men have a survival rate twice that of women, while children's survival rate reaches only 15%. This research posits the Titanic disaster as an exception, one of the few shipwrecks in the modern era where this principle was adhered to.\"\n\n> (en) M. Elinder et O. Erixson, \u00ab Gender, social norms, and survival in maritime disasters \u00bb, Proceedings of the National Academy of Sciences,\u200e 2 mai 2012 https://www.pnas.org/doi/full/10.1073/pnas.1207156109\n\nThe gender gap in survival rates has decreased since World War I, and women are more disadvantaged in British shipwrecks. The study asserts, \"Taken together, our results show that human behavior in life or death situations is better described by the expression 'every man for himself' or 'every person for themselves.'\"\n\nHowever, the study specifies that the Titanic disaster is an exception, and we will explore what the data analysis can tell us. Here, we will solely use the dataset provided by Kaggle as part of the friendly competition themed around the Titanic. We will stick to this dataset and refrain from introducing external structured data to play the game fairly.\n\n# 1.1 Brief Overview of the Sequence of Events. <a class=\"anchor\"  id=\"1.1\"></a>\n\nEven though this shipwreck is well-known, particularly through James Cameron's 1997 film, it seems useful to provide a brief overview of the events.\n\nThe sinking of the Titanic marked the end of the maiden voyage of the RMS Titanic, a ship intended to connect Southampton to New York. The Titanic was equipped with sixteen watertight compartments designed to protect the ship from significant damage. The media portrayed it as a reliable and even \"unsinkable\" vessel. However, contrary to this legend, historians emphasize that it was not considered \"unsinkable\" by its builders.\n\n> Source: Richard Howells, \"The Myth of the Titanic,\" Palgrave Macmillan, 2012.\n\nThe sinking unfolded on the night of April 14 to April 15, 1912, in the North Atlantic Ocean off the coast of Newfoundland. The ship struck an iceberg on the starboard side on Sunday, April 14, 1912, at 11:40 PM and sank in less than three hours, at 2:20 AM. Between 1,490 and 1,520 people perished, making this disaster one of the greatest maritime tragedies of all time.\n\nThe Titanic is a British transatlantic liner of the White Star Line, built at the initiative of Bruce Ismay and designed by the architect Thomas Andrews of the Harland & Wolff shipyards. Its construction began in 1909 in Belfast and was completed in 1912. At the time of its launch, it was the most luxurious and largest ship ever built. Its construction followed that of a nearly identical ship, the Olympic.\n\n# 1.2 Some Anecdotes and Notable Facts. <a class=\"anchor\"  id=\"1.2\"></a>\n\n* The ship did not have a sufficient number of lifeboats, and the crew had never been trained to handle this type of event.\n\n* The stewards then went to the cabins to invite passengers to put on warm clothes and a life jacket, asking them to go to the lifeboat deck. In order to reassure the passengers, the crew assured them that it was just a drill.\n\n* As a result, due to its reputation as unsinkable and the reassuring statements, disbelief prevailed.\n\n* Only a few passengers made their way to the lifeboat deck to board a lifeboat, and the majority did not worry and stayed inside the ship for a long time.\n\n* The first-class passengers were informed first, followed by the second class. The third-class passengers were prevented from accessing the deck until a later hour.\n\n* At 12:25 AM, the order is given to load women and children first into the lifeboats. At the same moment, the orchestra starts playing at the front of the lifeboat deck, following the command of Captain Smith, who aims to prevent any onset of panic.\n\n* Due to continued disbelief, many passengers were reluctant to board the lifeboats.\n\n* Regarding the first lifeboats, the officers on the port side only allowed women and children to board, while on the starboard side, each lifeboat was loaded with women and children first, followed by men. The pragmatism on the starboard side led to launching fully loaded lifeboats and better survivability for men, while on the port side, idealism and strict adherence to orders resulted in lifeboats with many vacant seats. This fact is very interesting, although it may be challenging to utilize with the data provided by Kaggle.\n\n* From 1:15 onwards, water began to flood the bow of the ship, and passengers, who were previously in disbelief, started to come to terms with the reality of the sinking. The evacuation accelerated from this point. Additionally, third-class passengers started arriving in larger numbers on the lifeboat deck.\n\n# 1.3 Getting to the Heart of the Matter <a class=\"anchor\"  id=\"1.3\"></a>\n\nIt's time to get to the heart of the matter, and to start, in the next cell, we will import all the libraries that will be useful to us. For practical reasons, we will centralize all imports here.\n\n\n\n\n\n",
            "mc_idx": 3,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2. Exploratory Data Analysis (EDA) <a class=\"anchor\"  id=\"2\"></a>\n\nIn summary, exploratory data analysis will help us understand the data patterns, check for integrity, and summarize relevant information for predictive models.\n\n> Exploratory data analysis (EDA) is used by data scientists to analyze and investigate data sets and summarize their main characteristics, often employing data visualization methods. It helps determine how best to manipulate data sources to get the answers you need, making it easier for data scientists to discover patterns, spot anomalies, test a hypothesis, or check assumptions.\n\n> source : https://www.ibm.com/topics/exploratory-data-analysis\n\n# 2.1 Data Loading and Verification <a class=\"anchor\"  id=\"2.1\"></a>\n\nIn this section, we will load the data provided by Kaggle and take a first look.",
            "mc_idx": 6,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.1.1 Data Dictionary <a class=\"anchor\"  id=\"2.1.1\"></a>\n\nEstablishing a data dictionary is essential as a reference to interpret the data without ambiguity regarding its meaning. Here is a good definition of what a data dictionary is:\n\n> A Data Dictionary is a collection of names, definitions, and attributes about data elements that are being used or captured in a database, information system, or part of a research project. It describes the meanings and purposes of data elements within the context of a project, and provides guidance on interpretation, accepted meanings and representation. A Data Dictionary also provides metadata about data elements. The metadata included in a Data Dictionary can assist in defining the scope and characteristics of data elements, as well the rules for their usage and application. \n\n> source: https://library.ucmerced.edu/data-dictionaries#:~:text=A%20Data%20Dictionary%20is%20a,part%20of%20a%20research%20project\n\n* **survival:** survival\n    * 0 = No,\n    * 1 = Yes\n* **pclass:** ticket class\n    * 1 = 1st,\n    * 2 = 2nd,\n    * 3 = 3rd\n* **sex:** sex\n* **Age:** age in years\n* **sibsp:** number of siblings / spouses aboard the Titanic\n* **parch:** number of parents / children aboard the Titanic\n* **ticket:** ticket number\n* **fare:** passenger fare\n* **cabin:** cabin number\n* **embarked:** Port of Embarkation\n    * C = Cherbourg,\n    * Q = Queenstown,\n    * S = Southampton\n\n\n\n# 2.1.2 The pandas.describe Function <a class=\"anchor\"  id=\"2.1.2\"></a>   \n\nFirstly, below is a description of the entire dataset using the 'describe' function provided by pandas.\n\n> The pandas.describe function is used to get a descriptive statistics summary of a given dataframe. This includes mean, count, std deviation, percentiles, and min-max values of all the features.\n\n> source : https://www.machinelearningplus.com/pandas/pandas-describe/",
            "mc_idx": 9,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.1.3 The pandas.info Function <a class=\"anchor\"  id=\"2.1.3\"></a>\n\n> The info() method prints information about the DataFrame. The information contains the number of columns, column labels, column data types, memory usage, range index, and the number of cells in each column (non-null values).\n\n> source : https://www.w3schools.com/python/pandas/ref_df_info.asp \n\n",
            "mc_idx": 11,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.2 Data Visualization: A picture is worth a thousand words! <a class=\"anchor\"  id=\"2.2\"></a>\n\nTo start, let's take a quick look at the distribution of age and the \"Fare\" feature. In the next cell, we will build a function to visualize them so that we don't have to repeat code unnecessarily. We will observe these two features on the entire available dataset.\n\n# 2.2.1 Visualization of the Age and Fare Distributions Using Histograms. <a class=\"anchor\"  id=\"2.2.1\"></a>\n\n> A histogram is a statistical graph that represents the distribution of a continuous dataset through plotted bars, each representing a particular category or class interval. The bar height reflects the frequency or count of data points within each group.\n\n> source : https://www.jaspersoft.com/articles/what-is-a-histogram-chart\n",
            "mc_idx": 13,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Of course, in observing the age distribution, we are mindful that we have 263 missing values across all data. Here, we won't attempt to fill these gaps using the mean or median, etc., to avoid creating a 'spike' in the graph that doesn't reflect reality. We will, therefore, work with the information we have.\n\n",
            "mc_idx": 15,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Regarding the fares (Fare), unsurprisingly, the lower values are more numerous.\n",
            "mc_idx": 18,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.2.2 Visualization and Analysis of Data Using a \"Swarm\" Plot <a class=\"anchor\"  id=\"2.2.2\"></a>\n\nWe will generate \"swarm\" plot graphs from the training data provided by Kaggle using the code below. These plots involve creating a scatter plot for each category with points adjusted to avoid overlap, providing a better representation of the distribution of values. We will use the \"seaborn\" library built on top of \"matplotlib\". If you want to learn more about this type of plot and how to implement it, I encourage you to consult the documentation.\n\n> https://seaborn.pydata.org/generated/seaborn.swarmplot.html\n\nIn our case, we will place the \"Sex\" category on the x-axis, with \"Age\" on the y-axis, and each point will be colored according to survival, specifically 'Survived'. We will extend this organization by distributing it over three columns representing each class.\n\nThis graph allows us to grasp a lot of information at a glance, and we will draw some initial insights from it. We will refer back to it later as well.\n\nAt first glance, it's evident that the survival rate for women is much higher, especially in the first and second classes, where the vast majority of women survive. However, in the third class, things are more mixed.\n\nFor men, it's a disaster, with still a better chance of survival in the first class. However, men in the second and third classes are literally decimated.\n\nRegarding the number of men and women, we observe that men are much more numerous. This imbalance is primarily due to the presence of a large number of men in the prime of life in the third class, perhaps in search of a better future. The destination being New York, and this city attracting many migrants, the idea of the \"American dream\" is prevalent at this time. In the first and second classes, things are a bit more balanced.\n\nRegarding children, taking into account that there are missing values (since we have the age of only 714 passengers out of 891), there seems to be relatively few children. Could some children be \"hidden\" among the 177 missing values?\n\nChildren seem to have a better survival rate. We can even observe that boys under 12 years old have survived much better than older men. Boys in the first and second classes seem to have all survived according to the data we have. These observations confirm the \"women and children first\" hypothesis, although once again, the chances of survival are more mixed in the third class.\n\nIndeed, there are likely more insights to gain from these graphs.\n\n",
            "mc_idx": 20,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.2.3 Visualization and Analysis of Boarding Data <a class=\"anchor\"  id=\"2.2.3\"></a>\n\nAt first glance at the graph showing the relationship between the city of embarkation and the probability of survival, we might think there is a useful correlation. However, using the \"strip plot\" graph highlighting embarkations and class, we can explain this by the fact that third-class passengers are much fewer in number. Therefore, it's the survival probability based on class that is significant rather than the city of embarkation.\n\nHere, we will use a bar chart :\n\n> A bar plot or bar chart is a graph that represents the category of data with rectangular bars with lengths and heights that is proportional to the values which they represent. The bar plots can be plotted horizontally or vertically.\n\n> source : https://www.geeksforgeeks.org/bar-plot-in-matplotlib/\n\nAnd a 'strip plot' graph :\n\n> It is basically a scatter plot that differentiates different categories. So, all the data that corresponds to each category is shown as a scatter plot, and all the observations and collected data that are visualized are shown, side-by-side on a single graph.\n\n> source : https://www.educative.io/answers/what-is-seabornstripplot\n\n",
            "mc_idx": 22,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.3 A Dash of Feature Engineering <a class=\"anchor\"  id=\"2.3\"></a>\n\nBefore delving further into data exploration, we will create new features from the existing ones that will be necessary for a better understanding of the context, making them more usable.\n\n> Feature engineering is the process of selecting, manipulating, and transforming raw data into features that can be used in supervised learning. In order to make machine learning work well on new tasks, it might be necessary to design and train better features.\n\n> source : https://towardsdatascience.com/what-is-feature-engineering-importance-tools-and-techniques-for-machine-learning-2080b0269f10\n\nWe will just initiate this process at this early stage to facilitate data exploration, but we will revisit it later to prepare the data for machine learning model usage.\n\n# 2.3.1 Family Size <a class=\"anchor\"  id=\"2.3.1\"></a>\n\nHere, we will create the \"family_size\" feature since the two features:\n\n* sibsp: the number of siblings, spouses aboard the Titanic.\n* parch: the number of parents and children aboard the Titanic.\n\nWhile they provide a better understanding of family composition, they do not immediately capture the total. Therefore, we will add these two features together to obtain the total size of an individual's family.\n\n",
            "mc_idx": 24,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.3.2 Title and Last Name <a class=\"anchor\"  id=\"2.3.2\"></a>\n\nStill, for a better understanding of the family, we will process the 'Name' feature to extract the last name. At the same time, we will extract the title, which can provide valuable information.\n\n",
            "mc_idx": 26,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\nAfter some research to understand the meaning of these different titles, one thing seems very interesting: the significance of the title \"Master,\" which was used at that time to designate boys too young to be called \"Mister.\" This might help us identify boys whose age is not specified.",
            "mc_idx": 28,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "The script, while effective in the vast majority of cases in extracting the title from the name, made an error by assigning 'the' instead of 'Countess.' for passenger 760. We correct this error below.\n",
            "mc_idx": 30,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Indeed, several boys with the title \"Master\" did not have the age specified!\n",
            "mc_idx": 32,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "All boys under 12 have the title \"Master,\" except passenger 732. Let's correct that quickly...\n",
            "mc_idx": 34,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.3.3 Identifying and grouping women and children from the same family <a class=\"anchor\"  id=\"2.3.3\"></a>\n\nHere, we will create new features that seem essential to capture the reality by grouping women and children from the same family.\n\nWe will define the 'WomenChild' feature as the membership in a group of women accompanied by children from the same family. Then, with the 'WomenChildNameSurvival' feature, we will assign a survival rate based on the training data for each of these families containing women and children.",
            "mc_idx": 36,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "An important point to note here is that if we observe the survival rate of women and children groups based on the last name, according to the training data, 66 families from the 'women and children' group survived entirely, 22 families perished entirely, and only 4 families had a mixed outcome.\n\nThis leads us to believe that it is indeed wise to group women and children by family, and these families tend to either all survive or all perish together.",
            "mc_idx": 38,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "And this phenomenon is especially noticeable for the third class, as we can see in the following graph.",
            "mc_idx": 40,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Before continuing, since we made these changes to all_data, the original train and test data do not have the new features. To preserve the original data if needed, we will create new dataframes, only_train and only_test, containing the new features.",
            "mc_idx": 42,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 2.4 Back to exploration... <a class=\"anchor\"  id=\"2.4\"></a>\n\nWe observe that family size seems to correlate with better survival, although for families with more than 4 members, the margin of error is too large to draw conclusions. As a hypothesis, following the \"women and children first\" principle, we can suggest that men traveling alone contribute to the drop in the survival rate of passengers traveling alone.",
            "mc_idx": 44,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Through this 'swarmplot' chart below, correlating survival, age, and family size for each passenger, we also observe that children from larger families in the third class appear to have a significantly lower survival rate. (However, as mentioned earlier, the data for large families is limited, resulting in a significant margin of error.)",
            "mc_idx": 46,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 3. Data modeling <a class=\"anchor\"  id=\"3\"></a>\n\nIn the files provided by Kaggle, aside from the training and test data, there is a 'gender_submission' file that represents the predictions of a very simple model: all women survive, all men die.\n\nBy providing this file, Kaggle is clearly inviting us to try this model. That's what we'll do in the next cell.\n\nNote that this model does not use machine learning but a very simple and rudimentary decision tree: \"if it's a woman, then survive; if it's a man, then not.\"\n\n> A decision tree is a decision support hierarchical model that uses a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements.\n\n> source : https://en.wikipedia.org/wiki/Decision_tree",
            "mc_idx": 48,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Despite its simplicity, this model manages to capture a significant part of reality with a score of 0.76555! So, we will continue to model manually, i.e., without machine learning, to see if we can beat this score, which will serve as a reference to assess the relevance of our subsequent models.\n\nWe will check our basic assumption, \"women and children first,\" by building another model that predicts only women and children survive, and no men.\n\nAs we saw during the data exploration, there are many missing ages. While this is not a problem for girls, who will be included in the model among the surviving women, it's a different story for boys. Relying solely on gender and age, we will likely miss some boys.\n\n\nFortunately, during the data exploration, we determined that the title \"Master\" allows us to identify boys with certainty. We will use this feature. Also, it seems that children in the third class have less chance of survival if their family is large.",
            "mc_idx": 50,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 3.1 Decision tree \"women and children first.\" <a class=\"anchor\"  id=\"3.1\"></a>\n\nLet's see if we can improve this score by testing our basic hypothesis, 'women and children first,' adjusted by the observation that children from large families in the third class seem to have much lower chances of survival.\n\nHere is our decision tree: \"if it's a man, then no-survival; if it's a woman, then survival; if it's a boy from the first and second class, then survival; if it's a boy from the third class and a small family, then survival.\"",
            "mc_idx": 51,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Score : 0.77751\n\nWe have already significantly improved the score. However, we have not yet used some of our observations, such as the possibility of grouping women and children by family, and that these families tend to survive or not survive together, etc.\n\nEven though it is still possible to create a decision tree manually, things are starting to get more complex. It seems that now is the time to turn to 'machine learning.'",
            "mc_idx": 55,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 4. Machine Learning <a class=\"anchor\"  id=\"4\"></a>\n\nAlthough this concept is probably already familiar to you, here is a definition of Machine Learning :\n\n> The use and development of computer systems capable of learning and adapting without following explicit instructions, using algorithms and statistical models to analyze and draw conclusions from patterns in data.\n\n> source : https://www.oed.com/?tl=true",
            "mc_idx": 56,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 4.1 Feature engineering and data preprocessing. <a class=\"anchor\"  id=\"4.1\"></a>\n\n\"We have already encountered the concept of feature engineering in this notebook.\n\nData preprocessing refers to the preliminary processing steps performed on the data before using it in an analysis or model. Preprocessing may include activities such as data cleaning, normalization, dimensionality reduction, etc.\"\n\n# 4.1.1 creation of the 'isMaster' feature. <a class=\"anchor\"  id=\"4.1.1\"></a>\n\nHere we are going to create the 'isMaster' feature, as, as we have seen, the title 'Master' is much more reliable for identifying boys than gender and age, due to many missing values concerning age.",
            "mc_idx": 57,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 4.1.2 Data preprocessing. <a class=\"anchor\"  id=\"4.1.2\"></a>\n\nWe will first set aside the features that we will not use for this instance: 'PassengerId', 'Name', 'Ticket', 'Cabin', 'Surname', 'Title', 'Embarked'.\"We will first set aside the features that we will not use for this instance: 'PassengerId', 'Name', 'Ticket', 'Cabin', 'Surname', 'Title', 'Embarked'.\"\n\n* 'PassengerId': This unique identifier is not useful for the model's learning.\n\n* 'Name': The unique name of each passenger neither.\n\n* 'Ticket': We set it aside for now because, at the outset, we consider the class to be a more significant feature.\n\n* Cabin': Many missing values; here too, we currently consider this feature as redundant since, indeed, only passengers in the first and second class have a cabin, indicating a higher socio-economic status, which is already captured by the 'Pclass' feature.\n\n* 'Surname': This feature allowed us to group women and children from the same family, but for now, it is not useful.\n\n* 'Title': This feature allowed us to identify boys reliably with the title 'Master', and we have created the 'isMaster' feature for that purpose, which we will use.\n\n* 'Embarked': We observed that the embarkation city alone is not really useful for determining a chance of survival, but rather the proportion of each class at embarkation matters.\"",
            "mc_idx": 59,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Only the 'Sex' feature is a categorical variable. We will now encode it with OneHotEncoder\n\n> One-hot encoding is the process by which categorical data are converted into numerical data for use in machine learning. Categorical features are turned into binary features that are \u201cone-hot\u201d encoded, meaning that if a feature is represented by that column, it receives a 1. Otherwise, it receives a 0.\n\n> source : https://datagy.io/sklearn-one-hot-encode/",
            "mc_idx": 61,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 4.2 XGBoost and GridSearchCV <a class=\"anchor\"  id=\"4.2\"></a>\n\nHere we will use XGBoost.\n\n> XGBoost, which stands for Extreme Gradient Boosting, is a scalable, distributed gradient-boosted decision tree (GBDT) machine learning library. It provides parallel tree boosting and is the leading machine learning library for regression, classification, and ranking problems.\n\n> source : https://www.nvidia.com/en-us/glossary/data-science/xgboost/\n\nWhat is 'gradient boosting'?\n\n> Gradient boosting is a machine learning technique used in regression and classification tasks, among others. It gives a prediction model in the form of an ensemble of weak prediction models, i.e., models that make very few assumptions about the data, which are typically simple decision trees.\n\n> source : https://en.wikipedia.org/wiki/Gradient_boosting\n\nWe will therefore use this algorithm using the 'GridSearchCV' technique.\n\n> GridSearchCV is the process of performing hyperparameter tuning in order to determine the optimal values for a given model. As mentioned above, the performance of a model significantly depends on the value of hyperparameters. Note that there is no way to know in advance the best values for hyperparameters so ideally, we need to try all possible values to know the optimal values. Doing this manually could take a considerable amount of time and resources and thus we use GridSearchCV to automate the tuning of hyperparameters.\n\n> source : https://www.mygreatlearning.com/blog/gridsearchcv/\n\nFinally, we will take advantage of a very interesting feature of XGBoost.\n\n> XGBoost supports missing values by default. In tree algorithms, branch directions for missing values are learned during training.\n\n> source : https://xgboost.readthedocs.io/en/stable/faq.html\n\n\n# 4.2.1 Definition of the hyperparameters to test <a class=\"anchor\"  id=\"4.2.1\"></a>",
            "mc_idx": 65,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 4.2.2 Definition of the xgb_classifier function <a class=\"anchor\"  id=\"4.2.2\"></a>\n\nAlthough for this specific public notebook, we will not perform multiple tests, it is however considered good practice to gather all instructions within a function so that this function can be reused at will during various experiments.",
            "mc_idx": 67,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 4.2.3 Feature Selection <a class=\"anchor\"  id=\"4.2.3\"></a>\n\nWe will discard some features:\n\n* 'Age': too many missing values, we exclude it for this experiment...\n* 'SibSp' and 'Parch': redundant with FamilySize\n* 'Fare': we exclude it for this experiment as we consider that the class is sufficient\n* 'WomenChildNameFreq': this feature would have been useful for grouping women and children from the same family, but it does not seem useful for this experiment.",
            "mc_idx": 69,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 4.2.4 training <a class=\"anchor\"  id=\"4.2.4\"></a>",
            "mc_idx": 71,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 4.2.5 Submitting our predictions to Kaggle and scoring <a class=\"anchor\"  id=\"4.2.5\"></a>",
            "mc_idx": 73,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 5. Recap and How to Go Further... <a class=\"anchor\"  id=\"5\"></a>",
            "mc_idx": 75,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 5.1 How good is your score  <a class=\"anchor\"  id=\"5.1\"></a>\n\nIt is well known that cheating is very prevalent in this friendly competition, for the simple reason that the complete data regarding the Titanic is public, and we already know the fate of each passenger. The only way to learn something from this challenge is to play the game honestly. As Carl McBride Ellis emphasizes in this notebook : \n\n> https://www.kaggle.com/code/carlmcbrideellis/titanic-leaderboard-a-score-0-8-is-great\n\nSo the only way to get a good way to evaluate your own score is to compare it with public notebooks that explain the entire method used to obtain a score in a transparent manner.\n\nHowever, be careful, the scoring system on the Titanic friendly competition has evolved over time, which changes the score of a notebook depending on whether it was submitted before or after this update, as explained here:\n\n> The first update (which many of you may already be aware of) is that the leaderboard scores are not permanent, and the scores will be removed after 2 months. The second update is that the calculation of the final score - which was previously performed on a percentage of the test data - has now changed. Scores are calculated on the entire test data. Now, ideally, this should not have changed the scoring model or changed it very little, on the order of a fraction of a percentage. But did you know that the scoring model is now such that you get a score between 1 and 3% LOWER than what could have been achieved previously!\n\nand to continue :\n\n> Scores of 79% and above are GOOD: Previously, 80% was considered very good. According to the new scoring model, this is equivalent to a score of about 79% and above. So, anything above that is a GOOD performance. Don't be disappointed if you don't reach 80%, which, according to the previous scoring model, was a benchmark score.\n\n> https://www.kaggle.com/competitions/titanic/discussion/177265\n\n# 5.2  How to go further? <a class=\"anchor\"  id=\"5.2\"></a>\n\nI recommend first reading this notebook where OSCAR TAKESHITA has done an excellent job of inventorying all possible approaches as well as raising questions about paths to explore\n\n> https://www.kaggle.com/code/pliptor/how-am-i-doing-with-my-score\n\nThen you will find here the notebooks with well-documented methods and providing the best scores, both in Python and R. I want to thank especially the authors for generously sharing their knowledge and expertise.\n\n(beware that the scores indicated are those before the update of the scoring system explained above)\n\n* Divide and Conquer \n> https://www.kaggle.com/code/pliptor/divide-and-conquer-0-82296/report\n    * Score : 0.82296\n* Lasso Ridge by Bisaria\n> https://www.kaggle.com/code/bisaria/titanic-lasso-ridge-implementation/report\n    * Score : 0.82296\n* Titanic using Name only Chris Deotte achieves this great score using nothing but the Name feature! (Note from his kernel: 0.81818 with Name only and 0.82296 by adding Ticket).\n> https://www.kaggle.com/code/cdeotte/titanic-using-name-only-0-81818/notebook\n    * Score : 0.82296\n* Titanic Deep Net by Chris Deotte\n> https://www.kaggle.com/code/cdeotte/titanic-deep-net-0-82296/notebook\n    * Score : 0.82296\n* Konstantin brings attention to feature scaling, which is essential when working with the kNN algorithm.\n> https://www.kaggle.com/code/konstantinmasich/titanic-0-82-0-83/notebook\n    * Score : 0.83253\n* Titanic Mega Model Chris Deotte ensembles Kaggle\u2019s top 6 models. It starts with a neat ensembling diagram.\n> https://www.kaggle.com/code/cdeotte/titantic-mega-model-0-84210/notebook\n    * Score : 0.84210\n* Titanic WCG+XGBoost Chris Deotte Is this the ultimate Titanic model?\n> https://www.kaggle.com/code/cdeotte/titanic-wcg-xgboost-0-84688/notebook\n    * Score : 0.84688  \n\n\n\n**I would like to thank the readers of this notebook as well as all the members of the Kaggle community. Thank you all!**",
            "mc_idx": 76,
            "nb_idx": 26,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        }
    ],
    "sim_matrix": [],
    "cell_sim_matrix": [],
    "nb_order": [],
    "summary_data_VA": null
}