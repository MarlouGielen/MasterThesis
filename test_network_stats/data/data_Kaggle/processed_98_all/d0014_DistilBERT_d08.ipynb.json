{
    "nb_idx": 14,
    "nb_name": "d0014",
    "filename": "d08.ipynb",
    "filepath": "data/data_Kaggle/raw/d08.ipynb",
    "source": "I learned and combined various Kaggle submissions, hopefully using all I learned to help you learn!  You can access any of these below:\n* https://www.kaggle.com/code/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n* https://www.kaggle.com/code/nadintamer/titanic-survival-predictions-beginner\n* https://www.kaggle.com/code/ash316/eda-to-prediction-dietanic\n* https://www.kaggle.com/code/mrisdal/exploring-survival-on-the-titanic\n* https://www.kaggle.com/code/startupsci/titanic-data-science-solutions\n\nAs many of the above sites do, I'm trying to provide you an educational resource as to why things are done a certain way instead of just doing them!\nData Science (analytics/informatics/machine learning) sounds like fun to me, but, unfortunately, a majority of the time is spent in 'wrangling' the data and not just running an algorithm! \n A Data Science Framework\n1. **Define the Problem**: If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the actual problem we are trying to solve.\n\n2. **Gather the Data**: John Naisbitt wrote in his 1984 (yes, 1984) book Megatrends, we are \u201cdrowning in data, yet staving for knowledge.\" So, chances are, the dataset(s) already exist somewhere, in some format. It may be external or internal, structured or unstructured, static or streamed, objective or subjective, etc. As the saying goes, you don't have to reinvent the wheel, you just have to know where to find it. In the next step, we will worry about transforming \"dirty data\" to \"clean data.\"\n\n3. **Prepare Data for Consumption**: This step is often referred to as data wrangling, a required process to turn \u201cwild\u201d data into \u201cmanageable\u201d data. Data wrangling includes implementing data architectures for storage and processing, developing data governance standards for quality and control, data extraction (i.e. ETL and web scraping), and data cleaning to identify aberrant, missing, or outlier data points.\n\n4. **Perform Exploratory Analysis**: Anybody who has ever worked with data knows, garbage-in, garbage-out (GIGO). Therefore, it is important to deploy descriptive and graphical statistics to look for potential problems, patterns, classifications, correlations and comparisons in the dataset. In addition, data categorization (i.e. qualitative vs quantitative) is also important to understand and select the correct hypothesis test or data model.\n\n5. **Model Data**: Like descriptive and inferential statistics, data modeling can either summarize the data or predict future outcomes. Your dataset and expected results, will determine the algorithms available for use. It's important to remember, algorithms are tools and not magical wands or silver bullets. You must still be the master craft (wo)man that knows how-to select the right tool for the job. An analogy would be asking someone to hand you a Philip screwdriver, and they hand you a flathead screwdriver or worst a hammer. At best, it shows a complete lack of understanding. At worst, it makes completing the project impossible. The same is true in data modelling. The wrong model can lead to poor performance at best and the wrong conclusion (that\u2019s used as actionable intelligence) at worst.\n\n6. **Validate and Implement Data Model**: After you've trained your model based on a subset of your data, it's time to test your model. This helps ensure you haven't overfit your model or made it so specific to the selected subset, that it does not accurately fit another subset from the same dataset. In this step we determine if our [model overfit, generalize, or underfit our dataset](https://docs.aws.amazon.com/machine-learning/latest/dg/model-fit-underfitting-vs-overfitting.html)\n\n7. **Optimize and Strategize**: This is the \"bionic man\" step, where you iterate back through the process to make it better...stronger...faster than it was before. As a data scientist, your strategy should be to outsource developer operations and application plumbing, so you have more time to focus on recommendations and design. Once you're able to package your ideas, this becomes your \u201ccurrency exchange\" rate. \n **Step 1: Define the Problem**\nDevelop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n**Step 2: Gather the Data**\nThe dataset is given to us!\n\n**Step 3: Prepare Data for Consumption**\nThe data is already organized, therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are not necessary (nor do I know how). Thus, only data cleaning is in scope. \n #3.1: Load Necessary Modelling Libraries:\n\nimport numpy as np # numpy is numerical python \nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns #visualization library\n\n# There were issues last time with loading files, so hopefully this command below will give a direct link you can use for the files.\n# Train.csv is all we will use.\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename)) \n #loading the \"train\" data using pd for pandas.\ntitanicdata = pd.read_csv('/kaggle/input/titanic/train.csv')\n\n#looking at 10 random samples of the data\ntitanicdata.sample(10) \n **3.2 Meet and Greet Data**\nGet to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)).\n\nNext we use the info() and sample() function, to get a quick and dirty overview of variable datatypes (i.e. qualitative vs quantitative).  We explored all of these in Excel, but I added some bits, so check it out again!\n\n1. The *Survived* variable is our outcome or dependent variable. It is a binary nominal datatype of 1 for survived and 0 for did not survive. All other variables are potential predictor or independent variables. It's important to note, **more predictor variables do not make a better model, but the right variables will.**\n2. The *PassengerID* and *Ticket* variables are assumed to be random unique identifiers, that have no impact on the outcome variable. Thus, they will be excluded from analysis.\n3. The *Pclass* variable is an ordinal datatype for the ticket class, a proxy for socio-economic status (SES), representing 1 = upper class, 2 = middle class, and 3 = lower class.\n4. The *Name* variable is a nominal datatype. It could be used in feature engineering to derive the gender from title, family size from surname, and SES from titles like doctor or master. Since these variables already exist, we'll make use of it to see if title, like 'Master', makes a difference.\n5. The *Sex* and *Embarked* variables are a categorical, nominal datatype. They will be converted to dummy variables for mathematical calculations.\n6. The *Age* and *Fare* variable are continuous quantitative datatypes.\n7. The *SibSp* represents number of related siblings/spouse aboard and *Parch* represents number of related parents/children aboard. Both are discrete quantitative datatypes. This can be used for feature engineering to create a family size and 'is alone' variable.\n8. The *Cabin* variable is missing many values, however, later we will make this a binary variable, Cabin=1, no Cabin=0. \n #We discuss above, but we can also see the data type: integer \"int64\", categorical \"object\", or numerical \"float64\"\ntitanicdata.info() \n #easier way to see missing values--I list two commands, they do the same thing, the second is better--but just be aware of varying code!\n#NOTE: if two lines of code are written, as below, only the bottom line will display unless the print(---enter the code here---) is used.\npd.isnull(titanicdata).sum()\ntitanicdata.isnull().sum() \n There are 177 missing values for Age, 687 for Cabin, and 2 for Embarked.  Our algorithms can't work with values that are not numbers, listed as \"NaN\". So we'll need to decide what to do with these. \n #The following command gives even more information, including quartiles.  It is nice to get a distribution for the data!\n\ntitanicdata.describe(include=\"all\") \n Some of the highlights:  There are 891 unique names, as expected, only 2 sexes (as expected), the average age was 30, lots of unique tickets and Cabins, but only 3 embarked, the most common being \"S\" with 644 departing from there. \n # **3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting**\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting**: Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential outliers in age and fare. However, since they are reasonable values, we will wait until after we complete our exploratory analysis to determine if we should include or exclude from the dataset. It should be noted, that if they were unreasonable values, for example age = 800 instead of 80, then it's probably a safe decision to fix now. However, we want to use caution when we modify data from its original value, because it may be necessary to create an accurate model.\n\n2. **Completing**: There are null values or missing data in the age, cabin, and embarked field. Missing values can be bad, because some algorithms don't know how-to handle null values and will fail. While others, like decision trees, can handle null values. Thus, it's important to fix before we start modeling, in case we want to compare and contrast several models. There are two common methods, either delete the record or populate the missing value using a reasonable input. It is not recommended to delete the record, especially a large percentage of records, unless it truly represents an incomplete record. Instead, it's best to impute missing values. *A basic methodology for qualitative data is impute using mode*. *A basic methodology for quantitative data is impute using mean, median, or mean + randomized standard deviation*. An intermediate methodology is to use the basic methodology based on specific criteria; like the average age by class or embark port by fare and SES. There are more complex methodologies, however before deploying, it should be compared to the base model to determine if complexity truly adds value. Imputing age with median is easy (KISS), however, we could use the 'name' column to predict the age and get a better model (in exchange for more work!)  Embark will be imputed with mode. Subsequent model iterations may modify this decision to determine if it improves the model\u2019s accuracy.\n\n3. **Creating**: Feature engineering is when we use existing features to create new features to determine if they provide new signals to predict our outcome. For this dataset, we will create a **title** feature to determine if it played a role in survival.\n\n4. **Converting**: Last, but certainly not least, we'll deal with formatting. There are no date or currency formats, but datatype formats. Our categorical data imported as objects, which makes it difficult for mathematical calculations. For this dataset, we will convert object datatypes to categorical dummy variables.\n\n  \n **I vary from the original document at this point--I believe it is critical to incorporate step 4 \"Perform Exploratory Analysis\" alongside step 3 \"Prepare the Data\".  The reason for this is some data does not deserve our time.  For example, ticket number, there is no need to clean up this data because it does not tell us anything useful, it is just a random number assigned to people.  However, to know this we would have to do a little exploratory analysis. \nAnother example: Cabin.  Most kaggle Titanic sites I visited said \"Cabin doesn't matter\" and there is too much missign data, so just drop it.  HOWEVER, as we will soon see, those with Cabin data were more likely to survive than those without.  So, instead of eliminating the data, we will turn it binary.  \"1\" for \"has a cabin number\" and \"0\" for does not.  This will take care of all the NaN, and provide us with helpful information! \n **3.22 Clean Data** \n #simpliest first: we have two missing embarked values, we will fill them with the mode, S:\ntitanicdata['Embarked'].fillna(titanicdata['Embarked'].mode()[0], inplace = True) \n #PassengerID and Ticket number are clearly just random identifiers and have no impact on outcome--so let's delete them!\ntitanicdata.drop(['PassengerId','Ticket'],axis=1,inplace=True) \n #Next we'll look at \"Name\" though names don't tell us much, TITLES do!  Here is a command I found in multiple worksheets to extract titles!\n#This command adds a new column \"Title\" to our data:\ntitanicdata['Title']=titanicdata.Name.str.extract('([A-Za-z]+)\\.',expand=False)\n\n#nice way to see this data\ntitanicdata['Title'].value_counts() \n FYI:  Most of these titles are \"rare\" meaning there are only a few of them.  Here is where the 'art' of data science comes into play.  We can combine them in different ways.  We could take everything that is not the big four: Mr, Mrs, Master, or Miss and combine it to \"Rare\".  Or we could use a finer toothed comb and notice that some of the titles are just abbreviations of titles we already know!\n\n* Mlle: Mademoiselle, an unmarried (presumably French) woman (\"Miss.\")\n* Mme: Madame, a married (presumably French) woman (\"Mrs.\")\n* Ms: we'll assume (\"Mrs.\")\n* Countess/Lady: (\"Mrs.\") --though one could also make the argument that Countess/Lady should be filed under \"Royalty\" --important for a different reason \n #It is also nice to see this data seperated by sex:\npd.crosstab(titanicdata['Title'],titanicdata['Sex']) \n #It is nice to see the data, before replacing/regrouping these, so let's just check the ultimate goal, survivability!\npd.crosstab(titanicdata['Title'],titanicdata['Survived']) \n #We CANNOT make assumptions/conclusions off of one or two data points!  We CANNOT assume all \"Ms\" survive, though with our data subset, it is true.  Normally we have data where we find patterns so we can apply those patterns to other, newer data, so gross assumptions off of a single data point are generally not a good idea.  However, we can regroup:  Mlle, Mme, Ms, Lady, Countess as \"Mrs.\" and leave the others as rare\ntitanicdata['Title']=titanicdata['Title'].replace(['Mlle',\"Mme\",\"Lady\",\"Countess\",\"Ms\"],'Mrs')\ntitanicdata['Title']=titanicdata['Title'].replace(['Dr',\"Rev\",\"Major\",\"Col\",\"Don\",\"Sir\",\"Capt\",\"Jonkheer\"],'Rare')\n#and then look at our new data\ntitanicdata['Title'].value_counts() \n #We now no longer need \"Name\"\ntitanicdata.drop(['Name'],axis=1,inplace=True)\n#and then look at the data again\ntitanicdata.sample(10) \n #Before we tackle the missing Age values, we should ask, is it worth it?  Does Age impact survivability?  However, we can't let Age be in its current continous state--we need to BIN it.  Again, the art of data science: What size bins? / how many bins?  Should we self-select, or use technology?  I'm going to use technology and create a new column with ages in 5 bins.  HOWEVER, I can't do this with my NaN values, so I'll first create a new data set where I eliminate all 177 ageless entries...\ntitanictempdata=titanicdata[[\"Age\",\"Survived\"]]\ntitanictempdata=titanictempdata.dropna() \n #now that the NaN are (temporarily) removed, we can visualize surviability, but first we make BINS\n#Here we use \"cut\" for equal age bins (16 to 32 and 32 to 48 etc).  Later we'll use \"qcut\" for equal numbers of people in each bin.\ntitanictempdata['AgeBin'] = pd.cut(titanictempdata['Age'].astype(int), 5)\n#and then look at it\ntitanictempdata['AgeBin'].info \n sns.barplot(x=\"AgeBin\", y=\"Survived\", data=titanictempdata) \n #Younger people were more likely to survive, older, not so much.  Let's look at how many people are in each bin!\nsns.countplot(x=\"AgeBin\", data=titanictempdata) \n #Alternatively, we can use \"qcut\" to designate an equal number of people in each bin:\ntitanictemp2data=titanicdata[[\"Age\",\"Survived\"]]\ntitanictemp2data=titanictemp2data.dropna()\ntitanictemp2data['AgeBin'] = pd.qcut(titanictemp2data['Age'].astype(int), 5)\n#and then look at it\ntitanictemp2data['AgeBin'].info \n #Python has autobinned this to 0 to 19, 19 to 25, 25 to 31.8, 31.8 to 41 and 41 to 80.\nsns.barplot(x=\"AgeBin\", y=\"Survived\", data=titanictemp2data)\n#plot below still shows younger more likely to live, but lost some of the info but equalizing numbers in each bin.\n#Long story short: age does give us information on survivability, so let's do our best to fill in age values (replace all NaN) \n # Time to tackle the missing age values.  Our recent work with \"Title\" will help alot! \n #For general description\ntitanicdata[titanicdata[\"Title\"]==\"Master\"].Age.describe() \n #So--\"Master\" means between 0 and 12!  Since there are only 40 data points (36 + 4 NaN), let's take a look at this list, sorted:\ntitanicdata[titanicdata[\"Title\"]==\"Master\"].sort_values(by=['Age']) \n # Let's fill in those four NaN. We could use the median, (code for that below), or mean, 4.5 previously calculated above.\ntitanicdata[titanicdata[\"Title\"]==\"Master\"].sort_values(by=['Age'])['Age'].median() \n #I'm using mean--this command took me three hours to figure out, so enjoy it.\ntitanicdata.loc[(titanicdata.Age.isnull())&(titanicdata.Title==\"Master\"),'Age']=4.5 \n **Now we need to rinse and repeat for Mr, Miss, Mrs, Rare** \n print(\"Mr mean age:\",titanicdata[titanicdata[\"Title\"]==\"Mr\"].Age.mean())\nprint(\"Miss mean age:\",titanicdata[titanicdata[\"Title\"]==\"Miss\"].Age.mean())\nprint(\"Mrs mean age:\",titanicdata[titanicdata[\"Title\"]==\"Mrs\"].Age.mean())\nprint(\"Rare mean age:\",titanicdata[titanicdata[\"Title\"]==\"Rare\"].Age.mean()) \n titanicdata.loc[(titanicdata.Age.isnull())&(titanicdata.Title==\"Mr\"),'Age']=32.3\ntitanicdata.loc[(titanicdata.Age.isnull())&(titanicdata.Title==\"Miss\"),'Age']=21.8\ntitanicdata.loc[(titanicdata.Age.isnull())&(titanicdata.Title==\"Mrs\"),'Age']=35.6\ntitanicdata.loc[(titanicdata.Age.isnull())&(titanicdata.Title==\"Rare\"),'Age']=46 \n #Checking out our ages--no NaN (not a number) left (we now have 891 entries!)\ntitanicdata.Age.describe() \n #We're still cleaning data, but I just have to have a pretty graph, so let's look at survivability by age, here I made these bins this size, just cause.  I use \"np.inf\" for \"infinity\" but I could have just used \"85\" since the oldest person is 80.\nbins=[0,12,20,35,50,65,np.inf]\n#different bins would (obviously!) give different results, but generally \"over 50% of children were saved\" and \"under 40% of everyone else\"\n#I don't want to mess up the original data, so I'll make a new \"NewAge\" dataset:\ntitanicdataNewAge=titanicdata\nlabels = ['Child', 'Teenager', 'Young Adult', 'Adult', 'Old Adult','Senior']\ntitanicdataNewAge['AgeGroup']=pd.cut(titanicdata[\"Age\"],bins,labels=labels)\nsns.barplot(x=\"AgeGroup\", y=\"Survived\", data=titanicdataNewAge) \n #Let's move on to filling in Cabin details. There are a lot (687) missing values, BUT, the fact that there are cabins listed, actually informs surviability: check out this graphic:\n#Creating a new column and representing having a cabin as \"1\"\ntitanicdata[\"CabinBin\"]=(titanicdata[\"Cabin\"].notnull().astype('int'))\nsns.barplot(x=\"CabinBin\",y=\"Survived\",data=titanicdata) \n SO--having a cabin played a HUGE role in survivability.  Though it should be noted that half of the kaggle websites I used dropped the feature as there were too many missing values.  It is better to convert what we know to \"1\" and what we don't know to \"0\".  Next we'll drop the \"Cabin\" column. \n #Since we made a new data column, \"CabinBin\", we'll drop the old one, \"Cabin\"\ntitanicdata.drop(['Cabin'],axis=1,inplace=True) \n #wooooo--where are we? let's take a look!\ntitanicdata.sample(10) \n #Checking for NaN:\ntitanicdata.isnull().sum() \n # 3.23 Time to use some tools to create (clean-up) the rest of the data! \n #Here is an idea many data scientists used.  I wouldn't have thought of this, but those travelling alone were more likely to have not survived.  Families stick together!\n#Combining SibSp and Parch to make 'FamilySize' and 'IsAlone' if FamilySize is <2\ntitanicdata['FamilySize'] = titanicdata ['SibSp'] + titanicdata['Parch'] + 1\n#make all values 1\ntitanicdata['IsAlone'] = 1\n#turn 1s to 0s if not alone\ntitanicdata.loc[titanicdata['FamilySize'] > 1,'IsAlone'] = 0 \n #why did we do that?---familysizes of 2,3,4 had higher chance of surviving, but notsomuch for bigger families or family size 1, i.e. IsAlone\nsns.barplot(x='FamilySize',y='Survived',data=titanicdata) \n #\"0\" is Not Alone, \"1\" is Alone--roughly 30% survived\nsns.barplot(x='IsAlone',y='Survived',data=titanicdata) \n #I like to check how things are looking...\ntitanicdata.sample(10) \n #OK--I'm tired of this--let's clean up the rest and get to Exploratory Analysis and model building\n#Basically we need to convert female/male to 1/0 and mr/miss/master to 1/2/3 etc.\ntitanicdata['Sex'] = titanicdata['Sex'].map( {'female': 1, 'male': 0} ).astype(int) \n titanicdata['Embarked'] = titanicdata['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int) \n title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\ntitanicdata['Title'] = titanicdata['Title'].map(title_mapping).astype(int) \n #I killed AgeGroup at midnight last night because it was registering as categorical...BUT I FIXED IT WITH THE ADDITION OF .astype(int)\nAgeGroup_mapping = {\"Child\":1, \"Teenager\":2, \"Young Adult\":3, \"Adult\":4, \"Old Adult\":5,\"Senior\":6}\ntitanicdata['AgeGroup'] = titanicdata['AgeGroup'].map(AgeGroup_mapping).astype(int) \n #Now we can also drop the Age column\ntitanicdata.drop(['Age'],axis=1,inplace=True) \n #As we did earlier with age, we will split the Fare into Bins.  Here I'm using qcut so each bin contains roughly the same number of fares.\ntitanicdata['FareBin'] = pd.qcut(titanicdata['Fare'], 4)\nfrom sklearn.preprocessing import LabelEncoder\nlabel = LabelEncoder()\n#But then I need to adjust the bins into numbers, this command does that!\ntitanicdata['FareBin_Code'] = label.fit_transform(titanicdata['FareBin'])\n \n #and then drop Fare\ntitanicdata.drop(['Fare'],axis=1,inplace=True) \n #and then drop FareBin---should have used one command, but I already ran the one above, and I can't run it again without an error!\ntitanicdata.drop(['FareBin'],axis=1,inplace=True) \n #One last look at the data--only integers!\ntitanicdata.info()\nprint(titanicdata.sample(10)) \n #hopefully can do some more #4 exploratory at some point, but I'm tired so I'm doing models now: \n # 5: MACHINE LEARNING MODELS!\nNow we are ready to train a model and predict the required solution. There are 60+ predictive modelling algorithms to choose from. We must understand the type of problem and solution requirement to narrow down to a select few models which we can evaluate. Our problem is a classification and regression problem. We want to identify relationship between output (Survived or not) with other variables or features (Gender, Age, Title...). We are also perfoming a category of machine learning which is called supervised learning as we are training our model with a given dataset. With these two criteria - Supervised Learning plus Classification and Regression, we can narrow down our choice of models to a few. \n I wanted this picture to just be here, but I couldn't get it to work...so here's a link!\nhttps://ferrisstateuniversity-my.sharepoint.com/:i:/g/personal/troubaj_ferris_edu/EZSEiQEzaKlNhhNZpQuCn6QBX5i7D-6MCtXb7SQTl9waJg?e=LhpbMi \n ![](https://ferrisstateuniversity-my.sharepoint.com/:i:/g/personal/troubaj_ferris_edu/EZSEiQEzaKlNhhNZpQuCn6QBX5i7D-6MCtXb7SQTl9waJg?e=LhpbMi) \n X_train=titanicdata.drop(\"Survived\",axis=1)\nY_train=titanicdata[\"Survived\"] \n # Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log \n #The next model Random Forests is one of the most popular. Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees (n_estimators=100) at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.\nfrom sklearn.ensemble import RandomForestClassifier\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\n\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest \n Ahm, say what now?!? I guess 10-hours pays off!  \nNow, what really is happening is we have overfit our model.  We need to apply our random forest to new data.  Officially, Titanic data is divided into train data (what we've been using) and test data (where we actually need to apply our model).  If I have time, I'll see how this model does on the test data! \n #\n\n\n\n\nI'm leaving space for this stuff below.  I just can't delete it, it took me too long to enter.  Basically this stuff below is a VERY QUICK machine learning algorithm that deletes most columns and just lets things happen. \n #These next few commands are a sidebar--in Excel we focused on Pclass and Sex and built a model.  Let's do a quick machine learning model!\n#This command drops all the columns that aren't Pclass or Sex, and then gives a sample to see. \ntrain_df = pd.read_csv('/kaggle/input/titanic/train.csv')\nquicktrain_df = train_df.drop(['PassengerId','Name','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked'], axis=1)\nquicktrain_df.sample(5) \n #Sex is a categorical variable \"male\" or \"female\" we need it to be integer valued for our machine learning model, so we switch to binary designation:\nquicktrain_df['Sex']=quicktrain_df['Sex'].map( {'female': 1, 'male': 0} ) \n #We want to use Pclass and Sex to determine survivability (like we did in Excel) so we drop the knowledge of \"Survived\" for our input variable X_train\n# and leave \"Survived\" in for our output variable.  Note, instead of dropping \"Survived\" we could have just designated using \"Pclass\" and \"Sex\" but\n# in a bigger model we would want to use many variables and just leave the predictor out.\nX_train = quicktrain_df.drop(\"Survived\", axis=1)\nY_train = quicktrain_df[\"Survived\"] \n #This is our machine learning model, RandomForest, we'll talk about the details later\nfrom sklearn.ensemble import RandomForestClassifier\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest \n The point here is we get 78.68%--exactly the same as using excel to predict all women survived.  \nBut, we can easily go further...\nThe next command combines it all into one quick algorithm to get our highest percentage yet!  Essentially we keep SipSp (number of siblings and/or spouse aboard) and Parch (number of parents/children aboard), and let machine learning figure it out! \n quickml_df=train_df.drop(['PassengerId','Name','Age','Ticket','Fare','Cabin','Embarked'], axis=1)\nquickml_df['Sex']=quickml_df['Sex'].map( {'female': 1, 'male': 0} )\nX_train = quickml_df.drop(\"Survived\", axis=1)\nY_train = quickml_df[\"Survived\"]\nfrom sklearn.ensemble import RandomForestClassifier\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest\n",
    "code_source": "#3.1: Load Necessary Modelling Libraries:\n\nimport numpy as np # numpy is numerical python \nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns #visualization library\n\n# There were issues last time with loading files, so hopefully this command below will give a direct link you can use for the files.\n# Train.csv is all we will use.\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename)) \n #loading the \"train\" data using pd for pandas.\ntitanicdata = pd.read_csv('/kaggle/input/titanic/train.csv')\n\n#looking at 10 random samples of the data\ntitanicdata.sample(10) \n #We discuss above, but we can also see the data type: integer \"int64\", categorical \"object\", or numerical \"float64\"\ntitanicdata.info() \n #easier way to see missing values--I list two commands, they do the same thing, the second is better--but just be aware of varying code!\n#NOTE: if two lines of code are written, as below, only the bottom line will display unless the print(---enter the code here---) is used.\npd.isnull(titanicdata).sum()\ntitanicdata.isnull().sum() \n #The following command gives even more information, including quartiles.  It is nice to get a distribution for the data!\n\ntitanicdata.describe(include=\"all\") \n #simpliest first: we have two missing embarked values, we will fill them with the mode, S:\ntitanicdata['Embarked'].fillna(titanicdata['Embarked'].mode()[0], inplace = True) \n #PassengerID and Ticket number are clearly just random identifiers and have no impact on outcome--so let's delete them!\ntitanicdata.drop(['PassengerId','Ticket'],axis=1,inplace=True) \n #Next we'll look at \"Name\" though names don't tell us much, TITLES do!  Here is a command I found in multiple worksheets to extract titles!\n#This command adds a new column \"Title\" to our data:\ntitanicdata['Title']=titanicdata.Name.str.extract('([A-Za-z]+)\\.',expand=False)\n\n#nice way to see this data\ntitanicdata['Title'].value_counts() \n #It is also nice to see this data seperated by sex:\npd.crosstab(titanicdata['Title'],titanicdata['Sex']) \n #It is nice to see the data, before replacing/regrouping these, so let's just check the ultimate goal, survivability!\npd.crosstab(titanicdata['Title'],titanicdata['Survived']) \n #We CANNOT make assumptions/conclusions off of one or two data points!  We CANNOT assume all \"Ms\" survive, though with our data subset, it is true.  Normally we have data where we find patterns so we can apply those patterns to other, newer data, so gross assumptions off of a single data point are generally not a good idea.  However, we can regroup:  Mlle, Mme, Ms, Lady, Countess as \"Mrs.\" and leave the others as rare\ntitanicdata['Title']=titanicdata['Title'].replace(['Mlle',\"Mme\",\"Lady\",\"Countess\",\"Ms\"],'Mrs')\ntitanicdata['Title']=titanicdata['Title'].replace(['Dr',\"Rev\",\"Major\",\"Col\",\"Don\",\"Sir\",\"Capt\",\"Jonkheer\"],'Rare')\n#and then look at our new data\ntitanicdata['Title'].value_counts() \n #We now no longer need \"Name\"\ntitanicdata.drop(['Name'],axis=1,inplace=True)\n#and then look at the data again\ntitanicdata.sample(10) \n #Before we tackle the missing Age values, we should ask, is it worth it?  Does Age impact survivability?  However, we can't let Age be in its current continous state--we need to BIN it.  Again, the art of data science: What size bins? / how many bins?  Should we self-select, or use technology?  I'm going to use technology and create a new column with ages in 5 bins.  HOWEVER, I can't do this with my NaN values, so I'll first create a new data set where I eliminate all 177 ageless entries...\ntitanictempdata=titanicdata[[\"Age\",\"Survived\"]]\ntitanictempdata=titanictempdata.dropna() \n #now that the NaN are (temporarily) removed, we can visualize surviability, but first we make BINS\n#Here we use \"cut\" for equal age bins (16 to 32 and 32 to 48 etc).  Later we'll use \"qcut\" for equal numbers of people in each bin.\ntitanictempdata['AgeBin'] = pd.cut(titanictempdata['Age'].astype(int), 5)\n#and then look at it\ntitanictempdata['AgeBin'].info \n sns.barplot(x=\"AgeBin\", y=\"Survived\", data=titanictempdata) \n #Younger people were more likely to survive, older, not so much.  Let's look at how many people are in each bin!\nsns.countplot(x=\"AgeBin\", data=titanictempdata) \n #Alternatively, we can use \"qcut\" to designate an equal number of people in each bin:\ntitanictemp2data=titanicdata[[\"Age\",\"Survived\"]]\ntitanictemp2data=titanictemp2data.dropna()\ntitanictemp2data['AgeBin'] = pd.qcut(titanictemp2data['Age'].astype(int), 5)\n#and then look at it\ntitanictemp2data['AgeBin'].info \n #Python has autobinned this to 0 to 19, 19 to 25, 25 to 31.8, 31.8 to 41 and 41 to 80.\nsns.barplot(x=\"AgeBin\", y=\"Survived\", data=titanictemp2data)\n#plot below still shows younger more likely to live, but lost some of the info but equalizing numbers in each bin.\n#Long story short: age does give us information on survivability, so let's do our best to fill in age values (replace all NaN) \n #For general description\ntitanicdata[titanicdata[\"Title\"]==\"Master\"].Age.describe() \n #So--\"Master\" means between 0 and 12!  Since there are only 40 data points (36 + 4 NaN), let's take a look at this list, sorted:\ntitanicdata[titanicdata[\"Title\"]==\"Master\"].sort_values(by=['Age']) \n # Let's fill in those four NaN. We could use the median, (code for that below), or mean, 4.5 previously calculated above.\ntitanicdata[titanicdata[\"Title\"]==\"Master\"].sort_values(by=['Age'])['Age'].median() \n #I'm using mean--this command took me three hours to figure out, so enjoy it.\ntitanicdata.loc[(titanicdata.Age.isnull())&(titanicdata.Title==\"Master\"),'Age']=4.5 \n print(\"Mr mean age:\",titanicdata[titanicdata[\"Title\"]==\"Mr\"].Age.mean())\nprint(\"Miss mean age:\",titanicdata[titanicdata[\"Title\"]==\"Miss\"].Age.mean())\nprint(\"Mrs mean age:\",titanicdata[titanicdata[\"Title\"]==\"Mrs\"].Age.mean())\nprint(\"Rare mean age:\",titanicdata[titanicdata[\"Title\"]==\"Rare\"].Age.mean()) \n titanicdata.loc[(titanicdata.Age.isnull())&(titanicdata.Title==\"Mr\"),'Age']=32.3\ntitanicdata.loc[(titanicdata.Age.isnull())&(titanicdata.Title==\"Miss\"),'Age']=21.8\ntitanicdata.loc[(titanicdata.Age.isnull())&(titanicdata.Title==\"Mrs\"),'Age']=35.6\ntitanicdata.loc[(titanicdata.Age.isnull())&(titanicdata.Title==\"Rare\"),'Age']=46 \n #Checking out our ages--no NaN (not a number) left (we now have 891 entries!)\ntitanicdata.Age.describe() \n #We're still cleaning data, but I just have to have a pretty graph, so let's look at survivability by age, here I made these bins this size, just cause.  I use \"np.inf\" for \"infinity\" but I could have just used \"85\" since the oldest person is 80.\nbins=[0,12,20,35,50,65,np.inf]\n#different bins would (obviously!) give different results, but generally \"over 50% of children were saved\" and \"under 40% of everyone else\"\n#I don't want to mess up the original data, so I'll make a new \"NewAge\" dataset:\ntitanicdataNewAge=titanicdata\nlabels = ['Child', 'Teenager', 'Young Adult', 'Adult', 'Old Adult','Senior']\ntitanicdataNewAge['AgeGroup']=pd.cut(titanicdata[\"Age\"],bins,labels=labels)\nsns.barplot(x=\"AgeGroup\", y=\"Survived\", data=titanicdataNewAge) \n #Let's move on to filling in Cabin details. There are a lot (687) missing values, BUT, the fact that there are cabins listed, actually informs surviability: check out this graphic:\n#Creating a new column and representing having a cabin as \"1\"\ntitanicdata[\"CabinBin\"]=(titanicdata[\"Cabin\"].notnull().astype('int'))\nsns.barplot(x=\"CabinBin\",y=\"Survived\",data=titanicdata) \n #Since we made a new data column, \"CabinBin\", we'll drop the old one, \"Cabin\"\ntitanicdata.drop(['Cabin'],axis=1,inplace=True) \n #wooooo--where are we? let's take a look!\ntitanicdata.sample(10) \n #Checking for NaN:\ntitanicdata.isnull().sum() \n #Here is an idea many data scientists used.  I wouldn't have thought of this, but those travelling alone were more likely to have not survived.  Families stick together!\n#Combining SibSp and Parch to make 'FamilySize' and 'IsAlone' if FamilySize is <2\ntitanicdata['FamilySize'] = titanicdata ['SibSp'] + titanicdata['Parch'] + 1\n#make all values 1\ntitanicdata['IsAlone'] = 1\n#turn 1s to 0s if not alone\ntitanicdata.loc[titanicdata['FamilySize'] > 1,'IsAlone'] = 0 \n #why did we do that?---familysizes of 2,3,4 had higher chance of surviving, but notsomuch for bigger families or family size 1, i.e. IsAlone\nsns.barplot(x='FamilySize',y='Survived',data=titanicdata) \n #\"0\" is Not Alone, \"1\" is Alone--roughly 30% survived\nsns.barplot(x='IsAlone',y='Survived',data=titanicdata) \n #I like to check how things are looking...\ntitanicdata.sample(10) \n #OK--I'm tired of this--let's clean up the rest and get to Exploratory Analysis and model building\n#Basically we need to convert female/male to 1/0 and mr/miss/master to 1/2/3 etc.\ntitanicdata['Sex'] = titanicdata['Sex'].map( {'female': 1, 'male': 0} ).astype(int) \n titanicdata['Embarked'] = titanicdata['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int) \n title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\ntitanicdata['Title'] = titanicdata['Title'].map(title_mapping).astype(int) \n #I killed AgeGroup at midnight last night because it was registering as categorical...BUT I FIXED IT WITH THE ADDITION OF .astype(int)\nAgeGroup_mapping = {\"Child\":1, \"Teenager\":2, \"Young Adult\":3, \"Adult\":4, \"Old Adult\":5,\"Senior\":6}\ntitanicdata['AgeGroup'] = titanicdata['AgeGroup'].map(AgeGroup_mapping).astype(int) \n #Now we can also drop the Age column\ntitanicdata.drop(['Age'],axis=1,inplace=True) \n #As we did earlier with age, we will split the Fare into Bins.  Here I'm using qcut so each bin contains roughly the same number of fares.\ntitanicdata['FareBin'] = pd.qcut(titanicdata['Fare'], 4)\nfrom sklearn.preprocessing import LabelEncoder\nlabel = LabelEncoder()\n#But then I need to adjust the bins into numbers, this command does that!\ntitanicdata['FareBin_Code'] = label.fit_transform(titanicdata['FareBin'])\n \n #and then drop Fare\ntitanicdata.drop(['Fare'],axis=1,inplace=True) \n #and then drop FareBin---should have used one command, but I already ran the one above, and I can't run it again without an error!\ntitanicdata.drop(['FareBin'],axis=1,inplace=True) \n #One last look at the data--only integers!\ntitanicdata.info()\nprint(titanicdata.sample(10)) \n #hopefully can do some more #4 exploratory at some point, but I'm tired so I'm doing models now: \n X_train=titanicdata.drop(\"Survived\",axis=1)\nY_train=titanicdata[\"Survived\"] \n # Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log \n #The next model Random Forests is one of the most popular. Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees (n_estimators=100) at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.\nfrom sklearn.ensemble import RandomForestClassifier\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\n\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest \n #These next few commands are a sidebar--in Excel we focused on Pclass and Sex and built a model.  Let's do a quick machine learning model!\n#This command drops all the columns that aren't Pclass or Sex, and then gives a sample to see. \ntrain_df = pd.read_csv('/kaggle/input/titanic/train.csv')\nquicktrain_df = train_df.drop(['PassengerId','Name','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked'], axis=1)\nquicktrain_df.sample(5) \n #Sex is a categorical variable \"male\" or \"female\" we need it to be integer valued for our machine learning model, so we switch to binary designation:\nquicktrain_df['Sex']=quicktrain_df['Sex'].map( {'female': 1, 'male': 0} ) \n #We want to use Pclass and Sex to determine survivability (like we did in Excel) so we drop the knowledge of \"Survived\" for our input variable X_train\n# and leave \"Survived\" in for our output variable.  Note, instead of dropping \"Survived\" we could have just designated using \"Pclass\" and \"Sex\" but\n# in a bigger model we would want to use many variables and just leave the predictor out.\nX_train = quicktrain_df.drop(\"Survived\", axis=1)\nY_train = quicktrain_df[\"Survived\"] \n #This is our machine learning model, RandomForest, we'll talk about the details later\nfrom sklearn.ensemble import RandomForestClassifier\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest \n quickml_df=train_df.drop(['PassengerId','Name','Age','Ticket','Fare','Cabin','Embarked'], axis=1)\nquickml_df['Sex']=quickml_df['Sex'].map( {'female': 1, 'male': 0} )\nX_train = quickml_df.drop(\"Survived\", axis=1)\nY_train = quickml_df[\"Survived\"]\nfrom sklearn.ensemble import RandomForestClassifier\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest\n",
    "markdown_source": "I learned and combined various Kaggle submissions, hopefully using all I learned to help you learn!  You can access any of these below:\n* https://www.kaggle.com/code/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n* https://www.kaggle.com/code/nadintamer/titanic-survival-predictions-beginner\n* https://www.kaggle.com/code/ash316/eda-to-prediction-dietanic\n* https://www.kaggle.com/code/mrisdal/exploring-survival-on-the-titanic\n* https://www.kaggle.com/code/startupsci/titanic-data-science-solutions\n\nAs many of the above sites do, I'm trying to provide you an educational resource as to why things are done a certain way instead of just doing them!\nData Science (analytics/informatics/machine learning) sounds like fun to me, but, unfortunately, a majority of the time is spent in 'wrangling' the data and not just running an algorithm! \n A Data Science Framework\n1. **Define the Problem**: If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the actual problem we are trying to solve.\n\n2. **Gather the Data**: John Naisbitt wrote in his 1984 (yes, 1984) book Megatrends, we are \u201cdrowning in data, yet staving for knowledge.\" So, chances are, the dataset(s) already exist somewhere, in some format. It may be external or internal, structured or unstructured, static or streamed, objective or subjective, etc. As the saying goes, you don't have to reinvent the wheel, you just have to know where to find it. In the next step, we will worry about transforming \"dirty data\" to \"clean data.\"\n\n3. **Prepare Data for Consumption**: This step is often referred to as data wrangling, a required process to turn \u201cwild\u201d data into \u201cmanageable\u201d data. Data wrangling includes implementing data architectures for storage and processing, developing data governance standards for quality and control, data extraction (i.e. ETL and web scraping), and data cleaning to identify aberrant, missing, or outlier data points.\n\n4. **Perform Exploratory Analysis**: Anybody who has ever worked with data knows, garbage-in, garbage-out (GIGO). Therefore, it is important to deploy descriptive and graphical statistics to look for potential problems, patterns, classifications, correlations and comparisons in the dataset. In addition, data categorization (i.e. qualitative vs quantitative) is also important to understand and select the correct hypothesis test or data model.\n\n5. **Model Data**: Like descriptive and inferential statistics, data modeling can either summarize the data or predict future outcomes. Your dataset and expected results, will determine the algorithms available for use. It's important to remember, algorithms are tools and not magical wands or silver bullets. You must still be the master craft (wo)man that knows how-to select the right tool for the job. An analogy would be asking someone to hand you a Philip screwdriver, and they hand you a flathead screwdriver or worst a hammer. At best, it shows a complete lack of understanding. At worst, it makes completing the project impossible. The same is true in data modelling. The wrong model can lead to poor performance at best and the wrong conclusion (that\u2019s used as actionable intelligence) at worst.\n\n6. **Validate and Implement Data Model**: After you've trained your model based on a subset of your data, it's time to test your model. This helps ensure you haven't overfit your model or made it so specific to the selected subset, that it does not accurately fit another subset from the same dataset. In this step we determine if our [model overfit, generalize, or underfit our dataset](https://docs.aws.amazon.com/machine-learning/latest/dg/model-fit-underfitting-vs-overfitting.html)\n\n7. **Optimize and Strategize**: This is the \"bionic man\" step, where you iterate back through the process to make it better...stronger...faster than it was before. As a data scientist, your strategy should be to outsource developer operations and application plumbing, so you have more time to focus on recommendations and design. Once you're able to package your ideas, this becomes your \u201ccurrency exchange\" rate. \n **Step 1: Define the Problem**\nDevelop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n**Step 2: Gather the Data**\nThe dataset is given to us!\n\n**Step 3: Prepare Data for Consumption**\nThe data is already organized, therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are not necessary (nor do I know how). Thus, only data cleaning is in scope. \n **3.2 Meet and Greet Data**\nGet to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)).\n\nNext we use the info() and sample() function, to get a quick and dirty overview of variable datatypes (i.e. qualitative vs quantitative).  We explored all of these in Excel, but I added some bits, so check it out again!\n\n1. The *Survived* variable is our outcome or dependent variable. It is a binary nominal datatype of 1 for survived and 0 for did not survive. All other variables are potential predictor or independent variables. It's important to note, **more predictor variables do not make a better model, but the right variables will.**\n2. The *PassengerID* and *Ticket* variables are assumed to be random unique identifiers, that have no impact on the outcome variable. Thus, they will be excluded from analysis.\n3. The *Pclass* variable is an ordinal datatype for the ticket class, a proxy for socio-economic status (SES), representing 1 = upper class, 2 = middle class, and 3 = lower class.\n4. The *Name* variable is a nominal datatype. It could be used in feature engineering to derive the gender from title, family size from surname, and SES from titles like doctor or master. Since these variables already exist, we'll make use of it to see if title, like 'Master', makes a difference.\n5. The *Sex* and *Embarked* variables are a categorical, nominal datatype. They will be converted to dummy variables for mathematical calculations.\n6. The *Age* and *Fare* variable are continuous quantitative datatypes.\n7. The *SibSp* represents number of related siblings/spouse aboard and *Parch* represents number of related parents/children aboard. Both are discrete quantitative datatypes. This can be used for feature engineering to create a family size and 'is alone' variable.\n8. The *Cabin* variable is missing many values, however, later we will make this a binary variable, Cabin=1, no Cabin=0. \n There are 177 missing values for Age, 687 for Cabin, and 2 for Embarked.  Our algorithms can't work with values that are not numbers, listed as \"NaN\". So we'll need to decide what to do with these. \n Some of the highlights:  There are 891 unique names, as expected, only 2 sexes (as expected), the average age was 30, lots of unique tickets and Cabins, but only 3 embarked, the most common being \"S\" with 644 departing from there. \n # **3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting**\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting**: Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential outliers in age and fare. However, since they are reasonable values, we will wait until after we complete our exploratory analysis to determine if we should include or exclude from the dataset. It should be noted, that if they were unreasonable values, for example age = 800 instead of 80, then it's probably a safe decision to fix now. However, we want to use caution when we modify data from its original value, because it may be necessary to create an accurate model.\n\n2. **Completing**: There are null values or missing data in the age, cabin, and embarked field. Missing values can be bad, because some algorithms don't know how-to handle null values and will fail. While others, like decision trees, can handle null values. Thus, it's important to fix before we start modeling, in case we want to compare and contrast several models. There are two common methods, either delete the record or populate the missing value using a reasonable input. It is not recommended to delete the record, especially a large percentage of records, unless it truly represents an incomplete record. Instead, it's best to impute missing values. *A basic methodology for qualitative data is impute using mode*. *A basic methodology for quantitative data is impute using mean, median, or mean + randomized standard deviation*. An intermediate methodology is to use the basic methodology based on specific criteria; like the average age by class or embark port by fare and SES. There are more complex methodologies, however before deploying, it should be compared to the base model to determine if complexity truly adds value. Imputing age with median is easy (KISS), however, we could use the 'name' column to predict the age and get a better model (in exchange for more work!)  Embark will be imputed with mode. Subsequent model iterations may modify this decision to determine if it improves the model\u2019s accuracy.\n\n3. **Creating**: Feature engineering is when we use existing features to create new features to determine if they provide new signals to predict our outcome. For this dataset, we will create a **title** feature to determine if it played a role in survival.\n\n4. **Converting**: Last, but certainly not least, we'll deal with formatting. There are no date or currency formats, but datatype formats. Our categorical data imported as objects, which makes it difficult for mathematical calculations. For this dataset, we will convert object datatypes to categorical dummy variables.\n\n  \n **I vary from the original document at this point--I believe it is critical to incorporate step 4 \"Perform Exploratory Analysis\" alongside step 3 \"Prepare the Data\".  The reason for this is some data does not deserve our time.  For example, ticket number, there is no need to clean up this data because it does not tell us anything useful, it is just a random number assigned to people.  However, to know this we would have to do a little exploratory analysis. \nAnother example: Cabin.  Most kaggle Titanic sites I visited said \"Cabin doesn't matter\" and there is too much missign data, so just drop it.  HOWEVER, as we will soon see, those with Cabin data were more likely to survive than those without.  So, instead of eliminating the data, we will turn it binary.  \"1\" for \"has a cabin number\" and \"0\" for does not.  This will take care of all the NaN, and provide us with helpful information! \n **3.22 Clean Data** \n FYI:  Most of these titles are \"rare\" meaning there are only a few of them.  Here is where the 'art' of data science comes into play.  We can combine them in different ways.  We could take everything that is not the big four: Mr, Mrs, Master, or Miss and combine it to \"Rare\".  Or we could use a finer toothed comb and notice that some of the titles are just abbreviations of titles we already know!\n\n* Mlle: Mademoiselle, an unmarried (presumably French) woman (\"Miss.\")\n* Mme: Madame, a married (presumably French) woman (\"Mrs.\")\n* Ms: we'll assume (\"Mrs.\")\n* Countess/Lady: (\"Mrs.\") --though one could also make the argument that Countess/Lady should be filed under \"Royalty\" --important for a different reason \n # Time to tackle the missing age values.  Our recent work with \"Title\" will help alot! \n **Now we need to rinse and repeat for Mr, Miss, Mrs, Rare** \n SO--having a cabin played a HUGE role in survivability.  Though it should be noted that half of the kaggle websites I used dropped the feature as there were too many missing values.  It is better to convert what we know to \"1\" and what we don't know to \"0\".  Next we'll drop the \"Cabin\" column. \n # 3.23 Time to use some tools to create (clean-up) the rest of the data! \n # 5: MACHINE LEARNING MODELS!\nNow we are ready to train a model and predict the required solution. There are 60+ predictive modelling algorithms to choose from. We must understand the type of problem and solution requirement to narrow down to a select few models which we can evaluate. Our problem is a classification and regression problem. We want to identify relationship between output (Survived or not) with other variables or features (Gender, Age, Title...). We are also perfoming a category of machine learning which is called supervised learning as we are training our model with a given dataset. With these two criteria - Supervised Learning plus Classification and Regression, we can narrow down our choice of models to a few. \n I wanted this picture to just be here, but I couldn't get it to work...so here's a link!\nhttps://ferrisstateuniversity-my.sharepoint.com/:i:/g/personal/troubaj_ferris_edu/EZSEiQEzaKlNhhNZpQuCn6QBX5i7D-6MCtXb7SQTl9waJg?e=LhpbMi \n ![](https://ferrisstateuniversity-my.sharepoint.com/:i:/g/personal/troubaj_ferris_edu/EZSEiQEzaKlNhhNZpQuCn6QBX5i7D-6MCtXb7SQTl9waJg?e=LhpbMi) \n Ahm, say what now?!? I guess 10-hours pays off!  \nNow, what really is happening is we have overfit our model.  We need to apply our random forest to new data.  Officially, Titanic data is divided into train data (what we've been using) and test data (where we actually need to apply our model).  If I have time, I'll see how this model does on the test data! \n #\n\n\n\n\nI'm leaving space for this stuff below.  I just can't delete it, it took me too long to enter.  Basically this stuff below is a VERY QUICK machine learning algorithm that deletes most columns and just lets things happen. \n The point here is we get 78.68%--exactly the same as using excel to predict all women survived.  \nBut, we can easily go further...\nThe next command combines it all into one quick algorithm to get our highest percentage yet!  Essentially we keep SipSp (number of siblings and/or spouse aboard) and Parch (number of parents/children aboard), and let machine learning figure it out!",
    "n_cells": 72,
    "n_code_cells": 52,
    "n_markdown_cells": 20,
    "n_raw_cells": 0,
    "n_outputs": 52,
    "r_code_cells": 0.7222222222222222,
    "r_markdown_cells": 0.2777777777777778,
    "r_raw_cells": 0.0,
    "r_outputs": 1.0,
    "n_exceptions": 0,
    "r_exceptions": 0.0,
    "n_lines": 278,
    "n_lines_code": 191,
    "n_lines_markdown": 87,
    "lines_per_cell": [
        9,
        14,
        8,
        13,
        5,
        13,
        2,
        4,
        1,
        3,
        1,
        12,
        2,
        1,
        2,
        2,
        6,
        6,
        2,
        2,
        5,
        4,
        3,
        5,
        1,
        2,
        6,
        4,
        1,
        2,
        2,
        2,
        2,
        1,
        4,
        4,
        2,
        8,
        4,
        1,
        2,
        2,
        2,
        1,
        7,
        2,
        2,
        2,
        3,
        1,
        2,
        3,
        2,
        7,
        2,
        2,
        3,
        1,
        2,
        2,
        1,
        2,
        6,
        9,
        2,
        6,
        5,
        2,
        5,
        6,
        3,
        10
    ],
    "lines_per_code_cell": [
        13,
        5,
        2,
        4,
        3,
        2,
        2,
        6,
        2,
        2,
        5,
        4,
        3,
        5,
        1,
        2,
        6,
        4,
        2,
        2,
        2,
        2,
        4,
        4,
        2,
        8,
        4,
        2,
        2,
        2,
        7,
        2,
        2,
        2,
        3,
        1,
        2,
        3,
        2,
        7,
        2,
        2,
        3,
        1,
        2,
        6,
        9,
        5,
        2,
        5,
        6,
        10
    ],
    "lines_per_markdown_cell": [
        9,
        14,
        8,
        13,
        1,
        1,
        12,
        2,
        1,
        6,
        1,
        1,
        1,
        1,
        2,
        2,
        1,
        2,
        6,
        3
    ],
    "ave_lines_per_cell": 3.861111111111111,
    "ave_lines_per_code_cell": 3.673076923076923,
    "ave_lines_per_markdown_cell": 4.35,
    "max_lines_per_cell": 14,
    "max_lines_per_code_cell": 13,
    "max_lines_per_markdown_cell": 14,
    "min_lines_per_cell": 1,
    "min_lines_per_code_cell": 1,
    "min_lines_per_markdown_cell": 1,
    "n_chars": 27683,
    "n_chars_code": 13160,
    "n_chars_markdown": 14523,
    "chars_per_cell": [
        849,
        3595,
        421,
        516,
        173,
        2060,
        134,
        330,
        197,
        157,
        230,
        2964,
        896,
        19,
        172,
        182,
        336,
        713,
        104,
        175,
        698,
        132,
        584,
        356,
        59,
        160,
        307,
        389,
        86,
        83,
        196,
        205,
        161,
        59,
        301,
        326,
        104,
        745,
        369,
        294,
        125,
        64,
        45,
        72,
        463,
        198,
        108,
        65,
        264,
        93,
        145,
        317,
        82,
        414,
        66,
        180,
        91,
        96,
        737,
        226,
        142,
        75,
        197,
        683,
        358,
        226,
        435,
        223,
        473,
        322,
        379,
        482
    ],
    "chars_per_code_cell": [
        516,
        173,
        134,
        330,
        157,
        172,
        182,
        336,
        104,
        175,
        698,
        132,
        584,
        356,
        59,
        160,
        307,
        389,
        83,
        196,
        205,
        161,
        301,
        326,
        104,
        745,
        369,
        125,
        64,
        45,
        463,
        198,
        108,
        65,
        264,
        93,
        145,
        317,
        82,
        414,
        66,
        180,
        91,
        96,
        75,
        197,
        683,
        435,
        223,
        473,
        322,
        482
    ],
    "chars_per_markdown_cell": [
        849,
        3595,
        421,
        2060,
        197,
        230,
        2964,
        896,
        19,
        713,
        86,
        59,
        294,
        72,
        737,
        226,
        142,
        358,
        226,
        379
    ],
    "ave_chars_per_line": 99.57913669064749,
    "ave_chars_per_cell": 384.4861111111111,
    "ave_chars_per_code_cell": 253.07692307692307,
    "ave_chars_per_markdown_cell": 726.15,
    "max_chars_per_cell": 3595,
    "max_chars_per_code_cell": 745,
    "max_chars_per_markdownell": 3595,
    "min_chars_per_cell": 19,
    "min_chars_per_code_cell": 45,
    "min_chars_per_markdown_cell": 19,
    "r_lines_code": 0.6870503597122302,
    "r_lines_markdown": 0.3129496402877698,
    "r_chars_markdown": 0.5246179966044142,
    "r_chars_code": 0.47538200339558573,
    "all_cells": [
        {
            "source": "I learned and combined various Kaggle submissions, hopefully using all I learned to help you learn!  You can access any of these below:\n* https://www.kaggle.com/code/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n* https://www.kaggle.com/code/nadintamer/titanic-survival-predictions-beginner\n* https://www.kaggle.com/code/ash316/eda-to-prediction-dietanic\n* https://www.kaggle.com/code/mrisdal/exploring-survival-on-the-titanic\n* https://www.kaggle.com/code/startupsci/titanic-data-science-solutions\n\nAs many of the above sites do, I'm trying to provide you an educational resource as to why things are done a certain way instead of just doing them!\nData Science (analytics/informatics/machine learning) sounds like fun to me, but, unfortunately, a majority of the time is spent in 'wrangling' the data and not just running an algorithm!",
            "mc_idx": 0,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "A Data Science Framework\n1. **Define the Problem**: If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the actual problem we are trying to solve.\n\n2. **Gather the Data**: John Naisbitt wrote in his 1984 (yes, 1984) book Megatrends, we are \u201cdrowning in data, yet staving for knowledge.\" So, chances are, the dataset(s) already exist somewhere, in some format. It may be external or internal, structured or unstructured, static or streamed, objective or subjective, etc. As the saying goes, you don't have to reinvent the wheel, you just have to know where to find it. In the next step, we will worry about transforming \"dirty data\" to \"clean data.\"\n\n3. **Prepare Data for Consumption**: This step is often referred to as data wrangling, a required process to turn \u201cwild\u201d data into \u201cmanageable\u201d data. Data wrangling includes implementing data architectures for storage and processing, developing data governance standards for quality and control, data extraction (i.e. ETL and web scraping), and data cleaning to identify aberrant, missing, or outlier data points.\n\n4. **Perform Exploratory Analysis**: Anybody who has ever worked with data knows, garbage-in, garbage-out (GIGO). Therefore, it is important to deploy descriptive and graphical statistics to look for potential problems, patterns, classifications, correlations and comparisons in the dataset. In addition, data categorization (i.e. qualitative vs quantitative) is also important to understand and select the correct hypothesis test or data model.\n\n5. **Model Data**: Like descriptive and inferential statistics, data modeling can either summarize the data or predict future outcomes. Your dataset and expected results, will determine the algorithms available for use. It's important to remember, algorithms are tools and not magical wands or silver bullets. You must still be the master craft (wo)man that knows how-to select the right tool for the job. An analogy would be asking someone to hand you a Philip screwdriver, and they hand you a flathead screwdriver or worst a hammer. At best, it shows a complete lack of understanding. At worst, it makes completing the project impossible. The same is true in data modelling. The wrong model can lead to poor performance at best and the wrong conclusion (that\u2019s used as actionable intelligence) at worst.\n\n6. **Validate and Implement Data Model**: After you've trained your model based on a subset of your data, it's time to test your model. This helps ensure you haven't overfit your model or made it so specific to the selected subset, that it does not accurately fit another subset from the same dataset. In this step we determine if our [model overfit, generalize, or underfit our dataset](https://docs.aws.amazon.com/machine-learning/latest/dg/model-fit-underfitting-vs-overfitting.html)\n\n7. **Optimize and Strategize**: This is the \"bionic man\" step, where you iterate back through the process to make it better...stronger...faster than it was before. As a data scientist, your strategy should be to outsource developer operations and application plumbing, so you have more time to focus on recommendations and design. Once you're able to package your ideas, this becomes your \u201ccurrency exchange\" rate.",
            "mc_idx": 1,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Step 1: Define the Problem**\nDevelop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n**Step 2: Gather the Data**\nThe dataset is given to us!\n\n**Step 3: Prepare Data for Consumption**\nThe data is already organized, therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are not necessary (nor do I know how). Thus, only data cleaning is in scope.",
            "mc_idx": 2,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#3.1: Load Necessary Modelling Libraries:\n\nimport numpy as np # numpy is numerical python \nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns #visualization library\n\n# There were issues last time with loading files, so hopefully this command below will give a direct link you can use for the files.\n# Train.csv is all we will use.\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))",
            "mc_idx": 3,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0975609756097561,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.04878048780487805,
                "Model_Train": 0.024390243902439025,
                "Model_Evaluation": 0.024390243902439025,
                "Model_Interpretation": 0.024390243902439025,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 4
                },
                "Data_Extraction": {
                    "read_csv": 2,
                    "pd.read_": 2
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".join(": 1,
                    ".join": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    0,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n"
                    ]
                },
                "mc_idx": 3,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 0,
                "o_idx": 0
            }
        },
        {
            "source": "#loading the \"train\" data using pd for pandas.\ntitanicdata = pd.read_csv('/kaggle/input/titanic/train.csv')\n\n#looking at 10 random samples of the data\ntitanicdata.sample(10)",
            "mc_idx": 4,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 2,
                    "pd.read_": 2
                },
                "Exploratory_Data_Analysis": {
                    ".sample": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    1,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "     PassengerId  Survived  Pclass                            Name     Sex  \\\n859          860         0       3                Razi, Mr. Raihed    male   \n560          561         0       3        Morrow, Mr. Thomas Rowan    male   \n484          485         1       1         Bishop, Mr. Dickinson H    male   \n124          125         0       1     White, Mr. Percival Wayland    male   \n579          580         1       3             Jussila, Mr. Eiriik    male   \n623          624         0       3     Hansen, Mr. Henry Damsgaard    male   \n713          714         0       3      Larsson, Mr. August Viktor    male   \n496          497         1       1  Eustis, Miss. Elizabeth Mussey  female   \n886          887         0       2           Montvila, Rev. Juozas    male   \n95            96         0       3     Shorney, Mr. Charles Joseph    male   \n\n      Age  SibSp  Parch             Ticket     Fare Cabin Embarked  \n859   NaN      0      0               2629   7.2292   NaN        C  \n560   NaN      0      0             372622   7.7500   NaN        Q  \n484  25.0      1      0              11967  91.0792   B49        C  \n124  54.0      0      1              35281  77.2875   D26        S  \n579  32.0      0      0  STON/O 2. 3101286   7.9250   NaN        S  \n623  21.0      0      0             350029   7.8542   NaN        S  \n713  29.0      0      0               7545   9.4833   NaN        S  \n496  54.0      1      0              36947  78.2667   D20        C  \n886  27.0      0      0             211536  13.0000   NaN        S  \n95    NaN      0      0             374910   8.0500   NaN        S  "
                    ]
                },
                "mc_idx": 4,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 1,
                "o_idx": 0
            }
        },
        {
            "source": "**3.2 Meet and Greet Data**\nGet to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)).\n\nNext we use the info() and sample() function, to get a quick and dirty overview of variable datatypes (i.e. qualitative vs quantitative).  We explored all of these in Excel, but I added some bits, so check it out again!\n\n1. The *Survived* variable is our outcome or dependent variable. It is a binary nominal datatype of 1 for survived and 0 for did not survive. All other variables are potential predictor or independent variables. It's important to note, **more predictor variables do not make a better model, but the right variables will.**\n2. The *PassengerID* and *Ticket* variables are assumed to be random unique identifiers, that have no impact on the outcome variable. Thus, they will be excluded from analysis.\n3. The *Pclass* variable is an ordinal datatype for the ticket class, a proxy for socio-economic status (SES), representing 1 = upper class, 2 = middle class, and 3 = lower class.\n4. The *Name* variable is a nominal datatype. It could be used in feature engineering to derive the gender from title, family size from surname, and SES from titles like doctor or master. Since these variables already exist, we'll make use of it to see if title, like 'Master', makes a difference.\n5. The *Sex* and *Embarked* variables are a categorical, nominal datatype. They will be converted to dummy variables for mathematical calculations.\n6. The *Age* and *Fare* variable are continuous quantitative datatypes.\n7. The *SibSp* represents number of related siblings/spouse aboard and *Parch* represents number of related parents/children aboard. Both are discrete quantitative datatypes. This can be used for feature engineering to create a family size and 'is alone' variable.\n8. The *Cabin* variable is missing many values, however, later we will make this a binary variable, Cabin=1, no Cabin=0.",
            "mc_idx": 5,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#We discuss above, but we can also see the data type: integer \"int64\", categorical \"object\", or numerical \"float64\"\ntitanicdata.info()",
            "mc_idx": 6,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".info(": 1,
                    "info": 1,
                    ".info": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    2,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n"
                    ]
                },
                "mc_idx": 6,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 2,
                "o_idx": 0
            }
        },
        {
            "source": "#easier way to see missing values--I list two commands, they do the same thing, the second is better--but just be aware of varying code!\n#NOTE: if two lines of code are written, as below, only the bottom line will display unless the print(---enter the code here---) is used.\npd.isnull(titanicdata).sum()\ntitanicdata.isnull().sum()",
            "mc_idx": 7,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "missing values": 1,
                    ".isnull": 2,
                    ".sum": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    3,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "PassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64"
                    ]
                },
                "mc_idx": 7,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 3,
                "o_idx": 0
            }
        },
        {
            "source": "There are 177 missing values for Age, 687 for Cabin, and 2 for Embarked.  Our algorithms can't work with values that are not numbers, listed as \"NaN\". So we'll need to decide what to do with these.",
            "mc_idx": 8,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#The following command gives even more information, including quartiles.  It is nice to get a distribution for the data!\n\ntitanicdata.describe(include=\"all\")",
            "mc_idx": 9,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".describe(": 1,
                    "info": 1,
                    "describe": 1,
                    ".describe": 1
                },
                "Data_Transform": {
                    "tile": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    4,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "        PassengerId    Survived      Pclass                     Name   Sex  \\\ncount    891.000000  891.000000  891.000000                      891   891   \nunique          NaN         NaN         NaN                      891     2   \ntop             NaN         NaN         NaN  Braund, Mr. Owen Harris  male   \nfreq            NaN         NaN         NaN                        1   577   \nmean     446.000000    0.383838    2.308642                      NaN   NaN   \nstd      257.353842    0.486592    0.836071                      NaN   NaN   \nmin        1.000000    0.000000    1.000000                      NaN   NaN   \n25%      223.500000    0.000000    2.000000                      NaN   NaN   \n50%      446.000000    0.000000    3.000000                      NaN   NaN   \n75%      668.500000    1.000000    3.000000                      NaN   NaN   \nmax      891.000000    1.000000    3.000000                      NaN   NaN   \n\n               Age       SibSp       Parch  Ticket        Fare    Cabin  \\\ncount   714.000000  891.000000  891.000000     891  891.000000      204   \nunique         NaN         NaN         NaN     681         NaN      147   \ntop            NaN         NaN         NaN  347082         NaN  B96 B98   \nfreq           NaN         NaN         NaN       7         NaN        4   \nmean     29.699118    0.523008    0.381594     NaN   32.204208      NaN   \nstd      14.526497    1.102743    0.806057     NaN   49.693429      NaN   \nmin       0.420000    0.000000    0.000000     NaN    0.000000      NaN   \n25%      20.125000    0.000000    0.000000     NaN    7.910400      NaN   \n50%      28.000000    0.000000    0.000000     NaN   14.454200      NaN   \n75%      38.000000    1.000000    0.000000     NaN   31.000000      NaN   \nmax      80.000000    8.000000    6.000000     NaN  512.329200      NaN   \n\n       Embarked  \ncount       889  \nunique        3  \ntop           S  \nfreq        644  \nmean        NaN  \nstd         NaN  \nmin         NaN  \n25%         NaN  \n50%         NaN  \n75%         NaN  \nmax         NaN  "
                    ]
                },
                "mc_idx": 9,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 4,
                "o_idx": 0
            }
        },
        {
            "source": "Some of the highlights:  There are 891 unique names, as expected, only 2 sexes (as expected), the average age was 30, lots of unique tickets and Cabins, but only 3 embarked, the most common being \"S\" with 644 departing from there.",
            "mc_idx": 10,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# **3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting**\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting**: Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential outliers in age and fare. However, since they are reasonable values, we will wait until after we complete our exploratory analysis to determine if we should include or exclude from the dataset. It should be noted, that if they were unreasonable values, for example age = 800 instead of 80, then it's probably a safe decision to fix now. However, we want to use caution when we modify data from its original value, because it may be necessary to create an accurate model.\n\n2. **Completing**: There are null values or missing data in the age, cabin, and embarked field. Missing values can be bad, because some algorithms don't know how-to handle null values and will fail. While others, like decision trees, can handle null values. Thus, it's important to fix before we start modeling, in case we want to compare and contrast several models. There are two common methods, either delete the record or populate the missing value using a reasonable input. It is not recommended to delete the record, especially a large percentage of records, unless it truly represents an incomplete record. Instead, it's best to impute missing values. *A basic methodology for qualitative data is impute using mode*. *A basic methodology for quantitative data is impute using mean, median, or mean + randomized standard deviation*. An intermediate methodology is to use the basic methodology based on specific criteria; like the average age by class or embark port by fare and SES. There are more complex methodologies, however before deploying, it should be compared to the base model to determine if complexity truly adds value. Imputing age with median is easy (KISS), however, we could use the 'name' column to predict the age and get a better model (in exchange for more work!)  Embark will be imputed with mode. Subsequent model iterations may modify this decision to determine if it improves the model\u2019s accuracy.\n\n3. **Creating**: Feature engineering is when we use existing features to create new features to determine if they provide new signals to predict our outcome. For this dataset, we will create a **title** feature to determine if it played a role in survival.\n\n4. **Converting**: Last, but certainly not least, we'll deal with formatting. There are no date or currency formats, but datatype formats. Our categorical data imported as objects, which makes it difficult for mathematical calculations. For this dataset, we will convert object datatypes to categorical dummy variables.\n\n ",
            "mc_idx": 11,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**I vary from the original document at this point--I believe it is critical to incorporate step 4 \"Perform Exploratory Analysis\" alongside step 3 \"Prepare the Data\".  The reason for this is some data does not deserve our time.  For example, ticket number, there is no need to clean up this data because it does not tell us anything useful, it is just a random number assigned to people.  However, to know this we would have to do a little exploratory analysis. \nAnother example: Cabin.  Most kaggle Titanic sites I visited said \"Cabin doesn't matter\" and there is too much missign data, so just drop it.  HOWEVER, as we will soon see, those with Cabin data were more likely to survive than those without.  So, instead of eliminating the data, we will turn it binary.  \"1\" for \"has a cabin number\" and \"0\" for does not.  This will take care of all the NaN, and provide us with helpful information!",
            "mc_idx": 12,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**3.22 Clean Data**",
            "mc_idx": 13,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#simpliest first: we have two missing embarked values, we will fill them with the mode, S:\ntitanicdata['Embarked'].fillna(titanicdata['Embarked'].mode()[0], inplace = True)",
            "mc_idx": 14,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mode": 1
                },
                "Data_Transform": {
                    ".fillna(": 1,
                    ".fillna": 1,
                    ".mod": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    5,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 14,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 5,
                "o_idx": 0
            }
        },
        {
            "source": "#PassengerID and Ticket number are clearly just random identifiers and have no impact on outcome--so let's delete them!\ntitanicdata.drop(['PassengerId','Ticket'],axis=1,inplace=True)",
            "mc_idx": 15,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "impact": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    6,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 15,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 6,
                "o_idx": 0
            }
        },
        {
            "source": "#Next we'll look at \"Name\" though names don't tell us much, TITLES do!  Here is a command I found in multiple worksheets to extract titles!\n#This command adds a new column \"Title\" to our data:\ntitanicdata['Title']=titanicdata.Name.str.extract('([A-Za-z]+)\\.',expand=False)\n\n#nice way to see this data\ntitanicdata['Title'].value_counts()",
            "mc_idx": 16,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "extract": 2
                },
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    7,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Title\nMr          517\nMiss        182\nMrs         125\nMaster       40\nDr            7\nRev           6\nMlle          2\nMajor         2\nCol           2\nCountess      1\nCapt          1\nMs            1\nSir           1\nLady          1\nMme           1\nDon           1\nJonkheer      1\nName: count, dtype: int64"
                    ]
                },
                "mc_idx": 16,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 7,
                "o_idx": 0
            }
        },
        {
            "source": "FYI:  Most of these titles are \"rare\" meaning there are only a few of them.  Here is where the 'art' of data science comes into play.  We can combine them in different ways.  We could take everything that is not the big four: Mr, Mrs, Master, or Miss and combine it to \"Rare\".  Or we could use a finer toothed comb and notice that some of the titles are just abbreviations of titles we already know!\n\n* Mlle: Mademoiselle, an unmarried (presumably French) woman (\"Miss.\")\n* Mme: Madame, a married (presumably French) woman (\"Mrs.\")\n* Ms: we'll assume (\"Mrs.\")\n* Countess/Lady: (\"Mrs.\") --though one could also make the argument that Countess/Lady should be filed under \"Royalty\" --important for a different reason",
            "mc_idx": 17,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#It is also nice to see this data seperated by sex:\npd.crosstab(titanicdata['Title'],titanicdata['Sex'])",
            "mc_idx": 18,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".cross": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    8,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Sex       female  male\nTitle                 \nCapt           0     1\nCol            0     2\nCountess       1     0\nDon            0     1\nDr             1     6\nJonkheer       0     1\nLady           1     0\nMajor          0     2\nMaster         0    40\nMiss         182     0\nMlle           2     0\nMme            1     0\nMr             0   517\nMrs          125     0\nMs             1     0\nRev            0     6\nSir            0     1"
                    ]
                },
                "mc_idx": 18,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 8,
                "o_idx": 0
            }
        },
        {
            "source": "#It is nice to see the data, before replacing/regrouping these, so let's just check the ultimate goal, survivability!\npd.crosstab(titanicdata['Title'],titanicdata['Survived'])",
            "mc_idx": 19,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".cross": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    9,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Survived    0    1\nTitle             \nCapt        1    0\nCol         1    1\nCountess    0    1\nDon         1    0\nDr          4    3\nJonkheer    1    0\nLady        0    1\nMajor       1    1\nMaster     17   23\nMiss       55  127\nMlle        0    2\nMme         0    1\nMr        436   81\nMrs        26   99\nMs          0    1\nRev         6    0\nSir         0    1"
                    ]
                },
                "mc_idx": 19,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 9,
                "o_idx": 0
            }
        },
        {
            "source": "#We CANNOT make assumptions/conclusions off of one or two data points!  We CANNOT assume all \"Ms\" survive, though with our data subset, it is true.  Normally we have data where we find patterns so we can apply those patterns to other, newer data, so gross assumptions off of a single data point are generally not a good idea.  However, we can regroup:  Mlle, Mme, Ms, Lady, Countess as \"Mrs.\" and leave the others as rare\ntitanicdata['Title']=titanicdata['Title'].replace(['Mlle',\"Mme\",\"Lady\",\"Countess\",\"Ms\"],'Mrs')\ntitanicdata['Title']=titanicdata['Title'].replace(['Dr',\"Rev\",\"Major\",\"Col\",\"Don\",\"Sir\",\"Capt\",\"Jonkheer\"],'Rare')\n#and then look at our new data\ntitanicdata['Title'].value_counts()",
            "mc_idx": 20,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    ".value_counts": 1
                },
                "Data_Transform": {
                    ".replace(": 2,
                    ".replace": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    10,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Title\nMr        517\nMiss      182\nMrs       131\nMaster     40\nRare       21\nName: count, dtype: int64"
                    ]
                },
                "mc_idx": 20,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 10,
                "o_idx": 0
            }
        },
        {
            "source": "#We now no longer need \"Name\"\ntitanicdata.drop(['Name'],axis=1,inplace=True)\n#and then look at the data again\ntitanicdata.sample(10)",
            "mc_idx": 21,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".sample": 1
                },
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    11,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "     Survived  Pclass     Sex   Age  SibSp  Parch     Fare    Cabin Embarked  \\\n530         1       2  female   2.0      1      1  26.0000      NaN        S   \n771         0       3    male  48.0      0      0   7.8542      NaN        S   \n147         0       3  female   9.0      2      2  34.3750      NaN        S   \n643         1       3    male   NaN      0      0  56.4958      NaN        S   \n633         0       1    male   NaN      0      0   0.0000      NaN        S   \n595         0       3    male  36.0      1      1  24.1500      NaN        S   \n797         1       3  female  31.0      0      0   8.6833      NaN        S   \n366         1       1  female  60.0      1      0  75.2500      D37        C   \n97          1       1    male  23.0      0      1  63.3583  D10 D12        C   \n723         0       2    male  50.0      0      0  13.0000      NaN        S   \n\n    Title  \n530  Miss  \n771    Mr  \n147  Miss  \n643    Mr  \n633    Mr  \n595    Mr  \n797   Mrs  \n366   Mrs  \n97     Mr  \n723    Mr  "
                    ]
                },
                "mc_idx": 21,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 11,
                "o_idx": 0
            }
        },
        {
            "source": "#Before we tackle the missing Age values, we should ask, is it worth it?  Does Age impact survivability?  However, we can't let Age be in its current continous state--we need to BIN it.  Again, the art of data science: What size bins? / how many bins?  Should we self-select, or use technology?  I'm going to use technology and create a new column with ages in 5 bins.  HOWEVER, I can't do this with my NaN values, so I'll first create a new data set where I eliminate all 177 ageless entries...\ntitanictempdata=titanicdata[[\"Age\",\"Survived\"]]\ntitanictempdata=titanictempdata.dropna()",
            "mc_idx": 22,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.3333333333333333,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {
                    ".dropna(": 1,
                    ".drop": 1,
                    ".dropna": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "impact": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    12,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 22,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 12,
                "o_idx": 0
            }
        },
        {
            "source": "#now that the NaN are (temporarily) removed, we can visualize surviability, but first we make BINS\n#Here we use \"cut\" for equal age bins (16 to 32 and 32 to 48 etc).  Later we'll use \"qcut\" for equal numbers of people in each bin.\ntitanictempdata['AgeBin'] = pd.cut(titanictempdata['Age'].astype(int), 5)\n#and then look at it\ntitanictempdata['AgeBin'].info",
            "mc_idx": 23,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.6666666666666666,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.3333333333333333,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "info": 1,
                    ".info": 1
                },
                "Data_Transform": {
                    ".astype(": 1,
                    ".cut(": 1,
                    ".cut": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "visualize": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    13,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<bound method Series.info of 0      (16.0, 32.0]\n1      (32.0, 48.0]\n2      (16.0, 32.0]\n3      (32.0, 48.0]\n4      (32.0, 48.0]\n           ...     \n885    (32.0, 48.0]\n886    (16.0, 32.0]\n887    (16.0, 32.0]\n889    (16.0, 32.0]\n890    (16.0, 32.0]\nName: AgeBin, Length: 714, dtype: category\nCategories (5, interval[float64, right]): [(-0.08, 16.0] < (16.0, 32.0] < (32.0, 48.0] < (48.0, 64.0] < (64.0, 80.0]]>"
                    ]
                },
                "mc_idx": 23,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 13,
                "o_idx": 0
            }
        },
        {
            "source": "sns.barplot(x=\"AgeBin\", y=\"Survived\", data=titanictempdata)",
            "mc_idx": 24,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0014_c014_o001_image_0.png",
                    14,
                    1,
                    0
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Axes: xlabel='AgeBin', ylabel='Survived'>",
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 24,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 14,
                "o_idx": 1
            }
        },
        {
            "source": "#Younger people were more likely to survive, older, not so much.  Let's look at how many people are in each bin!\nsns.countplot(x=\"AgeBin\", data=titanictempdata)",
            "mc_idx": 25,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0014_c015_o001_image_1.png",
                    15,
                    1,
                    1
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Axes: xlabel='AgeBin', ylabel='count'>",
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 25,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 15,
                "o_idx": 1
            }
        },
        {
            "source": "#Alternatively, we can use \"qcut\" to designate an equal number of people in each bin:\ntitanictemp2data=titanicdata[[\"Age\",\"Survived\"]]\ntitanictemp2data=titanictemp2data.dropna()\ntitanictemp2data['AgeBin'] = pd.qcut(titanictemp2data['Age'].astype(int), 5)\n#and then look at it\ntitanictemp2data['AgeBin'].info",
            "mc_idx": 26,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "info": 1,
                    ".info": 1
                },
                "Data_Transform": {
                    ".dropna(": 1,
                    ".astype(": 1,
                    ".qcut(": 1,
                    ".drop": 1,
                    ".dropna": 1,
                    ".qcut": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    16,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<bound method Series.info of 0        (19.0, 25.0]\n1        (31.8, 41.0]\n2        (25.0, 31.8]\n3        (31.8, 41.0]\n4        (31.8, 41.0]\n            ...      \n885      (31.8, 41.0]\n886      (25.0, 31.8]\n887    (-0.001, 19.0]\n889      (25.0, 31.8]\n890      (31.8, 41.0]\nName: AgeBin, Length: 714, dtype: category\nCategories (5, interval[float64, right]): [(-0.001, 19.0] < (19.0, 25.0] < (25.0, 31.8] < (31.8, 41.0] < (41.0, 80.0]]>"
                    ]
                },
                "mc_idx": 26,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 16,
                "o_idx": 0
            }
        },
        {
            "source": "#Python has autobinned this to 0 to 19, 19 to 25, 25 to 31.8, 31.8 to 41 and 41 to 80.\nsns.barplot(x=\"AgeBin\", y=\"Survived\", data=titanictemp2data)\n#plot below still shows younger more likely to live, but lost some of the info but equalizing numbers in each bin.\n#Long story short: age does give us information on survivability, so let's do our best to fill in age values (replace all NaN)",
            "mc_idx": 27,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.3333333333333333,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "info": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0014_c017_o001_image_2.png",
                    17,
                    1,
                    2
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Axes: xlabel='AgeBin', ylabel='Survived'>",
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 27,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 17,
                "o_idx": 1
            }
        },
        {
            "source": "# Time to tackle the missing age values.  Our recent work with \"Title\" will help alot!",
            "mc_idx": 28,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#For general description\ntitanicdata[titanicdata[\"Title\"]==\"Master\"].Age.describe()",
            "mc_idx": 29,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".describe(": 1,
                    "describe": 1,
                    ".describe": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    18,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "count    36.000000\nmean      4.574167\nstd       3.619872\nmin       0.420000\n25%       1.000000\n50%       3.500000\n75%       8.000000\nmax      12.000000\nName: Age, dtype: float64"
                    ]
                },
                "mc_idx": 29,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 18,
                "o_idx": 0
            }
        },
        {
            "source": "#So--\"Master\" means between 0 and 12!  Since there are only 40 data points (36 + 4 NaN), let's take a look at this list, sorted:\ntitanicdata[titanicdata[\"Title\"]==\"Master\"].sort_values(by=['Age'])",
            "mc_idx": 30,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    19,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "     Survived  Pclass   Sex    Age  SibSp  Parch      Fare    Cabin Embarked  \\\n803         1       3  male   0.42      0      1    8.5167      NaN        C   \n755         1       2  male   0.67      1      1   14.5000      NaN        S   \n831         1       2  male   0.83      1      1   18.7500      NaN        S   \n78          1       2  male   0.83      0      2   29.0000      NaN        S   \n305         1       1  male   0.92      1      2  151.5500  C22 C26        S   \n827         1       2  male   1.00      0      2   37.0042      NaN        C   \n164         0       3  male   1.00      4      1   39.6875      NaN        S   \n788         1       3  male   1.00      1      2   20.5750      NaN        S   \n183         1       2  male   1.00      2      1   39.0000       F4        S   \n386         0       3  male   1.00      5      2   46.9000      NaN        S   \n7           0       3  male   2.00      3      1   21.0750      NaN        S   \n16          0       3  male   2.00      4      1   29.1250      NaN        Q   \n824         0       3  male   2.00      4      1   39.6875      NaN        S   \n340         1       2  male   2.00      1      1   26.0000       F2        S   \n407         1       2  male   3.00      1      1   18.7500      NaN        S   \n348         1       3  male   3.00      1      1   15.9000      NaN        S   \n261         1       3  male   3.00      4      2   31.3875      NaN        S   \n193         1       2  male   3.00      1      1   26.0000       F2        S   \n63          0       3  male   4.00      3      2   27.9000      NaN        S   \n445         1       1  male   4.00      0      2   81.8583      A34        S   \n171         0       3  male   4.00      4      1   29.1250      NaN        Q   \n850         0       3  male   4.00      4      2   31.2750      NaN        S   \n869         1       3  male   4.00      1      1   11.1333      NaN        S   \n751         1       3  male   6.00      0      1   12.4750     E121        S   \n278         0       3  male   7.00      4      1   29.1250      NaN        Q   \n50          0       3  male   7.00      4      1   39.6875      NaN        S   \n549         1       2  male   8.00      1      1   36.7500      NaN        S   \n787         0       3  male   8.00      4      1   29.1250      NaN        Q   \n480         0       3  male   9.00      5      2   46.9000      NaN        S   \n489         1       3  male   9.00      1      1   15.9000      NaN        S   \n165         1       3  male   9.00      0      2   20.5250      NaN        S   \n182         0       3  male   9.00      4      2   31.3875      NaN        S   \n819         0       3  male  10.00      3      2   27.9000      NaN        S   \n802         1       1  male  11.00      1      2  120.0000  B96 B98        S   \n59          0       3  male  11.00      5      2   46.9000      NaN        S   \n125         1       3  male  12.00      1      0   11.2417      NaN        C   \n65          1       3  male    NaN      1      1   15.2458      NaN        C   \n159         0       3  male    NaN      8      2   69.5500      NaN        S   \n176         0       3  male    NaN      3      1   25.4667      NaN        S   \n709         1       3  male    NaN      1      1   15.2458      NaN        C   \n\n      Title  \n803  Master  \n755  Master  \n831  Master  \n78   Master  \n305  Master  \n827  Master  \n164  Master  \n788  Master  \n183  Master  \n386  Master  \n7    Master  \n16   Master  \n824  Master  \n340  Master  \n407  Master  \n348  Master  \n261  Master  \n193  Master  \n63   Master  \n445  Master  \n171  Master  \n850  Master  \n869  Master  \n751  Master  \n278  Master  \n50   Master  \n549  Master  \n787  Master  \n480  Master  \n489  Master  \n165  Master  \n182  Master  \n819  Master  \n802  Master  \n59   Master  \n125  Master  \n65   Master  \n159  Master  \n176  Master  \n709  Master  "
                    ]
                },
                "mc_idx": 30,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 19,
                "o_idx": 0
            }
        },
        {
            "source": "# Let's fill in those four NaN. We could use the median, (code for that below), or mean, 4.5 previously calculated above.\ntitanicdata[titanicdata[\"Title\"]==\"Master\"].sort_values(by=['Age'])['Age'].median()",
            "mc_idx": 31,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.5,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".median": 2
                },
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    20,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "3.5"
                    ]
                },
                "mc_idx": 31,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 20,
                "o_idx": 0
            }
        },
        {
            "source": "#I'm using mean--this command took me three hours to figure out, so enjoy it.\ntitanicdata.loc[(titanicdata.Age.isnull())&(titanicdata.Title==\"Master\"),'Age']=4.5",
            "mc_idx": 32,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".isnull": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    21,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 32,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 21,
                "o_idx": 0
            }
        },
        {
            "source": "**Now we need to rinse and repeat for Mr, Miss, Mrs, Rare**",
            "mc_idx": 33,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "print(\"Mr mean age:\",titanicdata[titanicdata[\"Title\"]==\"Mr\"].Age.mean())\nprint(\"Miss mean age:\",titanicdata[titanicdata[\"Title\"]==\"Miss\"].Age.mean())\nprint(\"Mrs mean age:\",titanicdata[titanicdata[\"Title\"]==\"Mrs\"].Age.mean())\nprint(\"Rare mean age:\",titanicdata[titanicdata[\"Title\"]==\"Rare\"].Age.mean())",
            "mc_idx": 34,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 4,
                    ".mean": 4
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    22,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Mr mean age: 32.368090452261306\nMiss mean age: 21.773972602739725\nMrs mean age: 35.59649122807018\nRare mean age: 46.05\n"
                    ]
                },
                "mc_idx": 34,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 22,
                "o_idx": 0
            }
        },
        {
            "source": "titanicdata.loc[(titanicdata.Age.isnull())&(titanicdata.Title==\"Mr\"),'Age']=32.3\ntitanicdata.loc[(titanicdata.Age.isnull())&(titanicdata.Title==\"Miss\"),'Age']=21.8\ntitanicdata.loc[(titanicdata.Age.isnull())&(titanicdata.Title==\"Mrs\"),'Age']=35.6\ntitanicdata.loc[(titanicdata.Age.isnull())&(titanicdata.Title==\"Rare\"),'Age']=46",
            "mc_idx": 35,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".isnull": 4
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    23,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 35,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 23,
                "o_idx": 0
            }
        },
        {
            "source": "#Checking out our ages--no NaN (not a number) left (we now have 891 entries!)\ntitanicdata.Age.describe()",
            "mc_idx": 36,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".describe(": 1,
                    "describe": 1,
                    ".describe": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    24,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "count    891.000000\nmean      29.745084\nstd       13.277659\nmin        0.420000\n25%       21.800000\n50%       30.000000\n75%       35.600000\nmax       80.000000\nName: Age, dtype: float64"
                    ]
                },
                "mc_idx": 36,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 24,
                "o_idx": 0
            }
        },
        {
            "source": "#We're still cleaning data, but I just have to have a pretty graph, so let's look at survivability by age, here I made these bins this size, just cause.  I use \"np.inf\" for \"infinity\" but I could have just used \"85\" since the oldest person is 80.\nbins=[0,12,20,35,50,65,np.inf]\n#different bins would (obviously!) give different results, but generally \"over 50% of children were saved\" and \"under 40% of everyone else\"\n#I don't want to mess up the original data, so I'll make a new \"NewAge\" dataset:\ntitanicdataNewAge=titanicdata\nlabels = ['Child', 'Teenager', 'Young Adult', 'Adult', 'Old Adult','Senior']\ntitanicdataNewAge['AgeGroup']=pd.cut(titanicdata[\"Age\"],bins,labels=labels)\nsns.barplot(x=\"AgeGroup\", y=\"Survived\", data=titanicdataNewAge)",
            "mc_idx": 37,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.3333333333333333,
                "Exploratory_Data_Analysis": 0.6666666666666666,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.6666666666666666,
                "Debug": 0.0,
                "Data_Export": 0.3333333333333333,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "dataset": 1
                },
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 1
                },
                "Data_Transform": {
                    "cleaning data": 1,
                    ".cut(": 1,
                    ".cut": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1,
                    "graph": 1
                },
                "Debug": {},
                "Data_Export": {
                    "save": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0014_c025_o001_image_3.png",
                    25,
                    1,
                    3
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Axes: xlabel='AgeGroup', ylabel='Survived'>",
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 37,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 25,
                "o_idx": 1
            }
        },
        {
            "source": "#Let's move on to filling in Cabin details. There are a lot (687) missing values, BUT, the fact that there are cabins listed, actually informs surviability: check out this graphic:\n#Creating a new column and representing having a cabin as \"1\"\ntitanicdata[\"CabinBin\"]=(titanicdata[\"Cabin\"].notnull().astype('int'))\nsns.barplot(x=\"CabinBin\",y=\"Survived\",data=titanicdata)",
            "mc_idx": 38,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.2,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.4,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "missing values": 1,
                    "sns.": 1,
                    "tail": 1,
                    "info": 1,
                    ".notnull": 1
                },
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1,
                    "graph": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0014_c026_o001_image_4.png",
                    26,
                    1,
                    4
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Axes: xlabel='CabinBin', ylabel='Survived'>",
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 38,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 26,
                "o_idx": 1
            }
        },
        {
            "source": "SO--having a cabin played a HUGE role in survivability.  Though it should be noted that half of the kaggle websites I used dropped the feature as there were too many missing values.  It is better to convert what we know to \"1\" and what we don't know to \"0\".  Next we'll drop the \"Cabin\" column.",
            "mc_idx": 39,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#Since we made a new data column, \"CabinBin\", we'll drop the old one, \"Cabin\"\ntitanicdata.drop(['Cabin'],axis=1,inplace=True)",
            "mc_idx": 40,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    27,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 40,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 27,
                "o_idx": 0
            }
        },
        {
            "source": "#wooooo--where are we? let's take a look!\ntitanicdata.sample(10)",
            "mc_idx": 41,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".sample": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    28,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "     Survived  Pclass     Sex   Age  SibSp  Parch      Fare Embarked   Title  \\\n544         0       1    male  50.0      1      0  106.4250        C      Mr   \n788         1       3    male   1.0      1      2   20.5750        S  Master   \n158         0       3    male  32.3      0      0    8.6625        S      Mr   \n278         0       3    male   7.0      4      1   29.1250        Q  Master   \n57          0       3    male  28.5      0      0    7.2292        C      Mr   \n882         0       3  female  22.0      0      0   10.5167        S    Miss   \n98          1       2  female  34.0      0      1   23.0000        S     Mrs   \n43          1       2  female   3.0      1      2   41.5792        C    Miss   \n151         1       1  female  22.0      1      0   66.6000        S     Mrs   \n705         0       2    male  39.0      0      0   26.0000        S      Mr   \n\n        AgeGroup  CabinBin  \n544        Adult         1  \n788        Child         0  \n158  Young Adult         0  \n278        Child         0  \n57   Young Adult         0  \n882  Young Adult         0  \n98   Young Adult         0  \n43         Child         0  \n151  Young Adult         1  \n705        Adult         0  "
                    ]
                },
                "mc_idx": 41,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 28,
                "o_idx": 0
            }
        },
        {
            "source": "#Checking for NaN:\ntitanicdata.isnull().sum()",
            "mc_idx": 42,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".isnull": 1,
                    ".sum": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    29,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Survived    0\nPclass      0\nSex         0\nAge         0\nSibSp       0\nParch       0\nFare        0\nEmbarked    0\nTitle       0\nAgeGroup    0\nCabinBin    0\ndtype: int64"
                    ]
                },
                "mc_idx": 42,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 29,
                "o_idx": 0
            }
        },
        {
            "source": "# 3.23 Time to use some tools to create (clean-up) the rest of the data!",
            "mc_idx": 43,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#Here is an idea many data scientists used.  I wouldn't have thought of this, but those travelling alone were more likely to have not survived.  Families stick together!\n#Combining SibSp and Parch to make 'FamilySize' and 'IsAlone' if FamilySize is <2\ntitanicdata['FamilySize'] = titanicdata ['SibSp'] + titanicdata['Parch'] + 1\n#make all values 1\ntitanicdata['IsAlone'] = 1\n#turn 1s to 0s if not alone\ntitanicdata.loc[titanicdata['FamilySize'] > 1,'IsAlone'] = 0",
            "mc_idx": 44,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 4
                },
                "Data_Transform": {
                    "ravel": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    30,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 44,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 30,
                "o_idx": 0
            }
        },
        {
            "source": "#why did we do that?---familysizes of 2,3,4 had higher chance of surviving, but notsomuch for bigger families or family size 1, i.e. IsAlone\nsns.barplot(x='FamilySize',y='Survived',data=titanicdata)",
            "mc_idx": 45,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.25,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 3
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0014_c031_o001_image_5.png",
                    31,
                    1,
                    5
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Axes: xlabel='FamilySize', ylabel='Survived'>",
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 45,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 31,
                "o_idx": 1
            }
        },
        {
            "source": "#\"0\" is Not Alone, \"1\" is Alone--roughly 30% survived\nsns.barplot(x='IsAlone',y='Survived',data=titanicdata)",
            "mc_idx": 46,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0014_c032_o001_image_6.png",
                    32,
                    1,
                    6
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Axes: xlabel='IsAlone', ylabel='Survived'>",
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 46,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 32,
                "o_idx": 1
            }
        },
        {
            "source": "#I like to check how things are looking...\ntitanicdata.sample(10)",
            "mc_idx": 47,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".sample": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    33,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "     Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked Title  \\\n68          1       3  female  17.0      4      2   7.9250        S  Miss   \n360         0       3    male  40.0      1      4  27.9000        S    Mr   \n835         1       1  female  39.0      1      1  83.1583        C  Miss   \n860         0       3    male  41.0      2      0  14.1083        S    Mr   \n724         1       1    male  27.0      1      0  53.1000        S    Mr   \n879         1       1  female  56.0      0      1  83.1583        C   Mrs   \n740         1       1    male  32.3      0      0  30.0000        S    Mr   \n598         0       3    male  32.3      0      0   7.2250        C    Mr   \n72          0       2    male  21.0      0      0  73.5000        S    Mr   \n799         0       3  female  30.0      1      1  24.1500        S   Mrs   \n\n        AgeGroup  CabinBin  FamilySize  IsAlone  \n68      Teenager         0           7        0  \n360        Adult         0           6        0  \n835        Adult         1           3        0  \n860        Adult         0           3        0  \n724  Young Adult         1           2        0  \n879    Old Adult         1           2        0  \n740  Young Adult         1           1        1  \n598  Young Adult         0           1        1  \n72   Young Adult         0           1        1  \n799  Young Adult         0           3        0  "
                    ]
                },
                "mc_idx": 47,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 33,
                "o_idx": 0
            }
        },
        {
            "source": "#OK--I'm tired of this--let's clean up the rest and get to Exploratory Analysis and model building\n#Basically we need to convert female/male to 1/0 and mr/miss/master to 1/2/3 etc.\ntitanicdata['Sex'] = titanicdata['Sex'].map( {'female': 1, 'male': 0} ).astype(int)",
            "mc_idx": 48,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 0.3333333333333333,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".map(": 1,
                    ".astype(": 1,
                    ".map": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    34,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 48,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 34,
                "o_idx": 0
            }
        },
        {
            "source": "titanicdata['Embarked'] = titanicdata['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)",
            "mc_idx": 49,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".map(": 1,
                    ".astype(": 1,
                    ".map": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    35,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 49,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 35,
                "o_idx": 0
            }
        },
        {
            "source": "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\ntitanicdata['Title'] = titanicdata['Title'].map(title_mapping).astype(int)",
            "mc_idx": 50,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".map(": 1,
                    ".astype(": 1,
                    ".map": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    36,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 50,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 36,
                "o_idx": 0
            }
        },
        {
            "source": "#I killed AgeGroup at midnight last night because it was registering as categorical...BUT I FIXED IT WITH THE ADDITION OF .astype(int)\nAgeGroup_mapping = {\"Child\":1, \"Teenager\":2, \"Young Adult\":3, \"Adult\":4, \"Old Adult\":5,\"Senior\":6}\ntitanicdata['AgeGroup'] = titanicdata['AgeGroup'].map(AgeGroup_mapping).astype(int)",
            "mc_idx": 51,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".map(": 1,
                    ".astype(": 2,
                    ".map": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    37,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 51,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 37,
                "o_idx": 0
            }
        },
        {
            "source": "#Now we can also drop the Age column\ntitanicdata.drop(['Age'],axis=1,inplace=True)",
            "mc_idx": 52,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    38,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 52,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 38,
                "o_idx": 0
            }
        },
        {
            "source": "#As we did earlier with age, we will split the Fare into Bins.  Here I'm using qcut so each bin contains roughly the same number of fares.\ntitanicdata['FareBin'] = pd.qcut(titanicdata['Fare'], 4)\nfrom sklearn.preprocessing import LabelEncoder\nlabel = LabelEncoder()\n#But then I need to adjust the bins into numbers, this command does that!\ntitanicdata['FareBin_Code'] = label.fit_transform(titanicdata['FareBin'])\n",
            "mc_idx": 53,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.8,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 10
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "fit_transform": 1,
                    "transform": 1,
                    ".qcut(": 1,
                    "labelencoder": 4,
                    ".qcut": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    39,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 53,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 39,
                "o_idx": 0
            }
        },
        {
            "source": "#and then drop Fare\ntitanicdata.drop(['Fare'],axis=1,inplace=True)",
            "mc_idx": 54,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    40,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 54,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 40,
                "o_idx": 0
            }
        },
        {
            "source": "#and then drop FareBin---should have used one command, but I already ran the one above, and I can't run it again without an error!\ntitanicdata.drop(['FareBin'],axis=1,inplace=True)",
            "mc_idx": 55,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    41,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 55,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 41,
                "o_idx": 0
            }
        },
        {
            "source": "#One last look at the data--only integers!\ntitanicdata.info()\nprint(titanicdata.sample(10))",
            "mc_idx": 56,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".info(": 1,
                    "info": 1,
                    ".info": 1,
                    ".sample": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    42,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column        Non-Null Count  Dtype\n---  ------        --------------  -----\n 0   Survived      891 non-null    int64\n 1   Pclass        891 non-null    int64\n 2   Sex           891 non-null    int64\n 3   SibSp         891 non-null    int64\n 4   Parch         891 non-null    int64\n 5   Embarked      891 non-null    int64\n 6   Title         891 non-null    int64\n 7   AgeGroup      891 non-null    int64\n 8   CabinBin      891 non-null    int64\n 9   FamilySize    891 non-null    int64\n 10  IsAlone       891 non-null    int64\n 11  FareBin_Code  891 non-null    int64\ndtypes: int64(12)\nmemory usage: 83.7 KB\n     Survived  Pclass  Sex  SibSp  Parch  Embarked  Title  AgeGroup  CabinBin  \\\n568         0       3    0      0      0         1      1         3         0   \n284         0       1    0      0      0         0      1         3         1   \n677         1       3    1      0      0         0      2         2         0   \n244         0       3    0      0      0         1      1         3         0   \n32          1       3    1      0      0         2      2         3         0   \n228         0       2    0      0      0         0      1         2         0   \n707         1       1    0      0      0         0      1         4         1   \n357         0       2    1      0      0         0      2         4         0   \n75          0       3    0      0      0         0      1         3         1   \n373         0       1    0      0      0         1      1         3         0   \n\n     FamilySize  IsAlone  FareBin_Code  \n568           1        1             0  \n284           1        1             2  \n677           1        1             1  \n244           1        1             0  \n32            1        1             0  \n228           1        1             1  \n707           1        1             2  \n357           1        1             1  \n75            1        1             0  \n373           1        1             3  \n"
                    ]
                },
                "mc_idx": 56,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 42,
                "o_idx": 0
            }
        },
        {
            "source": "#hopefully can do some more #4 exploratory at some point, but I'm tired so I'm doing models now:",
            "mc_idx": 57,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    43,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 57,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 43,
                "o_idx": 0
            }
        },
        {
            "source": "# 5: MACHINE LEARNING MODELS!\nNow we are ready to train a model and predict the required solution. There are 60+ predictive modelling algorithms to choose from. We must understand the type of problem and solution requirement to narrow down to a select few models which we can evaluate. Our problem is a classification and regression problem. We want to identify relationship between output (Survived or not) with other variables or features (Gender, Age, Title...). We are also perfoming a category of machine learning which is called supervised learning as we are training our model with a given dataset. With these two criteria - Supervised Learning plus Classification and Regression, we can narrow down our choice of models to a few.",
            "mc_idx": 58,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "I wanted this picture to just be here, but I couldn't get it to work...so here's a link!\nhttps://ferrisstateuniversity-my.sharepoint.com/:i:/g/personal/troubaj_ferris_edu/EZSEiQEzaKlNhhNZpQuCn6QBX5i7D-6MCtXb7SQTl9waJg?e=LhpbMi",
            "mc_idx": 59,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "![](https://ferrisstateuniversity-my.sharepoint.com/:i:/g/personal/troubaj_ferris_edu/EZSEiQEzaKlNhhNZpQuCn6QBX5i7D-6MCtXb7SQTl9waJg?e=LhpbMi)",
            "mc_idx": 60,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "X_train=titanicdata.drop(\"Survived\",axis=1)\nY_train=titanicdata[\"Survived\"]",
            "mc_idx": 61,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    44,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 61,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 44,
                "o_idx": 0
            }
        },
        {
            "source": "# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log",
            "mc_idx": 62,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.5,
                "Model_Evaluation": 0.2,
                "Model_Interpretation": 0.1,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 10
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "model": 1,
                    "logisticregression": 2,
                    ".linear": 1
                },
                "Model_Evaluation": {
                    "model": 1,
                    ".score(": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    45,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "82.15"
                    ]
                },
                "mc_idx": 62,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 45,
                "o_idx": 0
            }
        },
        {
            "source": "#The next model Random Forests is one of the most popular. Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees (n_estimators=100) at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.\nfrom sklearn.ensemble import RandomForestClassifier\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\n\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest",
            "mc_idx": 63,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.6,
                "Model_Evaluation": 0.3,
                "Model_Interpretation": 0.1,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 10
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "model": 1,
                    "randomforestclassifier": 4
                },
                "Model_Evaluation": {
                    "model": 1,
                    ".score(": 2
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    46,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "90.68"
                    ]
                },
                "mc_idx": 63,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 46,
                "o_idx": 0
            }
        },
        {
            "source": "Ahm, say what now?!? I guess 10-hours pays off!  \nNow, what really is happening is we have overfit our model.  We need to apply our random forest to new data.  Officially, Titanic data is divided into train data (what we've been using) and test data (where we actually need to apply our model).  If I have time, I'll see how this model does on the test data!",
            "mc_idx": 64,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#\n\n\n\n\nI'm leaving space for this stuff below.  I just can't delete it, it took me too long to enter.  Basically this stuff below is a VERY QUICK machine learning algorithm that deletes most columns and just lets things happen.",
            "mc_idx": 65,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#These next few commands are a sidebar--in Excel we focused on Pclass and Sex and built a model.  Let's do a quick machine learning model!\n#This command drops all the columns that aren't Pclass or Sex, and then gives a sample to see. \ntrain_df = pd.read_csv('/kaggle/input/titanic/train.csv')\nquicktrain_df = train_df.drop(['PassengerId','Name','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked'], axis=1)\nquicktrain_df.sample(5)",
            "mc_idx": 66,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 0.25,
                "Model_Train": 0.5,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 2,
                    "pd.read_": 2
                },
                "Exploratory_Data_Analysis": {
                    "columns": 1,
                    ".sample": 1
                },
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {
                    "model": 2
                },
                "Model_Evaluation": {
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    47,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 66,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 47,
                "o_idx": 0
            }
        },
        {
            "source": "#Sex is a categorical variable \"male\" or \"female\" we need it to be integer valued for our machine learning model, so we switch to binary designation:\nquicktrain_df['Sex']=quicktrain_df['Sex'].map( {'female': 1, 'male': 0} )",
            "mc_idx": 67,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.5,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".map(": 1,
                    ".map": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    48,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 67,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 48,
                "o_idx": 0
            }
        },
        {
            "source": "#We want to use Pclass and Sex to determine survivability (like we did in Excel) so we drop the knowledge of \"Survived\" for our input variable X_train\n# and leave \"Survived\" in for our output variable.  Note, instead of dropping \"Survived\" we could have just designated using \"Pclass\" and \"Sex\" but\n# in a bigger model we would want to use many variables and just leave the predictor out.\nX_train = quicktrain_df.drop(\"Survived\", axis=1)\nY_train = quicktrain_df[\"Survived\"]",
            "mc_idx": 68,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 0.3333333333333333,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 3
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    49,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 68,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 49,
                "o_idx": 0
            }
        },
        {
            "source": "#This is our machine learning model, RandomForest, we'll talk about the details later\nfrom sklearn.ensemble import RandomForestClassifier\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest",
            "mc_idx": 69,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.1,
                "Data_Transform": 0.0,
                "Model_Train": 0.6,
                "Model_Evaluation": 0.2,
                "Model_Interpretation": 0.1,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 10
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "tail": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "model": 1,
                    "randomforestclassifier": 4
                },
                "Model_Evaluation": {
                    "model": 1,
                    ".score(": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    50,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 69,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 50,
                "o_idx": 0
            }
        },
        {
            "source": "The point here is we get 78.68%--exactly the same as using excel to predict all women survived.  \nBut, we can easily go further...\nThe next command combines it all into one quick algorithm to get our highest percentage yet!  Essentially we keep SipSp (number of siblings and/or spouse aboard) and Parch (number of parents/children aboard), and let machine learning figure it out!",
            "mc_idx": 70,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "quickml_df=train_df.drop(['PassengerId','Name','Age','Ticket','Fare','Cabin','Embarked'], axis=1)\nquickml_df['Sex']=quickml_df['Sex'].map( {'female': 1, 'male': 0} )\nX_train = quickml_df.drop(\"Survived\", axis=1)\nY_train = quickml_df[\"Survived\"]\nfrom sklearn.ensemble import RandomForestClassifier\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest\n",
            "mc_idx": 71,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.4,
                "Model_Train": 0.5,
                "Model_Evaluation": 0.1,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 10
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".map(": 1,
                    ".drop": 2,
                    ".map": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "randomforestclassifier": 4
                },
                "Model_Evaluation": {
                    ".score(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    51,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 71,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 51,
                "o_idx": 0
            }
        }
    ],
    "code_cells": [
        {
            "source": "#3.1: Load Necessary Modelling Libraries:\n\nimport numpy as np # numpy is numerical python \nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns #visualization library\n\n# There were issues last time with loading files, so hopefully this command below will give a direct link you can use for the files.\n# Train.csv is all we will use.\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))",
            "mc_idx": 3,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0975609756097561,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.04878048780487805,
                "Model_Train": 0.024390243902439025,
                "Model_Evaluation": 0.024390243902439025,
                "Model_Interpretation": 0.024390243902439025,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 4
                },
                "Data_Extraction": {
                    "read_csv": 2,
                    "pd.read_": 2
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".join(": 1,
                    ".join": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    0,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n"
                    ]
                },
                "mc_idx": 3,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 0,
                "o_idx": 0
            }
        },
        {
            "source": "#loading the \"train\" data using pd for pandas.\ntitanicdata = pd.read_csv('/kaggle/input/titanic/train.csv')\n\n#looking at 10 random samples of the data\ntitanicdata.sample(10)",
            "mc_idx": 4,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 2,
                    "pd.read_": 2
                },
                "Exploratory_Data_Analysis": {
                    ".sample": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    1,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "     PassengerId  Survived  Pclass                            Name     Sex  \\\n859          860         0       3                Razi, Mr. Raihed    male   \n560          561         0       3        Morrow, Mr. Thomas Rowan    male   \n484          485         1       1         Bishop, Mr. Dickinson H    male   \n124          125         0       1     White, Mr. Percival Wayland    male   \n579          580         1       3             Jussila, Mr. Eiriik    male   \n623          624         0       3     Hansen, Mr. Henry Damsgaard    male   \n713          714         0       3      Larsson, Mr. August Viktor    male   \n496          497         1       1  Eustis, Miss. Elizabeth Mussey  female   \n886          887         0       2           Montvila, Rev. Juozas    male   \n95            96         0       3     Shorney, Mr. Charles Joseph    male   \n\n      Age  SibSp  Parch             Ticket     Fare Cabin Embarked  \n859   NaN      0      0               2629   7.2292   NaN        C  \n560   NaN      0      0             372622   7.7500   NaN        Q  \n484  25.0      1      0              11967  91.0792   B49        C  \n124  54.0      0      1              35281  77.2875   D26        S  \n579  32.0      0      0  STON/O 2. 3101286   7.9250   NaN        S  \n623  21.0      0      0             350029   7.8542   NaN        S  \n713  29.0      0      0               7545   9.4833   NaN        S  \n496  54.0      1      0              36947  78.2667   D20        C  \n886  27.0      0      0             211536  13.0000   NaN        S  \n95    NaN      0      0             374910   8.0500   NaN        S  "
                    ]
                },
                "mc_idx": 4,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 1,
                "o_idx": 0
            }
        },
        {
            "source": "#We discuss above, but we can also see the data type: integer \"int64\", categorical \"object\", or numerical \"float64\"\ntitanicdata.info()",
            "mc_idx": 6,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".info(": 1,
                    "info": 1,
                    ".info": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    2,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n"
                    ]
                },
                "mc_idx": 6,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 2,
                "o_idx": 0
            }
        },
        {
            "source": "#easier way to see missing values--I list two commands, they do the same thing, the second is better--but just be aware of varying code!\n#NOTE: if two lines of code are written, as below, only the bottom line will display unless the print(---enter the code here---) is used.\npd.isnull(titanicdata).sum()\ntitanicdata.isnull().sum()",
            "mc_idx": 7,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "missing values": 1,
                    ".isnull": 2,
                    ".sum": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    3,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "PassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64"
                    ]
                },
                "mc_idx": 7,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 3,
                "o_idx": 0
            }
        },
        {
            "source": "#The following command gives even more information, including quartiles.  It is nice to get a distribution for the data!\n\ntitanicdata.describe(include=\"all\")",
            "mc_idx": 9,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".describe(": 1,
                    "info": 1,
                    "describe": 1,
                    ".describe": 1
                },
                "Data_Transform": {
                    "tile": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    4,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "        PassengerId    Survived      Pclass                     Name   Sex  \\\ncount    891.000000  891.000000  891.000000                      891   891   \nunique          NaN         NaN         NaN                      891     2   \ntop             NaN         NaN         NaN  Braund, Mr. Owen Harris  male   \nfreq            NaN         NaN         NaN                        1   577   \nmean     446.000000    0.383838    2.308642                      NaN   NaN   \nstd      257.353842    0.486592    0.836071                      NaN   NaN   \nmin        1.000000    0.000000    1.000000                      NaN   NaN   \n25%      223.500000    0.000000    2.000000                      NaN   NaN   \n50%      446.000000    0.000000    3.000000                      NaN   NaN   \n75%      668.500000    1.000000    3.000000                      NaN   NaN   \nmax      891.000000    1.000000    3.000000                      NaN   NaN   \n\n               Age       SibSp       Parch  Ticket        Fare    Cabin  \\\ncount   714.000000  891.000000  891.000000     891  891.000000      204   \nunique         NaN         NaN         NaN     681         NaN      147   \ntop            NaN         NaN         NaN  347082         NaN  B96 B98   \nfreq           NaN         NaN         NaN       7         NaN        4   \nmean     29.699118    0.523008    0.381594     NaN   32.204208      NaN   \nstd      14.526497    1.102743    0.806057     NaN   49.693429      NaN   \nmin       0.420000    0.000000    0.000000     NaN    0.000000      NaN   \n25%      20.125000    0.000000    0.000000     NaN    7.910400      NaN   \n50%      28.000000    0.000000    0.000000     NaN   14.454200      NaN   \n75%      38.000000    1.000000    0.000000     NaN   31.000000      NaN   \nmax      80.000000    8.000000    6.000000     NaN  512.329200      NaN   \n\n       Embarked  \ncount       889  \nunique        3  \ntop           S  \nfreq        644  \nmean        NaN  \nstd         NaN  \nmin         NaN  \n25%         NaN  \n50%         NaN  \n75%         NaN  \nmax         NaN  "
                    ]
                },
                "mc_idx": 9,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 4,
                "o_idx": 0
            }
        },
        {
            "source": "#simpliest first: we have two missing embarked values, we will fill them with the mode, S:\ntitanicdata['Embarked'].fillna(titanicdata['Embarked'].mode()[0], inplace = True)",
            "mc_idx": 14,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mode": 1
                },
                "Data_Transform": {
                    ".fillna(": 1,
                    ".fillna": 1,
                    ".mod": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    5,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 14,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 5,
                "o_idx": 0
            }
        },
        {
            "source": "#PassengerID and Ticket number are clearly just random identifiers and have no impact on outcome--so let's delete them!\ntitanicdata.drop(['PassengerId','Ticket'],axis=1,inplace=True)",
            "mc_idx": 15,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "impact": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    6,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 15,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 6,
                "o_idx": 0
            }
        },
        {
            "source": "#Next we'll look at \"Name\" though names don't tell us much, TITLES do!  Here is a command I found in multiple worksheets to extract titles!\n#This command adds a new column \"Title\" to our data:\ntitanicdata['Title']=titanicdata.Name.str.extract('([A-Za-z]+)\\.',expand=False)\n\n#nice way to see this data\ntitanicdata['Title'].value_counts()",
            "mc_idx": 16,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "extract": 2
                },
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    7,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Title\nMr          517\nMiss        182\nMrs         125\nMaster       40\nDr            7\nRev           6\nMlle          2\nMajor         2\nCol           2\nCountess      1\nCapt          1\nMs            1\nSir           1\nLady          1\nMme           1\nDon           1\nJonkheer      1\nName: count, dtype: int64"
                    ]
                },
                "mc_idx": 16,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 7,
                "o_idx": 0
            }
        },
        {
            "source": "#It is also nice to see this data seperated by sex:\npd.crosstab(titanicdata['Title'],titanicdata['Sex'])",
            "mc_idx": 18,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".cross": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    8,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Sex       female  male\nTitle                 \nCapt           0     1\nCol            0     2\nCountess       1     0\nDon            0     1\nDr             1     6\nJonkheer       0     1\nLady           1     0\nMajor          0     2\nMaster         0    40\nMiss         182     0\nMlle           2     0\nMme            1     0\nMr             0   517\nMrs          125     0\nMs             1     0\nRev            0     6\nSir            0     1"
                    ]
                },
                "mc_idx": 18,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 8,
                "o_idx": 0
            }
        },
        {
            "source": "#It is nice to see the data, before replacing/regrouping these, so let's just check the ultimate goal, survivability!\npd.crosstab(titanicdata['Title'],titanicdata['Survived'])",
            "mc_idx": 19,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".cross": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    9,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Survived    0    1\nTitle             \nCapt        1    0\nCol         1    1\nCountess    0    1\nDon         1    0\nDr          4    3\nJonkheer    1    0\nLady        0    1\nMajor       1    1\nMaster     17   23\nMiss       55  127\nMlle        0    2\nMme         0    1\nMr        436   81\nMrs        26   99\nMs          0    1\nRev         6    0\nSir         0    1"
                    ]
                },
                "mc_idx": 19,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 9,
                "o_idx": 0
            }
        },
        {
            "source": "#We CANNOT make assumptions/conclusions off of one or two data points!  We CANNOT assume all \"Ms\" survive, though with our data subset, it is true.  Normally we have data where we find patterns so we can apply those patterns to other, newer data, so gross assumptions off of a single data point are generally not a good idea.  However, we can regroup:  Mlle, Mme, Ms, Lady, Countess as \"Mrs.\" and leave the others as rare\ntitanicdata['Title']=titanicdata['Title'].replace(['Mlle',\"Mme\",\"Lady\",\"Countess\",\"Ms\"],'Mrs')\ntitanicdata['Title']=titanicdata['Title'].replace(['Dr',\"Rev\",\"Major\",\"Col\",\"Don\",\"Sir\",\"Capt\",\"Jonkheer\"],'Rare')\n#and then look at our new data\ntitanicdata['Title'].value_counts()",
            "mc_idx": 20,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    ".value_counts": 1
                },
                "Data_Transform": {
                    ".replace(": 2,
                    ".replace": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    10,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Title\nMr        517\nMiss      182\nMrs       131\nMaster     40\nRare       21\nName: count, dtype: int64"
                    ]
                },
                "mc_idx": 20,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 10,
                "o_idx": 0
            }
        },
        {
            "source": "#We now no longer need \"Name\"\ntitanicdata.drop(['Name'],axis=1,inplace=True)\n#and then look at the data again\ntitanicdata.sample(10)",
            "mc_idx": 21,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".sample": 1
                },
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    11,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "     Survived  Pclass     Sex   Age  SibSp  Parch     Fare    Cabin Embarked  \\\n530         1       2  female   2.0      1      1  26.0000      NaN        S   \n771         0       3    male  48.0      0      0   7.8542      NaN        S   \n147         0       3  female   9.0      2      2  34.3750      NaN        S   \n643         1       3    male   NaN      0      0  56.4958      NaN        S   \n633         0       1    male   NaN      0      0   0.0000      NaN        S   \n595         0       3    male  36.0      1      1  24.1500      NaN        S   \n797         1       3  female  31.0      0      0   8.6833      NaN        S   \n366         1       1  female  60.0      1      0  75.2500      D37        C   \n97          1       1    male  23.0      0      1  63.3583  D10 D12        C   \n723         0       2    male  50.0      0      0  13.0000      NaN        S   \n\n    Title  \n530  Miss  \n771    Mr  \n147  Miss  \n643    Mr  \n633    Mr  \n595    Mr  \n797   Mrs  \n366   Mrs  \n97     Mr  \n723    Mr  "
                    ]
                },
                "mc_idx": 21,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 11,
                "o_idx": 0
            }
        },
        {
            "source": "#Before we tackle the missing Age values, we should ask, is it worth it?  Does Age impact survivability?  However, we can't let Age be in its current continous state--we need to BIN it.  Again, the art of data science: What size bins? / how many bins?  Should we self-select, or use technology?  I'm going to use technology and create a new column with ages in 5 bins.  HOWEVER, I can't do this with my NaN values, so I'll first create a new data set where I eliminate all 177 ageless entries...\ntitanictempdata=titanicdata[[\"Age\",\"Survived\"]]\ntitanictempdata=titanictempdata.dropna()",
            "mc_idx": 22,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.3333333333333333,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {
                    ".dropna(": 1,
                    ".drop": 1,
                    ".dropna": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "impact": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    12,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 22,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 12,
                "o_idx": 0
            }
        },
        {
            "source": "#now that the NaN are (temporarily) removed, we can visualize surviability, but first we make BINS\n#Here we use \"cut\" for equal age bins (16 to 32 and 32 to 48 etc).  Later we'll use \"qcut\" for equal numbers of people in each bin.\ntitanictempdata['AgeBin'] = pd.cut(titanictempdata['Age'].astype(int), 5)\n#and then look at it\ntitanictempdata['AgeBin'].info",
            "mc_idx": 23,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.6666666666666666,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.3333333333333333,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "info": 1,
                    ".info": 1
                },
                "Data_Transform": {
                    ".astype(": 1,
                    ".cut(": 1,
                    ".cut": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "visualize": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    13,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<bound method Series.info of 0      (16.0, 32.0]\n1      (32.0, 48.0]\n2      (16.0, 32.0]\n3      (32.0, 48.0]\n4      (32.0, 48.0]\n           ...     \n885    (32.0, 48.0]\n886    (16.0, 32.0]\n887    (16.0, 32.0]\n889    (16.0, 32.0]\n890    (16.0, 32.0]\nName: AgeBin, Length: 714, dtype: category\nCategories (5, interval[float64, right]): [(-0.08, 16.0] < (16.0, 32.0] < (32.0, 48.0] < (48.0, 64.0] < (64.0, 80.0]]>"
                    ]
                },
                "mc_idx": 23,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 13,
                "o_idx": 0
            }
        },
        {
            "source": "sns.barplot(x=\"AgeBin\", y=\"Survived\", data=titanictempdata)",
            "mc_idx": 24,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0014_c014_o001_image_0.png",
                    14,
                    1,
                    0
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Axes: xlabel='AgeBin', ylabel='Survived'>",
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 24,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 14,
                "o_idx": 1
            }
        },
        {
            "source": "#Younger people were more likely to survive, older, not so much.  Let's look at how many people are in each bin!\nsns.countplot(x=\"AgeBin\", data=titanictempdata)",
            "mc_idx": 25,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0014_c015_o001_image_1.png",
                    15,
                    1,
                    1
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Axes: xlabel='AgeBin', ylabel='count'>",
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 25,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 15,
                "o_idx": 1
            }
        },
        {
            "source": "#Alternatively, we can use \"qcut\" to designate an equal number of people in each bin:\ntitanictemp2data=titanicdata[[\"Age\",\"Survived\"]]\ntitanictemp2data=titanictemp2data.dropna()\ntitanictemp2data['AgeBin'] = pd.qcut(titanictemp2data['Age'].astype(int), 5)\n#and then look at it\ntitanictemp2data['AgeBin'].info",
            "mc_idx": 26,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "info": 1,
                    ".info": 1
                },
                "Data_Transform": {
                    ".dropna(": 1,
                    ".astype(": 1,
                    ".qcut(": 1,
                    ".drop": 1,
                    ".dropna": 1,
                    ".qcut": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    16,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<bound method Series.info of 0        (19.0, 25.0]\n1        (31.8, 41.0]\n2        (25.0, 31.8]\n3        (31.8, 41.0]\n4        (31.8, 41.0]\n            ...      \n885      (31.8, 41.0]\n886      (25.0, 31.8]\n887    (-0.001, 19.0]\n889      (25.0, 31.8]\n890      (31.8, 41.0]\nName: AgeBin, Length: 714, dtype: category\nCategories (5, interval[float64, right]): [(-0.001, 19.0] < (19.0, 25.0] < (25.0, 31.8] < (31.8, 41.0] < (41.0, 80.0]]>"
                    ]
                },
                "mc_idx": 26,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 16,
                "o_idx": 0
            }
        },
        {
            "source": "#Python has autobinned this to 0 to 19, 19 to 25, 25 to 31.8, 31.8 to 41 and 41 to 80.\nsns.barplot(x=\"AgeBin\", y=\"Survived\", data=titanictemp2data)\n#plot below still shows younger more likely to live, but lost some of the info but equalizing numbers in each bin.\n#Long story short: age does give us information on survivability, so let's do our best to fill in age values (replace all NaN)",
            "mc_idx": 27,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.3333333333333333,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "info": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0014_c017_o001_image_2.png",
                    17,
                    1,
                    2
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Axes: xlabel='AgeBin', ylabel='Survived'>",
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 27,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 17,
                "o_idx": 1
            }
        },
        {
            "source": "#For general description\ntitanicdata[titanicdata[\"Title\"]==\"Master\"].Age.describe()",
            "mc_idx": 29,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".describe(": 1,
                    "describe": 1,
                    ".describe": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    18,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "count    36.000000\nmean      4.574167\nstd       3.619872\nmin       0.420000\n25%       1.000000\n50%       3.500000\n75%       8.000000\nmax      12.000000\nName: Age, dtype: float64"
                    ]
                },
                "mc_idx": 29,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 18,
                "o_idx": 0
            }
        },
        {
            "source": "#So--\"Master\" means between 0 and 12!  Since there are only 40 data points (36 + 4 NaN), let's take a look at this list, sorted:\ntitanicdata[titanicdata[\"Title\"]==\"Master\"].sort_values(by=['Age'])",
            "mc_idx": 30,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    19,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "     Survived  Pclass   Sex    Age  SibSp  Parch      Fare    Cabin Embarked  \\\n803         1       3  male   0.42      0      1    8.5167      NaN        C   \n755         1       2  male   0.67      1      1   14.5000      NaN        S   \n831         1       2  male   0.83      1      1   18.7500      NaN        S   \n78          1       2  male   0.83      0      2   29.0000      NaN        S   \n305         1       1  male   0.92      1      2  151.5500  C22 C26        S   \n827         1       2  male   1.00      0      2   37.0042      NaN        C   \n164         0       3  male   1.00      4      1   39.6875      NaN        S   \n788         1       3  male   1.00      1      2   20.5750      NaN        S   \n183         1       2  male   1.00      2      1   39.0000       F4        S   \n386         0       3  male   1.00      5      2   46.9000      NaN        S   \n7           0       3  male   2.00      3      1   21.0750      NaN        S   \n16          0       3  male   2.00      4      1   29.1250      NaN        Q   \n824         0       3  male   2.00      4      1   39.6875      NaN        S   \n340         1       2  male   2.00      1      1   26.0000       F2        S   \n407         1       2  male   3.00      1      1   18.7500      NaN        S   \n348         1       3  male   3.00      1      1   15.9000      NaN        S   \n261         1       3  male   3.00      4      2   31.3875      NaN        S   \n193         1       2  male   3.00      1      1   26.0000       F2        S   \n63          0       3  male   4.00      3      2   27.9000      NaN        S   \n445         1       1  male   4.00      0      2   81.8583      A34        S   \n171         0       3  male   4.00      4      1   29.1250      NaN        Q   \n850         0       3  male   4.00      4      2   31.2750      NaN        S   \n869         1       3  male   4.00      1      1   11.1333      NaN        S   \n751         1       3  male   6.00      0      1   12.4750     E121        S   \n278         0       3  male   7.00      4      1   29.1250      NaN        Q   \n50          0       3  male   7.00      4      1   39.6875      NaN        S   \n549         1       2  male   8.00      1      1   36.7500      NaN        S   \n787         0       3  male   8.00      4      1   29.1250      NaN        Q   \n480         0       3  male   9.00      5      2   46.9000      NaN        S   \n489         1       3  male   9.00      1      1   15.9000      NaN        S   \n165         1       3  male   9.00      0      2   20.5250      NaN        S   \n182         0       3  male   9.00      4      2   31.3875      NaN        S   \n819         0       3  male  10.00      3      2   27.9000      NaN        S   \n802         1       1  male  11.00      1      2  120.0000  B96 B98        S   \n59          0       3  male  11.00      5      2   46.9000      NaN        S   \n125         1       3  male  12.00      1      0   11.2417      NaN        C   \n65          1       3  male    NaN      1      1   15.2458      NaN        C   \n159         0       3  male    NaN      8      2   69.5500      NaN        S   \n176         0       3  male    NaN      3      1   25.4667      NaN        S   \n709         1       3  male    NaN      1      1   15.2458      NaN        C   \n\n      Title  \n803  Master  \n755  Master  \n831  Master  \n78   Master  \n305  Master  \n827  Master  \n164  Master  \n788  Master  \n183  Master  \n386  Master  \n7    Master  \n16   Master  \n824  Master  \n340  Master  \n407  Master  \n348  Master  \n261  Master  \n193  Master  \n63   Master  \n445  Master  \n171  Master  \n850  Master  \n869  Master  \n751  Master  \n278  Master  \n50   Master  \n549  Master  \n787  Master  \n480  Master  \n489  Master  \n165  Master  \n182  Master  \n819  Master  \n802  Master  \n59   Master  \n125  Master  \n65   Master  \n159  Master  \n176  Master  \n709  Master  "
                    ]
                },
                "mc_idx": 30,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 19,
                "o_idx": 0
            }
        },
        {
            "source": "# Let's fill in those four NaN. We could use the median, (code for that below), or mean, 4.5 previously calculated above.\ntitanicdata[titanicdata[\"Title\"]==\"Master\"].sort_values(by=['Age'])['Age'].median()",
            "mc_idx": 31,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.5,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".median": 2
                },
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    20,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "3.5"
                    ]
                },
                "mc_idx": 31,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 20,
                "o_idx": 0
            }
        },
        {
            "source": "#I'm using mean--this command took me three hours to figure out, so enjoy it.\ntitanicdata.loc[(titanicdata.Age.isnull())&(titanicdata.Title==\"Master\"),'Age']=4.5",
            "mc_idx": 32,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".isnull": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    21,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 32,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 21,
                "o_idx": 0
            }
        },
        {
            "source": "print(\"Mr mean age:\",titanicdata[titanicdata[\"Title\"]==\"Mr\"].Age.mean())\nprint(\"Miss mean age:\",titanicdata[titanicdata[\"Title\"]==\"Miss\"].Age.mean())\nprint(\"Mrs mean age:\",titanicdata[titanicdata[\"Title\"]==\"Mrs\"].Age.mean())\nprint(\"Rare mean age:\",titanicdata[titanicdata[\"Title\"]==\"Rare\"].Age.mean())",
            "mc_idx": 34,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 4,
                    ".mean": 4
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    22,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Mr mean age: 32.368090452261306\nMiss mean age: 21.773972602739725\nMrs mean age: 35.59649122807018\nRare mean age: 46.05\n"
                    ]
                },
                "mc_idx": 34,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 22,
                "o_idx": 0
            }
        },
        {
            "source": "titanicdata.loc[(titanicdata.Age.isnull())&(titanicdata.Title==\"Mr\"),'Age']=32.3\ntitanicdata.loc[(titanicdata.Age.isnull())&(titanicdata.Title==\"Miss\"),'Age']=21.8\ntitanicdata.loc[(titanicdata.Age.isnull())&(titanicdata.Title==\"Mrs\"),'Age']=35.6\ntitanicdata.loc[(titanicdata.Age.isnull())&(titanicdata.Title==\"Rare\"),'Age']=46",
            "mc_idx": 35,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".isnull": 4
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    23,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 35,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 23,
                "o_idx": 0
            }
        },
        {
            "source": "#Checking out our ages--no NaN (not a number) left (we now have 891 entries!)\ntitanicdata.Age.describe()",
            "mc_idx": 36,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".describe(": 1,
                    "describe": 1,
                    ".describe": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    24,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "count    891.000000\nmean      29.745084\nstd       13.277659\nmin        0.420000\n25%       21.800000\n50%       30.000000\n75%       35.600000\nmax       80.000000\nName: Age, dtype: float64"
                    ]
                },
                "mc_idx": 36,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 24,
                "o_idx": 0
            }
        },
        {
            "source": "#We're still cleaning data, but I just have to have a pretty graph, so let's look at survivability by age, here I made these bins this size, just cause.  I use \"np.inf\" for \"infinity\" but I could have just used \"85\" since the oldest person is 80.\nbins=[0,12,20,35,50,65,np.inf]\n#different bins would (obviously!) give different results, but generally \"over 50% of children were saved\" and \"under 40% of everyone else\"\n#I don't want to mess up the original data, so I'll make a new \"NewAge\" dataset:\ntitanicdataNewAge=titanicdata\nlabels = ['Child', 'Teenager', 'Young Adult', 'Adult', 'Old Adult','Senior']\ntitanicdataNewAge['AgeGroup']=pd.cut(titanicdata[\"Age\"],bins,labels=labels)\nsns.barplot(x=\"AgeGroup\", y=\"Survived\", data=titanicdataNewAge)",
            "mc_idx": 37,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.3333333333333333,
                "Exploratory_Data_Analysis": 0.6666666666666666,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.6666666666666666,
                "Debug": 0.0,
                "Data_Export": 0.3333333333333333,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "dataset": 1
                },
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 1
                },
                "Data_Transform": {
                    "cleaning data": 1,
                    ".cut(": 1,
                    ".cut": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1,
                    "graph": 1
                },
                "Debug": {},
                "Data_Export": {
                    "save": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0014_c025_o001_image_3.png",
                    25,
                    1,
                    3
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Axes: xlabel='AgeGroup', ylabel='Survived'>",
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 37,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 25,
                "o_idx": 1
            }
        },
        {
            "source": "#Let's move on to filling in Cabin details. There are a lot (687) missing values, BUT, the fact that there are cabins listed, actually informs surviability: check out this graphic:\n#Creating a new column and representing having a cabin as \"1\"\ntitanicdata[\"CabinBin\"]=(titanicdata[\"Cabin\"].notnull().astype('int'))\nsns.barplot(x=\"CabinBin\",y=\"Survived\",data=titanicdata)",
            "mc_idx": 38,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.2,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.4,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "missing values": 1,
                    "sns.": 1,
                    "tail": 1,
                    "info": 1,
                    ".notnull": 1
                },
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1,
                    "graph": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0014_c026_o001_image_4.png",
                    26,
                    1,
                    4
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Axes: xlabel='CabinBin', ylabel='Survived'>",
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 38,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 26,
                "o_idx": 1
            }
        },
        {
            "source": "#Since we made a new data column, \"CabinBin\", we'll drop the old one, \"Cabin\"\ntitanicdata.drop(['Cabin'],axis=1,inplace=True)",
            "mc_idx": 40,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    27,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 40,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 27,
                "o_idx": 0
            }
        },
        {
            "source": "#wooooo--where are we? let's take a look!\ntitanicdata.sample(10)",
            "mc_idx": 41,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".sample": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    28,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "     Survived  Pclass     Sex   Age  SibSp  Parch      Fare Embarked   Title  \\\n544         0       1    male  50.0      1      0  106.4250        C      Mr   \n788         1       3    male   1.0      1      2   20.5750        S  Master   \n158         0       3    male  32.3      0      0    8.6625        S      Mr   \n278         0       3    male   7.0      4      1   29.1250        Q  Master   \n57          0       3    male  28.5      0      0    7.2292        C      Mr   \n882         0       3  female  22.0      0      0   10.5167        S    Miss   \n98          1       2  female  34.0      0      1   23.0000        S     Mrs   \n43          1       2  female   3.0      1      2   41.5792        C    Miss   \n151         1       1  female  22.0      1      0   66.6000        S     Mrs   \n705         0       2    male  39.0      0      0   26.0000        S      Mr   \n\n        AgeGroup  CabinBin  \n544        Adult         1  \n788        Child         0  \n158  Young Adult         0  \n278        Child         0  \n57   Young Adult         0  \n882  Young Adult         0  \n98   Young Adult         0  \n43         Child         0  \n151  Young Adult         1  \n705        Adult         0  "
                    ]
                },
                "mc_idx": 41,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 28,
                "o_idx": 0
            }
        },
        {
            "source": "#Checking for NaN:\ntitanicdata.isnull().sum()",
            "mc_idx": 42,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".isnull": 1,
                    ".sum": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    29,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Survived    0\nPclass      0\nSex         0\nAge         0\nSibSp       0\nParch       0\nFare        0\nEmbarked    0\nTitle       0\nAgeGroup    0\nCabinBin    0\ndtype: int64"
                    ]
                },
                "mc_idx": 42,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 29,
                "o_idx": 0
            }
        },
        {
            "source": "#Here is an idea many data scientists used.  I wouldn't have thought of this, but those travelling alone were more likely to have not survived.  Families stick together!\n#Combining SibSp and Parch to make 'FamilySize' and 'IsAlone' if FamilySize is <2\ntitanicdata['FamilySize'] = titanicdata ['SibSp'] + titanicdata['Parch'] + 1\n#make all values 1\ntitanicdata['IsAlone'] = 1\n#turn 1s to 0s if not alone\ntitanicdata.loc[titanicdata['FamilySize'] > 1,'IsAlone'] = 0",
            "mc_idx": 44,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 4
                },
                "Data_Transform": {
                    "ravel": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    30,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 44,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 30,
                "o_idx": 0
            }
        },
        {
            "source": "#why did we do that?---familysizes of 2,3,4 had higher chance of surviving, but notsomuch for bigger families or family size 1, i.e. IsAlone\nsns.barplot(x='FamilySize',y='Survived',data=titanicdata)",
            "mc_idx": 45,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.25,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 3
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0014_c031_o001_image_5.png",
                    31,
                    1,
                    5
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Axes: xlabel='FamilySize', ylabel='Survived'>",
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 45,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 31,
                "o_idx": 1
            }
        },
        {
            "source": "#\"0\" is Not Alone, \"1\" is Alone--roughly 30% survived\nsns.barplot(x='IsAlone',y='Survived',data=titanicdata)",
            "mc_idx": 46,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0014_c032_o001_image_6.png",
                    32,
                    1,
                    6
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Axes: xlabel='IsAlone', ylabel='Survived'>",
                        "<Figure size 640x480 with 1 Axes>"
                    ]
                },
                "mc_idx": 46,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 32,
                "o_idx": 1
            }
        },
        {
            "source": "#I like to check how things are looking...\ntitanicdata.sample(10)",
            "mc_idx": 47,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".sample": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    33,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "     Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked Title  \\\n68          1       3  female  17.0      4      2   7.9250        S  Miss   \n360         0       3    male  40.0      1      4  27.9000        S    Mr   \n835         1       1  female  39.0      1      1  83.1583        C  Miss   \n860         0       3    male  41.0      2      0  14.1083        S    Mr   \n724         1       1    male  27.0      1      0  53.1000        S    Mr   \n879         1       1  female  56.0      0      1  83.1583        C   Mrs   \n740         1       1    male  32.3      0      0  30.0000        S    Mr   \n598         0       3    male  32.3      0      0   7.2250        C    Mr   \n72          0       2    male  21.0      0      0  73.5000        S    Mr   \n799         0       3  female  30.0      1      1  24.1500        S   Mrs   \n\n        AgeGroup  CabinBin  FamilySize  IsAlone  \n68      Teenager         0           7        0  \n360        Adult         0           6        0  \n835        Adult         1           3        0  \n860        Adult         0           3        0  \n724  Young Adult         1           2        0  \n879    Old Adult         1           2        0  \n740  Young Adult         1           1        1  \n598  Young Adult         0           1        1  \n72   Young Adult         0           1        1  \n799  Young Adult         0           3        0  "
                    ]
                },
                "mc_idx": 47,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 33,
                "o_idx": 0
            }
        },
        {
            "source": "#OK--I'm tired of this--let's clean up the rest and get to Exploratory Analysis and model building\n#Basically we need to convert female/male to 1/0 and mr/miss/master to 1/2/3 etc.\ntitanicdata['Sex'] = titanicdata['Sex'].map( {'female': 1, 'male': 0} ).astype(int)",
            "mc_idx": 48,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 0.3333333333333333,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".map(": 1,
                    ".astype(": 1,
                    ".map": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    34,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 48,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 34,
                "o_idx": 0
            }
        },
        {
            "source": "titanicdata['Embarked'] = titanicdata['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)",
            "mc_idx": 49,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".map(": 1,
                    ".astype(": 1,
                    ".map": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    35,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 49,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 35,
                "o_idx": 0
            }
        },
        {
            "source": "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\ntitanicdata['Title'] = titanicdata['Title'].map(title_mapping).astype(int)",
            "mc_idx": 50,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".map(": 1,
                    ".astype(": 1,
                    ".map": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    36,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 50,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 36,
                "o_idx": 0
            }
        },
        {
            "source": "#I killed AgeGroup at midnight last night because it was registering as categorical...BUT I FIXED IT WITH THE ADDITION OF .astype(int)\nAgeGroup_mapping = {\"Child\":1, \"Teenager\":2, \"Young Adult\":3, \"Adult\":4, \"Old Adult\":5,\"Senior\":6}\ntitanicdata['AgeGroup'] = titanicdata['AgeGroup'].map(AgeGroup_mapping).astype(int)",
            "mc_idx": 51,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".map(": 1,
                    ".astype(": 2,
                    ".map": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    37,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 51,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 37,
                "o_idx": 0
            }
        },
        {
            "source": "#Now we can also drop the Age column\ntitanicdata.drop(['Age'],axis=1,inplace=True)",
            "mc_idx": 52,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    38,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 52,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 38,
                "o_idx": 0
            }
        },
        {
            "source": "#As we did earlier with age, we will split the Fare into Bins.  Here I'm using qcut so each bin contains roughly the same number of fares.\ntitanicdata['FareBin'] = pd.qcut(titanicdata['Fare'], 4)\nfrom sklearn.preprocessing import LabelEncoder\nlabel = LabelEncoder()\n#But then I need to adjust the bins into numbers, this command does that!\ntitanicdata['FareBin_Code'] = label.fit_transform(titanicdata['FareBin'])\n",
            "mc_idx": 53,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.8,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 10
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "fit_transform": 1,
                    "transform": 1,
                    ".qcut(": 1,
                    "labelencoder": 4,
                    ".qcut": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    39,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 53,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 39,
                "o_idx": 0
            }
        },
        {
            "source": "#and then drop Fare\ntitanicdata.drop(['Fare'],axis=1,inplace=True)",
            "mc_idx": 54,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    40,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 54,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 40,
                "o_idx": 0
            }
        },
        {
            "source": "#and then drop FareBin---should have used one command, but I already ran the one above, and I can't run it again without an error!\ntitanicdata.drop(['FareBin'],axis=1,inplace=True)",
            "mc_idx": 55,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    41,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 55,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 41,
                "o_idx": 0
            }
        },
        {
            "source": "#One last look at the data--only integers!\ntitanicdata.info()\nprint(titanicdata.sample(10))",
            "mc_idx": 56,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".info(": 1,
                    "info": 1,
                    ".info": 1,
                    ".sample": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    42,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column        Non-Null Count  Dtype\n---  ------        --------------  -----\n 0   Survived      891 non-null    int64\n 1   Pclass        891 non-null    int64\n 2   Sex           891 non-null    int64\n 3   SibSp         891 non-null    int64\n 4   Parch         891 non-null    int64\n 5   Embarked      891 non-null    int64\n 6   Title         891 non-null    int64\n 7   AgeGroup      891 non-null    int64\n 8   CabinBin      891 non-null    int64\n 9   FamilySize    891 non-null    int64\n 10  IsAlone       891 non-null    int64\n 11  FareBin_Code  891 non-null    int64\ndtypes: int64(12)\nmemory usage: 83.7 KB\n     Survived  Pclass  Sex  SibSp  Parch  Embarked  Title  AgeGroup  CabinBin  \\\n568         0       3    0      0      0         1      1         3         0   \n284         0       1    0      0      0         0      1         3         1   \n677         1       3    1      0      0         0      2         2         0   \n244         0       3    0      0      0         1      1         3         0   \n32          1       3    1      0      0         2      2         3         0   \n228         0       2    0      0      0         0      1         2         0   \n707         1       1    0      0      0         0      1         4         1   \n357         0       2    1      0      0         0      2         4         0   \n75          0       3    0      0      0         0      1         3         1   \n373         0       1    0      0      0         1      1         3         0   \n\n     FamilySize  IsAlone  FareBin_Code  \n568           1        1             0  \n284           1        1             2  \n677           1        1             1  \n244           1        1             0  \n32            1        1             0  \n228           1        1             1  \n707           1        1             2  \n357           1        1             1  \n75            1        1             0  \n373           1        1             3  \n"
                    ]
                },
                "mc_idx": 56,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 42,
                "o_idx": 0
            }
        },
        {
            "source": "#hopefully can do some more #4 exploratory at some point, but I'm tired so I'm doing models now:",
            "mc_idx": 57,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    43,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 57,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 43,
                "o_idx": 0
            }
        },
        {
            "source": "X_train=titanicdata.drop(\"Survived\",axis=1)\nY_train=titanicdata[\"Survived\"]",
            "mc_idx": 61,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    44,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 61,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 44,
                "o_idx": 0
            }
        },
        {
            "source": "# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log",
            "mc_idx": 62,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.5,
                "Model_Evaluation": 0.2,
                "Model_Interpretation": 0.1,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 10
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "model": 1,
                    "logisticregression": 2,
                    ".linear": 1
                },
                "Model_Evaluation": {
                    "model": 1,
                    ".score(": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    45,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "82.15"
                    ]
                },
                "mc_idx": 62,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 45,
                "o_idx": 0
            }
        },
        {
            "source": "#The next model Random Forests is one of the most popular. Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees (n_estimators=100) at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.\nfrom sklearn.ensemble import RandomForestClassifier\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\n\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest",
            "mc_idx": 63,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.6,
                "Model_Evaluation": 0.3,
                "Model_Interpretation": 0.1,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 10
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "model": 1,
                    "randomforestclassifier": 4
                },
                "Model_Evaluation": {
                    "model": 1,
                    ".score(": 2
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    46,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "90.68"
                    ]
                },
                "mc_idx": 63,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 46,
                "o_idx": 0
            }
        },
        {
            "source": "#These next few commands are a sidebar--in Excel we focused on Pclass and Sex and built a model.  Let's do a quick machine learning model!\n#This command drops all the columns that aren't Pclass or Sex, and then gives a sample to see. \ntrain_df = pd.read_csv('/kaggle/input/titanic/train.csv')\nquicktrain_df = train_df.drop(['PassengerId','Name','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked'], axis=1)\nquicktrain_df.sample(5)",
            "mc_idx": 66,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 0.25,
                "Model_Train": 0.5,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 2,
                    "pd.read_": 2
                },
                "Exploratory_Data_Analysis": {
                    "columns": 1,
                    ".sample": 1
                },
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {
                    "model": 2
                },
                "Model_Evaluation": {
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    47,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 66,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 47,
                "o_idx": 0
            }
        },
        {
            "source": "#Sex is a categorical variable \"male\" or \"female\" we need it to be integer valued for our machine learning model, so we switch to binary designation:\nquicktrain_df['Sex']=quicktrain_df['Sex'].map( {'female': 1, 'male': 0} )",
            "mc_idx": 67,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.5,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".map(": 1,
                    ".map": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    48,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 67,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 48,
                "o_idx": 0
            }
        },
        {
            "source": "#We want to use Pclass and Sex to determine survivability (like we did in Excel) so we drop the knowledge of \"Survived\" for our input variable X_train\n# and leave \"Survived\" in for our output variable.  Note, instead of dropping \"Survived\" we could have just designated using \"Pclass\" and \"Sex\" but\n# in a bigger model we would want to use many variables and just leave the predictor out.\nX_train = quicktrain_df.drop(\"Survived\", axis=1)\nY_train = quicktrain_df[\"Survived\"]",
            "mc_idx": 68,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 0.3333333333333333,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 3
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    49,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 68,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 49,
                "o_idx": 0
            }
        },
        {
            "source": "#This is our machine learning model, RandomForest, we'll talk about the details later\nfrom sklearn.ensemble import RandomForestClassifier\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest",
            "mc_idx": 69,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.1,
                "Data_Transform": 0.0,
                "Model_Train": 0.6,
                "Model_Evaluation": 0.2,
                "Model_Interpretation": 0.1,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 10
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "tail": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "model": 1,
                    "randomforestclassifier": 4
                },
                "Model_Evaluation": {
                    "model": 1,
                    ".score(": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    50,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 69,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 50,
                "o_idx": 0
            }
        },
        {
            "source": "quickml_df=train_df.drop(['PassengerId','Name','Age','Ticket','Fare','Cabin','Embarked'], axis=1)\nquickml_df['Sex']=quickml_df['Sex'].map( {'female': 1, 'male': 0} )\nX_train = quickml_df.drop(\"Survived\", axis=1)\nY_train = quickml_df[\"Survived\"]\nfrom sklearn.ensemble import RandomForestClassifier\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest\n",
            "mc_idx": 71,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.4,
                "Model_Train": 0.5,
                "Model_Evaluation": 0.1,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 10
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".map(": 1,
                    ".drop": 2,
                    ".map": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "randomforestclassifier": 4
                },
                "Model_Evaluation": {
                    ".score(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    51,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 71,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 51,
                "o_idx": 0
            }
        }
    ],
    "markdown_cells": [
        {
            "source": "I learned and combined various Kaggle submissions, hopefully using all I learned to help you learn!  You can access any of these below:\n* https://www.kaggle.com/code/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n* https://www.kaggle.com/code/nadintamer/titanic-survival-predictions-beginner\n* https://www.kaggle.com/code/ash316/eda-to-prediction-dietanic\n* https://www.kaggle.com/code/mrisdal/exploring-survival-on-the-titanic\n* https://www.kaggle.com/code/startupsci/titanic-data-science-solutions\n\nAs many of the above sites do, I'm trying to provide you an educational resource as to why things are done a certain way instead of just doing them!\nData Science (analytics/informatics/machine learning) sounds like fun to me, but, unfortunately, a majority of the time is spent in 'wrangling' the data and not just running an algorithm!",
            "mc_idx": 0,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "A Data Science Framework\n1. **Define the Problem**: If data science, big data, machine learning, predictive analytics, business intelligence, or any other buzzword is the solution, then what is the problem? As the saying goes, don't put the cart before the horse. Problems before requirements, requirements before solutions, solutions before design, and design before technology. Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the actual problem we are trying to solve.\n\n2. **Gather the Data**: John Naisbitt wrote in his 1984 (yes, 1984) book Megatrends, we are \u201cdrowning in data, yet staving for knowledge.\" So, chances are, the dataset(s) already exist somewhere, in some format. It may be external or internal, structured or unstructured, static or streamed, objective or subjective, etc. As the saying goes, you don't have to reinvent the wheel, you just have to know where to find it. In the next step, we will worry about transforming \"dirty data\" to \"clean data.\"\n\n3. **Prepare Data for Consumption**: This step is often referred to as data wrangling, a required process to turn \u201cwild\u201d data into \u201cmanageable\u201d data. Data wrangling includes implementing data architectures for storage and processing, developing data governance standards for quality and control, data extraction (i.e. ETL and web scraping), and data cleaning to identify aberrant, missing, or outlier data points.\n\n4. **Perform Exploratory Analysis**: Anybody who has ever worked with data knows, garbage-in, garbage-out (GIGO). Therefore, it is important to deploy descriptive and graphical statistics to look for potential problems, patterns, classifications, correlations and comparisons in the dataset. In addition, data categorization (i.e. qualitative vs quantitative) is also important to understand and select the correct hypothesis test or data model.\n\n5. **Model Data**: Like descriptive and inferential statistics, data modeling can either summarize the data or predict future outcomes. Your dataset and expected results, will determine the algorithms available for use. It's important to remember, algorithms are tools and not magical wands or silver bullets. You must still be the master craft (wo)man that knows how-to select the right tool for the job. An analogy would be asking someone to hand you a Philip screwdriver, and they hand you a flathead screwdriver or worst a hammer. At best, it shows a complete lack of understanding. At worst, it makes completing the project impossible. The same is true in data modelling. The wrong model can lead to poor performance at best and the wrong conclusion (that\u2019s used as actionable intelligence) at worst.\n\n6. **Validate and Implement Data Model**: After you've trained your model based on a subset of your data, it's time to test your model. This helps ensure you haven't overfit your model or made it so specific to the selected subset, that it does not accurately fit another subset from the same dataset. In this step we determine if our [model overfit, generalize, or underfit our dataset](https://docs.aws.amazon.com/machine-learning/latest/dg/model-fit-underfitting-vs-overfitting.html)\n\n7. **Optimize and Strategize**: This is the \"bionic man\" step, where you iterate back through the process to make it better...stronger...faster than it was before. As a data scientist, your strategy should be to outsource developer operations and application plumbing, so you have more time to focus on recommendations and design. Once you're able to package your ideas, this becomes your \u201ccurrency exchange\" rate.",
            "mc_idx": 1,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Step 1: Define the Problem**\nDevelop an algorithm to predict the survival outcome of passengers on the Titanic.\n\n**Step 2: Gather the Data**\nThe dataset is given to us!\n\n**Step 3: Prepare Data for Consumption**\nThe data is already organized, therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are not necessary (nor do I know how). Thus, only data cleaning is in scope.",
            "mc_idx": 2,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**3.2 Meet and Greet Data**\nGet to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)).\n\nNext we use the info() and sample() function, to get a quick and dirty overview of variable datatypes (i.e. qualitative vs quantitative).  We explored all of these in Excel, but I added some bits, so check it out again!\n\n1. The *Survived* variable is our outcome or dependent variable. It is a binary nominal datatype of 1 for survived and 0 for did not survive. All other variables are potential predictor or independent variables. It's important to note, **more predictor variables do not make a better model, but the right variables will.**\n2. The *PassengerID* and *Ticket* variables are assumed to be random unique identifiers, that have no impact on the outcome variable. Thus, they will be excluded from analysis.\n3. The *Pclass* variable is an ordinal datatype for the ticket class, a proxy for socio-economic status (SES), representing 1 = upper class, 2 = middle class, and 3 = lower class.\n4. The *Name* variable is a nominal datatype. It could be used in feature engineering to derive the gender from title, family size from surname, and SES from titles like doctor or master. Since these variables already exist, we'll make use of it to see if title, like 'Master', makes a difference.\n5. The *Sex* and *Embarked* variables are a categorical, nominal datatype. They will be converted to dummy variables for mathematical calculations.\n6. The *Age* and *Fare* variable are continuous quantitative datatypes.\n7. The *SibSp* represents number of related siblings/spouse aboard and *Parch* represents number of related parents/children aboard. Both are discrete quantitative datatypes. This can be used for feature engineering to create a family size and 'is alone' variable.\n8. The *Cabin* variable is missing many values, however, later we will make this a binary variable, Cabin=1, no Cabin=0.",
            "mc_idx": 5,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "There are 177 missing values for Age, 687 for Cabin, and 2 for Embarked.  Our algorithms can't work with values that are not numbers, listed as \"NaN\". So we'll need to decide what to do with these.",
            "mc_idx": 8,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Some of the highlights:  There are 891 unique names, as expected, only 2 sexes (as expected), the average age was 30, lots of unique tickets and Cabins, but only 3 embarked, the most common being \"S\" with 644 departing from there.",
            "mc_idx": 10,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# **3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting**\nIn this stage, we will clean our data by 1) correcting aberrant values and outliers, 2) completing missing information, 3) creating new features for analysis, and 4) converting fields to the correct format for calculations and presentation.\n\n1. **Correcting**: Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential outliers in age and fare. However, since they are reasonable values, we will wait until after we complete our exploratory analysis to determine if we should include or exclude from the dataset. It should be noted, that if they were unreasonable values, for example age = 800 instead of 80, then it's probably a safe decision to fix now. However, we want to use caution when we modify data from its original value, because it may be necessary to create an accurate model.\n\n2. **Completing**: There are null values or missing data in the age, cabin, and embarked field. Missing values can be bad, because some algorithms don't know how-to handle null values and will fail. While others, like decision trees, can handle null values. Thus, it's important to fix before we start modeling, in case we want to compare and contrast several models. There are two common methods, either delete the record or populate the missing value using a reasonable input. It is not recommended to delete the record, especially a large percentage of records, unless it truly represents an incomplete record. Instead, it's best to impute missing values. *A basic methodology for qualitative data is impute using mode*. *A basic methodology for quantitative data is impute using mean, median, or mean + randomized standard deviation*. An intermediate methodology is to use the basic methodology based on specific criteria; like the average age by class or embark port by fare and SES. There are more complex methodologies, however before deploying, it should be compared to the base model to determine if complexity truly adds value. Imputing age with median is easy (KISS), however, we could use the 'name' column to predict the age and get a better model (in exchange for more work!)  Embark will be imputed with mode. Subsequent model iterations may modify this decision to determine if it improves the model\u2019s accuracy.\n\n3. **Creating**: Feature engineering is when we use existing features to create new features to determine if they provide new signals to predict our outcome. For this dataset, we will create a **title** feature to determine if it played a role in survival.\n\n4. **Converting**: Last, but certainly not least, we'll deal with formatting. There are no date or currency formats, but datatype formats. Our categorical data imported as objects, which makes it difficult for mathematical calculations. For this dataset, we will convert object datatypes to categorical dummy variables.\n\n ",
            "mc_idx": 11,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**I vary from the original document at this point--I believe it is critical to incorporate step 4 \"Perform Exploratory Analysis\" alongside step 3 \"Prepare the Data\".  The reason for this is some data does not deserve our time.  For example, ticket number, there is no need to clean up this data because it does not tell us anything useful, it is just a random number assigned to people.  However, to know this we would have to do a little exploratory analysis. \nAnother example: Cabin.  Most kaggle Titanic sites I visited said \"Cabin doesn't matter\" and there is too much missign data, so just drop it.  HOWEVER, as we will soon see, those with Cabin data were more likely to survive than those without.  So, instead of eliminating the data, we will turn it binary.  \"1\" for \"has a cabin number\" and \"0\" for does not.  This will take care of all the NaN, and provide us with helpful information!",
            "mc_idx": 12,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**3.22 Clean Data**",
            "mc_idx": 13,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "FYI:  Most of these titles are \"rare\" meaning there are only a few of them.  Here is where the 'art' of data science comes into play.  We can combine them in different ways.  We could take everything that is not the big four: Mr, Mrs, Master, or Miss and combine it to \"Rare\".  Or we could use a finer toothed comb and notice that some of the titles are just abbreviations of titles we already know!\n\n* Mlle: Mademoiselle, an unmarried (presumably French) woman (\"Miss.\")\n* Mme: Madame, a married (presumably French) woman (\"Mrs.\")\n* Ms: we'll assume (\"Mrs.\")\n* Countess/Lady: (\"Mrs.\") --though one could also make the argument that Countess/Lady should be filed under \"Royalty\" --important for a different reason",
            "mc_idx": 17,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Time to tackle the missing age values.  Our recent work with \"Title\" will help alot!",
            "mc_idx": 28,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Now we need to rinse and repeat for Mr, Miss, Mrs, Rare**",
            "mc_idx": 33,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "SO--having a cabin played a HUGE role in survivability.  Though it should be noted that half of the kaggle websites I used dropped the feature as there were too many missing values.  It is better to convert what we know to \"1\" and what we don't know to \"0\".  Next we'll drop the \"Cabin\" column.",
            "mc_idx": 39,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 3.23 Time to use some tools to create (clean-up) the rest of the data!",
            "mc_idx": 43,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 5: MACHINE LEARNING MODELS!\nNow we are ready to train a model and predict the required solution. There are 60+ predictive modelling algorithms to choose from. We must understand the type of problem and solution requirement to narrow down to a select few models which we can evaluate. Our problem is a classification and regression problem. We want to identify relationship between output (Survived or not) with other variables or features (Gender, Age, Title...). We are also perfoming a category of machine learning which is called supervised learning as we are training our model with a given dataset. With these two criteria - Supervised Learning plus Classification and Regression, we can narrow down our choice of models to a few.",
            "mc_idx": 58,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "I wanted this picture to just be here, but I couldn't get it to work...so here's a link!\nhttps://ferrisstateuniversity-my.sharepoint.com/:i:/g/personal/troubaj_ferris_edu/EZSEiQEzaKlNhhNZpQuCn6QBX5i7D-6MCtXb7SQTl9waJg?e=LhpbMi",
            "mc_idx": 59,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "![](https://ferrisstateuniversity-my.sharepoint.com/:i:/g/personal/troubaj_ferris_edu/EZSEiQEzaKlNhhNZpQuCn6QBX5i7D-6MCtXb7SQTl9waJg?e=LhpbMi)",
            "mc_idx": 60,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Ahm, say what now?!? I guess 10-hours pays off!  \nNow, what really is happening is we have overfit our model.  We need to apply our random forest to new data.  Officially, Titanic data is divided into train data (what we've been using) and test data (where we actually need to apply our model).  If I have time, I'll see how this model does on the test data!",
            "mc_idx": 64,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#\n\n\n\n\nI'm leaving space for this stuff below.  I just can't delete it, it took me too long to enter.  Basically this stuff below is a VERY QUICK machine learning algorithm that deletes most columns and just lets things happen.",
            "mc_idx": 65,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "The point here is we get 78.68%--exactly the same as using excel to predict all women survived.  \nBut, we can easily go further...\nThe next command combines it all into one quick algorithm to get our highest percentage yet!  Essentially we keep SipSp (number of siblings and/or spouse aboard) and Parch (number of parents/children aboard), and let machine learning figure it out!",
            "mc_idx": 70,
            "nb_idx": 14,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        }
    ],
    "sim_matrix": [],
    "cell_sim_matrix": [],
    "nb_order": [],
    "summary_data_VA": null
}