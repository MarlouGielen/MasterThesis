{
    "nb_idx": 31,
    "nb_name": "d0031",
    "filename": "d29.ipynb",
    "filepath": "data/data_Kaggle/raw/d29.ipynb",
    "source": "<div style=\"padding: 20px; background-color: #000080; border-radius: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\">\n    <div style=\"border: 2px solid #000080; padding: 20px; text-align: center; border-radius: 10px; background-color: #ffffff;\">\n        <h1 style=\"color: #00000; font-size: 32px; text-transform: uppercase; letter-spacing: 2px; margin-bottom: 20px;\">Become a feature selection master</h1>\n        <div><em>\n       If you like the content please consider an upvote. It is a great motivator to keep sharing code and ideas.\n        Thank you!!!\n    </em></div>\n</div> \n In this notebook we will dive through various feature selection options. We will illustrate this on two model architectures to show the differences there as well. \n <h1 style=\"background-color: #000080; color: #ffff00;\">Table of contents</h1>\n\n* [Load tand install libraries](#1)\n* [Load the data](#2)\n* [Create helper functions and classes](#3)\n* [Mastering feature selection](#4)\n    * [Creating a baseline](#4.1)\n    * [Using statistical methods](#4.2)\n        * [No correlation to target](#4.2.1)\n        * [Mutual information score](#4.2.2)\n        * [Collinearity in the dataset](4.2.3)\n    * [Using model inbuilt feature importance](#4.3)\n        * [Linear Regression](#4.3.1)\n        * [HistGradientBoosting](#4.3.2)\n            * [Gain](#4.3.2.1)\n            * [Weight](#4.3.2.2)\n            * [Cover](#4.3.2.3)\n            * [Total gain](#4.3.2.4)\n            * [Total cover](#4.3.2.5)\n    * [Using feature selection algorithms](#4.4)\n        * [Using recursive feature elimination](#4.4.1)\n        * [Using recursive feature elimination with inbuilt cross validation](#4.4.2)\n        * [Sequential feature selection](#4.4.3)\n        * [Lime](#4.4.4)\n        * [Shap](#4.4.5)\n        * [Boruta](#4.4.5)\n* [Comparing the results](#5.0)\n* [How to (not) interpret feature importance](#6.0)\n* [Submission time](#7.0) \n <h1 style=\"background-color: #000080; color: #ffff00;\">Load and install libraries</h1> \n %%capture\n!pip install lime \n import numpy as np\nimport pandas as pd\nimport time\n\nimport lime\nfrom lime import lime_tabular\nfrom lime import submodular_pick\n\nimport optuna\nimport shap\n\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import mutual_info_classif, RFE, RFECV, SequentialFeatureSelector\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.metrics import make_scorer, accuracy_score\n\nimport xgboost as xgb \n <h1 style=\"background-color: #000080; color: #ffff00;\">Load the data</h1> \n train = pd.read_csv(r'/kaggle/input/titanic/train.csv')\ntest = pd.read_csv(r'/kaggle/input/titanic/test.csv')\nsample_submission = pd.read_csv(r'/kaggle/input/titanic/gender_submission.csv') \n target = \"Survived\" \n # borrowed from here: https://www.kaggle.com/code/tisa33/titanic-sk-87-2-rf-84-4-tf-87-1-rf-84-9/notebook\ndef normailize_data(df):\n    df['Cabin_Letter'] = df['Cabin'].apply(lambda x: str(x)[0])\n    df['Name_Title'] = df['Name'].apply(lambda x: x.split()[1]).apply(lambda x: x.split()[0])\n    df['Name_Len'] = df['Name'].apply(lambda x: len(x))\n    df['Age_Null'] = df['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n    #df['Age'] = df.groupby(['Name_Title', 'Pclass', 'Sex'])['Age'].transform(lambda x: x.fillna(x.mean()))\n    df['Age'] = df['Age'].fillna(0)\n    df['Ticket_Type'] = df['Ticket'].apply(lambda x: x[0])\n    df['Age'] = (df['Age'] - df['Age'].min()) / (df['Age'].max() - df['Age'].min())\n    df['Fare'] = (df['Fare'] - df['Fare'].min()) / (df['Fare'].max() - df['Fare'].min())\n    df['Name_Len'] = (df['Name_Len'] - df['Name_Len'].min()) / (df['Name_Len'].max() - df['Name_Len'].min())\n    df['SibSp'] = (df['SibSp'] - df['SibSp'].min()) / (df['SibSp'].max() - df['SibSp'].min())\n    df['Parch'] = (df['Parch'] - df['Parch'].min()) / (df['Parch'].max() - df['Parch'].min())\n    df = pd.get_dummies(df, columns=['Sex', 'Embarked', 'Name_Title', 'Cabin_Letter', 'Ticket_Type', 'Pclass'], drop_first=True, dtype=int)\n    df = df.drop(['Name', 'Cabin', 'PassengerId', 'Ticket'], axis=1)\n    return df\n\nfull_data = pd.concat([train, test])\nfull_data = normailize_data(full_data)\ntrain = full_data.loc[full_data[target].isna() == False].copy().fillna(0)\ntest = full_data.loc[full_data[target].isna() == True].copy().fillna(0) \n X = train.copy()\ny = X.pop(target) \n <h1 style=\"background-color: #000080; color: #ffff00;\">Create helper functions and classes</h1> \n class ResultTracker:\n    def __init__(self):\n        self.losses_mean = []\n        self.losses_std = []\n        self.runtime_secs = []\n        self.model_name = []\n        self.experiment_name  = []\n        \n    def eval_model(self, model, X, y):\n        mae_scorer = make_scorer(accuracy_score, greater_is_better=True)\n        start = time.time()\n        losses = cross_val_score(model, X, y, cv=5, n_jobs=-1, scoring=mae_scorer)\n        end = time.time()\n        runtime_secs = end - start\n        return np.mean(losses), np.std(losses),  runtime_secs\n    \n    def add_experiment(self, *, model, X, y, model_name, experiment_name):\n        exp_mean, exp_std, runtime_secs = self.eval_model(model, X, y)\n        print(f\"Model {model_name} achieved a score of {exp_mean} with an std of {exp_std} in {runtime_secs} secs\")\n        \n        self.losses_mean.append(exp_mean)\n        self.losses_std.append(exp_std)\n        self.runtime_secs.append(runtime_secs)\n        self.model_name.append(model_name)\n        self.experiment_name.append(experiment_name)\n        \n    def retrive_results(self):\n        results_df = pd.DataFrame(\n            {\n                \"losses_mean\": self.losses_mean,\n                \"losses_std\": self.losses_std,\n                \"runtime_secs\": self.runtime_secs,\n                \"model_name\": self.model_name,\n                \"experiment_name\": self.experiment_name\n            }\n        )\n        return results_df \n tracker = ResultTracker() \n <h1 style=\"background-color: #000080; color: #ffff00;\">Mastering feature selection</h1>\n\nNow that we installed everything we need and loaded our data it is time to deep dive into the actual topic. On purpose I do not preprocess the data, oping that we can see a bit more variation between both models.\n\nFeel free to copy the notebook and play with some preprocessing. \n <h2 style=\"background-color: #000080; color: #ffff00;\">Creating a baseline</h2>\n\nBefore we start we create a bseline for our models were we just run them using all features. \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X, y=y, model_name=\"HistGradientBoosting\", experiment_name=\"using_all_features\")\ntracker.add_experiment(model=lin_est, X=X, y=y, model_name=\"LogisticRegression\", experiment_name=\"using_all_features\") \n <h2 style=\"background-color: #000080; color: #ffff00;\">Using statistical methods</h2>\n\nIn this section we will remove features based on statistical methods and properties. \n <h3 style=\"background-color: #000080; color: #ffff00;\">No correlation to target</h3>\n\nWe measure the correlation of all columns to the target and eliminate the ones that have almost no correlation. This captures linear relationships only, which is a hard limitation and might underestimate the value of a feature. \n def calculate_correlations(df: pd.DataFrame, target: pd.Series) -> pd.DataFrame:\n    \"\"\"\n    Calculates the correlations of all columns with regards to the target and returns a DataFrame with all column names\n    and their correlation coefficient with regards to the target.\n    \n    :param df: Pandas DataFrame\n    :param target: Pandas Series with target values\n    :return: Pandas DataFrame with column names and their correlation coefficient with regards to the target\n    \"\"\"\n    correlations = df.corrwith(target)\n    return pd.DataFrame(correlations, columns=['correlation_coefficient']) \n correlations = calculate_correlations(X, y)\ncorrelations \n Here we remove the columns with a correlation coefficient close to zero. \n keep_columns = correlations.loc[\n    (\n        (correlations[\"correlation_coefficient\"] >= 0.1) |\n        (correlations[\"correlation_coefficient\"] <= -0.1)\n    )\n].index.to_list()\n\nkeep_columns \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_columns], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"removed_no_corr_to_target\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_columns], y=y, model_name=\"LogisticRegression\", experiment_name=\"removed_no_corr_to_target\") \n <h3 style=\"background-color: #000080; color: #ffff00;\">Mutual information score</h3>\n\nWe measure the mutual information score of all columns to with regards to the target and remove the ones with almost zero scoring. MI scores also consider non-linear information. \n def calculate_mi_scores(df, target):\n    \"\"\"\n    Calculates the mutual information score of all columns with regards to the (regression) target.\n    \n    Parameters:\n    df (Pandas DataFrame): The DataFrame containing the features.\n    target (Pandas Series): The target variable.\n    \n    Returns:\n    Pandas DataFrame: A DataFrame with all column names and their MI scores with regards to the target.\n    \"\"\"\n    mi_scores = mutual_info_classif(df, target)\n    mi_scores = pd.Series(mi_scores, name='MI Scores', index=df.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores.to_frame() \n mi_scores = calculate_mi_scores(X, y)\nmi_scores \n Interesting! Only the id column has very little value. So we only remove that one. \n keep_columns = mi_scores.loc[(mi_scores[\"MI Scores\"] >= 0.0)].index.to_list()\n\nkeep_columns \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_columns], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"removed_low_mi_score_to_target\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_columns], y=y, model_name=\"LogisticRegression\", experiment_name=\"removed_low_mi_score_to_target\") \n <h3 style=\"background-color: #000080; color: #ffff00;\">Collinearity in the dataset</h3>\n\nWe measure the correlation of all columns to each other and remove the ones with high correlation (one of them). \n def remove_collinearity(dataset, threshold=0.9):\n    \"\"\"\n    Loops through all columns and checks, if features are highly positively correlated.\n    If correlation is above given threshold, then only one column is kept.\n    :param threshold: Maximum allowed correlation. Expects a float from -1 to +1.\n    :return: Returns modified dataframe.\n    \"\"\"\n    col_corr = set()  # Set of all the names of deleted columns\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if (corr_matrix.iloc[i, j] >= threshold) and (\n                corr_matrix.columns[j] not in col_corr\n            ):\n                colname = corr_matrix.columns[i]  # getting the name of column\n                col_corr.add(colname)\n                if colname in dataset.columns:\n                    del dataset[colname]  # deleting the column from the dataset\n    return dataset \n X_thres_09 = remove_collinearity(X.copy(), 0.9)\nX_thres_09.columns.to_list()\nprint(f\"Removed columns {set(X.columns.to_list()) - set(X_thres_09.columns.to_list())}\") \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X_thres_09, y=y, model_name=\"HistGradientBoosting\", experiment_name=\"removed_collinearity_with_090plus\")\ntracker.add_experiment(model=lin_est, X=X_thres_09, y=y, model_name=\"LogisticRegression\", experiment_name=\"removed_collinearity_with_090plus\") \n X_thres_08 = remove_collinearity(X.copy(), 0.8)\nX_thres_08.columns.to_list()\nprint(f\"Removed columns {set(X.columns.to_list()) - set(X_thres_08.columns.to_list())}\") \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X_thres_08, y=y, model_name=\"HistGradientBoosting\", experiment_name=\"removed_collinearity_with_080plus\")\ntracker.add_experiment(model=lin_est, X=X_thres_08, y=y, model_name=\"LogisticRegression\", experiment_name=\"removed_collinearity_with_080plus\") \n <h2 style=\"background-color: #000080; color: #ffff00;\">Using model inbuilt feature importance</h2>\n\nIn this section we will invvestigate if the models itself provide us valueable information for feature selection. \n <h3 style=\"background-color: #000080; color: #ffff00;\">Linear Regression</h3>\n\nFor linear regression we need to train an instance first. Then we can make use of it's own coefficients to select features. \n lin_est = LogisticRegression()\nlin_est.fit(X, y) \n print(lin_est.coef_.shape, len(X.columns))\nlin_est.coef_ \n ((lin_est.coef_ < -0.05) | (lin_est.coef_ > 0.05))[0] \n We remove columns with coefficients close to zero.. \n keep_cols = X.loc[:, ((lin_est.coef_ < -0.05) | (lin_est.coef_ > 0.05))[0]].columns.to_list()\nkeep_cols \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"removed_lower_half_of_lr_coefficients\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"removed_lower_half_of_lr_coefficients\") \n <h3 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoosting</h3> \n It seems like the HistGradientBoostingClassifier from sklearn does not offer any feature importance functionality. However we can make use of HistGradientBoosting also via the Xgboost library and get our importances from there.\n\nHere we can pass one of multiple importance types via the importance_type parameter (see the [docs](https://xgboost.readthedocs.io/en/stable/python/python_api.html):\nThe feature importance type for the feature_importances_ property:\n* For tree model, it\u2019s either \u201cgain\u201d, \u201cweight\u201d, \u201ccover\u201d, \u201ctotal_gain\u201d or \u201ctotal_cover\u201d.\n* For linear model, only \u201cweight\u201d is defined and it\u2019s the normalized coefficients without bias.\n\nAs you can see there is a total of 5 feature importance metrics within gradient boosting. What is behind each of them I will quote from [this](https://towardsdatascience.com/be-careful-when-interpreting-your-features-importance-in-xgboost-6e16132588e7) Medium article. Please consider some claps there.\n \n <h4 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoosting gain</h4>\n\n\"The Gain implies the relative contribution of the corresponding feature to the model calculated by taking each feature\u2019s contribution for each tree in the model. A higher value of this metric when compared to another feature implies it is more important for generating a prediction.\n\nThe Gain is the most relevant attribute to interpret the relative importance of each feature.\n\n\u2018Gain\u2019 is the improvement in accuracy brought by a feature to the branches it is on. The idea is that before adding a new split on a feature X to the branch there was some wrongly classified elements, after adding the split on this feature, there are two new branches, and each of these branch is more accurate (one branch saying if your observation is on this branch then it should be classified as 1, and the other branch saying the exact opposite).\" \n model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"gain\")\nmodel.fit(X, y) \n xgb_gain = model.feature_importances_\nxgb_gain \n keep_cols = X.loc[:, xgb_gain > 0.05].columns.to_list()\nkeep_cols \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"xgboost_importance_gain\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"xgboost_importance_gain\") \n <h4 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoosting weight</h4>\n\n\"The Frequency (R)/Weight (python) is the percentage representing the relative number of times a particular feature occurs in the trees of the model. In the above example, if feature1 occurred in 2 splits, 1 split and 3 splits in each of tree1, tree2 and tree3; then the weight for feature1 will be 2+1+3 = 6. The frequency for feature1 is calculated as its percentage weight over weights of all features.\" \n model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"weight\")\nmodel.fit(X, y) \n xgb_weight = model.feature_importances_\nxgb_weight \n keep_cols = X.loc[:, xgb_weight > 0.05].columns.to_list()\nkeep_cols \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"xgboost_importance_weight\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"xgboost_importance_weight\") \n <h4 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoosting cover</h4>\n\n\"The Coverage metric means the relative number of observations related to this feature. For example, if you have 100 observations, 4 features and 3 trees, and suppose feature1 is used to decide the leaf node for 10, 5, and 2 observations in tree1, tree2 and tree3 respectively; then the metric will count cover for this feature as 10+5+2 = 17 observations. This will be calculated for all the 4 features and the cover will be 17 expressed as a percentage for all features\u2019 cover metrics.\" \n model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"cover\")\nmodel.fit(X, y) \n xgb_cover = model.feature_importances_\nxgb_cover \n keep_cols = X.loc[:, xgb_cover > 0.05].columns.to_list()\nkeep_cols \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"xgboost_importance_cover\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"xgboost_importance_cover\") \n <h4 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoosting total_gain</h4> \n model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"total_gain\")\nmodel.fit(X, y) \n xgb_total_gain = model.feature_importances_\nxgb_total_gain \n keep_cols = X.loc[:, xgb_total_gain > 0.05].columns.to_list()\nkeep_cols \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"xgboost_importance_total_gain\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"xgboost_importance_total_gain\") \n <h4 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoostingRegressor total_cover</h4> \n model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"total_cover\")\nmodel.fit(X, y) \n xgb_total_cover = model.feature_importances_\nxgb_total_cover \n keep_cols = X.loc[:, xgb_total_cover > 0.05].columns.to_list()\nkeep_cols \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"xgboost_importance_total_cover\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"xgboost_importance_total_cover\") \n <h2 style=\"background-color: #000080; color: #ffff00;\">Using feature selection algorithms</h2>\n\nIn this section we will investigate algorithms designed for feature selection. \n <h3 style=\"background-color: #000080; color: #ffff00;\">Using recursive feature elimination</h3>\n\n\"Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through any specific attribute or callable. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.\" (see [sklearn docs](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html))\n\nOne disadvantage here is that we need to tell in advance how many features shall be selected. One re-occuring pattern in this section is that these algorithms are not model agnostic. Therefore we will test each of them for both of our models if possible. \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\nhist_selector, lin_selector = RFE(hist_est, n_features_to_select=10, step=1), RFE(lin_est, n_features_to_select=10, step=1) \n #hist_selector = hist_selector.fit(X, y)\n#hist_selector.support_ \n This is not compatible with HistGradienBoosting as it misses `coef_` and `feature_importances_` attributes. \n lin_selector = lin_selector.fit(X, y)\nlin_selector.support_ \n keep_cols = X.loc[:, lin_selector.support_].columns.to_list()\nkeep_cols \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"rfe_based_on_logistic_regression\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"rfe_based_on_logistic_regression\") \n <h3 style=\"background-color: #000080; color: #ffff00;\">Using recursive feature elimination with inbuilt cross validation</h3> \n lin_est = LogisticRegression()\nlin_selector = RFECV(lin_est, step=1, cv=5) \n lin_selector = lin_selector.fit(X, y)\nlin_selector.support_ \n keep_cols = X.loc[:, lin_selector.support_].columns.to_list()\nkeep_cols \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"rfecv_based_on_logistic_regression\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"rfecv_based_on_logistic_regression\") \n <h3 style=\"background-color: #000080; color: #ffff00;\">Sequential feature selection</h3>\n\n\"This Sequential Feature Selector adds (forward selection) or removes (backward selection) features to form a feature subset in a greedy fashion. At each stage, this estimator chooses the best feature to add or remove based on the cross-validation score of an estimator. In the case of unsupervised learning, this Sequential Feature Selector looks only at the features (X), not the desired outputs (y).\" (see [sklearn docs](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html)) \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\nhist_sfs, lin_sfs = SequentialFeatureSelector(hist_est, n_features_to_select=10), SequentialFeatureSelector(lin_est, n_features_to_select=10) \n Skipping hist as this is really slow here \n #hist_sfs.fit(X, y)\n#hist_sfs.get_support() \n #keep_cols = X.loc[:, hist_sfs.get_support()].columns.to_list()\n#keep_cols \n #hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\n#tracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"seq_feat_sel_on_histgb\")\n#tracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"seq_feat_sel_on_histgb\") \n lin_sfs.fit(X, y)\nlin_sfs.get_support() \n keep_cols = X.loc[:, lin_sfs.get_support()].columns.to_list()\nkeep_cols \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"seq_feat_sel_on_logistic_regression\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"seq_feat_sel_on_logistic_regression\") \n <h3 style=\"background-color: #000080; color: #ffff00;\">Lime</h3>\n\nLime is a model explanantion framework that tries to \"solve for model interpretability by producing locally faithful explanations\". (see the source of the quote and deeper explanations in [this](https://towardsdatascience.com/decrypting-your-machine-learning-model-using-lime-5adc035109b5) Medium article). \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression() \n x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=100) \n hist_est.fit(x_train, y_train) \n explainer = lime_tabular.LimeTabularExplainer(\n    training_data=x_train.values,\n    feature_names=x_train.columns,\n    mode='regression'\n) \n exp = explainer.explain_instance(\n    data_row=x_test.iloc[1], \n    predict_fn=hist_est.predict\n) \n Lime offers us the ability to explain feature importance on row level. Let's show this for the second row in the DataFrame: \n exp.show_in_notebook(show_table=True) \n We use the sub-modular attributes available on SP-LIME to obtain a global perspective of the data instances. Then, we visualize the data to visual global representative samples extracted by the SP-LIME algorithm. This takes much longer than the local explanations. \n %%capture\nsp_exp = submodular_pick.SubmodularPick(explainer, \n                                        x_test.values,\n                                        predict_fn=hist_est.predict,\n                                        num_features=10,\n                                        num_exps_desired=5)\n \n [exp.show_in_notebook() for exp in sp_exp.sp_explanations]\nprint('SP-LIME Explanations.') \n It this not so easy to keep an overview here. Let's keep Sex_male and Name_Title_Master only. \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(\n    model=hist_est, \n    X=X.loc[:, [\"Sex_male\", \"Name_Title_Master.\"]], \n    y=y, \n    model_name=\"HistGradientBoosting\", \n    experiment_name=\"lime_visual_inspection_based_on_hist\"\n)\n\ntracker.add_experiment(\n    model=lin_est, \n    X=X.loc[:, [\"Sex_male\", \"Name_Title_Master.\"]],\n    y=y, \n    model_name=\"LogisticRegression\", \n    experiment_name=\"lime_visual_inspection_based_on_hist\"\n) \n We do one for linear regression as well. \n lin_est.fit(x_train, y_train)\nexplainer = lime_tabular.LimeTabularExplainer(\n    training_data=x_train.values,\n    feature_names=x_train.columns,\n    mode='regression'\n) \n %%capture\nsp_exp = submodular_pick.SubmodularPick(explainer, \n                                        x_test.values,\n                                        predict_fn=lin_est.predict,\n                                        num_features=10,\n                                        num_exps_desired=5) \n [exp.show_in_notebook() for exp in sp_exp.sp_explanations]\nprint('SP-LIME Explanations.') \n For this example we keep Sex_male and Ticket_Type_3 \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(\n    model=hist_est, \n    X=X.loc[:, [\"Sex_male\", \"Ticket_Type_3\"]],\n    y=y, \n    model_name=\"HistGradientBoosting\", \n    experiment_name=\"lime_visual_inspection_based_on_logistic_regression\"\n)\n\ntracker.add_experiment(\n    model=lin_est, \n    X=X.loc[:, [\"Sex_male\", \"Ticket_Type_3\"]], \n    y=y, \n    model_name=\"LogisticRegression\", \n    experiment_name=\"lime_visual_inspection_based_on_logistic_regression\"\n) \n <h3 style=\"background-color: #000080; color: #ffff00;\">Shap</h3>\n\n\"SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions[...]\" ([source](https://shap.readthedocs.io/en/latest/))\n\nThe original paper can be found [here](https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf). \n hist_est.fit(x_train, y_train) \n HistGradientBoosting is not yet supported by Shaps TreeExplainer (which is much faster for tree-based models). Alos be aware, that a model trained on GPU will utilize GPU acceleration also within Shap! \n explainer = shap.Explainer(hist_est.predict, x_test)\nshap_values = explainer(x_test) \n Let's show the feature importances... \n shap.summary_plot(shap_values, max_display=25, show=True) \n We can also show this as a barplot. \n shap.summary_plot(shap_values, max_display=35, show=False, plot_type='bar') \n In both plots the values are sorted top down by importance.\nThe shap library has also beautiful visuals to explore feature importance for individual rows and also dependency plots to better undersatnd feature interactions. I will skip this here as the Kernel is pretty long already.\n\nLet's drop [\"Name_Title_Gordon,\", \"Name_Title_Impe,\", \"Name_Itle_Jonkheer.\", \"Name_Title_Mlle.\", \"Ticket_Type_W\", \"Name_Title_Melkebelke\"] etc here. \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression() \n drop_cols = [\n    \"Name_Title_Gordon,\", \n    \"Name_Title_Impe,\", \n    \"Name_Title_Jonkheer.\", \n    \"Name_Title_Mlle.\", \n    \"Ticket_Type_W\", \n    \"Name_Title_Melkebeke,\",\n    \"Name_Title_Messemaeker,\",\n    \"Name_Title_Col.\",\n    \"Age_Null\"\n] \n tracker.add_experiment(\n    model=hist_est, \n    X=X.drop(drop_cols, axis=1),\n    y=y, \n    model_name=\"HistGradientBoosting\", \n    experiment_name=\"shap_visual_inspection_based_on_hist\"\n)\n\ntracker.add_experiment(\n    model=lin_est, \n    X=X.drop(drop_cols, axis=1), \n    y=y, \n    model_name=\"LogisticRegression\", \n    experiment_name=\"shap_visual_inspection_based_on_hist\"\n) \n We do the same for linear regression as Shap (like Lime) is not model-agnostic. \n lin_est.fit(x_train, y_train) \n explainer = shap.Explainer(lin_est.predict, x_test)\nshap_values = explainer(x_test) \n shap.summary_plot(shap_values, max_display=35, show=True) \n Here we drop just Name_Title_Dr. and Ticket_Type_F and S. \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression() \n tracker.add_experiment(\n    model=hist_est, \n    X=X.drop([\"Name_Title_Dr.\", \"Ticket_Type_F\", \"Ticket_Type_S\", \"Name_Title_Rev.\"], axis=1),\n    y=y, \n    model_name=\"HistGradientBoosting\", \n    experiment_name=\"shap_visual_inspection_based_on_logistic_regression\"\n)\n\ntracker.add_experiment(\n    model=lin_est, \n    X=X.drop([\"Name_Title_Dr.\", \"Ticket_Type_F\", \"Ticket_Type_S\", \"Name_Title_Rev.\"], axis=1), \n    y=y, \n    model_name=\"LogisticRegression\", \n    experiment_name=\"shap_visual_inspection_based_on_logistic_regression\"\n) \n <h3 style=\"background-color: #000080; color: #ffff00;\">Boruta</h3>\n\nIn Boruta, features do not compete among themselves. They are compared with a randomized version of them instead.\n\"In practice, starting from X, another dataframe is created by randomly shuffling each feature. These permuted features are called shadow features. At this point, the shadow dataframe is attached to the original dataframe to obtain a new dataframe (we will call it X_boruta), which has twice the number of columns of X.\"\n\nFor more details check out [this](https://towardsdatascience.com/boruta-explained-the-way-i-wish-someone-explained-it-to-me-4489d70e154a) Medium article.\n\nOver the past decade the boruta algorithm has seen multiple implementations and variants. The original algorithm is quite slow. Instead we use a less-known, but powerful variant: boostaroota\n\nPlease be aware, that boostaroota was a research project and is not maintained. It seems like compatibility breaks with Panndas 2.0 or higher. However the code is open source and could be adapted.\n\nIn general I struggled to find any Boruta implementation that can be installed in this Kernel and just runs without an error. Therefore I decided to tak the boostaroota source code and add it below, but debug the breaking parts.\n\nBoostaroota runs now and expects an estimator with a feature_imprtance_ attribute. This does not apply to HistGradientBoosting and linear regression, so we fallback to Xgboost once again. \n import numpy as np\nimport pandas as pd\nimport xgboost as xgb\nimport operator\nimport warnings\n\n\n########################################################################################\n#\n# Main Class and Methods\n#\n########################################################################################\n\n\nclass BoostARoota(object):\n\n    def __init__(self, metric=None, clf=None, cutoff=4, iters=10, max_rounds=100, delta=0.1, silent=False):\n        self.metric = metric\n        self.clf = clf\n        self.cutoff = cutoff\n        self.iters = iters\n        self.max_rounds = max_rounds\n        self.delta = delta\n        self.silent = silent\n        self.keep_vars_ = None\n\n        #Throw errors if the inputted parameters don't meet the necessary criteria\n        if (metric is None) and (clf is None):\n            raise ValueError('you must enter one of metric or clf as arguments')\n        if cutoff <= 0:\n            raise ValueError('cutoff should be greater than 0. You entered' + str(cutoff))\n        if iters <= 0:\n            raise ValueError('iters should be greater than 0. You entered' + str(iters))\n        if (delta <= 0) | (delta > 1):\n            raise ValueError('delta should be between 0 and 1, was ' + str(delta))\n\n        #Issue warnings for parameters to still let it run\n        if (metric is not None) and (clf is not None):\n            warnings.warn('You entered values for metric and clf, defaulting to clf and ignoring metric')\n        if delta < 0.02:\n            warnings.warn(\"WARNING: Setting a delta below 0.02 may not converge on a solution.\")\n        if max_rounds < 1:\n            warnings.warn(\"WARNING: Setting max_rounds below 1 will automatically be set to 1.\")\n\n    def fit(self, x, y):\n        self.keep_vars_ = _BoostARoota(x, y,\n                                       metric=self.metric,\n                                       clf = self.clf,\n                                       cutoff=self.cutoff,\n                                       iters=self.iters,\n                                       max_rounds=self.max_rounds,\n                                       delta=self.delta,\n                                       silent=self.silent)\n        return self\n\n    def transform(self, x):\n        if self.keep_vars_ is None:\n            raise ValueError(\"You need to fit the model first\")\n        return x[self.keep_vars_]\n\n    def fit_transform(self, x, y):\n        self.fit(x, y)\n        return self.transform(x)\n\n########################################################################################\n#\n# Helper Functions to do the Heavy Lifting\n#\n########################################################################################\n\n\ndef _create_shadow(x_train):\n    \"\"\"\n    Take all X variables, creating copies and randomly shuffling them\n    :param x_train: the dataframe to create shadow features on\n    :return: dataframe 2x width and the names of the shadows for removing later\n    \"\"\"\n    x_shadow = x_train.copy()\n    for c in x_shadow.columns:\n        np.random.shuffle(x_shadow[c].values)\n    # rename the shadow\n    shadow_names = [\"ShadowVar\" + str(i + 1) for i in range(x_train.shape[1])]\n    x_shadow.columns = shadow_names\n    # Combine to make one new dataframe\n    new_x = pd.concat([x_train, x_shadow], axis=1)\n    return new_x, shadow_names\n\n########################################################################################\n#\n# BoostARoota\n#\n########################################################################################\n\n\ndef _reduce_vars_xgb(x, y, metric, this_round, cutoff, n_iterations, delta, silent):\n    \"\"\"\n    Function to run through each\n    :param x: Input dataframe - X\n    :param y: Target variable\n    :param metric: Metric to optimize in XGBoost\n    :param this_round: Round so it can be printed to screen\n    :return: tuple - stopping criteria and the variables to keep\n    \"\"\"\n    #Set up the parameters for running the model in XGBoost - split is on multi log loss\n    if metric == 'mlogloss':\n        param = {'objective': 'multi:softmax',\n                 'eval_metric': 'mlogloss',\n                 'num_class': len(np.unique(y)),\n                 'silent': 1}\n    else:\n        param = {'eval_metric': metric,\n                 'silent': 1}\n    for i in range(1, n_iterations+1):\n        # Create the shadow variables and run the model to obtain importances\n        new_x, shadow_names = _create_shadow(x)\n        dtrain = xgb.DMatrix(new_x, label=y)\n        bst = xgb.train(param, dtrain, verbose_eval=False)\n        if i == 1:\n            df = pd.DataFrame({'feature': new_x.columns})\n            pass\n\n        importance = bst.get_fscore()\n        importance = sorted(importance.items(), key=operator.itemgetter(1))\n        df2 = pd.DataFrame(importance, columns=['feature', 'fscore'+str(i)])\n        df2['fscore'+str(i)] = df2['fscore'+str(i)] / df2['fscore'+str(i)].sum()\n        df = pd.merge(df, df2, on='feature', how='outer')\n        if not silent:\n            print(\"Round: \", this_round, \" iteration: \", i)\n\n    df['Mean'] = df.mean(axis=1)\n    #Split them back out\n    real_vars = df[~df['feature'].isin(shadow_names)]\n    shadow_vars = df[df['feature'].isin(shadow_names)]\n\n    # Get mean value from the shadows\n    mean_shadow = shadow_vars['Mean'].mean() / cutoff\n    real_vars = real_vars[(real_vars.Mean > mean_shadow)]\n\n    #Check for the stopping criteria\n    #Basically looking to make sure we are removing at least 10% of the variables, or we should stop\n    if (len(real_vars['feature']) / len(x.columns)) > (1-delta):\n        criteria = True\n    else:\n        criteria = False\n\n    return criteria, real_vars['feature']\n\n\ndef _reduce_vars_sklearn(x, y, clf, this_round, cutoff, n_iterations, delta, silent):\n    \"\"\"\n    Function to run through each\n    :param x: Input dataframe - X\n    :param y: Target variable\n    :param clf: the fully specified classifier passed in by user\n    :param this_round: Round so it can be printed to screen\n    :return: tuple - stopping criteria and the variables to keep\n    \"\"\"\n    #Set up the parameters for running the model in XGBoost - split is on multi log loss\n\n    for i in range(1, n_iterations+1):\n        # Create the shadow variables and run the model to obtain importances\n        new_x, shadow_names = _create_shadow(x)\n        clf = clf.fit(new_x, np.ravel(y))\n\n        if i == 1:\n            df = pd.DataFrame({'feature': new_x.columns})\n            df2 = df.copy()\n            pass\n\n        try:\n            importance = clf.feature_importances_\n            df2['fscore' + str(i)] = importance\n        except ValueError:\n            print(\"this clf doesn't have the feature_importances_ method.  Only Sklearn tree based methods allowed\")\n\n        # importance = sorted(importance.items(), key=operator.itemgetter(1))\n\n        # df2 = pd.DataFrame(importance, columns=['feature', 'fscore'+str(i)])\n        df2['fscore'+str(i)] = df2['fscore'+str(i)] / df2['fscore'+str(i)].sum()\n        df = pd.merge(df, df2, on='feature', how='outer', suffixes=('', '_y'))\n        df.drop(df.filter(regex='_y$').columns, axis=1, inplace=True)\n        if not silent:\n            print(\"Round: \", this_round, \" iteration: \", i)\n\n    df['Mean'] = df.drop(\"feature\", axis=1).mean(axis=1)\n    #Split them back out\n    real_vars = df[~df['feature'].isin(shadow_names)]\n    shadow_vars = df[df['feature'].isin(shadow_names)]\n\n    # Get mean value from the shadows\n    mean_shadow = shadow_vars['Mean'].mean() / cutoff\n    real_vars = real_vars[(real_vars.Mean > mean_shadow)]\n\n    #Check for the stopping criteria\n    #Basically looking to make sure we are removing at least 10% of the variables, or we should stop\n    if (len(real_vars['feature']) / len(x.columns)) > (1-delta):\n        criteria = True\n    else:\n        criteria = False\n\n    return criteria, real_vars['feature']\n\n#Main function exposed to run the algorithm\ndef _BoostARoota(x, y, metric, clf, cutoff, iters, max_rounds, delta, silent):\n    \"\"\"\n    Function loops through, waiting for the stopping criteria to change\n    :param x: X dataframe One Hot Encoded\n    :param y: Labels for the target variable\n    :param metric: The metric to optimize in XGBoost\n    :return: names of the variables to keep\n    \"\"\"\n\n    new_x = x.copy()\n    #Run through loop until \"crit\" changes\n    i = 0\n    while True:\n        #Inside this loop we reduce the dataset on each iteration exiting with keep_vars\n        i += 1\n        if clf is None:\n            crit, keep_vars = _reduce_vars_xgb(new_x,\n                                               y,\n                                               metric=metric,\n                                               this_round=i,\n                                               cutoff=cutoff,\n                                               n_iterations=iters,\n                                               delta=delta,\n                                               silent=silent)\n        else:\n            crit, keep_vars = _reduce_vars_sklearn(new_x,\n                                                   y,\n                                                   clf=clf,\n                                                   this_round=i,\n                                                   cutoff=cutoff,\n                                                   n_iterations=iters,\n                                                   delta=delta,\n                                                   silent=silent)\n\n        if crit | (i >= max_rounds):\n            break  # exit and use keep_vars as final variables\n        else:\n            new_x = new_x[keep_vars].copy()\n    if not silent:\n        print(\"BoostARoota ran successfully! Algorithm went through \", i, \" rounds.\")\n    return keep_vars \n model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"total_cover\")\n\nbr = BoostARoota(clf=model)\n\n#Fit the model for the subset of variables\nbr.fit(X, y)\n\n#Can look at the important variables - will return a pandas series\nbr.keep_vars_ \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, br.keep_vars_], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"boostaroota_on_histg\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, br.keep_vars_], y=y, model_name=\"LogisticRegression\", experiment_name=\"boostaroota_on_histg\") \n <h1 style=\"background-color: #000080; color: #ffff00;\">Comparing the results</h1> \n def highlight_max(s):\n    is_max = s == s.max()\n    return ['background-color: yellow' if v else '' for v in is_max] \n results = tracker.retrive_results()\n\nresults = results.style.apply(highlight_max, subset=['losses_mean'])\nresults \n So recursive feature elimination made the race here with logistic regression on top. \n <h1 style=\"background-color: #000080; color: #ffff00;\">How to (not) interpret feature importance</h1>\n\nAs shown above feature importance has many implementations and variants: From statistical approaches to dedicated feature selection algorithms, from a focus on local importance to an explanation of global importance.\nThey all have one thing in common though: They cannot be used to explain any causal relationships in the data (with a theoretical exception maybe). These algorithms just try to explain how a model behaves, but they do not explain how the data behaves. \n <h1 style=\"background-color: #000080; color: #ffff00;\">Submission time</h1>\n\nFinally we will take the best feature space and make a submission before we finish. \n lin_est = LogisticRegression()\nlin_selector = RFECV(lin_est, step=1, cv=5)\nlin_selector = lin_selector.fit(X, y)\nlin_selector.support_\nkeep_cols = X.loc[:, lin_selector.support_].columns.to_list()\nlin_est = LogisticRegression().fit(X.loc[:, keep_cols], y) \n preds = lin_est.predict(test.loc[:, keep_cols]) \n sample_submission[target] = preds\nsample_submission[target] = sample_submission[target].astype(int)\nsample_submission.to_csv('submission.csv', index = False) \n sample_submission \n Feel free to also checkout the [cross validation mastery](https://www.kaggle.com/code/thomasmeiner/become-a-cross-validation-master) notebook. \n <div style=\"padding: 20px; background-color: #000080; border-radius: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\">\n    <div style=\"border: 2px solid #000080; padding: 20px; text-align: center; border-radius: 10px; background-color: #ffffff;\">\n        <h1 style=\"color: #00000; font-size: 32px; text-transform: uppercase; letter-spacing: 2px; margin-bottom: 20px;\">Consider an upvote</h1>\n        <div><em>\n       This notebook took a while to be created. Upvotes help keeping the motivation up :-)\n    </em></div>\n</div>",
    "code_source": "%%capture\n!pip install lime \n import numpy as np\nimport pandas as pd\nimport time\n\nimport lime\nfrom lime import lime_tabular\nfrom lime import submodular_pick\n\nimport optuna\nimport shap\n\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import mutual_info_classif, RFE, RFECV, SequentialFeatureSelector\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.metrics import make_scorer, accuracy_score\n\nimport xgboost as xgb \n train = pd.read_csv(r'/kaggle/input/titanic/train.csv')\ntest = pd.read_csv(r'/kaggle/input/titanic/test.csv')\nsample_submission = pd.read_csv(r'/kaggle/input/titanic/gender_submission.csv') \n target = \"Survived\" \n # borrowed from here: https://www.kaggle.com/code/tisa33/titanic-sk-87-2-rf-84-4-tf-87-1-rf-84-9/notebook\ndef normailize_data(df):\n    df['Cabin_Letter'] = df['Cabin'].apply(lambda x: str(x)[0])\n    df['Name_Title'] = df['Name'].apply(lambda x: x.split()[1]).apply(lambda x: x.split()[0])\n    df['Name_Len'] = df['Name'].apply(lambda x: len(x))\n    df['Age_Null'] = df['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n    #df['Age'] = df.groupby(['Name_Title', 'Pclass', 'Sex'])['Age'].transform(lambda x: x.fillna(x.mean()))\n    df['Age'] = df['Age'].fillna(0)\n    df['Ticket_Type'] = df['Ticket'].apply(lambda x: x[0])\n    df['Age'] = (df['Age'] - df['Age'].min()) / (df['Age'].max() - df['Age'].min())\n    df['Fare'] = (df['Fare'] - df['Fare'].min()) / (df['Fare'].max() - df['Fare'].min())\n    df['Name_Len'] = (df['Name_Len'] - df['Name_Len'].min()) / (df['Name_Len'].max() - df['Name_Len'].min())\n    df['SibSp'] = (df['SibSp'] - df['SibSp'].min()) / (df['SibSp'].max() - df['SibSp'].min())\n    df['Parch'] = (df['Parch'] - df['Parch'].min()) / (df['Parch'].max() - df['Parch'].min())\n    df = pd.get_dummies(df, columns=['Sex', 'Embarked', 'Name_Title', 'Cabin_Letter', 'Ticket_Type', 'Pclass'], drop_first=True, dtype=int)\n    df = df.drop(['Name', 'Cabin', 'PassengerId', 'Ticket'], axis=1)\n    return df\n\nfull_data = pd.concat([train, test])\nfull_data = normailize_data(full_data)\ntrain = full_data.loc[full_data[target].isna() == False].copy().fillna(0)\ntest = full_data.loc[full_data[target].isna() == True].copy().fillna(0) \n X = train.copy()\ny = X.pop(target) \n class ResultTracker:\n    def __init__(self):\n        self.losses_mean = []\n        self.losses_std = []\n        self.runtime_secs = []\n        self.model_name = []\n        self.experiment_name  = []\n        \n    def eval_model(self, model, X, y):\n        mae_scorer = make_scorer(accuracy_score, greater_is_better=True)\n        start = time.time()\n        losses = cross_val_score(model, X, y, cv=5, n_jobs=-1, scoring=mae_scorer)\n        end = time.time()\n        runtime_secs = end - start\n        return np.mean(losses), np.std(losses),  runtime_secs\n    \n    def add_experiment(self, *, model, X, y, model_name, experiment_name):\n        exp_mean, exp_std, runtime_secs = self.eval_model(model, X, y)\n        print(f\"Model {model_name} achieved a score of {exp_mean} with an std of {exp_std} in {runtime_secs} secs\")\n        \n        self.losses_mean.append(exp_mean)\n        self.losses_std.append(exp_std)\n        self.runtime_secs.append(runtime_secs)\n        self.model_name.append(model_name)\n        self.experiment_name.append(experiment_name)\n        \n    def retrive_results(self):\n        results_df = pd.DataFrame(\n            {\n                \"losses_mean\": self.losses_mean,\n                \"losses_std\": self.losses_std,\n                \"runtime_secs\": self.runtime_secs,\n                \"model_name\": self.model_name,\n                \"experiment_name\": self.experiment_name\n            }\n        )\n        return results_df \n tracker = ResultTracker() \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X, y=y, model_name=\"HistGradientBoosting\", experiment_name=\"using_all_features\")\ntracker.add_experiment(model=lin_est, X=X, y=y, model_name=\"LogisticRegression\", experiment_name=\"using_all_features\") \n def calculate_correlations(df: pd.DataFrame, target: pd.Series) -> pd.DataFrame:\n    \"\"\"\n    Calculates the correlations of all columns with regards to the target and returns a DataFrame with all column names\n    and their correlation coefficient with regards to the target.\n    \n    :param df: Pandas DataFrame\n    :param target: Pandas Series with target values\n    :return: Pandas DataFrame with column names and their correlation coefficient with regards to the target\n    \"\"\"\n    correlations = df.corrwith(target)\n    return pd.DataFrame(correlations, columns=['correlation_coefficient']) \n correlations = calculate_correlations(X, y)\ncorrelations \n keep_columns = correlations.loc[\n    (\n        (correlations[\"correlation_coefficient\"] >= 0.1) |\n        (correlations[\"correlation_coefficient\"] <= -0.1)\n    )\n].index.to_list()\n\nkeep_columns \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_columns], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"removed_no_corr_to_target\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_columns], y=y, model_name=\"LogisticRegression\", experiment_name=\"removed_no_corr_to_target\") \n def calculate_mi_scores(df, target):\n    \"\"\"\n    Calculates the mutual information score of all columns with regards to the (regression) target.\n    \n    Parameters:\n    df (Pandas DataFrame): The DataFrame containing the features.\n    target (Pandas Series): The target variable.\n    \n    Returns:\n    Pandas DataFrame: A DataFrame with all column names and their MI scores with regards to the target.\n    \"\"\"\n    mi_scores = mutual_info_classif(df, target)\n    mi_scores = pd.Series(mi_scores, name='MI Scores', index=df.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores.to_frame() \n mi_scores = calculate_mi_scores(X, y)\nmi_scores \n keep_columns = mi_scores.loc[(mi_scores[\"MI Scores\"] >= 0.0)].index.to_list()\n\nkeep_columns \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_columns], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"removed_low_mi_score_to_target\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_columns], y=y, model_name=\"LogisticRegression\", experiment_name=\"removed_low_mi_score_to_target\") \n def remove_collinearity(dataset, threshold=0.9):\n    \"\"\"\n    Loops through all columns and checks, if features are highly positively correlated.\n    If correlation is above given threshold, then only one column is kept.\n    :param threshold: Maximum allowed correlation. Expects a float from -1 to +1.\n    :return: Returns modified dataframe.\n    \"\"\"\n    col_corr = set()  # Set of all the names of deleted columns\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if (corr_matrix.iloc[i, j] >= threshold) and (\n                corr_matrix.columns[j] not in col_corr\n            ):\n                colname = corr_matrix.columns[i]  # getting the name of column\n                col_corr.add(colname)\n                if colname in dataset.columns:\n                    del dataset[colname]  # deleting the column from the dataset\n    return dataset \n X_thres_09 = remove_collinearity(X.copy(), 0.9)\nX_thres_09.columns.to_list()\nprint(f\"Removed columns {set(X.columns.to_list()) - set(X_thres_09.columns.to_list())}\") \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X_thres_09, y=y, model_name=\"HistGradientBoosting\", experiment_name=\"removed_collinearity_with_090plus\")\ntracker.add_experiment(model=lin_est, X=X_thres_09, y=y, model_name=\"LogisticRegression\", experiment_name=\"removed_collinearity_with_090plus\") \n X_thres_08 = remove_collinearity(X.copy(), 0.8)\nX_thres_08.columns.to_list()\nprint(f\"Removed columns {set(X.columns.to_list()) - set(X_thres_08.columns.to_list())}\") \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X_thres_08, y=y, model_name=\"HistGradientBoosting\", experiment_name=\"removed_collinearity_with_080plus\")\ntracker.add_experiment(model=lin_est, X=X_thres_08, y=y, model_name=\"LogisticRegression\", experiment_name=\"removed_collinearity_with_080plus\") \n lin_est = LogisticRegression()\nlin_est.fit(X, y) \n print(lin_est.coef_.shape, len(X.columns))\nlin_est.coef_ \n ((lin_est.coef_ < -0.05) | (lin_est.coef_ > 0.05))[0] \n keep_cols = X.loc[:, ((lin_est.coef_ < -0.05) | (lin_est.coef_ > 0.05))[0]].columns.to_list()\nkeep_cols \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"removed_lower_half_of_lr_coefficients\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"removed_lower_half_of_lr_coefficients\") \n model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"gain\")\nmodel.fit(X, y) \n xgb_gain = model.feature_importances_\nxgb_gain \n keep_cols = X.loc[:, xgb_gain > 0.05].columns.to_list()\nkeep_cols \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"xgboost_importance_gain\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"xgboost_importance_gain\") \n model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"weight\")\nmodel.fit(X, y) \n xgb_weight = model.feature_importances_\nxgb_weight \n keep_cols = X.loc[:, xgb_weight > 0.05].columns.to_list()\nkeep_cols \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"xgboost_importance_weight\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"xgboost_importance_weight\") \n model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"cover\")\nmodel.fit(X, y) \n xgb_cover = model.feature_importances_\nxgb_cover \n keep_cols = X.loc[:, xgb_cover > 0.05].columns.to_list()\nkeep_cols \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"xgboost_importance_cover\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"xgboost_importance_cover\") \n model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"total_gain\")\nmodel.fit(X, y) \n xgb_total_gain = model.feature_importances_\nxgb_total_gain \n keep_cols = X.loc[:, xgb_total_gain > 0.05].columns.to_list()\nkeep_cols \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"xgboost_importance_total_gain\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"xgboost_importance_total_gain\") \n model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"total_cover\")\nmodel.fit(X, y) \n xgb_total_cover = model.feature_importances_\nxgb_total_cover \n keep_cols = X.loc[:, xgb_total_cover > 0.05].columns.to_list()\nkeep_cols \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"xgboost_importance_total_cover\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"xgboost_importance_total_cover\") \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\nhist_selector, lin_selector = RFE(hist_est, n_features_to_select=10, step=1), RFE(lin_est, n_features_to_select=10, step=1) \n #hist_selector = hist_selector.fit(X, y)\n#hist_selector.support_ \n lin_selector = lin_selector.fit(X, y)\nlin_selector.support_ \n keep_cols = X.loc[:, lin_selector.support_].columns.to_list()\nkeep_cols \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"rfe_based_on_logistic_regression\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"rfe_based_on_logistic_regression\") \n lin_est = LogisticRegression()\nlin_selector = RFECV(lin_est, step=1, cv=5) \n lin_selector = lin_selector.fit(X, y)\nlin_selector.support_ \n keep_cols = X.loc[:, lin_selector.support_].columns.to_list()\nkeep_cols \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"rfecv_based_on_logistic_regression\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"rfecv_based_on_logistic_regression\") \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\nhist_sfs, lin_sfs = SequentialFeatureSelector(hist_est, n_features_to_select=10), SequentialFeatureSelector(lin_est, n_features_to_select=10) \n #hist_sfs.fit(X, y)\n#hist_sfs.get_support() \n #keep_cols = X.loc[:, hist_sfs.get_support()].columns.to_list()\n#keep_cols \n #hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\n#tracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"seq_feat_sel_on_histgb\")\n#tracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"seq_feat_sel_on_histgb\") \n lin_sfs.fit(X, y)\nlin_sfs.get_support() \n keep_cols = X.loc[:, lin_sfs.get_support()].columns.to_list()\nkeep_cols \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"seq_feat_sel_on_logistic_regression\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"seq_feat_sel_on_logistic_regression\") \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression() \n x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=100) \n hist_est.fit(x_train, y_train) \n explainer = lime_tabular.LimeTabularExplainer(\n    training_data=x_train.values,\n    feature_names=x_train.columns,\n    mode='regression'\n) \n exp = explainer.explain_instance(\n    data_row=x_test.iloc[1], \n    predict_fn=hist_est.predict\n) \n exp.show_in_notebook(show_table=True) \n %%capture\nsp_exp = submodular_pick.SubmodularPick(explainer, \n                                        x_test.values,\n                                        predict_fn=hist_est.predict,\n                                        num_features=10,\n                                        num_exps_desired=5)\n \n [exp.show_in_notebook() for exp in sp_exp.sp_explanations]\nprint('SP-LIME Explanations.') \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(\n    model=hist_est, \n    X=X.loc[:, [\"Sex_male\", \"Name_Title_Master.\"]], \n    y=y, \n    model_name=\"HistGradientBoosting\", \n    experiment_name=\"lime_visual_inspection_based_on_hist\"\n)\n\ntracker.add_experiment(\n    model=lin_est, \n    X=X.loc[:, [\"Sex_male\", \"Name_Title_Master.\"]],\n    y=y, \n    model_name=\"LogisticRegression\", \n    experiment_name=\"lime_visual_inspection_based_on_hist\"\n) \n lin_est.fit(x_train, y_train)\nexplainer = lime_tabular.LimeTabularExplainer(\n    training_data=x_train.values,\n    feature_names=x_train.columns,\n    mode='regression'\n) \n %%capture\nsp_exp = submodular_pick.SubmodularPick(explainer, \n                                        x_test.values,\n                                        predict_fn=lin_est.predict,\n                                        num_features=10,\n                                        num_exps_desired=5) \n [exp.show_in_notebook() for exp in sp_exp.sp_explanations]\nprint('SP-LIME Explanations.') \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(\n    model=hist_est, \n    X=X.loc[:, [\"Sex_male\", \"Ticket_Type_3\"]],\n    y=y, \n    model_name=\"HistGradientBoosting\", \n    experiment_name=\"lime_visual_inspection_based_on_logistic_regression\"\n)\n\ntracker.add_experiment(\n    model=lin_est, \n    X=X.loc[:, [\"Sex_male\", \"Ticket_Type_3\"]], \n    y=y, \n    model_name=\"LogisticRegression\", \n    experiment_name=\"lime_visual_inspection_based_on_logistic_regression\"\n) \n hist_est.fit(x_train, y_train) \n explainer = shap.Explainer(hist_est.predict, x_test)\nshap_values = explainer(x_test) \n shap.summary_plot(shap_values, max_display=25, show=True) \n shap.summary_plot(shap_values, max_display=35, show=False, plot_type='bar') \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression() \n drop_cols = [\n    \"Name_Title_Gordon,\", \n    \"Name_Title_Impe,\", \n    \"Name_Title_Jonkheer.\", \n    \"Name_Title_Mlle.\", \n    \"Ticket_Type_W\", \n    \"Name_Title_Melkebeke,\",\n    \"Name_Title_Messemaeker,\",\n    \"Name_Title_Col.\",\n    \"Age_Null\"\n] \n tracker.add_experiment(\n    model=hist_est, \n    X=X.drop(drop_cols, axis=1),\n    y=y, \n    model_name=\"HistGradientBoosting\", \n    experiment_name=\"shap_visual_inspection_based_on_hist\"\n)\n\ntracker.add_experiment(\n    model=lin_est, \n    X=X.drop(drop_cols, axis=1), \n    y=y, \n    model_name=\"LogisticRegression\", \n    experiment_name=\"shap_visual_inspection_based_on_hist\"\n) \n lin_est.fit(x_train, y_train) \n explainer = shap.Explainer(lin_est.predict, x_test)\nshap_values = explainer(x_test) \n shap.summary_plot(shap_values, max_display=35, show=True) \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression() \n tracker.add_experiment(\n    model=hist_est, \n    X=X.drop([\"Name_Title_Dr.\", \"Ticket_Type_F\", \"Ticket_Type_S\", \"Name_Title_Rev.\"], axis=1),\n    y=y, \n    model_name=\"HistGradientBoosting\", \n    experiment_name=\"shap_visual_inspection_based_on_logistic_regression\"\n)\n\ntracker.add_experiment(\n    model=lin_est, \n    X=X.drop([\"Name_Title_Dr.\", \"Ticket_Type_F\", \"Ticket_Type_S\", \"Name_Title_Rev.\"], axis=1), \n    y=y, \n    model_name=\"LogisticRegression\", \n    experiment_name=\"shap_visual_inspection_based_on_logistic_regression\"\n) \n import numpy as np\nimport pandas as pd\nimport xgboost as xgb\nimport operator\nimport warnings\n\n\n########################################################################################\n#\n# Main Class and Methods\n#\n########################################################################################\n\n\nclass BoostARoota(object):\n\n    def __init__(self, metric=None, clf=None, cutoff=4, iters=10, max_rounds=100, delta=0.1, silent=False):\n        self.metric = metric\n        self.clf = clf\n        self.cutoff = cutoff\n        self.iters = iters\n        self.max_rounds = max_rounds\n        self.delta = delta\n        self.silent = silent\n        self.keep_vars_ = None\n\n        #Throw errors if the inputted parameters don't meet the necessary criteria\n        if (metric is None) and (clf is None):\n            raise ValueError('you must enter one of metric or clf as arguments')\n        if cutoff <= 0:\n            raise ValueError('cutoff should be greater than 0. You entered' + str(cutoff))\n        if iters <= 0:\n            raise ValueError('iters should be greater than 0. You entered' + str(iters))\n        if (delta <= 0) | (delta > 1):\n            raise ValueError('delta should be between 0 and 1, was ' + str(delta))\n\n        #Issue warnings for parameters to still let it run\n        if (metric is not None) and (clf is not None):\n            warnings.warn('You entered values for metric and clf, defaulting to clf and ignoring metric')\n        if delta < 0.02:\n            warnings.warn(\"WARNING: Setting a delta below 0.02 may not converge on a solution.\")\n        if max_rounds < 1:\n            warnings.warn(\"WARNING: Setting max_rounds below 1 will automatically be set to 1.\")\n\n    def fit(self, x, y):\n        self.keep_vars_ = _BoostARoota(x, y,\n                                       metric=self.metric,\n                                       clf = self.clf,\n                                       cutoff=self.cutoff,\n                                       iters=self.iters,\n                                       max_rounds=self.max_rounds,\n                                       delta=self.delta,\n                                       silent=self.silent)\n        return self\n\n    def transform(self, x):\n        if self.keep_vars_ is None:\n            raise ValueError(\"You need to fit the model first\")\n        return x[self.keep_vars_]\n\n    def fit_transform(self, x, y):\n        self.fit(x, y)\n        return self.transform(x)\n\n########################################################################################\n#\n# Helper Functions to do the Heavy Lifting\n#\n########################################################################################\n\n\ndef _create_shadow(x_train):\n    \"\"\"\n    Take all X variables, creating copies and randomly shuffling them\n    :param x_train: the dataframe to create shadow features on\n    :return: dataframe 2x width and the names of the shadows for removing later\n    \"\"\"\n    x_shadow = x_train.copy()\n    for c in x_shadow.columns:\n        np.random.shuffle(x_shadow[c].values)\n    # rename the shadow\n    shadow_names = [\"ShadowVar\" + str(i + 1) for i in range(x_train.shape[1])]\n    x_shadow.columns = shadow_names\n    # Combine to make one new dataframe\n    new_x = pd.concat([x_train, x_shadow], axis=1)\n    return new_x, shadow_names\n\n########################################################################################\n#\n# BoostARoota\n#\n########################################################################################\n\n\ndef _reduce_vars_xgb(x, y, metric, this_round, cutoff, n_iterations, delta, silent):\n    \"\"\"\n    Function to run through each\n    :param x: Input dataframe - X\n    :param y: Target variable\n    :param metric: Metric to optimize in XGBoost\n    :param this_round: Round so it can be printed to screen\n    :return: tuple - stopping criteria and the variables to keep\n    \"\"\"\n    #Set up the parameters for running the model in XGBoost - split is on multi log loss\n    if metric == 'mlogloss':\n        param = {'objective': 'multi:softmax',\n                 'eval_metric': 'mlogloss',\n                 'num_class': len(np.unique(y)),\n                 'silent': 1}\n    else:\n        param = {'eval_metric': metric,\n                 'silent': 1}\n    for i in range(1, n_iterations+1):\n        # Create the shadow variables and run the model to obtain importances\n        new_x, shadow_names = _create_shadow(x)\n        dtrain = xgb.DMatrix(new_x, label=y)\n        bst = xgb.train(param, dtrain, verbose_eval=False)\n        if i == 1:\n            df = pd.DataFrame({'feature': new_x.columns})\n            pass\n\n        importance = bst.get_fscore()\n        importance = sorted(importance.items(), key=operator.itemgetter(1))\n        df2 = pd.DataFrame(importance, columns=['feature', 'fscore'+str(i)])\n        df2['fscore'+str(i)] = df2['fscore'+str(i)] / df2['fscore'+str(i)].sum()\n        df = pd.merge(df, df2, on='feature', how='outer')\n        if not silent:\n            print(\"Round: \", this_round, \" iteration: \", i)\n\n    df['Mean'] = df.mean(axis=1)\n    #Split them back out\n    real_vars = df[~df['feature'].isin(shadow_names)]\n    shadow_vars = df[df['feature'].isin(shadow_names)]\n\n    # Get mean value from the shadows\n    mean_shadow = shadow_vars['Mean'].mean() / cutoff\n    real_vars = real_vars[(real_vars.Mean > mean_shadow)]\n\n    #Check for the stopping criteria\n    #Basically looking to make sure we are removing at least 10% of the variables, or we should stop\n    if (len(real_vars['feature']) / len(x.columns)) > (1-delta):\n        criteria = True\n    else:\n        criteria = False\n\n    return criteria, real_vars['feature']\n\n\ndef _reduce_vars_sklearn(x, y, clf, this_round, cutoff, n_iterations, delta, silent):\n    \"\"\"\n    Function to run through each\n    :param x: Input dataframe - X\n    :param y: Target variable\n    :param clf: the fully specified classifier passed in by user\n    :param this_round: Round so it can be printed to screen\n    :return: tuple - stopping criteria and the variables to keep\n    \"\"\"\n    #Set up the parameters for running the model in XGBoost - split is on multi log loss\n\n    for i in range(1, n_iterations+1):\n        # Create the shadow variables and run the model to obtain importances\n        new_x, shadow_names = _create_shadow(x)\n        clf = clf.fit(new_x, np.ravel(y))\n\n        if i == 1:\n            df = pd.DataFrame({'feature': new_x.columns})\n            df2 = df.copy()\n            pass\n\n        try:\n            importance = clf.feature_importances_\n            df2['fscore' + str(i)] = importance\n        except ValueError:\n            print(\"this clf doesn't have the feature_importances_ method.  Only Sklearn tree based methods allowed\")\n\n        # importance = sorted(importance.items(), key=operator.itemgetter(1))\n\n        # df2 = pd.DataFrame(importance, columns=['feature', 'fscore'+str(i)])\n        df2['fscore'+str(i)] = df2['fscore'+str(i)] / df2['fscore'+str(i)].sum()\n        df = pd.merge(df, df2, on='feature', how='outer', suffixes=('', '_y'))\n        df.drop(df.filter(regex='_y$').columns, axis=1, inplace=True)\n        if not silent:\n            print(\"Round: \", this_round, \" iteration: \", i)\n\n    df['Mean'] = df.drop(\"feature\", axis=1).mean(axis=1)\n    #Split them back out\n    real_vars = df[~df['feature'].isin(shadow_names)]\n    shadow_vars = df[df['feature'].isin(shadow_names)]\n\n    # Get mean value from the shadows\n    mean_shadow = shadow_vars['Mean'].mean() / cutoff\n    real_vars = real_vars[(real_vars.Mean > mean_shadow)]\n\n    #Check for the stopping criteria\n    #Basically looking to make sure we are removing at least 10% of the variables, or we should stop\n    if (len(real_vars['feature']) / len(x.columns)) > (1-delta):\n        criteria = True\n    else:\n        criteria = False\n\n    return criteria, real_vars['feature']\n\n#Main function exposed to run the algorithm\ndef _BoostARoota(x, y, metric, clf, cutoff, iters, max_rounds, delta, silent):\n    \"\"\"\n    Function loops through, waiting for the stopping criteria to change\n    :param x: X dataframe One Hot Encoded\n    :param y: Labels for the target variable\n    :param metric: The metric to optimize in XGBoost\n    :return: names of the variables to keep\n    \"\"\"\n\n    new_x = x.copy()\n    #Run through loop until \"crit\" changes\n    i = 0\n    while True:\n        #Inside this loop we reduce the dataset on each iteration exiting with keep_vars\n        i += 1\n        if clf is None:\n            crit, keep_vars = _reduce_vars_xgb(new_x,\n                                               y,\n                                               metric=metric,\n                                               this_round=i,\n                                               cutoff=cutoff,\n                                               n_iterations=iters,\n                                               delta=delta,\n                                               silent=silent)\n        else:\n            crit, keep_vars = _reduce_vars_sklearn(new_x,\n                                                   y,\n                                                   clf=clf,\n                                                   this_round=i,\n                                                   cutoff=cutoff,\n                                                   n_iterations=iters,\n                                                   delta=delta,\n                                                   silent=silent)\n\n        if crit | (i >= max_rounds):\n            break  # exit and use keep_vars as final variables\n        else:\n            new_x = new_x[keep_vars].copy()\n    if not silent:\n        print(\"BoostARoota ran successfully! Algorithm went through \", i, \" rounds.\")\n    return keep_vars \n model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"total_cover\")\n\nbr = BoostARoota(clf=model)\n\n#Fit the model for the subset of variables\nbr.fit(X, y)\n\n#Can look at the important variables - will return a pandas series\nbr.keep_vars_ \n hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, br.keep_vars_], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"boostaroota_on_histg\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, br.keep_vars_], y=y, model_name=\"LogisticRegression\", experiment_name=\"boostaroota_on_histg\") \n def highlight_max(s):\n    is_max = s == s.max()\n    return ['background-color: yellow' if v else '' for v in is_max] \n results = tracker.retrive_results()\n\nresults = results.style.apply(highlight_max, subset=['losses_mean'])\nresults \n lin_est = LogisticRegression()\nlin_selector = RFECV(lin_est, step=1, cv=5)\nlin_selector = lin_selector.fit(X, y)\nlin_selector.support_\nkeep_cols = X.loc[:, lin_selector.support_].columns.to_list()\nlin_est = LogisticRegression().fit(X.loc[:, keep_cols], y) \n preds = lin_est.predict(test.loc[:, keep_cols]) \n sample_submission[target] = preds\nsample_submission[target] = sample_submission[target].astype(int)\nsample_submission.to_csv('submission.csv', index = False) \n sample_submission",
    "markdown_source": "<div style=\"padding: 20px; background-color: #000080; border-radius: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\">\n    <div style=\"border: 2px solid #000080; padding: 20px; text-align: center; border-radius: 10px; background-color: #ffffff;\">\n        <h1 style=\"color: #00000; font-size: 32px; text-transform: uppercase; letter-spacing: 2px; margin-bottom: 20px;\">Become a feature selection master</h1>\n        <div><em>\n       If you like the content please consider an upvote. It is a great motivator to keep sharing code and ideas.\n        Thank you!!!\n    </em></div>\n</div> \n In this notebook we will dive through various feature selection options. We will illustrate this on two model architectures to show the differences there as well. \n <h1 style=\"background-color: #000080; color: #ffff00;\">Table of contents</h1>\n\n* [Load tand install libraries](#1)\n* [Load the data](#2)\n* [Create helper functions and classes](#3)\n* [Mastering feature selection](#4)\n    * [Creating a baseline](#4.1)\n    * [Using statistical methods](#4.2)\n        * [No correlation to target](#4.2.1)\n        * [Mutual information score](#4.2.2)\n        * [Collinearity in the dataset](4.2.3)\n    * [Using model inbuilt feature importance](#4.3)\n        * [Linear Regression](#4.3.1)\n        * [HistGradientBoosting](#4.3.2)\n            * [Gain](#4.3.2.1)\n            * [Weight](#4.3.2.2)\n            * [Cover](#4.3.2.3)\n            * [Total gain](#4.3.2.4)\n            * [Total cover](#4.3.2.5)\n    * [Using feature selection algorithms](#4.4)\n        * [Using recursive feature elimination](#4.4.1)\n        * [Using recursive feature elimination with inbuilt cross validation](#4.4.2)\n        * [Sequential feature selection](#4.4.3)\n        * [Lime](#4.4.4)\n        * [Shap](#4.4.5)\n        * [Boruta](#4.4.5)\n* [Comparing the results](#5.0)\n* [How to (not) interpret feature importance](#6.0)\n* [Submission time](#7.0) \n <h1 style=\"background-color: #000080; color: #ffff00;\">Load and install libraries</h1> \n <h1 style=\"background-color: #000080; color: #ffff00;\">Load the data</h1> \n <h1 style=\"background-color: #000080; color: #ffff00;\">Create helper functions and classes</h1> \n <h1 style=\"background-color: #000080; color: #ffff00;\">Mastering feature selection</h1>\n\nNow that we installed everything we need and loaded our data it is time to deep dive into the actual topic. On purpose I do not preprocess the data, oping that we can see a bit more variation between both models.\n\nFeel free to copy the notebook and play with some preprocessing. \n <h2 style=\"background-color: #000080; color: #ffff00;\">Creating a baseline</h2>\n\nBefore we start we create a bseline for our models were we just run them using all features. \n <h2 style=\"background-color: #000080; color: #ffff00;\">Using statistical methods</h2>\n\nIn this section we will remove features based on statistical methods and properties. \n <h3 style=\"background-color: #000080; color: #ffff00;\">No correlation to target</h3>\n\nWe measure the correlation of all columns to the target and eliminate the ones that have almost no correlation. This captures linear relationships only, which is a hard limitation and might underestimate the value of a feature. \n Here we remove the columns with a correlation coefficient close to zero. \n <h3 style=\"background-color: #000080; color: #ffff00;\">Mutual information score</h3>\n\nWe measure the mutual information score of all columns to with regards to the target and remove the ones with almost zero scoring. MI scores also consider non-linear information. \n Interesting! Only the id column has very little value. So we only remove that one. \n <h3 style=\"background-color: #000080; color: #ffff00;\">Collinearity in the dataset</h3>\n\nWe measure the correlation of all columns to each other and remove the ones with high correlation (one of them). \n <h2 style=\"background-color: #000080; color: #ffff00;\">Using model inbuilt feature importance</h2>\n\nIn this section we will invvestigate if the models itself provide us valueable information for feature selection. \n <h3 style=\"background-color: #000080; color: #ffff00;\">Linear Regression</h3>\n\nFor linear regression we need to train an instance first. Then we can make use of it's own coefficients to select features. \n We remove columns with coefficients close to zero.. \n <h3 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoosting</h3> \n It seems like the HistGradientBoostingClassifier from sklearn does not offer any feature importance functionality. However we can make use of HistGradientBoosting also via the Xgboost library and get our importances from there.\n\nHere we can pass one of multiple importance types via the importance_type parameter (see the [docs](https://xgboost.readthedocs.io/en/stable/python/python_api.html):\nThe feature importance type for the feature_importances_ property:\n* For tree model, it\u2019s either \u201cgain\u201d, \u201cweight\u201d, \u201ccover\u201d, \u201ctotal_gain\u201d or \u201ctotal_cover\u201d.\n* For linear model, only \u201cweight\u201d is defined and it\u2019s the normalized coefficients without bias.\n\nAs you can see there is a total of 5 feature importance metrics within gradient boosting. What is behind each of them I will quote from [this](https://towardsdatascience.com/be-careful-when-interpreting-your-features-importance-in-xgboost-6e16132588e7) Medium article. Please consider some claps there.\n \n <h4 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoosting gain</h4>\n\n\"The Gain implies the relative contribution of the corresponding feature to the model calculated by taking each feature\u2019s contribution for each tree in the model. A higher value of this metric when compared to another feature implies it is more important for generating a prediction.\n\nThe Gain is the most relevant attribute to interpret the relative importance of each feature.\n\n\u2018Gain\u2019 is the improvement in accuracy brought by a feature to the branches it is on. The idea is that before adding a new split on a feature X to the branch there was some wrongly classified elements, after adding the split on this feature, there are two new branches, and each of these branch is more accurate (one branch saying if your observation is on this branch then it should be classified as 1, and the other branch saying the exact opposite).\" \n <h4 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoosting weight</h4>\n\n\"The Frequency (R)/Weight (python) is the percentage representing the relative number of times a particular feature occurs in the trees of the model. In the above example, if feature1 occurred in 2 splits, 1 split and 3 splits in each of tree1, tree2 and tree3; then the weight for feature1 will be 2+1+3 = 6. The frequency for feature1 is calculated as its percentage weight over weights of all features.\" \n <h4 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoosting cover</h4>\n\n\"The Coverage metric means the relative number of observations related to this feature. For example, if you have 100 observations, 4 features and 3 trees, and suppose feature1 is used to decide the leaf node for 10, 5, and 2 observations in tree1, tree2 and tree3 respectively; then the metric will count cover for this feature as 10+5+2 = 17 observations. This will be calculated for all the 4 features and the cover will be 17 expressed as a percentage for all features\u2019 cover metrics.\" \n <h4 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoosting total_gain</h4> \n <h4 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoostingRegressor total_cover</h4> \n <h2 style=\"background-color: #000080; color: #ffff00;\">Using feature selection algorithms</h2>\n\nIn this section we will investigate algorithms designed for feature selection. \n <h3 style=\"background-color: #000080; color: #ffff00;\">Using recursive feature elimination</h3>\n\n\"Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through any specific attribute or callable. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.\" (see [sklearn docs](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html))\n\nOne disadvantage here is that we need to tell in advance how many features shall be selected. One re-occuring pattern in this section is that these algorithms are not model agnostic. Therefore we will test each of them for both of our models if possible. \n This is not compatible with HistGradienBoosting as it misses `coef_` and `feature_importances_` attributes. \n <h3 style=\"background-color: #000080; color: #ffff00;\">Using recursive feature elimination with inbuilt cross validation</h3> \n <h3 style=\"background-color: #000080; color: #ffff00;\">Sequential feature selection</h3>\n\n\"This Sequential Feature Selector adds (forward selection) or removes (backward selection) features to form a feature subset in a greedy fashion. At each stage, this estimator chooses the best feature to add or remove based on the cross-validation score of an estimator. In the case of unsupervised learning, this Sequential Feature Selector looks only at the features (X), not the desired outputs (y).\" (see [sklearn docs](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html)) \n Skipping hist as this is really slow here \n <h3 style=\"background-color: #000080; color: #ffff00;\">Lime</h3>\n\nLime is a model explanantion framework that tries to \"solve for model interpretability by producing locally faithful explanations\". (see the source of the quote and deeper explanations in [this](https://towardsdatascience.com/decrypting-your-machine-learning-model-using-lime-5adc035109b5) Medium article). \n Lime offers us the ability to explain feature importance on row level. Let's show this for the second row in the DataFrame: \n We use the sub-modular attributes available on SP-LIME to obtain a global perspective of the data instances. Then, we visualize the data to visual global representative samples extracted by the SP-LIME algorithm. This takes much longer than the local explanations. \n It this not so easy to keep an overview here. Let's keep Sex_male and Name_Title_Master only. \n We do one for linear regression as well. \n For this example we keep Sex_male and Ticket_Type_3 \n <h3 style=\"background-color: #000080; color: #ffff00;\">Shap</h3>\n\n\"SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions[...]\" ([source](https://shap.readthedocs.io/en/latest/))\n\nThe original paper can be found [here](https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf). \n HistGradientBoosting is not yet supported by Shaps TreeExplainer (which is much faster for tree-based models). Alos be aware, that a model trained on GPU will utilize GPU acceleration also within Shap! \n Let's show the feature importances... \n We can also show this as a barplot. \n In both plots the values are sorted top down by importance.\nThe shap library has also beautiful visuals to explore feature importance for individual rows and also dependency plots to better undersatnd feature interactions. I will skip this here as the Kernel is pretty long already.\n\nLet's drop [\"Name_Title_Gordon,\", \"Name_Title_Impe,\", \"Name_Itle_Jonkheer.\", \"Name_Title_Mlle.\", \"Ticket_Type_W\", \"Name_Title_Melkebelke\"] etc here. \n We do the same for linear regression as Shap (like Lime) is not model-agnostic. \n Here we drop just Name_Title_Dr. and Ticket_Type_F and S. \n <h3 style=\"background-color: #000080; color: #ffff00;\">Boruta</h3>\n\nIn Boruta, features do not compete among themselves. They are compared with a randomized version of them instead.\n\"In practice, starting from X, another dataframe is created by randomly shuffling each feature. These permuted features are called shadow features. At this point, the shadow dataframe is attached to the original dataframe to obtain a new dataframe (we will call it X_boruta), which has twice the number of columns of X.\"\n\nFor more details check out [this](https://towardsdatascience.com/boruta-explained-the-way-i-wish-someone-explained-it-to-me-4489d70e154a) Medium article.\n\nOver the past decade the boruta algorithm has seen multiple implementations and variants. The original algorithm is quite slow. Instead we use a less-known, but powerful variant: boostaroota\n\nPlease be aware, that boostaroota was a research project and is not maintained. It seems like compatibility breaks with Panndas 2.0 or higher. However the code is open source and could be adapted.\n\nIn general I struggled to find any Boruta implementation that can be installed in this Kernel and just runs without an error. Therefore I decided to tak the boostaroota source code and add it below, but debug the breaking parts.\n\nBoostaroota runs now and expects an estimator with a feature_imprtance_ attribute. This does not apply to HistGradientBoosting and linear regression, so we fallback to Xgboost once again. \n <h1 style=\"background-color: #000080; color: #ffff00;\">Comparing the results</h1> \n So recursive feature elimination made the race here with logistic regression on top. \n <h1 style=\"background-color: #000080; color: #ffff00;\">How to (not) interpret feature importance</h1>\n\nAs shown above feature importance has many implementations and variants: From statistical approaches to dedicated feature selection algorithms, from a focus on local importance to an explanation of global importance.\nThey all have one thing in common though: They cannot be used to explain any causal relationships in the data (with a theoretical exception maybe). These algorithms just try to explain how a model behaves, but they do not explain how the data behaves. \n <h1 style=\"background-color: #000080; color: #ffff00;\">Submission time</h1>\n\nFinally we will take the best feature space and make a submission before we finish. \n Feel free to also checkout the [cross validation mastery](https://www.kaggle.com/code/thomasmeiner/become-a-cross-validation-master) notebook. \n <div style=\"padding: 20px; background-color: #000080; border-radius: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\">\n    <div style=\"border: 2px solid #000080; padding: 20px; text-align: center; border-radius: 10px; background-color: #ffffff;\">\n        <h1 style=\"color: #00000; font-size: 32px; text-transform: uppercase; letter-spacing: 2px; margin-bottom: 20px;\">Consider an upvote</h1>\n        <div><em>\n       This notebook took a while to be created. Upvotes help keeping the motivation up :-)\n    </em></div>\n</div>",
    "n_cells": 147,
    "n_code_cells": 97,
    "n_markdown_cells": 50,
    "n_raw_cells": 0,
    "n_outputs": 97,
    "r_code_cells": 0.6598639455782312,
    "r_markdown_cells": 0.3401360544217687,
    "r_raw_cells": 0.0,
    "r_outputs": 1.0,
    "n_exceptions": 0,
    "r_exceptions": 0.0,
    "n_lines": 814,
    "n_lines_code": 652,
    "n_lines_markdown": 162,
    "lines_per_cell": [
        8,
        1,
        29,
        1,
        2,
        18,
        1,
        3,
        1,
        22,
        2,
        1,
        37,
        1,
        5,
        3,
        3,
        3,
        3,
        11,
        2,
        1,
        8,
        3,
        3,
        15,
        2,
        1,
        3,
        3,
        3,
        19,
        3,
        3,
        3,
        3,
        3,
        3,
        2,
        2,
        1,
        1,
        2,
        3,
        1,
        9,
        7,
        2,
        2,
        2,
        3,
        3,
        2,
        2,
        2,
        3,
        3,
        2,
        2,
        2,
        3,
        1,
        2,
        2,
        2,
        3,
        1,
        2,
        2,
        2,
        3,
        3,
        5,
        2,
        2,
        1,
        2,
        2,
        3,
        1,
        2,
        2,
        2,
        3,
        3,
        2,
        1,
        2,
        2,
        3,
        2,
        2,
        3,
        3,
        1,
        1,
        1,
        5,
        4,
        1,
        1,
        1,
        7,
        2,
        1,
        16,
        1,
        6,
        6,
        2,
        1,
        16,
        5,
        1,
        1,
        2,
        1,
        1,
        1,
        1,
        4,
        1,
        11,
        15,
        1,
        1,
        2,
        1,
        1,
        1,
        15,
        14,
        244,
        9,
        3,
        1,
        3,
        4,
        1,
        4,
        3,
        6,
        1,
        3,
        1,
        1,
        7
    ],
    "lines_per_code_cell": [
        2,
        18,
        3,
        1,
        22,
        2,
        37,
        1,
        3,
        11,
        2,
        8,
        3,
        15,
        2,
        3,
        3,
        19,
        3,
        3,
        3,
        3,
        2,
        2,
        1,
        2,
        3,
        2,
        2,
        2,
        3,
        2,
        2,
        2,
        3,
        2,
        2,
        2,
        3,
        2,
        2,
        2,
        3,
        2,
        2,
        2,
        3,
        2,
        2,
        2,
        2,
        3,
        2,
        2,
        2,
        3,
        2,
        2,
        2,
        3,
        2,
        2,
        3,
        1,
        1,
        1,
        5,
        4,
        1,
        7,
        2,
        16,
        6,
        6,
        2,
        16,
        1,
        2,
        1,
        1,
        1,
        11,
        15,
        1,
        2,
        1,
        1,
        15,
        244,
        9,
        3,
        3,
        4,
        6,
        1,
        3,
        1
    ],
    "lines_per_markdown_cell": [
        8,
        1,
        29,
        1,
        1,
        1,
        5,
        3,
        3,
        3,
        1,
        3,
        1,
        3,
        3,
        3,
        1,
        1,
        9,
        7,
        3,
        3,
        1,
        1,
        3,
        5,
        1,
        1,
        3,
        1,
        3,
        1,
        1,
        1,
        1,
        1,
        5,
        1,
        1,
        1,
        4,
        1,
        1,
        14,
        1,
        1,
        4,
        3,
        1,
        7
    ],
    "ave_lines_per_cell": 5.537414965986395,
    "ave_lines_per_code_cell": 6.721649484536083,
    "ave_lines_per_markdown_cell": 3.24,
    "max_lines_per_cell": 244,
    "max_lines_per_code_cell": 244,
    "max_lines_per_markdown_cell": 29,
    "min_lines_per_cell": 1,
    "min_lines_per_code_cell": 1,
    "min_lines_per_markdown_cell": 1,
    "n_chars": 45292,
    "n_chars_code": 30355,
    "n_chars_markdown": 14937,
    "chars_per_cell": [
        582,
        162,
        1157,
        86,
        27,
        519,
        73,
        189,
        19,
        1536,
        34,
        95,
        1443,
        25,
        367,
        173,
        331,
        171,
        313,
        594,
        56,
        72,
        193,
        387,
        264,
        618,
        47,
        82,
        91,
        397,
        201,
        913,
        165,
        379,
        165,
        379,
        213,
        202,
        48,
        56,
        53,
        51,
        103,
        405,
        80,
        950,
        919,
        136,
        46,
        65,
        377,
        495,
        138,
        50,
        67,
        381,
        576,
        137,
        48,
        66,
        379,
        91,
        142,
        58,
        71,
        389,
        101,
        143,
        60,
        72,
        391,
        174,
        1065,
        214,
        64,
        107,
        59,
        71,
        395,
        125,
        74,
        59,
        71,
        399,
        622,
        232,
        41,
        43,
        74,
        378,
        39,
        71,
        401,
        372,
        90,
        91,
        30,
        139,
        97,
        123,
        37,
        264,
        303,
        89,
        93,
        505,
        40,
        169,
        301,
        89,
        51,
        525,
        515,
        30,
        201,
        84,
        37,
        57,
        35,
        75,
        432,
        90,
        241,
        376,
        79,
        29,
        83,
        57,
        57,
        90,
        530,
        1466,
        9737,
        295,
        379,
        81,
        116,
        113,
        84,
        571,
        160,
        255,
        47,
        157,
        17,
        142,
        524
    ],
    "chars_per_code_cell": [
        27,
        519,
        189,
        19,
        1536,
        34,
        1443,
        25,
        331,
        594,
        56,
        193,
        387,
        618,
        47,
        91,
        397,
        913,
        165,
        379,
        165,
        379,
        48,
        56,
        53,
        103,
        405,
        136,
        46,
        65,
        377,
        138,
        50,
        67,
        381,
        137,
        48,
        66,
        379,
        142,
        58,
        71,
        389,
        143,
        60,
        72,
        391,
        214,
        64,
        59,
        71,
        395,
        74,
        59,
        71,
        399,
        232,
        43,
        74,
        378,
        39,
        71,
        401,
        90,
        91,
        30,
        139,
        97,
        37,
        303,
        89,
        505,
        169,
        301,
        89,
        525,
        30,
        84,
        57,
        75,
        90,
        241,
        376,
        29,
        83,
        57,
        90,
        530,
        9737,
        295,
        379,
        116,
        113,
        255,
        47,
        157,
        17
    ],
    "chars_per_markdown_cell": [
        582,
        162,
        1157,
        86,
        73,
        95,
        367,
        173,
        171,
        313,
        72,
        264,
        82,
        201,
        213,
        202,
        51,
        80,
        950,
        919,
        495,
        576,
        91,
        101,
        174,
        1065,
        107,
        125,
        622,
        41,
        372,
        123,
        264,
        93,
        40,
        51,
        515,
        201,
        37,
        35,
        432,
        79,
        57,
        1466,
        81,
        84,
        571,
        160,
        142,
        524
    ],
    "ave_chars_per_line": 55.64127764127764,
    "ave_chars_per_cell": 308.10884353741494,
    "ave_chars_per_code_cell": 312.9381443298969,
    "ave_chars_per_markdown_cell": 298.74,
    "max_chars_per_cell": 9737,
    "max_chars_per_code_cell": 9737,
    "max_chars_per_markdownell": 1466,
    "min_chars_per_cell": 17,
    "min_chars_per_code_cell": 17,
    "min_chars_per_markdown_cell": 35,
    "r_lines_code": 0.800982800982801,
    "r_lines_markdown": 0.19901719901719903,
    "r_chars_markdown": 0.32979334098737084,
    "r_chars_code": 0.6702066590126292,
    "all_cells": [
        {
            "source": "<div style=\"padding: 20px; background-color: #000080; border-radius: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\">\n    <div style=\"border: 2px solid #000080; padding: 20px; text-align: center; border-radius: 10px; background-color: #ffffff;\">\n        <h1 style=\"color: #00000; font-size: 32px; text-transform: uppercase; letter-spacing: 2px; margin-bottom: 20px;\">Become a feature selection master</h1>\n        <div><em>\n       If you like the content please consider an upvote. It is a great motivator to keep sharing code and ideas.\n        Thank you!!!\n    </em></div>\n</div>",
            "mc_idx": 0,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "In this notebook we will dive through various feature selection options. We will illustrate this on two model architectures to show the differences there as well.",
            "mc_idx": 1,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h1 style=\"background-color: #000080; color: #ffff00;\">Table of contents</h1>\n\n* [Load tand install libraries](#1)\n* [Load the data](#2)\n* [Create helper functions and classes](#3)\n* [Mastering feature selection](#4)\n    * [Creating a baseline](#4.1)\n    * [Using statistical methods](#4.2)\n        * [No correlation to target](#4.2.1)\n        * [Mutual information score](#4.2.2)\n        * [Collinearity in the dataset](4.2.3)\n    * [Using model inbuilt feature importance](#4.3)\n        * [Linear Regression](#4.3.1)\n        * [HistGradientBoosting](#4.3.2)\n            * [Gain](#4.3.2.1)\n            * [Weight](#4.3.2.2)\n            * [Cover](#4.3.2.3)\n            * [Total gain](#4.3.2.4)\n            * [Total cover](#4.3.2.5)\n    * [Using feature selection algorithms](#4.4)\n        * [Using recursive feature elimination](#4.4.1)\n        * [Using recursive feature elimination with inbuilt cross validation](#4.4.2)\n        * [Sequential feature selection](#4.4.3)\n        * [Lime](#4.4.4)\n        * [Shap](#4.4.5)\n        * [Boruta](#4.4.5)\n* [Comparing the results](#5.0)\n* [How to (not) interpret feature importance](#6.0)\n* [Submission time](#7.0)",
            "mc_idx": 2,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h1 style=\"background-color: #000080; color: #ffff00;\">Load and install libraries</h1>",
            "mc_idx": 3,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "%%capture\n!pip install lime",
            "mc_idx": 4,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "!pip install": 1,
                    "install": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "lime": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    0,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 4,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 0,
                "o_idx": 0
            }
        },
        {
            "source": "import numpy as np\nimport pandas as pd\nimport time\n\nimport lime\nfrom lime import lime_tabular\nfrom lime import submodular_pick\n\nimport optuna\nimport shap\n\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import mutual_info_classif, RFE, RFECV, SequentialFeatureSelector\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.metrics import make_scorer, accuracy_score\n\nimport xgboost as xgb",
            "mc_idx": 5,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.014285714285714285,
                "Data_Transform": 0.007142857142857143,
                "Model_Train": 0.05,
                "Model_Evaluation": 0.03571428571428571,
                "Model_Interpretation": 0.05714285714285714,
                "Hyperparameter_Tuning": 0.02857142857142857,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 14
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "info": 1,
                    ".mode": 1
                },
                "Data_Transform": {
                    ".mod": 1
                },
                "Model_Train": {
                    "train_test_split": 1,
                    "model": 2,
                    "model_selection": 1,
                    "logisticregression": 1,
                    "gradientboostingclassifier": 1,
                    ".linear": 1
                },
                "Model_Evaluation": {
                    "accuracy_score": 2,
                    "cross_val_score": 1,
                    "model": 2
                },
                "Model_Interpretation": {
                    "lime": 4,
                    "shap": 1,
                    "model": 2,
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {
                    "optuna": 1,
                    "cross_val_score": 1,
                    "kfold": 1,
                    "train_test_split": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    1,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 5,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 1,
                "o_idx": 0
            }
        },
        {
            "source": "<h1 style=\"background-color: #000080; color: #ffff00;\">Load the data</h1>",
            "mc_idx": 6,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "train = pd.read_csv(r'/kaggle/input/titanic/train.csv')\ntest = pd.read_csv(r'/kaggle/input/titanic/test.csv')\nsample_submission = pd.read_csv(r'/kaggle/input/titanic/gender_submission.csv')",
            "mc_idx": 7,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 6,
                    "pd.read_": 6
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    2,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 7,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 2,
                "o_idx": 0
            }
        },
        {
            "source": "target = \"Survived\"",
            "mc_idx": 8,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    3,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 8,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 3,
                "o_idx": 0
            }
        },
        {
            "source": "# borrowed from here: https://www.kaggle.com/code/tisa33/titanic-sk-87-2-rf-84-4-tf-87-1-rf-84-9/notebook\ndef normailize_data(df):\n    df['Cabin_Letter'] = df['Cabin'].apply(lambda x: str(x)[0])\n    df['Name_Title'] = df['Name'].apply(lambda x: x.split()[1]).apply(lambda x: x.split()[0])\n    df['Name_Len'] = df['Name'].apply(lambda x: len(x))\n    df['Age_Null'] = df['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n    #df['Age'] = df.groupby(['Name_Title', 'Pclass', 'Sex'])['Age'].transform(lambda x: x.fillna(x.mean()))\n    df['Age'] = df['Age'].fillna(0)\n    df['Ticket_Type'] = df['Ticket'].apply(lambda x: x[0])\n    df['Age'] = (df['Age'] - df['Age'].min()) / (df['Age'].max() - df['Age'].min())\n    df['Fare'] = (df['Fare'] - df['Fare'].min()) / (df['Fare'].max() - df['Fare'].min())\n    df['Name_Len'] = (df['Name_Len'] - df['Name_Len'].min()) / (df['Name_Len'].max() - df['Name_Len'].min())\n    df['SibSp'] = (df['SibSp'] - df['SibSp'].min()) / (df['SibSp'].max() - df['SibSp'].min())\n    df['Parch'] = (df['Parch'] - df['Parch'].min()) / (df['Parch'].max() - df['Parch'].min())\n    df = pd.get_dummies(df, columns=['Sex', 'Embarked', 'Name_Title', 'Cabin_Letter', 'Ticket_Type', 'Pclass'], drop_first=True, dtype=int)\n    df = df.drop(['Name', 'Cabin', 'PassengerId', 'Ticket'], axis=1)\n    return df\n\nfull_data = pd.concat([train, test])\nfull_data = normailize_data(full_data)\ntrain = full_data.loc[full_data[target].isna() == False].copy().fillna(0)\ntest = full_data.loc[full_data[target].isna() == True].copy().fillna(0)",
            "mc_idx": 9,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.7857142857142857,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    "columns": 1,
                    ".isna": 2,
                    ".isnull": 1,
                    ".mean": 1,
                    ".min": 10,
                    ".max": 5,
                    ".groupby": 1
                },
                "Data_Transform": {
                    ".concat(": 1,
                    ".groupby(": 1,
                    ".fillna(": 4,
                    ".apply(": 6,
                    "transform": 1,
                    ".split": 2,
                    ".drop": 1,
                    ".fillna": 4,
                    ".apply": 6,
                    ".concat": 1,
                    ".get_dummies": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    4,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 9,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 4,
                "o_idx": 0
            }
        },
        {
            "source": "X = train.copy()\ny = X.pop(target)",
            "mc_idx": 10,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    5,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 10,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 5,
                "o_idx": 0
            }
        },
        {
            "source": "<h1 style=\"background-color: #000080; color: #ffff00;\">Create helper functions and classes</h1>",
            "mc_idx": 11,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "class ResultTracker:\n    def __init__(self):\n        self.losses_mean = []\n        self.losses_std = []\n        self.runtime_secs = []\n        self.model_name = []\n        self.experiment_name  = []\n        \n    def eval_model(self, model, X, y):\n        mae_scorer = make_scorer(accuracy_score, greater_is_better=True)\n        start = time.time()\n        losses = cross_val_score(model, X, y, cv=5, n_jobs=-1, scoring=mae_scorer)\n        end = time.time()\n        runtime_secs = end - start\n        return np.mean(losses), np.std(losses),  runtime_secs\n    \n    def add_experiment(self, *, model, X, y, model_name, experiment_name):\n        exp_mean, exp_std, runtime_secs = self.eval_model(model, X, y)\n        print(f\"Model {model_name} achieved a score of {exp_mean} with an std of {exp_std} in {runtime_secs} secs\")\n        \n        self.losses_mean.append(exp_mean)\n        self.losses_std.append(exp_std)\n        self.runtime_secs.append(runtime_secs)\n        self.model_name.append(model_name)\n        self.experiment_name.append(experiment_name)\n        \n    def retrive_results(self):\n        results_df = pd.DataFrame(\n            {\n                \"losses_mean\": self.losses_mean,\n                \"losses_std\": self.losses_std,\n                \"runtime_secs\": self.runtime_secs,\n                \"model_name\": self.model_name,\n                \"experiment_name\": self.experiment_name\n            }\n        )\n        return results_df",
            "mc_idx": 12,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5294117647058824,
                "Data_Transform": 0.35294117647058826,
                "Model_Train": 0.8235294117647058,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.8235294117647058,
                "Hyperparameter_Tuning": 0.058823529411764705,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".std(": 1,
                    "np.mean": 1,
                    "np.std": 1,
                    ".mean": 1,
                    ".std": 1,
                    ".mode": 3
                },
                "Data_Transform": {
                    ".exp": 3,
                    ".mod": 3
                },
                "Model_Train": {
                    "model": 14
                },
                "Model_Evaluation": {
                    "accuracy_score": 2,
                    "cross_val_score": 1,
                    "model": 14
                },
                "Model_Interpretation": {
                    "model": 14
                },
                "Hyperparameter_Tuning": {
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    6,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 12,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 6,
                "o_idx": 0
            }
        },
        {
            "source": "tracker = ResultTracker()",
            "mc_idx": 13,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    7,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 13,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 7,
                "o_idx": 0
            }
        },
        {
            "source": "<h1 style=\"background-color: #000080; color: #ffff00;\">Mastering feature selection</h1>\n\nNow that we installed everything we need and loaded our data it is time to deep dive into the actual topic. On purpose I do not preprocess the data, oping that we can see a bit more variation between both models.\n\nFeel free to copy the notebook and play with some preprocessing.",
            "mc_idx": 14,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h2 style=\"background-color: #000080; color: #ffff00;\">Creating a baseline</h2>\n\nBefore we start we create a bseline for our models were we just run them using all features.",
            "mc_idx": 15,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X, y=y, model_name=\"HistGradientBoosting\", experiment_name=\"using_all_features\")\ntracker.add_experiment(model=lin_est, X=X, y=y, model_name=\"LogisticRegression\", experiment_name=\"using_all_features\")",
            "mc_idx": 16,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    8,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8226727763480008 with an std of 0.01649095088807791 in 3.680934429168701 secs\nModel LogisticRegression achieved a score of 0.8204255853367648 with an std of 0.02864899384162871 in 0.0760965347290039 secs\n"
                    ]
                },
                "mc_idx": 16,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 8,
                "o_idx": 0
            }
        },
        {
            "source": "<h2 style=\"background-color: #000080; color: #ffff00;\">Using statistical methods</h2>\n\nIn this section we will remove features based on statistical methods and properties.",
            "mc_idx": 17,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">No correlation to target</h3>\n\nWe measure the correlation of all columns to the target and eliminate the ones that have almost no correlation. This captures linear relationships only, which is a hard limitation and might underestimate the value of a feature.",
            "mc_idx": 18,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "def calculate_correlations(df: pd.DataFrame, target: pd.Series) -> pd.DataFrame:\n    \"\"\"\n    Calculates the correlations of all columns with regards to the target and returns a DataFrame with all column names\n    and their correlation coefficient with regards to the target.\n    \n    :param df: Pandas DataFrame\n    :param target: Pandas Series with target values\n    :return: Pandas DataFrame with column names and their correlation coefficient with regards to the target\n    \"\"\"\n    correlations = df.corrwith(target)\n    return pd.DataFrame(correlations, columns=['correlation_coefficient'])",
            "mc_idx": 19,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.5,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".corr": 2,
                    "columns": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    9,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 19,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 9,
                "o_idx": 0
            }
        },
        {
            "source": "correlations = calculate_correlations(X, y)\ncorrelations",
            "mc_idx": 20,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    10,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "               correlation_coefficient\nAge                           0.010539\nSibSp                        -0.035322\nParch                         0.081629\nFare                          0.257307\nName_Len                      0.332350\n...                                ...\nTicket_Type_P                 0.151310\nTicket_Type_S                -0.035049\nTicket_Type_W                -0.057546\nPclass_2                      0.093349\nPclass_3                     -0.322308\n\n[67 rows x 1 columns]"
                    ]
                },
                "mc_idx": 20,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 10,
                "o_idx": 0
            }
        },
        {
            "source": "Here we remove the columns with a correlation coefficient close to zero.",
            "mc_idx": 21,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "keep_columns = correlations.loc[\n    (\n        (correlations[\"correlation_coefficient\"] >= 0.1) |\n        (correlations[\"correlation_coefficient\"] <= -0.1)\n    )\n].index.to_list()\n\nkeep_columns",
            "mc_idx": 22,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    11,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Fare',\n 'Name_Len',\n 'Sex_male',\n 'Embarked_S',\n 'Name_Title_Miss.',\n 'Name_Title_Mr.',\n 'Name_Title_Mrs.',\n 'Cabin_Letter_B',\n 'Cabin_Letter_C',\n 'Cabin_Letter_D',\n 'Cabin_Letter_E',\n 'Cabin_Letter_n',\n 'Ticket_Type_3',\n 'Ticket_Type_A',\n 'Ticket_Type_P',\n 'Pclass_3']"
                    ]
                },
                "mc_idx": 22,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 11,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_columns], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"removed_no_corr_to_target\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_columns], y=y, model_name=\"LogisticRegression\", experiment_name=\"removed_no_corr_to_target\")",
            "mc_idx": 23,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2857142857142857,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 2
                },
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    12,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8036344234511329 with an std of 0.027379687968800925 in 0.904163122177124 secs\nModel LogisticRegression achieved a score of 0.786761659657272 with an std of 0.014123873083912195 in 0.0602869987487793 secs\n"
                    ]
                },
                "mc_idx": 23,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 12,
                "o_idx": 0
            }
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">Mutual information score</h3>\n\nWe measure the mutual information score of all columns to with regards to the target and remove the ones with almost zero scoring. MI scores also consider non-linear information.",
            "mc_idx": 24,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "def calculate_mi_scores(df, target):\n    \"\"\"\n    Calculates the mutual information score of all columns with regards to the (regression) target.\n    \n    Parameters:\n    df (Pandas DataFrame): The DataFrame containing the features.\n    target (Pandas Series): The target variable.\n    \n    Returns:\n    Pandas DataFrame: A DataFrame with all column names and their MI scores with regards to the target.\n    \"\"\"\n    mi_scores = mutual_info_classif(df, target)\n    mi_scores = pd.Series(mi_scores, name='MI Scores', index=df.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores.to_frame()",
            "mc_idx": 25,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.25,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.25,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "info": 2,
                    "columns": 2
                },
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    13,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 25,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 13,
                "o_idx": 0
            }
        },
        {
            "source": "mi_scores = calculate_mi_scores(X, y)\nmi_scores",
            "mc_idx": 26,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    14,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "                   MI Scores\nSex_male            0.163445\nFare                0.135732\nName_Title_Mr.      0.122084\nName_Len            0.103633\nCabin_Letter_n      0.054900\n...                      ...\nName_Title_Velde,   0.000000\nName_Title_Steen,   0.000000\nName_Title_Carlo,   0.000000\nName_Title_Ms.      0.000000\nName_Title_y        0.000000\n\n[67 rows x 1 columns]"
                    ]
                },
                "mc_idx": 26,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 14,
                "o_idx": 0
            }
        },
        {
            "source": "Interesting! Only the id column has very little value. So we only remove that one.",
            "mc_idx": 27,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "keep_columns = mi_scores.loc[(mi_scores[\"MI Scores\"] >= 0.0)].index.to_list()\n\nkeep_columns",
            "mc_idx": 28,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    15,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Sex_male',\n 'Fare',\n 'Name_Title_Mr.',\n 'Name_Len',\n 'Cabin_Letter_n',\n 'Name_Title_Miss.',\n 'Name_Title_Mrs.',\n 'Ticket_Type_F',\n 'Pclass_3',\n 'Cabin_Letter_E',\n 'Ticket_Type_P',\n 'Name_Title_Jonkheer.',\n 'Ticket_Type_7',\n 'Cabin_Letter_T',\n 'Age',\n 'Embarked_S',\n 'Parch',\n 'Ticket_Type_S',\n 'Name_Title_Master.',\n 'Age_Null',\n 'Name_Title_Shawah,',\n 'Name_Title_Capt.',\n 'Cabin_Letter_C',\n 'Cabin_Letter_B',\n 'Name_Title_Khalil,',\n 'Cabin_Letter_F',\n 'Name_Title_Planke,',\n 'Name_Title_Mlle.',\n 'SibSp',\n 'Name_Title_Palmquist,',\n 'Name_Title_Dr.',\n 'Ticket_Type_6',\n 'Cabin_Letter_D',\n 'Name_Title_der',\n 'Name_Title_Brito,',\n 'Embarked_Q',\n 'Name_Title_Gordon,',\n 'Name_Title_Mme.',\n 'Name_Title_Col.',\n 'Ticket_Type_C',\n 'Name_Title_Rev.',\n 'Ticket_Type_9',\n 'Name_Title_Don.',\n 'Ticket_Type_L',\n 'Name_Title_Impe,',\n 'Name_Title_Major.',\n 'Ticket_Type_5',\n 'Ticket_Type_W',\n 'Ticket_Type_A',\n 'Ticket_Type_8',\n 'Pclass_2',\n 'Name_Title_Mulder,',\n 'Name_Title_Melkebeke,',\n 'Ticket_Type_4',\n 'Ticket_Type_3',\n 'Ticket_Type_2',\n 'Name_Title_Pelsmaeker,',\n 'Cabin_Letter_G',\n 'Name_Title_Messemaeker,',\n 'Name_Title_Cruyssen,',\n 'Name_Title_the',\n 'Name_Title_Walle,',\n 'Name_Title_Velde,',\n 'Name_Title_Steen,',\n 'Name_Title_Carlo,',\n 'Name_Title_Ms.',\n 'Name_Title_y']"
                    ]
                },
                "mc_idx": 28,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 15,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_columns], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"removed_low_mi_score_to_target\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_columns], y=y, model_name=\"LogisticRegression\", experiment_name=\"removed_low_mi_score_to_target\")",
            "mc_idx": 29,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2857142857142857,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 2
                },
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    16,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8226727763480006 with an std of 0.01097521926722228 in 1.4778385162353516 secs\nModel LogisticRegression achieved a score of 0.8204255853367648 with an std of 0.02864899384162871 in 0.06644296646118164 secs\n"
                    ]
                },
                "mc_idx": 29,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 16,
                "o_idx": 0
            }
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">Collinearity in the dataset</h3>\n\nWe measure the correlation of all columns to each other and remove the ones with high correlation (one of them).",
            "mc_idx": 30,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "def remove_collinearity(dataset, threshold=0.9):\n    \"\"\"\n    Loops through all columns and checks, if features are highly positively correlated.\n    If correlation is above given threshold, then only one column is kept.\n    :param threshold: Maximum allowed correlation. Expects a float from -1 to +1.\n    :return: Returns modified dataframe.\n    \"\"\"\n    col_corr = set()  # Set of all the names of deleted columns\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if (corr_matrix.iloc[i, j] >= threshold) and (\n                corr_matrix.columns[j] not in col_corr\n            ):\n                colname = corr_matrix.columns[i]  # getting the name of column\n                col_corr.add(colname)\n                if colname in dataset.columns:\n                    del dataset[colname]  # deleting the column from the dataset\n    return dataset",
            "mc_idx": 31,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.75,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.125,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.125,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "dataset": 6
                },
                "Exploratory_Data_Analysis": {
                    ".corr": 2,
                    "columns": 6
                },
                "Data_Transform": {
                    ".add": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    17,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 31,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 17,
                "o_idx": 0
            }
        },
        {
            "source": "X_thres_09 = remove_collinearity(X.copy(), 0.9)\nX_thres_09.columns.to_list()\nprint(f\"Removed columns {set(X.columns.to_list()) - set(X_thres_09.columns.to_list())}\")",
            "mc_idx": 32,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 4
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    18,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Removed columns set()\n"
                    ]
                },
                "mc_idx": 32,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 18,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X_thres_09, y=y, model_name=\"HistGradientBoosting\", experiment_name=\"removed_collinearity_with_090plus\")\ntracker.add_experiment(model=lin_est, X=X_thres_09, y=y, model_name=\"LogisticRegression\", experiment_name=\"removed_collinearity_with_090plus\")",
            "mc_idx": 33,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    19,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8226727763480008 with an std of 0.01649095088807791 in 1.4731111526489258 secs\nModel LogisticRegression achieved a score of 0.8204255853367648 with an std of 0.02864899384162871 in 0.0719904899597168 secs\n"
                    ]
                },
                "mc_idx": 33,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 19,
                "o_idx": 0
            }
        },
        {
            "source": "X_thres_08 = remove_collinearity(X.copy(), 0.8)\nX_thres_08.columns.to_list()\nprint(f\"Removed columns {set(X.columns.to_list()) - set(X_thres_08.columns.to_list())}\")",
            "mc_idx": 34,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 4
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    20,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Removed columns {'Name_Title_Mr.'}\n"
                    ]
                },
                "mc_idx": 34,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 20,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X_thres_08, y=y, model_name=\"HistGradientBoosting\", experiment_name=\"removed_collinearity_with_080plus\")\ntracker.add_experiment(model=lin_est, X=X_thres_08, y=y, model_name=\"LogisticRegression\", experiment_name=\"removed_collinearity_with_080plus\")",
            "mc_idx": 35,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    21,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8193082669010107 with an std of 0.00957769381205687 in 1.443075180053711 secs\nModel LogisticRegression achieved a score of 0.826031008725127 with an std of 0.02779141048557072 in 0.09639143943786621 secs\n"
                    ]
                },
                "mc_idx": 35,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 21,
                "o_idx": 0
            }
        },
        {
            "source": "<h2 style=\"background-color: #000080; color: #ffff00;\">Using model inbuilt feature importance</h2>\n\nIn this section we will invvestigate if the models itself provide us valueable information for feature selection.",
            "mc_idx": 36,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">Linear Regression</h3>\n\nFor linear regression we need to train an instance first. Then we can make use of it's own coefficients to select features.",
            "mc_idx": 37,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "lin_est = LogisticRegression()\nlin_est.fit(X, y)",
            "mc_idx": 38,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "logisticregression": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    22,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "LogisticRegression()"
                    ]
                },
                "mc_idx": 38,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 22,
                "o_idx": 0
            }
        },
        {
            "source": "print(lin_est.coef_.shape, len(X.columns))\nlin_est.coef_",
            "mc_idx": 39,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.6666666666666666,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1,
                    "shape": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap": 1,
                    "coef_": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    23,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "(1, 67) 67\n",
                        "array([[-1.26836826, -2.22171938, -1.35275202,  0.71873876,  1.02384122,\n        -0.5645056 , -1.63522012,  0.25964309, -0.34326716,  0.        ,\n        -0.13424704, -0.30790936,  0.06837276, -0.08342326, -0.34254269,\n        -0.18053407,  0.40432002, -0.57851042, -0.33586632,  0.        ,\n        -0.04061364,  1.79074941, -0.09716645,  0.50435643,  0.49459713,\n         0.15062311,  0.06894093, -0.73569689,  0.76674893,  0.24003438,\n         0.78842234,  0.        , -0.12213086, -0.57618861, -0.88698026,\n        -0.23957743, -0.10730336, -0.10676901, -0.11119572, -0.4154385 ,\n         0.06064046,  0.15102603,  0.19663832, -0.27583558,  0.76952743,\n         0.86541321,  0.15572634, -0.61482308, -0.29819382, -0.62853534,\n        -0.1406039 , -0.91369688, -1.1085717 , -0.58027576, -0.06368129,\n        -0.96118875, -0.24038735,  0.1371446 , -0.83526741, -0.20698204,\n         0.09609536,  0.33000732, -0.21143127,  0.00891648, -1.32809348,\n        -0.32435197, -0.86525348]])"
                    ]
                },
                "mc_idx": 39,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 23,
                "o_idx": 1
            }
        },
        {
            "source": "((lin_est.coef_ < -0.05) | (lin_est.coef_ > 0.05))[0]",
            "mc_idx": 40,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "coef_": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    24,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n       False,  True,  True,  True,  True,  True,  True,  True,  True,\n        True, False, False,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True, False,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n       False,  True,  True,  True])"
                    ]
                },
                "mc_idx": 40,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 24,
                "o_idx": 0
            }
        },
        {
            "source": "We remove columns with coefficients close to zero..",
            "mc_idx": 41,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "keep_cols = X.loc[:, ((lin_est.coef_ < -0.05) | (lin_est.coef_ > 0.05))[0]].columns.to_list()\nkeep_cols",
            "mc_idx": 42,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "coef_": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    25,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Age',\n 'SibSp',\n 'Parch',\n 'Fare',\n 'Name_Len',\n 'Age_Null',\n 'Sex_male',\n 'Embarked_Q',\n 'Embarked_S',\n 'Name_Title_Capt.',\n 'Name_Title_Carlo,',\n 'Name_Title_Col.',\n 'Name_Title_Cruyssen,',\n 'Name_Title_Don.',\n 'Name_Title_Dr.',\n 'Name_Title_Gordon,',\n 'Name_Title_Impe,',\n 'Name_Title_Jonkheer.',\n 'Name_Title_Master.',\n 'Name_Title_Melkebeke,',\n 'Name_Title_Messemaeker,',\n 'Name_Title_Miss.',\n 'Name_Title_Mlle.',\n 'Name_Title_Mme.',\n 'Name_Title_Mr.',\n 'Name_Title_Mrs.',\n 'Name_Title_Ms.',\n 'Name_Title_Mulder,',\n 'Name_Title_Pelsmaeker,',\n 'Name_Title_Planke,',\n 'Name_Title_Rev.',\n 'Name_Title_Shawah,',\n 'Name_Title_Steen,',\n 'Name_Title_Velde,',\n 'Name_Title_Walle,',\n 'Name_Title_der',\n 'Name_Title_the',\n 'Name_Title_y',\n 'Cabin_Letter_B',\n 'Cabin_Letter_C',\n 'Cabin_Letter_D',\n 'Cabin_Letter_E',\n 'Cabin_Letter_F',\n 'Cabin_Letter_G',\n 'Cabin_Letter_T',\n 'Cabin_Letter_n',\n 'Ticket_Type_2',\n 'Ticket_Type_3',\n 'Ticket_Type_4',\n 'Ticket_Type_5',\n 'Ticket_Type_6',\n 'Ticket_Type_7',\n 'Ticket_Type_8',\n 'Ticket_Type_9',\n 'Ticket_Type_A',\n 'Ticket_Type_C',\n 'Ticket_Type_F',\n 'Ticket_Type_L',\n 'Ticket_Type_P',\n 'Ticket_Type_W',\n 'Pclass_2',\n 'Pclass_3']"
                    ]
                },
                "mc_idx": 42,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 25,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"removed_lower_half_of_lr_coefficients\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"removed_lower_half_of_lr_coefficients\")",
            "mc_idx": 43,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    26,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8260435628648546 with an std of 0.012728910275995875 in 1.4154045581817627 secs\nModel LogisticRegression achieved a score of 0.8215491808423827 with an std of 0.02894802237428172 in 0.0769658088684082 secs\n"
                    ]
                },
                "mc_idx": 43,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 26,
                "o_idx": 0
            }
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoosting</h3>",
            "mc_idx": 44,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "It seems like the HistGradientBoostingClassifier from sklearn does not offer any feature importance functionality. However we can make use of HistGradientBoosting also via the Xgboost library and get our importances from there.\n\nHere we can pass one of multiple importance types via the importance_type parameter (see the [docs](https://xgboost.readthedocs.io/en/stable/python/python_api.html):\nThe feature importance type for the feature_importances_ property:\n* For tree model, it\u2019s either \u201cgain\u201d, \u201cweight\u201d, \u201ccover\u201d, \u201ctotal_gain\u201d or \u201ctotal_cover\u201d.\n* For linear model, only \u201cweight\u201d is defined and it\u2019s the normalized coefficients without bias.\n\nAs you can see there is a total of 5 feature importance metrics within gradient boosting. What is behind each of them I will quote from [this](https://towardsdatascience.com/be-careful-when-interpreting-your-features-importance-in-xgboost-6e16132588e7) Medium article. Please consider some claps there.\n",
            "mc_idx": 45,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h4 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoosting gain</h4>\n\n\"The Gain implies the relative contribution of the corresponding feature to the model calculated by taking each feature\u2019s contribution for each tree in the model. A higher value of this metric when compared to another feature implies it is more important for generating a prediction.\n\nThe Gain is the most relevant attribute to interpret the relative importance of each feature.\n\n\u2018Gain\u2019 is the improvement in accuracy brought by a feature to the branches it is on. The idea is that before adding a new split on a feature X to the branch there was some wrongly classified elements, after adding the split on this feature, there are two new branches, and each of these branch is more accurate (one branch saying if your observation is on this branch then it should be classified as 1, and the other branch saying the exact opposite).\"",
            "mc_idx": 46,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"gain\")\nmodel.fit(X, y)",
            "mc_idx": 47,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model.fit": 1,
                    ".fit(": 1,
                    "model": 2
                },
                "Model_Evaluation": {
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    27,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type='gain',\n              interaction_constraints=None, learning_rate=None, max_bin=255,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, random_state=100, ...)"
                    ]
                },
                "mc_idx": 47,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 27,
                "o_idx": 0
            }
        },
        {
            "source": "xgb_gain = model.feature_importances_\nxgb_gain",
            "mc_idx": 48,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "feature_importances_": 2,
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    28,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([0.0135434 , 0.02883319, 0.0093273 , 0.01767678, 0.0123399 ,\n       0.        , 0.26620883, 0.00521423, 0.01701247, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.01941586, 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.04230755, 0.        , 0.        , 0.02395579,\n       0.        , 0.        , 0.07754616, 0.01392192, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.12761562,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.00287151, 0.01627882, 0.00705073,\n       0.01460894, 0.        , 0.        , 0.        , 0.06574743,\n       0.00766516, 0.01376058, 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.00484979, 0.01086271,\n       0.        , 0.        , 0.01218499, 0.01182252, 0.0217451 ,\n       0.02385882, 0.11177391], dtype=float32)"
                    ]
                },
                "mc_idx": 48,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 28,
                "o_idx": 0
            }
        },
        {
            "source": "keep_cols = X.loc[:, xgb_gain > 0.05].columns.to_list()\nkeep_cols",
            "mc_idx": 49,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    29,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Sex_male', 'Name_Title_Mr.', 'Name_Title_Rev.', 'Cabin_Letter_n', 'Pclass_3']"
                    ]
                },
                "mc_idx": 49,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 29,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"xgboost_importance_gain\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"xgboost_importance_gain\")",
            "mc_idx": 50,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    30,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.7800326407632918 with an std of 0.008709637448781676 in 0.3093535900115967 secs\nModel LogisticRegression achieved a score of 0.7900947837549432 with an std of 0.015659861494704365 in 0.0467069149017334 secs\n"
                    ]
                },
                "mc_idx": 50,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 30,
                "o_idx": 0
            }
        },
        {
            "source": "<h4 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoosting weight</h4>\n\n\"The Frequency (R)/Weight (python) is the percentage representing the relative number of times a particular feature occurs in the trees of the model. In the above example, if feature1 occurred in 2 splits, 1 split and 3 splits in each of tree1, tree2 and tree3; then the weight for feature1 will be 2+1+3 = 6. The frequency for feature1 is calculated as its percentage weight over weights of all features.\"",
            "mc_idx": 51,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"weight\")\nmodel.fit(X, y)",
            "mc_idx": 52,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model.fit": 1,
                    ".fit(": 1,
                    "model": 2
                },
                "Model_Evaluation": {
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    31,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type='weight',\n              interaction_constraints=None, learning_rate=None, max_bin=255,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, random_state=100, ...)"
                    ]
                },
                "mc_idx": 52,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 31,
                "o_idx": 0
            }
        },
        {
            "source": "xgb_weight = model.feature_importances_\nxgb_weight",
            "mc_idx": 53,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "feature_importances_": 2,
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    32,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([0.25703463, 0.03192641, 0.02164502, 0.26623377, 0.21861471,\n       0.        , 0.02272727, 0.00324675, 0.0232684 , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.00054113, 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.01677489, 0.        , 0.        , 0.00108225,\n       0.        , 0.        , 0.01244589, 0.00595238, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.00054113,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.0021645 , 0.01190476, 0.00757576,\n       0.00541126, 0.        , 0.        , 0.        , 0.01136364,\n       0.00974026, 0.02272727, 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.00487013, 0.00162338,\n       0.        , 0.        , 0.00324675, 0.01298701, 0.00162338,\n       0.00595238, 0.01677489], dtype=float32)"
                    ]
                },
                "mc_idx": 53,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 32,
                "o_idx": 0
            }
        },
        {
            "source": "keep_cols = X.loc[:, xgb_weight > 0.05].columns.to_list()\nkeep_cols",
            "mc_idx": 54,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    33,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Age', 'Fare', 'Name_Len']"
                    ]
                },
                "mc_idx": 54,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 33,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"xgboost_importance_weight\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"xgboost_importance_weight\")",
            "mc_idx": 55,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    34,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.7149959199045886 with an std of 0.03786511167697809 in 0.7832012176513672 secs\nModel LogisticRegression achieved a score of 0.685757328479066 with an std of 0.016814167133173404 in 0.0418243408203125 secs\n"
                    ]
                },
                "mc_idx": 55,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 34,
                "o_idx": 0
            }
        },
        {
            "source": "<h4 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoosting cover</h4>\n\n\"The Coverage metric means the relative number of observations related to this feature. For example, if you have 100 observations, 4 features and 3 trees, and suppose feature1 is used to decide the leaf node for 10, 5, and 2 observations in tree1, tree2 and tree3 respectively; then the metric will count cover for this feature as 10+5+2 = 17 observations. This will be calculated for all the 4 features and the cover will be 17 expressed as a percentage for all features\u2019 cover metrics.\"",
            "mc_idx": 56,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"cover\")\nmodel.fit(X, y)",
            "mc_idx": 57,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "cov": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model.fit": 1,
                    ".fit(": 1,
                    "model": 2
                },
                "Model_Evaluation": {
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    35,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type='cover',\n              interaction_constraints=None, learning_rate=None, max_bin=255,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, random_state=100, ...)"
                    ]
                },
                "mc_idx": 57,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 35,
                "o_idx": 0
            }
        },
        {
            "source": "xgb_cover = model.feature_importances_\nxgb_cover",
            "mc_idx": 58,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.6666666666666666,
                "Data_Transform": 0.0,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "cov": 2
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "feature_importances_": 2,
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    36,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([0.01676155, 0.01472439, 0.01844941, 0.02428181, 0.02002116,\n       0.        , 0.0733851 , 0.00499388, 0.03057476, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.04707531, 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.0646151 , 0.        , 0.        , 0.00690226,\n       0.        , 0.        , 0.02320972, 0.03372166, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.05071908,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.04474477, 0.01116774, 0.06085984,\n       0.07158813, 0.        , 0.        , 0.        , 0.03167669,\n       0.01213521, 0.02077974, 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.05531023, 0.02401487,\n       0.        , 0.        , 0.03828023, 0.03123656, 0.10688441,\n       0.02607676, 0.03580966], dtype=float32)"
                    ]
                },
                "mc_idx": 58,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 36,
                "o_idx": 0
            }
        },
        {
            "source": "keep_cols = X.loc[:, xgb_cover > 0.05].columns.to_list()\nkeep_cols",
            "mc_idx": 59,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "cov": 1,
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    37,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Sex_male',\n 'Name_Title_Master.',\n 'Name_Title_Rev.',\n 'Cabin_Letter_D',\n 'Cabin_Letter_E',\n 'Ticket_Type_A',\n 'Ticket_Type_W']"
                    ]
                },
                "mc_idx": 59,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 37,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"xgboost_importance_cover\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"xgboost_importance_cover\")",
            "mc_idx": 60,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2857142857142857,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "cov": 2
                },
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    38,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.794620551126734 with an std of 0.018228868104151152 in 0.2340531349182129 secs\nModel LogisticRegression achieved a score of 0.7901136149645345 with an std of 0.019100377882376823 in 0.0467984676361084 secs\n"
                    ]
                },
                "mc_idx": 60,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 38,
                "o_idx": 0
            }
        },
        {
            "source": "<h4 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoosting total_gain</h4>",
            "mc_idx": 61,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"total_gain\")\nmodel.fit(X, y)",
            "mc_idx": 62,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model.fit": 1,
                    ".fit(": 1,
                    "model": 2
                },
                "Model_Evaluation": {
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    39,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type='total_gain',\n              interaction_constraints=None, learning_rate=None, max_bin=255,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, random_state=100, ...)"
                    ]
                },
                "mc_idx": 62,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 39,
                "o_idx": 0
            }
        },
        {
            "source": "xgb_total_gain = model.feature_importances_\nxgb_total_gain",
            "mc_idx": 63,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "feature_importances_": 2,
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    40,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([0.14452143, 0.03821693, 0.0083816 , 0.19537959, 0.11199635,\n       0.        , 0.25117862, 0.00070283, 0.01643413, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.00043618, 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.02946392, 0.        , 0.        , 0.00107635,\n       0.        , 0.        , 0.04006813, 0.00344035, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.00286691,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.00025804, 0.00804557, 0.00221755,\n       0.00328193, 0.        , 0.        , 0.        , 0.03101766,\n       0.00309959, 0.01298366, 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.00098057, 0.0007321 ,\n       0.        , 0.        , 0.00164243, 0.00637429, 0.00146553,\n       0.00589593, 0.07784184], dtype=float32)"
                    ]
                },
                "mc_idx": 63,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 40,
                "o_idx": 0
            }
        },
        {
            "source": "keep_cols = X.loc[:, xgb_total_gain > 0.05].columns.to_list()\nkeep_cols",
            "mc_idx": 64,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    41,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Age', 'Fare', 'Name_Len', 'Sex_male', 'Pclass_3']"
                    ]
                },
                "mc_idx": 64,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 41,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"xgboost_importance_total_gain\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"xgboost_importance_total_gain\")",
            "mc_idx": 65,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    42,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8081099742640137 with an std of 0.013470583152657546 in 0.8187851905822754 secs\nModel LogisticRegression achieved a score of 0.7901136149645346 with an std of 0.01842756354064995 in 0.046328067779541016 secs\n"
                    ]
                },
                "mc_idx": 65,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 42,
                "o_idx": 0
            }
        },
        {
            "source": "<h4 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoostingRegressor total_cover</h4>",
            "mc_idx": 66,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"total_cover\")\nmodel.fit(X, y)",
            "mc_idx": 67,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "cov": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model.fit": 1,
                    ".fit(": 1,
                    "model": 2
                },
                "Model_Evaluation": {
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    43,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type='total_cover',\n              interaction_constraints=None, learning_rate=None, max_bin=255,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, random_state=100, ...)"
                    ]
                },
                "mc_idx": 67,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 43,
                "o_idx": 0
            }
        },
        {
            "source": "xgb_total_cover = model.feature_importances_\nxgb_total_cover",
            "mc_idx": 68,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.6666666666666666,
                "Data_Transform": 0.0,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "cov": 2
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "feature_importances_": 2,
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    44,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([0.18067877, 0.01971463, 0.01674718, 0.2711099 , 0.18355656,\n       0.        , 0.06994496, 0.00067997, 0.02983532, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.0010683 , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.04545639, 0.        , 0.        , 0.00031327,\n       0.        , 0.        , 0.01211426, 0.00841784, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.00115099,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.00406164, 0.00557554, 0.01933562,\n       0.01624577, 0.        , 0.        , 0.        , 0.01509587,\n       0.004957  , 0.01980563, 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.01129659, 0.00163494,\n       0.        , 0.        , 0.00521225, 0.01701272, 0.00727671,\n       0.00650947, 0.02519191], dtype=float32)"
                    ]
                },
                "mc_idx": 68,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 44,
                "o_idx": 0
            }
        },
        {
            "source": "keep_cols = X.loc[:, xgb_total_cover > 0.05].columns.to_list()\nkeep_cols",
            "mc_idx": 69,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "cov": 1,
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    45,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Age', 'Fare', 'Name_Len', 'Sex_male']"
                    ]
                },
                "mc_idx": 69,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 45,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"xgboost_importance_total_cover\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"xgboost_importance_total_cover\")",
            "mc_idx": 70,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2857142857142857,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "cov": 2
                },
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    46,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.7867553825874082 with an std of 0.023304255696803628 in 0.802293062210083 secs\nModel LogisticRegression achieved a score of 0.7878664239532986 with an std of 0.015801680287401174 in 0.04020857810974121 secs\n"
                    ]
                },
                "mc_idx": 70,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 46,
                "o_idx": 0
            }
        },
        {
            "source": "<h2 style=\"background-color: #000080; color: #ffff00;\">Using feature selection algorithms</h2>\n\nIn this section we will investigate algorithms designed for feature selection.",
            "mc_idx": 71,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">Using recursive feature elimination</h3>\n\n\"Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through any specific attribute or callable. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.\" (see [sklearn docs](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html))\n\nOne disadvantage here is that we need to tell in advance how many features shall be selected. One re-occuring pattern in this section is that these algorithms are not model agnostic. Therefore we will test each of them for both of our models if possible.",
            "mc_idx": 72,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\nhist_selector, lin_selector = RFE(hist_est, n_features_to_select=10, step=1), RFE(lin_est, n_features_to_select=10, step=1)",
            "mc_idx": 73,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "logisticregression": 1,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    47,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 73,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 47,
                "o_idx": 0
            }
        },
        {
            "source": "#hist_selector = hist_selector.fit(X, y)\n#hist_selector.support_",
            "mc_idx": 74,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    48,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 74,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 48,
                "o_idx": 0
            }
        },
        {
            "source": "This is not compatible with HistGradienBoosting as it misses `coef_` and `feature_importances_` attributes.",
            "mc_idx": 75,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "lin_selector = lin_selector.fit(X, y)\nlin_selector.support_",
            "mc_idx": 76,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    49,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([False,  True,  True, False, False, False,  True, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False,  True, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False,  True, False,  True,  True, False,\n       False,  True, False, False,  True, False, False, False, False,\n       False,  True, False, False])"
                    ]
                },
                "mc_idx": 76,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 49,
                "o_idx": 0
            }
        },
        {
            "source": "keep_cols = X.loc[:, lin_selector.support_].columns.to_list()\nkeep_cols",
            "mc_idx": 77,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    50,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['SibSp',\n 'Parch',\n 'Sex_male',\n 'Name_Title_Master.',\n 'Cabin_Letter_n',\n 'Ticket_Type_3',\n 'Ticket_Type_4',\n 'Ticket_Type_7',\n 'Ticket_Type_A',\n 'Ticket_Type_W']"
                    ]
                },
                "mc_idx": 77,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 50,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"rfe_based_on_logistic_regression\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"rfe_based_on_logistic_regression\")",
            "mc_idx": 78,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    51,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8226853304877283 with an std of 0.012389425379234905 in 0.5716044902801514 secs\nModel LogisticRegression achieved a score of 0.8125478626577113 with an std of 0.03317577568032311 in 0.05377817153930664 secs\n"
                    ]
                },
                "mc_idx": 78,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 51,
                "o_idx": 0
            }
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">Using recursive feature elimination with inbuilt cross validation</h3>",
            "mc_idx": 79,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "lin_est = LogisticRegression()\nlin_selector = RFECV(lin_est, step=1, cv=5)",
            "mc_idx": 80,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "logisticregression": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    52,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 80,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 52,
                "o_idx": 0
            }
        },
        {
            "source": "lin_selector = lin_selector.fit(X, y)\nlin_selector.support_",
            "mc_idx": 81,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    53,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n       False,  True,  True, False, False,  True,  True,  True,  True,\n        True, False, False,  True, False,  True,  True,  True, False,\n        True,  True,  True,  True, False, False,  True,  True,  True,\n       False, False, False,  True, False,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n       False,  True,  True,  True,  True,  True, False,  True,  True,\n       False,  True,  True,  True])"
                    ]
                },
                "mc_idx": 81,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 53,
                "o_idx": 0
            }
        },
        {
            "source": "keep_cols = X.loc[:, lin_selector.support_].columns.to_list()\nkeep_cols",
            "mc_idx": 82,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    54,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Age',\n 'SibSp',\n 'Parch',\n 'Fare',\n 'Name_Len',\n 'Age_Null',\n 'Sex_male',\n 'Embarked_Q',\n 'Embarked_S',\n 'Name_Title_Capt.',\n 'Name_Title_Carlo,',\n 'Name_Title_Don.',\n 'Name_Title_Dr.',\n 'Name_Title_Gordon,',\n 'Name_Title_Impe,',\n 'Name_Title_Jonkheer.',\n 'Name_Title_Master.',\n 'Name_Title_Messemaeker,',\n 'Name_Title_Miss.',\n 'Name_Title_Mlle.',\n 'Name_Title_Mr.',\n 'Name_Title_Mrs.',\n 'Name_Title_Ms.',\n 'Name_Title_Mulder,',\n 'Name_Title_Planke,',\n 'Name_Title_Rev.',\n 'Name_Title_Shawah,',\n 'Name_Title_der',\n 'Name_Title_y',\n 'Cabin_Letter_B',\n 'Cabin_Letter_C',\n 'Cabin_Letter_D',\n 'Cabin_Letter_E',\n 'Cabin_Letter_F',\n 'Cabin_Letter_G',\n 'Cabin_Letter_T',\n 'Cabin_Letter_n',\n 'Ticket_Type_2',\n 'Ticket_Type_3',\n 'Ticket_Type_4',\n 'Ticket_Type_5',\n 'Ticket_Type_7',\n 'Ticket_Type_8',\n 'Ticket_Type_9',\n 'Ticket_Type_A',\n 'Ticket_Type_C',\n 'Ticket_Type_L',\n 'Ticket_Type_P',\n 'Ticket_Type_W',\n 'Pclass_2',\n 'Pclass_3']"
                    ]
                },
                "mc_idx": 82,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 54,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"rfecv_based_on_logistic_regression\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"rfecv_based_on_logistic_regression\")",
            "mc_idx": 83,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    55,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8260435628648546 with an std of 0.012728910275995875 in 1.2924294471740723 secs\nModel LogisticRegression achieved a score of 0.8226727763480006 with an std of 0.030676683281000327 in 0.06981945037841797 secs\n"
                    ]
                },
                "mc_idx": 83,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 55,
                "o_idx": 0
            }
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">Sequential feature selection</h3>\n\n\"This Sequential Feature Selector adds (forward selection) or removes (backward selection) features to form a feature subset in a greedy fashion. At each stage, this estimator chooses the best feature to add or remove based on the cross-validation score of an estimator. In the case of unsupervised learning, this Sequential Feature Selector looks only at the features (X), not the desired outputs (y).\" (see [sklearn docs](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html))",
            "mc_idx": 84,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\nhist_sfs, lin_sfs = SequentialFeatureSelector(hist_est, n_features_to_select=10), SequentialFeatureSelector(lin_est, n_features_to_select=10)",
            "mc_idx": 85,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "logisticregression": 1,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    56,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 85,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 56,
                "o_idx": 0
            }
        },
        {
            "source": "Skipping hist as this is really slow here",
            "mc_idx": 86,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#hist_sfs.fit(X, y)\n#hist_sfs.get_support()",
            "mc_idx": 87,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    57,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 87,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 57,
                "o_idx": 0
            }
        },
        {
            "source": "#keep_cols = X.loc[:, hist_sfs.get_support()].columns.to_list()\n#keep_cols",
            "mc_idx": 88,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    58,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 88,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 58,
                "o_idx": 0
            }
        },
        {
            "source": "#hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\n#tracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"seq_feat_sel_on_histgb\")\n#tracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"seq_feat_sel_on_histgb\")",
            "mc_idx": 89,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    59,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 89,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 59,
                "o_idx": 0
            }
        },
        {
            "source": "lin_sfs.fit(X, y)\nlin_sfs.get_support()",
            "mc_idx": 90,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    60,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([False,  True, False,  True, False, False,  True, False, False,\n       False, False, False, False, False, False, False, False,  True,\n       False, False, False,  True, False, False,  True, False, False,\n        True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False,  True, False,\n       False, False, False, False,  True, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False])"
                    ]
                },
                "mc_idx": 90,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 60,
                "o_idx": 0
            }
        },
        {
            "source": "keep_cols = X.loc[:, lin_sfs.get_support()].columns.to_list()\nkeep_cols",
            "mc_idx": 91,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    61,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['SibSp',\n 'Fare',\n 'Sex_male',\n 'Name_Title_Impe,',\n 'Name_Title_Master.',\n 'Name_Title_Miss.',\n 'Name_Title_Mr.',\n 'Cabin_Letter_C',\n 'Cabin_Letter_n',\n 'Ticket_Type_W']"
                    ]
                },
                "mc_idx": 91,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 61,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"seq_feat_sel_on_logistic_regression\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"seq_feat_sel_on_logistic_regression\")",
            "mc_idx": 92,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    62,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8249074132195091 with an std of 0.02601611401897143 in 0.8028106689453125 secs\nModel LogisticRegression achieved a score of 0.8305065595380077 with an std of 0.03054274488797953 in 0.04700136184692383 secs\n"
                    ]
                },
                "mc_idx": 92,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 62,
                "o_idx": 0
            }
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">Lime</h3>\n\nLime is a model explanantion framework that tries to \"solve for model interpretability by producing locally faithful explanations\". (see the source of the quote and deeper explanations in [this](https://towardsdatascience.com/decrypting-your-machine-learning-model-using-lime-5adc035109b5) Medium article).",
            "mc_idx": 93,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()",
            "mc_idx": 94,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "logisticregression": 1,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    63,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 94,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 63,
                "o_idx": 0
            }
        },
        {
            "source": "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=100)",
            "mc_idx": 95,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "train_test_split": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "train_test_split": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    64,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 95,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 64,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est.fit(x_train, y_train)",
            "mc_idx": 96,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    65,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "HistGradientBoostingClassifier(random_state=100)"
                    ]
                },
                "mc_idx": 96,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 65,
                "o_idx": 0
            }
        },
        {
            "source": "explainer = lime_tabular.LimeTabularExplainer(\n    training_data=x_train.values,\n    feature_names=x_train.columns,\n    mode='regression'\n)",
            "mc_idx": 97,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 0.0,
                "Model_Train": 0.5,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "training_data": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "lime": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    66,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 97,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 66,
                "o_idx": 0
            }
        },
        {
            "source": "exp = explainer.explain_instance(\n    data_row=x_test.iloc[1], \n    predict_fn=hist_est.predict\n)",
            "mc_idx": 98,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".exp": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    67,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "X does not have valid feature names, but HistGradientBoostingClassifier was fitted with feature names\n"
                    ]
                },
                "mc_idx": 98,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 67,
                "o_idx": 0
            }
        },
        {
            "source": "Lime offers us the ability to explain feature importance on row level. Let's show this for the second row in the DataFrame:",
            "mc_idx": 99,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "exp.show_in_notebook(show_table=True)",
            "mc_idx": 100,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    68,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.HTML object>"
                    ]
                },
                "mc_idx": 100,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 68,
                "o_idx": 0
            }
        },
        {
            "source": "We use the sub-modular attributes available on SP-LIME to obtain a global perspective of the data instances. Then, we visualize the data to visual global representative samples extracted by the SP-LIME algorithm. This takes much longer than the local explanations.",
            "mc_idx": 101,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "%%capture\nsp_exp = submodular_pick.SubmodularPick(explainer, \n                                        x_test.values,\n                                        predict_fn=hist_est.predict,\n                                        num_features=10,\n                                        num_exps_desired=5)\n",
            "mc_idx": 102,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    69,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 102,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 69,
                "o_idx": 0
            }
        },
        {
            "source": "[exp.show_in_notebook() for exp in sp_exp.sp_explanations]\nprint('SP-LIME Explanations.')",
            "mc_idx": 103,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "lime": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    70,
                    5,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.HTML object>",
                        "<IPython.core.display.HTML object>",
                        "<IPython.core.display.HTML object>",
                        "<IPython.core.display.HTML object>",
                        "<IPython.core.display.HTML object>",
                        "SP-LIME Explanations.\n"
                    ]
                },
                "mc_idx": 103,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 70,
                "o_idx": 5
            }
        },
        {
            "source": "It this not so easy to keep an overview here. Let's keep Sex_male and Name_Title_Master only.",
            "mc_idx": 104,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(\n    model=hist_est, \n    X=X.loc[:, [\"Sex_male\", \"Name_Title_Master.\"]], \n    y=y, \n    model_name=\"HistGradientBoosting\", \n    experiment_name=\"lime_visual_inspection_based_on_hist\"\n)\n\ntracker.add_experiment(\n    model=lin_est, \n    X=X.loc[:, [\"Sex_male\", \"Name_Title_Master.\"]],\n    y=y, \n    model_name=\"LogisticRegression\", \n    experiment_name=\"lime_visual_inspection_based_on_hist\"\n)",
            "mc_idx": 105,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.875,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "lime": 2,
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    71,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.7934844014813884 with an std of 0.01899410639729653 in 0.1680436134338379 secs\nModel LogisticRegression achieved a score of 0.7878664239532986 with an std of 0.015801680287401174 in 0.03221297264099121 secs\n"
                    ]
                },
                "mc_idx": 105,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 71,
                "o_idx": 0
            }
        },
        {
            "source": "We do one for linear regression as well.",
            "mc_idx": 106,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "lin_est.fit(x_train, y_train)\nexplainer = lime_tabular.LimeTabularExplainer(\n    training_data=x_train.values,\n    feature_names=x_train.columns,\n    mode='regression'\n)",
            "mc_idx": 107,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "training_data": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "lime": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    72,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 107,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 72,
                "o_idx": 0
            }
        },
        {
            "source": "%%capture\nsp_exp = submodular_pick.SubmodularPick(explainer, \n                                        x_test.values,\n                                        predict_fn=lin_est.predict,\n                                        num_features=10,\n                                        num_exps_desired=5)",
            "mc_idx": 108,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    73,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 108,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 73,
                "o_idx": 0
            }
        },
        {
            "source": "[exp.show_in_notebook() for exp in sp_exp.sp_explanations]\nprint('SP-LIME Explanations.')",
            "mc_idx": 109,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "lime": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    74,
                    5,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.HTML object>",
                        "<IPython.core.display.HTML object>",
                        "<IPython.core.display.HTML object>",
                        "<IPython.core.display.HTML object>",
                        "<IPython.core.display.HTML object>",
                        "SP-LIME Explanations.\n"
                    ]
                },
                "mc_idx": 109,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 74,
                "o_idx": 5
            }
        },
        {
            "source": "For this example we keep Sex_male and Ticket_Type_3",
            "mc_idx": 110,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(\n    model=hist_est, \n    X=X.loc[:, [\"Sex_male\", \"Ticket_Type_3\"]],\n    y=y, \n    model_name=\"HistGradientBoosting\", \n    experiment_name=\"lime_visual_inspection_based_on_logistic_regression\"\n)\n\ntracker.add_experiment(\n    model=lin_est, \n    X=X.loc[:, [\"Sex_male\", \"Ticket_Type_3\"]], \n    y=y, \n    model_name=\"LogisticRegression\", \n    experiment_name=\"lime_visual_inspection_based_on_logistic_regression\"\n)",
            "mc_idx": 111,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.875,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "lime": 2,
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    75,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.7867365513778168 with an std of 0.018667207932566335 in 0.20354676246643066 secs\nModel LogisticRegression achieved a score of 0.7867365513778168 with an std of 0.018667207932566335 in 0.03999137878417969 secs\n"
                    ]
                },
                "mc_idx": 111,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 75,
                "o_idx": 0
            }
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">Shap</h3>\n\n\"SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions[...]\" ([source](https://shap.readthedocs.io/en/latest/))\n\nThe original paper can be found [here](https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf).",
            "mc_idx": 112,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "hist_est.fit(x_train, y_train)",
            "mc_idx": 113,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    76,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "HistGradientBoostingClassifier(random_state=100)"
                    ]
                },
                "mc_idx": 113,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 76,
                "o_idx": 0
            }
        },
        {
            "source": "HistGradientBoosting is not yet supported by Shaps TreeExplainer (which is much faster for tree-based models). Alos be aware, that a model trained on GPU will utilize GPU acceleration also within Shap!",
            "mc_idx": 114,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "explainer = shap.Explainer(hist_est.predict, x_test)\nshap_values = explainer(x_test)",
            "mc_idx": 115,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".exp": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap_values": 1,
                    "shap": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    77,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "PermutationExplainer explainer: 180it [00:33,  4.53it/s]\n"
                    ]
                },
                "mc_idx": 115,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 77,
                "o_idx": 0
            }
        },
        {
            "source": "Let's show the feature importances...",
            "mc_idx": 116,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "shap.summary_plot(shap_values, max_display=25, show=True)",
            "mc_idx": 117,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".sum": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap_values": 1,
                    "shap": 2,
                    "summary": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0031_c078_o000_image_0.png",
                    78,
                    0,
                    0
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 800x1150 with 2 Axes>"
                    ]
                },
                "mc_idx": 117,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 78,
                "o_idx": 0
            }
        },
        {
            "source": "We can also show this as a barplot.",
            "mc_idx": 118,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "shap.summary_plot(shap_values, max_display=35, show=False, plot_type='bar')",
            "mc_idx": 119,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".sum": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap_values": 1,
                    "shap": 2,
                    "summary": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0031_c079_o000_image_1.png",
                    79,
                    0,
                    1
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 800x1550 with 1 Axes>"
                    ]
                },
                "mc_idx": 119,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 79,
                "o_idx": 0
            }
        },
        {
            "source": "In both plots the values are sorted top down by importance.\nThe shap library has also beautiful visuals to explore feature importance for individual rows and also dependency plots to better undersatnd feature interactions. I will skip this here as the Kernel is pretty long already.\n\nLet's drop [\"Name_Title_Gordon,\", \"Name_Title_Impe,\", \"Name_Itle_Jonkheer.\", \"Name_Title_Mlle.\", \"Ticket_Type_W\", \"Name_Title_Melkebelke\"] etc here.",
            "mc_idx": 120,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()",
            "mc_idx": 121,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "logisticregression": 1,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    80,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 121,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 80,
                "o_idx": 0
            }
        },
        {
            "source": "drop_cols = [\n    \"Name_Title_Gordon,\", \n    \"Name_Title_Impe,\", \n    \"Name_Title_Jonkheer.\", \n    \"Name_Title_Mlle.\", \n    \"Ticket_Type_W\", \n    \"Name_Title_Melkebeke,\",\n    \"Name_Title_Messemaeker,\",\n    \"Name_Title_Col.\",\n    \"Age_Null\"\n]",
            "mc_idx": 122,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    81,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 122,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 81,
                "o_idx": 0
            }
        },
        {
            "source": "tracker.add_experiment(\n    model=hist_est, \n    X=X.drop(drop_cols, axis=1),\n    y=y, \n    model_name=\"HistGradientBoosting\", \n    experiment_name=\"shap_visual_inspection_based_on_hist\"\n)\n\ntracker.add_experiment(\n    model=lin_est, \n    X=X.drop(drop_cols, axis=1), \n    y=y, \n    model_name=\"LogisticRegression\", \n    experiment_name=\"shap_visual_inspection_based_on_hist\"\n)",
            "mc_idx": 123,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5714285714285714,
                "Model_Train": 0.7142857142857143,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 2,
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "shap": 2,
                    "model": 4,
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    82,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8226727763480008 with an std of 0.01649095088807791 in 1.366065502166748 secs\nModel LogisticRegression achieved a score of 0.8114556525014125 with an std of 0.02495837966860871 in 0.07034039497375488 secs\n"
                    ]
                },
                "mc_idx": 123,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 82,
                "o_idx": 0
            }
        },
        {
            "source": "We do the same for linear regression as Shap (like Lime) is not model-agnostic.",
            "mc_idx": 124,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "lin_est.fit(x_train, y_train)",
            "mc_idx": 125,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    83,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "LogisticRegression()"
                    ]
                },
                "mc_idx": 125,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 83,
                "o_idx": 0
            }
        },
        {
            "source": "explainer = shap.Explainer(lin_est.predict, x_test)\nshap_values = explainer(x_test)",
            "mc_idx": 126,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".exp": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap_values": 1,
                    "shap": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    84,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "PermutationExplainer explainer: 180it [00:13,  3.33it/s]\n"
                    ]
                },
                "mc_idx": 126,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 84,
                "o_idx": 0
            }
        },
        {
            "source": "shap.summary_plot(shap_values, max_display=35, show=True)",
            "mc_idx": 127,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".sum": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap_values": 1,
                    "shap": 2,
                    "summary": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0031_c085_o000_image_2.png",
                    85,
                    0,
                    2
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 800x1550 with 2 Axes>"
                    ]
                },
                "mc_idx": 127,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 85,
                "o_idx": 0
            }
        },
        {
            "source": "Here we drop just Name_Title_Dr. and Ticket_Type_F and S.",
            "mc_idx": 128,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()",
            "mc_idx": 129,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "logisticregression": 1,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    86,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 129,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 86,
                "o_idx": 0
            }
        },
        {
            "source": "tracker.add_experiment(\n    model=hist_est, \n    X=X.drop([\"Name_Title_Dr.\", \"Ticket_Type_F\", \"Ticket_Type_S\", \"Name_Title_Rev.\"], axis=1),\n    y=y, \n    model_name=\"HistGradientBoosting\", \n    experiment_name=\"shap_visual_inspection_based_on_logistic_regression\"\n)\n\ntracker.add_experiment(\n    model=lin_est, \n    X=X.drop([\"Name_Title_Dr.\", \"Ticket_Type_F\", \"Ticket_Type_S\", \"Name_Title_Rev.\"], axis=1), \n    y=y, \n    model_name=\"LogisticRegression\", \n    experiment_name=\"shap_visual_inspection_based_on_logistic_regression\"\n)",
            "mc_idx": 130,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5714285714285714,
                "Model_Train": 0.7142857142857143,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 2,
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "shap": 2,
                    "model": 4,
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    87,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8260435628648546 with an std of 0.012728910275995875 in 1.402008295059204 secs\nModel LogisticRegression achieved a score of 0.8249074132195091 with an std of 0.026969183581597663 in 0.07071948051452637 secs\n"
                    ]
                },
                "mc_idx": 130,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 87,
                "o_idx": 0
            }
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">Boruta</h3>\n\nIn Boruta, features do not compete among themselves. They are compared with a randomized version of them instead.\n\"In practice, starting from X, another dataframe is created by randomly shuffling each feature. These permuted features are called shadow features. At this point, the shadow dataframe is attached to the original dataframe to obtain a new dataframe (we will call it X_boruta), which has twice the number of columns of X.\"\n\nFor more details check out [this](https://towardsdatascience.com/boruta-explained-the-way-i-wish-someone-explained-it-to-me-4489d70e154a) Medium article.\n\nOver the past decade the boruta algorithm has seen multiple implementations and variants. The original algorithm is quite slow. Instead we use a less-known, but powerful variant: boostaroota\n\nPlease be aware, that boostaroota was a research project and is not maintained. It seems like compatibility breaks with Panndas 2.0 or higher. However the code is open source and could be adapted.\n\nIn general I struggled to find any Boruta implementation that can be installed in this Kernel and just runs without an error. Therefore I decided to tak the boostaroota source code and add it below, but debug the breaking parts.\n\nBoostaroota runs now and expects an estimator with a feature_imprtance_ attribute. This does not apply to HistGradientBoosting and linear regression, so we fallback to Xgboost once again.",
            "mc_idx": 131,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "import numpy as np\nimport pandas as pd\nimport xgboost as xgb\nimport operator\nimport warnings\n\n\n########################################################################################\n#\n# Main Class and Methods\n#\n########################################################################################\n\n\nclass BoostARoota(object):\n\n    def __init__(self, metric=None, clf=None, cutoff=4, iters=10, max_rounds=100, delta=0.1, silent=False):\n        self.metric = metric\n        self.clf = clf\n        self.cutoff = cutoff\n        self.iters = iters\n        self.max_rounds = max_rounds\n        self.delta = delta\n        self.silent = silent\n        self.keep_vars_ = None\n\n        #Throw errors if the inputted parameters don't meet the necessary criteria\n        if (metric is None) and (clf is None):\n            raise ValueError('you must enter one of metric or clf as arguments')\n        if cutoff <= 0:\n            raise ValueError('cutoff should be greater than 0. You entered' + str(cutoff))\n        if iters <= 0:\n            raise ValueError('iters should be greater than 0. You entered' + str(iters))\n        if (delta <= 0) | (delta > 1):\n            raise ValueError('delta should be between 0 and 1, was ' + str(delta))\n\n        #Issue warnings for parameters to still let it run\n        if (metric is not None) and (clf is not None):\n            warnings.warn('You entered values for metric and clf, defaulting to clf and ignoring metric')\n        if delta < 0.02:\n            warnings.warn(\"WARNING: Setting a delta below 0.02 may not converge on a solution.\")\n        if max_rounds < 1:\n            warnings.warn(\"WARNING: Setting max_rounds below 1 will automatically be set to 1.\")\n\n    def fit(self, x, y):\n        self.keep_vars_ = _BoostARoota(x, y,\n                                       metric=self.metric,\n                                       clf = self.clf,\n                                       cutoff=self.cutoff,\n                                       iters=self.iters,\n                                       max_rounds=self.max_rounds,\n                                       delta=self.delta,\n                                       silent=self.silent)\n        return self\n\n    def transform(self, x):\n        if self.keep_vars_ is None:\n            raise ValueError(\"You need to fit the model first\")\n        return x[self.keep_vars_]\n\n    def fit_transform(self, x, y):\n        self.fit(x, y)\n        return self.transform(x)\n\n########################################################################################\n#\n# Helper Functions to do the Heavy Lifting\n#\n########################################################################################\n\n\ndef _create_shadow(x_train):\n    \"\"\"\n    Take all X variables, creating copies and randomly shuffling them\n    :param x_train: the dataframe to create shadow features on\n    :return: dataframe 2x width and the names of the shadows for removing later\n    \"\"\"\n    x_shadow = x_train.copy()\n    for c in x_shadow.columns:\n        np.random.shuffle(x_shadow[c].values)\n    # rename the shadow\n    shadow_names = [\"ShadowVar\" + str(i + 1) for i in range(x_train.shape[1])]\n    x_shadow.columns = shadow_names\n    # Combine to make one new dataframe\n    new_x = pd.concat([x_train, x_shadow], axis=1)\n    return new_x, shadow_names\n\n########################################################################################\n#\n# BoostARoota\n#\n########################################################################################\n\n\ndef _reduce_vars_xgb(x, y, metric, this_round, cutoff, n_iterations, delta, silent):\n    \"\"\"\n    Function to run through each\n    :param x: Input dataframe - X\n    :param y: Target variable\n    :param metric: Metric to optimize in XGBoost\n    :param this_round: Round so it can be printed to screen\n    :return: tuple - stopping criteria and the variables to keep\n    \"\"\"\n    #Set up the parameters for running the model in XGBoost - split is on multi log loss\n    if metric == 'mlogloss':\n        param = {'objective': 'multi:softmax',\n                 'eval_metric': 'mlogloss',\n                 'num_class': len(np.unique(y)),\n                 'silent': 1}\n    else:\n        param = {'eval_metric': metric,\n                 'silent': 1}\n    for i in range(1, n_iterations+1):\n        # Create the shadow variables and run the model to obtain importances\n        new_x, shadow_names = _create_shadow(x)\n        dtrain = xgb.DMatrix(new_x, label=y)\n        bst = xgb.train(param, dtrain, verbose_eval=False)\n        if i == 1:\n            df = pd.DataFrame({'feature': new_x.columns})\n            pass\n\n        importance = bst.get_fscore()\n        importance = sorted(importance.items(), key=operator.itemgetter(1))\n        df2 = pd.DataFrame(importance, columns=['feature', 'fscore'+str(i)])\n        df2['fscore'+str(i)] = df2['fscore'+str(i)] / df2['fscore'+str(i)].sum()\n        df = pd.merge(df, df2, on='feature', how='outer')\n        if not silent:\n            print(\"Round: \", this_round, \" iteration: \", i)\n\n    df['Mean'] = df.mean(axis=1)\n    #Split them back out\n    real_vars = df[~df['feature'].isin(shadow_names)]\n    shadow_vars = df[df['feature'].isin(shadow_names)]\n\n    # Get mean value from the shadows\n    mean_shadow = shadow_vars['Mean'].mean() / cutoff\n    real_vars = real_vars[(real_vars.Mean > mean_shadow)]\n\n    #Check for the stopping criteria\n    #Basically looking to make sure we are removing at least 10% of the variables, or we should stop\n    if (len(real_vars['feature']) / len(x.columns)) > (1-delta):\n        criteria = True\n    else:\n        criteria = False\n\n    return criteria, real_vars['feature']\n\n\ndef _reduce_vars_sklearn(x, y, clf, this_round, cutoff, n_iterations, delta, silent):\n    \"\"\"\n    Function to run through each\n    :param x: Input dataframe - X\n    :param y: Target variable\n    :param clf: the fully specified classifier passed in by user\n    :param this_round: Round so it can be printed to screen\n    :return: tuple - stopping criteria and the variables to keep\n    \"\"\"\n    #Set up the parameters for running the model in XGBoost - split is on multi log loss\n\n    for i in range(1, n_iterations+1):\n        # Create the shadow variables and run the model to obtain importances\n        new_x, shadow_names = _create_shadow(x)\n        clf = clf.fit(new_x, np.ravel(y))\n\n        if i == 1:\n            df = pd.DataFrame({'feature': new_x.columns})\n            df2 = df.copy()\n            pass\n\n        try:\n            importance = clf.feature_importances_\n            df2['fscore' + str(i)] = importance\n        except ValueError:\n            print(\"this clf doesn't have the feature_importances_ method.  Only Sklearn tree based methods allowed\")\n\n        # importance = sorted(importance.items(), key=operator.itemgetter(1))\n\n        # df2 = pd.DataFrame(importance, columns=['feature', 'fscore'+str(i)])\n        df2['fscore'+str(i)] = df2['fscore'+str(i)] / df2['fscore'+str(i)].sum()\n        df = pd.merge(df, df2, on='feature', how='outer', suffixes=('', '_y'))\n        df.drop(df.filter(regex='_y$').columns, axis=1, inplace=True)\n        if not silent:\n            print(\"Round: \", this_round, \" iteration: \", i)\n\n    df['Mean'] = df.drop(\"feature\", axis=1).mean(axis=1)\n    #Split them back out\n    real_vars = df[~df['feature'].isin(shadow_names)]\n    shadow_vars = df[df['feature'].isin(shadow_names)]\n\n    # Get mean value from the shadows\n    mean_shadow = shadow_vars['Mean'].mean() / cutoff\n    real_vars = real_vars[(real_vars.Mean > mean_shadow)]\n\n    #Check for the stopping criteria\n    #Basically looking to make sure we are removing at least 10% of the variables, or we should stop\n    if (len(real_vars['feature']) / len(x.columns)) > (1-delta):\n        criteria = True\n    else:\n        criteria = False\n\n    return criteria, real_vars['feature']\n\n#Main function exposed to run the algorithm\ndef _BoostARoota(x, y, metric, clf, cutoff, iters, max_rounds, delta, silent):\n    \"\"\"\n    Function loops through, waiting for the stopping criteria to change\n    :param x: X dataframe One Hot Encoded\n    :param y: Labels for the target variable\n    :param metric: The metric to optimize in XGBoost\n    :return: names of the variables to keep\n    \"\"\"\n\n    new_x = x.copy()\n    #Run through loop until \"crit\" changes\n    i = 0\n    while True:\n        #Inside this loop we reduce the dataset on each iteration exiting with keep_vars\n        i += 1\n        if clf is None:\n            crit, keep_vars = _reduce_vars_xgb(new_x,\n                                               y,\n                                               metric=metric,\n                                               this_round=i,\n                                               cutoff=cutoff,\n                                               n_iterations=iters,\n                                               delta=delta,\n                                               silent=silent)\n        else:\n            crit, keep_vars = _reduce_vars_sklearn(new_x,\n                                                   y,\n                                                   clf=clf,\n                                                   this_round=i,\n                                                   cutoff=cutoff,\n                                                   n_iterations=iters,\n                                                   delta=delta,\n                                                   silent=silent)\n\n        if crit | (i >= max_rounds):\n            break  # exit and use keep_vars as final variables\n        else:\n            new_x = new_x[keep_vars].copy()\n    if not silent:\n        print(\"BoostARoota ran successfully! Algorithm went through \", i, \" rounds.\")\n    return keep_vars",
            "mc_idx": 132,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.016129032258064516,
                "Exploratory_Data_Analysis": 0.4032258064516129,
                "Data_Transform": 0.24193548387096775,
                "Model_Train": 0.12903225806451613,
                "Model_Evaluation": 0.08064516129032258,
                "Model_Interpretation": 0.16129032258064516,
                "Hyperparameter_Tuning": 0.4032258064516129,
                "Visualization": 0.0,
                "Debug": 0.016129032258064516,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 5
                },
                "Data_Extraction": {
                    "dataset": 1
                },
                "Exploratory_Data_Analysis": {
                    ".mean(": 4,
                    "np.unique": 1,
                    "columns": 9,
                    "shape": 1,
                    ".sum": 2,
                    ".mean": 6,
                    ".max": 2
                },
                "Data_Transform": {
                    ".merge(": 2,
                    ".concat(": 1,
                    "fit_transform": 1,
                    "transform": 3,
                    "ravel": 1,
                    ".drop": 2,
                    ".merge": 2,
                    ".concat": 1,
                    ".cut": 2
                },
                "Model_Train": {
                    ".fit(": 2,
                    "model": 5,
                    ".train(": 1
                },
                "Model_Evaluation": {
                    "model": 5
                },
                "Model_Interpretation": {
                    "feature_importances_": 4,
                    "shap": 1,
                    "model": 5
                },
                "Hyperparameter_Tuning": {
                    "n_iter": 6,
                    "param": 19
                },
                "Visualization": {},
                "Debug": {
                    "try:": 1
                },
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    88,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 132,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 88,
                "o_idx": 0
            }
        },
        {
            "source": "model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"total_cover\")\n\nbr = BoostARoota(clf=model)\n\n#Fit the model for the subset of variables\nbr.fit(X, y)\n\n#Can look at the important variables - will return a pandas series\nbr.keep_vars_",
            "mc_idx": 133,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.75,
                "Model_Interpretation": 0.75,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 2
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "cov": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "model": 3
                },
                "Model_Evaluation": {
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    89,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Round:  1  iteration:  1\nRound:  1  iteration:  2\nRound:  1  iteration:  3\nRound:  1  iteration:  4\nRound:  1  iteration:  5\nRound:  1  iteration:  6\nRound:  1  iteration:  7\nRound:  1  iteration:  8\nRound:  1  iteration:  9\nRound:  1  iteration:  10\nRound:  2  iteration:  1\nRound:  2  iteration:  2\nRound:  2  iteration:  3\nRound:  2  iteration:  4\nRound:  2  iteration:  5\nRound:  2  iteration:  6\nRound:  2  iteration:  7\nRound:  2  iteration:  8\nRound:  2  iteration:  9\nRound:  2  iteration:  10\nRound:  3  iteration:  1\nRound:  3  iteration:  2\nRound:  3  iteration:  3\nRound:  3  iteration:  4\nRound:  3  iteration:  5\nRound:  3  iteration:  6\nRound:  3  iteration:  7\nRound:  3  iteration:  8\nRound:  3  iteration:  9\nRound:  3  iteration:  10\nBoostARoota ran successfully! Algorithm went through  3  rounds.\n",
                        "0                    Age\n1                  SibSp\n2                  Parch\n3                   Fare\n4               Name_Len\n5               Sex_male\n6             Embarked_S\n7     Name_Title_Master.\n8         Name_Title_Mr.\n10        Cabin_Letter_D\n11        Cabin_Letter_E\n12        Cabin_Letter_n\n13         Ticket_Type_3\n14         Ticket_Type_S\n15              Pclass_2\n16              Pclass_3\nName: feature, dtype: object"
                    ]
                },
                "mc_idx": 133,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 89,
                "o_idx": 1
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, br.keep_vars_], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"boostaroota_on_histg\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, br.keep_vars_], y=y, model_name=\"LogisticRegression\", experiment_name=\"boostaroota_on_histg\")",
            "mc_idx": 134,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    90,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8282907538760906 with an std of 0.008227991222518525 in 0.9468529224395752 secs\nModel LogisticRegression achieved a score of 0.8204444165463561 with an std of 0.010315500638846266 in 0.059476613998413086 secs\n"
                    ]
                },
                "mc_idx": 134,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 90,
                "o_idx": 0
            }
        },
        {
            "source": "<h1 style=\"background-color: #000080; color: #ffff00;\">Comparing the results</h1>",
            "mc_idx": 135,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "def highlight_max(s):\n    is_max = s == s.max()\n    return ['background-color: yellow' if v else '' for v in is_max]",
            "mc_idx": 136,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".max": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    91,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 136,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 91,
                "o_idx": 0
            }
        },
        {
            "source": "results = tracker.retrive_results()\n\nresults = results.style.apply(highlight_max, subset=['losses_mean'])\nresults",
            "mc_idx": 137,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".apply(": 1,
                    ".apply": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    92,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<pandas.io.formats.style.Styler at 0x7ae841e762c0>"
                    ]
                },
                "mc_idx": 137,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 92,
                "o_idx": 0
            }
        },
        {
            "source": "So recursive feature elimination made the race here with logistic regression on top.",
            "mc_idx": 138,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h1 style=\"background-color: #000080; color: #ffff00;\">How to (not) interpret feature importance</h1>\n\nAs shown above feature importance has many implementations and variants: From statistical approaches to dedicated feature selection algorithms, from a focus on local importance to an explanation of global importance.\nThey all have one thing in common though: They cannot be used to explain any causal relationships in the data (with a theoretical exception maybe). These algorithms just try to explain how a model behaves, but they do not explain how the data behaves.",
            "mc_idx": 139,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h1 style=\"background-color: #000080; color: #ffff00;\">Submission time</h1>\n\nFinally we will take the best feature space and make a submission before we finish.",
            "mc_idx": 140,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "lin_est = LogisticRegression()\nlin_selector = RFECV(lin_est, step=1, cv=5)\nlin_selector = lin_selector.fit(X, y)\nlin_selector.support_\nkeep_cols = X.loc[:, lin_selector.support_].columns.to_list()\nlin_est = LogisticRegression().fit(X.loc[:, keep_cols], y)",
            "mc_idx": 141,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 2,
                    "logisticregression": 2
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    93,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 141,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 93,
                "o_idx": 0
            }
        },
        {
            "source": "preds = lin_est.predict(test.loc[:, keep_cols])",
            "mc_idx": 142,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    94,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 142,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 94,
                "o_idx": 0
            }
        },
        {
            "source": "sample_submission[target] = preds\nsample_submission[target] = sample_submission[target].astype(int)\nsample_submission.to_csv('submission.csv', index = False)",
            "mc_idx": 143,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    95,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 143,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 95,
                "o_idx": 0
            }
        },
        {
            "source": "sample_submission",
            "mc_idx": 144,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    96,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "     PassengerId  Survived\n0            892         0\n1            893         0\n2            894         0\n3            895         0\n4            896         1\n..           ...       ...\n413         1305         0\n414         1306         1\n415         1307         0\n416         1308         0\n417         1309         1\n\n[418 rows x 2 columns]"
                    ]
                },
                "mc_idx": 144,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 96,
                "o_idx": 0
            }
        },
        {
            "source": "Feel free to also checkout the [cross validation mastery](https://www.kaggle.com/code/thomasmeiner/become-a-cross-validation-master) notebook.",
            "mc_idx": 145,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<div style=\"padding: 20px; background-color: #000080; border-radius: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\">\n    <div style=\"border: 2px solid #000080; padding: 20px; text-align: center; border-radius: 10px; background-color: #ffffff;\">\n        <h1 style=\"color: #00000; font-size: 32px; text-transform: uppercase; letter-spacing: 2px; margin-bottom: 20px;\">Consider an upvote</h1>\n        <div><em>\n       This notebook took a while to be created. Upvotes help keeping the motivation up :-)\n    </em></div>\n</div>",
            "mc_idx": 146,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        }
    ],
    "code_cells": [
        {
            "source": "%%capture\n!pip install lime",
            "mc_idx": 4,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "!pip install": 1,
                    "install": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "lime": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    0,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 4,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 0,
                "o_idx": 0
            }
        },
        {
            "source": "import numpy as np\nimport pandas as pd\nimport time\n\nimport lime\nfrom lime import lime_tabular\nfrom lime import submodular_pick\n\nimport optuna\nimport shap\n\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import mutual_info_classif, RFE, RFECV, SequentialFeatureSelector\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.metrics import make_scorer, accuracy_score\n\nimport xgboost as xgb",
            "mc_idx": 5,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.014285714285714285,
                "Data_Transform": 0.007142857142857143,
                "Model_Train": 0.05,
                "Model_Evaluation": 0.03571428571428571,
                "Model_Interpretation": 0.05714285714285714,
                "Hyperparameter_Tuning": 0.02857142857142857,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 14
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "info": 1,
                    ".mode": 1
                },
                "Data_Transform": {
                    ".mod": 1
                },
                "Model_Train": {
                    "train_test_split": 1,
                    "model": 2,
                    "model_selection": 1,
                    "logisticregression": 1,
                    "gradientboostingclassifier": 1,
                    ".linear": 1
                },
                "Model_Evaluation": {
                    "accuracy_score": 2,
                    "cross_val_score": 1,
                    "model": 2
                },
                "Model_Interpretation": {
                    "lime": 4,
                    "shap": 1,
                    "model": 2,
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {
                    "optuna": 1,
                    "cross_val_score": 1,
                    "kfold": 1,
                    "train_test_split": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    1,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 5,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 1,
                "o_idx": 0
            }
        },
        {
            "source": "train = pd.read_csv(r'/kaggle/input/titanic/train.csv')\ntest = pd.read_csv(r'/kaggle/input/titanic/test.csv')\nsample_submission = pd.read_csv(r'/kaggle/input/titanic/gender_submission.csv')",
            "mc_idx": 7,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 6,
                    "pd.read_": 6
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    2,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 7,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 2,
                "o_idx": 0
            }
        },
        {
            "source": "target = \"Survived\"",
            "mc_idx": 8,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    3,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 8,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 3,
                "o_idx": 0
            }
        },
        {
            "source": "# borrowed from here: https://www.kaggle.com/code/tisa33/titanic-sk-87-2-rf-84-4-tf-87-1-rf-84-9/notebook\ndef normailize_data(df):\n    df['Cabin_Letter'] = df['Cabin'].apply(lambda x: str(x)[0])\n    df['Name_Title'] = df['Name'].apply(lambda x: x.split()[1]).apply(lambda x: x.split()[0])\n    df['Name_Len'] = df['Name'].apply(lambda x: len(x))\n    df['Age_Null'] = df['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n    #df['Age'] = df.groupby(['Name_Title', 'Pclass', 'Sex'])['Age'].transform(lambda x: x.fillna(x.mean()))\n    df['Age'] = df['Age'].fillna(0)\n    df['Ticket_Type'] = df['Ticket'].apply(lambda x: x[0])\n    df['Age'] = (df['Age'] - df['Age'].min()) / (df['Age'].max() - df['Age'].min())\n    df['Fare'] = (df['Fare'] - df['Fare'].min()) / (df['Fare'].max() - df['Fare'].min())\n    df['Name_Len'] = (df['Name_Len'] - df['Name_Len'].min()) / (df['Name_Len'].max() - df['Name_Len'].min())\n    df['SibSp'] = (df['SibSp'] - df['SibSp'].min()) / (df['SibSp'].max() - df['SibSp'].min())\n    df['Parch'] = (df['Parch'] - df['Parch'].min()) / (df['Parch'].max() - df['Parch'].min())\n    df = pd.get_dummies(df, columns=['Sex', 'Embarked', 'Name_Title', 'Cabin_Letter', 'Ticket_Type', 'Pclass'], drop_first=True, dtype=int)\n    df = df.drop(['Name', 'Cabin', 'PassengerId', 'Ticket'], axis=1)\n    return df\n\nfull_data = pd.concat([train, test])\nfull_data = normailize_data(full_data)\ntrain = full_data.loc[full_data[target].isna() == False].copy().fillna(0)\ntest = full_data.loc[full_data[target].isna() == True].copy().fillna(0)",
            "mc_idx": 9,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.7857142857142857,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    "columns": 1,
                    ".isna": 2,
                    ".isnull": 1,
                    ".mean": 1,
                    ".min": 10,
                    ".max": 5,
                    ".groupby": 1
                },
                "Data_Transform": {
                    ".concat(": 1,
                    ".groupby(": 1,
                    ".fillna(": 4,
                    ".apply(": 6,
                    "transform": 1,
                    ".split": 2,
                    ".drop": 1,
                    ".fillna": 4,
                    ".apply": 6,
                    ".concat": 1,
                    ".get_dummies": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    4,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 9,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 4,
                "o_idx": 0
            }
        },
        {
            "source": "X = train.copy()\ny = X.pop(target)",
            "mc_idx": 10,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    5,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 10,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 5,
                "o_idx": 0
            }
        },
        {
            "source": "class ResultTracker:\n    def __init__(self):\n        self.losses_mean = []\n        self.losses_std = []\n        self.runtime_secs = []\n        self.model_name = []\n        self.experiment_name  = []\n        \n    def eval_model(self, model, X, y):\n        mae_scorer = make_scorer(accuracy_score, greater_is_better=True)\n        start = time.time()\n        losses = cross_val_score(model, X, y, cv=5, n_jobs=-1, scoring=mae_scorer)\n        end = time.time()\n        runtime_secs = end - start\n        return np.mean(losses), np.std(losses),  runtime_secs\n    \n    def add_experiment(self, *, model, X, y, model_name, experiment_name):\n        exp_mean, exp_std, runtime_secs = self.eval_model(model, X, y)\n        print(f\"Model {model_name} achieved a score of {exp_mean} with an std of {exp_std} in {runtime_secs} secs\")\n        \n        self.losses_mean.append(exp_mean)\n        self.losses_std.append(exp_std)\n        self.runtime_secs.append(runtime_secs)\n        self.model_name.append(model_name)\n        self.experiment_name.append(experiment_name)\n        \n    def retrive_results(self):\n        results_df = pd.DataFrame(\n            {\n                \"losses_mean\": self.losses_mean,\n                \"losses_std\": self.losses_std,\n                \"runtime_secs\": self.runtime_secs,\n                \"model_name\": self.model_name,\n                \"experiment_name\": self.experiment_name\n            }\n        )\n        return results_df",
            "mc_idx": 12,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5294117647058824,
                "Data_Transform": 0.35294117647058826,
                "Model_Train": 0.8235294117647058,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.8235294117647058,
                "Hyperparameter_Tuning": 0.058823529411764705,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".std(": 1,
                    "np.mean": 1,
                    "np.std": 1,
                    ".mean": 1,
                    ".std": 1,
                    ".mode": 3
                },
                "Data_Transform": {
                    ".exp": 3,
                    ".mod": 3
                },
                "Model_Train": {
                    "model": 14
                },
                "Model_Evaluation": {
                    "accuracy_score": 2,
                    "cross_val_score": 1,
                    "model": 14
                },
                "Model_Interpretation": {
                    "model": 14
                },
                "Hyperparameter_Tuning": {
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    6,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 12,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 6,
                "o_idx": 0
            }
        },
        {
            "source": "tracker = ResultTracker()",
            "mc_idx": 13,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    7,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 13,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 7,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X, y=y, model_name=\"HistGradientBoosting\", experiment_name=\"using_all_features\")\ntracker.add_experiment(model=lin_est, X=X, y=y, model_name=\"LogisticRegression\", experiment_name=\"using_all_features\")",
            "mc_idx": 16,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    8,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8226727763480008 with an std of 0.01649095088807791 in 3.680934429168701 secs\nModel LogisticRegression achieved a score of 0.8204255853367648 with an std of 0.02864899384162871 in 0.0760965347290039 secs\n"
                    ]
                },
                "mc_idx": 16,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 8,
                "o_idx": 0
            }
        },
        {
            "source": "def calculate_correlations(df: pd.DataFrame, target: pd.Series) -> pd.DataFrame:\n    \"\"\"\n    Calculates the correlations of all columns with regards to the target and returns a DataFrame with all column names\n    and their correlation coefficient with regards to the target.\n    \n    :param df: Pandas DataFrame\n    :param target: Pandas Series with target values\n    :return: Pandas DataFrame with column names and their correlation coefficient with regards to the target\n    \"\"\"\n    correlations = df.corrwith(target)\n    return pd.DataFrame(correlations, columns=['correlation_coefficient'])",
            "mc_idx": 19,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.5,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".corr": 2,
                    "columns": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    9,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 19,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 9,
                "o_idx": 0
            }
        },
        {
            "source": "correlations = calculate_correlations(X, y)\ncorrelations",
            "mc_idx": 20,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    10,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "               correlation_coefficient\nAge                           0.010539\nSibSp                        -0.035322\nParch                         0.081629\nFare                          0.257307\nName_Len                      0.332350\n...                                ...\nTicket_Type_P                 0.151310\nTicket_Type_S                -0.035049\nTicket_Type_W                -0.057546\nPclass_2                      0.093349\nPclass_3                     -0.322308\n\n[67 rows x 1 columns]"
                    ]
                },
                "mc_idx": 20,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 10,
                "o_idx": 0
            }
        },
        {
            "source": "keep_columns = correlations.loc[\n    (\n        (correlations[\"correlation_coefficient\"] >= 0.1) |\n        (correlations[\"correlation_coefficient\"] <= -0.1)\n    )\n].index.to_list()\n\nkeep_columns",
            "mc_idx": 22,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    11,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Fare',\n 'Name_Len',\n 'Sex_male',\n 'Embarked_S',\n 'Name_Title_Miss.',\n 'Name_Title_Mr.',\n 'Name_Title_Mrs.',\n 'Cabin_Letter_B',\n 'Cabin_Letter_C',\n 'Cabin_Letter_D',\n 'Cabin_Letter_E',\n 'Cabin_Letter_n',\n 'Ticket_Type_3',\n 'Ticket_Type_A',\n 'Ticket_Type_P',\n 'Pclass_3']"
                    ]
                },
                "mc_idx": 22,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 11,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_columns], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"removed_no_corr_to_target\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_columns], y=y, model_name=\"LogisticRegression\", experiment_name=\"removed_no_corr_to_target\")",
            "mc_idx": 23,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2857142857142857,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 2
                },
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    12,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8036344234511329 with an std of 0.027379687968800925 in 0.904163122177124 secs\nModel LogisticRegression achieved a score of 0.786761659657272 with an std of 0.014123873083912195 in 0.0602869987487793 secs\n"
                    ]
                },
                "mc_idx": 23,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 12,
                "o_idx": 0
            }
        },
        {
            "source": "def calculate_mi_scores(df, target):\n    \"\"\"\n    Calculates the mutual information score of all columns with regards to the (regression) target.\n    \n    Parameters:\n    df (Pandas DataFrame): The DataFrame containing the features.\n    target (Pandas Series): The target variable.\n    \n    Returns:\n    Pandas DataFrame: A DataFrame with all column names and their MI scores with regards to the target.\n    \"\"\"\n    mi_scores = mutual_info_classif(df, target)\n    mi_scores = pd.Series(mi_scores, name='MI Scores', index=df.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores.to_frame()",
            "mc_idx": 25,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.25,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.25,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "info": 2,
                    "columns": 2
                },
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    13,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 25,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 13,
                "o_idx": 0
            }
        },
        {
            "source": "mi_scores = calculate_mi_scores(X, y)\nmi_scores",
            "mc_idx": 26,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    14,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "                   MI Scores\nSex_male            0.163445\nFare                0.135732\nName_Title_Mr.      0.122084\nName_Len            0.103633\nCabin_Letter_n      0.054900\n...                      ...\nName_Title_Velde,   0.000000\nName_Title_Steen,   0.000000\nName_Title_Carlo,   0.000000\nName_Title_Ms.      0.000000\nName_Title_y        0.000000\n\n[67 rows x 1 columns]"
                    ]
                },
                "mc_idx": 26,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 14,
                "o_idx": 0
            }
        },
        {
            "source": "keep_columns = mi_scores.loc[(mi_scores[\"MI Scores\"] >= 0.0)].index.to_list()\n\nkeep_columns",
            "mc_idx": 28,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    15,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Sex_male',\n 'Fare',\n 'Name_Title_Mr.',\n 'Name_Len',\n 'Cabin_Letter_n',\n 'Name_Title_Miss.',\n 'Name_Title_Mrs.',\n 'Ticket_Type_F',\n 'Pclass_3',\n 'Cabin_Letter_E',\n 'Ticket_Type_P',\n 'Name_Title_Jonkheer.',\n 'Ticket_Type_7',\n 'Cabin_Letter_T',\n 'Age',\n 'Embarked_S',\n 'Parch',\n 'Ticket_Type_S',\n 'Name_Title_Master.',\n 'Age_Null',\n 'Name_Title_Shawah,',\n 'Name_Title_Capt.',\n 'Cabin_Letter_C',\n 'Cabin_Letter_B',\n 'Name_Title_Khalil,',\n 'Cabin_Letter_F',\n 'Name_Title_Planke,',\n 'Name_Title_Mlle.',\n 'SibSp',\n 'Name_Title_Palmquist,',\n 'Name_Title_Dr.',\n 'Ticket_Type_6',\n 'Cabin_Letter_D',\n 'Name_Title_der',\n 'Name_Title_Brito,',\n 'Embarked_Q',\n 'Name_Title_Gordon,',\n 'Name_Title_Mme.',\n 'Name_Title_Col.',\n 'Ticket_Type_C',\n 'Name_Title_Rev.',\n 'Ticket_Type_9',\n 'Name_Title_Don.',\n 'Ticket_Type_L',\n 'Name_Title_Impe,',\n 'Name_Title_Major.',\n 'Ticket_Type_5',\n 'Ticket_Type_W',\n 'Ticket_Type_A',\n 'Ticket_Type_8',\n 'Pclass_2',\n 'Name_Title_Mulder,',\n 'Name_Title_Melkebeke,',\n 'Ticket_Type_4',\n 'Ticket_Type_3',\n 'Ticket_Type_2',\n 'Name_Title_Pelsmaeker,',\n 'Cabin_Letter_G',\n 'Name_Title_Messemaeker,',\n 'Name_Title_Cruyssen,',\n 'Name_Title_the',\n 'Name_Title_Walle,',\n 'Name_Title_Velde,',\n 'Name_Title_Steen,',\n 'Name_Title_Carlo,',\n 'Name_Title_Ms.',\n 'Name_Title_y']"
                    ]
                },
                "mc_idx": 28,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 15,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_columns], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"removed_low_mi_score_to_target\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_columns], y=y, model_name=\"LogisticRegression\", experiment_name=\"removed_low_mi_score_to_target\")",
            "mc_idx": 29,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2857142857142857,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 2
                },
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    16,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8226727763480006 with an std of 0.01097521926722228 in 1.4778385162353516 secs\nModel LogisticRegression achieved a score of 0.8204255853367648 with an std of 0.02864899384162871 in 0.06644296646118164 secs\n"
                    ]
                },
                "mc_idx": 29,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 16,
                "o_idx": 0
            }
        },
        {
            "source": "def remove_collinearity(dataset, threshold=0.9):\n    \"\"\"\n    Loops through all columns and checks, if features are highly positively correlated.\n    If correlation is above given threshold, then only one column is kept.\n    :param threshold: Maximum allowed correlation. Expects a float from -1 to +1.\n    :return: Returns modified dataframe.\n    \"\"\"\n    col_corr = set()  # Set of all the names of deleted columns\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if (corr_matrix.iloc[i, j] >= threshold) and (\n                corr_matrix.columns[j] not in col_corr\n            ):\n                colname = corr_matrix.columns[i]  # getting the name of column\n                col_corr.add(colname)\n                if colname in dataset.columns:\n                    del dataset[colname]  # deleting the column from the dataset\n    return dataset",
            "mc_idx": 31,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.75,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.125,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.125,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "dataset": 6
                },
                "Exploratory_Data_Analysis": {
                    ".corr": 2,
                    "columns": 6
                },
                "Data_Transform": {
                    ".add": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    17,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 31,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 17,
                "o_idx": 0
            }
        },
        {
            "source": "X_thres_09 = remove_collinearity(X.copy(), 0.9)\nX_thres_09.columns.to_list()\nprint(f\"Removed columns {set(X.columns.to_list()) - set(X_thres_09.columns.to_list())}\")",
            "mc_idx": 32,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 4
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    18,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Removed columns set()\n"
                    ]
                },
                "mc_idx": 32,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 18,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X_thres_09, y=y, model_name=\"HistGradientBoosting\", experiment_name=\"removed_collinearity_with_090plus\")\ntracker.add_experiment(model=lin_est, X=X_thres_09, y=y, model_name=\"LogisticRegression\", experiment_name=\"removed_collinearity_with_090plus\")",
            "mc_idx": 33,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    19,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8226727763480008 with an std of 0.01649095088807791 in 1.4731111526489258 secs\nModel LogisticRegression achieved a score of 0.8204255853367648 with an std of 0.02864899384162871 in 0.0719904899597168 secs\n"
                    ]
                },
                "mc_idx": 33,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 19,
                "o_idx": 0
            }
        },
        {
            "source": "X_thres_08 = remove_collinearity(X.copy(), 0.8)\nX_thres_08.columns.to_list()\nprint(f\"Removed columns {set(X.columns.to_list()) - set(X_thres_08.columns.to_list())}\")",
            "mc_idx": 34,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 4
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    20,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Removed columns {'Name_Title_Mr.'}\n"
                    ]
                },
                "mc_idx": 34,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 20,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X_thres_08, y=y, model_name=\"HistGradientBoosting\", experiment_name=\"removed_collinearity_with_080plus\")\ntracker.add_experiment(model=lin_est, X=X_thres_08, y=y, model_name=\"LogisticRegression\", experiment_name=\"removed_collinearity_with_080plus\")",
            "mc_idx": 35,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    21,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8193082669010107 with an std of 0.00957769381205687 in 1.443075180053711 secs\nModel LogisticRegression achieved a score of 0.826031008725127 with an std of 0.02779141048557072 in 0.09639143943786621 secs\n"
                    ]
                },
                "mc_idx": 35,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 21,
                "o_idx": 0
            }
        },
        {
            "source": "lin_est = LogisticRegression()\nlin_est.fit(X, y)",
            "mc_idx": 38,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "logisticregression": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    22,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "LogisticRegression()"
                    ]
                },
                "mc_idx": 38,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 22,
                "o_idx": 0
            }
        },
        {
            "source": "print(lin_est.coef_.shape, len(X.columns))\nlin_est.coef_",
            "mc_idx": 39,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.6666666666666666,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1,
                    "shape": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap": 1,
                    "coef_": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    23,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "(1, 67) 67\n",
                        "array([[-1.26836826, -2.22171938, -1.35275202,  0.71873876,  1.02384122,\n        -0.5645056 , -1.63522012,  0.25964309, -0.34326716,  0.        ,\n        -0.13424704, -0.30790936,  0.06837276, -0.08342326, -0.34254269,\n        -0.18053407,  0.40432002, -0.57851042, -0.33586632,  0.        ,\n        -0.04061364,  1.79074941, -0.09716645,  0.50435643,  0.49459713,\n         0.15062311,  0.06894093, -0.73569689,  0.76674893,  0.24003438,\n         0.78842234,  0.        , -0.12213086, -0.57618861, -0.88698026,\n        -0.23957743, -0.10730336, -0.10676901, -0.11119572, -0.4154385 ,\n         0.06064046,  0.15102603,  0.19663832, -0.27583558,  0.76952743,\n         0.86541321,  0.15572634, -0.61482308, -0.29819382, -0.62853534,\n        -0.1406039 , -0.91369688, -1.1085717 , -0.58027576, -0.06368129,\n        -0.96118875, -0.24038735,  0.1371446 , -0.83526741, -0.20698204,\n         0.09609536,  0.33000732, -0.21143127,  0.00891648, -1.32809348,\n        -0.32435197, -0.86525348]])"
                    ]
                },
                "mc_idx": 39,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 23,
                "o_idx": 1
            }
        },
        {
            "source": "((lin_est.coef_ < -0.05) | (lin_est.coef_ > 0.05))[0]",
            "mc_idx": 40,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "coef_": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    24,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n       False,  True,  True,  True,  True,  True,  True,  True,  True,\n        True, False, False,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True, False,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n       False,  True,  True,  True])"
                    ]
                },
                "mc_idx": 40,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 24,
                "o_idx": 0
            }
        },
        {
            "source": "keep_cols = X.loc[:, ((lin_est.coef_ < -0.05) | (lin_est.coef_ > 0.05))[0]].columns.to_list()\nkeep_cols",
            "mc_idx": 42,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "coef_": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    25,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Age',\n 'SibSp',\n 'Parch',\n 'Fare',\n 'Name_Len',\n 'Age_Null',\n 'Sex_male',\n 'Embarked_Q',\n 'Embarked_S',\n 'Name_Title_Capt.',\n 'Name_Title_Carlo,',\n 'Name_Title_Col.',\n 'Name_Title_Cruyssen,',\n 'Name_Title_Don.',\n 'Name_Title_Dr.',\n 'Name_Title_Gordon,',\n 'Name_Title_Impe,',\n 'Name_Title_Jonkheer.',\n 'Name_Title_Master.',\n 'Name_Title_Melkebeke,',\n 'Name_Title_Messemaeker,',\n 'Name_Title_Miss.',\n 'Name_Title_Mlle.',\n 'Name_Title_Mme.',\n 'Name_Title_Mr.',\n 'Name_Title_Mrs.',\n 'Name_Title_Ms.',\n 'Name_Title_Mulder,',\n 'Name_Title_Pelsmaeker,',\n 'Name_Title_Planke,',\n 'Name_Title_Rev.',\n 'Name_Title_Shawah,',\n 'Name_Title_Steen,',\n 'Name_Title_Velde,',\n 'Name_Title_Walle,',\n 'Name_Title_der',\n 'Name_Title_the',\n 'Name_Title_y',\n 'Cabin_Letter_B',\n 'Cabin_Letter_C',\n 'Cabin_Letter_D',\n 'Cabin_Letter_E',\n 'Cabin_Letter_F',\n 'Cabin_Letter_G',\n 'Cabin_Letter_T',\n 'Cabin_Letter_n',\n 'Ticket_Type_2',\n 'Ticket_Type_3',\n 'Ticket_Type_4',\n 'Ticket_Type_5',\n 'Ticket_Type_6',\n 'Ticket_Type_7',\n 'Ticket_Type_8',\n 'Ticket_Type_9',\n 'Ticket_Type_A',\n 'Ticket_Type_C',\n 'Ticket_Type_F',\n 'Ticket_Type_L',\n 'Ticket_Type_P',\n 'Ticket_Type_W',\n 'Pclass_2',\n 'Pclass_3']"
                    ]
                },
                "mc_idx": 42,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 25,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"removed_lower_half_of_lr_coefficients\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"removed_lower_half_of_lr_coefficients\")",
            "mc_idx": 43,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    26,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8260435628648546 with an std of 0.012728910275995875 in 1.4154045581817627 secs\nModel LogisticRegression achieved a score of 0.8215491808423827 with an std of 0.02894802237428172 in 0.0769658088684082 secs\n"
                    ]
                },
                "mc_idx": 43,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 26,
                "o_idx": 0
            }
        },
        {
            "source": "model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"gain\")\nmodel.fit(X, y)",
            "mc_idx": 47,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model.fit": 1,
                    ".fit(": 1,
                    "model": 2
                },
                "Model_Evaluation": {
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    27,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type='gain',\n              interaction_constraints=None, learning_rate=None, max_bin=255,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, random_state=100, ...)"
                    ]
                },
                "mc_idx": 47,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 27,
                "o_idx": 0
            }
        },
        {
            "source": "xgb_gain = model.feature_importances_\nxgb_gain",
            "mc_idx": 48,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "feature_importances_": 2,
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    28,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([0.0135434 , 0.02883319, 0.0093273 , 0.01767678, 0.0123399 ,\n       0.        , 0.26620883, 0.00521423, 0.01701247, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.01941586, 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.04230755, 0.        , 0.        , 0.02395579,\n       0.        , 0.        , 0.07754616, 0.01392192, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.12761562,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.00287151, 0.01627882, 0.00705073,\n       0.01460894, 0.        , 0.        , 0.        , 0.06574743,\n       0.00766516, 0.01376058, 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.00484979, 0.01086271,\n       0.        , 0.        , 0.01218499, 0.01182252, 0.0217451 ,\n       0.02385882, 0.11177391], dtype=float32)"
                    ]
                },
                "mc_idx": 48,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 28,
                "o_idx": 0
            }
        },
        {
            "source": "keep_cols = X.loc[:, xgb_gain > 0.05].columns.to_list()\nkeep_cols",
            "mc_idx": 49,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    29,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Sex_male', 'Name_Title_Mr.', 'Name_Title_Rev.', 'Cabin_Letter_n', 'Pclass_3']"
                    ]
                },
                "mc_idx": 49,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 29,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"xgboost_importance_gain\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"xgboost_importance_gain\")",
            "mc_idx": 50,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    30,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.7800326407632918 with an std of 0.008709637448781676 in 0.3093535900115967 secs\nModel LogisticRegression achieved a score of 0.7900947837549432 with an std of 0.015659861494704365 in 0.0467069149017334 secs\n"
                    ]
                },
                "mc_idx": 50,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 30,
                "o_idx": 0
            }
        },
        {
            "source": "model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"weight\")\nmodel.fit(X, y)",
            "mc_idx": 52,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model.fit": 1,
                    ".fit(": 1,
                    "model": 2
                },
                "Model_Evaluation": {
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    31,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type='weight',\n              interaction_constraints=None, learning_rate=None, max_bin=255,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, random_state=100, ...)"
                    ]
                },
                "mc_idx": 52,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 31,
                "o_idx": 0
            }
        },
        {
            "source": "xgb_weight = model.feature_importances_\nxgb_weight",
            "mc_idx": 53,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "feature_importances_": 2,
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    32,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([0.25703463, 0.03192641, 0.02164502, 0.26623377, 0.21861471,\n       0.        , 0.02272727, 0.00324675, 0.0232684 , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.00054113, 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.01677489, 0.        , 0.        , 0.00108225,\n       0.        , 0.        , 0.01244589, 0.00595238, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.00054113,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.0021645 , 0.01190476, 0.00757576,\n       0.00541126, 0.        , 0.        , 0.        , 0.01136364,\n       0.00974026, 0.02272727, 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.00487013, 0.00162338,\n       0.        , 0.        , 0.00324675, 0.01298701, 0.00162338,\n       0.00595238, 0.01677489], dtype=float32)"
                    ]
                },
                "mc_idx": 53,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 32,
                "o_idx": 0
            }
        },
        {
            "source": "keep_cols = X.loc[:, xgb_weight > 0.05].columns.to_list()\nkeep_cols",
            "mc_idx": 54,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    33,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Age', 'Fare', 'Name_Len']"
                    ]
                },
                "mc_idx": 54,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 33,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"xgboost_importance_weight\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"xgboost_importance_weight\")",
            "mc_idx": 55,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    34,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.7149959199045886 with an std of 0.03786511167697809 in 0.7832012176513672 secs\nModel LogisticRegression achieved a score of 0.685757328479066 with an std of 0.016814167133173404 in 0.0418243408203125 secs\n"
                    ]
                },
                "mc_idx": 55,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 34,
                "o_idx": 0
            }
        },
        {
            "source": "model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"cover\")\nmodel.fit(X, y)",
            "mc_idx": 57,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "cov": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model.fit": 1,
                    ".fit(": 1,
                    "model": 2
                },
                "Model_Evaluation": {
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    35,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type='cover',\n              interaction_constraints=None, learning_rate=None, max_bin=255,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, random_state=100, ...)"
                    ]
                },
                "mc_idx": 57,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 35,
                "o_idx": 0
            }
        },
        {
            "source": "xgb_cover = model.feature_importances_\nxgb_cover",
            "mc_idx": 58,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.6666666666666666,
                "Data_Transform": 0.0,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "cov": 2
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "feature_importances_": 2,
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    36,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([0.01676155, 0.01472439, 0.01844941, 0.02428181, 0.02002116,\n       0.        , 0.0733851 , 0.00499388, 0.03057476, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.04707531, 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.0646151 , 0.        , 0.        , 0.00690226,\n       0.        , 0.        , 0.02320972, 0.03372166, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.05071908,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.04474477, 0.01116774, 0.06085984,\n       0.07158813, 0.        , 0.        , 0.        , 0.03167669,\n       0.01213521, 0.02077974, 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.05531023, 0.02401487,\n       0.        , 0.        , 0.03828023, 0.03123656, 0.10688441,\n       0.02607676, 0.03580966], dtype=float32)"
                    ]
                },
                "mc_idx": 58,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 36,
                "o_idx": 0
            }
        },
        {
            "source": "keep_cols = X.loc[:, xgb_cover > 0.05].columns.to_list()\nkeep_cols",
            "mc_idx": 59,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "cov": 1,
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    37,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Sex_male',\n 'Name_Title_Master.',\n 'Name_Title_Rev.',\n 'Cabin_Letter_D',\n 'Cabin_Letter_E',\n 'Ticket_Type_A',\n 'Ticket_Type_W']"
                    ]
                },
                "mc_idx": 59,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 37,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"xgboost_importance_cover\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"xgboost_importance_cover\")",
            "mc_idx": 60,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2857142857142857,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "cov": 2
                },
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    38,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.794620551126734 with an std of 0.018228868104151152 in 0.2340531349182129 secs\nModel LogisticRegression achieved a score of 0.7901136149645345 with an std of 0.019100377882376823 in 0.0467984676361084 secs\n"
                    ]
                },
                "mc_idx": 60,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 38,
                "o_idx": 0
            }
        },
        {
            "source": "model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"total_gain\")\nmodel.fit(X, y)",
            "mc_idx": 62,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model.fit": 1,
                    ".fit(": 1,
                    "model": 2
                },
                "Model_Evaluation": {
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    39,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type='total_gain',\n              interaction_constraints=None, learning_rate=None, max_bin=255,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, random_state=100, ...)"
                    ]
                },
                "mc_idx": 62,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 39,
                "o_idx": 0
            }
        },
        {
            "source": "xgb_total_gain = model.feature_importances_\nxgb_total_gain",
            "mc_idx": 63,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "feature_importances_": 2,
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    40,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([0.14452143, 0.03821693, 0.0083816 , 0.19537959, 0.11199635,\n       0.        , 0.25117862, 0.00070283, 0.01643413, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.00043618, 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.02946392, 0.        , 0.        , 0.00107635,\n       0.        , 0.        , 0.04006813, 0.00344035, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.00286691,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.00025804, 0.00804557, 0.00221755,\n       0.00328193, 0.        , 0.        , 0.        , 0.03101766,\n       0.00309959, 0.01298366, 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.00098057, 0.0007321 ,\n       0.        , 0.        , 0.00164243, 0.00637429, 0.00146553,\n       0.00589593, 0.07784184], dtype=float32)"
                    ]
                },
                "mc_idx": 63,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 40,
                "o_idx": 0
            }
        },
        {
            "source": "keep_cols = X.loc[:, xgb_total_gain > 0.05].columns.to_list()\nkeep_cols",
            "mc_idx": 64,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    41,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Age', 'Fare', 'Name_Len', 'Sex_male', 'Pclass_3']"
                    ]
                },
                "mc_idx": 64,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 41,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"xgboost_importance_total_gain\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"xgboost_importance_total_gain\")",
            "mc_idx": 65,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    42,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8081099742640137 with an std of 0.013470583152657546 in 0.8187851905822754 secs\nModel LogisticRegression achieved a score of 0.7901136149645346 with an std of 0.01842756354064995 in 0.046328067779541016 secs\n"
                    ]
                },
                "mc_idx": 65,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 42,
                "o_idx": 0
            }
        },
        {
            "source": "model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"total_cover\")\nmodel.fit(X, y)",
            "mc_idx": 67,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "cov": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model.fit": 1,
                    ".fit(": 1,
                    "model": 2
                },
                "Model_Evaluation": {
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    43,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type='total_cover',\n              interaction_constraints=None, learning_rate=None, max_bin=255,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, random_state=100, ...)"
                    ]
                },
                "mc_idx": 67,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 43,
                "o_idx": 0
            }
        },
        {
            "source": "xgb_total_cover = model.feature_importances_\nxgb_total_cover",
            "mc_idx": 68,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.6666666666666666,
                "Data_Transform": 0.0,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "cov": 2
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "feature_importances_": 2,
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    44,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([0.18067877, 0.01971463, 0.01674718, 0.2711099 , 0.18355656,\n       0.        , 0.06994496, 0.00067997, 0.02983532, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.0010683 , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.04545639, 0.        , 0.        , 0.00031327,\n       0.        , 0.        , 0.01211426, 0.00841784, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.00115099,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.00406164, 0.00557554, 0.01933562,\n       0.01624577, 0.        , 0.        , 0.        , 0.01509587,\n       0.004957  , 0.01980563, 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.01129659, 0.00163494,\n       0.        , 0.        , 0.00521225, 0.01701272, 0.00727671,\n       0.00650947, 0.02519191], dtype=float32)"
                    ]
                },
                "mc_idx": 68,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 44,
                "o_idx": 0
            }
        },
        {
            "source": "keep_cols = X.loc[:, xgb_total_cover > 0.05].columns.to_list()\nkeep_cols",
            "mc_idx": 69,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "cov": 1,
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    45,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Age', 'Fare', 'Name_Len', 'Sex_male']"
                    ]
                },
                "mc_idx": 69,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 45,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"xgboost_importance_total_cover\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"xgboost_importance_total_cover\")",
            "mc_idx": 70,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2857142857142857,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "cov": 2
                },
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    46,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.7867553825874082 with an std of 0.023304255696803628 in 0.802293062210083 secs\nModel LogisticRegression achieved a score of 0.7878664239532986 with an std of 0.015801680287401174 in 0.04020857810974121 secs\n"
                    ]
                },
                "mc_idx": 70,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 46,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\nhist_selector, lin_selector = RFE(hist_est, n_features_to_select=10, step=1), RFE(lin_est, n_features_to_select=10, step=1)",
            "mc_idx": 73,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "logisticregression": 1,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    47,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 73,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 47,
                "o_idx": 0
            }
        },
        {
            "source": "#hist_selector = hist_selector.fit(X, y)\n#hist_selector.support_",
            "mc_idx": 74,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    48,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 74,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 48,
                "o_idx": 0
            }
        },
        {
            "source": "lin_selector = lin_selector.fit(X, y)\nlin_selector.support_",
            "mc_idx": 76,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    49,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([False,  True,  True, False, False, False,  True, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False,  True, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False,  True, False,  True,  True, False,\n       False,  True, False, False,  True, False, False, False, False,\n       False,  True, False, False])"
                    ]
                },
                "mc_idx": 76,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 49,
                "o_idx": 0
            }
        },
        {
            "source": "keep_cols = X.loc[:, lin_selector.support_].columns.to_list()\nkeep_cols",
            "mc_idx": 77,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    50,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['SibSp',\n 'Parch',\n 'Sex_male',\n 'Name_Title_Master.',\n 'Cabin_Letter_n',\n 'Ticket_Type_3',\n 'Ticket_Type_4',\n 'Ticket_Type_7',\n 'Ticket_Type_A',\n 'Ticket_Type_W']"
                    ]
                },
                "mc_idx": 77,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 50,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"rfe_based_on_logistic_regression\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"rfe_based_on_logistic_regression\")",
            "mc_idx": 78,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    51,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8226853304877283 with an std of 0.012389425379234905 in 0.5716044902801514 secs\nModel LogisticRegression achieved a score of 0.8125478626577113 with an std of 0.03317577568032311 in 0.05377817153930664 secs\n"
                    ]
                },
                "mc_idx": 78,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 51,
                "o_idx": 0
            }
        },
        {
            "source": "lin_est = LogisticRegression()\nlin_selector = RFECV(lin_est, step=1, cv=5)",
            "mc_idx": 80,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "logisticregression": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    52,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 80,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 52,
                "o_idx": 0
            }
        },
        {
            "source": "lin_selector = lin_selector.fit(X, y)\nlin_selector.support_",
            "mc_idx": 81,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    53,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n       False,  True,  True, False, False,  True,  True,  True,  True,\n        True, False, False,  True, False,  True,  True,  True, False,\n        True,  True,  True,  True, False, False,  True,  True,  True,\n       False, False, False,  True, False,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n       False,  True,  True,  True,  True,  True, False,  True,  True,\n       False,  True,  True,  True])"
                    ]
                },
                "mc_idx": 81,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 53,
                "o_idx": 0
            }
        },
        {
            "source": "keep_cols = X.loc[:, lin_selector.support_].columns.to_list()\nkeep_cols",
            "mc_idx": 82,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    54,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Age',\n 'SibSp',\n 'Parch',\n 'Fare',\n 'Name_Len',\n 'Age_Null',\n 'Sex_male',\n 'Embarked_Q',\n 'Embarked_S',\n 'Name_Title_Capt.',\n 'Name_Title_Carlo,',\n 'Name_Title_Don.',\n 'Name_Title_Dr.',\n 'Name_Title_Gordon,',\n 'Name_Title_Impe,',\n 'Name_Title_Jonkheer.',\n 'Name_Title_Master.',\n 'Name_Title_Messemaeker,',\n 'Name_Title_Miss.',\n 'Name_Title_Mlle.',\n 'Name_Title_Mr.',\n 'Name_Title_Mrs.',\n 'Name_Title_Ms.',\n 'Name_Title_Mulder,',\n 'Name_Title_Planke,',\n 'Name_Title_Rev.',\n 'Name_Title_Shawah,',\n 'Name_Title_der',\n 'Name_Title_y',\n 'Cabin_Letter_B',\n 'Cabin_Letter_C',\n 'Cabin_Letter_D',\n 'Cabin_Letter_E',\n 'Cabin_Letter_F',\n 'Cabin_Letter_G',\n 'Cabin_Letter_T',\n 'Cabin_Letter_n',\n 'Ticket_Type_2',\n 'Ticket_Type_3',\n 'Ticket_Type_4',\n 'Ticket_Type_5',\n 'Ticket_Type_7',\n 'Ticket_Type_8',\n 'Ticket_Type_9',\n 'Ticket_Type_A',\n 'Ticket_Type_C',\n 'Ticket_Type_L',\n 'Ticket_Type_P',\n 'Ticket_Type_W',\n 'Pclass_2',\n 'Pclass_3']"
                    ]
                },
                "mc_idx": 82,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 54,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"rfecv_based_on_logistic_regression\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"rfecv_based_on_logistic_regression\")",
            "mc_idx": 83,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    55,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8260435628648546 with an std of 0.012728910275995875 in 1.2924294471740723 secs\nModel LogisticRegression achieved a score of 0.8226727763480006 with an std of 0.030676683281000327 in 0.06981945037841797 secs\n"
                    ]
                },
                "mc_idx": 83,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 55,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\nhist_sfs, lin_sfs = SequentialFeatureSelector(hist_est, n_features_to_select=10), SequentialFeatureSelector(lin_est, n_features_to_select=10)",
            "mc_idx": 85,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "logisticregression": 1,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    56,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 85,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 56,
                "o_idx": 0
            }
        },
        {
            "source": "#hist_sfs.fit(X, y)\n#hist_sfs.get_support()",
            "mc_idx": 87,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    57,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 87,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 57,
                "o_idx": 0
            }
        },
        {
            "source": "#keep_cols = X.loc[:, hist_sfs.get_support()].columns.to_list()\n#keep_cols",
            "mc_idx": 88,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    58,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 88,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 58,
                "o_idx": 0
            }
        },
        {
            "source": "#hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\n#tracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"seq_feat_sel_on_histgb\")\n#tracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"seq_feat_sel_on_histgb\")",
            "mc_idx": 89,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    59,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 89,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 59,
                "o_idx": 0
            }
        },
        {
            "source": "lin_sfs.fit(X, y)\nlin_sfs.get_support()",
            "mc_idx": 90,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    60,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([False,  True, False,  True, False, False,  True, False, False,\n       False, False, False, False, False, False, False, False,  True,\n       False, False, False,  True, False, False,  True, False, False,\n        True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False,  True, False,\n       False, False, False, False,  True, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False])"
                    ]
                },
                "mc_idx": 90,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 60,
                "o_idx": 0
            }
        },
        {
            "source": "keep_cols = X.loc[:, lin_sfs.get_support()].columns.to_list()\nkeep_cols",
            "mc_idx": 91,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    61,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['SibSp',\n 'Fare',\n 'Sex_male',\n 'Name_Title_Impe,',\n 'Name_Title_Master.',\n 'Name_Title_Miss.',\n 'Name_Title_Mr.',\n 'Cabin_Letter_C',\n 'Cabin_Letter_n',\n 'Ticket_Type_W']"
                    ]
                },
                "mc_idx": 91,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 61,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, keep_cols], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"seq_feat_sel_on_logistic_regression\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, keep_cols], y=y, model_name=\"LogisticRegression\", experiment_name=\"seq_feat_sel_on_logistic_regression\")",
            "mc_idx": 92,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    62,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8249074132195091 with an std of 0.02601611401897143 in 0.8028106689453125 secs\nModel LogisticRegression achieved a score of 0.8305065595380077 with an std of 0.03054274488797953 in 0.04700136184692383 secs\n"
                    ]
                },
                "mc_idx": 92,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 62,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()",
            "mc_idx": 94,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "logisticregression": 1,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    63,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 94,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 63,
                "o_idx": 0
            }
        },
        {
            "source": "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=100)",
            "mc_idx": 95,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "train_test_split": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "train_test_split": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    64,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 95,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 64,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est.fit(x_train, y_train)",
            "mc_idx": 96,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    65,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "HistGradientBoostingClassifier(random_state=100)"
                    ]
                },
                "mc_idx": 96,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 65,
                "o_idx": 0
            }
        },
        {
            "source": "explainer = lime_tabular.LimeTabularExplainer(\n    training_data=x_train.values,\n    feature_names=x_train.columns,\n    mode='regression'\n)",
            "mc_idx": 97,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 0.0,
                "Model_Train": 0.5,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "training_data": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "lime": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    66,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 97,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 66,
                "o_idx": 0
            }
        },
        {
            "source": "exp = explainer.explain_instance(\n    data_row=x_test.iloc[1], \n    predict_fn=hist_est.predict\n)",
            "mc_idx": 98,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".exp": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    67,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "X does not have valid feature names, but HistGradientBoostingClassifier was fitted with feature names\n"
                    ]
                },
                "mc_idx": 98,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 67,
                "o_idx": 0
            }
        },
        {
            "source": "exp.show_in_notebook(show_table=True)",
            "mc_idx": 100,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    68,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.HTML object>"
                    ]
                },
                "mc_idx": 100,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 68,
                "o_idx": 0
            }
        },
        {
            "source": "%%capture\nsp_exp = submodular_pick.SubmodularPick(explainer, \n                                        x_test.values,\n                                        predict_fn=hist_est.predict,\n                                        num_features=10,\n                                        num_exps_desired=5)\n",
            "mc_idx": 102,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    69,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 102,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 69,
                "o_idx": 0
            }
        },
        {
            "source": "[exp.show_in_notebook() for exp in sp_exp.sp_explanations]\nprint('SP-LIME Explanations.')",
            "mc_idx": 103,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "lime": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    70,
                    5,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.HTML object>",
                        "<IPython.core.display.HTML object>",
                        "<IPython.core.display.HTML object>",
                        "<IPython.core.display.HTML object>",
                        "<IPython.core.display.HTML object>",
                        "SP-LIME Explanations.\n"
                    ]
                },
                "mc_idx": 103,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 70,
                "o_idx": 5
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(\n    model=hist_est, \n    X=X.loc[:, [\"Sex_male\", \"Name_Title_Master.\"]], \n    y=y, \n    model_name=\"HistGradientBoosting\", \n    experiment_name=\"lime_visual_inspection_based_on_hist\"\n)\n\ntracker.add_experiment(\n    model=lin_est, \n    X=X.loc[:, [\"Sex_male\", \"Name_Title_Master.\"]],\n    y=y, \n    model_name=\"LogisticRegression\", \n    experiment_name=\"lime_visual_inspection_based_on_hist\"\n)",
            "mc_idx": 105,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.875,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "lime": 2,
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    71,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.7934844014813884 with an std of 0.01899410639729653 in 0.1680436134338379 secs\nModel LogisticRegression achieved a score of 0.7878664239532986 with an std of 0.015801680287401174 in 0.03221297264099121 secs\n"
                    ]
                },
                "mc_idx": 105,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 71,
                "o_idx": 0
            }
        },
        {
            "source": "lin_est.fit(x_train, y_train)\nexplainer = lime_tabular.LimeTabularExplainer(\n    training_data=x_train.values,\n    feature_names=x_train.columns,\n    mode='regression'\n)",
            "mc_idx": 107,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "training_data": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "lime": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    72,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 107,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 72,
                "o_idx": 0
            }
        },
        {
            "source": "%%capture\nsp_exp = submodular_pick.SubmodularPick(explainer, \n                                        x_test.values,\n                                        predict_fn=lin_est.predict,\n                                        num_features=10,\n                                        num_exps_desired=5)",
            "mc_idx": 108,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    73,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 108,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 73,
                "o_idx": 0
            }
        },
        {
            "source": "[exp.show_in_notebook() for exp in sp_exp.sp_explanations]\nprint('SP-LIME Explanations.')",
            "mc_idx": 109,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "lime": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    74,
                    5,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.HTML object>",
                        "<IPython.core.display.HTML object>",
                        "<IPython.core.display.HTML object>",
                        "<IPython.core.display.HTML object>",
                        "<IPython.core.display.HTML object>",
                        "SP-LIME Explanations.\n"
                    ]
                },
                "mc_idx": 109,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 74,
                "o_idx": 5
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(\n    model=hist_est, \n    X=X.loc[:, [\"Sex_male\", \"Ticket_Type_3\"]],\n    y=y, \n    model_name=\"HistGradientBoosting\", \n    experiment_name=\"lime_visual_inspection_based_on_logistic_regression\"\n)\n\ntracker.add_experiment(\n    model=lin_est, \n    X=X.loc[:, [\"Sex_male\", \"Ticket_Type_3\"]], \n    y=y, \n    model_name=\"LogisticRegression\", \n    experiment_name=\"lime_visual_inspection_based_on_logistic_regression\"\n)",
            "mc_idx": 111,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.875,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "lime": 2,
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    75,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.7867365513778168 with an std of 0.018667207932566335 in 0.20354676246643066 secs\nModel LogisticRegression achieved a score of 0.7867365513778168 with an std of 0.018667207932566335 in 0.03999137878417969 secs\n"
                    ]
                },
                "mc_idx": 111,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 75,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est.fit(x_train, y_train)",
            "mc_idx": 113,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    76,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "HistGradientBoostingClassifier(random_state=100)"
                    ]
                },
                "mc_idx": 113,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 76,
                "o_idx": 0
            }
        },
        {
            "source": "explainer = shap.Explainer(hist_est.predict, x_test)\nshap_values = explainer(x_test)",
            "mc_idx": 115,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".exp": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap_values": 1,
                    "shap": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    77,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "PermutationExplainer explainer: 180it [00:33,  4.53it/s]\n"
                    ]
                },
                "mc_idx": 115,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 77,
                "o_idx": 0
            }
        },
        {
            "source": "shap.summary_plot(shap_values, max_display=25, show=True)",
            "mc_idx": 117,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".sum": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap_values": 1,
                    "shap": 2,
                    "summary": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0031_c078_o000_image_0.png",
                    78,
                    0,
                    0
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 800x1150 with 2 Axes>"
                    ]
                },
                "mc_idx": 117,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 78,
                "o_idx": 0
            }
        },
        {
            "source": "shap.summary_plot(shap_values, max_display=35, show=False, plot_type='bar')",
            "mc_idx": 119,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".sum": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap_values": 1,
                    "shap": 2,
                    "summary": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0031_c079_o000_image_1.png",
                    79,
                    0,
                    1
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 800x1550 with 1 Axes>"
                    ]
                },
                "mc_idx": 119,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 79,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()",
            "mc_idx": 121,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "logisticregression": 1,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    80,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 121,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 80,
                "o_idx": 0
            }
        },
        {
            "source": "drop_cols = [\n    \"Name_Title_Gordon,\", \n    \"Name_Title_Impe,\", \n    \"Name_Title_Jonkheer.\", \n    \"Name_Title_Mlle.\", \n    \"Ticket_Type_W\", \n    \"Name_Title_Melkebeke,\",\n    \"Name_Title_Messemaeker,\",\n    \"Name_Title_Col.\",\n    \"Age_Null\"\n]",
            "mc_idx": 122,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    81,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 122,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 81,
                "o_idx": 0
            }
        },
        {
            "source": "tracker.add_experiment(\n    model=hist_est, \n    X=X.drop(drop_cols, axis=1),\n    y=y, \n    model_name=\"HistGradientBoosting\", \n    experiment_name=\"shap_visual_inspection_based_on_hist\"\n)\n\ntracker.add_experiment(\n    model=lin_est, \n    X=X.drop(drop_cols, axis=1), \n    y=y, \n    model_name=\"LogisticRegression\", \n    experiment_name=\"shap_visual_inspection_based_on_hist\"\n)",
            "mc_idx": 123,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5714285714285714,
                "Model_Train": 0.7142857142857143,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 2,
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "shap": 2,
                    "model": 4,
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    82,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8226727763480008 with an std of 0.01649095088807791 in 1.366065502166748 secs\nModel LogisticRegression achieved a score of 0.8114556525014125 with an std of 0.02495837966860871 in 0.07034039497375488 secs\n"
                    ]
                },
                "mc_idx": 123,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 82,
                "o_idx": 0
            }
        },
        {
            "source": "lin_est.fit(x_train, y_train)",
            "mc_idx": 125,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    83,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "LogisticRegression()"
                    ]
                },
                "mc_idx": 125,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 83,
                "o_idx": 0
            }
        },
        {
            "source": "explainer = shap.Explainer(lin_est.predict, x_test)\nshap_values = explainer(x_test)",
            "mc_idx": 126,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".exp": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap_values": 1,
                    "shap": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    84,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "PermutationExplainer explainer: 180it [00:13,  3.33it/s]\n"
                    ]
                },
                "mc_idx": 126,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 84,
                "o_idx": 0
            }
        },
        {
            "source": "shap.summary_plot(shap_values, max_display=35, show=True)",
            "mc_idx": 127,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".sum": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap_values": 1,
                    "shap": 2,
                    "summary": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0031_c085_o000_image_2.png",
                    85,
                    0,
                    2
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 800x1550 with 2 Axes>"
                    ]
                },
                "mc_idx": 127,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 85,
                "o_idx": 0
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()",
            "mc_idx": 129,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "logisticregression": 1,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    86,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 129,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 86,
                "o_idx": 0
            }
        },
        {
            "source": "tracker.add_experiment(\n    model=hist_est, \n    X=X.drop([\"Name_Title_Dr.\", \"Ticket_Type_F\", \"Ticket_Type_S\", \"Name_Title_Rev.\"], axis=1),\n    y=y, \n    model_name=\"HistGradientBoosting\", \n    experiment_name=\"shap_visual_inspection_based_on_logistic_regression\"\n)\n\ntracker.add_experiment(\n    model=lin_est, \n    X=X.drop([\"Name_Title_Dr.\", \"Ticket_Type_F\", \"Ticket_Type_S\", \"Name_Title_Rev.\"], axis=1), \n    y=y, \n    model_name=\"LogisticRegression\", \n    experiment_name=\"shap_visual_inspection_based_on_logistic_regression\"\n)",
            "mc_idx": 130,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5714285714285714,
                "Model_Train": 0.7142857142857143,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 2,
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "shap": 2,
                    "model": 4,
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    87,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8260435628648546 with an std of 0.012728910275995875 in 1.402008295059204 secs\nModel LogisticRegression achieved a score of 0.8249074132195091 with an std of 0.026969183581597663 in 0.07071948051452637 secs\n"
                    ]
                },
                "mc_idx": 130,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 87,
                "o_idx": 0
            }
        },
        {
            "source": "import numpy as np\nimport pandas as pd\nimport xgboost as xgb\nimport operator\nimport warnings\n\n\n########################################################################################\n#\n# Main Class and Methods\n#\n########################################################################################\n\n\nclass BoostARoota(object):\n\n    def __init__(self, metric=None, clf=None, cutoff=4, iters=10, max_rounds=100, delta=0.1, silent=False):\n        self.metric = metric\n        self.clf = clf\n        self.cutoff = cutoff\n        self.iters = iters\n        self.max_rounds = max_rounds\n        self.delta = delta\n        self.silent = silent\n        self.keep_vars_ = None\n\n        #Throw errors if the inputted parameters don't meet the necessary criteria\n        if (metric is None) and (clf is None):\n            raise ValueError('you must enter one of metric or clf as arguments')\n        if cutoff <= 0:\n            raise ValueError('cutoff should be greater than 0. You entered' + str(cutoff))\n        if iters <= 0:\n            raise ValueError('iters should be greater than 0. You entered' + str(iters))\n        if (delta <= 0) | (delta > 1):\n            raise ValueError('delta should be between 0 and 1, was ' + str(delta))\n\n        #Issue warnings for parameters to still let it run\n        if (metric is not None) and (clf is not None):\n            warnings.warn('You entered values for metric and clf, defaulting to clf and ignoring metric')\n        if delta < 0.02:\n            warnings.warn(\"WARNING: Setting a delta below 0.02 may not converge on a solution.\")\n        if max_rounds < 1:\n            warnings.warn(\"WARNING: Setting max_rounds below 1 will automatically be set to 1.\")\n\n    def fit(self, x, y):\n        self.keep_vars_ = _BoostARoota(x, y,\n                                       metric=self.metric,\n                                       clf = self.clf,\n                                       cutoff=self.cutoff,\n                                       iters=self.iters,\n                                       max_rounds=self.max_rounds,\n                                       delta=self.delta,\n                                       silent=self.silent)\n        return self\n\n    def transform(self, x):\n        if self.keep_vars_ is None:\n            raise ValueError(\"You need to fit the model first\")\n        return x[self.keep_vars_]\n\n    def fit_transform(self, x, y):\n        self.fit(x, y)\n        return self.transform(x)\n\n########################################################################################\n#\n# Helper Functions to do the Heavy Lifting\n#\n########################################################################################\n\n\ndef _create_shadow(x_train):\n    \"\"\"\n    Take all X variables, creating copies and randomly shuffling them\n    :param x_train: the dataframe to create shadow features on\n    :return: dataframe 2x width and the names of the shadows for removing later\n    \"\"\"\n    x_shadow = x_train.copy()\n    for c in x_shadow.columns:\n        np.random.shuffle(x_shadow[c].values)\n    # rename the shadow\n    shadow_names = [\"ShadowVar\" + str(i + 1) for i in range(x_train.shape[1])]\n    x_shadow.columns = shadow_names\n    # Combine to make one new dataframe\n    new_x = pd.concat([x_train, x_shadow], axis=1)\n    return new_x, shadow_names\n\n########################################################################################\n#\n# BoostARoota\n#\n########################################################################################\n\n\ndef _reduce_vars_xgb(x, y, metric, this_round, cutoff, n_iterations, delta, silent):\n    \"\"\"\n    Function to run through each\n    :param x: Input dataframe - X\n    :param y: Target variable\n    :param metric: Metric to optimize in XGBoost\n    :param this_round: Round so it can be printed to screen\n    :return: tuple - stopping criteria and the variables to keep\n    \"\"\"\n    #Set up the parameters for running the model in XGBoost - split is on multi log loss\n    if metric == 'mlogloss':\n        param = {'objective': 'multi:softmax',\n                 'eval_metric': 'mlogloss',\n                 'num_class': len(np.unique(y)),\n                 'silent': 1}\n    else:\n        param = {'eval_metric': metric,\n                 'silent': 1}\n    for i in range(1, n_iterations+1):\n        # Create the shadow variables and run the model to obtain importances\n        new_x, shadow_names = _create_shadow(x)\n        dtrain = xgb.DMatrix(new_x, label=y)\n        bst = xgb.train(param, dtrain, verbose_eval=False)\n        if i == 1:\n            df = pd.DataFrame({'feature': new_x.columns})\n            pass\n\n        importance = bst.get_fscore()\n        importance = sorted(importance.items(), key=operator.itemgetter(1))\n        df2 = pd.DataFrame(importance, columns=['feature', 'fscore'+str(i)])\n        df2['fscore'+str(i)] = df2['fscore'+str(i)] / df2['fscore'+str(i)].sum()\n        df = pd.merge(df, df2, on='feature', how='outer')\n        if not silent:\n            print(\"Round: \", this_round, \" iteration: \", i)\n\n    df['Mean'] = df.mean(axis=1)\n    #Split them back out\n    real_vars = df[~df['feature'].isin(shadow_names)]\n    shadow_vars = df[df['feature'].isin(shadow_names)]\n\n    # Get mean value from the shadows\n    mean_shadow = shadow_vars['Mean'].mean() / cutoff\n    real_vars = real_vars[(real_vars.Mean > mean_shadow)]\n\n    #Check for the stopping criteria\n    #Basically looking to make sure we are removing at least 10% of the variables, or we should stop\n    if (len(real_vars['feature']) / len(x.columns)) > (1-delta):\n        criteria = True\n    else:\n        criteria = False\n\n    return criteria, real_vars['feature']\n\n\ndef _reduce_vars_sklearn(x, y, clf, this_round, cutoff, n_iterations, delta, silent):\n    \"\"\"\n    Function to run through each\n    :param x: Input dataframe - X\n    :param y: Target variable\n    :param clf: the fully specified classifier passed in by user\n    :param this_round: Round so it can be printed to screen\n    :return: tuple - stopping criteria and the variables to keep\n    \"\"\"\n    #Set up the parameters for running the model in XGBoost - split is on multi log loss\n\n    for i in range(1, n_iterations+1):\n        # Create the shadow variables and run the model to obtain importances\n        new_x, shadow_names = _create_shadow(x)\n        clf = clf.fit(new_x, np.ravel(y))\n\n        if i == 1:\n            df = pd.DataFrame({'feature': new_x.columns})\n            df2 = df.copy()\n            pass\n\n        try:\n            importance = clf.feature_importances_\n            df2['fscore' + str(i)] = importance\n        except ValueError:\n            print(\"this clf doesn't have the feature_importances_ method.  Only Sklearn tree based methods allowed\")\n\n        # importance = sorted(importance.items(), key=operator.itemgetter(1))\n\n        # df2 = pd.DataFrame(importance, columns=['feature', 'fscore'+str(i)])\n        df2['fscore'+str(i)] = df2['fscore'+str(i)] / df2['fscore'+str(i)].sum()\n        df = pd.merge(df, df2, on='feature', how='outer', suffixes=('', '_y'))\n        df.drop(df.filter(regex='_y$').columns, axis=1, inplace=True)\n        if not silent:\n            print(\"Round: \", this_round, \" iteration: \", i)\n\n    df['Mean'] = df.drop(\"feature\", axis=1).mean(axis=1)\n    #Split them back out\n    real_vars = df[~df['feature'].isin(shadow_names)]\n    shadow_vars = df[df['feature'].isin(shadow_names)]\n\n    # Get mean value from the shadows\n    mean_shadow = shadow_vars['Mean'].mean() / cutoff\n    real_vars = real_vars[(real_vars.Mean > mean_shadow)]\n\n    #Check for the stopping criteria\n    #Basically looking to make sure we are removing at least 10% of the variables, or we should stop\n    if (len(real_vars['feature']) / len(x.columns)) > (1-delta):\n        criteria = True\n    else:\n        criteria = False\n\n    return criteria, real_vars['feature']\n\n#Main function exposed to run the algorithm\ndef _BoostARoota(x, y, metric, clf, cutoff, iters, max_rounds, delta, silent):\n    \"\"\"\n    Function loops through, waiting for the stopping criteria to change\n    :param x: X dataframe One Hot Encoded\n    :param y: Labels for the target variable\n    :param metric: The metric to optimize in XGBoost\n    :return: names of the variables to keep\n    \"\"\"\n\n    new_x = x.copy()\n    #Run through loop until \"crit\" changes\n    i = 0\n    while True:\n        #Inside this loop we reduce the dataset on each iteration exiting with keep_vars\n        i += 1\n        if clf is None:\n            crit, keep_vars = _reduce_vars_xgb(new_x,\n                                               y,\n                                               metric=metric,\n                                               this_round=i,\n                                               cutoff=cutoff,\n                                               n_iterations=iters,\n                                               delta=delta,\n                                               silent=silent)\n        else:\n            crit, keep_vars = _reduce_vars_sklearn(new_x,\n                                                   y,\n                                                   clf=clf,\n                                                   this_round=i,\n                                                   cutoff=cutoff,\n                                                   n_iterations=iters,\n                                                   delta=delta,\n                                                   silent=silent)\n\n        if crit | (i >= max_rounds):\n            break  # exit and use keep_vars as final variables\n        else:\n            new_x = new_x[keep_vars].copy()\n    if not silent:\n        print(\"BoostARoota ran successfully! Algorithm went through \", i, \" rounds.\")\n    return keep_vars",
            "mc_idx": 132,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.016129032258064516,
                "Exploratory_Data_Analysis": 0.4032258064516129,
                "Data_Transform": 0.24193548387096775,
                "Model_Train": 0.12903225806451613,
                "Model_Evaluation": 0.08064516129032258,
                "Model_Interpretation": 0.16129032258064516,
                "Hyperparameter_Tuning": 0.4032258064516129,
                "Visualization": 0.0,
                "Debug": 0.016129032258064516,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 5
                },
                "Data_Extraction": {
                    "dataset": 1
                },
                "Exploratory_Data_Analysis": {
                    ".mean(": 4,
                    "np.unique": 1,
                    "columns": 9,
                    "shape": 1,
                    ".sum": 2,
                    ".mean": 6,
                    ".max": 2
                },
                "Data_Transform": {
                    ".merge(": 2,
                    ".concat(": 1,
                    "fit_transform": 1,
                    "transform": 3,
                    "ravel": 1,
                    ".drop": 2,
                    ".merge": 2,
                    ".concat": 1,
                    ".cut": 2
                },
                "Model_Train": {
                    ".fit(": 2,
                    "model": 5,
                    ".train(": 1
                },
                "Model_Evaluation": {
                    "model": 5
                },
                "Model_Interpretation": {
                    "feature_importances_": 4,
                    "shap": 1,
                    "model": 5
                },
                "Hyperparameter_Tuning": {
                    "n_iter": 6,
                    "param": 19
                },
                "Visualization": {},
                "Debug": {
                    "try:": 1
                },
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    88,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 132,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 88,
                "o_idx": 0
            }
        },
        {
            "source": "model = xgb.XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100, random_state=100, importance_type=\"total_cover\")\n\nbr = BoostARoota(clf=model)\n\n#Fit the model for the subset of variables\nbr.fit(X, y)\n\n#Can look at the important variables - will return a pandas series\nbr.keep_vars_",
            "mc_idx": 133,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.75,
                "Model_Interpretation": 0.75,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 2
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "cov": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "model": 3
                },
                "Model_Evaluation": {
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    89,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Round:  1  iteration:  1\nRound:  1  iteration:  2\nRound:  1  iteration:  3\nRound:  1  iteration:  4\nRound:  1  iteration:  5\nRound:  1  iteration:  6\nRound:  1  iteration:  7\nRound:  1  iteration:  8\nRound:  1  iteration:  9\nRound:  1  iteration:  10\nRound:  2  iteration:  1\nRound:  2  iteration:  2\nRound:  2  iteration:  3\nRound:  2  iteration:  4\nRound:  2  iteration:  5\nRound:  2  iteration:  6\nRound:  2  iteration:  7\nRound:  2  iteration:  8\nRound:  2  iteration:  9\nRound:  2  iteration:  10\nRound:  3  iteration:  1\nRound:  3  iteration:  2\nRound:  3  iteration:  3\nRound:  3  iteration:  4\nRound:  3  iteration:  5\nRound:  3  iteration:  6\nRound:  3  iteration:  7\nRound:  3  iteration:  8\nRound:  3  iteration:  9\nRound:  3  iteration:  10\nBoostARoota ran successfully! Algorithm went through  3  rounds.\n",
                        "0                    Age\n1                  SibSp\n2                  Parch\n3                   Fare\n4               Name_Len\n5               Sex_male\n6             Embarked_S\n7     Name_Title_Master.\n8         Name_Title_Mr.\n10        Cabin_Letter_D\n11        Cabin_Letter_E\n12        Cabin_Letter_n\n13         Ticket_Type_3\n14         Ticket_Type_S\n15              Pclass_2\n16              Pclass_3\nName: feature, dtype: object"
                    ]
                },
                "mc_idx": 133,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 89,
                "o_idx": 1
            }
        },
        {
            "source": "hist_est, lin_est = HistGradientBoostingClassifier(random_state=100), LogisticRegression()\ntracker.add_experiment(model=hist_est, X=X.loc[:, br.keep_vars_], y=y, model_name=\"HistGradientBoosting\", experiment_name=\"boostaroota_on_histg\")\ntracker.add_experiment(model=lin_est, X=X.loc[:, br.keep_vars_], y=y, model_name=\"LogisticRegression\", experiment_name=\"boostaroota_on_histg\")",
            "mc_idx": 134,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5714285714285714,
                "Model_Interpretation": 0.8571428571428571,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    "model": 4,
                    "logisticregression": 2,
                    "gradientboostingclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    90,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Model HistGradientBoosting achieved a score of 0.8282907538760906 with an std of 0.008227991222518525 in 0.9468529224395752 secs\nModel LogisticRegression achieved a score of 0.8204444165463561 with an std of 0.010315500638846266 in 0.059476613998413086 secs\n"
                    ]
                },
                "mc_idx": 134,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 90,
                "o_idx": 0
            }
        },
        {
            "source": "def highlight_max(s):\n    is_max = s == s.max()\n    return ['background-color: yellow' if v else '' for v in is_max]",
            "mc_idx": 136,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".max": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    91,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 136,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 91,
                "o_idx": 0
            }
        },
        {
            "source": "results = tracker.retrive_results()\n\nresults = results.style.apply(highlight_max, subset=['losses_mean'])\nresults",
            "mc_idx": 137,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".apply(": 1,
                    ".apply": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    92,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<pandas.io.formats.style.Styler at 0x7ae841e762c0>"
                    ]
                },
                "mc_idx": 137,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 92,
                "o_idx": 0
            }
        },
        {
            "source": "lin_est = LogisticRegression()\nlin_selector = RFECV(lin_est, step=1, cv=5)\nlin_selector = lin_selector.fit(X, y)\nlin_selector.support_\nkeep_cols = X.loc[:, lin_selector.support_].columns.to_list()\nlin_est = LogisticRegression().fit(X.loc[:, keep_cols], y)",
            "mc_idx": 141,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 2,
                    "logisticregression": 2
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    93,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 141,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 93,
                "o_idx": 0
            }
        },
        {
            "source": "preds = lin_est.predict(test.loc[:, keep_cols])",
            "mc_idx": 142,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {
                    ".predict(": 1
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    94,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 142,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 94,
                "o_idx": 0
            }
        },
        {
            "source": "sample_submission[target] = preds\nsample_submission[target] = sample_submission[target].astype(int)\nsample_submission.to_csv('submission.csv', index = False)",
            "mc_idx": 143,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    95,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 143,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 95,
                "o_idx": 0
            }
        },
        {
            "source": "sample_submission",
            "mc_idx": 144,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    96,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "     PassengerId  Survived\n0            892         0\n1            893         0\n2            894         0\n3            895         0\n4            896         1\n..           ...       ...\n413         1305         0\n414         1306         1\n415         1307         0\n416         1308         0\n417         1309         1\n\n[418 rows x 2 columns]"
                    ]
                },
                "mc_idx": 144,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 96,
                "o_idx": 0
            }
        }
    ],
    "markdown_cells": [
        {
            "source": "<div style=\"padding: 20px; background-color: #000080; border-radius: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\">\n    <div style=\"border: 2px solid #000080; padding: 20px; text-align: center; border-radius: 10px; background-color: #ffffff;\">\n        <h1 style=\"color: #00000; font-size: 32px; text-transform: uppercase; letter-spacing: 2px; margin-bottom: 20px;\">Become a feature selection master</h1>\n        <div><em>\n       If you like the content please consider an upvote. It is a great motivator to keep sharing code and ideas.\n        Thank you!!!\n    </em></div>\n</div>",
            "mc_idx": 0,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "In this notebook we will dive through various feature selection options. We will illustrate this on two model architectures to show the differences there as well.",
            "mc_idx": 1,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h1 style=\"background-color: #000080; color: #ffff00;\">Table of contents</h1>\n\n* [Load tand install libraries](#1)\n* [Load the data](#2)\n* [Create helper functions and classes](#3)\n* [Mastering feature selection](#4)\n    * [Creating a baseline](#4.1)\n    * [Using statistical methods](#4.2)\n        * [No correlation to target](#4.2.1)\n        * [Mutual information score](#4.2.2)\n        * [Collinearity in the dataset](4.2.3)\n    * [Using model inbuilt feature importance](#4.3)\n        * [Linear Regression](#4.3.1)\n        * [HistGradientBoosting](#4.3.2)\n            * [Gain](#4.3.2.1)\n            * [Weight](#4.3.2.2)\n            * [Cover](#4.3.2.3)\n            * [Total gain](#4.3.2.4)\n            * [Total cover](#4.3.2.5)\n    * [Using feature selection algorithms](#4.4)\n        * [Using recursive feature elimination](#4.4.1)\n        * [Using recursive feature elimination with inbuilt cross validation](#4.4.2)\n        * [Sequential feature selection](#4.4.3)\n        * [Lime](#4.4.4)\n        * [Shap](#4.4.5)\n        * [Boruta](#4.4.5)\n* [Comparing the results](#5.0)\n* [How to (not) interpret feature importance](#6.0)\n* [Submission time](#7.0)",
            "mc_idx": 2,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h1 style=\"background-color: #000080; color: #ffff00;\">Load and install libraries</h1>",
            "mc_idx": 3,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h1 style=\"background-color: #000080; color: #ffff00;\">Load the data</h1>",
            "mc_idx": 6,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h1 style=\"background-color: #000080; color: #ffff00;\">Create helper functions and classes</h1>",
            "mc_idx": 11,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h1 style=\"background-color: #000080; color: #ffff00;\">Mastering feature selection</h1>\n\nNow that we installed everything we need and loaded our data it is time to deep dive into the actual topic. On purpose I do not preprocess the data, oping that we can see a bit more variation between both models.\n\nFeel free to copy the notebook and play with some preprocessing.",
            "mc_idx": 14,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h2 style=\"background-color: #000080; color: #ffff00;\">Creating a baseline</h2>\n\nBefore we start we create a bseline for our models were we just run them using all features.",
            "mc_idx": 15,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h2 style=\"background-color: #000080; color: #ffff00;\">Using statistical methods</h2>\n\nIn this section we will remove features based on statistical methods and properties.",
            "mc_idx": 17,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">No correlation to target</h3>\n\nWe measure the correlation of all columns to the target and eliminate the ones that have almost no correlation. This captures linear relationships only, which is a hard limitation and might underestimate the value of a feature.",
            "mc_idx": 18,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Here we remove the columns with a correlation coefficient close to zero.",
            "mc_idx": 21,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">Mutual information score</h3>\n\nWe measure the mutual information score of all columns to with regards to the target and remove the ones with almost zero scoring. MI scores also consider non-linear information.",
            "mc_idx": 24,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Interesting! Only the id column has very little value. So we only remove that one.",
            "mc_idx": 27,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">Collinearity in the dataset</h3>\n\nWe measure the correlation of all columns to each other and remove the ones with high correlation (one of them).",
            "mc_idx": 30,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h2 style=\"background-color: #000080; color: #ffff00;\">Using model inbuilt feature importance</h2>\n\nIn this section we will invvestigate if the models itself provide us valueable information for feature selection.",
            "mc_idx": 36,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">Linear Regression</h3>\n\nFor linear regression we need to train an instance first. Then we can make use of it's own coefficients to select features.",
            "mc_idx": 37,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "We remove columns with coefficients close to zero..",
            "mc_idx": 41,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoosting</h3>",
            "mc_idx": 44,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "It seems like the HistGradientBoostingClassifier from sklearn does not offer any feature importance functionality. However we can make use of HistGradientBoosting also via the Xgboost library and get our importances from there.\n\nHere we can pass one of multiple importance types via the importance_type parameter (see the [docs](https://xgboost.readthedocs.io/en/stable/python/python_api.html):\nThe feature importance type for the feature_importances_ property:\n* For tree model, it\u2019s either \u201cgain\u201d, \u201cweight\u201d, \u201ccover\u201d, \u201ctotal_gain\u201d or \u201ctotal_cover\u201d.\n* For linear model, only \u201cweight\u201d is defined and it\u2019s the normalized coefficients without bias.\n\nAs you can see there is a total of 5 feature importance metrics within gradient boosting. What is behind each of them I will quote from [this](https://towardsdatascience.com/be-careful-when-interpreting-your-features-importance-in-xgboost-6e16132588e7) Medium article. Please consider some claps there.\n",
            "mc_idx": 45,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h4 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoosting gain</h4>\n\n\"The Gain implies the relative contribution of the corresponding feature to the model calculated by taking each feature\u2019s contribution for each tree in the model. A higher value of this metric when compared to another feature implies it is more important for generating a prediction.\n\nThe Gain is the most relevant attribute to interpret the relative importance of each feature.\n\n\u2018Gain\u2019 is the improvement in accuracy brought by a feature to the branches it is on. The idea is that before adding a new split on a feature X to the branch there was some wrongly classified elements, after adding the split on this feature, there are two new branches, and each of these branch is more accurate (one branch saying if your observation is on this branch then it should be classified as 1, and the other branch saying the exact opposite).\"",
            "mc_idx": 46,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h4 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoosting weight</h4>\n\n\"The Frequency (R)/Weight (python) is the percentage representing the relative number of times a particular feature occurs in the trees of the model. In the above example, if feature1 occurred in 2 splits, 1 split and 3 splits in each of tree1, tree2 and tree3; then the weight for feature1 will be 2+1+3 = 6. The frequency for feature1 is calculated as its percentage weight over weights of all features.\"",
            "mc_idx": 51,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h4 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoosting cover</h4>\n\n\"The Coverage metric means the relative number of observations related to this feature. For example, if you have 100 observations, 4 features and 3 trees, and suppose feature1 is used to decide the leaf node for 10, 5, and 2 observations in tree1, tree2 and tree3 respectively; then the metric will count cover for this feature as 10+5+2 = 17 observations. This will be calculated for all the 4 features and the cover will be 17 expressed as a percentage for all features\u2019 cover metrics.\"",
            "mc_idx": 56,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h4 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoosting total_gain</h4>",
            "mc_idx": 61,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h4 style=\"background-color: #000080; color: #ffff00;\">HistGradientBoostingRegressor total_cover</h4>",
            "mc_idx": 66,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h2 style=\"background-color: #000080; color: #ffff00;\">Using feature selection algorithms</h2>\n\nIn this section we will investigate algorithms designed for feature selection.",
            "mc_idx": 71,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">Using recursive feature elimination</h3>\n\n\"Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through any specific attribute or callable. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.\" (see [sklearn docs](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html))\n\nOne disadvantage here is that we need to tell in advance how many features shall be selected. One re-occuring pattern in this section is that these algorithms are not model agnostic. Therefore we will test each of them for both of our models if possible.",
            "mc_idx": 72,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "This is not compatible with HistGradienBoosting as it misses `coef_` and `feature_importances_` attributes.",
            "mc_idx": 75,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">Using recursive feature elimination with inbuilt cross validation</h3>",
            "mc_idx": 79,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">Sequential feature selection</h3>\n\n\"This Sequential Feature Selector adds (forward selection) or removes (backward selection) features to form a feature subset in a greedy fashion. At each stage, this estimator chooses the best feature to add or remove based on the cross-validation score of an estimator. In the case of unsupervised learning, this Sequential Feature Selector looks only at the features (X), not the desired outputs (y).\" (see [sklearn docs](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html))",
            "mc_idx": 84,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Skipping hist as this is really slow here",
            "mc_idx": 86,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">Lime</h3>\n\nLime is a model explanantion framework that tries to \"solve for model interpretability by producing locally faithful explanations\". (see the source of the quote and deeper explanations in [this](https://towardsdatascience.com/decrypting-your-machine-learning-model-using-lime-5adc035109b5) Medium article).",
            "mc_idx": 93,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Lime offers us the ability to explain feature importance on row level. Let's show this for the second row in the DataFrame:",
            "mc_idx": 99,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "We use the sub-modular attributes available on SP-LIME to obtain a global perspective of the data instances. Then, we visualize the data to visual global representative samples extracted by the SP-LIME algorithm. This takes much longer than the local explanations.",
            "mc_idx": 101,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "It this not so easy to keep an overview here. Let's keep Sex_male and Name_Title_Master only.",
            "mc_idx": 104,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "We do one for linear regression as well.",
            "mc_idx": 106,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "For this example we keep Sex_male and Ticket_Type_3",
            "mc_idx": 110,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">Shap</h3>\n\n\"SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions[...]\" ([source](https://shap.readthedocs.io/en/latest/))\n\nThe original paper can be found [here](https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf).",
            "mc_idx": 112,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "HistGradientBoosting is not yet supported by Shaps TreeExplainer (which is much faster for tree-based models). Alos be aware, that a model trained on GPU will utilize GPU acceleration also within Shap!",
            "mc_idx": 114,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Let's show the feature importances...",
            "mc_idx": 116,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "We can also show this as a barplot.",
            "mc_idx": 118,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "In both plots the values are sorted top down by importance.\nThe shap library has also beautiful visuals to explore feature importance for individual rows and also dependency plots to better undersatnd feature interactions. I will skip this here as the Kernel is pretty long already.\n\nLet's drop [\"Name_Title_Gordon,\", \"Name_Title_Impe,\", \"Name_Itle_Jonkheer.\", \"Name_Title_Mlle.\", \"Ticket_Type_W\", \"Name_Title_Melkebelke\"] etc here.",
            "mc_idx": 120,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "We do the same for linear regression as Shap (like Lime) is not model-agnostic.",
            "mc_idx": 124,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Here we drop just Name_Title_Dr. and Ticket_Type_F and S.",
            "mc_idx": 128,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h3 style=\"background-color: #000080; color: #ffff00;\">Boruta</h3>\n\nIn Boruta, features do not compete among themselves. They are compared with a randomized version of them instead.\n\"In practice, starting from X, another dataframe is created by randomly shuffling each feature. These permuted features are called shadow features. At this point, the shadow dataframe is attached to the original dataframe to obtain a new dataframe (we will call it X_boruta), which has twice the number of columns of X.\"\n\nFor more details check out [this](https://towardsdatascience.com/boruta-explained-the-way-i-wish-someone-explained-it-to-me-4489d70e154a) Medium article.\n\nOver the past decade the boruta algorithm has seen multiple implementations and variants. The original algorithm is quite slow. Instead we use a less-known, but powerful variant: boostaroota\n\nPlease be aware, that boostaroota was a research project and is not maintained. It seems like compatibility breaks with Panndas 2.0 or higher. However the code is open source and could be adapted.\n\nIn general I struggled to find any Boruta implementation that can be installed in this Kernel and just runs without an error. Therefore I decided to tak the boostaroota source code and add it below, but debug the breaking parts.\n\nBoostaroota runs now and expects an estimator with a feature_imprtance_ attribute. This does not apply to HistGradientBoosting and linear regression, so we fallback to Xgboost once again.",
            "mc_idx": 131,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h1 style=\"background-color: #000080; color: #ffff00;\">Comparing the results</h1>",
            "mc_idx": 135,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "So recursive feature elimination made the race here with logistic regression on top.",
            "mc_idx": 138,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h1 style=\"background-color: #000080; color: #ffff00;\">How to (not) interpret feature importance</h1>\n\nAs shown above feature importance has many implementations and variants: From statistical approaches to dedicated feature selection algorithms, from a focus on local importance to an explanation of global importance.\nThey all have one thing in common though: They cannot be used to explain any causal relationships in the data (with a theoretical exception maybe). These algorithms just try to explain how a model behaves, but they do not explain how the data behaves.",
            "mc_idx": 139,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h1 style=\"background-color: #000080; color: #ffff00;\">Submission time</h1>\n\nFinally we will take the best feature space and make a submission before we finish.",
            "mc_idx": 140,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Feel free to also checkout the [cross validation mastery](https://www.kaggle.com/code/thomasmeiner/become-a-cross-validation-master) notebook.",
            "mc_idx": 145,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<div style=\"padding: 20px; background-color: #000080; border-radius: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\">\n    <div style=\"border: 2px solid #000080; padding: 20px; text-align: center; border-radius: 10px; background-color: #ffffff;\">\n        <h1 style=\"color: #00000; font-size: 32px; text-transform: uppercase; letter-spacing: 2px; margin-bottom: 20px;\">Consider an upvote</h1>\n        <div><em>\n       This notebook took a while to be created. Upvotes help keeping the motivation up :-)\n    </em></div>\n</div>",
            "mc_idx": 146,
            "nb_idx": 31,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        }
    ],
    "sim_matrix": [],
    "cell_sim_matrix": [],
    "nb_order": [],
    "summary_data_VA": null
}