{
    "nb_idx": 4,
    "nb_name": "d0004",
    "filename": "a-comprehensive-guide-to-titanic-machine-learning.ipynb",
    "filepath": "data/data_Kaggle/raw/a-comprehensive-guide-to-titanic-machine-learning.ipynb",
    "source": "# About this Kernel\nThis kernel may (or may not) be helpful in your long and often tedious machine learning journey. Sometimes you may find this notebook verbose and overwhelming particularly if you're a beginner. This verbosity tries to explain everything I could possibly know. Once you get through the notebook, you could expect to have a good grasp of the fundamentals. I've also tried to write reusable codes as much as possible using custom functions so that we can avoid writing the same code again and again. Let's get started. \n # Outlines\n\n* [1.Problem Description and Objective](#1)\n* [2.Importing Packages and Collecting Data](#2)\n* [3.Variable Description and Identification](#3)\n   * [3.1 Variable Description](#3.1) [3.2 Categorical and Numerical Variables](#3.2) [3.3 Variable Data Types](#3.3)\n* [4.Univariate Analysis](#4)\n   * [4.1 Categorical Variables](#4.1)\n      * [4.1.1 Survived](#4.1.1) [4.1.2 Sex](#4.1.2) [4.1.3 Pclass](#4.1.3) [4.1.4 Embarked](#4.1.4) [4.1.5 Cabin](#4.1.5) [4.1.6 Name](#4.1.6) [4.1.7 Ticket](#4.1.7) [4.1.8 SibSp](#4.1.8) [4.1.9 Parch](#4.1.9)\n   * [4.2 Numerical Variables](#4.2)    \n      * [4.2.1 Fare](#4.2.1)  [4.2.2 Age](#4.2.2)  [4.2.3 PassengerId](#4.2.3)\n* [5.Feature Engineering](#5)\n   * [5.1 Process Cabin](#5.1) [5.2 Process Name](#5.2) [5.3 Process SibSp & Parch](#5.3)  [5.4 Process Ticket](#5.4)\n* [6.Outliers Detection](#6)\n   * [6.1 Outliers Detection of Age](#6.1)  [6.1 Outliers Detection of Fare](#6.2)\n* [7.Imputing Missing Variables](#7)\n   * [7.1 Impute Embarked & Fare](#7.1)  [7.2 Impute Age](#7.2)\n* [8.Bivariate Analysis](#8)\n   * [8.1 Numerical & Categorical Variables](#8.1)\n      * [8.1.1 Fare & Survived](#8.1.1)   [8.1.2 Age & Survived](#8.1.2)\n   * [8.2 Categorical & Categorical Variables](#8.2)\n      * [8.2.1 Sex & Survived](#8.2.1) [8.2.2 Pclass & Survived](#8.2.2) [8.2.3 Embarked & Survived](#8.2.3) [8.2.4 SIbSp & Survived](#8.2.4) [8.2.5 Parch & Survived](#8.2.5) [8.2.6 nameProcessed & Survived](#8.2.6) [8.2.7 familySize & Survived](#8.2.7) [8.2.8 cabinProcessed & Survived](#8.2.8) [ 8.2.9 ticketProcessed & Survived](#8.2.9)\n* [9.Multivariate Analysis](#9)  \n   * [9.1 (Pclass, Sex, cabinProcessed) vs Survived](#9.1) [9.2 (Pclass, Sex, Embarked) vs Survived](#9.2) [9.3 (Pclass, Sex, SibSp) vs Survived](#9.3) [9.4 (Pclass, Sex, Parch) vs Survived](#9.4) [9.5 (Pclass, Sex, nameProcessed) vs Survived](#9.5) [9.6 (Pclass, Sex, familySize) vs Survived](#9.6) [9.7 (Pclass, Sex, ticketProcessed) vs Survived](#9.7) [9.8 (Pclass, nameProcessed, cabinProcessed) vs Survived](#9.8) [9.9 (familySize, Sex, cabinProcessed) vs Survived](#9.9) [9.10 (Sex, nameProcessed, familySize) vs Survived](#9.10) [9.11 (Sex, nameProcessed, cabinProcessed) vs Survived](#9.11) [9.12 (Sex, nameProcessed, Embarked) vs Survived](#9.12) [9.13 (Sex, nameProcessed, ticketProcessed) vs Survived ](#9.13)\n* [10.Data Transformation](#10) \n   * [10.1 Binning Continuous Variables](#10.1)\n      * [10.1.1 Binning Age](#10.1.1) [10.1.2 Binning Fare](#10.1.2)\n   * [10.2 Dropping Features](#10.2) [10.3 Correcting Data Types](#10.3) [10.4 Encoding Categorical Variables](#10.4)\n* [11.Model Building and Evaluation](#11)   \n   * [11.1 Training Model](#11.1) [11.2 Model Evaluation](#11.2) [11.2.1 Cross Validation](#11.2.1) [11.2.2 Tunning Hyperparameters](#11.2.2) [11.2.3 Model Selection](#11.2.3) [11.3 Retrain & Predict Using Optimized Hyperparameters](#11.3) [11.4 Feature Importance](#11.4) [11.5 Learning Curves](#11.5)\n* [12.More Evaluation Metrics](#12)  \n   * [12.1 Confusion Matrix](#12.1) [12.2 Precision Score](#12.2) [12.3 Recall (or Sensitivity or True Positive Rate)](#12.3) [12.4 Specificity ( or True Negative Rate)](#12.4) [12.5 F1 Score](#12.5) [12.6 Classification Report](#12.6) [12.7 Precision-Recall vs Threshold Curve](#12.7) [12.8 Precision-Recall Curve](#12.8) [12.9 ROC  Curve & AUC Score ](#12.9)\n* [13.Prediction & Submission](#13) \n* [14.Introduction to Ensemble](#14)\n   * [14.1 Hard Voting Ensemble](#14.1) [14.2 Introduction to PCA](#14.2) [14.3 Soft Voting Ensemble](#14.3) [14.4 Bagging](#14.4) [14.5 Boosting](#14.5) [14.6 Blending](#14.6) [14.7 Stacking](#14.7) [14.8 Evaluating Different Ensembles](#14.8)\n* [15.End Note](#15) \n # 1.Problem Description and Objective <a id=\"1\"></a>\nThe sinking of the RMS Titanic is one of the most notorious shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crews. This harrowing tragedy shocked the international community and led to better safety regulations for ships.\n\nIn this problem, we're asked to complete the analysis of what sorts of passengers were likely to survive the tragedy using machine learning. So its our job to predict if a passenger survived from the sinking Titanic or not with the help of machine learning. So its a binary classification problem.\n\n# 2.Importing Packages and Collecting Data <a id=\"2\"></a>\nAfter importing required modules, let's read train and test data from csv files. \n \"\"\"Import basic modules.\"\"\"\nimport numpy as np               # For linear algebra\nimport pandas as pd              # For data manipulation\nimport matplotlib.pyplot as plt  # For 2D visualization\nimport seaborn as sns            \nfrom scipy import stats          # For statistics\n\n\"\"\"Plotly visualization.\"\"\"\nimport plotly.graph_objs as go\nfrom plotly.tools import make_subplots\nfrom plotly.offline import iplot, init_notebook_mode\ninit_notebook_mode(connected = True) # Required to use plotly offline in jupyter notebook\n\n\"\"\"Machine learning models.\"\"\"\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom xgboost import XGBClassifier\n\n\n\"\"\"Classification (evaluation) metrices.\"\"\"\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\n\n\"\"\"Ensembling\"\"\"\nfrom mlxtend.classifier import EnsembleVoteClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom mlxtend.plotting import plot_decision_regions\nfrom sklearn.ensemble import BaggingClassifier\nfrom mlens.ensemble import BlendEnsemble\nfrom vecstack import stacking \n \"\"\"Customize visualization.\"\"\"\nplt.style.use(\"bmh\")                    # Use bmh's style for plotting\nsns.set_style({\"axes.grid\":False})      # Remove gridlines\n\n\"\"\"Display markdown formatted output like bold, italic bold etc.\"\"\"\nfrom IPython.display import Markdown\ndef bold(string):\n    return display(Markdown(f\"**{string}**\")) \n \"\"\"Read and preview the train data from csv file.\"\"\"\ntrain = pd.read_csv(\"../input/train.csv\")\nbold(\"Preview of Train Data:\")\ndisplay(train.head(2))\n\n\"\"\"Read and preview the test from csv file.\"\"\"\ntest = pd.read_csv(\"../input/test.csv\")\nbold(\"Preview of Test Data:\")\ndisplay(test.head(2)) \n **Note:** We don't have Survived variable for test set. This will be our task to infer Survived for test set by learning from the train set. \n # 3.Variable Description and Identification <a id=\"3\"></a>\nLet's describe what each of the variable indicates and identify our response and predictor variables. Also seperate the categorical variables from numerical variables and finally identify pandas data types (i.e., object, float64 or int64) for every variable.\n\n## 3.1 Variable Description <a id=\"3.1\"></a> \n \"\"\"Merge train and test data together. This eliminates the hassle of handling train and test data seperately for various analysis.\"\"\"\nmerged = pd.concat([train, test], sort = False).reset_index(drop=True)\nbold(\"Preview of Merged Data:\")\ndisplay(merged.head(5)) \n \"\"\"Shape of the combined data.\"\"\"\nbold(\"Shape of the Merged Data:\")\ndisplay(merged.shape)\n\n\"\"\"Variables in the combined data.\"\"\"\nbold(\"Name of the Variables in merged data:\")\ndisplay(merged.columns) \n ### So what can we see??\n**We can see total 12 variables. And each variable has 1309 observations (excluding Survived).**\n### Here comes the description of all variables:\n1. **PassengerId** is a unique identifying number assigned to each passenger.\n2. **Survived** is a flag that indicates if a passenger survived or died ( i.e., 0 = No, 1 = Yes).\n3. **Pclass** is the passenger class (i.e., 1 = 1st class, 2 = 2nd class, 3 = 3rd class).\n4. **Name** is the name of the passenger.\n5. **Sex** indicates the gender of the passenger (i.e., Male or female).\n6. **Age** indicates the age of the passenger.\n7. **Sibsp**  is the number of siblings/spouses aboard.\n8. **Parch** is the number of parents/children aboard.\n9. **Ticket** indicates the ticket number issued to the passenger.\n10. **Fare** indicates the amount of money spent on their ticket.\n11. **Cabin** indicates the cabin category occupied by the passenger.\n12. **Embarked** indicates the port where the passenger embarked from (i.e., C = Cherbourg, Q = Queenstown, S = Southampton).\n\n\n### Here, Survived is the target variable and rest of the variables are predictor variables.\n\n## 3.2 Categorical and Numerical Variables  <a id=\"3.2\"></a>\n**Categorical Variable:** Survived, Sex, Pclass (ordinal), Embarked, Cabin, Name, Ticket, SibSp, and Parch.\n\n**Numerical Variable:** Fare, Age, and PassengerId.\n## 3.3 Variable Data Types <a id=\"3.3\"></a> \n \"\"\"Pandas data types for our different variables.\"\"\"\nbold(\"Data Types of Our Variables:\")\ndisplay(merged.dtypes) \n 1. **int data type variables:** Pclass, SibSp, Parch, and PassengerId.\n2. **float data type variables:** Fare and Age, *Survived (due to concatenation)*\n3. **object (numbers + strings) data type variables:** Name, Sex, Ticket, Cabin, and Embarked.\n\n# 4.Univariate Analysis <a id=\"4\"></a>\nUnivariate analysis separately explores the distribution of each variable in a data set. It looks at the range of values, as well as the central tendency of the values. Univariate data analysis does not look at relationships between various variables (like bivariate and multivariate analysis) rather it summarises each variable on its own. Methods to perform univariate analysis will depend on whether the variable is categorical or numerical. For numerical variable, we would explore its shape of distribution (distribution can either be symmetric or skewed) using histogram and density plots. For categorical variables, we would use bar plots to visualize the absolute and proportional frequency distribution. Knowing the distribution of the feature values becomes important when you use machine learning methods that assume a particular type of it, most often Gaussian. **Let's starts off with categorical variables:**\n\n## 4.1 Categorical Variables  <a id=\"4.1\"></a>\nTo analyse categorical variables, let's create a custom function to display bar chart in absolute and relative scale of a variable in a subplot. \n \"\"\"Create a function to plot a variable's absolute and relative frequency.\"\"\"\ndef plotFrequency(variable):\n    \"\"\"Plots absolute and relative frequency of a avriable.\"\"\"\n    \n    # Calculates absolute frequency\n    absFreq = variable.value_counts()\n    \n    # Calculates relative frequency\n    relFreq = variable.value_counts(normalize=True).round(4)*100\n    \n    # Creates a dataframe off absolute and relative frequency\n    df = pd.DataFrame({\n        \"absoluteFrequency\":absFreq,\n        \"relativeFrequency\":relFreq\n    })\n    \n    # Create two subplots of bar chart\n    fig=make_subplots(\n        rows=1, \n        cols=2,\n        vertical_spacing=0.3,\n        subplot_titles=(\"Absolute Frequency\", \"Relative Frequency\"),\n        print_grid=False) # This suppresses \"This is the format of your plot grid:\" text from popping out.\n\n    # Add trace for absolute frequency\n    fig.add_trace(\n        go.Bar(\n        y=df.index, \n        x=df.absoluteFrequency,\n        orientation=\"h\",\n        text=df.absoluteFrequency,\n        hoverinfo=\"x+y\",\n        textposition=\"auto\", \n        name=\"Abs Freq\",\n        textfont=dict(family=\"sans serif\",size=14),\n        marker = dict(color=df.absoluteFrequency, colorscale=\"Rainbow\")),\n        row=1,\n        col=1\n        )\n\n    # Add another trace for relative frequency\n    fig.add_trace(\n        go.Bar(y=df.index,\n        x=df.relativeFrequency.round(2),\n        orientation=\"h\",\n        text=df.relativeFrequency.round(2),\n        hoverinfo=\"x+y\",\n        textposition=\"auto\", \n        name=\"Rel Freq(%)\",\n        textfont=dict(family=\"sans serif\",size=15),\n        marker=dict(color=df.relativeFrequency.round(2), colorscale=\"Rainbow\")),\n        row=1,\n        col=2\n        )\n\n    # Update the layout. Add title, dimension, and background color\n    fig.layout.update(\n        height=600, \n        width=970,\n        hovermode=\"closest\",\n        title_text=f\"Absolute and Relative Frequency of {variable.name}\",showlegend=False,\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n\n    # Set y-axis title in bold\n    fig.layout.yaxis1.update(title=f\"<b>{variable.name}</b>\")\n    \n    # Set x-axes titles in bold\n    fig.layout.xaxis1.update(title=\"<b>Abs Freq</b>\")\n    fig.layout.xaxis2.update(title=\"<b>Rel Freq(%)</b>\")\n    # or, fig[\"layout\"][\"xaxis2\"].update(title=\"<b>Rel Freq(%)</b>\")\n    return fig.show() \n ###  4.1.1 Survived <a id=\"4.1.1\"></a> \n \"\"\"Plot number of survivors and victims in absolute and relative scale in the tragedy.\"\"\"\nplotFrequency(merged.Survived) \n **Findings:** Variable Survived is imbalanced since the proportion of survivors and victims is not equally represented in its distribution. Out of 891 passengers, only 342 passengers survived and a whopping 549 passengers died. Or put another way, 61.62% passengers died while just 38.38% of passengers were lucky enough to survive. \n ### 4.1.2 Sex <a id=\"4.1.2\"></a> \n \"\"\"Plot the absolute and relative frequency of Sex.\"\"\"\nplotFrequency(merged.Sex) \n **Findings:** Variable Sex is imbalanced as proportion of male vs female in its distribution are not equally represented. Rather Male(843) has outnumbered female (466) in variable Sex. Or, proportionally, over 64% of Sex variable consists of label male while female contibutes to only over 35.5% of Sex.\n\n### 4.1.3 Pclass  <a id=\"4.1.3\"></a> \n \"\"\"Absolute and relative frequency of Pclass.\"\"\"\nplotFrequency(merged.Pclass) \n **Findings:** Again class distribution of Pclass is imbalanced as three categories of Pclass are not evenly represented in its distribution. 3 (Pclass3) is the most occured (709) levels of Pclass while 2 is the least occured (277). Another way of saying that, over  54% of Pclass variable consists of 3(Pclass3) while 1 and 2 both combinedly contribute to nearly 46% of Pclass.\n\n### 4.1.4 Embarked  <a id=\"4.1.4\"></a> \n \"\"\"Plot absolute and relative frequency of Embarked.\"\"\"\nplotFrequency(merged.Embarked) \n **Findings:** Embarked is also imbalanced since its levels are not equally represented in its distribution. A whopping 914 passengers embarked from Southamton while just 123 embarked from Queenstown. In other words, almost 70% of Embarked consists of S while both C and Q contribute to 30 to Embarked.\n\n### 4.1.5 Cabin <a id=\"4.1.5\"></a> \n \"\"\"Absolute frequency of Cabin.\"\"\"\nabsFreqCabin = merged.Cabin.value_counts(dropna = False)\nbold(\"Categories of Cabin:\")\ndisplay(absFreqCabin.head()) \n \n\"\"\"As frequency of Cabin isn't what we expected, let's count total categories in Cabin.\"\"\"\nbold(\"Total Categories in Cabin:\")\ndisplay(absFreqCabin.count()) \n \"\"\"Finally preview the variable Cabin to see what is causing the irregularity.\"\"\"\nbold(\"Preview of Cabin:\")\ndisplay(merged.Cabin.head(7)) \n **Findings:** Looks like Cabin is an alphanumeric type variable with 1014 missing obsevations. There are 187 kinds of categories in variable Cabin. Since there are too many categories in Cabin, we must process (i.e., reduce the number of categories) Cabin to check if there is any association between Survived and Cabin.\n\n### 4.1.6 Name <a id=\"4.1.6\"></a> \n \"\"\"Count total categories in Name.\"\"\"\nbold(\"Total Categories in Name:\")\ndisplay(merged.Name.value_counts().count()) \n \"\"\"Let's finally check the what's inside the variable Name.\"\"\"\nbold(\"Preview of Name:\")\ndisplay(merged.Name.head()) \n **Findings:** As expected Name contains strings that has 1307 variations. So, like Cabin, we must process Name to get any clue about survival from it.\n\n### 4.1.7 Ticket  <a id=\"4.1.7\"></a> \n \"\"\"Count total groups in variable Ticket.\"\"\"\nbold(\"Total Groups in Ticket:\")\ndisplay(merged.Ticket.value_counts().count()) \n \"\"\"Lets investigate Ticket.\"\"\"\nbold(\"Preview of Ticket:\")\ndisplay(merged.Ticket.head()) \n **Findings:** It seems Ticket also has too many unique categories (929). Being an alphanumeric type variable, we must process Ticket to get any useful insights about survival.\n\n### 4.1.8 SibSp  <a id=\"4.1.8\"></a> \n \"\"\"Plot the absolute and relative frequency of SibSp to investigate its distribution.\"\"\"\nplotFrequency(merged.SibSp) \n **Findings:** Once again, SibSp is not balanced as levels of SibSp(7) are not equally represented in its distribution. 891 passengers were without siblings or spouses. Put another way, over 68% passengers had no siblings or spouses aboard, followed by over 24% passengers had 1 siblings or spouse.\n\n### 4.1.9 Parch  <a id=\"4.1.9\"></a> \n \"\"\"Absolute and relative frequency of Parch.\"\"\"\nplotFrequency(merged.Parch) \n **Findings:** Parch isn't balanced as levels of Parch(8) are not equally represented in its distribution. Over one thousand passengers were without parents or children, followed by 170 passengers had one parents or children. In other words, over 76.5% passengers were without parents or children while rest of the 23.5% had few parents or children.\n\n## 4.2 Numerical Variables <a id=\"4.2\"></a>\nWe would like to analyse numerical variables using histogram, density plot, and summary statistics. To analyse numerical variables, we will create 2 custom functions. The 1st one will plot histogram and density plot for each numerical variable. And the 2nd one will calculate summary statistics including skewness. \n \"\"\"#1.Create a function to plot histogram and density plot.\"\"\"\ndef plotHistogram(variable):\n    \"\"\"Plots histogram and density plot of a variable.\"\"\"\n    \n    # Create subplot object.\n    fig = make_subplots(\n        rows=2,\n        cols=1,\n        print_grid=False,\n    subplot_titles=(f\"Distribution of {variable.name} with Histogram\", f\"Distribution of {variable.name} with Density Plot\"))\n    \n    # This is a count histogram\n    fig.add_trace(\n        go.Histogram(\n            x = variable,\n            hoverinfo=\"x+y\",\n            marker = dict(color = \"chocolate\")\n        ),\n    row=1,col=1)\n    \n    # This is a density histogram\n    fig.add_trace(\n        go.Histogram(\n            x = variable,\n            hoverinfo=\"x+y\",\n            histnorm = \"density\",\n            marker = dict(color = \"darkred\")\n        ),\n    row=2,col=1)\n    \n    # Update layout\n    fig.layout.update(\n        height=800, \n        width=870,\n        hovermode=\"closest\",\n        showlegend=False,\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n    \n    # Update axes\n    fig.layout.yaxis1.update(title=\"<b>Abs Frequency</b>\")\n    fig.layout.yaxis2.update(title=\"<b>Density(%)</b>\")\n    fig.layout.xaxis2.update(title=f\"<b>{variable.name}</b>\")\n    return fig.show()\n    \n\n    \n'''#2.Calculate descriptive statistics.'''\ndef calculateSummaryStats(variable):\n    stats = variable.describe()\n    skewness = pd.Series(variable.skew(), index = [\"skewness\"])\n    statsDf = pd.DataFrame(pd.concat([skewness, stats], sort = False), columns = [variable.name])\n    statsDf = statsDf.reset_index().rename(columns={\"index\":\"summaryStats\"})\n    return display(statsDf.round(2)) \n ### 4.2.1 Fare <a id=\"4.2.1\"></a> \n '''Plot histogram and density plot of Fare.'''\nplotHistogram(merged.Fare) \n **Reading the histogram, it's clear that Fare's distribution has a high positive skewness. And it seems a number of passengers (653) paid for fare between 5 to 15 (less than 15), followed by 25 to 35 (less than 35).**\n\nThere is also another, often clearer, way to grasp the distribution: density plots or, more formally, Kernel Density Plots. They can be considered a smoothed version of the histogram. One advantage of density plot over histogram is that its shape of distribution isn't affected by the number of bins used. \n \"\"\"Calculate summary statistics of Fare.\"\"\"\nbold(\"Summary Stats of Fare:\")\ncalculateSummaryStats(merged.Fare) \n **So what does the  value of skewness suggest?**\n1. If skewness is less than \u22121 or greater than +1, the distribution can be considered as highly skewed.\n2. If skewness is between \u22121 and \u2212\u00bd or between +\u00bd and +1, the distribution can be considered as moderately skewed.\n3. And finally if skewness is between \u2212\u00bd and +\u00bd, the distribution can be considered as approximately symmetric.    \n\n**Findings:** Density plot shows the mass of the distribution of Fare is heavily concentrated on the left of the figure due to very long tail on the right side. So it can be said that Fare is substantially skewed(positively) that is also supported by the calculated positive value of skewness of 4.37\n\n### 4.2.2 Age <a id=\"4.2.2\"></a> \n \"\"\"Plot histogram and density plot of Age.\"\"\"\nplotHistogram(merged.Age) \n \"\"\"Calculate summary stats for Age\"\"\"\ncalculateSummaryStats(merged.Age) \n **At first glance, Age seems to be positively skewed (slightly). 344 passengers' age is between 20 to 30(less than 30). And passengers between age 70 to 80(including 80) was 8 were the least.** \n **Findings:** What we can see from the density plot is that the mass of the distribution of Age is slightly concentrated on the left of the figure due to comparatively long tail on the right side. So it can be said that Age is almost normally distributed since the tail on the both sides are almost equal and it has a small value of positive skewness of 0.41 (in between -0.5 to 0.5). So it can be said that Age is almost normally distributed.\n\n### 4.2.3 PassengerId <a id=\"4.2.3\"></a> \n \"\"\"What does passengerId contain?\"\"\"\ndisplay(merged.PassengerId.head()) \n **Findings:** PassengersId is an unique identity number (positive integer) assigned to each passenger.\n\n# 5.Feature Engineering <a id=\"5\"></a>\nIn this section, we would either modify or create new features from the exsisting features which are otherwise hard to analyse in their raw forms that we saw in Univariate Analysis section. We would engineer features like Cabin, Name, SibSp & Parch, and Ticket that could tell us something about survival or death once they're processed.\n\n## 5.1 Process Cabin <a id=\"5.1\"></a> \n \"\"\"Let's preview the Cabin again.\"\"\"\nbold(\"Preview of Cabin:\")\ndisplay(merged.Cabin.head()) \n \"\"\"It seems Cabin contains some missing values. Let's count them.\"\"\"\nbold(\"Missing Values in Cabin:\")\ndisplay(merged.Cabin.isna().sum()) \n \"\"\"Total categories in Cabin before processing.\"\"\"\nbold(\"Total Categories in Cabin before Processing:\")\ndisplay(merged.Cabin.value_counts(dropna=False).count()) \n Looks like Cabin is alphanumeric type variable with no special characters (like ., /, % etc) between letters and numbers. It has also 1014 missing obsevations. It is reasonable to presume that those NaNs didn't have a cabin, which could tell us something about 'Survived'. We will flag NaN as 'X' and keep only the 1st character where Cabin has alphanumeric values. Since its a categorical variable, we must reduce the number of categories for further analysis. **To avoid mutability, we won't change any variable's state in place, rather we'll create a brand new variable.** \n \"\"\"Flag all the NaNs of Cabin as 'X'.\"\"\"\nnanReplaced= merged.Cabin.fillna(\"X\") \n \"\"\"Extract only the 1st character from Cabin, which is only a Letter. And insert it to the dataframe.\"\"\"\nmerged[\"cabinProcessed\"] = nanReplaced.str.get(0) \nbold(\"Cabin Categories after Processing:\")\ndisplay(merged.cabinProcessed.value_counts()) \n \"\"\"After processing, we can visualize the absolute and relative frequency of newly transformed Cabin variable.\"\"\"\nplotFrequency(merged.cabinProcessed) \n **Findings:** It seems nearly 77.5% of passengers had X cabin category (formerly NaNs), followed by over 7% had cabin category C and nearly 5% had cabin category B.\n\n## 5.2 Process Name <a id=\"5.2\"></a> \n \"\"\"Lets see what's inside the Name.\"\"\"\ndisplay(merged.Name.head(8)) \n What we can easily understand from this column, it contains strings that further contains titles such as Mr, Mrs, Master etc. These titles give us some useful information about sex(Mr = male, Mrs = married female), age(Miss is usually younger than Mrs), and profession(Master indicates profession and hence social status) etc which in the end could tell us something more about survival. Now we want to extract these titles from Name to check if there is any association between these titles and Survived. \n \"\"\"Extract those firstName from Name.\"\"\"\nfirstName = merged.Name.str.split(\".\").str.get(0).str.split(\",\").str.get(-1) \n \"\"\"Count the extracted categories of firstName from Name.\"\"\"\ndisplay(firstName.value_counts()) \n We can see there are several titles with the very least frequency. So, it makes sense to put them in fewer buckets. Professionals like Dr, Rev, Col, Major, Capt will be put into 'Officer' bucket. First name such as Dona, Jonkheer, Countess, Sir, Lady, Don were usually entitled to the aristocrats and hence these first name will be put into bucket 'Aristocrat'. We would also replace Mlle and Ms with Miss and Mme by Mrs as these are French titles. \n \"\"\"Create a bucket Officer and put Dr, Rev, Col, Major, Capt titles into it.\"\"\"\nfirstName.replace(to_replace = [\"Dr\", \"Rev\", \"Col\", \"Major\", \"Capt\"], value = \"Officer\", inplace = True,regex=True)\n\n\"\"\"Put Dona, Jonkheer, Countess, Sir, Lady, Don in bucket Aristocrat.\"\"\"\nfirstName.replace(to_replace = [\"Dona\", \"Jonkheer\", \"Countess\", \"Sir\", \"Lady\", \"Don\"], value = \"Aristocrat\", inplace = True,regex=True)\n\n\"\"\"Finally Replace Mlle and Ms with Miss. And Mme with Mrs.\"\"\"\nfirstName.replace({\"Mlle\":\"Miss\", \"Ms\":\"Miss\", \"Mme\":\"Mrs\"}, inplace = True,regex=True)\n\n\"\"\"Replace the Aristocrat with Aristocrat\"\"\"\nfirstName.replace({\"the Aristocrat\":\"Aristocrat\"}, inplace = True,regex=True)\n\n\"\"\"Insert a column named 'nameProcessed'.\"\"\"\nmerged[\"nameProcessed\"] = firstName \n \"\"\"let's see how nameProcessed looks now\"\"\"\ndisplay(merged.nameProcessed.value_counts()) \n \"\"\"After processing, visualise and count absolute and relative frequency of transformed Name.\"\"\"\nplotFrequency(merged.nameProcessed) \n **Findings:** Nearly 58% passengers had title Mr(male of course), followed almost 20% passengers had titles Miss(unmarried women hence usually younger than Mrs). Just over 15% passengers were married women (Mrs).\n\n## 5.3 Process SibSp & Parch <a id=\"5.3\"></a>\nIn univariate analysis, we saw some passengers had siblings/spouses and some didn't have. The same is also true for variable Parch. Since these two variables together indicate the size of a family, we would create a new variable 'familySize' from these two variables. \n \"\"\"Merge SibSp and Parch to create a variable Family_size.\"\"\"\nmerged[\"familySize\"] = merged.SibSp + merged.Parch + 1  # Adding 1 for single person\nbold(\"Categoiries in Family_size:\")\ndisplay(merged.familySize.value_counts()) \n We see there are several family sizes with the very least frequency. So its sensible to put them in a fewer buckets. We will create 4 buckets namely single, small, medium, and large for rest of them. \n \"\"\"Create buckets of single, small, medium, and large and then put respective values into them.\"\"\"\nmerged.familySize.replace(to_replace = [1], value = \"single\", inplace = True)\nmerged.familySize.replace(to_replace = [2,3], value = \"small\", inplace = True)\nmerged.familySize.replace(to_replace = [4,5], value = \"medium\", inplace = True)\nmerged.familySize.replace(to_replace = [6, 7, 8, 11], value = \"large\", inplace = True) \n \"\"\"After processing, visualise and count the absolute and relative frequency of engineered familySize.\"\"\"\nplotFrequency(merged.familySize) \n **Findings:** Looks like most of the passengers (over 60%) were single(without family), followed by 30% passengers had a small family. Almost 5% passengers had medium families and just over 4.5% passengers had large families abroad.\n\n## 5.4 Process Ticket <a id=\"5.4\"></a> \n \"\"\"Let's preview the variable Ticket first.\"\"\"\ndisplay(merged.Ticket.head()) \n Ticket is also an alphanumeric type variable. We will create two groups-one will contain just number and other will only contain character extracted from string. If a row contains both character and number, we will keep only character. \n \"\"\"Assign 'N' if there is only digits in Ticket. Otherwise just get the 1st character from Ticket.\"\"\"\notherwise = merged.Ticket.str.split(\" \").str.get(0).str.get(0) # This extracts the 1st character\nmerged[\"ticketProcessed\"] = np.where(merged.Ticket.str.isdigit(), \"N\", otherwise) \n \"\"\"Now calculate the categories in the ticketProcessed column.\"\"\"\nbold(\"Ticket after Processing:\")\ndisplay(merged.ticketProcessed.value_counts()) \n \"\"\"After processing, visualise and count the absolute and relative frequency of updated Ticket.\"\"\"\nplotFrequency(merged.ticketProcessed) \n **Findings:** Over 73% passengers had ticket of category N, followed by nearly 7.5% passengers ticket category were S and P. Passengers with W ticket category were as low as 1.45%.\n\n# 6.Outliers Detection <a id=\"6\"></a>\n**How outliers affect the distribution:** If a value of a variable is significantly above the expected range, it will drag the distribution to the right, making the graph right-skewed or positive-skewed (like Fare). Alternatively, If a value is significantly below the expected range, it will drag the distribution to the left, making the graph left-skewed or negative-skewed.\n\nAnother useful plot for visualizing a continuous variable is box plot. Box plot is particularly helpful to understand the spread of the continus data and whether there are potential unusual observations (outliers) in that variable. It presents information of min, 1st quartile, 2nd quartile(median), 3rd quartile, and max of a variable.**We will use IQR method to detect the outliers for variable Age and Fare though we won't remove them.** \n \"\"\"#1.Create a function that removes outliers\"\"\"\ndef removeOutliers(variable):\n    \"\"\"Calculates and removes outliers using IQR method.\"\"\"\n    \n    # Calculate 1st, 3rd quartiles and iqr.\n    q1, q3 = variable.quantile(0.25), variable.quantile(0.75)\n    iqr = q3 - q1\n    \n    # Calculate lower fence and upper fence for outliers\n    lowerFence, upperFence = q1-1.5*iqr, q3+1.5*iqr   # Any values less than l_fence and greater than u_fence are outliers.\n    \n    # Observations that are outliers\n    outliers = variable[(variable<lowerFence) | (variable>upperFence)]\n    \n    # Drop obsevations that are outliers\n    filtered = variable.drop(outliers.index, axis = 0).reset_index(drop=True)\n    return filtered\n\n\n\"\"\"#2.Create another function to plot boxplot with and without outliers.\"\"\"\ndef plotBoxPlot(variable,filteredVariable):\n    \"\"\"Plots Box plot of a variable with and without outliers.\n    We will also use the output of removeOutliers function as the input to this function.\n    variable = variable with outliers,\n    filteredVariable = variable without outliers\"\"\"\n    \n    # Create subplot object.\n    fig = make_subplots(\n        rows=2,\n        cols=1,\n        print_grid=False,\n    subplot_titles=(f\"{variable.name} Distribution with Outliers\", f\"{variable.name} Distribution without Outliers\"))\n    \n    # This trace plots boxplot with outliers\n    fig.add_trace(\n        go.Box(\n            x = variable,\n            name = \"\", # This removes trace 0\n            marker = dict(color=\"darkred\")\n        ),\n    row=1,col=1)\n    \n    # This trace plots boxplot without outliers\n    fig.add_trace(\n        go.Box(\n            x = filteredVariable,\n            name = \"\",\n            marker = dict(color=\"green\")\n        ),\n    row=2,col=1)\n    \n    # Update layout\n    fig.layout.update(\n        height=800, \n        width=870,\n        showlegend=False,\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n    \n    # Update axes\n    fig.layout.xaxis2.update(title=f\"<b>{variable.name}</b>\")\n    return fig.show() \n ## 6.1 Outliers Detection for Age <a id=\"6.1\"></a> \n \"\"\"Plot Age with and without outliers.\"\"\"\nplotBoxPlot(merged.Age,removeOutliers(merged.Age)) \n **For a box plot, if the longer part of the box is right (or above) to the median, the data is said to be skewed right. If the longer part is  left (or below) to the median, the data is skewed left. In our case, the bigger part of the box is right to the median**\n\n## 6.2 Outliers Detection for Fare <a id=\"6.2\"></a> \n \"\"\"Plot Fare with and without outliers.\"\"\"\nplotBoxPlot(merged.Fare,removeOutliers(merged.Fare)) \n # 7.Imputing Missing Variables <a id=\"7\"></a>\nThe simpliest way to impute missing values of a variable is to impute its missing values with its mean, median or mode depending on its distribution and variable type(categorical or numerical). By now, we should have a good idea about the distribution of the variables and the presence of outliers in those variables. For categorical variables mode-imputation is performed and for numerical variable mean-impuation is performed if its distribution is symmetric(or almost symmetric or normal like Age). On the other hand, for a variable with skewed distribution and outliers (like Fare), meadian-imputation is recommended as median is more immune to outliers than mean. \n\nHowever, one clear disadvantage of using mean, median or mode to impute missing values is the addition of bias if the amount of missing values is significant (like Age). So simply replacing them with the mean or the median age might not be the best solution since the age may differ by groups and categories of passengers.\n\nTo solve this, we can group our data by some variables that have no missing values and for each subset compute the median age to impute the missing values. Or we can build a linear regression model that will predict missing values of Age using the features that have no missing values. These two methods may result in better accuracy without high bias, unless a missing value is expected to have a very high variance. We will show the former method of imputation. \n \"\"\"#1.Create a function to calculate missing values\"\"\"\ndef calculateMissingValues(variable):\n    \"\"\"Calculates missing values of a variable.\"\"\"\n    \n    return merged.isna().sum()[merged.isna().sum()>0] # Returns only columns with missing values\n\n\n\n\"\"\"\"#2.Create a function to plot scatter plot.\nThis can also be used to plot missing values\"\"\"\ndef plotScatterPlot(x, y, title, yaxis):\n    trace = go.Scatter(\n    x = x,\n    y = y,\n    mode = \"markers\",\n    marker = dict(color = y, size = 35, showscale = True, colorscale = \"Rainbow\"))\n    layout = go.Layout(hovermode= \"closest\",\n                       title = title,\n                       yaxis = dict(title = yaxis),\n                       height=600,\n                       width=900,\n                       showlegend=False,\n                        paper_bgcolor=\"rgb(243, 243, 243)\",\n                        plot_bgcolor=\"rgb(243, 243, 243)\"\n                      )\n    fig = go.Figure(data = [trace], layout = layout)\n    return fig.show()       \n \"\"\"Plot variables with their corresponding missing values.\"\"\"\nplotScatterPlot(calculateMissingValues(merged).index,\n               calculateMissingValues(merged),\n               \"Features with Missing Values\",\n               \"Missing Values\") \n **The above plot shows the most missing values for Cabin, Survived, followed by Age, Embarked and Fare. Since we created a new variable cabinProcessed off Cabin, we don't need to impute Cabin.** \n **Findings:** \n1. Age has 263 missing values.\n2. Fare has only 1.\n3. Cabin has a whopping 1014 missing values.\n4. Embarked has just 2 missing values.\n5. **Finally Survived has missing values (due to concatenation of train and test set) that we would predict learning from the train dataset.**\n\n**Remember we have total 1309 observations except variable Survived.**\n\n## 7.1 Impute Embarked & Fare <a id=\"7.1\"></a> \n \"\"\"Impute missing values of Embarked. Embarked is a categorical variable where S is the most frequent.\"\"\"\nmerged.Embarked.fillna(value=\"S\", inplace = True)\n\n\"\"\"Impute missing values of Fare. Fare is a numerical variable with outliers. Hence it will be imputed by median.\"\"\"\nmerged.Fare.fillna(value=merged.Fare.median(), inplace = True) \n ## 7.2 Impute Age <a id=\"7.2\"></a>\nTo impute Age with grouped median, we need to know which features are highly correlated with Age. Let's find out the variables correlated with Age. \n \"\"\"Create a boxplot to view the variables correlated with Age. First extract the variables we're interested in.\"\"\"\ntoSearch = merged.loc[:, [\"Sex\", \"Pclass\", \"Embarked\", \"nameProcessed\", \"familySize\", \"Parch\", \n                             \"SibSp\", \"cabinProcessed\", \"ticketProcessed\"]]\n\nfig, axes = plt.subplots(nrows = 3, ncols = 3, figsize = (25,25))\nfor ax, column in zip(axes.flatten(), toSearch.columns):\n    sns.boxplot(x = toSearch[column], y = merged.Age, ax = ax)\n    ax.set_title(column, fontsize = 23)\n    ax.tick_params(axis = \"both\", which = \"major\", labelsize = 20)\n    ax.tick_params(axis = \"both\", which = \"minor\", labelsize = 20)\n    ax.set_ylabel(\"Age\", fontsize = 20)\n    ax.set_xlabel(\"\")\nfig.suptitle(\"Variables Associated with Age\", fontsize = 30)\nfig.tight_layout(rect = [0, 0.03, 1, 0.95]) \n **Findings:** \n1. Age distribution seems to be the same in male and female subpopulations of Sex and S, C, Q subpopulations of Embarked. So Sex and Embarked aren't good predictors for Age.\n2. On the other hand, Age distribution seems to be distinct in Pclass's 1, 2 and 3 subpopulations, so Pclass is informative to predict Age.\n3. Finally, Age distribution seems to be distinct in different categories for nameProcessed, familySize, SibSp, Parch, and cabinProcessed. So they might be good predictors for Age as well. \n \"\"\"Let's plot correlation heatmap to see which variable is highly correlated with Age and if our \nboxplot interpretation holds true. We need to convert categorical variable into numerical to plot \ncorrelation heatmap. So convert categorical variables into numerical.\"\"\"\nfrom sklearn.preprocessing import LabelEncoder\ntoSearch = toSearch.agg(LabelEncoder().fit_transform)\ntoSearch[\"Age\"] = merged.Age # Inserting Age in dataframe \"toSearch\".\ntoSearch = toSearch.set_index(\"Age\").reset_index() # Move Age column at index 0.\n\n# Now create the correlation heatmap\nfig,ax = plt.subplots(nrows=1, ncols=1, figsize=(15,6))\nsns.heatmap(toSearch.corr(), cmap =\"YlGnBu\", annot=True, annot_kws={\"size\":14}, ax=ax)\nax.set_title(\"Variables correlated with Age\", fontsize = 20)\nax.tick_params(axis = \"both\", which = \"major\", labelsize = 14)\nax.tick_params(axis = \"both\", which = \"minor\", labelsize = 14)\nplt.show() \n **Findings:** As expected Sex, Embarked, and ticketProcessed have the weakest correlation with Age what we could guess beforehand from boxplot. Parch and familySize are moderately correlated with Age. nameProcessed, Pclass, Cabin, and SibSp have the highest correlation with Age. But we are gonna use nameProcessed and Pclass only in order to impute Age since they have the strongest correlation with Age. So the tactic is to impute missing values of Age with the median age of similar rows according to nameProcessed and Pclass. \n \"\"\"Impute Age with median of respective columns (i.e., nameProcessed and Pclass).\"\"\"\nmerged.Age = merged.groupby([\"nameProcessed\", \"Pclass\"])[\"Age\"].transform(lambda x: x.fillna(x.median()))\n\n\"\"\"So by now we should have variables with no missing values.\"\"\"\nbold(\"Missing Values after Imputation:\")\ndisplay(merged.isnull().sum()) \n # 8.Bivariate Analysis <a id=\"8\"></a>\nBeing the most important part, bivariate analysis tries to find the relationship between two variables. We will look for correlation or association between our predictor and target variables. Bivariate analysis is performed for any combination of categorical and numerical variables. The combination can be: Numerical & Numerical, Numerical & Categorical and Categorical & Categorical. Different methods are used to tackle these combinations during analysis process. The methods are:\n1. Numerical & Numerical: Pearson's correlation, or Spearman correlation (the later doesn't require normal distribution).\n2. Numerical & Categorical: Point biserial correlation (only  if categorical variable is binary type), or ANOVA test. For this problem, you can use either biserial correlation or ANOVA. But I will perform both test just to learn because ANOVA will come in handy if categorical variable has more than two classes.\n3. Categorical & Categorical: We would use Chi-square test for bivariate analysis between categorical variables.\n\n## 8.1 Numerical & Categorical Variables <a id=\"8.1\"></a>\nFirst we create a boxplot between our numerical and categorical variables to check if the distribution of numerical variable is distinct in different classes of nominal variables. Then we find the mean of numerical variable for every class of categorical variable. Again we plot a histogram of numerical variable for every class of categorical variable. Finally anova or point biserial correlation (in case of two class categorical variable) is calculated to find association between nominal and numerical variables.    \n \"\"\"Let's split the train and test data for bivariate analysis since test data has no Survived values. We need our target variable without missing values to conduct the association test with predictor variables.\"\"\"\ndf_train = merged.iloc[:891, :]\ndf_test = merged.iloc[891:, :]\ndf_test = df_test.drop(columns = [\"Survived\"], axis = 1)\n\n\"\"\"#1.Create a function that creates boxplot between categorical and numerical variables and calculates biserial correlation.\"\"\"\ndef boxplotAndCorrelation(numVariable,catVariable=df_train.Survived):\n    \"\"\"Return boxplot between a categorical and numerical variable. Also calculates biserial correlation.\n    numVariable = a numerical variable of interest.\"\"\"\n    \n    # Calculate point biserial correlation and p value\n    biserialCorr = stats.pointbiserialr(numVariable,catVariable)[0].round(2)\n    pValue = stats.pointbiserialr(numVariable,catVariable)[1].round(5)\n    \n    # Create subplot object.\n    fig = make_subplots(\n        rows=1,\n        cols=1,\n        print_grid=False,\n    )\n    \n    # This trace plots boxplot of categorical variable vs numerical variable\n    fig.add_trace(\n        go.Box(\n            x = catVariable,\n            y = numVariable,\n            marker_color=\"lightseagreen\",\n            ))\n    \n    \n    # Update layout\n    fig.layout.update(\n        height=500, \n        width=900,\n        showlegend=False,\n        title_text= f\"Association between {catVariable.name} and {numVariable.name} (corr: {biserialCorr}, p: {pValue})\",\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n    \n    # Update axes\n    fig.layout.xaxis1.update(title=f\"<b>{catVariable.name}</b>\")\n    fig.layout.yaxis1.update(title=f\"<b>{numVariable.name}</b>\")\n    return fig.show()\n\n\n\"\"\"#2.Create another function to calculate mean when grouped by categorical variable. And also plot the grouped mean.\"\"\"\ndef numGroupedByCat(numVariable,catVariable=df_train.Survived):\n    \"\"\"Returns a barplot showing mean of numerical variable across the class of categorical variable.\"\"\"\n    \n    # Calculates mean across different classes of categorical variable\n    numGroupedByCat = numVariable.groupby(catVariable).mean().round(2)\n    \n    # Create subplot object.\n    fig = make_subplots(\n        rows=1,\n        cols=1,\n        print_grid=False,\n    )\n    \n    # This trace plots barplot\n    fig.add_trace(\n        go.Bar(\n            x = numGroupedByCat.index,\n            y = numGroupedByCat,\n            text=numGroupedByCat,\n            hoverinfo=\"x+y\",\n            textposition=\"auto\",\n            textfont=dict(family=\"sans serif\",size=15)\n        ))\n    \n    # Update layout\n    fig.layout.update(\n        height=500, \n        width=900,\n        showlegend=False,\n        title_text= f\"Mean {numVariable.name} across {catVariable.name}\",\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n    \n    # Update axes\n    fig.layout.xaxis1.update(title=f\"<b>{catVariable.name}</b>\")\n    fig.layout.yaxis1.update(title=f\"<b>Mean {numVariable.name}</b>\")\n    return fig.show()\n\n    \n\"\"\"#3.This function plots histogram of numerical variable for every class of categorical variable.\"\"\"\ndef numHistByCat(numVariable,catVariable=df_train.Survived):\n    \"\"\"Returns numerical variable distribution across classes of categorical variable.\"\"\"\n    fig,ax = plt.subplots(1,1,figsize = (18,7))\n    font_size = 15\n    title_size = 18\n    numVariable[catVariable==1].hist(bins=50,color=\"green\", label = \"survived\", grid = False, alpha=0.5)\n    numVariable[catVariable==0].hist(bins=50,color=\"red\", label = \"died\", grid = False, alpha=0.5)\n    ax.set_yticks([])\n    ax.tick_params(axis=\"x\", labelsize=font_size)\n    ax.set_xlabel(f\"{numVariable.name}\", fontsize = font_size)\n    ax.set_title(f\"{numVariable.name} Distribution of Survivors vs Victims\", fontsize = title_size)\n    plt.legend()\n    return plt.show()\n\n   \n\"\"\"#4.Create a function to calculate anova between numerical and categorical variable.\"\"\"\ndef calculateAnova(numVariable, catVariable=df_train.Survived):\n    \"\"\"Returns f statistics and p value after anova calculation.\"\"\"\n    \n    groupNumVariableByCatVariable1 = numVariable[catVariable==1] # Group our numerical variable by categorical variable(1). Group Fair by survivors\n    groupNumVariableByCatVariable0 = numVariable[catVariable==0] # Group our numerical variable by categorical variable(0). Group Fare by victims\n    # Calculate one way anova\n    fValue, pValue = stats.f_oneway(groupNumVariableByCatVariable1, groupNumVariableByCatVariable0) # Calculate f statistics and p value\n    return f\"Anova Result between {numVariable.name} & {catVariable.name}: f=> {fValue}, p=> {pValue}\" \n ### 8.1.1 Fare & Survived <a id=\"8.1.1\"></a> \n \"\"\"Create a boxplot to visualize the strength of association of Survived with Fare. Also calculate biserial correlation.\"\"\"\nboxplotAndCorrelation(df_train.Fare) \n **Findings:** The distribution of Fare between different categories of Survived (0 and 1) are distinct (very least overlap) that makes it comparatively strong predictor for Survived what is kind of true from the correlation value of  0.257307 and the p value (less than 0.01) that suggests we're 99% confident that this correlation is statistically significant. Also survival is positively correlated to Fare, so the more you pay for fare, the more your chances are to survive that is quite evident from the box plot. \n \"\"\"So the mean fare of survivors should be much more (from positive correlation or boxplot interpretation) than those who died. Calculate mean fare paid by the survivors as well as by the victims.\"\"\"\nnumGroupedByCat(df_train.Fare) \n **Looks like, on average, if you pay more for your ticket, you are more likely to survive. Let's plot histogram of survivors and victims fare together to validate our intuition:** \n \"\"\"Plot histogram of survivor's vs victims fare.\"\"\"\nnumHistByCat(df_train.Fare) \n **That's true. Passengers who paid more for their fair, mostly survived.**\n\n**ANOVA:** \nThe ANOVA(ANalysis Of VAriance) test lets us check whether a numeric response variable varies according to the levels (or class) of a categorical variable. When we simply refer to 'ANOVA', we usually mean the 'one way' ANOVA which is a test for exploring the impact of one single factor on three or more groups (but two groups would also do, as we explain below).\n\nThough one should use either point biserial correlation (if categorical variable is of binary type) or ANOVA method for this problem to find any association between a categorical and a numerical variable, I would perform ANOVA too to have an intuition of how ANOVA works. Though ANOVA is usually prefered if the categorical variable having more than two groups, it is also possible to perform ANOVA for a categorical variable with two groups.\n\nThe one-way ANOVA tests whether the mean of some numeric variable differs across the levels of one categorical variable. It essentially answers the question: do any of the group means differ from one another? The null hypothesis is all of the group means are equal. And the alternate hypothesis is any of the group means differ from one another. \n \"\"\"Let's perform ANOVA between Fare and Survived. One can omit this step. I perform just to show how anova is performed if there were more than two groups in our categorical variable.\"\"\"\ncalculateAnova(df_train.Fare) \n **Interpretation of ANOVA result:**\nAs p < 0.05 we state that we have a main interaction effect. This simply means that amongst the groups at least any of the group(or groups) means statistically significantly  differ from one another (true for only more than two groups). However, this result does not identify the sample pair (or pairs) which cause this significance (again true for more than two groups of categorical variable but we have just two groups..i.e., 0 and 1).\nSo, when ANOVA reports 'interaction effect' we need to further identify the group pairs by applying pair-wise controls(required for more than two groups of categorical variable). Although these controls could be done by implementing ordinary t-test but this is not the right approach. So a post hoc-test ( usually Tukey's test) is performed to find the pair or pairs that cause the difference. Though Tukey's test is not required with a categorical variable less than three groups.\n\n***Note:*** Tukey's test is not required if ANOVA gives a p value greater than 0.05 and nominal variable has less than three groups.  \n \n### 8.1.2 Age & Survived <a id=\"8.1.2\"></a> \n \"\"\"Let's create a box plot between Age and Survived to have an idea by how much Age is associated with Survived. Also find point biserial correlation between them.\"\"\"\nboxplotAndCorrelation(df_train.Age) \n **Findings:** Box plot shows the distribution of Age between categories of Survived (1 and 0) has significant overlap which is also kind of true from a small correlation value of -0.05939. And a p value greater than 0.05 indicates that there is no evidence that the correlation is statistically significant. As we can see that Survived is inversly correlated to Age, so if you are younger, you are just likely to survive. \n \"\"\"So the mean age of survivors should be just less than those who died (small negative correlation and reading boxplot). Calculate the mean age of survivors and victims.\"\"\"\nnumGroupedByCat(df_train.Age) \n **Analysing box and above bar plot, we have a feeling that younger people, on average, were just more likely to survive. Let's plot one histogram of survivors' age and another of victims' age to validate our intuition.** \n \"\"\"Histogram of survivors vs victims age.\"\"\"\nnumHistByCat(df_train.Age) \n **We see infants and children had high survival rate. The oldest passengers (Age = 80) also survived. A large number of passengers aged from 16 to 30 died.** \n \"\"\"Perform ANOVA between all the levels of Survived (i.e., 0 and 1) and Age.\"\"\"\ncalculateAnova(df_train.Age) \n **Note:** Choose either biserial correlation (if categorical variable has two groups) or Anova. If anova states main interaction effect(i.e.,p<0.05) and categorical variable has more than two categories ( like good, better, best), then perform tukey test to find out the pair or pairs that cause the difference(i.e., main interaction effect).\n\n**Interpretation of ANOVA result:**\nSince p>0.05, we can say that survival chance is not statistically associated with Age.\n\n## 8.2 Categorical & Categorical Variables <a id=\"8.2\"></a>\nWe will calculate and plot absolute and relative frequency of output categorical variable by predictor nominal variables. We would calculate the chi square test between target nominal and predictor nominal variables. Finally we will calculate Bonferroni-adjusted P value if the contingency table has dimension more than 2x2. \n \"\"\"#1.Create a function that calculates absolute and relative frequency of Survived variable by a categorical variable. And then plots the absolute and relative frequency of Survived by a categorical variable.\"\"\"\ndef calculateCrosstabulation(catVariable, targetCatVariable=df_train.Survived):\n    \"\"\" Plots cross tabulation in absolute and relative scale.\n    catVariable = input categorical variable, \n    targetCatVariable = our target categorical variable.\"\"\"\n    \n    # Calculate cross tabulation in abs and relative scale\n    absCount = pd.crosstab(index = catVariable, columns = targetCatVariable)\\\n    .rename(columns={0:\"Victims\",1:\"Survivors\"})\n    relCount = pd.crosstab(index = catVariable, columns = targetCatVariable, normalize=\"index\")\\\n    .rename(columns={0:\"Victims\",1:\"Survivors\"})*100\n    relCount = relCount.round(1)\n    \n    # Create two subplots of bar chart\n    fig=make_subplots(\n        rows=2, \n        cols=1,\n        vertical_spacing=0.3,\n        subplot_titles=(f\"Absolute Count of Survival and Death by {catVariable.name}\", \n                        f\"Percentage Count of Survival and Death by {catVariable.name}\"),\n        print_grid=False) # This suppresses \"This is the format of your plot grid:\" text from popping out.\n\n    # Add trace for absolute frequency\n    for col in absCount.columns:\n        fig.add_trace(go.Bar(x=absCount.index,\n                             y=absCount[col],\n                             text=absCount[col],\n                             hoverinfo=\"x+y\",\n                             textposition=\"auto\",\n                             name=f\"{col}\",\n                             textfont=dict(family=\"sans serif\",size=14),\n                             ),\n                     row=1,\n                     col=1\n                     )\n\n\n    # Add another trace for relative frequency\n    for col in relCount.columns:\n        fig.add_trace(go.Bar(x=relCount.index,\n                             y=relCount[col],\n                             text=relCount[col],\n                             hoverinfo=\"x+y\",\n                             textposition=\"auto\",\n                             name=f\"{col}\",\n                             textfont=dict(family=\"sans serif\",size=14),\n                            ),\n                     row=2,\n                     col=1\n                     )\n        \n    # Update the layout. Add title, dimension, and background color\n    fig.layout.update(\n        height=600, \n        width=1000,\n        hovermode=\"closest\",\n        barmode = \"group\",\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n\n    # Set y-axes titles in bold\n    fig.layout.yaxis1.update(title=\"<b>Abs Frequency</b>\")\n    fig.layout.yaxis2.update(title=\"<b>Rel Frequency(%)</b>\")\n    \n    # Set x-axis title in bold\n    fig.layout.xaxis2.update(title=f\"<b>{catVariable.name}</b>\")\n    return fig.show()\n\n    \n\"\"\"#2.Create a function to calculate chi square test between a categorical and target categorical variable.\"\"\"\ndef calculateChiSquare(catVariable, targetCatVariable=df_train.Survived):\n    \"\"\"Returns chi square test restult between independent and dependent target variables.\"\"\"\n    \n    catGroupedByCatTarget = pd.crosstab(index = catVariable, columns = targetCatVariable)\n    testResult = stats.chi2_contingency(catGroupedByCatTarget)\n    print(f\"Chi Square Test Result between {targetCatVariable.name} & {catVariable.name}:\")\n    return print(testResult)\n\n\n\"\"\"#3.Finally create another function to calculate Bonferroni-adjusted pvalue for a categorical and target categorical variable.\"\"\"\ndef calculateBonferroniAdjusted(catVariable, targetCatVariable=df_train.Survived):\n    \"\"\"Returns bonferroni-adjusted pvalue between independent and dependent target variables.\"\"\"\n    \n    # Create one hot encoding for the independent categorical variable\n    catEncoded = pd.get_dummies(catVariable)\n    for column in catEncoded.columns:\n        catGroupedByCatTarget = pd.crosstab(index = catEncoded[column], columns = targetCatVariable)\n        testResult = stats.chi2_contingency(catGroupedByCatTarget)\n        print(f\"Bonferroni-adjusted pvalue between {catVariable.name}({column}) and {targetCatVariable.name}:\")\n        print(f\"{testResult}\\n\") \n ### 8.2.1 Sex & Survived <a id=\"8.2.1\"></a> \n \"\"\"Plot the no of passergers who survived and died due to their sex in absolute and relative scale.\"\"\"\ncalculateCrosstabulation(df_train.Sex) \n **Findings:** Out of 342 survivors, 233 passergers were female while only 109 passengers were male. So female survivors were more than double the male survivors. Proportion tells a female has over 74% chance of survival while male has almost 19% chance of survival. So female has the best chance of survival.\n\n***Chi-square Test***: The Chi-square test of independence tests if there is a significant relationship between two categorical variables.The data is usually displayed in a cross-tabulation format with each row representing a category for one variable and each column representing a category for another variable. Chi-square test of independence is an omnibus test.That is it tests the data as a whole. This means that one will not be able to tell which levels (categories) of the variables are responsible for the relationship **if the Chi-square table is larger than 2\u00d72. If the test is larger than 2\u00d72, it requires post hoc testing.**\n\n**The H0 (Null Hypothesis): There is no relationship between variable 1 and variable 2.**\n\n**The H1 (Alternative Hypothesis): There is a relationship between variable 1 and variable 2.**\n\nIf the p-value is significant (less than 0.05), you can reject the null hypothesis and claim that the findings support the alternate hypothesis. While we check the results of the chi2 test, we need also to check that the expected cell frequencies are greater than or equal to 5. If a cell has an expected frequency less that 5, then the Fisher\u2019s Exact test should be use to overcome this problem.\n\nThe chi2_contingency() method conducts the Chi-square test on a contingency table (crosstab). \n \"\"\"Perform chi-square test of independence between Survived and Sex.\"\"\"\ncalculateChiSquare(df_train.Sex) \n ***Interpretation of chi-square test outcome***: The first value (260.717) is the Chi-square value, followed by the p-value (1.197e-58), then comes the degrees of freedom (1), and lastly it outputs the expected frequencies as an array. Since all of the expected frequencies are greater than 5, the chi2 test results can be trusted. We can reject the null hypothesis as the p-value is less than 0.05(infact p value is almost 0).  Thus, the results indicate that there is a statistically significant relationship between Sex and Survived.\n\n### 8.2.2 Pclass & Survived <a id=\"8.2.2\"></a> \n \"\"\"Plot the number of passengers who survived and died due to their pclass in absolute and relative scale.\"\"\"\ncalculateCrosstabulation(df_train.Pclass) \n **Findings:** Out of 342 survivors, pclass1(136) has the most number of survivors followed by pclass3(119) and pclass2(87). But the percentage tells different story. If you're in class1, your survival chance is nearly 63% while pclass2 has just over 47% survival chance. But if you are in class3, your chance of survival is very bleak, i.e.,just over 24%. \n \"\"\"Perform chi-square test of independence between Survived and Pclass.\"\"\"\ncalculateChiSquare(df_train.Pclass) \n **Interpretation of chi-square test outcome:** The overall 3x2 table has a chi-square value of 102.889, pvalue  of 4.549e-23, degrees of freedom of 2 and the rest are the expected frequencies of array. Since all of the expected frequencies are greater than 5, the chi2 test results can be trusted. We can reject the null hypothesis as the p-value is less than 0.05(infact p value is almost 0). Thus, the results indicate that there is a statistically significant relationship between Pclass and titanic's survivors. \n\n\n**Post Hoc Test**: Although our Chi-square test was signficant, since our analysis is 3x2 we don't know which levels of Pclass(1, 2 or 3) have the strongest association with variable Survived. Hence we need to perform a post hoc test to verify if and which combinations are actually significantly associated with Survived. In order to do this, we need to conduct multiple 2\u00d72 Chi-square tests using the *Bonferroni-adjusted p-value.*\n\nTo conduct multiple 2\u00d72 Chi-square tests, one needs to regroup the variables for each test to where it is one category against the rest. For us, it will be:\n\n1. 1 vs 2\n2. 1 vs 3\n3. And finally 2 vs 3\n\n**Because there are 3 comparisons, the Bonferroni-adjusted P value needed for significance is 0.05/3, or 0.017. So for our any planned pairwise comparisons to be significant, the p-value must be less than 0.017.** \n \"\"\"Calculate Bonferroni-adjusted pvalue for Pclass (1,2,3) and Survived.\"\"\"\ncalculateBonferroniAdjusted(df_train.Pclass) \n **Interpretation of the outcome of  Bonferroni-adjusted p-value test:** Using the Bonferroni-adjusted p-value of 0.017, 3 out of 3 planned pairwise comparisons are significant. Though p value suggests Pclass2 has the weakest association with Survived compared to Pclass1 and Pclass3.\n\n###  8.2.3 Embarked & Survived <a id=\"8.2.3\"></a> \n \"\"\"Count and plot the survivors and victims by place of embarkation in absolute and relative scale.\"\"\"\ncalculateCrosstabulation(df_train.Embarked) \n **Findings:** Though people embarked from Southampton have the most survivors count (219) but proportion-wise it has only nearly 34% chance of survival. Because 427 passengers embarked from Southampton died. On the contrary, if you would embark from Cherbourg, you have a very decent chance of survival of over 55%.  Finally, people embarked from  Queenstown have a chance of survival more than 5% from those who embarked from Southampton. \n \"\"\"Now perform chi-square test to find the association between Embarked and Survived.\"\"\"\ncalculateChiSquare(df_train.Embarked) \n **Interpretation of chi-square test result:** The  3x2 table has a chi-square value of 25.96, pvalue of 2.3e-06, degrees of freedom of 2 and the rest are the expected frequencies of array. Since all of the expected frequencies are greater than 5, the chi2 test results can be trusted. We can reject the null hypothesis as the p-value is less than 0.05(infact p value is less than 0.01). Thus, the results indicate that there is a statistically significant relationship between the variables Embarked and Survived.\n\n**Because there are three comparisons, the Bonferroni-adjusted P value needed for significance is 0.05/3, or 0.017. So for our any planned pairwise comparisons to be significant, the p-value must be less than 0.017.** \n \"\"\"Calculate Bonferroni-adjusted pvalue  between Embarked (C,Q,S one by one) and Survived.\"\"\"\ncalculateBonferroniAdjusted(df_train.Embarked) \n **Interpreting the result of pair-wise Bonferroni-adjusted pvalue:** Using the Bonferroni-adjusted p-value of 0.017, 2 of the 3 planned pairwise comparisons are significant. Bonferroni-adjusted p-value for Q and Survived is 0.989 which is way greater than 0.017. So it can be said that level Q of variable Embarked is not statistically associated with variable Survived.\n\n### 8.2.4 SibSp & Survived <a id=\"8.2.4\"></a> \n \"\"\"Count and plot absolute and relative number of survivors and victims due to SibSp.\"\"\"\ncalculateCrosstabulation(df_train.SibSp) \n **Findings:** A large number of passengers (210) who survived were without (0) any siblings or spouse, followed by 112 passengers with 1 spouse or siblings. Percentage-wise, passengers with 1 spouse or siblings had over 53.5% chance of survival, followed by passengers with 2 siblings or spouse had over 46% chance of survival. Passengers with 5 or 8 siblings or spouse had all died. \n \"\"\"Chi-square test between SibSp and Survived.\"\"\"\ncalculateChiSquare(df_train.SibSp) \n **Interpretation of Chi-square Test:**  Since all the expected frequencies aren't greater than 5, chi-square test result can't be trusted.\n\n### 8.2.5 Parch & Survived  <a id=\"8.2.5\"></a> \n \"\"\"Visualize absolute and relative number of survivors and victims by Parch.\"\"\"\ncalculateCrosstabulation(df_train.Parch) \n **Findings:** Passengers with 3 children/parent had 60% survival rate, followed by passengers with 2 children/parent has a 50% survival rate. No passengers survived with 4 or 6 children/parent. \n \"\"\"Perform Chi-square test of independence between Parch and Survived.\"\"\"\ncalculateChiSquare(df_train.Parch) \n **Interpretation of Chi-square Test Outcome:**  Since all the expected frequencies aren't greater than 5, chi-square test result can't be trusted.\n\n### 8.2.6 nameProcessed & Survived <a id=\"8.2.6\"></a> \n \"\"\"Visualize absolute and relative number of survivors and victims by nameProcessed.\"\"\"\ncalculateCrosstabulation(df_train.nameProcessed) \n **Findings:** Women had the best survival rate, i.e., Mrs(over 79%) and Miss(over 70%) that reminds us the variable Sex where we have seen female were more likely to survive in. Mr is the worst title to have when it comes to survival situation since just over 15% of passengers with title Mr survived that again indicates the importance of Sex as a deal breaker for survival. \n \"\"\"Perform Chi-square test of independence between nameProcessed and Survived.\"\"\"\ncalculateChiSquare(df_train.nameProcessed) \n **Interpretation of chi-square test result**: Since all the expected frequencies aren't greater than 5, chi-square test result can't be trusted.\n\n### 8.2.7 familySize & Survived <a id=\"8.2.7\"></a> \n \"\"\"Plot the Survived's absolute and percentage count by familySize.\"\"\"\ncalculateCrosstabulation(df_train.familySize) \n **Findings:** Passengers with small and medium familiy size had good survival rate. Single passengers had survival chance of just over 30%. And passengers with large families has a survival rate below 15%. \n \"\"\"Perform Chi-square test of independence between familySize and Survived.\"\"\"\ncalculateChiSquare(df_train.familySize) \n **Interpretation of chi-square test result**:Since all of the expected frequencies are greater than 5, the chi2 test results can be trusted. We can reject the null hypothesis as the p-value is less than 0.05(infact p value is almost 0). Thus, the results indicate that there is a statistically significant relationship between variable Family_size and Survived.\n\n**Because there are 8 comparisons, the Bonferroni-adjusted P value needed for significance is 0.05/8, or 0.0063. So for our any planned pairwise comparisons to be significant, the p-value must be less than 0.0063.** \n \"\"\"Calculate Bonferroni-adjusted pvalue  between familySize and Survived.\"\"\"\ncalculateBonferroniAdjusted(df_train.familySize) \n **Interpretation of Bonferroni-adjusted Post-hoc test result:** Using the Bonferroni-adjusted p-value of 0.0063, 3 of the 4 planned pairwise comparisons are significant. Bonferroni-adjusted p-value for medium and Survived is 0.03555 which is way greater than 0.0063. So it can be said that level medium of variable familySize is not statistically associated with variable Survived.\n\n### 8.2.8 cabinProcessed & Survived <a id=\"8.2.8\"></a> \n \"\"\"Count and plot absolute and relative number of survivors and victims due to cabin possession.\"\"\"\ncalculateCrosstabulation(df_train.cabinProcessed) \n **Findings:** Most of the passengers survived and died were from cabin X. But percentage-wise, its category B, D, and E that had impressive chance of survival. People from cabin category X had just 30% chance of survival. \n \"\"\"Perform Chi-square test of independence between Cabin and Survived.\"\"\"\ncalculateChiSquare(df_train.cabinProcessed) \n **Interpretation of chi-square test result**: Since all of the expected frequencies aren't greater than 5, the chi2 test results can't be trusted.\n\n### 8.2.9 ticketProcessed & Survived <a id=\"8.2.9\"></a> \n \"\"\"Count and plot absolute and relative number of survivors and victims due to ticketProcessed category.\"\"\"\ncalculateCrosstabulation(df_train.ticketProcessed) \n **Findings:** 93% passengers died with ticket category A, over 64% survived from category P. Over 57% survived from F and just over 15% passengers survived from ticket category W. \n \"\"\"Perform Chi-square test of independence between ticketProcessed and Survived.\"\"\"\ncalculateChiSquare(df_train.ticketProcessed) \n **Interpretation of chi-square test result**: Since all of the expected frequencies aren't greater than 5, the chi2 test results can't be trusted.\n\n# 9.Multivariate Analysis <a id=\"9\"></a>\nIn multivariate analysis, we try to find the relationship among more than two variables. Number of predictor variable in bivariate analysis was one. On the contrary, number of predictor variables for multivariate analysis are more than one. More specifically, we will try to associate more than one predictor variable with the response variable. We will just visualize the impact of different predictor variables (3 variables) at a time on variable Survived. \n \"\"\"Create a function that plots the impact of 3 predictor variables at a time on a target variable.\"\"\"\ndef doMultivariateAnalysis(catVar1, catVar2, catVar3, targetCatVariable=df_train.Survived):\n    \"\"\"Plots the impact of 3 variables on Survived variable at the same time.\n    catVar1 = independent categorical variable 1,\n    catVar2 = independent categorical variable 2,\n    catVar3 = independent categorical variable 3.\n    targetCatVariable = our dependent categorical variable.\"\"\"\n    \n    fig,ax = plt.subplots(1,1,figsize = (18,5))\n    fontSize = 15\n    catGroupedByCatTarget = pd.crosstab(index = [catVar1, catVar2, catVar3],\n                                        columns = targetCatVariable, normalize = \"index\")*100\n    catGroupedByCatTarget.rename({0:\"%Died\", 1:\"%Survived\"}, axis = 1, inplace = True)\n    catGroupedByCatTarget.plot.bar(color = [\"red\", \"green\"],ax=ax)\n    ax.set_xlabel(f\"{catVar1.name},{catVar2.name},{catVar3.name}\", fontsize = fontSize)\n    ax.set_ylabel(\"Relative Frequency(%)\", fontsize = fontSize)\n    ax.tick_params(axis=\"x\", labelsize=fontSize)\n    ax.tick_params(axis=\"x\", labelsize=fontSize)\n    plt.legend(loc = \"best\")\n    return plt.show() \n ## 9.1 (Pclass, Sex, cabinProcessed) vs Survived <a id=\"9.1\"></a> \n \"\"\"Proportion of survivors and victims due to pclass, sex, and cabinProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.cabinProcessed)\nbold(\"Findings: Sex male seems to be deciding factor for death.\") \n ## 9.2 (Pclass, Sex, Embarked) vs Survived <a id=\"9.2\"></a> \n \"\"\"Proportion of survivors and victims due to pclass, sex, and embarked.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.Embarked)\nbold(\"Findings: Again Sex male seems to be deciding factor for death and female for survival.\") \n ## 9.3 (Pclass, Sex, SibSp) vs Survived <a id=\"9.3\"></a> \n \"\"\"Proportion of survivors and victims due to pclass, sex, and SibSp.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.SibSp)\nbold(\"Findings: Bigger SibSp and male Sex is responsible more for death.\") \n ## 9.4 (Pclass, Sex, Parch) vs Survived <a id=\"9.4\"></a> \n \"\"\"Proportion of survivors and victims due to pclass, sex, and Parch.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.Parch)\nbold(\"indings: Bigger Parch and Sex male is responsible more for death.\") \n ## 9.5 (Pclass, Sex, nameProcessed) vs Survived <a id=\"9.5\"></a> \n \"\"\"Proportion of survivors and victims due to pclass, sex, and nameProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.nameProcessed)\nbold(\"Findings: Findings: Passengers with sex male and title mr mostly died.\") \n ## 9.6 (Pclass, Sex, familySize) vs Survived <a id=\"9.6\"></a> \n \"\"\"Proportion of survivors and victims due to pclass, sex, and familySize.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.familySize)\nbold(\"Findings: Sex male, family size single and large greatly influence the death ratio.\") \n ## 9.7 (Pclass, Sex, ticketProcessed) vs Survived <a id=\"9.7\"></a> \n \"\"\"Proportion of survivors and victims due to pclass, sex, and ticketProcessed category.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.ticketProcessed)\nbold(\"Findings: Sex female, ticketProcessed p and w mostly survived.\") \n ## 9.8 (Pclass, nameProcessed, cabinProcessed) vs Survived <a id=\"9.8\"></a> \n \"\"\"Proportion of survivors and victims due to pclass, nameProcessed, and cabinProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.nameProcessed, df_train.cabinProcessed)\nbold(\"Findings: Title mrs, master and cabin x had best survival ratio.\") \n ## 9.9 (familySize, Sex, cabinProcessed) vs Survived <a id=\"9.9\"></a> \n \"\"\"Proportion of survivors and victims due to familSize, sex, and cabinProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.familySize, df_train.Sex, df_train.cabinProcessed)\nbold(\"Findings: family size small, medium and sex female had best survival chance.\") \n ## 9.10 (Sex, nameProcessed, familySize) vs Survived <a id=\"9.10\"></a> \n \"\"\"Proportion of survivors and victims due to sex, nameProcessed, and familySize.\"\"\"\ndoMultivariateAnalysis(df_train.Sex, df_train.nameProcessed, df_train.familySize)\nbold(\"Findings: Title aristocrat, sex female and familySize small mostly survived.\") \n ## 9.11 (Sex, nameProcessed, cabinProcessed) vs Survived <a id=\"9.11\"></a> \n \"\"\"Proportion of survivors and victims due to sex, nameProcessed, and cabinProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.Sex, df_train.nameProcessed, df_train.cabinProcessed)\nbold(\"Findings: Title aristocrat, miss, mrs and sex female mostly survived.\") \n ## 9.12 (Sex, nameProcessed, Embarked) vs Survived <a id=\"9.12\"></a> \n \"\"\"Proportion of survivors and victims due to sex, nameProcessed, and embarked.\"\"\"\ndoMultivariateAnalysis(df_train.Sex, df_train.nameProcessed, df_train.Embarked)\nbold(\"Findings: Embarked c, sex female and title master and aristocrat had best survival rate.\") \n ## 9.13 (Sex, nameProcessed, ticketProcessed) vs Survived <a id=\"9.13\"></a> \n \"\"\"Proportion of survivors and victims due to sex, nameProcessed, and ticketProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.Sex, df_train.nameProcessed, df_train.ticketProcessed)\nbold(\"Findings: ticketProcessed n, w and sex male and title mr mostly died.\") \n # 10.Data Transformation <a id=\"10\"></a>\nIn this section, we will categorize our continuous variables. After that, redundant and useless features will be dropped. And finally categorical variables will be encoded into numerical variables to feed our machine learning models.\n\n## 10.1 Binning Continuous Variables <a id=\"10.1\"></a>\nWe saw Age is inversely correlated with survival and infants were more likely to survive. We will create some categories of age to check which categories of age  are more likely to survive. We would do the same for Fare except Fair is posivively correlated with Survived.\n\n**Note:** Binning continuous variables prevents overfitting which is a common problem for tree based models like decision trees and random forest etc.\n\n### 10.1.1 Binning Age <a id=\"10.1.1\"></a> \n \"\"\"Create bin categories for Age.\"\"\"\nageGroups = [\"infant\",\"child\",\"teenager\",\"youngAdult\",\"adult\",\"aged\"]\n\n\"\"\"Create range for each bin categories of Age.\"\"\"\ngroupRanges = [0,5,12,18,35,60,81]\n\n\"\"\"Create and view categorized Age with original Age.\"\"\"\nmerged[\"ageBinned\"] = pd.cut(merged.Age, groupRanges, labels = ageGroups)\nbold('**Age with Categorized Age:**')\ndisplay(merged[['Age', 'ageBinned']].head(2)) \n ### 10.1.2 Binning Fare <a id=\"10.1.2\"></a> \n \"\"\"Create bin categories for Fare.\"\"\"\nfareGroups = [\"low\",\"medium\",\"high\",\"veryHigh\"]\n\n\"\"\"Create range for each bin categories of Fare.\"\"\"\nfareGroupRanges = [-1, 130, 260, 390, 520]\n\n\"\"\"Create and view categorized Fare with original Fare.\"\"\"\nmerged[\"fareBinned\"] = pd.cut(merged.Fare, fareGroupRanges, labels = fareGroups)\nbold(\"Fare with Categorized Fare:\")\ndisplay(merged[[\"Fare\", \"fareBinned\"]].head(2)) \n ##  10.2 Dropping Features <a id=\"10.2\"></a>\nNow we have both transformed and the original variables transformation have been made from. So we should safely drop the variables that we think would not be useful anymore for our survival analysis since they are very unlikely to be analyzed in their raw forms. \n display(merged.head(2)) \n \"\"\"Let's see all the variables we currently have with their category.\"\"\"\ndisplay(merged.head(2))\n\n\"\"\"Drop the features that would not be useful anymore.\"\"\"\nmerged.drop(columns = [\"Name\", \"Age\", \"Fare\", \"Ticket\", \"Cabin\"], inplace = True, axis = 1)\n\n\"\"\"Features after dropping.\"\"\"\nbold(\"Features Remaining after Dropping:\")\ndisplay(merged.columns) \n ## 10.3 Correcting Data Types <a id=\"10.3\"></a> \n \"\"\"Checking current data types.\"\"\"\nbold(\"Current Variable Data Types:\")\ndisplay(merged.dtypes) \n 1. PassengerId, SibSp, and Parch data types will be kept same (integer).\n2. Survived data type will be converted into integer and rest of the variables' data types will be converted into categorical data types. \n \"\"\"Correcting data types, converting into categorical variables.\"\"\"\nmerged.loc[:, [\"Pclass\", \"Sex\", \"Embarked\", \"cabinProcessed\", \"nameProcessed\", \"familySize\", \"ticketProcessed\"]]\\\n= merged.loc[:, [\"Pclass\", \"Sex\", \"Embarked\", \"cabinProcessed\", \"nameProcessed\", \"familySize\", \"ticketProcessed\"]]\\\n.astype('category') \n \"\"\"Check if data types have been corrected.\"\"\"\nbold(\"Data Types after Correction:\")\ndisplay(merged.dtypes) \n ## 10.4 Encoding Categorical Variables <a id=\"10.4\"></a>\nWe would like to use one hot encoding instead of label encoding because algorithm might give weights to higher values if label encoding is used to encode numeric variables. \n \"\"\"Convert categorical data into numeric to feed our machine learning model.\"\"\"\nmerged = pd.get_dummies(merged)\n\n\"\"\"Let's visualize the updated dataset that would be fed to our machine learning algorithms.\"\"\"\nbold(\"Preview of Processed Data:\")\ndisplay(merged.head(2)) \n # 11.Model Building and Evaluation <a id=\"11\"></a>\nWith all the preprocessings done and dusted, we're ready to train classifiers with the processed data. First extract train and test data from variable merged. Then feed the training data to the classifiers we're interested in for this problem. \n \"\"\"Set a seed for reproducibility\"\"\"\nseed = 43\n\n\"\"\"Let's split the train and test set to feed machine learning algorithm.\"\"\"\ntrain = merged.iloc[:891, :]\ntest  = merged.iloc[891:, :] \n \"\"\"Drop passengerid from train set and Survived from test set.\"\"\"\ntrain = train.drop(columns = [\"PassengerId\"], axis = 1)\ntrain.Survived = train.Survived.astype(int) # Converts Survived to int requored for submission, otherwise\ntest = test.drop(columns = [\"Survived\"], axis = 1) # you will scored 0 on submission. \n \"\"\"Extract data sets as input and output for machine learning models.\"\"\"\nxTrain = train.drop(columns = [\"Survived\"], axis = 1) # Input matrix as pandas dataframe (dim:891*47).\nyTrain = train['Survived'] # Output vector as pandas series (dim:891*1)\n\n\"\"\"Extract test set\"\"\"\nxTest  = test.drop(\"PassengerId\", axis = 1).copy() \n \"\"\"See the dimensions of input and output data set.\"\"\"\nprint(f\"Input Matrix Dimension: {xTrain.shape}\")\nprint(f\"Output Vector Dimension: {yTrain.shape}\")\nprint(f\"Test Data Dimension: {xTest.shape}\") \n ## 11.1 Training Model <a id=\"11.1\"></a>\nWe would train 10 different classifiers for this binary classification problem. \n \"\"\"Building machine learning models: \nWe will try 10 different classifiers to find the best classifier after tunning model's hyperparameters that will best generalize the unseen(test) data.\"\"\"\n\n\"\"\"Now initialize all the classifiers object.\"\"\"\n\"\"\"#1.Logistic Regression\"\"\"\nlr = LogisticRegression()\n\n\"\"\"#2.Support Vector Machines\"\"\"\nsvc = SVC(gamma = \"auto\")\n\n\"\"\"#3.Random Forest Classifier\"\"\"\nrf = RandomForestClassifier(random_state = seed, n_estimators = 100)\n\n\"\"\"#4.KNN\"\"\"\nknn = KNeighborsClassifier()\n\n\"\"\"#5.Gaussian Naive Bayes\"\"\"\ngnb = GaussianNB()\n\n\"\"\"#6.Decision Tree Classifier\"\"\"\ndt = DecisionTreeClassifier(random_state = seed)\n\n\"\"\"#7.Gradient Boosting Classifier\"\"\"\ngbc = GradientBoostingClassifier(random_state = seed)\n\n\"\"\"#8.Adaboost Classifier\"\"\"\nabc = AdaBoostClassifier(random_state = seed)\n\n\"\"\"#9.ExtraTrees Classifier\"\"\"\netc = ExtraTreesClassifier(random_state = seed)\n\n\"\"\"#10.Extreme Gradient Boosting\"\"\"\nxgbc = XGBClassifier(random_state = seed)\n\n\n\"\"\"List of all the models with their indices.\"\"\"\nmodelNames = [\"LR\", \"SVC\", \"RF\", \"KNN\", \"GNB\", \"DT\", \"GBC\", \"ABC\", \"ETC\", \"XGBC\"]\nmodels = [lr, svc, rf, knn, gnb, dt, gbc, abc, etc, xgbc] \n \"\"\"Create a function that returns train accuracy of different models.\"\"\"\ndef calculateTrainAccuracy(model):\n    \"\"\"Returns training accuracy of a model.\"\"\"\n    \n    model.fit(xTrain, yTrain)\n    trainAccuracy = model.score(xTrain, yTrain)\n    trainAccuracy = round(trainAccuracy*100, 2)\n    return trainAccuracy\n\n# Calculate train accuracy of all the models and store them in a dataframe\nmodelScores = list(map(calculateTrainAccuracy, models))\ntrainAccuracy = pd.DataFrame(modelScores, columns = [\"trainAccuracy\"], index=modelNames)\ntrainAccuracySorted = trainAccuracy.sort_values(by=\"trainAccuracy\", ascending=False)\nbold(\"Training Accuracy of the Classifiers:\")\ndisplay(trainAccuracySorted) \n **Looks like all the tree based models have highest train accuracy followed KNN, LR, ABC and SVC. But train accuracy of a model is not enough to tell if a model can be able to generalize the unseen data or not. Because training data is something our model has been trained with, i.e., data our model has already seen it. We all know that, the purpose of building a machine learning model is to generalize the unseen data, i.e., data our model has not yet seen. Hence we can't use training accuracy for our model evaluation rather we must know how our model will perform on the data our model is yet to see.**\n\n## 11.2 Model Evaluation <a id=\"11.2\"></a>\nSo basically, to evaluate a model's performance, we need some data (input) for which we know the ground truth(label). For this problem, we don't know the ground truth for the test set but we do know for the train set. So the idea is to train and evaluate the model performance on different data. One thing we can do is to split the train set in two groups, usually in 80:20 ratio. That means we would train our model on 80% of the training data and we reserve the rest 20% for evaluating the model since we know the ground truth for this 20% data. Then we can compare our model prediction with this ground truth (for 20% data). That's how we can tell how our model would perform on unseen data. This is the first model evaluation technique. In sklearn we have a train_test_split method for that.\n\nTrain_test split has its drawbacks. Because this approach introduces bias as we are not using all of our observations for testing and also we're  reducing the train data size. To overcome this we can use a technique called cross validation where all the data is used for training and testing periodically. Thus we may reduce the bias introduced by train_test_split. From different cross validation methods, we would use k-fold cross validation. In sklearn we have a method cross_val_score for calculating k-fold cross validation score.\n\nHowever,  as the train set gets larger, train_test_split has its advantage over k-fold cross validation. Train_test_split is k-times faster than k-fold cross validation. If the training set is very large, both train_test_split and k-fold cross validation perform identically. So for a large training data, train_test_split is prefered over k-fold cross validation to accelerate the training process.\n\n### 11.2.1 K-Fold Cross Validation <a id=\"11.2.1\"></a>\nLet's say we will use 10-fold cross validation. So k = 10 and we have total 891 observations. Each fold would have 891/10 = 89.1 observations. So basically k-fold cross validation uses fold-1 (89.1 samples) as the testing set and k-1 (9 folds) as the training sets and calculates test accuracy.This procedure is repeated k times (if k = 10, then 10 times); each time, a different group of observations is treated as a validation or test set. This process results in k estimates of the test accuracy which are then averaged out. \n \"\"\"Create a function that returns mean cross validation score for different models.\"\"\"\ndef calculateXValScore(model):\n    \"\"\"Returns models' cross validation scores.\"\"\"\n    \n    xValScore = cross_val_score(model, xTrain, yTrain, cv = 10, scoring=\"accuracy\").mean()\n    xValScore = round(xValScore*100, 2)\n    return xValScore\n\n# Calculate cross validation scores of all the models and store them in a dataframe\nmodelScores = list(map(calculateXValScore, models))\nxValScores = pd.DataFrame(modelScores, columns = [\"xValScore\"], index=modelNames)\nxValScoresSorted = xValScores.sort_values(by=\"xValScore\", ascending=False)\nbold(\"Models 10-fold Cross Validation Score:\")\ndisplay(xValScoresSorted) \n **I've always found that trying out multiple algorithms on the same problem reveals very interesting differences in the patterns the algorithms pick up well. Algorithms disagree on predictions because they've different ways of viewing the data.**\n\n**Findings:** Looks like LR and SVC have the highest cross validation accuracy among the classifiers, followed by GBC, XGBC, KNN, ABC, RF, and ETC.\n\n## 11.2.2 Tuning Hyperparameters  <a id=\"11.2.2\"></a>\n**Now let's add Grid Search to all the classifiers with the hopes of optimizing their hyperparameters and thus improving their accuracy. Are the default model parameters the best bet? Let's find out.**\n\n**Note:** Hyperparameters should be tuned for all the models you try because only then you will be able to tell what is the best you can get out of that particular model. \n \"\"\"Define all the models\" hyperparameters one by one first::\"\"\"\n\n\"\"\"Define hyperparameters the logistic regression will be tuned with. For LR, the following hyperparameters are usually tunned.\"\"\"\nlrParams = {\"penalty\":[\"l1\", \"l2\"],\n            \"C\": np.logspace(0, 4, 10),\n            \"max_iter\":[5000]}\n\n\"\"\"For GBC, the following hyperparameters are usually tunned.\"\"\"\ngbcParams = {\"learning_rate\": [0.01, 0.02, 0.05, 0.01],\n              \"max_depth\": [4, 6, 8],\n              \"max_features\": [1.0, 0.3, 0.1], \n              \"min_samples_split\": [ 2, 3, 4],\n              \"random_state\":[seed]}\n\n\"\"\"For SVC, the following hyperparameters are usually tunned.\"\"\"\nsvcParams = {\"C\": np.arange(6,13), \n              \"kernel\": [\"linear\",\"rbf\"],\n              \"gamma\": [0.5, 0.2, 0.1, 0.001, 0.0001]}\n\n\"\"\"For DT, the following hyperparameters are usually tunned.\"\"\"\ndtParams = {\"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n             \"min_samples_split\": np.arange(2,16), \n             \"min_samples_leaf\":np.arange(1,12),\n             \"random_state\":[seed]}\n\n\"\"\"For RF, the following hyperparameters are usually tunned.\"\"\"\nrfParams = {\"criterion\":[\"gini\",\"entropy\"],\n             \"n_estimators\":[10, 15, 20, 25, 30],\n             \"min_samples_leaf\":[1, 2, 3],\n             \"min_samples_split\":np.arange(3,8), \n             \"max_features\":[\"sqrt\", \"auto\", \"log2\"],\n             \"random_state\":[44]}\n\n\"\"\"For KNN, the following hyperparameters are usually tunned.\"\"\"\nknnParams = {\"n_neighbors\":np.arange(3,9),\n              \"leaf_size\":[1, 2, 3, 5],\n              \"weights\":[\"uniform\", \"distance\"],\n              \"algorithm\":[\"auto\", \"ball_tree\",\"kd_tree\",\"brute\"]}\n\n\"\"\"For ABC, the following hyperparameters are usually tunned.\"\"\"\nabcParams = {\"n_estimators\":[1, 5, 10, 15, 20, 25, 40, 50, 60, 80, 100, 130, 160, 200, 250, 300],\n              \"learning_rate\":[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5],\n              \"random_state\":[seed]}\n\n\"\"\"For ETC, the following hyperparameters are usually tunned.\"\"\"\netcParams = {\"max_depth\":[None],\n              \"max_features\":[1, 3, 10],\n              \"min_samples_split\":[2, 3, 10],\n              \"min_samples_leaf\":[1, 3, 10],\n              \"bootstrap\":[False],\n              \"n_estimators\":[100, 300],\n              \"criterion\":[\"gini\"], \n              \"random_state\":[seed]}\n\n\"\"\"For XGBC, the following hyperparameters are usually tunned.\"\"\"\nxgbcParams = {\"n_estimators\": (150, 250, 350, 450, 550, 650, 700, 800, 850, 1000),\n              \"learning_rate\": (0.01, 0.6),\n              \"subsample\": (0.3, 0.9),\n              \"max_depth\": np.arange(3,10),\n              \"colsample_bytree\": (0.5, 0.9),\n              \"min_child_weight\": [1, 2, 3, 4],\n              \"random_state\":[seed]} \n \"\"\"Create a function to tune hyperparameters of the selected models.\"\"\"\ndef tuneHyperparameters(model, params):\n    \"\"\"Returns best score of a model and its corresponding hyperparameters.\n    model = model to be optimized.\n    params = hyperparameters the models will be optimized with.\"\"\"\n    \n    # Construct grid search object with 10 fold cross validation.\n    gridSearch = GridSearchCV(model, params, verbose=0, cv=10, scoring=\"accuracy\", n_jobs = -1)\n    # Fit using grid search.\n    gridSearch.fit(xTrain, yTrain)\n    bestParams, bestScore = gridSearch.best_params_, round(gridSearch.best_score_*100, 2)\n    return bestScore, bestParams \n **Note:** GridSearchCV will only consider the values for each hyperparameter that you explicitly define here. If you don't \ndefine it in the parameter dictionary object, it will not be included in the grid search.This process of finding the best \nparameters is called exhaustive grid-search because its trying every combination. \n \"\"\"Due to computational restrictions, I won't optimise xgbc's hyperparameters.\"\"\"\nmodelNamesToTune = [x for x in modelNames if x not in [\"GNB\",\"XGBC\"]]\nmodelsToTune = [lr, svc, rf, knn, dt, gbc, abc, etc]\nparametersLists = [lrParams, svcParams, rfParams, knnParams, dtParams, gbcParams, abcParams, etcParams]\nbestScoreAndHyperparameters = list(map(tuneHyperparameters, modelsToTune, parametersLists)) \n \"\"\"Let's create a dataframe to store best score and best params.\"\"\"\nbestScoreAndHyperparameters = pd.DataFrame(bestScoreAndHyperparameters,\n                                             index=modelNamesToTune,\n                                             columns=[\"tunedAccuracy\", \"bestHyperparameters\"])\nbestScoreAndHyperparametersSorted = bestScoreAndHyperparameters.sort_values(by=\"tunedAccuracy\",\n                                                                                ascending=False)\nbold(\"Model's Accuracy after Tuning Hyperparameters:\")\ndisplay(bestScoreAndHyperparametersSorted.iloc[:,0].to_frame()) \n \"\"\"Let's check out LR separately.\"\"\"\nprint(f\"LR Best Score: {bestScoreAndHyperparametersSorted.loc['LR'][0]}\")\nprint(f\"And Best Parameters: {bestScoreAndHyperparametersSorted.loc['LR'][1]}\") \n **Since accuracy increases, it can be said that the most accurate logistic regression model uses C = 2.7825594022071245 and penalty = l2 as hyperparameters.** \n ## 11.2.3  Model Selection <a id=\"11.2.3\"></a>\nLet's compare our models according to their accuracy score after tunning hyperparameters with cross validation scores to select the best models for further study on this classification problem. \n \"\"\"Create a function that compares cross validation scores with tunned scores for different models by\nplotting them.\"\"\"\ndef compareModelsAccuracy():\n    \"\"\"Returns a stack bar chart of tuned and x validation scores of models.\"\"\"\n    \n    # Sort by index and converting to series object to plot.\n    xValScore = xValScoresSorted[~xValScoresSorted.index.isin([\"XGBC\",\"GNB\"])].sort_index().T.squeeze()\n    tunedScore = bestScoreAndHyperparametersSorted.iloc[:,0].sort_index().T.squeeze()\n    \n    # Create two subplots of stack bar chart\n    fig=make_subplots(\n        rows=1, \n        cols=1,\n        vertical_spacing=0.3,\n        print_grid=False) # This suppresses \"This is the format of your plot grid:\" text from popping out.\n\n    # Add trace for stack bar\n    fig.add_trace(go.Bar(x=xValScore.index,\n                             y=xValScore,\n                             text=xValScore,\n                             hoverinfo=\"x+y\",\n                             textposition=\"auto\",\n                             name=\"xValScore\",\n                             textfont=dict(family=\"sans serif\",size=14),\n                             ),\n                     row=1,\n                     col=1\n                     )\n\n    # Add another trace for stack bar\n    fig.add_trace(go.Bar(x=tunedScore.index,\n                             y=tunedScore,\n                             text=tunedScore,\n                             hoverinfo=\"x+y\",\n                             textposition=\"auto\",\n                             name=\"tunedScores\",\n                             textfont=dict(family=\"sans serif\",size=14),\n                             ),\n                     row=1,\n                     col=1\n                     )\n        \n    # Update the layout. Add title, dimension, and background color\n    fig.layout.update(\n        height=600, \n        width=950,\n        hovermode=\"closest\",\n        barmode = \"stack\",\n        title_text = \"Cross Vaidation Scores vs Optimized Scores\",\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n\n    # Set y-axis titles in bold\n    fig.layout.yaxis1.update(title=\"<b>%Accuracy</b>\")\n    \n    # Set x-axis title in bold\n    fig.layout.xaxis1.update(title=\"<b>Models</b>\")\n    return fig.show()\n\n\"\"\"Call the function to plot the scores.\"\"\"\ncompareModelsAccuracy() \n **Findings:** Among the classifiers, RF and GBC have the highest accuracy after  tunning hyperparameters. So RF and GBC are perhaps worthy of further study on this classification problem. Hence we choose RF and GBC.\n\n**Note:** Please note that if we chose our classifier based on cross validation scores, we would not get RF and GBC as our best classifiers instead we would end up choosing LR and SVC. So it is recommended to select best classifiers based on accuracy after tunning hyperparameters though it is computationally intensive.\n\n## 11.3 Retrain and Predict Using Optimized Hyperparameters <a id=\"11.3\"></a>\nSo we have our best classifiers with their best hyperparameters that produces best accuracy out of a model. That means if we retrain the classifiers using their best hyperparameters, we will be able to get the very same score that we got after tunning hyperparameters (see part 14.4). Let's retrain our classifiers and then use cross validation to calculate the accuracy of the trained model. That's how we will have the same accuracy score as after tunning hyperparameters. Let's retrain models with optimized hyperparameters. \n \"\"\"Instantiate the models with optimized hyperparameters.\"\"\"\n# Sort the dataframe by index and select bestHyperparameters column\ntunedParams = bestScoreAndHyperparametersSorted.sort_index().loc[:,\"bestHyperparameters\"]\nabc = AdaBoostClassifier(**tunedParams[\"ABC\"])\ndt  = DecisionTreeClassifier(**tunedParams[\"DT\"])\netc = ExtraTreesClassifier(**tunedParams[\"ETC\"])\ngbc = GradientBoostingClassifier(**tunedParams[\"GBC\"])\nknn = KNeighborsClassifier(**tunedParams[\"KNN\"])\nlr  = LogisticRegression(**tunedParams[\"LR\"])\nrf  = RandomForestClassifier(**tunedParams[\"RF\"])\nsvc = SVC(**tunedParams[\"SVC\"])\n\n\n\n\"\"\"Train all the models with optimised hyperparameters.\"\"\"\nmodels = [abc, dt, etc, gbc, knn, lr, rf, svc]\nmodelNames = tunedParams.index.values\nkeyValue = dict(zip(modelNames, models))\nbold(\"10-fold Cross Validation after Optimization:\")\nxValScore = []\nfor key, value in keyValue.items():\n    # Train the models with optimized parameters using cross validation.\n    # No need to fit the data. cross_val_score does that for us.\n    # But we need to fit train data for prediction in the follow session.\n    value.fit(xTrain, yTrain)\n    scores = cross_val_score(value, xTrain, yTrain, cv = 10, scoring=\"accuracy\")*100\n    xValScore.append(scores.mean())\n    print(\"Mean Accuracy: {:.4f} (+/- {:.4f}) [{}]\".format(scores.mean(), scores.std(), key)) \n **See! We've successfully managed to reproduce the same score that we achived only after tunning hyperparameters. Now if we predict using these trained models, we should have the best test accuracy possible out of those model. So let's predict using those trained models:** \n \"\"\"Make prediction using all the trained models.\"\"\"\nmodelPrediction = pd.DataFrame({\"RF\":rf.predict(xTest),\n                                 \"GBC\":gbc.predict(xTest),\n                                 \"ABC\":abc.predict(xTest),\n                                 \"ETC\":etc.predict(xTest), \n                                 \"DT\":dt.predict(xTest),\n                                 \"SVC\":svc.predict(xTest), \n                                 \"KNN\":knn.predict(xTest), \n                                 \"LR\":lr.predict(xTest)\n                                })\n\n\"\"\"Let\"s see how each model classifies a prticular class.\"\"\"\nbold(\"All the Models Prediction:\")\ndisplay(modelPrediction.head()) \n ## 11.4 Feature Importance <a id=\"11.4\"></a>\nDo the classifiers give the same priority to every feature? Let's visualize the features importance given by our classifiers. \n \"\"\"Create a function that plot feature importance by the selected tree based models.\"\"\"\ndef plotFeatureImportance(model):\n    \"\"\"Return a plot of feature importance by model.\"\"\"\n    \n    importance = pd.DataFrame({\"feature\": xTrain.columns,\n                              \"importance\": np.round(model.feature_importances_,3)})\n    importanceSorted = importance.sort_values(by = \"importance\", ascending = False).set_index(\"feature\")\n    return importanceSorted\n\n\"\"\"Create subplots of feature impotance of rf, gbc, dt, etc, and abc.\"\"\"\nfig, axes = plt.subplots(3,2, figsize = (20,40))\nfig.suptitle(\"Tree Based Models Feature Importance\", fontsize = 28)\ntreeModels = [rf, gbc, dt, etc, abc]\ntreeModelNames = [\"RF\", \"GBC\", \"DT\", \"ETC\", \"ABC\"]\nfor ax, model, name in zip(axes.flatten(), treeModels, treeModelNames):\n    plotFeatureImportance(model).plot.barh(ax=ax, title=name, fontsize=18, color=\"green\")\n    ax.set_ylabel(\"Features\", fontsize = 15)\nfig.delaxes(ax = axes[2,1]) # We don\"t need the last subplot.\nfig.tight_layout(rect = [0, 0.03, 1, 0.97]) \n **Findings:** RF, DT, ETC, and ABC (in particular) give some features no importance (zero importance). On the other hand, GBC give all the features more or less importance but it doesn't give zero importance to any features. These are the tree based models that have 'feature_importances_' method by default. LR, KNN and SVC don't have this method. In this problem, SVC uses rbf kernel (only possible for linear kernel to plot feature importance), so its not possible to view feature importance given by SVC. Though its trickier, we would try to get the feature importance given by LR. \n \"\"\"Let's plot feature importance of LR.\"\"\"\nfig, ax = plt.subplots(figsize=(18,4))\ncoeff = pd.DataFrame({\"feature\":xTrain.columns,\n                      \"importance\":np.transpose(lr.coef_[0])})\n\ncoeff.sort_values(by = \"importance\").set_index(\"feature\")\\\n.plot.bar(title = \"Feature Importance of Linear Model (LR)\", color=\"chocolate\", ax=ax)\nax.tick_params(axis = \"both\", which = \"major\", labelsize = 15)\nax.tick_params(axis = \"both\", which = \"minor\", labelsize = 15)\nax.set_xlabel(\"Feature\", fontsize = 15)\nplt.show() \n **Findings:** We can see some negative values that means that higher value of the corresponding feature pushes the classification more towards the negative class (in our case 0) that is, of course, something we're already aware of. Some features like Family_size_single, Embarked_Q, Embarked_C, and Cabin_F were given zero importance by lr.\n\n## 11.5 Learning Curves  <a id=\"11.5\"></a>\nLet's plot the learning curves for the optimized classifiers to see their bias-variance tradeoff. \n \"\"\"Create a function that returns learning curves for different classifiers.\"\"\"\ndef plotLearningCurve(model):\n    \"\"\"Returns a plot of learning curve of a model.\"\"\"\n    \n    # Create feature matrix and target vector\n    X, y = xTrain, yTrain\n    # Create CV training and test scores for various training set sizes\n    trainSizes, trainScores, testScores = learning_curve(model, X, y, cv = 10,\n                                                    scoring=\"accuracy\", n_jobs = -1, \n                                                    train_sizes = np.linspace(0.01, 1.0, 17), # 17 different sizes of the training set\n                                                    random_state = seed)\n                                                    \n\n    # Create means and standard deviations of training set scores\n    trainMean = np.mean(trainScores, axis = 1)\n    trainStd = np.std(trainScores, axis = 1)\n\n    # Create means and standard deviations of test set scores\n    testMean = np.mean(testScores, axis = 1)\n    testStd = np.std(testScores, axis = 1)\n\n    # Draw lines\n    plt.plot(trainSizes, trainMean, \"o-\", color = \"red\",  label = \"training score\")\n    plt.plot(trainSizes, testMean, \"o-\", color = \"green\", label = \"cross-validation score\")\n    \n    # Draw bands\n    plt.fill_between(trainSizes, trainMean - trainStd, trainMean + trainStd, alpha = 0.1, color = \"r\") # Alpha controls band transparency.\n    plt.fill_between(trainSizes, testMean - testStd, testMean + testStd, alpha = 0.1, color = \"g\")\n\n    # Create plot\n    font_size = 15\n    plt.xlabel(\"Training Set Size\", fontsize = font_size)\n    plt.ylabel(\"Accuracy Score\", fontsize = font_size)\n    plt.xticks(fontsize = font_size)\n    plt.yticks(fontsize = font_size)\n    plt.legend(loc = \"best\")\n    plt.grid() \n \"\"\"Now plot learning curves of the optimized models in subplots.\"\"\"\nplt.figure(figsize = (25,25))\nlcModels = [rf, gbc, dt, etc, abc, knn, svc, lr]\nlcLabels = [\"RF\", \"GBC\", \"DT\", \"ETC\", \"ABC\", \"KNN\", \"SVC\", \"LR\"]\n\nfor ax, model, label in zip (range(1,9), lcModels, lcLabels):\n    plt.subplot(4,2,ax)\n    plotLearningCurve(model)\n    plt.title(label, fontsize = 18)\nplt.suptitle(\"Learning Curves of Optimized Models\", fontsize = 28)\nplt.tight_layout(rect = [0, 0.03, 1, 0.97]) \n **Findings:**\n1. RF, DT, SVC and ETC are just doing okay. Among them, SVC is doing the best in terms of bias-variance tradeoff since svc's train accuracy and cross validation accuracy are almost equal. Since training and validation curves haven't yet converged for these classifiers, adding more instances (rows) might help.\n\n2. On the other hand, learning curve of GBC, ABC, KNN and LR indicates a little bit high bias or low variance (underfitting) and as the curves have already converged, adding more training data just might not help. Rather adding more features (columns) and increasing model's complexity might help.\n\n# 12.More Evaluation Metrics  <a id=\"12\"></a>\nWe've so far used accuracy score to evaluate our classifiers. But sometimes accuracy score isn't all enough to evaluate a classifier properly as accuracy score doesn't tell exactly which class (positive or negative) is being wrongly classified by our classifier in case of low accuracy score. **Again for imbalanced classification problem, accuracy score isn't the best metric to choose between different classifiers. To clarify this, in this section, we will calculate confusion matrix, precision score, recall score, specificity, f1 score, classification report for both random forest and gradient boosting classifier. And then we will compare our two best classifiers (rf and gbc) using these calculated metrics to see exactly where one classifier excels the other.**\n\n## 12.1 Confusion Matrix  <a id=\"12.1\"></a>\nThe confusion matrix shows the number of correct classifications along with misclassifications when a classifier make predictions for each class (positive or negative). The diagonal elements are correct classification while the off diagonal elements are misscalssifications. Some basic terms associated with confusion matrix:\n1. True positives (TP): These are cases in which we predicted 1(yes), and the actual is also 1(yes).\n2. True negatives (TN): We predicted 0(no), and the actual is also 0(no).\n3. False positives (FP): We predicted 1(yes), but the actual is 0(no). (Also known as a \"Type I error.\")\n4. False negatives (FN): We predicted 0(no), but the actual is 1(yes). (Also known as a \"Type II error.\") \n \"\"\"Return prediction to use it in another function.\"\"\"\ndef xValPredict(model):\n    \"\"\"Returns prediction by which we can calculate different classification metrices.\"\"\"\n    \n    predicted = cross_val_predict(model, xTrain, yTrain, cv = 10)\n    return predicted # Now we can use it in another function by assigning the function to its return value.\n\n\"\"\"Function to return confusion matrix.\"\"\"\ndef calculateConfusionMatrix(model):\n    \"\"\"returns a models confusion matrix\"\"\"\n    \n    predicted = xValPredict(model)\n    confusionMatrix = pd.crosstab(yTrain, predicted, rownames = [\"Actual\"],\n                                   colnames = [\"Predicted/Classified\"], margins = True)\n    return display(confusionMatrix)\n\n\"\"\"Now calculate confusion matrix of rf and gbc.\"\"\"\nbold(\"RF Confusion Matrix:\")\ncalculateConfusionMatrix(rf)\nbold(\"GBC Confusion Matrix:\")\ncalculateConfusionMatrix(gbc) \n The 1st row of our confusion matrix( or sometimes called error matrix) is about the negative class (because of 0 and hence non-survived) and The 2nd row of our confusion matrix( or sometimes called error matrix) is about the positive class (because of 1 and hence survived).\n\nFor rf, passengers correctly classified as survived are 243 (true positives) and passengers correctly classified as non-survived (died) are 506(true negatives). While 43 passengers (false positives) from class 0 (non-survived) were misclassified as survived and 99 (false negatives) passengers who actually survived were classified as non-survived.\n\nAnd for gbc, passengers correctly classified as survived are 248(true positives) and passengers correctly classified as non-survived (died) are 501(true negatives). While 48 (false positives) passengers from class 0 (non-survived) were misclassified as survived and 94 (false negatives) passengers who actually survived were misclassified as non-survived.\n\n**RF (749) makes exactly same correct predictions (true positives+true negatives) as gbc (749), hence rf and gbc have exactly same accuracy score that we saw when we calculated both model's accuracy score.**\n\n## 12.2 Precision Score  <a id=\"12.2\"></a>\nPrecision is the ratio of true positive to total predicted positive(true positive + false positive). So precision score tells how many true positives our model can capture out of total predicted positives. \n \"\"\"Function to calculate precision score.\"\"\"\ndef calculatePrecisionScore(model):\n    \"\"\"Calculates a model's precision score.\"\"\"\n    \n    predicted = xValPredict(model)\n    precisionScore = precision_score(yTrain, predicted)\n    return round(precisionScore*100, 2)\n\n\"\"\"Compute precision score for rf and gbc.\"\"\"\nprint(f\"RF  Precision Score: {calculatePrecisionScore(rf)}\")\nprint(f\"GBC Precision Score: {calculatePrecisionScore(gbc)}\") \n **RF's precision score tells when it predicts a passenger as a survivor (=class1), it is correct nearly 85% of the time. And gbc's precision score tells when gbc predicts a passenger as a survivor, it is correct nearly 84% of the time. So rf has a better precision score than gbc.**\n\n## 12.3 Recall (or Sensitivity or True Positive Rate)  <a id=\"12.3\"></a>\nRecall is the ratio of true positive to total actual positive(true positive + false negative). So recall score basically calculates true positives from total actual positives. \n \"\"\"Function to calculate recall score.\"\"\"\ndef calculateRecallScore(model):\n    \"\"\"Calculate a model's recall score.\"\"\"\n    \n    predicted = xValPredict(model)\n    recallScore = recall_score(yTrain, predicted)\n    return round(recallScore*100, 2)\n\n\"\"\"Compute recall score for rf and gbc.\"\"\"\nprint(f\"RF  Recall Score: {calculateRecallScore(rf)}\")\nprint(f\"GBC Recall Score: {calculateRecallScore(gbc)}\") \n **RF's recall score tells it correctly identifies over 71% of all the survivors. Or put another way, it predicts over 71.5% of the survivors as a survivor. On the other hand, gbc predicts just over 72.5% of the survivors as survivor. So gbc is more capable of capturing true positives than rf that we also observed from confusion matrix.**\n\n## 12.4 Specificity ( or True Negative Rate)  <a id=\"12.4\"></a>\nSpecificity is the ratio of true negative to total actual negative(true negative + false positive). Specificity  is exactly the opposite of recall. So specificity score basically calculates true negatives from total actual negatives. \n \"\"\"Function for specificity score.\"\"\"\ndef calculateSpecificityScore(model):\n    \"\"\"Returns a model's specificity score.\"\"\"\n    \n    predicted = xValPredict(model)\n    tn, fp, fn, tp = confusion_matrix(yTrain, predicted).ravel()\n    specificityScore = tn / (tn + fp)\n    return round(specificityScore*100, 2)\n\n\"\"\"Calculate specificity score for rf and gbc.\"\"\"\nprint(f\"RF  Specificity Score: {calculateSpecificityScore(rf)}\")\nprint(f\"GBC Specificity Score: {calculateSpecificityScore(gbc)}\") \n **RF's specificity score indicates it correctly predicts over 92% of the victims as a victim. Comparing recall score with specificity, it looks like our rf model is more accurate on predicting negative class (victims = 0) than predicting positive class (survivors = 1).**\n\n**While  gbc's specificity score indicates it correctly predicts over 91% of the victims as a victim. Comparing recall score with specificity, it looks like our gbc also is more accurate on predicting negative class (victims = 0) than predicting positive class (survivors = 1).**\n\n**Interesting! RF is better than capturing true negatives than gbc. So if we were to choose a model between rf and gbc where our priority is the negative class (0), we would choose rf. And if our priority is positive class(1), we would choose gbc.**\n\n## 12.5 F1 Score  <a id=\"12.5\"></a>\nWe can't choose classifiers solely depending on their precision or recall score. Rather we need to consider both to find out the best classifiers. Here comes the f1 score which is  the balanced harmonic mean of Recall and Precision, giving both metrics equal weight. The higher the f1 score is, the better. \n \"\"\"Function for F1 score.\"\"\"\ndef calculateF1Score(model):\n    \"\"\"Returns a model's f1 score.\"\"\"\n    \n    predicted = xValPredict(model)\n    f1Score = f1_score(yTrain, predicted)\n    return round(f1Score*100, 2)\n\n\"\"\"Calculate f1 score for rf and gbc.\"\"\"\nprint(f\"RF  F1 Score: {calculateF1Score(rf)}\")\nprint(f\"GBC F1 Score: {calculateF1Score(gbc)}\") \n **Looks like gbc is better than rf in terms of f1 score.**\n## 12.6 Classification Report  <a id=\"12.6\"></a>\nPrecision, recall, and f1 score is only associated with true positives. But what if we want to measure true negatives? We can measure them with true positives and count of each class (0 and 1) in  a classification report. It provides precision, recall, f1 score and class count altogether for both classs (0 and 1) but at the cost of less hassle. \n \"\"\"Function to compute classification report.\"\"\"\ndef calculateClassificationReport(model):\n    \"\"\"Returns a model\"s classification report.\"\"\"\n    \n    predicted = xValPredict(model)\n    classificationReport = classification_report(yTrain, predicted)\n    return print(classificationReport)\n\n\"\"\"Now calculate classification report for rf and gbc.\"\"\"\nbold(\"RF Classification Report:\")\ncalculateClassificationReport(rf)\nbold(\"GBC Classification Report:\")\ncalculateClassificationReport(gbc) \n **We can see precision, recall, f1 score and class count for both class (0 and 1) of our two models.**\n## 12.7 Precision-Recall vs Threshold Curve  <a id=\"12.7\"></a>\nSometimes we want a high precision and sometimes a high recall depending on our classification problem. The thing is that an increasing precision results in a decreasing recall and vice versa. This is called the precision-recall tradeoff that can be illustrated using precision-recall curve as a function of the decision threshold. \n \"\"\"Function for plotting precision-recall vs threshold curve.\"\"\"\ndef plotPrecisionRecallVsThresholdCurve(model, title):\n    \"\"\"Plots precision-recall vs threshold curve for a model.\"\"\"\n\n    probablity = model.predict_proba(xTrain)[:, 1]\n    plt.figure(figsize = (18, 5))\n    precision, recall, threshold = precision_recall_curve(yTrain, probablity)\n    plt.plot(threshold, precision[:-1], \"b-\", label = \"precision\", lw = 3.7)\n    plt.plot(threshold, recall[:-1], \"g\", label = \"recall\", lw = 3.7)\n    plt.xlabel(\"Threshold\")\n    plt.legend(loc = \"best\")\n    plt.ylim([0, 1])\n    plt.title(title)\n    plt.show()\n\n\"\"\"Now plot precision-recall vs threshold curve for rf and gbc.\"\"\"\nplotPrecisionRecallVsThresholdCurve(rf, title = \"RF Precision-Recall vs Threshold Curve\" )\nplotPrecisionRecallVsThresholdCurve(gbc, title = \"GBC Precision-Recall vs Threshold Curve\") \n **We can see for RF, the recall falls quickly at a precision of around 84%. So therefore, we need to select the precision-recall tradeoff before 84% of precision which could be at around 82%. Now, for example, if we want a precision of 80% off RF we would need a threshold of around 0.4**\n\n**On the other hand, for GBC, the recall falls fast at a precision of around 84% and hence we would select precision-recall tradeoff at around 80% of precision. If we want a precision of around 81% off GBC, we would need a threshold of around 0.38**\n\n## 12.8 Precision-Recall Curve  <a id=\"12.8\"></a>\nWe can also plot precision against recall to get an idea of precision-recall tradeoff where y-axis represents precision and x-axis represents recall. In my plot, I plot recall on y-axis and precision on x-axis. \n \"\"\"Function to plot recall vs precision curve.\"\"\"\ndef plotPrecisionVsRecallCurve(model, title):\n    \"\"\"Return amodel's recall vs precision curve.\"\"\"\n    \n    probablity = model.predict_proba(xTrain)[:, 1]\n    plt.figure(figsize = (18, 5))\n    precision, recall, threshold = precision_recall_curve(yTrain, probablity)\n    plt.plot(recall, precision, \"r-\", lw = 3.7)\n    plt.ylabel(\"Recall\")\n    plt.xlabel(\"Precision\")\n    plt.axis([0, 1.5, 0, 1.5])\n    plt.title(title)\n    plt.show()\n\n\"\"\"Now plot recall vs precision curve of rf and gbc.\"\"\"\nplotPrecisionVsRecallCurve(rf, title = \"RF Precision-Recall Curve\")\nplotPrecisionVsRecallCurve(gbc, title = \"GBC Precision-Recall Curve\") \n **We can see recall falls rapidly at around a precision of 0.84 for both RF and 0.82 for GBC that we've observed in the previous section.**\n\n## 12.9 ROC  Curve & AUC Score  <a id=\"12.9\"></a>\nROC (Reicever Operating Characteristic Curve) is a plot of the true positive rate against the false positive rate of a classifier. It shows the tradeoff between sensitivity and specificity (any increase in sensitivity will be accompanied by a decrease in specificity). AUC (Area under the ROC Curve) score is the corresponding score to the AUC Curve. It is simply computed by measuring the area under the ROC curve, which is called AUC. We will plot ROC curve and AUC score together for our two classifiers. \n \"\"\"Function to plot ROC curve with AUC score.\"\"\"\ndef plotRocAndAucScore(model, title):\n    \"\"\"Returns roc and auc score of a model.\"\"\"\n    \n    probablity = model.predict_proba(xTrain)[:, 1]\n    plt.figure(figsize = (18, 5))\n    false_positive_rate, true_positive_rate, threshold = roc_curve(yTrain, probablity)\n    auc_score = roc_auc_score(yTrain, probablity)\n    plt.plot(false_positive_rate, true_positive_rate, label = \"ROC CURVE, AREA = \"+ str(auc_score))\n    plt.plot([0, 1], [0, 1], \"red\", lw = 3.7)\n    plt.xlabel(\"False Positive Rate (1-Specificity)\")\n    plt.ylabel(\"True Positive Rate (Sensitivity)\")\n    plt.axis([0, 1, 0, 1])\n    plt.legend(loc = 4)\n    plt.title(title)\n    plt.show()\n\n\"\"\"Plot roc curve and auc score for rf and gbc.\"\"\"\nplotRocAndAucScore(rf, title = \"RF ROC Curve with AUC Score\")\nplotRocAndAucScore(gbc, title = \"GBC ROC Curve with AUC Score\") \n This two plots tells few different things:\n\n1. A model that predicts at chance will have an ROC curve that looks like the diagonal red line. That is not a discriminating model.\n\n2. The further the curve is off the diagonal red line, the better the model is at discriminating between positives and negatives in general.\n\n3. There are useful statistics that can be calculated from this curve, like the Area Under the Curve (AUC). This tells you how well the model predicts and the optimal cut point for any given model (under specific circumstances).\n\n**Comparing the two ROC curves, we can see the distance between blue and red line of RF is greater than the distance between blue and red line of GBC. Hence it can safely be said that RF, in general, is better at discriminating between positives and negatives than GBC. Also RF(92.11%) auc score (which is the area under the roc curve) is greater than gbc(91.94%). It seems the higher the area, the further the classifier is off the red diagonal line and vice versa and hence more accurate. Since RF has more area under the ROC curve than GBC, RF is more accurate.**\n\n# 13.Prediction & Submission  <a id=\"13\"></a>\nFirst we will predict using both rf and gbc. Then we will create two prediction files in csv format for kaggle submission. \n \"\"\"Submission with the most accurate random forest classifier.\"\"\"\nsubmissionRF = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": rf.predict(xTest)})\nsubmissionRF.to_csv(\"rfSubmission.csv\", index = False)\n\n\n\"\"\"Submission with the most accurate gradient boosting classifier.\"\"\"\nsubmissionGBC = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": gbc.predict(xTest)})\nsubmissionGBC.to_csv(\"gbcSubmission.csv\", index = False) \n **Though both RF and GBC have the identical validation accuracy (in our case optimized accuracy ~0.8406), RF scored 0.79425 while GBC scored 0.78468 on kaggle leaderboard. The fact that gbc's accuracy on the holdout data is 0.78468 compared with the 0.8406 accuracy we got with cross-validation indicates that GBC underfits the training data that we obsetved from the learning curve (see part 11.7). Hence it performs poorly on kaggle hold out set compared to RF.**\n\n### Can we further improve our classifiers' accuracy? May be we can! In the next few section, we will try to improve our models' accuracy with the help of ensemble method. \n # 14.Introduction to Ensemble <a id=\"14\"></a>\nCan we further boost the accuracy of our best models? That's what we will try to do using ensemble method. Ensembles combine predictions from different models to generate a final prediction, and the more models we include the better it performs. Better still, because ensembles combine baseline predictions, they perform at least as well as the best baseline model. Most of the errors from a model\u2019s learning are from three main factors: variance, noise, and bias. By using ensemble methods, we\u2019re able to increase the stability of the final model and reduce the errors caused by bias, variance, and noise. By combining many models, we\u2019re able to (mostly) reduce the variance, even when they are individually not great, as we won\u2019t suffer from random errors from a single source. **The main principle behind ensemble modelling is to group weak learners together to form one strong learner. The most basic ensemble is majority voting rule (where the prediction or vote given by the majority of the models used as final prediction).But there are many other ways to combine predictions, and more generally we can use a model to learn how to best combine predictions.** \n **To implement an ensemble we need three basic things:**\n1. A group of base learners that generate predictions.\n2. A meta learner that learns how to best combine these predictions outputed by base learners.\n3. And finally a method for splitting the training data between the base learners and the meta learner.\n\n**An ensemble works best if:**\n1. There is a less correlation in the base models' predictions.\n2. We increase the number of base learners though it might slow the process down.\n\n\n## 14.1 Different Ensemble Methods\nWe would first categorize ensemble methods into two subcategories like 1.Simple Ensemble Methods and 2.Advanced Ensemble Methods\n\n### 14.1.1 Simple Ensemble Methods\nThey're the simpliest yet so useful form of enselbles. They can be further categorised into \n1. Voting, \n2. Averaging and \n3. Weighted Average. \n\nFirst one is usually used for classification while the later two are used for regression problems.\n\n#### 14.1.1.1 Voting Ensemble  \nVoting ensemble is further classified into \n1. Hard voting and \n2. Soft voting.\n\n##### 14.1.1.1.1 Hard Voting (or Majority Voting or Max Voting) <a id=\"14.1\"></a>\nThis hard voting method is usually used for classification problems. The idea is to train multiple models to make predictions for each data point. The predictions by each model are considered as a \u2018vote\u2019. The predictions which we get from the majority of the models are used as the final prediction. Say rf and lr predict a class as 1 while knn predicts the same class as 0. Since the majority of the vots is casted in favour of class 1, the voting classifier would predict the very same class as 1. See the table below to understand how hard voting ensemble works. \n bold(\"How hard voting works:\")\ndata = [[1, 1, 1, 0, 1], \n        [0, 0, 0, 1, 0]]\ndisplay(pd.DataFrame(data, columns= [\"Class\",\"RF\", \"LR\", \"KNN\", \"Hard_voting\"]).set_index(\"Class\")) \n **Correlation among Base Models Predictions:** How base models' predictions are correlated? If base models' predictions are weakly correlated with each other, the ensemble will likely to perform better. On the other hand, for a strong correlation of predictions among the base models, the ensemble will unlikely to perform better. To sumarize, diversity of predictions among the base models is inversely proportional to the ensemble accuracy. Let's make prediction for the test set. \n \"\"\"Create a data frame to store base models prediction.\nFirst 5 in the dataframe are tree based models. Then two are kernel based. \nAnd the last is a linear model.\"\"\"\nbasePrediction = modelPrediction # We\"ve a df of all the models prediction.\n\n\"\"\"Let\"s see how each model classifies a prticular class.\"\"\"\nbold(\"All the Base Models Prediction:\")\ndisplay(basePrediction.head())\n\n\"\"\"Let\"s visualize the correlations among the predictions of base models.\"\"\"\nfig,ax = plt.subplots(nrows=1, ncols=1, figsize=(15,6))\nsns.heatmap(basePrediction.corr(), cmap =\"YlGnBu\", annot=True, annot_kws={\"size\":14}, ax=ax)\nax.set_title(\"Prediction Correlation among the Base Models\", fontsize = 20)\nax.tick_params(axis = \"both\", which = \"major\", labelsize = 14)\nax.tick_params(axis = \"both\", which = \"minor\", labelsize = 14)\nplt.show() \n **Findings:** The prediction looks quite similar for the 8 classifiers except when DT is compared to the others classifiers. Now we will create an ensemble with the base models RF, GBC, DT, KNN and LR. This ensemble can be called heterogeneous ensemble since we have three tree based, one kernel based and one linear models. We would use **EnsembleVotingClassifier method from mlxtend module** for both hard and soft voting ensembles. The advantage is it requires lesser codes to plot decision regions and I find it a bit faster than sklearn's voting classifier. \n \"\"\"We will use mlxtend library to train, predict and plot decision regions of hard voting ensemble classifier.\"\"\"\n\"\"\"Define base models for hard voting ensemble.\"\"\"\nbaseModels = [rf, gbc, dt, knn, lr]\n\n\"\"\"Initialize hard voting ensemble.\"\"\"\nhardVct = EnsembleVoteClassifier(clfs = baseModels, voting=\"hard\")\nprint(\"Training Hard Voting Ensemble Classifier...\")\ndisplay(hardVct.fit(xTrain, yTrain))\nprint(\"Done.\")\n\n\"\"\"Predict with hard voting ensemble.\"\"\"\nyPredHardVct = pd.DataFrame(hardVct.predict(xTest), columns = [\"hardVct\"])\n\n\"\"\"Hard voting cross validation score.\"\"\"\nprint(\"\\nComputing Hard Voting Cross Val Score...\")\nhardXValScore = cross_val_score(hardVct, xTrain, yTrain, cv = 10, scoring = \"accuracy\")\nhardXValScore = round(hardXValScore.mean()*100, 2)\nprint(\"Done.\")\n\n\"\"\"Our tunned scores\"\"\"\ntunedScore = bestScoreAndHyperparametersSorted.iloc[:,0]\n\n\"\"\"Compare hard voting score with best base models scores.\"\"\"\nhardVctVsBaseScore = pd.DataFrame({\"hardVsBaseScore(%)\": [hardXValScore,\n                                                          tunedScore[\"RF\"],\n                                                          tunedScore[\"GBC\"], \n                                                          tunedScore[\"DT\"],\n                                                          tunedScore[\"KNN\"], \n                                                          tunedScore[\"LR\"]]\n                                  })\n\n\"\"\"So basically we\"re comparing hard voting x_val_score with base models\"s tunned score.\"\"\"\nhardVctVsBaseScore.index = [\"hardVct\", \"RF\", \"GBC\", \"DT\", \"KNN\", \"LR\"]\nbold(\"Hard Voting vs Base Models Scores:\")\ndisplay(hardVctVsBaseScore) \n **Findings:** We can see Hard voting classifier uses RF as meta learner for this problem that beats the best base learners (rf and gbc) by some margin. So we may want to further investigate how hard voting is using its decision boundary to excel our best base learners. Let's visualize the decision regions of hard voting classifier with base classifiers.\n\n**Now we have a new challenge. In machine learning, visualizing 2 or 3 dimensional data is not that challenging. But we have 47 dimensions (47 input features). That's way too much to visualize. So we need to reduce the dimensionality- may be into 2 or 3 dimensionality. That's where PCA comes into play.**\n\n### **Introduction to Principal Component Analysis (PCA) <a id=\"14.2\"></a>\nThe main goal of a PCA analysis is to identify patterns in data. PCA aims to detect the correlation between variables. If a strong correlation between variables exists, the attempt to reduce the dimensionality only makes sense. In a nutshell, this is what PCA is all about: Finding the directions of maximum variance in high-dimensional data and project it onto a smaller dimensional subspace while retaining most of the information. PCA is very useful in the following two cases:\n1. When the training process takes too long due to large input dimension of training data.\n2. Reducing dimensions, it make data visualization a breeze.\n\nPCA is often effected if your input features have different ranges. So to make PCA work better we shoud scale the input features. We would use sklearn's StandardScaler to standarize our input features. The idea behind StandardScaler is that it will transform our data such that its distribution will have a mean value 0 and standard deviation of 1. **If the variables are correlated, PCA can achieve dimension reduction. If not, PCA just orders them according to their variances.**\n\n**Now let's perform standarization and then PCA to plot decision regions of different trained classifiers.** \n \"\"\"Perform Standarization:\nVariables have very different ranges (diffenence between max and  min).\nThe purpose of standarization is to reduce the dispersion of these variables.\"\"\"\n\n\"\"\"Initialize standard scaler object.\"\"\"\nstdScaler = StandardScaler()\n\"\"\"Fit standard scaler object to train data.\"\"\"\nstdScaler.fit(xTrain)\n\"\"\"Apply the standard scaler to training set.\"\"\"\nxTrainScaled = stdScaler.transform(xTrain)\n\n\n\"\"\"Perform PCA:\"\"\"\n\"\"\"Initialize pca object with two components. i.e., converting into 2d from 47d.\"\"\"\npca = PCA(n_components = 2) # Projection to 2d from 47d\n\"\"\"Fit pca to scaled data.\"\"\"\npca.fit(xTrainScaled)\n\"\"\"Apply pca to scaled data.\"\"\"\npcaTrain = pca.transform(xTrainScaled)\n\"\"\"Create a data frame consisting of two pca.\"\"\"\ntrainPca = pd.DataFrame(data = pcaTrain, columns = [\"pca-1\", \"pca-2\"])\nbold(\"Projection to 2D from 47D:\")\ndisplay(trainPca.head())\n\n\"\"\"let\"s merge our two pca components with our target feature.\"\"\"\nfinalDf = pd.concat([trainPca, yTrain], axis = 1)\nbold(\"Target with 2-PCA Components:\")\ndisplay(finalDf.head()) \n **So there we have it! We're down to 2 features only from 47 features. Now we want to calculate how much variance we're able to extract off these 2 components.** \n \"\"\"Now calculate how much variance we get off these two components.\"\"\"\nbold(\"Total Variance Explained by 2 PCA Components:\")\ndisplay(round((pca.explained_variance_ratio_[0] + pca.explained_variance_ratio_[1])*100, 2)) \n **Not so much! But considering the number of features we have, its not either too less. Let's visualize our two components (transformed features) in a scatter plot.** \n \"\"\"Visualize our newly transformed samples with class labels.\"\"\"\nfig,ax = plt.subplots(1,1, figsize = (18,7))\nax.set_xlabel(\"PCA_1\", fontsize = 15)\nax.set_ylabel(\"PCA_2\", fontsize = 15)\nax.set_title(\"2-Component PCA (2D-Transformed Samples)\", fontsize = 20)\ntargets = [1, 0]\ncolors = [\"g\", \"r\"]\nfor target, color in zip(targets,colors):\n    indices = finalDf[\"Survived\"] == target\n    ax.scatter(finalDf.loc[indices, \"pca-1\"],\n               finalDf.loc[indices, \"pca-2\"],\n               c = color, s = 37)\nplt.legend(targets)\nplt.show() \n **Looking at this plot, one thing we can say that a linear decision boundary will not be a good choice to separate these two classes. Now we would train our models on this 2d transformed samples to visualize decision regions created by them.**\n\n**Note:** PCA gives you an intuition if a linear or non-linear algorithms would be suitable for a problem. For example, if we look at the scatter plot, we see a non-linear trend between the two class that is, of course better seperable by a non-linear decision boundary. So a non-linear model would be a better bet than a linear one. That's why rf(non-linear) performs better than lr(linear model) for this problem. \n \"\"\"We will use mlxtend for plotting decision regions of base and ensemble models. Initialize base models and hard voting ensemble.\"\"\"\nrfPca = RandomForestClassifier(random_state = seed)\ngbcPca = GradientBoostingClassifier(random_state = seed)\ndtPca = DecisionTreeClassifier(random_state = seed)\nknnPca = KNeighborsClassifier()\nlrPca = LogisticRegression(random_state = seed)\nbaseModelPca = [rfPca, gbcPca, dtPca, knnPca, lrPca]\nhardVctPca = EnsembleVoteClassifier(clfs = baseModelPca, voting=\"hard\")\n\n\"\"\"Function to plot decision region.\"\"\"\ndef plotDecisionRegion(model):\n    \"\"\"Returns a model's decision region.\"\"\"\n    \n    \"\"\"Train models with data pca returned. Get the train data.\"\"\"\n    X = trainPca.values # Must be converted into numpy array.\n    y = yTrain.values\n    model.fit(X, y) \n    decisionRegion = plot_decision_regions(X = X, y = y.astype(np.integer), clf=model)\n    plt.xlabel(\"PCA-1\", fontsize = 15)\n    plt.ylabel(\"PCA_2\", fontsize = 15)\n    plt.xticks(fontsize = 15)\n    plt.yticks(fontsize = 15)\n    return decisionRegion\n\n\"\"\"Now plot decison regions for hard voting ensemble vs base models in subplots.\"\"\"\nplt.figure(figsize = (25,25))\nenModels = [hardVctPca, rfPca, gbcPca, dtPca, knnPca, lrPca]\nenLabels = [\"Hard_vct\", \"RF\", \"GBC\", \"DT\", \"KNN\", \"LR\"]\nfor ax, model, label in zip(range(1,7), enModels, enLabels):\n    plt.subplot(3,2,ax)\n    plotDecisionRegion(model)\n    plt.title(label, fontsize = 18)\nplt.suptitle(\"Hard Voting vs Base Models Decision Regions\", fontsize = 28)\nplt.tight_layout(rect = [0, 0.03, 1, 0.97]) \n **Findings:** There seems to be lesser misclassifications made by hard voting decision region compared to both rf and gbc's decision regions. Let's see how and where hard voting ensemble corrects base learners prediction in a data frame together. \n \"\"\"Create a data frame consisting of base models and hard voting ensemble predictions. Revised base models are now rf, gbc, dt, knn, lr without svc and etc.\"\"\"\nbasePrediction = basePrediction.drop(columns = [\"ABC\", \"SVC\", \"ETC\"], axis = 1)\n\n\"\"\"See base models prediction with hard voting prediction.\"\"\"\nhardBase = pd.concat([basePrediction, yPredHardVct], sort = False, axis = 1)\ndisplay(hardBase.head(7)) \n **Great! We can see hard voting ensemble is considering majority of the models vote(prediction) to label a particular class. Thus it can reduce prediction errors when predicted by a single base learners.**\n\n##### 14.1.1.1.2 Soft Voting <a id=\"14.3\"></a>\nOn the other hand, When an ensembles averages based on probabilities  we refer to it as soft voting. In an ensemble model, all classifiers (algorithms) are able to estimate class probabilities (i.e., they all have predict_proba() method), then we can specify Scikit-Learn to predict the class with the highest probability, averaged over all the individual classifiers. In a voting classifier setting the voting parameter to 'soft' enables the models to calculate their probability(also known as confidence score) individually and present it to the voting classifier, then the voting classifier averages them and outputs the class with the highest probability. If average probablity of class-1 is greater than class-0, it outputs predicted class is 1 otherwise 0. \n\n**Note:** This soft-voting classifier often work better than hard-voting as it gives more weight to highly confident votes. We Need to specify voting=\u201dsoft\u201d and ensure that all classifiers can estimate class probabilities. One algorithm where we need to be careful is SVC, by default SVC will not give probabilities, we have to specify 'probability' hyperparameter to True.\nSee the table below to understand how soft voting ensemble works. \n bold(\"How soft voting works:\")\ndata = [[0.49, 0.99, 0.49, 0.66, 1], \n        [0.51, 0.01, 0.51, 0.34, 0]]\ndisplay(pd.DataFrame(data, columns= [\"RF\", \"LR\", \"KNN\", \"Average\", \"Soft_voting\"])) \n **Let's implement soft voting ensemble in mlxtend.** \n \"\"\"Base models for soft voting is the base models of hard voting.\"\"\"\n\"\"\"Initialize soft voting ensemble.\"\"\"\nbaseModels = [rf, gbc, dt, knn, lr]\nsoftVct = EnsembleVoteClassifier(clfs = baseModels, voting = \"soft\")\nprint(\"Fitting Soft Voting Ensemble...\")\ndisplay(softVct.fit(xTrain, yTrain))\nprint(\"Done.\")\n\n\"\"\"Predict with soft voting ensemble.\"\"\"\nyPredSoftVct = pd.DataFrame(softVct.predict(xTest), columns = [\"Soft_vct\"])\n\n\"\"\"Hard voting cross validation score.\"\"\"\nprint(\"\\nComputing Soft Voting X Val Score...\")\nsoftXValScore = cross_val_score(softVct, xTrain, yTrain, cv = 10, scoring = \"accuracy\")\nsoftXValScore = round(softXValScore.mean()*100, 2)\nprint(\"Done.\")\n\n\"\"\"Compare hard voting score with best base models scores.\"\"\"\nsoftVsBaseScore = pd.DataFrame({\"Soft_vs_base_score(%)\": [softXValScore,\n                                                          tunedScore[\"RF\"],\n                                                          tunedScore[\"GBC\"], \n                                                          tunedScore[\"DT\"],\n                                                          tunedScore[\"KNN\"], \n                                                          tunedScore[\"LR\"]]\n                               })\n\"\"\"So basically we\"re comparing soft voting x_val_score with base models\"s tunned score.\"\"\"\nsoftVsBaseScore.index = [\"Soft_vct\", \"RF\", \"GBC\", \"DT\", \"KNN\", \"LR\"]\nbold(\"Soft Voting vs Base Models Scores:\")\ndisplay(softVsBaseScore) \n **Findings:** Soft voting ensemble fails to beat our two best models (rf and gbc). In fact, it produces way to inferior results compared to hard voting ensemble (83.95 vs 84.18). So hard voting ensemble, for this problem, seems to be superior to soft voting ensemble method. WE can visualize soft voting ensemble decision region along with base models decision regions. \n \"\"\"We would use the same data to plot decision region we got analysing PCA.\"\"\"\nsoftVctPca = EnsembleVoteClassifier(clfs = baseModelPca, voting = \"soft\")\n\n\"\"\"Plot decision regions for soft voting ensemble vs base models in subplots.\"\"\"\nplt.figure(figsize = (25,25))\nenModels = [softVctPca, rfPca, gbcPca, dtPca, knnPca, lrPca]\nenLabels = [\"Soft_vct\", \"RF\", \"GBC\", \"DT\", \"KNN\", \"LR\"]\nfor ax, model, label in zip(range(1,7), enModels, enLabels):\n    plt.subplot(3,2,ax)\n    plotDecisionRegion(model)\n    plt.title(label, fontsize = 18)\nplt.suptitle(\"Soft Voting vs Base Models Decision Regions\", fontsize = 28)\nplt.tight_layout(rect = [0, 0.03, 1, 0.97]) \n **Findings:** Soft voting decision region just seems to be creating more misclassification than rf and gbc. \n \"\"\"See base models prediction with soft voting prediction.\"\"\"\nsoftBase = pd.concat([basePrediction,yPredSoftVct], sort = False, axis = 1)\ndisplay(softBase.head()) \n ### 14.1.2 Advanced Ensemble Methods\nAdvanced ensemble methods can further be classified into \n1. Bagging\n2. Boostoing\n3. Stacking\n4. Blending\n\n#### 14.1.2.1 Bagging  <a id=\"14.4\"></a>\nBagging, is shorthand for the combination of bootstrapping and aggregating. Bootstrapping is a method to help decrease the variance of the classifier and thus reduce overfitting. So the model created should be less overfitted than a single individual model. Bagging is more suitable for high variance low bias models (complex models). Random forest itself is an ensemble machine learning algorithm that follows the bagging technique. We would use rf as the base estimator for bagging instead of default dt. Let's try to implement bagging in sklearn: \n \"\"\"Initialize bagging classifier.\"\"\"\nbagg = BaggingClassifier(base_estimator = rf, verbose = 0, n_jobs = -1, random_state = seed)\n\"\"\"We use rf as the base estimator for bagging technique.\"\"\"\nprint(\"Fitting Bagging Ensemble...\")\ndisplay(bagg.fit(xTrain, yTrain))\nprint(\"Done.\")\n\n\"\"\"Bagging cross validation score.\"\"\"\nprint(\"\\nComputing Bagging X Val Score..\")\nbaggXValScore = cross_val_score(bagg, xTrain, yTrain, cv = 10, scoring = \"accuracy\")\nbaggXValScore = np.round(baggXValScore.mean()*100, 2)\nprint(\"Done.\")\n\n\"\"\"Compare bagging ensemble score with best base models scores.\"\"\"\nbaggVsBaseScore = pd.DataFrame({\"Bagging_vs_base_score(%)\": [baggXValScore,\n                                                          tunedScore[\"RF\"],\n                                                          tunedScore[\"GBC\"], \n                                                          tunedScore[\"DT\"],\n                                                          tunedScore[\"KNN\"], \n                                                          tunedScore[\"LR\"]]\n                               })\n\n\"\"\"So basically we\"re comparing bagging x_val_score with base models\"s tunned score.\"\"\"\nbaggVsBaseScore.index = [\"Bagg\", \"RF\", \"GBC\", \"DT\", \"KNN\", \"LR\"]\nbold(\"Bagging vs Base Models Scores:\")\ndisplay(baggVsBaseScore) \n **Findings:** Bagging can't beat our best base learners.\n\n#### 14.1.2.2 Boosting  <a id=\"14.5\"></a>\nBoosting refers to any Ensemble method that can combine several weak learners into a strong learner. It does this through a weighted majority vote (classification) or a weighted sum (regression). Ada boost and Gradient boost, and Extreme gradient boost are popular models that uses boosting technique. Boosting is particularly suitable for low variance high bias models (less complex models). Unlike bagging, its a sequential ensemble technique. We will perform a simple voting ensemble of boosting classifiers rather performing boosting ensemble using only a single classifer with a base estimator (for ada boost). I found this method to give higher accuracy than adaboost(with a base estimator), gradient boosting, or extreme gradient boosting for this problem. Let's perform boosting ensemble(infact voting of boosting classifiers) in mlxtend. \n \"\"\"We will use adaptive boosting, gradient boosting and extreme gradient boosting classifiers for boosting ensemble method.\"\"\"\n\"\"\"Initialize boosting classifier. Base models for boosting:\"\"\"\nboostModels = [abc, gbc, xgbc] # Unoptimized xgbc\nboost = EnsembleVoteClassifier(clfs = boostModels, voting=\"hard\")\n\n\"\"\"Fitting boosting.\"\"\"\nprint(\"Fitting Boosting Ensemble...\")\ndisplay(boost.fit(xTrain, yTrain))\nprint(\"Done.\")\n\n\"\"\"Boosting cross validation score.\"\"\"\nprint(\"\\nCalculating Boosting X Val Score...\")\nboosXValScore = cross_val_score(boost, xTrain, yTrain, cv = 10, scoring = \"accuracy\")\nboosXValScore = round(boosXValScore.mean()*100, 2)\nprint(\"Done.\")\n\n\"\"\"Compare boosting ensemble score with best base models scores.\"\"\"\nxgbcXValScore = 82.27  # xgbc\"s x_val_score.\nboostVsBaseScore = pd.DataFrame({\"Boosting_vs_base_score(%)\": [boosXValScore,\n                                                                  tunedScore[\"ABC\"],\n                                                                  tunedScore[\"GBC\"], \n                                                                  xgbcXValScore]})\n\"\"\"So basically we\"re comparing boosting x_val_score with base models\"s tunned score except xgbc.\"\"\"\nboostVsBaseScore.index = [\"Boost\", \"ABC\", \"GBC\", \"XGBC\"]\nbold(\"Boosting vs Base Models Scores:\")\ndisplay(boostVsBaseScore) \n **Findings:** Boosting method can't beat best boosting base learner gbc. Though it could beat, if we would have optimized xgbc. If you have time and infrastructure, you can tune xgbc's hyperparameters. Then compare boosting accuracy with its base models accuracy.\n\n#### 14.1.2.3 Blending  <a id=\"14.6\"></a>\nIn blending, full training data is split into training and prediction sets. The base models (also called level 0 models) are trained on this train set and then predictions are made on this prediction set. These predictions made by base learers are then fed as an input to the meta learner (also called level 1 model). That is meta learner are trained with the output (predictions) of base learners. Blending ensemble uses only a subset of data to train base learners and another subset of data to make predictions. By only fitting every base learner once on a subset of the full training data, Blend ensemble is a fast ensemble that can handle very large datasets simply by only using portion of it at each stage. The cost of this approach is that information is thrown out at each stage, as one layer will not see the training data used by the previous layer. **We will use BlendEnsemble method from mlens.ensemble module to perform blending.** \n \"\"\"Perform blending in mlens.\"\"\"\n\"\"\"Initialize blend ensembler.\"\"\"\nblend = BlendEnsemble(n_jobs = -1, test_size = 0.5, random_state = seed)\n\"\"\"Base models for blending.\"\"\"\nbaseModels = [gbc, rf, dt, knn, abc]\nblend.add(baseModels)\n\"\"\"Meta learner for blending. We will use lr.\"\"\"\nblend.add_meta(lr)\n\"\"\"Train the blend ensemble.\"\"\"\nprint(\"Fitting Blending...\")\ndisplay(blend.fit(xTrain, yTrain))\nprint(\"Done.\") \n #### 14.1.2.4 Stacking (Or Stacked Generalization)  <a id=\"14.7\"></a>\nIn blending, we trained the base learners and the meta learner on only half the data, so a lot of information is lost. To prevent this, we need to use a cross-validation strategy. Fitting an ensemble with cross-validation is often referred to as stacking, while the ensemble itself is known as the Super Learner. So basically in stacking, the individual classification models (or base models) are trained on the complete training set; then, the meta-classifier is fitted on the outputs (predictions) of those base learners. The meta-classifier can either be trained on the predicted class labels or probabilities from the ensemble.\n\n**The basic difference between blending and stacking is therefore that stacking allows both base learners and the meta learner to train on the full data set.The outcome of stacking is improved accuracy which is typical for small and medium-sized data sets, where the effect of blending can be severe. As the data set size increases, blending and stacking performs similarly and hence for large data sets blending is preferred over stacking since stacking takes significant amount of time to train the ensemble. We will use package vecstack to perform stacking that can save you from writing a lot of codes if you implement stacking from scratch.** \n \"\"\"Initialize base models. We will use the same base models as blending.\"\"\"\nbaseModels = [rf, dt, gbc, abc, knn]\n\"\"\"Perform stacking.\"\"\"\nsTrain, sTest = stacking(baseModels,                # list of base models\n                           xTrain, yTrain, xTest,   # data\n                           regression = False,         # classification task (if you need \n                                                       # regression - set to True)\n                           mode = \"oof_pred_bag\",      # mode: oof for train set, predict test \n                                                       # set in each fold and vote\n                           needs_proba = False,        # predict class labels (if you need \n                                                       # probabilities - set to True) \n                           save_dir = None,            # do not save result and log (to save \n                                                       # in current dir - set to \".\")\n                           metric = accuracy_score,    # metric: callable\n                           n_folds = 10,               # number of folds\n                           stratified = True,          # stratified split for folds\n                           shuffle = True,             # shuffle the data\n                           random_state= seed,         # ensure reproducibility\n                           verbose = 1)                # print progress \n **So now we have OOF from base (or 0 level models) models and we can build level 1 model. We have 5 base models (level 0 models), so we expect to get 5 columns in sTrain and sTest. sTrain will be our input feature to train our meta learner and then prediction will be made on sTest after we train our meta learner. And this prediction on sTest is actually the prediction for our test set (xTest). Before we train our meta learner we can investigate sTrain and sTest.** \n \"\"\"Input features for meta learner.\"\"\"\ndisplay(sTrain[:5])\ndisplay(sTrain.shape) \n '''Test (prediction) set for meta learner.'''\ndisplay(sTest[:5].shape)\ndisplay(sTest.shape) \n \"\"\"Initialize 1st level model that is our meta learner. We will use lr.\"\"\"\nsuperLearner = lr \n    \n\"\"\"Fit meta learner on the output of base learners.\"\"\"\nprint(\"Fitting Stacking...\")\nsuperLearner.fit(sTrain, yTrain)\nprint(\"Done.\")\n\"\"\"Finally predict using super learner.\"\"\"\nyPredSuper = superLearner.predict(sTest) \n ## 14.2  Evaluating Different Ensembles <a id=\"14.8\"></a>\nI've tried to demonstrate various ensemble methods. Let's make predictions with them to see how they perform on our test set on kaggle submission. \n \"\"\"Predicting with different ensembles.\"\"\"\n\n\"\"\"Hard voting.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": hardVct.predict(xTest)})\nsubmission.to_csv(\"hardVctSubmission.csv\", index = False)\n\n\"\"\"Soft voting.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": softVct.predict(xTest)})\nsubmission.to_csv(\"softVctSubmission.csv\", index = False)\n\n\"\"\"Bagging.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": bagg.predict(xTest)})\nsubmission.to_csv(\"baggSubmission.csv\", index = False)\n\n\"\"\"Boosting.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": boost.predict(xTest)})\nsubmission.to_csv(\"boostSubmission.csv\", index = False)\n\n\"\"\"Blending.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": blend.predict(xTest).astype(int)})\nsubmission.to_csv(\"blendSubmission.csv\", index = False)\n\n\"\"\"Stacking.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": yPredSuper.astype(int)})\nsubmission.to_csv(\"stackingSubmission.csv\", index = False) \n **We've made our submissions using different ensembles. Let's now compare their submission scores with our best base models'  submission scores.** \n \"\"\"Create a df of different ensemble submission scores and base models.\"\"\"\nsubmissionScore = pd.DataFrame({\"models\":[\"bagging(en)\", \"boosting(en)\", \"blending(en)\", \"stacking(en)\", \n                                          \"hardVoting(en)\", \"softVoting(en)\", \"rf(base)\", \"gbc(base)\"],\n             \"scoredOnSubmission\":[0.81339, 0.78947, 0.79425, 0.79904, 0.79904, 0.79904, 0.80382, 0.78947]})\nsubmissionScore = submissionScore.set_index(\"models\").sort_values(by=\"scoredOnSubmission\", ascending = False)\nbold(\"Ensemble vs Base Models Scores on Submission:\")\ndisplay(submissionScore) \n \"\"\"Let's plot models' submission score for the last time.\"\"\"\ndef plotSubmissionScore():\n    \"\"\"Returns a bar chart of different models scored on submission.\"\"\"\n    \n    # Create a subplot of bar chart\n    fig=make_subplots(\n        rows=1, \n        cols=1,\n        vertical_spacing=0.3,\n        print_grid=False) # This suppresses \"This is the format of your plot grid:\" text from popping out.\n\n    # Add trace for bar chart\n    fig.add_trace(go.Bar(x=submissionScore.index,\n                             y=submissionScore.T.squeeze(), # Converts df to series\n                             text=submissionScore.T.squeeze(),\n                             hoverinfo=\"x+y\",\n                             textposition=\"auto\",\n                             marker = dict(color=submissionScore.T.squeeze(), colorscale=\"Rainbow\"),\n                             textfont=dict(family=\"sans serif\",size=14),\n                             ),\n                     row=1,\n                     col=1\n                     )\n\n        \n    # Update the layout. Add title, dimension, and background color\n    fig.layout.update(\n        height=600, \n        width=950,\n        hovermode=\"closest\",\n        title_text = \"Models Score on Submission\",\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n\n    # Set y-axis titles in bold\n    fig.layout.yaxis1.update(title=\"<b>Submission score</b>\")\n    \n    # Set x-axis title in bold\n    fig.layout.xaxis1.update(title=\"<b>Models</b>\")\n    return fig.show()\n\n\"\"\"Call the function to plot the scores.\"\"\"\nplotSubmissionScore() \n **Findings:**So there you have it! Surprisingly its bagging that comes out on top with a score of *0.81339* that can take you to the top *4%* on the leaderboard! Random forest (base model) comes second with score 0.80382. Hard voting, stacking and soft voting perform identical and can't beat best base rf. Since bagging performs well for high variance model, we have a feeling that we might have overfitted the training data because cross validation score for bagging is 82.61% and it still scores over 81% on kaggle leaderboard. So its possible to overfit though your cross validation score is high since some models with higher cross validation score perform poorly on kaggle leaderboard compared to bagging ensemble. \n # 15.End Note <a id=\"15\"></a>\n**If you're still with me, I congratulate you because you've learned all those things that I learned after months of study, practice and of course patience. Of course, there is always room for improvement. I'm still learning. I've tried to explain everything I could possibly know. Any suggestion is cordially welcomed. May be trying out different base learners and meta learner to improve ensemble further or may be by tunning xgbc. And if you find my kernel useful, some upvotes will be appreciated.  I have also another kernel for advanced house price regression problem that you might find useful as well.**\n\n**Finally I provide some links that I've found useful in creating this notebook.**\n\n**Recommended Readings:**\n1. Mlxtend package for voting ensemble and decision region: https://rasbt.github.io/mlxtend/user_guide/classifier/EnsembleVoteClassifier/ and\nhttps://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/\n2. Mlens package for blending ensemble: https://github.com/flennerhag/mlens/blob/master/mlens/ensemble/blend.py\n3. Vecstack package for stacking ensemble: https://github.com/vecxoz/vecstack\n4. Introduction to Python Ensembles by Dataquest: https://www.dataquest.io/blog/introduction-to-ensembles/\n5. Kaggle ensemble guide by MLWave: https://mlwave.com/kaggle-ensembling-guide/",
    "code_source": "\"\"\"Import basic modules.\"\"\"\nimport numpy as np               # For linear algebra\nimport pandas as pd              # For data manipulation\nimport matplotlib.pyplot as plt  # For 2D visualization\nimport seaborn as sns            \nfrom scipy import stats          # For statistics\n\n\"\"\"Plotly visualization.\"\"\"\nimport plotly.graph_objs as go\nfrom plotly.tools import make_subplots\nfrom plotly.offline import iplot, init_notebook_mode\ninit_notebook_mode(connected = True) # Required to use plotly offline in jupyter notebook\n\n\"\"\"Machine learning models.\"\"\"\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom xgboost import XGBClassifier\n\n\n\"\"\"Classification (evaluation) metrices.\"\"\"\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\n\n\"\"\"Ensembling\"\"\"\nfrom mlxtend.classifier import EnsembleVoteClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom mlxtend.plotting import plot_decision_regions\nfrom sklearn.ensemble import BaggingClassifier\nfrom mlens.ensemble import BlendEnsemble\nfrom vecstack import stacking \n \"\"\"Customize visualization.\"\"\"\nplt.style.use(\"bmh\")                    # Use bmh's style for plotting\nsns.set_style({\"axes.grid\":False})      # Remove gridlines\n\n\"\"\"Display markdown formatted output like bold, italic bold etc.\"\"\"\nfrom IPython.display import Markdown\ndef bold(string):\n    return display(Markdown(f\"**{string}**\")) \n \"\"\"Read and preview the train data from csv file.\"\"\"\ntrain = pd.read_csv(\"../input/train.csv\")\nbold(\"Preview of Train Data:\")\ndisplay(train.head(2))\n\n\"\"\"Read and preview the test from csv file.\"\"\"\ntest = pd.read_csv(\"../input/test.csv\")\nbold(\"Preview of Test Data:\")\ndisplay(test.head(2)) \n \"\"\"Merge train and test data together. This eliminates the hassle of handling train and test data seperately for various analysis.\"\"\"\nmerged = pd.concat([train, test], sort = False).reset_index(drop=True)\nbold(\"Preview of Merged Data:\")\ndisplay(merged.head(5)) \n \"\"\"Shape of the combined data.\"\"\"\nbold(\"Shape of the Merged Data:\")\ndisplay(merged.shape)\n\n\"\"\"Variables in the combined data.\"\"\"\nbold(\"Name of the Variables in merged data:\")\ndisplay(merged.columns) \n \"\"\"Pandas data types for our different variables.\"\"\"\nbold(\"Data Types of Our Variables:\")\ndisplay(merged.dtypes) \n \"\"\"Create a function to plot a variable's absolute and relative frequency.\"\"\"\ndef plotFrequency(variable):\n    \"\"\"Plots absolute and relative frequency of a avriable.\"\"\"\n    \n    # Calculates absolute frequency\n    absFreq = variable.value_counts()\n    \n    # Calculates relative frequency\n    relFreq = variable.value_counts(normalize=True).round(4)*100\n    \n    # Creates a dataframe off absolute and relative frequency\n    df = pd.DataFrame({\n        \"absoluteFrequency\":absFreq,\n        \"relativeFrequency\":relFreq\n    })\n    \n    # Create two subplots of bar chart\n    fig=make_subplots(\n        rows=1, \n        cols=2,\n        vertical_spacing=0.3,\n        subplot_titles=(\"Absolute Frequency\", \"Relative Frequency\"),\n        print_grid=False) # This suppresses \"This is the format of your plot grid:\" text from popping out.\n\n    # Add trace for absolute frequency\n    fig.add_trace(\n        go.Bar(\n        y=df.index, \n        x=df.absoluteFrequency,\n        orientation=\"h\",\n        text=df.absoluteFrequency,\n        hoverinfo=\"x+y\",\n        textposition=\"auto\", \n        name=\"Abs Freq\",\n        textfont=dict(family=\"sans serif\",size=14),\n        marker = dict(color=df.absoluteFrequency, colorscale=\"Rainbow\")),\n        row=1,\n        col=1\n        )\n\n    # Add another trace for relative frequency\n    fig.add_trace(\n        go.Bar(y=df.index,\n        x=df.relativeFrequency.round(2),\n        orientation=\"h\",\n        text=df.relativeFrequency.round(2),\n        hoverinfo=\"x+y\",\n        textposition=\"auto\", \n        name=\"Rel Freq(%)\",\n        textfont=dict(family=\"sans serif\",size=15),\n        marker=dict(color=df.relativeFrequency.round(2), colorscale=\"Rainbow\")),\n        row=1,\n        col=2\n        )\n\n    # Update the layout. Add title, dimension, and background color\n    fig.layout.update(\n        height=600, \n        width=970,\n        hovermode=\"closest\",\n        title_text=f\"Absolute and Relative Frequency of {variable.name}\",showlegend=False,\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n\n    # Set y-axis title in bold\n    fig.layout.yaxis1.update(title=f\"<b>{variable.name}</b>\")\n    \n    # Set x-axes titles in bold\n    fig.layout.xaxis1.update(title=\"<b>Abs Freq</b>\")\n    fig.layout.xaxis2.update(title=\"<b>Rel Freq(%)</b>\")\n    # or, fig[\"layout\"][\"xaxis2\"].update(title=\"<b>Rel Freq(%)</b>\")\n    return fig.show() \n \"\"\"Plot number of survivors and victims in absolute and relative scale in the tragedy.\"\"\"\nplotFrequency(merged.Survived) \n \"\"\"Plot the absolute and relative frequency of Sex.\"\"\"\nplotFrequency(merged.Sex) \n \"\"\"Absolute and relative frequency of Pclass.\"\"\"\nplotFrequency(merged.Pclass) \n \"\"\"Plot absolute and relative frequency of Embarked.\"\"\"\nplotFrequency(merged.Embarked) \n \"\"\"Absolute frequency of Cabin.\"\"\"\nabsFreqCabin = merged.Cabin.value_counts(dropna = False)\nbold(\"Categories of Cabin:\")\ndisplay(absFreqCabin.head()) \n \n\"\"\"As frequency of Cabin isn't what we expected, let's count total categories in Cabin.\"\"\"\nbold(\"Total Categories in Cabin:\")\ndisplay(absFreqCabin.count()) \n \"\"\"Finally preview the variable Cabin to see what is causing the irregularity.\"\"\"\nbold(\"Preview of Cabin:\")\ndisplay(merged.Cabin.head(7)) \n \"\"\"Count total categories in Name.\"\"\"\nbold(\"Total Categories in Name:\")\ndisplay(merged.Name.value_counts().count()) \n \"\"\"Let's finally check the what's inside the variable Name.\"\"\"\nbold(\"Preview of Name:\")\ndisplay(merged.Name.head()) \n \"\"\"Count total groups in variable Ticket.\"\"\"\nbold(\"Total Groups in Ticket:\")\ndisplay(merged.Ticket.value_counts().count()) \n \"\"\"Lets investigate Ticket.\"\"\"\nbold(\"Preview of Ticket:\")\ndisplay(merged.Ticket.head()) \n \"\"\"Plot the absolute and relative frequency of SibSp to investigate its distribution.\"\"\"\nplotFrequency(merged.SibSp) \n \"\"\"Absolute and relative frequency of Parch.\"\"\"\nplotFrequency(merged.Parch) \n \"\"\"#1.Create a function to plot histogram and density plot.\"\"\"\ndef plotHistogram(variable):\n    \"\"\"Plots histogram and density plot of a variable.\"\"\"\n    \n    # Create subplot object.\n    fig = make_subplots(\n        rows=2,\n        cols=1,\n        print_grid=False,\n    subplot_titles=(f\"Distribution of {variable.name} with Histogram\", f\"Distribution of {variable.name} with Density Plot\"))\n    \n    # This is a count histogram\n    fig.add_trace(\n        go.Histogram(\n            x = variable,\n            hoverinfo=\"x+y\",\n            marker = dict(color = \"chocolate\")\n        ),\n    row=1,col=1)\n    \n    # This is a density histogram\n    fig.add_trace(\n        go.Histogram(\n            x = variable,\n            hoverinfo=\"x+y\",\n            histnorm = \"density\",\n            marker = dict(color = \"darkred\")\n        ),\n    row=2,col=1)\n    \n    # Update layout\n    fig.layout.update(\n        height=800, \n        width=870,\n        hovermode=\"closest\",\n        showlegend=False,\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n    \n    # Update axes\n    fig.layout.yaxis1.update(title=\"<b>Abs Frequency</b>\")\n    fig.layout.yaxis2.update(title=\"<b>Density(%)</b>\")\n    fig.layout.xaxis2.update(title=f\"<b>{variable.name}</b>\")\n    return fig.show()\n    \n\n    \n'''#2.Calculate descriptive statistics.'''\ndef calculateSummaryStats(variable):\n    stats = variable.describe()\n    skewness = pd.Series(variable.skew(), index = [\"skewness\"])\n    statsDf = pd.DataFrame(pd.concat([skewness, stats], sort = False), columns = [variable.name])\n    statsDf = statsDf.reset_index().rename(columns={\"index\":\"summaryStats\"})\n    return display(statsDf.round(2)) \n '''Plot histogram and density plot of Fare.'''\nplotHistogram(merged.Fare) \n \"\"\"Calculate summary statistics of Fare.\"\"\"\nbold(\"Summary Stats of Fare:\")\ncalculateSummaryStats(merged.Fare) \n \"\"\"Plot histogram and density plot of Age.\"\"\"\nplotHistogram(merged.Age) \n \"\"\"Calculate summary stats for Age\"\"\"\ncalculateSummaryStats(merged.Age) \n \"\"\"What does passengerId contain?\"\"\"\ndisplay(merged.PassengerId.head()) \n \"\"\"Let's preview the Cabin again.\"\"\"\nbold(\"Preview of Cabin:\")\ndisplay(merged.Cabin.head()) \n \"\"\"It seems Cabin contains some missing values. Let's count them.\"\"\"\nbold(\"Missing Values in Cabin:\")\ndisplay(merged.Cabin.isna().sum()) \n \"\"\"Total categories in Cabin before processing.\"\"\"\nbold(\"Total Categories in Cabin before Processing:\")\ndisplay(merged.Cabin.value_counts(dropna=False).count()) \n \"\"\"Flag all the NaNs of Cabin as 'X'.\"\"\"\nnanReplaced= merged.Cabin.fillna(\"X\") \n \"\"\"Extract only the 1st character from Cabin, which is only a Letter. And insert it to the dataframe.\"\"\"\nmerged[\"cabinProcessed\"] = nanReplaced.str.get(0) \nbold(\"Cabin Categories after Processing:\")\ndisplay(merged.cabinProcessed.value_counts()) \n \"\"\"After processing, we can visualize the absolute and relative frequency of newly transformed Cabin variable.\"\"\"\nplotFrequency(merged.cabinProcessed) \n \"\"\"Lets see what's inside the Name.\"\"\"\ndisplay(merged.Name.head(8)) \n \"\"\"Extract those firstName from Name.\"\"\"\nfirstName = merged.Name.str.split(\".\").str.get(0).str.split(\",\").str.get(-1) \n \"\"\"Count the extracted categories of firstName from Name.\"\"\"\ndisplay(firstName.value_counts()) \n \"\"\"Create a bucket Officer and put Dr, Rev, Col, Major, Capt titles into it.\"\"\"\nfirstName.replace(to_replace = [\"Dr\", \"Rev\", \"Col\", \"Major\", \"Capt\"], value = \"Officer\", inplace = True,regex=True)\n\n\"\"\"Put Dona, Jonkheer, Countess, Sir, Lady, Don in bucket Aristocrat.\"\"\"\nfirstName.replace(to_replace = [\"Dona\", \"Jonkheer\", \"Countess\", \"Sir\", \"Lady\", \"Don\"], value = \"Aristocrat\", inplace = True,regex=True)\n\n\"\"\"Finally Replace Mlle and Ms with Miss. And Mme with Mrs.\"\"\"\nfirstName.replace({\"Mlle\":\"Miss\", \"Ms\":\"Miss\", \"Mme\":\"Mrs\"}, inplace = True,regex=True)\n\n\"\"\"Replace the Aristocrat with Aristocrat\"\"\"\nfirstName.replace({\"the Aristocrat\":\"Aristocrat\"}, inplace = True,regex=True)\n\n\"\"\"Insert a column named 'nameProcessed'.\"\"\"\nmerged[\"nameProcessed\"] = firstName \n \"\"\"let's see how nameProcessed looks now\"\"\"\ndisplay(merged.nameProcessed.value_counts()) \n \"\"\"After processing, visualise and count absolute and relative frequency of transformed Name.\"\"\"\nplotFrequency(merged.nameProcessed) \n \"\"\"Merge SibSp and Parch to create a variable Family_size.\"\"\"\nmerged[\"familySize\"] = merged.SibSp + merged.Parch + 1  # Adding 1 for single person\nbold(\"Categoiries in Family_size:\")\ndisplay(merged.familySize.value_counts()) \n \"\"\"Create buckets of single, small, medium, and large and then put respective values into them.\"\"\"\nmerged.familySize.replace(to_replace = [1], value = \"single\", inplace = True)\nmerged.familySize.replace(to_replace = [2,3], value = \"small\", inplace = True)\nmerged.familySize.replace(to_replace = [4,5], value = \"medium\", inplace = True)\nmerged.familySize.replace(to_replace = [6, 7, 8, 11], value = \"large\", inplace = True) \n \"\"\"After processing, visualise and count the absolute and relative frequency of engineered familySize.\"\"\"\nplotFrequency(merged.familySize) \n \"\"\"Let's preview the variable Ticket first.\"\"\"\ndisplay(merged.Ticket.head()) \n \"\"\"Assign 'N' if there is only digits in Ticket. Otherwise just get the 1st character from Ticket.\"\"\"\notherwise = merged.Ticket.str.split(\" \").str.get(0).str.get(0) # This extracts the 1st character\nmerged[\"ticketProcessed\"] = np.where(merged.Ticket.str.isdigit(), \"N\", otherwise) \n \"\"\"Now calculate the categories in the ticketProcessed column.\"\"\"\nbold(\"Ticket after Processing:\")\ndisplay(merged.ticketProcessed.value_counts()) \n \"\"\"After processing, visualise and count the absolute and relative frequency of updated Ticket.\"\"\"\nplotFrequency(merged.ticketProcessed) \n \"\"\"#1.Create a function that removes outliers\"\"\"\ndef removeOutliers(variable):\n    \"\"\"Calculates and removes outliers using IQR method.\"\"\"\n    \n    # Calculate 1st, 3rd quartiles and iqr.\n    q1, q3 = variable.quantile(0.25), variable.quantile(0.75)\n    iqr = q3 - q1\n    \n    # Calculate lower fence and upper fence for outliers\n    lowerFence, upperFence = q1-1.5*iqr, q3+1.5*iqr   # Any values less than l_fence and greater than u_fence are outliers.\n    \n    # Observations that are outliers\n    outliers = variable[(variable<lowerFence) | (variable>upperFence)]\n    \n    # Drop obsevations that are outliers\n    filtered = variable.drop(outliers.index, axis = 0).reset_index(drop=True)\n    return filtered\n\n\n\"\"\"#2.Create another function to plot boxplot with and without outliers.\"\"\"\ndef plotBoxPlot(variable,filteredVariable):\n    \"\"\"Plots Box plot of a variable with and without outliers.\n    We will also use the output of removeOutliers function as the input to this function.\n    variable = variable with outliers,\n    filteredVariable = variable without outliers\"\"\"\n    \n    # Create subplot object.\n    fig = make_subplots(\n        rows=2,\n        cols=1,\n        print_grid=False,\n    subplot_titles=(f\"{variable.name} Distribution with Outliers\", f\"{variable.name} Distribution without Outliers\"))\n    \n    # This trace plots boxplot with outliers\n    fig.add_trace(\n        go.Box(\n            x = variable,\n            name = \"\", # This removes trace 0\n            marker = dict(color=\"darkred\")\n        ),\n    row=1,col=1)\n    \n    # This trace plots boxplot without outliers\n    fig.add_trace(\n        go.Box(\n            x = filteredVariable,\n            name = \"\",\n            marker = dict(color=\"green\")\n        ),\n    row=2,col=1)\n    \n    # Update layout\n    fig.layout.update(\n        height=800, \n        width=870,\n        showlegend=False,\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n    \n    # Update axes\n    fig.layout.xaxis2.update(title=f\"<b>{variable.name}</b>\")\n    return fig.show() \n \"\"\"Plot Age with and without outliers.\"\"\"\nplotBoxPlot(merged.Age,removeOutliers(merged.Age)) \n \"\"\"Plot Fare with and without outliers.\"\"\"\nplotBoxPlot(merged.Fare,removeOutliers(merged.Fare)) \n \"\"\"#1.Create a function to calculate missing values\"\"\"\ndef calculateMissingValues(variable):\n    \"\"\"Calculates missing values of a variable.\"\"\"\n    \n    return merged.isna().sum()[merged.isna().sum()>0] # Returns only columns with missing values\n\n\n\n\"\"\"\"#2.Create a function to plot scatter plot.\nThis can also be used to plot missing values\"\"\"\ndef plotScatterPlot(x, y, title, yaxis):\n    trace = go.Scatter(\n    x = x,\n    y = y,\n    mode = \"markers\",\n    marker = dict(color = y, size = 35, showscale = True, colorscale = \"Rainbow\"))\n    layout = go.Layout(hovermode= \"closest\",\n                       title = title,\n                       yaxis = dict(title = yaxis),\n                       height=600,\n                       width=900,\n                       showlegend=False,\n                        paper_bgcolor=\"rgb(243, 243, 243)\",\n                        plot_bgcolor=\"rgb(243, 243, 243)\"\n                      )\n    fig = go.Figure(data = [trace], layout = layout)\n    return fig.show()       \n \"\"\"Plot variables with their corresponding missing values.\"\"\"\nplotScatterPlot(calculateMissingValues(merged).index,\n               calculateMissingValues(merged),\n               \"Features with Missing Values\",\n               \"Missing Values\") \n \"\"\"Impute missing values of Embarked. Embarked is a categorical variable where S is the most frequent.\"\"\"\nmerged.Embarked.fillna(value=\"S\", inplace = True)\n\n\"\"\"Impute missing values of Fare. Fare is a numerical variable with outliers. Hence it will be imputed by median.\"\"\"\nmerged.Fare.fillna(value=merged.Fare.median(), inplace = True) \n \"\"\"Create a boxplot to view the variables correlated with Age. First extract the variables we're interested in.\"\"\"\ntoSearch = merged.loc[:, [\"Sex\", \"Pclass\", \"Embarked\", \"nameProcessed\", \"familySize\", \"Parch\", \n                             \"SibSp\", \"cabinProcessed\", \"ticketProcessed\"]]\n\nfig, axes = plt.subplots(nrows = 3, ncols = 3, figsize = (25,25))\nfor ax, column in zip(axes.flatten(), toSearch.columns):\n    sns.boxplot(x = toSearch[column], y = merged.Age, ax = ax)\n    ax.set_title(column, fontsize = 23)\n    ax.tick_params(axis = \"both\", which = \"major\", labelsize = 20)\n    ax.tick_params(axis = \"both\", which = \"minor\", labelsize = 20)\n    ax.set_ylabel(\"Age\", fontsize = 20)\n    ax.set_xlabel(\"\")\nfig.suptitle(\"Variables Associated with Age\", fontsize = 30)\nfig.tight_layout(rect = [0, 0.03, 1, 0.95]) \n \"\"\"Let's plot correlation heatmap to see which variable is highly correlated with Age and if our \nboxplot interpretation holds true. We need to convert categorical variable into numerical to plot \ncorrelation heatmap. So convert categorical variables into numerical.\"\"\"\nfrom sklearn.preprocessing import LabelEncoder\ntoSearch = toSearch.agg(LabelEncoder().fit_transform)\ntoSearch[\"Age\"] = merged.Age # Inserting Age in dataframe \"toSearch\".\ntoSearch = toSearch.set_index(\"Age\").reset_index() # Move Age column at index 0.\n\n# Now create the correlation heatmap\nfig,ax = plt.subplots(nrows=1, ncols=1, figsize=(15,6))\nsns.heatmap(toSearch.corr(), cmap =\"YlGnBu\", annot=True, annot_kws={\"size\":14}, ax=ax)\nax.set_title(\"Variables correlated with Age\", fontsize = 20)\nax.tick_params(axis = \"both\", which = \"major\", labelsize = 14)\nax.tick_params(axis = \"both\", which = \"minor\", labelsize = 14)\nplt.show() \n \"\"\"Impute Age with median of respective columns (i.e., nameProcessed and Pclass).\"\"\"\nmerged.Age = merged.groupby([\"nameProcessed\", \"Pclass\"])[\"Age\"].transform(lambda x: x.fillna(x.median()))\n\n\"\"\"So by now we should have variables with no missing values.\"\"\"\nbold(\"Missing Values after Imputation:\")\ndisplay(merged.isnull().sum()) \n \"\"\"Let's split the train and test data for bivariate analysis since test data has no Survived values. We need our target variable without missing values to conduct the association test with predictor variables.\"\"\"\ndf_train = merged.iloc[:891, :]\ndf_test = merged.iloc[891:, :]\ndf_test = df_test.drop(columns = [\"Survived\"], axis = 1)\n\n\"\"\"#1.Create a function that creates boxplot between categorical and numerical variables and calculates biserial correlation.\"\"\"\ndef boxplotAndCorrelation(numVariable,catVariable=df_train.Survived):\n    \"\"\"Return boxplot between a categorical and numerical variable. Also calculates biserial correlation.\n    numVariable = a numerical variable of interest.\"\"\"\n    \n    # Calculate point biserial correlation and p value\n    biserialCorr = stats.pointbiserialr(numVariable,catVariable)[0].round(2)\n    pValue = stats.pointbiserialr(numVariable,catVariable)[1].round(5)\n    \n    # Create subplot object.\n    fig = make_subplots(\n        rows=1,\n        cols=1,\n        print_grid=False,\n    )\n    \n    # This trace plots boxplot of categorical variable vs numerical variable\n    fig.add_trace(\n        go.Box(\n            x = catVariable,\n            y = numVariable,\n            marker_color=\"lightseagreen\",\n            ))\n    \n    \n    # Update layout\n    fig.layout.update(\n        height=500, \n        width=900,\n        showlegend=False,\n        title_text= f\"Association between {catVariable.name} and {numVariable.name} (corr: {biserialCorr}, p: {pValue})\",\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n    \n    # Update axes\n    fig.layout.xaxis1.update(title=f\"<b>{catVariable.name}</b>\")\n    fig.layout.yaxis1.update(title=f\"<b>{numVariable.name}</b>\")\n    return fig.show()\n\n\n\"\"\"#2.Create another function to calculate mean when grouped by categorical variable. And also plot the grouped mean.\"\"\"\ndef numGroupedByCat(numVariable,catVariable=df_train.Survived):\n    \"\"\"Returns a barplot showing mean of numerical variable across the class of categorical variable.\"\"\"\n    \n    # Calculates mean across different classes of categorical variable\n    numGroupedByCat = numVariable.groupby(catVariable).mean().round(2)\n    \n    # Create subplot object.\n    fig = make_subplots(\n        rows=1,\n        cols=1,\n        print_grid=False,\n    )\n    \n    # This trace plots barplot\n    fig.add_trace(\n        go.Bar(\n            x = numGroupedByCat.index,\n            y = numGroupedByCat,\n            text=numGroupedByCat,\n            hoverinfo=\"x+y\",\n            textposition=\"auto\",\n            textfont=dict(family=\"sans serif\",size=15)\n        ))\n    \n    # Update layout\n    fig.layout.update(\n        height=500, \n        width=900,\n        showlegend=False,\n        title_text= f\"Mean {numVariable.name} across {catVariable.name}\",\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n    \n    # Update axes\n    fig.layout.xaxis1.update(title=f\"<b>{catVariable.name}</b>\")\n    fig.layout.yaxis1.update(title=f\"<b>Mean {numVariable.name}</b>\")\n    return fig.show()\n\n    \n\"\"\"#3.This function plots histogram of numerical variable for every class of categorical variable.\"\"\"\ndef numHistByCat(numVariable,catVariable=df_train.Survived):\n    \"\"\"Returns numerical variable distribution across classes of categorical variable.\"\"\"\n    fig,ax = plt.subplots(1,1,figsize = (18,7))\n    font_size = 15\n    title_size = 18\n    numVariable[catVariable==1].hist(bins=50,color=\"green\", label = \"survived\", grid = False, alpha=0.5)\n    numVariable[catVariable==0].hist(bins=50,color=\"red\", label = \"died\", grid = False, alpha=0.5)\n    ax.set_yticks([])\n    ax.tick_params(axis=\"x\", labelsize=font_size)\n    ax.set_xlabel(f\"{numVariable.name}\", fontsize = font_size)\n    ax.set_title(f\"{numVariable.name} Distribution of Survivors vs Victims\", fontsize = title_size)\n    plt.legend()\n    return plt.show()\n\n   \n\"\"\"#4.Create a function to calculate anova between numerical and categorical variable.\"\"\"\ndef calculateAnova(numVariable, catVariable=df_train.Survived):\n    \"\"\"Returns f statistics and p value after anova calculation.\"\"\"\n    \n    groupNumVariableByCatVariable1 = numVariable[catVariable==1] # Group our numerical variable by categorical variable(1). Group Fair by survivors\n    groupNumVariableByCatVariable0 = numVariable[catVariable==0] # Group our numerical variable by categorical variable(0). Group Fare by victims\n    # Calculate one way anova\n    fValue, pValue = stats.f_oneway(groupNumVariableByCatVariable1, groupNumVariableByCatVariable0) # Calculate f statistics and p value\n    return f\"Anova Result between {numVariable.name} & {catVariable.name}: f=> {fValue}, p=> {pValue}\" \n \"\"\"Create a boxplot to visualize the strength of association of Survived with Fare. Also calculate biserial correlation.\"\"\"\nboxplotAndCorrelation(df_train.Fare) \n \"\"\"So the mean fare of survivors should be much more (from positive correlation or boxplot interpretation) than those who died. Calculate mean fare paid by the survivors as well as by the victims.\"\"\"\nnumGroupedByCat(df_train.Fare) \n \"\"\"Plot histogram of survivor's vs victims fare.\"\"\"\nnumHistByCat(df_train.Fare) \n \"\"\"Let's perform ANOVA between Fare and Survived. One can omit this step. I perform just to show how anova is performed if there were more than two groups in our categorical variable.\"\"\"\ncalculateAnova(df_train.Fare) \n \"\"\"Let's create a box plot between Age and Survived to have an idea by how much Age is associated with Survived. Also find point biserial correlation between them.\"\"\"\nboxplotAndCorrelation(df_train.Age) \n \"\"\"So the mean age of survivors should be just less than those who died (small negative correlation and reading boxplot). Calculate the mean age of survivors and victims.\"\"\"\nnumGroupedByCat(df_train.Age) \n \"\"\"Histogram of survivors vs victims age.\"\"\"\nnumHistByCat(df_train.Age) \n \"\"\"Perform ANOVA between all the levels of Survived (i.e., 0 and 1) and Age.\"\"\"\ncalculateAnova(df_train.Age) \n \"\"\"#1.Create a function that calculates absolute and relative frequency of Survived variable by a categorical variable. And then plots the absolute and relative frequency of Survived by a categorical variable.\"\"\"\ndef calculateCrosstabulation(catVariable, targetCatVariable=df_train.Survived):\n    \"\"\" Plots cross tabulation in absolute and relative scale.\n    catVariable = input categorical variable, \n    targetCatVariable = our target categorical variable.\"\"\"\n    \n    # Calculate cross tabulation in abs and relative scale\n    absCount = pd.crosstab(index = catVariable, columns = targetCatVariable)\\\n    .rename(columns={0:\"Victims\",1:\"Survivors\"})\n    relCount = pd.crosstab(index = catVariable, columns = targetCatVariable, normalize=\"index\")\\\n    .rename(columns={0:\"Victims\",1:\"Survivors\"})*100\n    relCount = relCount.round(1)\n    \n    # Create two subplots of bar chart\n    fig=make_subplots(\n        rows=2, \n        cols=1,\n        vertical_spacing=0.3,\n        subplot_titles=(f\"Absolute Count of Survival and Death by {catVariable.name}\", \n                        f\"Percentage Count of Survival and Death by {catVariable.name}\"),\n        print_grid=False) # This suppresses \"This is the format of your plot grid:\" text from popping out.\n\n    # Add trace for absolute frequency\n    for col in absCount.columns:\n        fig.add_trace(go.Bar(x=absCount.index,\n                             y=absCount[col],\n                             text=absCount[col],\n                             hoverinfo=\"x+y\",\n                             textposition=\"auto\",\n                             name=f\"{col}\",\n                             textfont=dict(family=\"sans serif\",size=14),\n                             ),\n                     row=1,\n                     col=1\n                     )\n\n\n    # Add another trace for relative frequency\n    for col in relCount.columns:\n        fig.add_trace(go.Bar(x=relCount.index,\n                             y=relCount[col],\n                             text=relCount[col],\n                             hoverinfo=\"x+y\",\n                             textposition=\"auto\",\n                             name=f\"{col}\",\n                             textfont=dict(family=\"sans serif\",size=14),\n                            ),\n                     row=2,\n                     col=1\n                     )\n        \n    # Update the layout. Add title, dimension, and background color\n    fig.layout.update(\n        height=600, \n        width=1000,\n        hovermode=\"closest\",\n        barmode = \"group\",\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n\n    # Set y-axes titles in bold\n    fig.layout.yaxis1.update(title=\"<b>Abs Frequency</b>\")\n    fig.layout.yaxis2.update(title=\"<b>Rel Frequency(%)</b>\")\n    \n    # Set x-axis title in bold\n    fig.layout.xaxis2.update(title=f\"<b>{catVariable.name}</b>\")\n    return fig.show()\n\n    \n\"\"\"#2.Create a function to calculate chi square test between a categorical and target categorical variable.\"\"\"\ndef calculateChiSquare(catVariable, targetCatVariable=df_train.Survived):\n    \"\"\"Returns chi square test restult between independent and dependent target variables.\"\"\"\n    \n    catGroupedByCatTarget = pd.crosstab(index = catVariable, columns = targetCatVariable)\n    testResult = stats.chi2_contingency(catGroupedByCatTarget)\n    print(f\"Chi Square Test Result between {targetCatVariable.name} & {catVariable.name}:\")\n    return print(testResult)\n\n\n\"\"\"#3.Finally create another function to calculate Bonferroni-adjusted pvalue for a categorical and target categorical variable.\"\"\"\ndef calculateBonferroniAdjusted(catVariable, targetCatVariable=df_train.Survived):\n    \"\"\"Returns bonferroni-adjusted pvalue between independent and dependent target variables.\"\"\"\n    \n    # Create one hot encoding for the independent categorical variable\n    catEncoded = pd.get_dummies(catVariable)\n    for column in catEncoded.columns:\n        catGroupedByCatTarget = pd.crosstab(index = catEncoded[column], columns = targetCatVariable)\n        testResult = stats.chi2_contingency(catGroupedByCatTarget)\n        print(f\"Bonferroni-adjusted pvalue between {catVariable.name}({column}) and {targetCatVariable.name}:\")\n        print(f\"{testResult}\\n\") \n \"\"\"Plot the no of passergers who survived and died due to their sex in absolute and relative scale.\"\"\"\ncalculateCrosstabulation(df_train.Sex) \n \"\"\"Perform chi-square test of independence between Survived and Sex.\"\"\"\ncalculateChiSquare(df_train.Sex) \n \"\"\"Plot the number of passengers who survived and died due to their pclass in absolute and relative scale.\"\"\"\ncalculateCrosstabulation(df_train.Pclass) \n \"\"\"Perform chi-square test of independence between Survived and Pclass.\"\"\"\ncalculateChiSquare(df_train.Pclass) \n \"\"\"Calculate Bonferroni-adjusted pvalue for Pclass (1,2,3) and Survived.\"\"\"\ncalculateBonferroniAdjusted(df_train.Pclass) \n \"\"\"Count and plot the survivors and victims by place of embarkation in absolute and relative scale.\"\"\"\ncalculateCrosstabulation(df_train.Embarked) \n \"\"\"Now perform chi-square test to find the association between Embarked and Survived.\"\"\"\ncalculateChiSquare(df_train.Embarked) \n \"\"\"Calculate Bonferroni-adjusted pvalue  between Embarked (C,Q,S one by one) and Survived.\"\"\"\ncalculateBonferroniAdjusted(df_train.Embarked) \n \"\"\"Count and plot absolute and relative number of survivors and victims due to SibSp.\"\"\"\ncalculateCrosstabulation(df_train.SibSp) \n \"\"\"Chi-square test between SibSp and Survived.\"\"\"\ncalculateChiSquare(df_train.SibSp) \n \"\"\"Visualize absolute and relative number of survivors and victims by Parch.\"\"\"\ncalculateCrosstabulation(df_train.Parch) \n \"\"\"Perform Chi-square test of independence between Parch and Survived.\"\"\"\ncalculateChiSquare(df_train.Parch) \n \"\"\"Visualize absolute and relative number of survivors and victims by nameProcessed.\"\"\"\ncalculateCrosstabulation(df_train.nameProcessed) \n \"\"\"Perform Chi-square test of independence between nameProcessed and Survived.\"\"\"\ncalculateChiSquare(df_train.nameProcessed) \n \"\"\"Plot the Survived's absolute and percentage count by familySize.\"\"\"\ncalculateCrosstabulation(df_train.familySize) \n \"\"\"Perform Chi-square test of independence between familySize and Survived.\"\"\"\ncalculateChiSquare(df_train.familySize) \n \"\"\"Calculate Bonferroni-adjusted pvalue  between familySize and Survived.\"\"\"\ncalculateBonferroniAdjusted(df_train.familySize) \n \"\"\"Count and plot absolute and relative number of survivors and victims due to cabin possession.\"\"\"\ncalculateCrosstabulation(df_train.cabinProcessed) \n \"\"\"Perform Chi-square test of independence between Cabin and Survived.\"\"\"\ncalculateChiSquare(df_train.cabinProcessed) \n \"\"\"Count and plot absolute and relative number of survivors and victims due to ticketProcessed category.\"\"\"\ncalculateCrosstabulation(df_train.ticketProcessed) \n \"\"\"Perform Chi-square test of independence between ticketProcessed and Survived.\"\"\"\ncalculateChiSquare(df_train.ticketProcessed) \n \"\"\"Create a function that plots the impact of 3 predictor variables at a time on a target variable.\"\"\"\ndef doMultivariateAnalysis(catVar1, catVar2, catVar3, targetCatVariable=df_train.Survived):\n    \"\"\"Plots the impact of 3 variables on Survived variable at the same time.\n    catVar1 = independent categorical variable 1,\n    catVar2 = independent categorical variable 2,\n    catVar3 = independent categorical variable 3.\n    targetCatVariable = our dependent categorical variable.\"\"\"\n    \n    fig,ax = plt.subplots(1,1,figsize = (18,5))\n    fontSize = 15\n    catGroupedByCatTarget = pd.crosstab(index = [catVar1, catVar2, catVar3],\n                                        columns = targetCatVariable, normalize = \"index\")*100\n    catGroupedByCatTarget.rename({0:\"%Died\", 1:\"%Survived\"}, axis = 1, inplace = True)\n    catGroupedByCatTarget.plot.bar(color = [\"red\", \"green\"],ax=ax)\n    ax.set_xlabel(f\"{catVar1.name},{catVar2.name},{catVar3.name}\", fontsize = fontSize)\n    ax.set_ylabel(\"Relative Frequency(%)\", fontsize = fontSize)\n    ax.tick_params(axis=\"x\", labelsize=fontSize)\n    ax.tick_params(axis=\"x\", labelsize=fontSize)\n    plt.legend(loc = \"best\")\n    return plt.show() \n \"\"\"Proportion of survivors and victims due to pclass, sex, and cabinProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.cabinProcessed)\nbold(\"Findings: Sex male seems to be deciding factor for death.\") \n \"\"\"Proportion of survivors and victims due to pclass, sex, and embarked.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.Embarked)\nbold(\"Findings: Again Sex male seems to be deciding factor for death and female for survival.\") \n \"\"\"Proportion of survivors and victims due to pclass, sex, and SibSp.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.SibSp)\nbold(\"Findings: Bigger SibSp and male Sex is responsible more for death.\") \n \"\"\"Proportion of survivors and victims due to pclass, sex, and Parch.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.Parch)\nbold(\"indings: Bigger Parch and Sex male is responsible more for death.\") \n \"\"\"Proportion of survivors and victims due to pclass, sex, and nameProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.nameProcessed)\nbold(\"Findings: Findings: Passengers with sex male and title mr mostly died.\") \n \"\"\"Proportion of survivors and victims due to pclass, sex, and familySize.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.familySize)\nbold(\"Findings: Sex male, family size single and large greatly influence the death ratio.\") \n \"\"\"Proportion of survivors and victims due to pclass, sex, and ticketProcessed category.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.ticketProcessed)\nbold(\"Findings: Sex female, ticketProcessed p and w mostly survived.\") \n \"\"\"Proportion of survivors and victims due to pclass, nameProcessed, and cabinProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.nameProcessed, df_train.cabinProcessed)\nbold(\"Findings: Title mrs, master and cabin x had best survival ratio.\") \n \"\"\"Proportion of survivors and victims due to familSize, sex, and cabinProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.familySize, df_train.Sex, df_train.cabinProcessed)\nbold(\"Findings: family size small, medium and sex female had best survival chance.\") \n \"\"\"Proportion of survivors and victims due to sex, nameProcessed, and familySize.\"\"\"\ndoMultivariateAnalysis(df_train.Sex, df_train.nameProcessed, df_train.familySize)\nbold(\"Findings: Title aristocrat, sex female and familySize small mostly survived.\") \n \"\"\"Proportion of survivors and victims due to sex, nameProcessed, and cabinProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.Sex, df_train.nameProcessed, df_train.cabinProcessed)\nbold(\"Findings: Title aristocrat, miss, mrs and sex female mostly survived.\") \n \"\"\"Proportion of survivors and victims due to sex, nameProcessed, and embarked.\"\"\"\ndoMultivariateAnalysis(df_train.Sex, df_train.nameProcessed, df_train.Embarked)\nbold(\"Findings: Embarked c, sex female and title master and aristocrat had best survival rate.\") \n \"\"\"Proportion of survivors and victims due to sex, nameProcessed, and ticketProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.Sex, df_train.nameProcessed, df_train.ticketProcessed)\nbold(\"Findings: ticketProcessed n, w and sex male and title mr mostly died.\") \n \"\"\"Create bin categories for Age.\"\"\"\nageGroups = [\"infant\",\"child\",\"teenager\",\"youngAdult\",\"adult\",\"aged\"]\n\n\"\"\"Create range for each bin categories of Age.\"\"\"\ngroupRanges = [0,5,12,18,35,60,81]\n\n\"\"\"Create and view categorized Age with original Age.\"\"\"\nmerged[\"ageBinned\"] = pd.cut(merged.Age, groupRanges, labels = ageGroups)\nbold('**Age with Categorized Age:**')\ndisplay(merged[['Age', 'ageBinned']].head(2)) \n \"\"\"Create bin categories for Fare.\"\"\"\nfareGroups = [\"low\",\"medium\",\"high\",\"veryHigh\"]\n\n\"\"\"Create range for each bin categories of Fare.\"\"\"\nfareGroupRanges = [-1, 130, 260, 390, 520]\n\n\"\"\"Create and view categorized Fare with original Fare.\"\"\"\nmerged[\"fareBinned\"] = pd.cut(merged.Fare, fareGroupRanges, labels = fareGroups)\nbold(\"Fare with Categorized Fare:\")\ndisplay(merged[[\"Fare\", \"fareBinned\"]].head(2)) \n display(merged.head(2)) \n \"\"\"Let's see all the variables we currently have with their category.\"\"\"\ndisplay(merged.head(2))\n\n\"\"\"Drop the features that would not be useful anymore.\"\"\"\nmerged.drop(columns = [\"Name\", \"Age\", \"Fare\", \"Ticket\", \"Cabin\"], inplace = True, axis = 1)\n\n\"\"\"Features after dropping.\"\"\"\nbold(\"Features Remaining after Dropping:\")\ndisplay(merged.columns) \n \"\"\"Checking current data types.\"\"\"\nbold(\"Current Variable Data Types:\")\ndisplay(merged.dtypes) \n \"\"\"Correcting data types, converting into categorical variables.\"\"\"\nmerged.loc[:, [\"Pclass\", \"Sex\", \"Embarked\", \"cabinProcessed\", \"nameProcessed\", \"familySize\", \"ticketProcessed\"]]\\\n= merged.loc[:, [\"Pclass\", \"Sex\", \"Embarked\", \"cabinProcessed\", \"nameProcessed\", \"familySize\", \"ticketProcessed\"]]\\\n.astype('category') \n \"\"\"Check if data types have been corrected.\"\"\"\nbold(\"Data Types after Correction:\")\ndisplay(merged.dtypes) \n \"\"\"Convert categorical data into numeric to feed our machine learning model.\"\"\"\nmerged = pd.get_dummies(merged)\n\n\"\"\"Let's visualize the updated dataset that would be fed to our machine learning algorithms.\"\"\"\nbold(\"Preview of Processed Data:\")\ndisplay(merged.head(2)) \n \"\"\"Set a seed for reproducibility\"\"\"\nseed = 43\n\n\"\"\"Let's split the train and test set to feed machine learning algorithm.\"\"\"\ntrain = merged.iloc[:891, :]\ntest  = merged.iloc[891:, :] \n \"\"\"Drop passengerid from train set and Survived from test set.\"\"\"\ntrain = train.drop(columns = [\"PassengerId\"], axis = 1)\ntrain.Survived = train.Survived.astype(int) # Converts Survived to int requored for submission, otherwise\ntest = test.drop(columns = [\"Survived\"], axis = 1) # you will scored 0 on submission. \n \"\"\"Extract data sets as input and output for machine learning models.\"\"\"\nxTrain = train.drop(columns = [\"Survived\"], axis = 1) # Input matrix as pandas dataframe (dim:891*47).\nyTrain = train['Survived'] # Output vector as pandas series (dim:891*1)\n\n\"\"\"Extract test set\"\"\"\nxTest  = test.drop(\"PassengerId\", axis = 1).copy() \n \"\"\"See the dimensions of input and output data set.\"\"\"\nprint(f\"Input Matrix Dimension: {xTrain.shape}\")\nprint(f\"Output Vector Dimension: {yTrain.shape}\")\nprint(f\"Test Data Dimension: {xTest.shape}\") \n \"\"\"Building machine learning models: \nWe will try 10 different classifiers to find the best classifier after tunning model's hyperparameters that will best generalize the unseen(test) data.\"\"\"\n\n\"\"\"Now initialize all the classifiers object.\"\"\"\n\"\"\"#1.Logistic Regression\"\"\"\nlr = LogisticRegression()\n\n\"\"\"#2.Support Vector Machines\"\"\"\nsvc = SVC(gamma = \"auto\")\n\n\"\"\"#3.Random Forest Classifier\"\"\"\nrf = RandomForestClassifier(random_state = seed, n_estimators = 100)\n\n\"\"\"#4.KNN\"\"\"\nknn = KNeighborsClassifier()\n\n\"\"\"#5.Gaussian Naive Bayes\"\"\"\ngnb = GaussianNB()\n\n\"\"\"#6.Decision Tree Classifier\"\"\"\ndt = DecisionTreeClassifier(random_state = seed)\n\n\"\"\"#7.Gradient Boosting Classifier\"\"\"\ngbc = GradientBoostingClassifier(random_state = seed)\n\n\"\"\"#8.Adaboost Classifier\"\"\"\nabc = AdaBoostClassifier(random_state = seed)\n\n\"\"\"#9.ExtraTrees Classifier\"\"\"\netc = ExtraTreesClassifier(random_state = seed)\n\n\"\"\"#10.Extreme Gradient Boosting\"\"\"\nxgbc = XGBClassifier(random_state = seed)\n\n\n\"\"\"List of all the models with their indices.\"\"\"\nmodelNames = [\"LR\", \"SVC\", \"RF\", \"KNN\", \"GNB\", \"DT\", \"GBC\", \"ABC\", \"ETC\", \"XGBC\"]\nmodels = [lr, svc, rf, knn, gnb, dt, gbc, abc, etc, xgbc] \n \"\"\"Create a function that returns train accuracy of different models.\"\"\"\ndef calculateTrainAccuracy(model):\n    \"\"\"Returns training accuracy of a model.\"\"\"\n    \n    model.fit(xTrain, yTrain)\n    trainAccuracy = model.score(xTrain, yTrain)\n    trainAccuracy = round(trainAccuracy*100, 2)\n    return trainAccuracy\n\n# Calculate train accuracy of all the models and store them in a dataframe\nmodelScores = list(map(calculateTrainAccuracy, models))\ntrainAccuracy = pd.DataFrame(modelScores, columns = [\"trainAccuracy\"], index=modelNames)\ntrainAccuracySorted = trainAccuracy.sort_values(by=\"trainAccuracy\", ascending=False)\nbold(\"Training Accuracy of the Classifiers:\")\ndisplay(trainAccuracySorted) \n \"\"\"Create a function that returns mean cross validation score for different models.\"\"\"\ndef calculateXValScore(model):\n    \"\"\"Returns models' cross validation scores.\"\"\"\n    \n    xValScore = cross_val_score(model, xTrain, yTrain, cv = 10, scoring=\"accuracy\").mean()\n    xValScore = round(xValScore*100, 2)\n    return xValScore\n\n# Calculate cross validation scores of all the models and store them in a dataframe\nmodelScores = list(map(calculateXValScore, models))\nxValScores = pd.DataFrame(modelScores, columns = [\"xValScore\"], index=modelNames)\nxValScoresSorted = xValScores.sort_values(by=\"xValScore\", ascending=False)\nbold(\"Models 10-fold Cross Validation Score:\")\ndisplay(xValScoresSorted) \n \"\"\"Define all the models\" hyperparameters one by one first::\"\"\"\n\n\"\"\"Define hyperparameters the logistic regression will be tuned with. For LR, the following hyperparameters are usually tunned.\"\"\"\nlrParams = {\"penalty\":[\"l1\", \"l2\"],\n            \"C\": np.logspace(0, 4, 10),\n            \"max_iter\":[5000]}\n\n\"\"\"For GBC, the following hyperparameters are usually tunned.\"\"\"\ngbcParams = {\"learning_rate\": [0.01, 0.02, 0.05, 0.01],\n              \"max_depth\": [4, 6, 8],\n              \"max_features\": [1.0, 0.3, 0.1], \n              \"min_samples_split\": [ 2, 3, 4],\n              \"random_state\":[seed]}\n\n\"\"\"For SVC, the following hyperparameters are usually tunned.\"\"\"\nsvcParams = {\"C\": np.arange(6,13), \n              \"kernel\": [\"linear\",\"rbf\"],\n              \"gamma\": [0.5, 0.2, 0.1, 0.001, 0.0001]}\n\n\"\"\"For DT, the following hyperparameters are usually tunned.\"\"\"\ndtParams = {\"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n             \"min_samples_split\": np.arange(2,16), \n             \"min_samples_leaf\":np.arange(1,12),\n             \"random_state\":[seed]}\n\n\"\"\"For RF, the following hyperparameters are usually tunned.\"\"\"\nrfParams = {\"criterion\":[\"gini\",\"entropy\"],\n             \"n_estimators\":[10, 15, 20, 25, 30],\n             \"min_samples_leaf\":[1, 2, 3],\n             \"min_samples_split\":np.arange(3,8), \n             \"max_features\":[\"sqrt\", \"auto\", \"log2\"],\n             \"random_state\":[44]}\n\n\"\"\"For KNN, the following hyperparameters are usually tunned.\"\"\"\nknnParams = {\"n_neighbors\":np.arange(3,9),\n              \"leaf_size\":[1, 2, 3, 5],\n              \"weights\":[\"uniform\", \"distance\"],\n              \"algorithm\":[\"auto\", \"ball_tree\",\"kd_tree\",\"brute\"]}\n\n\"\"\"For ABC, the following hyperparameters are usually tunned.\"\"\"\nabcParams = {\"n_estimators\":[1, 5, 10, 15, 20, 25, 40, 50, 60, 80, 100, 130, 160, 200, 250, 300],\n              \"learning_rate\":[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5],\n              \"random_state\":[seed]}\n\n\"\"\"For ETC, the following hyperparameters are usually tunned.\"\"\"\netcParams = {\"max_depth\":[None],\n              \"max_features\":[1, 3, 10],\n              \"min_samples_split\":[2, 3, 10],\n              \"min_samples_leaf\":[1, 3, 10],\n              \"bootstrap\":[False],\n              \"n_estimators\":[100, 300],\n              \"criterion\":[\"gini\"], \n              \"random_state\":[seed]}\n\n\"\"\"For XGBC, the following hyperparameters are usually tunned.\"\"\"\nxgbcParams = {\"n_estimators\": (150, 250, 350, 450, 550, 650, 700, 800, 850, 1000),\n              \"learning_rate\": (0.01, 0.6),\n              \"subsample\": (0.3, 0.9),\n              \"max_depth\": np.arange(3,10),\n              \"colsample_bytree\": (0.5, 0.9),\n              \"min_child_weight\": [1, 2, 3, 4],\n              \"random_state\":[seed]} \n \"\"\"Create a function to tune hyperparameters of the selected models.\"\"\"\ndef tuneHyperparameters(model, params):\n    \"\"\"Returns best score of a model and its corresponding hyperparameters.\n    model = model to be optimized.\n    params = hyperparameters the models will be optimized with.\"\"\"\n    \n    # Construct grid search object with 10 fold cross validation.\n    gridSearch = GridSearchCV(model, params, verbose=0, cv=10, scoring=\"accuracy\", n_jobs = -1)\n    # Fit using grid search.\n    gridSearch.fit(xTrain, yTrain)\n    bestParams, bestScore = gridSearch.best_params_, round(gridSearch.best_score_*100, 2)\n    return bestScore, bestParams \n \"\"\"Due to computational restrictions, I won't optimise xgbc's hyperparameters.\"\"\"\nmodelNamesToTune = [x for x in modelNames if x not in [\"GNB\",\"XGBC\"]]\nmodelsToTune = [lr, svc, rf, knn, dt, gbc, abc, etc]\nparametersLists = [lrParams, svcParams, rfParams, knnParams, dtParams, gbcParams, abcParams, etcParams]\nbestScoreAndHyperparameters = list(map(tuneHyperparameters, modelsToTune, parametersLists)) \n \"\"\"Let's create a dataframe to store best score and best params.\"\"\"\nbestScoreAndHyperparameters = pd.DataFrame(bestScoreAndHyperparameters,\n                                             index=modelNamesToTune,\n                                             columns=[\"tunedAccuracy\", \"bestHyperparameters\"])\nbestScoreAndHyperparametersSorted = bestScoreAndHyperparameters.sort_values(by=\"tunedAccuracy\",\n                                                                                ascending=False)\nbold(\"Model's Accuracy after Tuning Hyperparameters:\")\ndisplay(bestScoreAndHyperparametersSorted.iloc[:,0].to_frame()) \n \"\"\"Let's check out LR separately.\"\"\"\nprint(f\"LR Best Score: {bestScoreAndHyperparametersSorted.loc['LR'][0]}\")\nprint(f\"And Best Parameters: {bestScoreAndHyperparametersSorted.loc['LR'][1]}\") \n \"\"\"Create a function that compares cross validation scores with tunned scores for different models by\nplotting them.\"\"\"\ndef compareModelsAccuracy():\n    \"\"\"Returns a stack bar chart of tuned and x validation scores of models.\"\"\"\n    \n    # Sort by index and converting to series object to plot.\n    xValScore = xValScoresSorted[~xValScoresSorted.index.isin([\"XGBC\",\"GNB\"])].sort_index().T.squeeze()\n    tunedScore = bestScoreAndHyperparametersSorted.iloc[:,0].sort_index().T.squeeze()\n    \n    # Create two subplots of stack bar chart\n    fig=make_subplots(\n        rows=1, \n        cols=1,\n        vertical_spacing=0.3,\n        print_grid=False) # This suppresses \"This is the format of your plot grid:\" text from popping out.\n\n    # Add trace for stack bar\n    fig.add_trace(go.Bar(x=xValScore.index,\n                             y=xValScore,\n                             text=xValScore,\n                             hoverinfo=\"x+y\",\n                             textposition=\"auto\",\n                             name=\"xValScore\",\n                             textfont=dict(family=\"sans serif\",size=14),\n                             ),\n                     row=1,\n                     col=1\n                     )\n\n    # Add another trace for stack bar\n    fig.add_trace(go.Bar(x=tunedScore.index,\n                             y=tunedScore,\n                             text=tunedScore,\n                             hoverinfo=\"x+y\",\n                             textposition=\"auto\",\n                             name=\"tunedScores\",\n                             textfont=dict(family=\"sans serif\",size=14),\n                             ),\n                     row=1,\n                     col=1\n                     )\n        \n    # Update the layout. Add title, dimension, and background color\n    fig.layout.update(\n        height=600, \n        width=950,\n        hovermode=\"closest\",\n        barmode = \"stack\",\n        title_text = \"Cross Vaidation Scores vs Optimized Scores\",\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n\n    # Set y-axis titles in bold\n    fig.layout.yaxis1.update(title=\"<b>%Accuracy</b>\")\n    \n    # Set x-axis title in bold\n    fig.layout.xaxis1.update(title=\"<b>Models</b>\")\n    return fig.show()\n\n\"\"\"Call the function to plot the scores.\"\"\"\ncompareModelsAccuracy() \n \"\"\"Instantiate the models with optimized hyperparameters.\"\"\"\n# Sort the dataframe by index and select bestHyperparameters column\ntunedParams = bestScoreAndHyperparametersSorted.sort_index().loc[:,\"bestHyperparameters\"]\nabc = AdaBoostClassifier(**tunedParams[\"ABC\"])\ndt  = DecisionTreeClassifier(**tunedParams[\"DT\"])\netc = ExtraTreesClassifier(**tunedParams[\"ETC\"])\ngbc = GradientBoostingClassifier(**tunedParams[\"GBC\"])\nknn = KNeighborsClassifier(**tunedParams[\"KNN\"])\nlr  = LogisticRegression(**tunedParams[\"LR\"])\nrf  = RandomForestClassifier(**tunedParams[\"RF\"])\nsvc = SVC(**tunedParams[\"SVC\"])\n\n\n\n\"\"\"Train all the models with optimised hyperparameters.\"\"\"\nmodels = [abc, dt, etc, gbc, knn, lr, rf, svc]\nmodelNames = tunedParams.index.values\nkeyValue = dict(zip(modelNames, models))\nbold(\"10-fold Cross Validation after Optimization:\")\nxValScore = []\nfor key, value in keyValue.items():\n    # Train the models with optimized parameters using cross validation.\n    # No need to fit the data. cross_val_score does that for us.\n    # But we need to fit train data for prediction in the follow session.\n    value.fit(xTrain, yTrain)\n    scores = cross_val_score(value, xTrain, yTrain, cv = 10, scoring=\"accuracy\")*100\n    xValScore.append(scores.mean())\n    print(\"Mean Accuracy: {:.4f} (+/- {:.4f}) [{}]\".format(scores.mean(), scores.std(), key)) \n \"\"\"Make prediction using all the trained models.\"\"\"\nmodelPrediction = pd.DataFrame({\"RF\":rf.predict(xTest),\n                                 \"GBC\":gbc.predict(xTest),\n                                 \"ABC\":abc.predict(xTest),\n                                 \"ETC\":etc.predict(xTest), \n                                 \"DT\":dt.predict(xTest),\n                                 \"SVC\":svc.predict(xTest), \n                                 \"KNN\":knn.predict(xTest), \n                                 \"LR\":lr.predict(xTest)\n                                })\n\n\"\"\"Let\"s see how each model classifies a prticular class.\"\"\"\nbold(\"All the Models Prediction:\")\ndisplay(modelPrediction.head()) \n \"\"\"Create a function that plot feature importance by the selected tree based models.\"\"\"\ndef plotFeatureImportance(model):\n    \"\"\"Return a plot of feature importance by model.\"\"\"\n    \n    importance = pd.DataFrame({\"feature\": xTrain.columns,\n                              \"importance\": np.round(model.feature_importances_,3)})\n    importanceSorted = importance.sort_values(by = \"importance\", ascending = False).set_index(\"feature\")\n    return importanceSorted\n\n\"\"\"Create subplots of feature impotance of rf, gbc, dt, etc, and abc.\"\"\"\nfig, axes = plt.subplots(3,2, figsize = (20,40))\nfig.suptitle(\"Tree Based Models Feature Importance\", fontsize = 28)\ntreeModels = [rf, gbc, dt, etc, abc]\ntreeModelNames = [\"RF\", \"GBC\", \"DT\", \"ETC\", \"ABC\"]\nfor ax, model, name in zip(axes.flatten(), treeModels, treeModelNames):\n    plotFeatureImportance(model).plot.barh(ax=ax, title=name, fontsize=18, color=\"green\")\n    ax.set_ylabel(\"Features\", fontsize = 15)\nfig.delaxes(ax = axes[2,1]) # We don\"t need the last subplot.\nfig.tight_layout(rect = [0, 0.03, 1, 0.97]) \n \"\"\"Let's plot feature importance of LR.\"\"\"\nfig, ax = plt.subplots(figsize=(18,4))\ncoeff = pd.DataFrame({\"feature\":xTrain.columns,\n                      \"importance\":np.transpose(lr.coef_[0])})\n\ncoeff.sort_values(by = \"importance\").set_index(\"feature\")\\\n.plot.bar(title = \"Feature Importance of Linear Model (LR)\", color=\"chocolate\", ax=ax)\nax.tick_params(axis = \"both\", which = \"major\", labelsize = 15)\nax.tick_params(axis = \"both\", which = \"minor\", labelsize = 15)\nax.set_xlabel(\"Feature\", fontsize = 15)\nplt.show() \n \"\"\"Create a function that returns learning curves for different classifiers.\"\"\"\ndef plotLearningCurve(model):\n    \"\"\"Returns a plot of learning curve of a model.\"\"\"\n    \n    # Create feature matrix and target vector\n    X, y = xTrain, yTrain\n    # Create CV training and test scores for various training set sizes\n    trainSizes, trainScores, testScores = learning_curve(model, X, y, cv = 10,\n                                                    scoring=\"accuracy\", n_jobs = -1, \n                                                    train_sizes = np.linspace(0.01, 1.0, 17), # 17 different sizes of the training set\n                                                    random_state = seed)\n                                                    \n\n    # Create means and standard deviations of training set scores\n    trainMean = np.mean(trainScores, axis = 1)\n    trainStd = np.std(trainScores, axis = 1)\n\n    # Create means and standard deviations of test set scores\n    testMean = np.mean(testScores, axis = 1)\n    testStd = np.std(testScores, axis = 1)\n\n    # Draw lines\n    plt.plot(trainSizes, trainMean, \"o-\", color = \"red\",  label = \"training score\")\n    plt.plot(trainSizes, testMean, \"o-\", color = \"green\", label = \"cross-validation score\")\n    \n    # Draw bands\n    plt.fill_between(trainSizes, trainMean - trainStd, trainMean + trainStd, alpha = 0.1, color = \"r\") # Alpha controls band transparency.\n    plt.fill_between(trainSizes, testMean - testStd, testMean + testStd, alpha = 0.1, color = \"g\")\n\n    # Create plot\n    font_size = 15\n    plt.xlabel(\"Training Set Size\", fontsize = font_size)\n    plt.ylabel(\"Accuracy Score\", fontsize = font_size)\n    plt.xticks(fontsize = font_size)\n    plt.yticks(fontsize = font_size)\n    plt.legend(loc = \"best\")\n    plt.grid() \n \"\"\"Now plot learning curves of the optimized models in subplots.\"\"\"\nplt.figure(figsize = (25,25))\nlcModels = [rf, gbc, dt, etc, abc, knn, svc, lr]\nlcLabels = [\"RF\", \"GBC\", \"DT\", \"ETC\", \"ABC\", \"KNN\", \"SVC\", \"LR\"]\n\nfor ax, model, label in zip (range(1,9), lcModels, lcLabels):\n    plt.subplot(4,2,ax)\n    plotLearningCurve(model)\n    plt.title(label, fontsize = 18)\nplt.suptitle(\"Learning Curves of Optimized Models\", fontsize = 28)\nplt.tight_layout(rect = [0, 0.03, 1, 0.97]) \n \"\"\"Return prediction to use it in another function.\"\"\"\ndef xValPredict(model):\n    \"\"\"Returns prediction by which we can calculate different classification metrices.\"\"\"\n    \n    predicted = cross_val_predict(model, xTrain, yTrain, cv = 10)\n    return predicted # Now we can use it in another function by assigning the function to its return value.\n\n\"\"\"Function to return confusion matrix.\"\"\"\ndef calculateConfusionMatrix(model):\n    \"\"\"returns a models confusion matrix\"\"\"\n    \n    predicted = xValPredict(model)\n    confusionMatrix = pd.crosstab(yTrain, predicted, rownames = [\"Actual\"],\n                                   colnames = [\"Predicted/Classified\"], margins = True)\n    return display(confusionMatrix)\n\n\"\"\"Now calculate confusion matrix of rf and gbc.\"\"\"\nbold(\"RF Confusion Matrix:\")\ncalculateConfusionMatrix(rf)\nbold(\"GBC Confusion Matrix:\")\ncalculateConfusionMatrix(gbc) \n \"\"\"Function to calculate precision score.\"\"\"\ndef calculatePrecisionScore(model):\n    \"\"\"Calculates a model's precision score.\"\"\"\n    \n    predicted = xValPredict(model)\n    precisionScore = precision_score(yTrain, predicted)\n    return round(precisionScore*100, 2)\n\n\"\"\"Compute precision score for rf and gbc.\"\"\"\nprint(f\"RF  Precision Score: {calculatePrecisionScore(rf)}\")\nprint(f\"GBC Precision Score: {calculatePrecisionScore(gbc)}\") \n \"\"\"Function to calculate recall score.\"\"\"\ndef calculateRecallScore(model):\n    \"\"\"Calculate a model's recall score.\"\"\"\n    \n    predicted = xValPredict(model)\n    recallScore = recall_score(yTrain, predicted)\n    return round(recallScore*100, 2)\n\n\"\"\"Compute recall score for rf and gbc.\"\"\"\nprint(f\"RF  Recall Score: {calculateRecallScore(rf)}\")\nprint(f\"GBC Recall Score: {calculateRecallScore(gbc)}\") \n \"\"\"Function for specificity score.\"\"\"\ndef calculateSpecificityScore(model):\n    \"\"\"Returns a model's specificity score.\"\"\"\n    \n    predicted = xValPredict(model)\n    tn, fp, fn, tp = confusion_matrix(yTrain, predicted).ravel()\n    specificityScore = tn / (tn + fp)\n    return round(specificityScore*100, 2)\n\n\"\"\"Calculate specificity score for rf and gbc.\"\"\"\nprint(f\"RF  Specificity Score: {calculateSpecificityScore(rf)}\")\nprint(f\"GBC Specificity Score: {calculateSpecificityScore(gbc)}\") \n \"\"\"Function for F1 score.\"\"\"\ndef calculateF1Score(model):\n    \"\"\"Returns a model's f1 score.\"\"\"\n    \n    predicted = xValPredict(model)\n    f1Score = f1_score(yTrain, predicted)\n    return round(f1Score*100, 2)\n\n\"\"\"Calculate f1 score for rf and gbc.\"\"\"\nprint(f\"RF  F1 Score: {calculateF1Score(rf)}\")\nprint(f\"GBC F1 Score: {calculateF1Score(gbc)}\") \n \"\"\"Function to compute classification report.\"\"\"\ndef calculateClassificationReport(model):\n    \"\"\"Returns a model\"s classification report.\"\"\"\n    \n    predicted = xValPredict(model)\n    classificationReport = classification_report(yTrain, predicted)\n    return print(classificationReport)\n\n\"\"\"Now calculate classification report for rf and gbc.\"\"\"\nbold(\"RF Classification Report:\")\ncalculateClassificationReport(rf)\nbold(\"GBC Classification Report:\")\ncalculateClassificationReport(gbc) \n \"\"\"Function for plotting precision-recall vs threshold curve.\"\"\"\ndef plotPrecisionRecallVsThresholdCurve(model, title):\n    \"\"\"Plots precision-recall vs threshold curve for a model.\"\"\"\n\n    probablity = model.predict_proba(xTrain)[:, 1]\n    plt.figure(figsize = (18, 5))\n    precision, recall, threshold = precision_recall_curve(yTrain, probablity)\n    plt.plot(threshold, precision[:-1], \"b-\", label = \"precision\", lw = 3.7)\n    plt.plot(threshold, recall[:-1], \"g\", label = \"recall\", lw = 3.7)\n    plt.xlabel(\"Threshold\")\n    plt.legend(loc = \"best\")\n    plt.ylim([0, 1])\n    plt.title(title)\n    plt.show()\n\n\"\"\"Now plot precision-recall vs threshold curve for rf and gbc.\"\"\"\nplotPrecisionRecallVsThresholdCurve(rf, title = \"RF Precision-Recall vs Threshold Curve\" )\nplotPrecisionRecallVsThresholdCurve(gbc, title = \"GBC Precision-Recall vs Threshold Curve\") \n \"\"\"Function to plot recall vs precision curve.\"\"\"\ndef plotPrecisionVsRecallCurve(model, title):\n    \"\"\"Return amodel's recall vs precision curve.\"\"\"\n    \n    probablity = model.predict_proba(xTrain)[:, 1]\n    plt.figure(figsize = (18, 5))\n    precision, recall, threshold = precision_recall_curve(yTrain, probablity)\n    plt.plot(recall, precision, \"r-\", lw = 3.7)\n    plt.ylabel(\"Recall\")\n    plt.xlabel(\"Precision\")\n    plt.axis([0, 1.5, 0, 1.5])\n    plt.title(title)\n    plt.show()\n\n\"\"\"Now plot recall vs precision curve of rf and gbc.\"\"\"\nplotPrecisionVsRecallCurve(rf, title = \"RF Precision-Recall Curve\")\nplotPrecisionVsRecallCurve(gbc, title = \"GBC Precision-Recall Curve\") \n \"\"\"Function to plot ROC curve with AUC score.\"\"\"\ndef plotRocAndAucScore(model, title):\n    \"\"\"Returns roc and auc score of a model.\"\"\"\n    \n    probablity = model.predict_proba(xTrain)[:, 1]\n    plt.figure(figsize = (18, 5))\n    false_positive_rate, true_positive_rate, threshold = roc_curve(yTrain, probablity)\n    auc_score = roc_auc_score(yTrain, probablity)\n    plt.plot(false_positive_rate, true_positive_rate, label = \"ROC CURVE, AREA = \"+ str(auc_score))\n    plt.plot([0, 1], [0, 1], \"red\", lw = 3.7)\n    plt.xlabel(\"False Positive Rate (1-Specificity)\")\n    plt.ylabel(\"True Positive Rate (Sensitivity)\")\n    plt.axis([0, 1, 0, 1])\n    plt.legend(loc = 4)\n    plt.title(title)\n    plt.show()\n\n\"\"\"Plot roc curve and auc score for rf and gbc.\"\"\"\nplotRocAndAucScore(rf, title = \"RF ROC Curve with AUC Score\")\nplotRocAndAucScore(gbc, title = \"GBC ROC Curve with AUC Score\") \n \"\"\"Submission with the most accurate random forest classifier.\"\"\"\nsubmissionRF = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": rf.predict(xTest)})\nsubmissionRF.to_csv(\"rfSubmission.csv\", index = False)\n\n\n\"\"\"Submission with the most accurate gradient boosting classifier.\"\"\"\nsubmissionGBC = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": gbc.predict(xTest)})\nsubmissionGBC.to_csv(\"gbcSubmission.csv\", index = False) \n bold(\"How hard voting works:\")\ndata = [[1, 1, 1, 0, 1], \n        [0, 0, 0, 1, 0]]\ndisplay(pd.DataFrame(data, columns= [\"Class\",\"RF\", \"LR\", \"KNN\", \"Hard_voting\"]).set_index(\"Class\")) \n \"\"\"Create a data frame to store base models prediction.\nFirst 5 in the dataframe are tree based models. Then two are kernel based. \nAnd the last is a linear model.\"\"\"\nbasePrediction = modelPrediction # We\"ve a df of all the models prediction.\n\n\"\"\"Let\"s see how each model classifies a prticular class.\"\"\"\nbold(\"All the Base Models Prediction:\")\ndisplay(basePrediction.head())\n\n\"\"\"Let\"s visualize the correlations among the predictions of base models.\"\"\"\nfig,ax = plt.subplots(nrows=1, ncols=1, figsize=(15,6))\nsns.heatmap(basePrediction.corr(), cmap =\"YlGnBu\", annot=True, annot_kws={\"size\":14}, ax=ax)\nax.set_title(\"Prediction Correlation among the Base Models\", fontsize = 20)\nax.tick_params(axis = \"both\", which = \"major\", labelsize = 14)\nax.tick_params(axis = \"both\", which = \"minor\", labelsize = 14)\nplt.show() \n \"\"\"We will use mlxtend library to train, predict and plot decision regions of hard voting ensemble classifier.\"\"\"\n\"\"\"Define base models for hard voting ensemble.\"\"\"\nbaseModels = [rf, gbc, dt, knn, lr]\n\n\"\"\"Initialize hard voting ensemble.\"\"\"\nhardVct = EnsembleVoteClassifier(clfs = baseModels, voting=\"hard\")\nprint(\"Training Hard Voting Ensemble Classifier...\")\ndisplay(hardVct.fit(xTrain, yTrain))\nprint(\"Done.\")\n\n\"\"\"Predict with hard voting ensemble.\"\"\"\nyPredHardVct = pd.DataFrame(hardVct.predict(xTest), columns = [\"hardVct\"])\n\n\"\"\"Hard voting cross validation score.\"\"\"\nprint(\"\\nComputing Hard Voting Cross Val Score...\")\nhardXValScore = cross_val_score(hardVct, xTrain, yTrain, cv = 10, scoring = \"accuracy\")\nhardXValScore = round(hardXValScore.mean()*100, 2)\nprint(\"Done.\")\n\n\"\"\"Our tunned scores\"\"\"\ntunedScore = bestScoreAndHyperparametersSorted.iloc[:,0]\n\n\"\"\"Compare hard voting score with best base models scores.\"\"\"\nhardVctVsBaseScore = pd.DataFrame({\"hardVsBaseScore(%)\": [hardXValScore,\n                                                          tunedScore[\"RF\"],\n                                                          tunedScore[\"GBC\"], \n                                                          tunedScore[\"DT\"],\n                                                          tunedScore[\"KNN\"], \n                                                          tunedScore[\"LR\"]]\n                                  })\n\n\"\"\"So basically we\"re comparing hard voting x_val_score with base models\"s tunned score.\"\"\"\nhardVctVsBaseScore.index = [\"hardVct\", \"RF\", \"GBC\", \"DT\", \"KNN\", \"LR\"]\nbold(\"Hard Voting vs Base Models Scores:\")\ndisplay(hardVctVsBaseScore) \n \"\"\"Perform Standarization:\nVariables have very different ranges (diffenence between max and  min).\nThe purpose of standarization is to reduce the dispersion of these variables.\"\"\"\n\n\"\"\"Initialize standard scaler object.\"\"\"\nstdScaler = StandardScaler()\n\"\"\"Fit standard scaler object to train data.\"\"\"\nstdScaler.fit(xTrain)\n\"\"\"Apply the standard scaler to training set.\"\"\"\nxTrainScaled = stdScaler.transform(xTrain)\n\n\n\"\"\"Perform PCA:\"\"\"\n\"\"\"Initialize pca object with two components. i.e., converting into 2d from 47d.\"\"\"\npca = PCA(n_components = 2) # Projection to 2d from 47d\n\"\"\"Fit pca to scaled data.\"\"\"\npca.fit(xTrainScaled)\n\"\"\"Apply pca to scaled data.\"\"\"\npcaTrain = pca.transform(xTrainScaled)\n\"\"\"Create a data frame consisting of two pca.\"\"\"\ntrainPca = pd.DataFrame(data = pcaTrain, columns = [\"pca-1\", \"pca-2\"])\nbold(\"Projection to 2D from 47D:\")\ndisplay(trainPca.head())\n\n\"\"\"let\"s merge our two pca components with our target feature.\"\"\"\nfinalDf = pd.concat([trainPca, yTrain], axis = 1)\nbold(\"Target with 2-PCA Components:\")\ndisplay(finalDf.head()) \n \"\"\"Now calculate how much variance we get off these two components.\"\"\"\nbold(\"Total Variance Explained by 2 PCA Components:\")\ndisplay(round((pca.explained_variance_ratio_[0] + pca.explained_variance_ratio_[1])*100, 2)) \n \"\"\"Visualize our newly transformed samples with class labels.\"\"\"\nfig,ax = plt.subplots(1,1, figsize = (18,7))\nax.set_xlabel(\"PCA_1\", fontsize = 15)\nax.set_ylabel(\"PCA_2\", fontsize = 15)\nax.set_title(\"2-Component PCA (2D-Transformed Samples)\", fontsize = 20)\ntargets = [1, 0]\ncolors = [\"g\", \"r\"]\nfor target, color in zip(targets,colors):\n    indices = finalDf[\"Survived\"] == target\n    ax.scatter(finalDf.loc[indices, \"pca-1\"],\n               finalDf.loc[indices, \"pca-2\"],\n               c = color, s = 37)\nplt.legend(targets)\nplt.show() \n \"\"\"We will use mlxtend for plotting decision regions of base and ensemble models. Initialize base models and hard voting ensemble.\"\"\"\nrfPca = RandomForestClassifier(random_state = seed)\ngbcPca = GradientBoostingClassifier(random_state = seed)\ndtPca = DecisionTreeClassifier(random_state = seed)\nknnPca = KNeighborsClassifier()\nlrPca = LogisticRegression(random_state = seed)\nbaseModelPca = [rfPca, gbcPca, dtPca, knnPca, lrPca]\nhardVctPca = EnsembleVoteClassifier(clfs = baseModelPca, voting=\"hard\")\n\n\"\"\"Function to plot decision region.\"\"\"\ndef plotDecisionRegion(model):\n    \"\"\"Returns a model's decision region.\"\"\"\n    \n    \"\"\"Train models with data pca returned. Get the train data.\"\"\"\n    X = trainPca.values # Must be converted into numpy array.\n    y = yTrain.values\n    model.fit(X, y) \n    decisionRegion = plot_decision_regions(X = X, y = y.astype(np.integer), clf=model)\n    plt.xlabel(\"PCA-1\", fontsize = 15)\n    plt.ylabel(\"PCA_2\", fontsize = 15)\n    plt.xticks(fontsize = 15)\n    plt.yticks(fontsize = 15)\n    return decisionRegion\n\n\"\"\"Now plot decison regions for hard voting ensemble vs base models in subplots.\"\"\"\nplt.figure(figsize = (25,25))\nenModels = [hardVctPca, rfPca, gbcPca, dtPca, knnPca, lrPca]\nenLabels = [\"Hard_vct\", \"RF\", \"GBC\", \"DT\", \"KNN\", \"LR\"]\nfor ax, model, label in zip(range(1,7), enModels, enLabels):\n    plt.subplot(3,2,ax)\n    plotDecisionRegion(model)\n    plt.title(label, fontsize = 18)\nplt.suptitle(\"Hard Voting vs Base Models Decision Regions\", fontsize = 28)\nplt.tight_layout(rect = [0, 0.03, 1, 0.97]) \n \"\"\"Create a data frame consisting of base models and hard voting ensemble predictions. Revised base models are now rf, gbc, dt, knn, lr without svc and etc.\"\"\"\nbasePrediction = basePrediction.drop(columns = [\"ABC\", \"SVC\", \"ETC\"], axis = 1)\n\n\"\"\"See base models prediction with hard voting prediction.\"\"\"\nhardBase = pd.concat([basePrediction, yPredHardVct], sort = False, axis = 1)\ndisplay(hardBase.head(7)) \n bold(\"How soft voting works:\")\ndata = [[0.49, 0.99, 0.49, 0.66, 1], \n        [0.51, 0.01, 0.51, 0.34, 0]]\ndisplay(pd.DataFrame(data, columns= [\"RF\", \"LR\", \"KNN\", \"Average\", \"Soft_voting\"])) \n \"\"\"Base models for soft voting is the base models of hard voting.\"\"\"\n\"\"\"Initialize soft voting ensemble.\"\"\"\nbaseModels = [rf, gbc, dt, knn, lr]\nsoftVct = EnsembleVoteClassifier(clfs = baseModels, voting = \"soft\")\nprint(\"Fitting Soft Voting Ensemble...\")\ndisplay(softVct.fit(xTrain, yTrain))\nprint(\"Done.\")\n\n\"\"\"Predict with soft voting ensemble.\"\"\"\nyPredSoftVct = pd.DataFrame(softVct.predict(xTest), columns = [\"Soft_vct\"])\n\n\"\"\"Hard voting cross validation score.\"\"\"\nprint(\"\\nComputing Soft Voting X Val Score...\")\nsoftXValScore = cross_val_score(softVct, xTrain, yTrain, cv = 10, scoring = \"accuracy\")\nsoftXValScore = round(softXValScore.mean()*100, 2)\nprint(\"Done.\")\n\n\"\"\"Compare hard voting score with best base models scores.\"\"\"\nsoftVsBaseScore = pd.DataFrame({\"Soft_vs_base_score(%)\": [softXValScore,\n                                                          tunedScore[\"RF\"],\n                                                          tunedScore[\"GBC\"], \n                                                          tunedScore[\"DT\"],\n                                                          tunedScore[\"KNN\"], \n                                                          tunedScore[\"LR\"]]\n                               })\n\"\"\"So basically we\"re comparing soft voting x_val_score with base models\"s tunned score.\"\"\"\nsoftVsBaseScore.index = [\"Soft_vct\", \"RF\", \"GBC\", \"DT\", \"KNN\", \"LR\"]\nbold(\"Soft Voting vs Base Models Scores:\")\ndisplay(softVsBaseScore) \n \"\"\"We would use the same data to plot decision region we got analysing PCA.\"\"\"\nsoftVctPca = EnsembleVoteClassifier(clfs = baseModelPca, voting = \"soft\")\n\n\"\"\"Plot decision regions for soft voting ensemble vs base models in subplots.\"\"\"\nplt.figure(figsize = (25,25))\nenModels = [softVctPca, rfPca, gbcPca, dtPca, knnPca, lrPca]\nenLabels = [\"Soft_vct\", \"RF\", \"GBC\", \"DT\", \"KNN\", \"LR\"]\nfor ax, model, label in zip(range(1,7), enModels, enLabels):\n    plt.subplot(3,2,ax)\n    plotDecisionRegion(model)\n    plt.title(label, fontsize = 18)\nplt.suptitle(\"Soft Voting vs Base Models Decision Regions\", fontsize = 28)\nplt.tight_layout(rect = [0, 0.03, 1, 0.97]) \n \"\"\"See base models prediction with soft voting prediction.\"\"\"\nsoftBase = pd.concat([basePrediction,yPredSoftVct], sort = False, axis = 1)\ndisplay(softBase.head()) \n \"\"\"Initialize bagging classifier.\"\"\"\nbagg = BaggingClassifier(base_estimator = rf, verbose = 0, n_jobs = -1, random_state = seed)\n\"\"\"We use rf as the base estimator for bagging technique.\"\"\"\nprint(\"Fitting Bagging Ensemble...\")\ndisplay(bagg.fit(xTrain, yTrain))\nprint(\"Done.\")\n\n\"\"\"Bagging cross validation score.\"\"\"\nprint(\"\\nComputing Bagging X Val Score..\")\nbaggXValScore = cross_val_score(bagg, xTrain, yTrain, cv = 10, scoring = \"accuracy\")\nbaggXValScore = np.round(baggXValScore.mean()*100, 2)\nprint(\"Done.\")\n\n\"\"\"Compare bagging ensemble score with best base models scores.\"\"\"\nbaggVsBaseScore = pd.DataFrame({\"Bagging_vs_base_score(%)\": [baggXValScore,\n                                                          tunedScore[\"RF\"],\n                                                          tunedScore[\"GBC\"], \n                                                          tunedScore[\"DT\"],\n                                                          tunedScore[\"KNN\"], \n                                                          tunedScore[\"LR\"]]\n                               })\n\n\"\"\"So basically we\"re comparing bagging x_val_score with base models\"s tunned score.\"\"\"\nbaggVsBaseScore.index = [\"Bagg\", \"RF\", \"GBC\", \"DT\", \"KNN\", \"LR\"]\nbold(\"Bagging vs Base Models Scores:\")\ndisplay(baggVsBaseScore) \n \"\"\"We will use adaptive boosting, gradient boosting and extreme gradient boosting classifiers for boosting ensemble method.\"\"\"\n\"\"\"Initialize boosting classifier. Base models for boosting:\"\"\"\nboostModels = [abc, gbc, xgbc] # Unoptimized xgbc\nboost = EnsembleVoteClassifier(clfs = boostModels, voting=\"hard\")\n\n\"\"\"Fitting boosting.\"\"\"\nprint(\"Fitting Boosting Ensemble...\")\ndisplay(boost.fit(xTrain, yTrain))\nprint(\"Done.\")\n\n\"\"\"Boosting cross validation score.\"\"\"\nprint(\"\\nCalculating Boosting X Val Score...\")\nboosXValScore = cross_val_score(boost, xTrain, yTrain, cv = 10, scoring = \"accuracy\")\nboosXValScore = round(boosXValScore.mean()*100, 2)\nprint(\"Done.\")\n\n\"\"\"Compare boosting ensemble score with best base models scores.\"\"\"\nxgbcXValScore = 82.27  # xgbc\"s x_val_score.\nboostVsBaseScore = pd.DataFrame({\"Boosting_vs_base_score(%)\": [boosXValScore,\n                                                                  tunedScore[\"ABC\"],\n                                                                  tunedScore[\"GBC\"], \n                                                                  xgbcXValScore]})\n\"\"\"So basically we\"re comparing boosting x_val_score with base models\"s tunned score except xgbc.\"\"\"\nboostVsBaseScore.index = [\"Boost\", \"ABC\", \"GBC\", \"XGBC\"]\nbold(\"Boosting vs Base Models Scores:\")\ndisplay(boostVsBaseScore) \n \"\"\"Perform blending in mlens.\"\"\"\n\"\"\"Initialize blend ensembler.\"\"\"\nblend = BlendEnsemble(n_jobs = -1, test_size = 0.5, random_state = seed)\n\"\"\"Base models for blending.\"\"\"\nbaseModels = [gbc, rf, dt, knn, abc]\nblend.add(baseModels)\n\"\"\"Meta learner for blending. We will use lr.\"\"\"\nblend.add_meta(lr)\n\"\"\"Train the blend ensemble.\"\"\"\nprint(\"Fitting Blending...\")\ndisplay(blend.fit(xTrain, yTrain))\nprint(\"Done.\") \n \"\"\"Initialize base models. We will use the same base models as blending.\"\"\"\nbaseModels = [rf, dt, gbc, abc, knn]\n\"\"\"Perform stacking.\"\"\"\nsTrain, sTest = stacking(baseModels,                # list of base models\n                           xTrain, yTrain, xTest,   # data\n                           regression = False,         # classification task (if you need \n                                                       # regression - set to True)\n                           mode = \"oof_pred_bag\",      # mode: oof for train set, predict test \n                                                       # set in each fold and vote\n                           needs_proba = False,        # predict class labels (if you need \n                                                       # probabilities - set to True) \n                           save_dir = None,            # do not save result and log (to save \n                                                       # in current dir - set to \".\")\n                           metric = accuracy_score,    # metric: callable\n                           n_folds = 10,               # number of folds\n                           stratified = True,          # stratified split for folds\n                           shuffle = True,             # shuffle the data\n                           random_state= seed,         # ensure reproducibility\n                           verbose = 1)                # print progress \n \"\"\"Input features for meta learner.\"\"\"\ndisplay(sTrain[:5])\ndisplay(sTrain.shape) \n '''Test (prediction) set for meta learner.'''\ndisplay(sTest[:5].shape)\ndisplay(sTest.shape) \n \"\"\"Initialize 1st level model that is our meta learner. We will use lr.\"\"\"\nsuperLearner = lr \n    \n\"\"\"Fit meta learner on the output of base learners.\"\"\"\nprint(\"Fitting Stacking...\")\nsuperLearner.fit(sTrain, yTrain)\nprint(\"Done.\")\n\"\"\"Finally predict using super learner.\"\"\"\nyPredSuper = superLearner.predict(sTest) \n \"\"\"Predicting with different ensembles.\"\"\"\n\n\"\"\"Hard voting.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": hardVct.predict(xTest)})\nsubmission.to_csv(\"hardVctSubmission.csv\", index = False)\n\n\"\"\"Soft voting.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": softVct.predict(xTest)})\nsubmission.to_csv(\"softVctSubmission.csv\", index = False)\n\n\"\"\"Bagging.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": bagg.predict(xTest)})\nsubmission.to_csv(\"baggSubmission.csv\", index = False)\n\n\"\"\"Boosting.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": boost.predict(xTest)})\nsubmission.to_csv(\"boostSubmission.csv\", index = False)\n\n\"\"\"Blending.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": blend.predict(xTest).astype(int)})\nsubmission.to_csv(\"blendSubmission.csv\", index = False)\n\n\"\"\"Stacking.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": yPredSuper.astype(int)})\nsubmission.to_csv(\"stackingSubmission.csv\", index = False) \n \"\"\"Create a df of different ensemble submission scores and base models.\"\"\"\nsubmissionScore = pd.DataFrame({\"models\":[\"bagging(en)\", \"boosting(en)\", \"blending(en)\", \"stacking(en)\", \n                                          \"hardVoting(en)\", \"softVoting(en)\", \"rf(base)\", \"gbc(base)\"],\n             \"scoredOnSubmission\":[0.81339, 0.78947, 0.79425, 0.79904, 0.79904, 0.79904, 0.80382, 0.78947]})\nsubmissionScore = submissionScore.set_index(\"models\").sort_values(by=\"scoredOnSubmission\", ascending = False)\nbold(\"Ensemble vs Base Models Scores on Submission:\")\ndisplay(submissionScore) \n \"\"\"Let's plot models' submission score for the last time.\"\"\"\ndef plotSubmissionScore():\n    \"\"\"Returns a bar chart of different models scored on submission.\"\"\"\n    \n    # Create a subplot of bar chart\n    fig=make_subplots(\n        rows=1, \n        cols=1,\n        vertical_spacing=0.3,\n        print_grid=False) # This suppresses \"This is the format of your plot grid:\" text from popping out.\n\n    # Add trace for bar chart\n    fig.add_trace(go.Bar(x=submissionScore.index,\n                             y=submissionScore.T.squeeze(), # Converts df to series\n                             text=submissionScore.T.squeeze(),\n                             hoverinfo=\"x+y\",\n                             textposition=\"auto\",\n                             marker = dict(color=submissionScore.T.squeeze(), colorscale=\"Rainbow\"),\n                             textfont=dict(family=\"sans serif\",size=14),\n                             ),\n                     row=1,\n                     col=1\n                     )\n\n        \n    # Update the layout. Add title, dimension, and background color\n    fig.layout.update(\n        height=600, \n        width=950,\n        hovermode=\"closest\",\n        title_text = \"Models Score on Submission\",\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n\n    # Set y-axis titles in bold\n    fig.layout.yaxis1.update(title=\"<b>Submission score</b>\")\n    \n    # Set x-axis title in bold\n    fig.layout.xaxis1.update(title=\"<b>Models</b>\")\n    return fig.show()\n\n\"\"\"Call the function to plot the scores.\"\"\"\nplotSubmissionScore()",
    "markdown_source": "# About this Kernel\nThis kernel may (or may not) be helpful in your long and often tedious machine learning journey. Sometimes you may find this notebook verbose and overwhelming particularly if you're a beginner. This verbosity tries to explain everything I could possibly know. Once you get through the notebook, you could expect to have a good grasp of the fundamentals. I've also tried to write reusable codes as much as possible using custom functions so that we can avoid writing the same code again and again. Let's get started. \n # Outlines\n\n* [1.Problem Description and Objective](#1)\n* [2.Importing Packages and Collecting Data](#2)\n* [3.Variable Description and Identification](#3)\n   * [3.1 Variable Description](#3.1) [3.2 Categorical and Numerical Variables](#3.2) [3.3 Variable Data Types](#3.3)\n* [4.Univariate Analysis](#4)\n   * [4.1 Categorical Variables](#4.1)\n      * [4.1.1 Survived](#4.1.1) [4.1.2 Sex](#4.1.2) [4.1.3 Pclass](#4.1.3) [4.1.4 Embarked](#4.1.4) [4.1.5 Cabin](#4.1.5) [4.1.6 Name](#4.1.6) [4.1.7 Ticket](#4.1.7) [4.1.8 SibSp](#4.1.8) [4.1.9 Parch](#4.1.9)\n   * [4.2 Numerical Variables](#4.2)    \n      * [4.2.1 Fare](#4.2.1)  [4.2.2 Age](#4.2.2)  [4.2.3 PassengerId](#4.2.3)\n* [5.Feature Engineering](#5)\n   * [5.1 Process Cabin](#5.1) [5.2 Process Name](#5.2) [5.3 Process SibSp & Parch](#5.3)  [5.4 Process Ticket](#5.4)\n* [6.Outliers Detection](#6)\n   * [6.1 Outliers Detection of Age](#6.1)  [6.1 Outliers Detection of Fare](#6.2)\n* [7.Imputing Missing Variables](#7)\n   * [7.1 Impute Embarked & Fare](#7.1)  [7.2 Impute Age](#7.2)\n* [8.Bivariate Analysis](#8)\n   * [8.1 Numerical & Categorical Variables](#8.1)\n      * [8.1.1 Fare & Survived](#8.1.1)   [8.1.2 Age & Survived](#8.1.2)\n   * [8.2 Categorical & Categorical Variables](#8.2)\n      * [8.2.1 Sex & Survived](#8.2.1) [8.2.2 Pclass & Survived](#8.2.2) [8.2.3 Embarked & Survived](#8.2.3) [8.2.4 SIbSp & Survived](#8.2.4) [8.2.5 Parch & Survived](#8.2.5) [8.2.6 nameProcessed & Survived](#8.2.6) [8.2.7 familySize & Survived](#8.2.7) [8.2.8 cabinProcessed & Survived](#8.2.8) [ 8.2.9 ticketProcessed & Survived](#8.2.9)\n* [9.Multivariate Analysis](#9)  \n   * [9.1 (Pclass, Sex, cabinProcessed) vs Survived](#9.1) [9.2 (Pclass, Sex, Embarked) vs Survived](#9.2) [9.3 (Pclass, Sex, SibSp) vs Survived](#9.3) [9.4 (Pclass, Sex, Parch) vs Survived](#9.4) [9.5 (Pclass, Sex, nameProcessed) vs Survived](#9.5) [9.6 (Pclass, Sex, familySize) vs Survived](#9.6) [9.7 (Pclass, Sex, ticketProcessed) vs Survived](#9.7) [9.8 (Pclass, nameProcessed, cabinProcessed) vs Survived](#9.8) [9.9 (familySize, Sex, cabinProcessed) vs Survived](#9.9) [9.10 (Sex, nameProcessed, familySize) vs Survived](#9.10) [9.11 (Sex, nameProcessed, cabinProcessed) vs Survived](#9.11) [9.12 (Sex, nameProcessed, Embarked) vs Survived](#9.12) [9.13 (Sex, nameProcessed, ticketProcessed) vs Survived ](#9.13)\n* [10.Data Transformation](#10) \n   * [10.1 Binning Continuous Variables](#10.1)\n      * [10.1.1 Binning Age](#10.1.1) [10.1.2 Binning Fare](#10.1.2)\n   * [10.2 Dropping Features](#10.2) [10.3 Correcting Data Types](#10.3) [10.4 Encoding Categorical Variables](#10.4)\n* [11.Model Building and Evaluation](#11)   \n   * [11.1 Training Model](#11.1) [11.2 Model Evaluation](#11.2) [11.2.1 Cross Validation](#11.2.1) [11.2.2 Tunning Hyperparameters](#11.2.2) [11.2.3 Model Selection](#11.2.3) [11.3 Retrain & Predict Using Optimized Hyperparameters](#11.3) [11.4 Feature Importance](#11.4) [11.5 Learning Curves](#11.5)\n* [12.More Evaluation Metrics](#12)  \n   * [12.1 Confusion Matrix](#12.1) [12.2 Precision Score](#12.2) [12.3 Recall (or Sensitivity or True Positive Rate)](#12.3) [12.4 Specificity ( or True Negative Rate)](#12.4) [12.5 F1 Score](#12.5) [12.6 Classification Report](#12.6) [12.7 Precision-Recall vs Threshold Curve](#12.7) [12.8 Precision-Recall Curve](#12.8) [12.9 ROC  Curve & AUC Score ](#12.9)\n* [13.Prediction & Submission](#13) \n* [14.Introduction to Ensemble](#14)\n   * [14.1 Hard Voting Ensemble](#14.1) [14.2 Introduction to PCA](#14.2) [14.3 Soft Voting Ensemble](#14.3) [14.4 Bagging](#14.4) [14.5 Boosting](#14.5) [14.6 Blending](#14.6) [14.7 Stacking](#14.7) [14.8 Evaluating Different Ensembles](#14.8)\n* [15.End Note](#15) \n # 1.Problem Description and Objective <a id=\"1\"></a>\nThe sinking of the RMS Titanic is one of the most notorious shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crews. This harrowing tragedy shocked the international community and led to better safety regulations for ships.\n\nIn this problem, we're asked to complete the analysis of what sorts of passengers were likely to survive the tragedy using machine learning. So its our job to predict if a passenger survived from the sinking Titanic or not with the help of machine learning. So its a binary classification problem.\n\n# 2.Importing Packages and Collecting Data <a id=\"2\"></a>\nAfter importing required modules, let's read train and test data from csv files. \n **Note:** We don't have Survived variable for test set. This will be our task to infer Survived for test set by learning from the train set. \n # 3.Variable Description and Identification <a id=\"3\"></a>\nLet's describe what each of the variable indicates and identify our response and predictor variables. Also seperate the categorical variables from numerical variables and finally identify pandas data types (i.e., object, float64 or int64) for every variable.\n\n## 3.1 Variable Description <a id=\"3.1\"></a> \n ### So what can we see??\n**We can see total 12 variables. And each variable has 1309 observations (excluding Survived).**\n### Here comes the description of all variables:\n1. **PassengerId** is a unique identifying number assigned to each passenger.\n2. **Survived** is a flag that indicates if a passenger survived or died ( i.e., 0 = No, 1 = Yes).\n3. **Pclass** is the passenger class (i.e., 1 = 1st class, 2 = 2nd class, 3 = 3rd class).\n4. **Name** is the name of the passenger.\n5. **Sex** indicates the gender of the passenger (i.e., Male or female).\n6. **Age** indicates the age of the passenger.\n7. **Sibsp**  is the number of siblings/spouses aboard.\n8. **Parch** is the number of parents/children aboard.\n9. **Ticket** indicates the ticket number issued to the passenger.\n10. **Fare** indicates the amount of money spent on their ticket.\n11. **Cabin** indicates the cabin category occupied by the passenger.\n12. **Embarked** indicates the port where the passenger embarked from (i.e., C = Cherbourg, Q = Queenstown, S = Southampton).\n\n\n### Here, Survived is the target variable and rest of the variables are predictor variables.\n\n## 3.2 Categorical and Numerical Variables  <a id=\"3.2\"></a>\n**Categorical Variable:** Survived, Sex, Pclass (ordinal), Embarked, Cabin, Name, Ticket, SibSp, and Parch.\n\n**Numerical Variable:** Fare, Age, and PassengerId.\n## 3.3 Variable Data Types <a id=\"3.3\"></a> \n 1. **int data type variables:** Pclass, SibSp, Parch, and PassengerId.\n2. **float data type variables:** Fare and Age, *Survived (due to concatenation)*\n3. **object (numbers + strings) data type variables:** Name, Sex, Ticket, Cabin, and Embarked.\n\n# 4.Univariate Analysis <a id=\"4\"></a>\nUnivariate analysis separately explores the distribution of each variable in a data set. It looks at the range of values, as well as the central tendency of the values. Univariate data analysis does not look at relationships between various variables (like bivariate and multivariate analysis) rather it summarises each variable on its own. Methods to perform univariate analysis will depend on whether the variable is categorical or numerical. For numerical variable, we would explore its shape of distribution (distribution can either be symmetric or skewed) using histogram and density plots. For categorical variables, we would use bar plots to visualize the absolute and proportional frequency distribution. Knowing the distribution of the feature values becomes important when you use machine learning methods that assume a particular type of it, most often Gaussian. **Let's starts off with categorical variables:**\n\n## 4.1 Categorical Variables  <a id=\"4.1\"></a>\nTo analyse categorical variables, let's create a custom function to display bar chart in absolute and relative scale of a variable in a subplot. \n ###  4.1.1 Survived <a id=\"4.1.1\"></a> \n **Findings:** Variable Survived is imbalanced since the proportion of survivors and victims is not equally represented in its distribution. Out of 891 passengers, only 342 passengers survived and a whopping 549 passengers died. Or put another way, 61.62% passengers died while just 38.38% of passengers were lucky enough to survive. \n ### 4.1.2 Sex <a id=\"4.1.2\"></a> \n **Findings:** Variable Sex is imbalanced as proportion of male vs female in its distribution are not equally represented. Rather Male(843) has outnumbered female (466) in variable Sex. Or, proportionally, over 64% of Sex variable consists of label male while female contibutes to only over 35.5% of Sex.\n\n### 4.1.3 Pclass  <a id=\"4.1.3\"></a> \n **Findings:** Again class distribution of Pclass is imbalanced as three categories of Pclass are not evenly represented in its distribution. 3 (Pclass3) is the most occured (709) levels of Pclass while 2 is the least occured (277). Another way of saying that, over  54% of Pclass variable consists of 3(Pclass3) while 1 and 2 both combinedly contribute to nearly 46% of Pclass.\n\n### 4.1.4 Embarked  <a id=\"4.1.4\"></a> \n **Findings:** Embarked is also imbalanced since its levels are not equally represented in its distribution. A whopping 914 passengers embarked from Southamton while just 123 embarked from Queenstown. In other words, almost 70% of Embarked consists of S while both C and Q contribute to 30 to Embarked.\n\n### 4.1.5 Cabin <a id=\"4.1.5\"></a> \n **Findings:** Looks like Cabin is an alphanumeric type variable with 1014 missing obsevations. There are 187 kinds of categories in variable Cabin. Since there are too many categories in Cabin, we must process (i.e., reduce the number of categories) Cabin to check if there is any association between Survived and Cabin.\n\n### 4.1.6 Name <a id=\"4.1.6\"></a> \n **Findings:** As expected Name contains strings that has 1307 variations. So, like Cabin, we must process Name to get any clue about survival from it.\n\n### 4.1.7 Ticket  <a id=\"4.1.7\"></a> \n **Findings:** It seems Ticket also has too many unique categories (929). Being an alphanumeric type variable, we must process Ticket to get any useful insights about survival.\n\n### 4.1.8 SibSp  <a id=\"4.1.8\"></a> \n **Findings:** Once again, SibSp is not balanced as levels of SibSp(7) are not equally represented in its distribution. 891 passengers were without siblings or spouses. Put another way, over 68% passengers had no siblings or spouses aboard, followed by over 24% passengers had 1 siblings or spouse.\n\n### 4.1.9 Parch  <a id=\"4.1.9\"></a> \n **Findings:** Parch isn't balanced as levels of Parch(8) are not equally represented in its distribution. Over one thousand passengers were without parents or children, followed by 170 passengers had one parents or children. In other words, over 76.5% passengers were without parents or children while rest of the 23.5% had few parents or children.\n\n## 4.2 Numerical Variables <a id=\"4.2\"></a>\nWe would like to analyse numerical variables using histogram, density plot, and summary statistics. To analyse numerical variables, we will create 2 custom functions. The 1st one will plot histogram and density plot for each numerical variable. And the 2nd one will calculate summary statistics including skewness. \n ### 4.2.1 Fare <a id=\"4.2.1\"></a> \n **Reading the histogram, it's clear that Fare's distribution has a high positive skewness. And it seems a number of passengers (653) paid for fare between 5 to 15 (less than 15), followed by 25 to 35 (less than 35).**\n\nThere is also another, often clearer, way to grasp the distribution: density plots or, more formally, Kernel Density Plots. They can be considered a smoothed version of the histogram. One advantage of density plot over histogram is that its shape of distribution isn't affected by the number of bins used. \n **So what does the  value of skewness suggest?**\n1. If skewness is less than \u22121 or greater than +1, the distribution can be considered as highly skewed.\n2. If skewness is between \u22121 and \u2212\u00bd or between +\u00bd and +1, the distribution can be considered as moderately skewed.\n3. And finally if skewness is between \u2212\u00bd and +\u00bd, the distribution can be considered as approximately symmetric.    \n\n**Findings:** Density plot shows the mass of the distribution of Fare is heavily concentrated on the left of the figure due to very long tail on the right side. So it can be said that Fare is substantially skewed(positively) that is also supported by the calculated positive value of skewness of 4.37\n\n### 4.2.2 Age <a id=\"4.2.2\"></a> \n **At first glance, Age seems to be positively skewed (slightly). 344 passengers' age is between 20 to 30(less than 30). And passengers between age 70 to 80(including 80) was 8 were the least.** \n **Findings:** What we can see from the density plot is that the mass of the distribution of Age is slightly concentrated on the left of the figure due to comparatively long tail on the right side. So it can be said that Age is almost normally distributed since the tail on the both sides are almost equal and it has a small value of positive skewness of 0.41 (in between -0.5 to 0.5). So it can be said that Age is almost normally distributed.\n\n### 4.2.3 PassengerId <a id=\"4.2.3\"></a> \n **Findings:** PassengersId is an unique identity number (positive integer) assigned to each passenger.\n\n# 5.Feature Engineering <a id=\"5\"></a>\nIn this section, we would either modify or create new features from the exsisting features which are otherwise hard to analyse in their raw forms that we saw in Univariate Analysis section. We would engineer features like Cabin, Name, SibSp & Parch, and Ticket that could tell us something about survival or death once they're processed.\n\n## 5.1 Process Cabin <a id=\"5.1\"></a> \n Looks like Cabin is alphanumeric type variable with no special characters (like ., /, % etc) between letters and numbers. It has also 1014 missing obsevations. It is reasonable to presume that those NaNs didn't have a cabin, which could tell us something about 'Survived'. We will flag NaN as 'X' and keep only the 1st character where Cabin has alphanumeric values. Since its a categorical variable, we must reduce the number of categories for further analysis. **To avoid mutability, we won't change any variable's state in place, rather we'll create a brand new variable.** \n **Findings:** It seems nearly 77.5% of passengers had X cabin category (formerly NaNs), followed by over 7% had cabin category C and nearly 5% had cabin category B.\n\n## 5.2 Process Name <a id=\"5.2\"></a> \n What we can easily understand from this column, it contains strings that further contains titles such as Mr, Mrs, Master etc. These titles give us some useful information about sex(Mr = male, Mrs = married female), age(Miss is usually younger than Mrs), and profession(Master indicates profession and hence social status) etc which in the end could tell us something more about survival. Now we want to extract these titles from Name to check if there is any association between these titles and Survived. \n We can see there are several titles with the very least frequency. So, it makes sense to put them in fewer buckets. Professionals like Dr, Rev, Col, Major, Capt will be put into 'Officer' bucket. First name such as Dona, Jonkheer, Countess, Sir, Lady, Don were usually entitled to the aristocrats and hence these first name will be put into bucket 'Aristocrat'. We would also replace Mlle and Ms with Miss and Mme by Mrs as these are French titles. \n **Findings:** Nearly 58% passengers had title Mr(male of course), followed almost 20% passengers had titles Miss(unmarried women hence usually younger than Mrs). Just over 15% passengers were married women (Mrs).\n\n## 5.3 Process SibSp & Parch <a id=\"5.3\"></a>\nIn univariate analysis, we saw some passengers had siblings/spouses and some didn't have. The same is also true for variable Parch. Since these two variables together indicate the size of a family, we would create a new variable 'familySize' from these two variables. \n We see there are several family sizes with the very least frequency. So its sensible to put them in a fewer buckets. We will create 4 buckets namely single, small, medium, and large for rest of them. \n **Findings:** Looks like most of the passengers (over 60%) were single(without family), followed by 30% passengers had a small family. Almost 5% passengers had medium families and just over 4.5% passengers had large families abroad.\n\n## 5.4 Process Ticket <a id=\"5.4\"></a> \n Ticket is also an alphanumeric type variable. We will create two groups-one will contain just number and other will only contain character extracted from string. If a row contains both character and number, we will keep only character. \n **Findings:** Over 73% passengers had ticket of category N, followed by nearly 7.5% passengers ticket category were S and P. Passengers with W ticket category were as low as 1.45%.\n\n# 6.Outliers Detection <a id=\"6\"></a>\n**How outliers affect the distribution:** If a value of a variable is significantly above the expected range, it will drag the distribution to the right, making the graph right-skewed or positive-skewed (like Fare). Alternatively, If a value is significantly below the expected range, it will drag the distribution to the left, making the graph left-skewed or negative-skewed.\n\nAnother useful plot for visualizing a continuous variable is box plot. Box plot is particularly helpful to understand the spread of the continus data and whether there are potential unusual observations (outliers) in that variable. It presents information of min, 1st quartile, 2nd quartile(median), 3rd quartile, and max of a variable.**We will use IQR method to detect the outliers for variable Age and Fare though we won't remove them.** \n ## 6.1 Outliers Detection for Age <a id=\"6.1\"></a> \n **For a box plot, if the longer part of the box is right (or above) to the median, the data is said to be skewed right. If the longer part is  left (or below) to the median, the data is skewed left. In our case, the bigger part of the box is right to the median**\n\n## 6.2 Outliers Detection for Fare <a id=\"6.2\"></a> \n # 7.Imputing Missing Variables <a id=\"7\"></a>\nThe simpliest way to impute missing values of a variable is to impute its missing values with its mean, median or mode depending on its distribution and variable type(categorical or numerical). By now, we should have a good idea about the distribution of the variables and the presence of outliers in those variables. For categorical variables mode-imputation is performed and for numerical variable mean-impuation is performed if its distribution is symmetric(or almost symmetric or normal like Age). On the other hand, for a variable with skewed distribution and outliers (like Fare), meadian-imputation is recommended as median is more immune to outliers than mean. \n\nHowever, one clear disadvantage of using mean, median or mode to impute missing values is the addition of bias if the amount of missing values is significant (like Age). So simply replacing them with the mean or the median age might not be the best solution since the age may differ by groups and categories of passengers.\n\nTo solve this, we can group our data by some variables that have no missing values and for each subset compute the median age to impute the missing values. Or we can build a linear regression model that will predict missing values of Age using the features that have no missing values. These two methods may result in better accuracy without high bias, unless a missing value is expected to have a very high variance. We will show the former method of imputation. \n **The above plot shows the most missing values for Cabin, Survived, followed by Age, Embarked and Fare. Since we created a new variable cabinProcessed off Cabin, we don't need to impute Cabin.** \n **Findings:** \n1. Age has 263 missing values.\n2. Fare has only 1.\n3. Cabin has a whopping 1014 missing values.\n4. Embarked has just 2 missing values.\n5. **Finally Survived has missing values (due to concatenation of train and test set) that we would predict learning from the train dataset.**\n\n**Remember we have total 1309 observations except variable Survived.**\n\n## 7.1 Impute Embarked & Fare <a id=\"7.1\"></a> \n ## 7.2 Impute Age <a id=\"7.2\"></a>\nTo impute Age with grouped median, we need to know which features are highly correlated with Age. Let's find out the variables correlated with Age. \n **Findings:** \n1. Age distribution seems to be the same in male and female subpopulations of Sex and S, C, Q subpopulations of Embarked. So Sex and Embarked aren't good predictors for Age.\n2. On the other hand, Age distribution seems to be distinct in Pclass's 1, 2 and 3 subpopulations, so Pclass is informative to predict Age.\n3. Finally, Age distribution seems to be distinct in different categories for nameProcessed, familySize, SibSp, Parch, and cabinProcessed. So they might be good predictors for Age as well. \n **Findings:** As expected Sex, Embarked, and ticketProcessed have the weakest correlation with Age what we could guess beforehand from boxplot. Parch and familySize are moderately correlated with Age. nameProcessed, Pclass, Cabin, and SibSp have the highest correlation with Age. But we are gonna use nameProcessed and Pclass only in order to impute Age since they have the strongest correlation with Age. So the tactic is to impute missing values of Age with the median age of similar rows according to nameProcessed and Pclass. \n # 8.Bivariate Analysis <a id=\"8\"></a>\nBeing the most important part, bivariate analysis tries to find the relationship between two variables. We will look for correlation or association between our predictor and target variables. Bivariate analysis is performed for any combination of categorical and numerical variables. The combination can be: Numerical & Numerical, Numerical & Categorical and Categorical & Categorical. Different methods are used to tackle these combinations during analysis process. The methods are:\n1. Numerical & Numerical: Pearson's correlation, or Spearman correlation (the later doesn't require normal distribution).\n2. Numerical & Categorical: Point biserial correlation (only  if categorical variable is binary type), or ANOVA test. For this problem, you can use either biserial correlation or ANOVA. But I will perform both test just to learn because ANOVA will come in handy if categorical variable has more than two classes.\n3. Categorical & Categorical: We would use Chi-square test for bivariate analysis between categorical variables.\n\n## 8.1 Numerical & Categorical Variables <a id=\"8.1\"></a>\nFirst we create a boxplot between our numerical and categorical variables to check if the distribution of numerical variable is distinct in different classes of nominal variables. Then we find the mean of numerical variable for every class of categorical variable. Again we plot a histogram of numerical variable for every class of categorical variable. Finally anova or point biserial correlation (in case of two class categorical variable) is calculated to find association between nominal and numerical variables.    \n ### 8.1.1 Fare & Survived <a id=\"8.1.1\"></a> \n **Findings:** The distribution of Fare between different categories of Survived (0 and 1) are distinct (very least overlap) that makes it comparatively strong predictor for Survived what is kind of true from the correlation value of  0.257307 and the p value (less than 0.01) that suggests we're 99% confident that this correlation is statistically significant. Also survival is positively correlated to Fare, so the more you pay for fare, the more your chances are to survive that is quite evident from the box plot. \n **Looks like, on average, if you pay more for your ticket, you are more likely to survive. Let's plot histogram of survivors and victims fare together to validate our intuition:** \n **That's true. Passengers who paid more for their fair, mostly survived.**\n\n**ANOVA:** \nThe ANOVA(ANalysis Of VAriance) test lets us check whether a numeric response variable varies according to the levels (or class) of a categorical variable. When we simply refer to 'ANOVA', we usually mean the 'one way' ANOVA which is a test for exploring the impact of one single factor on three or more groups (but two groups would also do, as we explain below).\n\nThough one should use either point biserial correlation (if categorical variable is of binary type) or ANOVA method for this problem to find any association between a categorical and a numerical variable, I would perform ANOVA too to have an intuition of how ANOVA works. Though ANOVA is usually prefered if the categorical variable having more than two groups, it is also possible to perform ANOVA for a categorical variable with two groups.\n\nThe one-way ANOVA tests whether the mean of some numeric variable differs across the levels of one categorical variable. It essentially answers the question: do any of the group means differ from one another? The null hypothesis is all of the group means are equal. And the alternate hypothesis is any of the group means differ from one another. \n **Interpretation of ANOVA result:**\nAs p < 0.05 we state that we have a main interaction effect. This simply means that amongst the groups at least any of the group(or groups) means statistically significantly  differ from one another (true for only more than two groups). However, this result does not identify the sample pair (or pairs) which cause this significance (again true for more than two groups of categorical variable but we have just two groups..i.e., 0 and 1).\nSo, when ANOVA reports 'interaction effect' we need to further identify the group pairs by applying pair-wise controls(required for more than two groups of categorical variable). Although these controls could be done by implementing ordinary t-test but this is not the right approach. So a post hoc-test ( usually Tukey's test) is performed to find the pair or pairs that cause the difference. Though Tukey's test is not required with a categorical variable less than three groups.\n\n***Note:*** Tukey's test is not required if ANOVA gives a p value greater than 0.05 and nominal variable has less than three groups.  \n \n### 8.1.2 Age & Survived <a id=\"8.1.2\"></a> \n **Findings:** Box plot shows the distribution of Age between categories of Survived (1 and 0) has significant overlap which is also kind of true from a small correlation value of -0.05939. And a p value greater than 0.05 indicates that there is no evidence that the correlation is statistically significant. As we can see that Survived is inversly correlated to Age, so if you are younger, you are just likely to survive. \n **Analysing box and above bar plot, we have a feeling that younger people, on average, were just more likely to survive. Let's plot one histogram of survivors' age and another of victims' age to validate our intuition.** \n **We see infants and children had high survival rate. The oldest passengers (Age = 80) also survived. A large number of passengers aged from 16 to 30 died.** \n **Note:** Choose either biserial correlation (if categorical variable has two groups) or Anova. If anova states main interaction effect(i.e.,p<0.05) and categorical variable has more than two categories ( like good, better, best), then perform tukey test to find out the pair or pairs that cause the difference(i.e., main interaction effect).\n\n**Interpretation of ANOVA result:**\nSince p>0.05, we can say that survival chance is not statistically associated with Age.\n\n## 8.2 Categorical & Categorical Variables <a id=\"8.2\"></a>\nWe will calculate and plot absolute and relative frequency of output categorical variable by predictor nominal variables. We would calculate the chi square test between target nominal and predictor nominal variables. Finally we will calculate Bonferroni-adjusted P value if the contingency table has dimension more than 2x2. \n ### 8.2.1 Sex & Survived <a id=\"8.2.1\"></a> \n **Findings:** Out of 342 survivors, 233 passergers were female while only 109 passengers were male. So female survivors were more than double the male survivors. Proportion tells a female has over 74% chance of survival while male has almost 19% chance of survival. So female has the best chance of survival.\n\n***Chi-square Test***: The Chi-square test of independence tests if there is a significant relationship between two categorical variables.The data is usually displayed in a cross-tabulation format with each row representing a category for one variable and each column representing a category for another variable. Chi-square test of independence is an omnibus test.That is it tests the data as a whole. This means that one will not be able to tell which levels (categories) of the variables are responsible for the relationship **if the Chi-square table is larger than 2\u00d72. If the test is larger than 2\u00d72, it requires post hoc testing.**\n\n**The H0 (Null Hypothesis): There is no relationship between variable 1 and variable 2.**\n\n**The H1 (Alternative Hypothesis): There is a relationship between variable 1 and variable 2.**\n\nIf the p-value is significant (less than 0.05), you can reject the null hypothesis and claim that the findings support the alternate hypothesis. While we check the results of the chi2 test, we need also to check that the expected cell frequencies are greater than or equal to 5. If a cell has an expected frequency less that 5, then the Fisher\u2019s Exact test should be use to overcome this problem.\n\nThe chi2_contingency() method conducts the Chi-square test on a contingency table (crosstab). \n ***Interpretation of chi-square test outcome***: The first value (260.717) is the Chi-square value, followed by the p-value (1.197e-58), then comes the degrees of freedom (1), and lastly it outputs the expected frequencies as an array. Since all of the expected frequencies are greater than 5, the chi2 test results can be trusted. We can reject the null hypothesis as the p-value is less than 0.05(infact p value is almost 0).  Thus, the results indicate that there is a statistically significant relationship between Sex and Survived.\n\n### 8.2.2 Pclass & Survived <a id=\"8.2.2\"></a> \n **Findings:** Out of 342 survivors, pclass1(136) has the most number of survivors followed by pclass3(119) and pclass2(87). But the percentage tells different story. If you're in class1, your survival chance is nearly 63% while pclass2 has just over 47% survival chance. But if you are in class3, your chance of survival is very bleak, i.e.,just over 24%. \n **Interpretation of chi-square test outcome:** The overall 3x2 table has a chi-square value of 102.889, pvalue  of 4.549e-23, degrees of freedom of 2 and the rest are the expected frequencies of array. Since all of the expected frequencies are greater than 5, the chi2 test results can be trusted. We can reject the null hypothesis as the p-value is less than 0.05(infact p value is almost 0). Thus, the results indicate that there is a statistically significant relationship between Pclass and titanic's survivors. \n\n\n**Post Hoc Test**: Although our Chi-square test was signficant, since our analysis is 3x2 we don't know which levels of Pclass(1, 2 or 3) have the strongest association with variable Survived. Hence we need to perform a post hoc test to verify if and which combinations are actually significantly associated with Survived. In order to do this, we need to conduct multiple 2\u00d72 Chi-square tests using the *Bonferroni-adjusted p-value.*\n\nTo conduct multiple 2\u00d72 Chi-square tests, one needs to regroup the variables for each test to where it is one category against the rest. For us, it will be:\n\n1. 1 vs 2\n2. 1 vs 3\n3. And finally 2 vs 3\n\n**Because there are 3 comparisons, the Bonferroni-adjusted P value needed for significance is 0.05/3, or 0.017. So for our any planned pairwise comparisons to be significant, the p-value must be less than 0.017.** \n **Interpretation of the outcome of  Bonferroni-adjusted p-value test:** Using the Bonferroni-adjusted p-value of 0.017, 3 out of 3 planned pairwise comparisons are significant. Though p value suggests Pclass2 has the weakest association with Survived compared to Pclass1 and Pclass3.\n\n###  8.2.3 Embarked & Survived <a id=\"8.2.3\"></a> \n **Findings:** Though people embarked from Southampton have the most survivors count (219) but proportion-wise it has only nearly 34% chance of survival. Because 427 passengers embarked from Southampton died. On the contrary, if you would embark from Cherbourg, you have a very decent chance of survival of over 55%.  Finally, people embarked from  Queenstown have a chance of survival more than 5% from those who embarked from Southampton. \n **Interpretation of chi-square test result:** The  3x2 table has a chi-square value of 25.96, pvalue of 2.3e-06, degrees of freedom of 2 and the rest are the expected frequencies of array. Since all of the expected frequencies are greater than 5, the chi2 test results can be trusted. We can reject the null hypothesis as the p-value is less than 0.05(infact p value is less than 0.01). Thus, the results indicate that there is a statistically significant relationship between the variables Embarked and Survived.\n\n**Because there are three comparisons, the Bonferroni-adjusted P value needed for significance is 0.05/3, or 0.017. So for our any planned pairwise comparisons to be significant, the p-value must be less than 0.017.** \n **Interpreting the result of pair-wise Bonferroni-adjusted pvalue:** Using the Bonferroni-adjusted p-value of 0.017, 2 of the 3 planned pairwise comparisons are significant. Bonferroni-adjusted p-value for Q and Survived is 0.989 which is way greater than 0.017. So it can be said that level Q of variable Embarked is not statistically associated with variable Survived.\n\n### 8.2.4 SibSp & Survived <a id=\"8.2.4\"></a> \n **Findings:** A large number of passengers (210) who survived were without (0) any siblings or spouse, followed by 112 passengers with 1 spouse or siblings. Percentage-wise, passengers with 1 spouse or siblings had over 53.5% chance of survival, followed by passengers with 2 siblings or spouse had over 46% chance of survival. Passengers with 5 or 8 siblings or spouse had all died. \n **Interpretation of Chi-square Test:**  Since all the expected frequencies aren't greater than 5, chi-square test result can't be trusted.\n\n### 8.2.5 Parch & Survived  <a id=\"8.2.5\"></a> \n **Findings:** Passengers with 3 children/parent had 60% survival rate, followed by passengers with 2 children/parent has a 50% survival rate. No passengers survived with 4 or 6 children/parent. \n **Interpretation of Chi-square Test Outcome:**  Since all the expected frequencies aren't greater than 5, chi-square test result can't be trusted.\n\n### 8.2.6 nameProcessed & Survived <a id=\"8.2.6\"></a> \n **Findings:** Women had the best survival rate, i.e., Mrs(over 79%) and Miss(over 70%) that reminds us the variable Sex where we have seen female were more likely to survive in. Mr is the worst title to have when it comes to survival situation since just over 15% of passengers with title Mr survived that again indicates the importance of Sex as a deal breaker for survival. \n **Interpretation of chi-square test result**: Since all the expected frequencies aren't greater than 5, chi-square test result can't be trusted.\n\n### 8.2.7 familySize & Survived <a id=\"8.2.7\"></a> \n **Findings:** Passengers with small and medium familiy size had good survival rate. Single passengers had survival chance of just over 30%. And passengers with large families has a survival rate below 15%. \n **Interpretation of chi-square test result**:Since all of the expected frequencies are greater than 5, the chi2 test results can be trusted. We can reject the null hypothesis as the p-value is less than 0.05(infact p value is almost 0). Thus, the results indicate that there is a statistically significant relationship between variable Family_size and Survived.\n\n**Because there are 8 comparisons, the Bonferroni-adjusted P value needed for significance is 0.05/8, or 0.0063. So for our any planned pairwise comparisons to be significant, the p-value must be less than 0.0063.** \n **Interpretation of Bonferroni-adjusted Post-hoc test result:** Using the Bonferroni-adjusted p-value of 0.0063, 3 of the 4 planned pairwise comparisons are significant. Bonferroni-adjusted p-value for medium and Survived is 0.03555 which is way greater than 0.0063. So it can be said that level medium of variable familySize is not statistically associated with variable Survived.\n\n### 8.2.8 cabinProcessed & Survived <a id=\"8.2.8\"></a> \n **Findings:** Most of the passengers survived and died were from cabin X. But percentage-wise, its category B, D, and E that had impressive chance of survival. People from cabin category X had just 30% chance of survival. \n **Interpretation of chi-square test result**: Since all of the expected frequencies aren't greater than 5, the chi2 test results can't be trusted.\n\n### 8.2.9 ticketProcessed & Survived <a id=\"8.2.9\"></a> \n **Findings:** 93% passengers died with ticket category A, over 64% survived from category P. Over 57% survived from F and just over 15% passengers survived from ticket category W. \n **Interpretation of chi-square test result**: Since all of the expected frequencies aren't greater than 5, the chi2 test results can't be trusted.\n\n# 9.Multivariate Analysis <a id=\"9\"></a>\nIn multivariate analysis, we try to find the relationship among more than two variables. Number of predictor variable in bivariate analysis was one. On the contrary, number of predictor variables for multivariate analysis are more than one. More specifically, we will try to associate more than one predictor variable with the response variable. We will just visualize the impact of different predictor variables (3 variables) at a time on variable Survived. \n ## 9.1 (Pclass, Sex, cabinProcessed) vs Survived <a id=\"9.1\"></a> \n ## 9.2 (Pclass, Sex, Embarked) vs Survived <a id=\"9.2\"></a> \n ## 9.3 (Pclass, Sex, SibSp) vs Survived <a id=\"9.3\"></a> \n ## 9.4 (Pclass, Sex, Parch) vs Survived <a id=\"9.4\"></a> \n ## 9.5 (Pclass, Sex, nameProcessed) vs Survived <a id=\"9.5\"></a> \n ## 9.6 (Pclass, Sex, familySize) vs Survived <a id=\"9.6\"></a> \n ## 9.7 (Pclass, Sex, ticketProcessed) vs Survived <a id=\"9.7\"></a> \n ## 9.8 (Pclass, nameProcessed, cabinProcessed) vs Survived <a id=\"9.8\"></a> \n ## 9.9 (familySize, Sex, cabinProcessed) vs Survived <a id=\"9.9\"></a> \n ## 9.10 (Sex, nameProcessed, familySize) vs Survived <a id=\"9.10\"></a> \n ## 9.11 (Sex, nameProcessed, cabinProcessed) vs Survived <a id=\"9.11\"></a> \n ## 9.12 (Sex, nameProcessed, Embarked) vs Survived <a id=\"9.12\"></a> \n ## 9.13 (Sex, nameProcessed, ticketProcessed) vs Survived <a id=\"9.13\"></a> \n # 10.Data Transformation <a id=\"10\"></a>\nIn this section, we will categorize our continuous variables. After that, redundant and useless features will be dropped. And finally categorical variables will be encoded into numerical variables to feed our machine learning models.\n\n## 10.1 Binning Continuous Variables <a id=\"10.1\"></a>\nWe saw Age is inversely correlated with survival and infants were more likely to survive. We will create some categories of age to check which categories of age  are more likely to survive. We would do the same for Fare except Fair is posivively correlated with Survived.\n\n**Note:** Binning continuous variables prevents overfitting which is a common problem for tree based models like decision trees and random forest etc.\n\n### 10.1.1 Binning Age <a id=\"10.1.1\"></a> \n ### 10.1.2 Binning Fare <a id=\"10.1.2\"></a> \n ##  10.2 Dropping Features <a id=\"10.2\"></a>\nNow we have both transformed and the original variables transformation have been made from. So we should safely drop the variables that we think would not be useful anymore for our survival analysis since they are very unlikely to be analyzed in their raw forms. \n ## 10.3 Correcting Data Types <a id=\"10.3\"></a> \n 1. PassengerId, SibSp, and Parch data types will be kept same (integer).\n2. Survived data type will be converted into integer and rest of the variables' data types will be converted into categorical data types. \n ## 10.4 Encoding Categorical Variables <a id=\"10.4\"></a>\nWe would like to use one hot encoding instead of label encoding because algorithm might give weights to higher values if label encoding is used to encode numeric variables. \n # 11.Model Building and Evaluation <a id=\"11\"></a>\nWith all the preprocessings done and dusted, we're ready to train classifiers with the processed data. First extract train and test data from variable merged. Then feed the training data to the classifiers we're interested in for this problem. \n ## 11.1 Training Model <a id=\"11.1\"></a>\nWe would train 10 different classifiers for this binary classification problem. \n **Looks like all the tree based models have highest train accuracy followed KNN, LR, ABC and SVC. But train accuracy of a model is not enough to tell if a model can be able to generalize the unseen data or not. Because training data is something our model has been trained with, i.e., data our model has already seen it. We all know that, the purpose of building a machine learning model is to generalize the unseen data, i.e., data our model has not yet seen. Hence we can't use training accuracy for our model evaluation rather we must know how our model will perform on the data our model is yet to see.**\n\n## 11.2 Model Evaluation <a id=\"11.2\"></a>\nSo basically, to evaluate a model's performance, we need some data (input) for which we know the ground truth(label). For this problem, we don't know the ground truth for the test set but we do know for the train set. So the idea is to train and evaluate the model performance on different data. One thing we can do is to split the train set in two groups, usually in 80:20 ratio. That means we would train our model on 80% of the training data and we reserve the rest 20% for evaluating the model since we know the ground truth for this 20% data. Then we can compare our model prediction with this ground truth (for 20% data). That's how we can tell how our model would perform on unseen data. This is the first model evaluation technique. In sklearn we have a train_test_split method for that.\n\nTrain_test split has its drawbacks. Because this approach introduces bias as we are not using all of our observations for testing and also we're  reducing the train data size. To overcome this we can use a technique called cross validation where all the data is used for training and testing periodically. Thus we may reduce the bias introduced by train_test_split. From different cross validation methods, we would use k-fold cross validation. In sklearn we have a method cross_val_score for calculating k-fold cross validation score.\n\nHowever,  as the train set gets larger, train_test_split has its advantage over k-fold cross validation. Train_test_split is k-times faster than k-fold cross validation. If the training set is very large, both train_test_split and k-fold cross validation perform identically. So for a large training data, train_test_split is prefered over k-fold cross validation to accelerate the training process.\n\n### 11.2.1 K-Fold Cross Validation <a id=\"11.2.1\"></a>\nLet's say we will use 10-fold cross validation. So k = 10 and we have total 891 observations. Each fold would have 891/10 = 89.1 observations. So basically k-fold cross validation uses fold-1 (89.1 samples) as the testing set and k-1 (9 folds) as the training sets and calculates test accuracy.This procedure is repeated k times (if k = 10, then 10 times); each time, a different group of observations is treated as a validation or test set. This process results in k estimates of the test accuracy which are then averaged out. \n **I've always found that trying out multiple algorithms on the same problem reveals very interesting differences in the patterns the algorithms pick up well. Algorithms disagree on predictions because they've different ways of viewing the data.**\n\n**Findings:** Looks like LR and SVC have the highest cross validation accuracy among the classifiers, followed by GBC, XGBC, KNN, ABC, RF, and ETC.\n\n## 11.2.2 Tuning Hyperparameters  <a id=\"11.2.2\"></a>\n**Now let's add Grid Search to all the classifiers with the hopes of optimizing their hyperparameters and thus improving their accuracy. Are the default model parameters the best bet? Let's find out.**\n\n**Note:** Hyperparameters should be tuned for all the models you try because only then you will be able to tell what is the best you can get out of that particular model. \n **Note:** GridSearchCV will only consider the values for each hyperparameter that you explicitly define here. If you don't \ndefine it in the parameter dictionary object, it will not be included in the grid search.This process of finding the best \nparameters is called exhaustive grid-search because its trying every combination. \n **Since accuracy increases, it can be said that the most accurate logistic regression model uses C = 2.7825594022071245 and penalty = l2 as hyperparameters.** \n ## 11.2.3  Model Selection <a id=\"11.2.3\"></a>\nLet's compare our models according to their accuracy score after tunning hyperparameters with cross validation scores to select the best models for further study on this classification problem. \n **Findings:** Among the classifiers, RF and GBC have the highest accuracy after  tunning hyperparameters. So RF and GBC are perhaps worthy of further study on this classification problem. Hence we choose RF and GBC.\n\n**Note:** Please note that if we chose our classifier based on cross validation scores, we would not get RF and GBC as our best classifiers instead we would end up choosing LR and SVC. So it is recommended to select best classifiers based on accuracy after tunning hyperparameters though it is computationally intensive.\n\n## 11.3 Retrain and Predict Using Optimized Hyperparameters <a id=\"11.3\"></a>\nSo we have our best classifiers with their best hyperparameters that produces best accuracy out of a model. That means if we retrain the classifiers using their best hyperparameters, we will be able to get the very same score that we got after tunning hyperparameters (see part 14.4). Let's retrain our classifiers and then use cross validation to calculate the accuracy of the trained model. That's how we will have the same accuracy score as after tunning hyperparameters. Let's retrain models with optimized hyperparameters. \n **See! We've successfully managed to reproduce the same score that we achived only after tunning hyperparameters. Now if we predict using these trained models, we should have the best test accuracy possible out of those model. So let's predict using those trained models:** \n ## 11.4 Feature Importance <a id=\"11.4\"></a>\nDo the classifiers give the same priority to every feature? Let's visualize the features importance given by our classifiers. \n **Findings:** RF, DT, ETC, and ABC (in particular) give some features no importance (zero importance). On the other hand, GBC give all the features more or less importance but it doesn't give zero importance to any features. These are the tree based models that have 'feature_importances_' method by default. LR, KNN and SVC don't have this method. In this problem, SVC uses rbf kernel (only possible for linear kernel to plot feature importance), so its not possible to view feature importance given by SVC. Though its trickier, we would try to get the feature importance given by LR. \n **Findings:** We can see some negative values that means that higher value of the corresponding feature pushes the classification more towards the negative class (in our case 0) that is, of course, something we're already aware of. Some features like Family_size_single, Embarked_Q, Embarked_C, and Cabin_F were given zero importance by lr.\n\n## 11.5 Learning Curves  <a id=\"11.5\"></a>\nLet's plot the learning curves for the optimized classifiers to see their bias-variance tradeoff. \n **Findings:**\n1. RF, DT, SVC and ETC are just doing okay. Among them, SVC is doing the best in terms of bias-variance tradeoff since svc's train accuracy and cross validation accuracy are almost equal. Since training and validation curves haven't yet converged for these classifiers, adding more instances (rows) might help.\n\n2. On the other hand, learning curve of GBC, ABC, KNN and LR indicates a little bit high bias or low variance (underfitting) and as the curves have already converged, adding more training data just might not help. Rather adding more features (columns) and increasing model's complexity might help.\n\n# 12.More Evaluation Metrics  <a id=\"12\"></a>\nWe've so far used accuracy score to evaluate our classifiers. But sometimes accuracy score isn't all enough to evaluate a classifier properly as accuracy score doesn't tell exactly which class (positive or negative) is being wrongly classified by our classifier in case of low accuracy score. **Again for imbalanced classification problem, accuracy score isn't the best metric to choose between different classifiers. To clarify this, in this section, we will calculate confusion matrix, precision score, recall score, specificity, f1 score, classification report for both random forest and gradient boosting classifier. And then we will compare our two best classifiers (rf and gbc) using these calculated metrics to see exactly where one classifier excels the other.**\n\n## 12.1 Confusion Matrix  <a id=\"12.1\"></a>\nThe confusion matrix shows the number of correct classifications along with misclassifications when a classifier make predictions for each class (positive or negative). The diagonal elements are correct classification while the off diagonal elements are misscalssifications. Some basic terms associated with confusion matrix:\n1. True positives (TP): These are cases in which we predicted 1(yes), and the actual is also 1(yes).\n2. True negatives (TN): We predicted 0(no), and the actual is also 0(no).\n3. False positives (FP): We predicted 1(yes), but the actual is 0(no). (Also known as a \"Type I error.\")\n4. False negatives (FN): We predicted 0(no), but the actual is 1(yes). (Also known as a \"Type II error.\") \n The 1st row of our confusion matrix( or sometimes called error matrix) is about the negative class (because of 0 and hence non-survived) and The 2nd row of our confusion matrix( or sometimes called error matrix) is about the positive class (because of 1 and hence survived).\n\nFor rf, passengers correctly classified as survived are 243 (true positives) and passengers correctly classified as non-survived (died) are 506(true negatives). While 43 passengers (false positives) from class 0 (non-survived) were misclassified as survived and 99 (false negatives) passengers who actually survived were classified as non-survived.\n\nAnd for gbc, passengers correctly classified as survived are 248(true positives) and passengers correctly classified as non-survived (died) are 501(true negatives). While 48 (false positives) passengers from class 0 (non-survived) were misclassified as survived and 94 (false negatives) passengers who actually survived were misclassified as non-survived.\n\n**RF (749) makes exactly same correct predictions (true positives+true negatives) as gbc (749), hence rf and gbc have exactly same accuracy score that we saw when we calculated both model's accuracy score.**\n\n## 12.2 Precision Score  <a id=\"12.2\"></a>\nPrecision is the ratio of true positive to total predicted positive(true positive + false positive). So precision score tells how many true positives our model can capture out of total predicted positives. \n **RF's precision score tells when it predicts a passenger as a survivor (=class1), it is correct nearly 85% of the time. And gbc's precision score tells when gbc predicts a passenger as a survivor, it is correct nearly 84% of the time. So rf has a better precision score than gbc.**\n\n## 12.3 Recall (or Sensitivity or True Positive Rate)  <a id=\"12.3\"></a>\nRecall is the ratio of true positive to total actual positive(true positive + false negative). So recall score basically calculates true positives from total actual positives. \n **RF's recall score tells it correctly identifies over 71% of all the survivors. Or put another way, it predicts over 71.5% of the survivors as a survivor. On the other hand, gbc predicts just over 72.5% of the survivors as survivor. So gbc is more capable of capturing true positives than rf that we also observed from confusion matrix.**\n\n## 12.4 Specificity ( or True Negative Rate)  <a id=\"12.4\"></a>\nSpecificity is the ratio of true negative to total actual negative(true negative + false positive). Specificity  is exactly the opposite of recall. So specificity score basically calculates true negatives from total actual negatives. \n **RF's specificity score indicates it correctly predicts over 92% of the victims as a victim. Comparing recall score with specificity, it looks like our rf model is more accurate on predicting negative class (victims = 0) than predicting positive class (survivors = 1).**\n\n**While  gbc's specificity score indicates it correctly predicts over 91% of the victims as a victim. Comparing recall score with specificity, it looks like our gbc also is more accurate on predicting negative class (victims = 0) than predicting positive class (survivors = 1).**\n\n**Interesting! RF is better than capturing true negatives than gbc. So if we were to choose a model between rf and gbc where our priority is the negative class (0), we would choose rf. And if our priority is positive class(1), we would choose gbc.**\n\n## 12.5 F1 Score  <a id=\"12.5\"></a>\nWe can't choose classifiers solely depending on their precision or recall score. Rather we need to consider both to find out the best classifiers. Here comes the f1 score which is  the balanced harmonic mean of Recall and Precision, giving both metrics equal weight. The higher the f1 score is, the better. \n **Looks like gbc is better than rf in terms of f1 score.**\n## 12.6 Classification Report  <a id=\"12.6\"></a>\nPrecision, recall, and f1 score is only associated with true positives. But what if we want to measure true negatives? We can measure them with true positives and count of each class (0 and 1) in  a classification report. It provides precision, recall, f1 score and class count altogether for both classs (0 and 1) but at the cost of less hassle. \n **We can see precision, recall, f1 score and class count for both class (0 and 1) of our two models.**\n## 12.7 Precision-Recall vs Threshold Curve  <a id=\"12.7\"></a>\nSometimes we want a high precision and sometimes a high recall depending on our classification problem. The thing is that an increasing precision results in a decreasing recall and vice versa. This is called the precision-recall tradeoff that can be illustrated using precision-recall curve as a function of the decision threshold. \n **We can see for RF, the recall falls quickly at a precision of around 84%. So therefore, we need to select the precision-recall tradeoff before 84% of precision which could be at around 82%. Now, for example, if we want a precision of 80% off RF we would need a threshold of around 0.4**\n\n**On the other hand, for GBC, the recall falls fast at a precision of around 84% and hence we would select precision-recall tradeoff at around 80% of precision. If we want a precision of around 81% off GBC, we would need a threshold of around 0.38**\n\n## 12.8 Precision-Recall Curve  <a id=\"12.8\"></a>\nWe can also plot precision against recall to get an idea of precision-recall tradeoff where y-axis represents precision and x-axis represents recall. In my plot, I plot recall on y-axis and precision on x-axis. \n **We can see recall falls rapidly at around a precision of 0.84 for both RF and 0.82 for GBC that we've observed in the previous section.**\n\n## 12.9 ROC  Curve & AUC Score  <a id=\"12.9\"></a>\nROC (Reicever Operating Characteristic Curve) is a plot of the true positive rate against the false positive rate of a classifier. It shows the tradeoff between sensitivity and specificity (any increase in sensitivity will be accompanied by a decrease in specificity). AUC (Area under the ROC Curve) score is the corresponding score to the AUC Curve. It is simply computed by measuring the area under the ROC curve, which is called AUC. We will plot ROC curve and AUC score together for our two classifiers. \n This two plots tells few different things:\n\n1. A model that predicts at chance will have an ROC curve that looks like the diagonal red line. That is not a discriminating model.\n\n2. The further the curve is off the diagonal red line, the better the model is at discriminating between positives and negatives in general.\n\n3. There are useful statistics that can be calculated from this curve, like the Area Under the Curve (AUC). This tells you how well the model predicts and the optimal cut point for any given model (under specific circumstances).\n\n**Comparing the two ROC curves, we can see the distance between blue and red line of RF is greater than the distance between blue and red line of GBC. Hence it can safely be said that RF, in general, is better at discriminating between positives and negatives than GBC. Also RF(92.11%) auc score (which is the area under the roc curve) is greater than gbc(91.94%). It seems the higher the area, the further the classifier is off the red diagonal line and vice versa and hence more accurate. Since RF has more area under the ROC curve than GBC, RF is more accurate.**\n\n# 13.Prediction & Submission  <a id=\"13\"></a>\nFirst we will predict using both rf and gbc. Then we will create two prediction files in csv format for kaggle submission. \n **Though both RF and GBC have the identical validation accuracy (in our case optimized accuracy ~0.8406), RF scored 0.79425 while GBC scored 0.78468 on kaggle leaderboard. The fact that gbc's accuracy on the holdout data is 0.78468 compared with the 0.8406 accuracy we got with cross-validation indicates that GBC underfits the training data that we obsetved from the learning curve (see part 11.7). Hence it performs poorly on kaggle hold out set compared to RF.**\n\n### Can we further improve our classifiers' accuracy? May be we can! In the next few section, we will try to improve our models' accuracy with the help of ensemble method. \n # 14.Introduction to Ensemble <a id=\"14\"></a>\nCan we further boost the accuracy of our best models? That's what we will try to do using ensemble method. Ensembles combine predictions from different models to generate a final prediction, and the more models we include the better it performs. Better still, because ensembles combine baseline predictions, they perform at least as well as the best baseline model. Most of the errors from a model\u2019s learning are from three main factors: variance, noise, and bias. By using ensemble methods, we\u2019re able to increase the stability of the final model and reduce the errors caused by bias, variance, and noise. By combining many models, we\u2019re able to (mostly) reduce the variance, even when they are individually not great, as we won\u2019t suffer from random errors from a single source. **The main principle behind ensemble modelling is to group weak learners together to form one strong learner. The most basic ensemble is majority voting rule (where the prediction or vote given by the majority of the models used as final prediction).But there are many other ways to combine predictions, and more generally we can use a model to learn how to best combine predictions.** \n **To implement an ensemble we need three basic things:**\n1. A group of base learners that generate predictions.\n2. A meta learner that learns how to best combine these predictions outputed by base learners.\n3. And finally a method for splitting the training data between the base learners and the meta learner.\n\n**An ensemble works best if:**\n1. There is a less correlation in the base models' predictions.\n2. We increase the number of base learners though it might slow the process down.\n\n\n## 14.1 Different Ensemble Methods\nWe would first categorize ensemble methods into two subcategories like 1.Simple Ensemble Methods and 2.Advanced Ensemble Methods\n\n### 14.1.1 Simple Ensemble Methods\nThey're the simpliest yet so useful form of enselbles. They can be further categorised into \n1. Voting, \n2. Averaging and \n3. Weighted Average. \n\nFirst one is usually used for classification while the later two are used for regression problems.\n\n#### 14.1.1.1 Voting Ensemble  \nVoting ensemble is further classified into \n1. Hard voting and \n2. Soft voting.\n\n##### 14.1.1.1.1 Hard Voting (or Majority Voting or Max Voting) <a id=\"14.1\"></a>\nThis hard voting method is usually used for classification problems. The idea is to train multiple models to make predictions for each data point. The predictions by each model are considered as a \u2018vote\u2019. The predictions which we get from the majority of the models are used as the final prediction. Say rf and lr predict a class as 1 while knn predicts the same class as 0. Since the majority of the vots is casted in favour of class 1, the voting classifier would predict the very same class as 1. See the table below to understand how hard voting ensemble works. \n **Correlation among Base Models Predictions:** How base models' predictions are correlated? If base models' predictions are weakly correlated with each other, the ensemble will likely to perform better. On the other hand, for a strong correlation of predictions among the base models, the ensemble will unlikely to perform better. To sumarize, diversity of predictions among the base models is inversely proportional to the ensemble accuracy. Let's make prediction for the test set. \n **Findings:** The prediction looks quite similar for the 8 classifiers except when DT is compared to the others classifiers. Now we will create an ensemble with the base models RF, GBC, DT, KNN and LR. This ensemble can be called heterogeneous ensemble since we have three tree based, one kernel based and one linear models. We would use **EnsembleVotingClassifier method from mlxtend module** for both hard and soft voting ensembles. The advantage is it requires lesser codes to plot decision regions and I find it a bit faster than sklearn's voting classifier. \n **Findings:** We can see Hard voting classifier uses RF as meta learner for this problem that beats the best base learners (rf and gbc) by some margin. So we may want to further investigate how hard voting is using its decision boundary to excel our best base learners. Let's visualize the decision regions of hard voting classifier with base classifiers.\n\n**Now we have a new challenge. In machine learning, visualizing 2 or 3 dimensional data is not that challenging. But we have 47 dimensions (47 input features). That's way too much to visualize. So we need to reduce the dimensionality- may be into 2 or 3 dimensionality. That's where PCA comes into play.**\n\n### **Introduction to Principal Component Analysis (PCA) <a id=\"14.2\"></a>\nThe main goal of a PCA analysis is to identify patterns in data. PCA aims to detect the correlation between variables. If a strong correlation between variables exists, the attempt to reduce the dimensionality only makes sense. In a nutshell, this is what PCA is all about: Finding the directions of maximum variance in high-dimensional data and project it onto a smaller dimensional subspace while retaining most of the information. PCA is very useful in the following two cases:\n1. When the training process takes too long due to large input dimension of training data.\n2. Reducing dimensions, it make data visualization a breeze.\n\nPCA is often effected if your input features have different ranges. So to make PCA work better we shoud scale the input features. We would use sklearn's StandardScaler to standarize our input features. The idea behind StandardScaler is that it will transform our data such that its distribution will have a mean value 0 and standard deviation of 1. **If the variables are correlated, PCA can achieve dimension reduction. If not, PCA just orders them according to their variances.**\n\n**Now let's perform standarization and then PCA to plot decision regions of different trained classifiers.** \n **So there we have it! We're down to 2 features only from 47 features. Now we want to calculate how much variance we're able to extract off these 2 components.** \n **Not so much! But considering the number of features we have, its not either too less. Let's visualize our two components (transformed features) in a scatter plot.** \n **Looking at this plot, one thing we can say that a linear decision boundary will not be a good choice to separate these two classes. Now we would train our models on this 2d transformed samples to visualize decision regions created by them.**\n\n**Note:** PCA gives you an intuition if a linear or non-linear algorithms would be suitable for a problem. For example, if we look at the scatter plot, we see a non-linear trend between the two class that is, of course better seperable by a non-linear decision boundary. So a non-linear model would be a better bet than a linear one. That's why rf(non-linear) performs better than lr(linear model) for this problem. \n **Findings:** There seems to be lesser misclassifications made by hard voting decision region compared to both rf and gbc's decision regions. Let's see how and where hard voting ensemble corrects base learners prediction in a data frame together. \n **Great! We can see hard voting ensemble is considering majority of the models vote(prediction) to label a particular class. Thus it can reduce prediction errors when predicted by a single base learners.**\n\n##### 14.1.1.1.2 Soft Voting <a id=\"14.3\"></a>\nOn the other hand, When an ensembles averages based on probabilities  we refer to it as soft voting. In an ensemble model, all classifiers (algorithms) are able to estimate class probabilities (i.e., they all have predict_proba() method), then we can specify Scikit-Learn to predict the class with the highest probability, averaged over all the individual classifiers. In a voting classifier setting the voting parameter to 'soft' enables the models to calculate their probability(also known as confidence score) individually and present it to the voting classifier, then the voting classifier averages them and outputs the class with the highest probability. If average probablity of class-1 is greater than class-0, it outputs predicted class is 1 otherwise 0. \n\n**Note:** This soft-voting classifier often work better than hard-voting as it gives more weight to highly confident votes. We Need to specify voting=\u201dsoft\u201d and ensure that all classifiers can estimate class probabilities. One algorithm where we need to be careful is SVC, by default SVC will not give probabilities, we have to specify 'probability' hyperparameter to True.\nSee the table below to understand how soft voting ensemble works. \n **Let's implement soft voting ensemble in mlxtend.** \n **Findings:** Soft voting ensemble fails to beat our two best models (rf and gbc). In fact, it produces way to inferior results compared to hard voting ensemble (83.95 vs 84.18). So hard voting ensemble, for this problem, seems to be superior to soft voting ensemble method. WE can visualize soft voting ensemble decision region along with base models decision regions. \n **Findings:** Soft voting decision region just seems to be creating more misclassification than rf and gbc. \n ### 14.1.2 Advanced Ensemble Methods\nAdvanced ensemble methods can further be classified into \n1. Bagging\n2. Boostoing\n3. Stacking\n4. Blending\n\n#### 14.1.2.1 Bagging  <a id=\"14.4\"></a>\nBagging, is shorthand for the combination of bootstrapping and aggregating. Bootstrapping is a method to help decrease the variance of the classifier and thus reduce overfitting. So the model created should be less overfitted than a single individual model. Bagging is more suitable for high variance low bias models (complex models). Random forest itself is an ensemble machine learning algorithm that follows the bagging technique. We would use rf as the base estimator for bagging instead of default dt. Let's try to implement bagging in sklearn: \n **Findings:** Bagging can't beat our best base learners.\n\n#### 14.1.2.2 Boosting  <a id=\"14.5\"></a>\nBoosting refers to any Ensemble method that can combine several weak learners into a strong learner. It does this through a weighted majority vote (classification) or a weighted sum (regression). Ada boost and Gradient boost, and Extreme gradient boost are popular models that uses boosting technique. Boosting is particularly suitable for low variance high bias models (less complex models). Unlike bagging, its a sequential ensemble technique. We will perform a simple voting ensemble of boosting classifiers rather performing boosting ensemble using only a single classifer with a base estimator (for ada boost). I found this method to give higher accuracy than adaboost(with a base estimator), gradient boosting, or extreme gradient boosting for this problem. Let's perform boosting ensemble(infact voting of boosting classifiers) in mlxtend. \n **Findings:** Boosting method can't beat best boosting base learner gbc. Though it could beat, if we would have optimized xgbc. If you have time and infrastructure, you can tune xgbc's hyperparameters. Then compare boosting accuracy with its base models accuracy.\n\n#### 14.1.2.3 Blending  <a id=\"14.6\"></a>\nIn blending, full training data is split into training and prediction sets. The base models (also called level 0 models) are trained on this train set and then predictions are made on this prediction set. These predictions made by base learers are then fed as an input to the meta learner (also called level 1 model). That is meta learner are trained with the output (predictions) of base learners. Blending ensemble uses only a subset of data to train base learners and another subset of data to make predictions. By only fitting every base learner once on a subset of the full training data, Blend ensemble is a fast ensemble that can handle very large datasets simply by only using portion of it at each stage. The cost of this approach is that information is thrown out at each stage, as one layer will not see the training data used by the previous layer. **We will use BlendEnsemble method from mlens.ensemble module to perform blending.** \n #### 14.1.2.4 Stacking (Or Stacked Generalization)  <a id=\"14.7\"></a>\nIn blending, we trained the base learners and the meta learner on only half the data, so a lot of information is lost. To prevent this, we need to use a cross-validation strategy. Fitting an ensemble with cross-validation is often referred to as stacking, while the ensemble itself is known as the Super Learner. So basically in stacking, the individual classification models (or base models) are trained on the complete training set; then, the meta-classifier is fitted on the outputs (predictions) of those base learners. The meta-classifier can either be trained on the predicted class labels or probabilities from the ensemble.\n\n**The basic difference between blending and stacking is therefore that stacking allows both base learners and the meta learner to train on the full data set.The outcome of stacking is improved accuracy which is typical for small and medium-sized data sets, where the effect of blending can be severe. As the data set size increases, blending and stacking performs similarly and hence for large data sets blending is preferred over stacking since stacking takes significant amount of time to train the ensemble. We will use package vecstack to perform stacking that can save you from writing a lot of codes if you implement stacking from scratch.** \n **So now we have OOF from base (or 0 level models) models and we can build level 1 model. We have 5 base models (level 0 models), so we expect to get 5 columns in sTrain and sTest. sTrain will be our input feature to train our meta learner and then prediction will be made on sTest after we train our meta learner. And this prediction on sTest is actually the prediction for our test set (xTest). Before we train our meta learner we can investigate sTrain and sTest.** \n ## 14.2  Evaluating Different Ensembles <a id=\"14.8\"></a>\nI've tried to demonstrate various ensemble methods. Let's make predictions with them to see how they perform on our test set on kaggle submission. \n **We've made our submissions using different ensembles. Let's now compare their submission scores with our best base models'  submission scores.** \n **Findings:**So there you have it! Surprisingly its bagging that comes out on top with a score of *0.81339* that can take you to the top *4%* on the leaderboard! Random forest (base model) comes second with score 0.80382. Hard voting, stacking and soft voting perform identical and can't beat best base rf. Since bagging performs well for high variance model, we have a feeling that we might have overfitted the training data because cross validation score for bagging is 82.61% and it still scores over 81% on kaggle leaderboard. So its possible to overfit though your cross validation score is high since some models with higher cross validation score perform poorly on kaggle leaderboard compared to bagging ensemble. \n # 15.End Note <a id=\"15\"></a>\n**If you're still with me, I congratulate you because you've learned all those things that I learned after months of study, practice and of course patience. Of course, there is always room for improvement. I'm still learning. I've tried to explain everything I could possibly know. Any suggestion is cordially welcomed. May be trying out different base learners and meta learner to improve ensemble further or may be by tunning xgbc. And if you find my kernel useful, some upvotes will be appreciated.  I have also another kernel for advanced house price regression problem that you might find useful as well.**\n\n**Finally I provide some links that I've found useful in creating this notebook.**\n\n**Recommended Readings:**\n1. Mlxtend package for voting ensemble and decision region: https://rasbt.github.io/mlxtend/user_guide/classifier/EnsembleVoteClassifier/ and\nhttps://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/\n2. Mlens package for blending ensemble: https://github.com/flennerhag/mlens/blob/master/mlens/ensemble/blend.py\n3. Vecstack package for stacking ensemble: https://github.com/vecxoz/vecstack\n4. Introduction to Python Ensembles by Dataquest: https://www.dataquest.io/blog/introduction-to-ensembles/\n5. Kaggle ensemble guide by MLWave: https://mlwave.com/kaggle-ensembling-guide/",
    "n_cells": 296,
    "n_code_cells": 158,
    "n_markdown_cells": 138,
    "n_raw_cells": 0,
    "n_outputs": 158,
    "r_code_cells": 0.5337837837837838,
    "r_markdown_cells": 0.46621621621621623,
    "r_raw_cells": 0.0,
    "r_outputs": 1.0,
    "n_exceptions": 0,
    "r_exceptions": 0.0,
    "n_lines": 2228,
    "n_lines_code": 1702,
    "n_lines_markdown": 526,
    "lines_per_cell": [
        2,
        36,
        7,
        50,
        8,
        9,
        1,
        4,
        4,
        7,
        24,
        3,
        9,
        73,
        1,
        2,
        1,
        1,
        2,
        3,
        2,
        3,
        2,
        3,
        4,
        4,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        2,
        3,
        2,
        4,
        55,
        1,
        2,
        3,
        3,
        8,
        2,
        2,
        1,
        3,
        2,
        6,
        3,
        3,
        3,
        1,
        2,
        4,
        2,
        3,
        2,
        1,
        2,
        2,
        1,
        14,
        2,
        2,
        4,
        4,
        1,
        5,
        2,
        3,
        2,
        1,
        3,
        3,
        2,
        6,
        63,
        1,
        2,
        3,
        2,
        6,
        27,
        5,
        1,
        10,
        5,
        2,
        14,
        4,
        15,
        1,
        6,
        8,
        112,
        1,
        2,
        1,
        2,
        1,
        2,
        8,
        2,
        5,
        2,
        2,
        1,
        2,
        1,
        2,
        1,
        2,
        7,
        91,
        1,
        2,
        11,
        2,
        3,
        2,
        1,
        2,
        12,
        2,
        3,
        2,
        1,
        2,
        3,
        2,
        3,
        2,
        1,
        2,
        3,
        2,
        1,
        2,
        3,
        2,
        1,
        2,
        3,
        2,
        1,
        2,
        3,
        2,
        3,
        2,
        1,
        2,
        3,
        2,
        1,
        2,
        4,
        20,
        1,
        3,
        1,
        3,
        1,
        3,
        1,
        3,
        1,
        3,
        1,
        3,
        1,
        3,
        1,
        3,
        1,
        3,
        1,
        3,
        1,
        3,
        1,
        3,
        1,
        3,
        9,
        10,
        1,
        10,
        2,
        1,
        9,
        1,
        3,
        2,
        4,
        3,
        2,
        6,
        2,
        6,
        4,
        6,
        4,
        2,
        38,
        15,
        11,
        14,
        8,
        62,
        12,
        3,
        5,
        8,
        3,
        1,
        2,
        62,
        6,
        28,
        1,
        14,
        2,
        19,
        1,
        11,
        4,
        37,
        11,
        14,
        21,
        10,
        11,
        4,
        11,
        4,
        12,
        8,
        11,
        3,
        13,
        3,
        18,
        6,
        17,
        4,
        20,
        12,
        12,
        3,
        2,
        28,
        4,
        1,
        16,
        1,
        35,
        12,
        28,
        1,
        3,
        1,
        14,
        3,
        34,
        1,
        6,
        7,
        4,
        1,
        29,
        1,
        13,
        1,
        3,
        9,
        26,
        4,
        26,
        4,
        12,
        4,
        19,
        1,
        3,
        3,
        9,
        2,
        37,
        1,
        7,
        44,
        1,
        12
    ],
    "lines_per_code_cell": [
        50,
        8,
        9,
        4,
        7,
        3,
        73,
        2,
        2,
        2,
        2,
        4,
        4,
        3,
        3,
        3,
        3,
        3,
        2,
        2,
        55,
        2,
        3,
        2,
        2,
        2,
        3,
        3,
        3,
        2,
        4,
        2,
        2,
        2,
        2,
        14,
        2,
        2,
        4,
        5,
        2,
        2,
        3,
        3,
        2,
        63,
        2,
        2,
        27,
        5,
        5,
        14,
        15,
        6,
        112,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        91,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        20,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        10,
        10,
        1,
        9,
        3,
        4,
        3,
        6,
        6,
        4,
        6,
        4,
        38,
        15,
        14,
        62,
        12,
        5,
        8,
        3,
        62,
        28,
        14,
        19,
        11,
        37,
        11,
        21,
        11,
        11,
        12,
        11,
        13,
        18,
        17,
        20,
        12,
        4,
        16,
        35,
        28,
        3,
        14,
        34,
        6,
        4,
        29,
        13,
        3,
        26,
        26,
        12,
        19,
        3,
        3,
        9,
        37,
        7,
        44
    ],
    "lines_per_markdown_cell": [
        2,
        36,
        7,
        1,
        4,
        24,
        9,
        1,
        1,
        1,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        4,
        1,
        3,
        8,
        1,
        3,
        6,
        1,
        3,
        1,
        1,
        4,
        1,
        3,
        1,
        6,
        1,
        3,
        6,
        1,
        10,
        2,
        4,
        1,
        8,
        1,
        1,
        1,
        8,
        5,
        2,
        1,
        1,
        1,
        7,
        1,
        11,
        3,
        1,
        12,
        3,
        1,
        3,
        3,
        1,
        3,
        1,
        3,
        1,
        3,
        1,
        3,
        3,
        1,
        3,
        1,
        4,
        1,
        1,
        1,
        1,
        1,
        1,
        1,
        1,
        1,
        1,
        1,
        1,
        1,
        9,
        1,
        2,
        1,
        2,
        2,
        2,
        2,
        11,
        8,
        3,
        1,
        2,
        6,
        1,
        2,
        1,
        4,
        14,
        10,
        4,
        4,
        8,
        3,
        3,
        6,
        4,
        12,
        3,
        2,
        28,
        1,
        1,
        12,
        1,
        1,
        3,
        1,
        7,
        1,
        1,
        1,
        9,
        4,
        4,
        4,
        1,
        2,
        1,
        1,
        12
    ],
    "ave_lines_per_cell": 7.527027027027027,
    "ave_lines_per_code_cell": 10.772151898734178,
    "ave_lines_per_markdown_cell": 3.8115942028985508,
    "max_lines_per_cell": 112,
    "max_lines_per_code_cell": 112,
    "max_lines_per_markdown_cell": 36,
    "min_lines_per_cell": 1,
    "min_lines_per_code_cell": 1,
    "min_lines_per_markdown_cell": 1,
    "n_chars": 152012,
    "n_chars_code": 77156,
    "n_chars_markdown": 74856,
    "chars_per_cell": [
        535,
        3689,
        823,
        2003,
        330,
        288,
        140,
        363,
        260,
        198,
        1401,
        112,
        1403,
        2404,
        38,
        120,
        332,
        32,
        80,
        341,
        77,
        417,
        86,
        337,
        149,
        156,
        137,
        355,
        115,
        115,
        188,
        122,
        87,
        212,
        116,
        334,
        75,
        708,
        1702,
        33,
        73,
        524,
        109,
        719,
        71,
        71,
        193,
        485,
        71,
        519,
        91,
        136,
        160,
        575,
        78,
        244,
        150,
        202,
        67,
        505,
        117,
        94,
        448,
        763,
        88,
        132,
        527,
        224,
        199,
        422,
        138,
        272,
        76,
        235,
        280,
        145,
        136,
        1038,
        2070,
        50,
        92,
        316,
        95,
        1504,
        1003,
        242,
        194,
        412,
        336,
        182,
        814,
        517,
        900,
        529,
        328,
        1648,
        4720,
        44,
        160,
        517,
        230,
        179,
        79,
        1242,
        216,
        1091,
        44,
        202,
        421,
        203,
        220,
        71,
        157,
        108,
        853,
        4255,
        43,
        141,
        1628,
        104,
        584,
        151,
        355,
        110,
        1368,
        120,
        334,
        146,
        439,
        126,
        732,
        140,
        417,
        129,
        383,
        84,
        186,
        120,
        193,
        108,
        201,
        136,
        375,
        124,
        196,
        116,
        205,
        118,
        578,
        125,
        437,
        149,
        221,
        117,
        203,
        158,
        179,
        128,
        647,
        1182,
        65,
        226,
        59,
        244,
        56,
        217,
        56,
        216,
        64,
        237,
        61,
        244,
        66,
        242,
        75,
        253,
        69,
        252,
        70,
        251,
        74,
        252,
        68,
        259,
        75,
        254,
        798,
        409,
        43,
        406,
        307,
        23,
        346,
        47,
        94,
        210,
        317,
        106,
        229,
        267,
        294,
        182,
        313,
        322,
        198,
        120,
        1157,
        692,
        2970,
        692,
        824,
        2716,
        643,
        328,
        400,
        615,
        190,
        158,
        240,
        2342,
        1144,
        1345,
        273,
        682,
        170,
        1050,
        585,
        516,
        482,
        1772,
        474,
        2198,
        883,
        1440,
        434,
        532,
        400,
        638,
        489,
        1147,
        347,
        454,
        485,
        497,
        860,
        801,
        679,
        698,
        877,
        1286,
        479,
        638,
        1211,
        1697,
        181,
        482,
        815,
        562,
        1652,
        1964,
        1055,
        161,
        217,
        166,
        537,
        660,
        1546,
        246,
        405,
        1458,
        189,
        52,
        1451,
        369,
        651,
        107,
        162,
        734,
        1292,
        946,
        1328,
        1252,
        409,
        1350,
        1438,
        468,
        80,
        91,
        314,
        204,
        1198,
        146,
        582,
        1590,
        720,
        1346
    ],
    "chars_per_code_cell": [
        2003,
        330,
        288,
        260,
        198,
        112,
        2404,
        120,
        80,
        77,
        86,
        149,
        156,
        137,
        115,
        115,
        122,
        87,
        116,
        75,
        1702,
        73,
        109,
        71,
        71,
        71,
        91,
        136,
        160,
        78,
        244,
        150,
        67,
        117,
        94,
        763,
        88,
        132,
        224,
        422,
        138,
        76,
        280,
        145,
        136,
        2070,
        92,
        95,
        1003,
        242,
        336,
        814,
        900,
        328,
        4720,
        160,
        230,
        79,
        216,
        202,
        203,
        71,
        108,
        4255,
        141,
        104,
        151,
        110,
        120,
        146,
        126,
        140,
        129,
        84,
        120,
        108,
        136,
        124,
        116,
        118,
        125,
        149,
        117,
        158,
        128,
        1182,
        226,
        244,
        217,
        216,
        237,
        244,
        242,
        253,
        252,
        251,
        252,
        259,
        254,
        409,
        406,
        23,
        346,
        94,
        317,
        106,
        267,
        182,
        313,
        322,
        198,
        1157,
        692,
        692,
        2716,
        643,
        400,
        615,
        190,
        2342,
        1345,
        682,
        1050,
        516,
        1772,
        474,
        883,
        434,
        400,
        489,
        347,
        485,
        860,
        679,
        877,
        479,
        181,
        815,
        1652,
        1055,
        217,
        537,
        1546,
        405,
        189,
        1451,
        651,
        162,
        1292,
        1328,
        409,
        1438,
        80,
        91,
        314,
        1198,
        582,
        1590
    ],
    "chars_per_markdown_cell": [
        535,
        3689,
        823,
        140,
        363,
        1401,
        1403,
        38,
        332,
        32,
        341,
        417,
        337,
        355,
        188,
        212,
        334,
        708,
        33,
        524,
        719,
        193,
        485,
        519,
        575,
        202,
        505,
        448,
        527,
        199,
        272,
        235,
        1038,
        50,
        316,
        1504,
        194,
        412,
        182,
        517,
        529,
        1648,
        44,
        517,
        179,
        1242,
        1091,
        44,
        421,
        220,
        157,
        853,
        43,
        1628,
        584,
        355,
        1368,
        334,
        439,
        732,
        417,
        383,
        186,
        193,
        201,
        375,
        196,
        205,
        578,
        437,
        221,
        203,
        179,
        647,
        65,
        59,
        56,
        56,
        64,
        61,
        66,
        75,
        69,
        70,
        74,
        68,
        75,
        798,
        43,
        307,
        47,
        210,
        229,
        294,
        120,
        2970,
        824,
        328,
        158,
        240,
        1144,
        273,
        170,
        585,
        482,
        2198,
        1440,
        532,
        638,
        1147,
        454,
        497,
        801,
        698,
        1286,
        638,
        1211,
        1697,
        482,
        562,
        1964,
        161,
        166,
        660,
        246,
        1458,
        52,
        369,
        107,
        734,
        946,
        1252,
        1350,
        468,
        204,
        146,
        720,
        1346
    ],
    "ave_chars_per_line": 68.22800718132855,
    "ave_chars_per_cell": 513.5540540540541,
    "ave_chars_per_code_cell": 488.32911392405066,
    "ave_chars_per_markdown_cell": 542.4347826086956,
    "max_chars_per_cell": 4720,
    "max_chars_per_code_cell": 4720,
    "max_chars_per_markdownell": 3689,
    "min_chars_per_cell": 23,
    "min_chars_per_code_cell": 23,
    "min_chars_per_markdown_cell": 32,
    "r_lines_code": 0.7639138240574507,
    "r_lines_markdown": 0.23608617594254938,
    "r_chars_markdown": 0.4924348077783333,
    "r_chars_code": 0.5075651922216667,
    "all_cells": [
        {
            "source": "# About this Kernel\nThis kernel may (or may not) be helpful in your long and often tedious machine learning journey. Sometimes you may find this notebook verbose and overwhelming particularly if you're a beginner. This verbosity tries to explain everything I could possibly know. Once you get through the notebook, you could expect to have a good grasp of the fundamentals. I've also tried to write reusable codes as much as possible using custom functions so that we can avoid writing the same code again and again. Let's get started.",
            "mc_idx": 0,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "# Outlines\n\n* [1.Problem Description and Objective](#1)\n* [2.Importing Packages and Collecting Data](#2)\n* [3.Variable Description and Identification](#3)\n   * [3.1 Variable Description](#3.1) [3.2 Categorical and Numerical Variables](#3.2) [3.3 Variable Data Types](#3.3)\n* [4.Univariate Analysis](#4)\n   * [4.1 Categorical Variables](#4.1)\n      * [4.1.1 Survived](#4.1.1) [4.1.2 Sex](#4.1.2) [4.1.3 Pclass](#4.1.3) [4.1.4 Embarked](#4.1.4) [4.1.5 Cabin](#4.1.5) [4.1.6 Name](#4.1.6) [4.1.7 Ticket](#4.1.7) [4.1.8 SibSp](#4.1.8) [4.1.9 Parch](#4.1.9)\n   * [4.2 Numerical Variables](#4.2)    \n      * [4.2.1 Fare](#4.2.1)  [4.2.2 Age](#4.2.2)  [4.2.3 PassengerId](#4.2.3)\n* [5.Feature Engineering](#5)\n   * [5.1 Process Cabin](#5.1) [5.2 Process Name](#5.2) [5.3 Process SibSp & Parch](#5.3)  [5.4 Process Ticket](#5.4)\n* [6.Outliers Detection](#6)\n   * [6.1 Outliers Detection of Age](#6.1)  [6.1 Outliers Detection of Fare](#6.2)\n* [7.Imputing Missing Variables](#7)\n   * [7.1 Impute Embarked & Fare](#7.1)  [7.2 Impute Age](#7.2)\n* [8.Bivariate Analysis](#8)\n   * [8.1 Numerical & Categorical Variables](#8.1)\n      * [8.1.1 Fare & Survived](#8.1.1)   [8.1.2 Age & Survived](#8.1.2)\n   * [8.2 Categorical & Categorical Variables](#8.2)\n      * [8.2.1 Sex & Survived](#8.2.1) [8.2.2 Pclass & Survived](#8.2.2) [8.2.3 Embarked & Survived](#8.2.3) [8.2.4 SIbSp & Survived](#8.2.4) [8.2.5 Parch & Survived](#8.2.5) [8.2.6 nameProcessed & Survived](#8.2.6) [8.2.7 familySize & Survived](#8.2.7) [8.2.8 cabinProcessed & Survived](#8.2.8) [ 8.2.9 ticketProcessed & Survived](#8.2.9)\n* [9.Multivariate Analysis](#9)  \n   * [9.1 (Pclass, Sex, cabinProcessed) vs Survived](#9.1) [9.2 (Pclass, Sex, Embarked) vs Survived](#9.2) [9.3 (Pclass, Sex, SibSp) vs Survived](#9.3) [9.4 (Pclass, Sex, Parch) vs Survived](#9.4) [9.5 (Pclass, Sex, nameProcessed) vs Survived](#9.5) [9.6 (Pclass, Sex, familySize) vs Survived](#9.6) [9.7 (Pclass, Sex, ticketProcessed) vs Survived](#9.7) [9.8 (Pclass, nameProcessed, cabinProcessed) vs Survived](#9.8) [9.9 (familySize, Sex, cabinProcessed) vs Survived](#9.9) [9.10 (Sex, nameProcessed, familySize) vs Survived](#9.10) [9.11 (Sex, nameProcessed, cabinProcessed) vs Survived](#9.11) [9.12 (Sex, nameProcessed, Embarked) vs Survived](#9.12) [9.13 (Sex, nameProcessed, ticketProcessed) vs Survived ](#9.13)\n* [10.Data Transformation](#10) \n   * [10.1 Binning Continuous Variables](#10.1)\n      * [10.1.1 Binning Age](#10.1.1) [10.1.2 Binning Fare](#10.1.2)\n   * [10.2 Dropping Features](#10.2) [10.3 Correcting Data Types](#10.3) [10.4 Encoding Categorical Variables](#10.4)\n* [11.Model Building and Evaluation](#11)   \n   * [11.1 Training Model](#11.1) [11.2 Model Evaluation](#11.2) [11.2.1 Cross Validation](#11.2.1) [11.2.2 Tunning Hyperparameters](#11.2.2) [11.2.3 Model Selection](#11.2.3) [11.3 Retrain & Predict Using Optimized Hyperparameters](#11.3) [11.4 Feature Importance](#11.4) [11.5 Learning Curves](#11.5)\n* [12.More Evaluation Metrics](#12)  \n   * [12.1 Confusion Matrix](#12.1) [12.2 Precision Score](#12.2) [12.3 Recall (or Sensitivity or True Positive Rate)](#12.3) [12.4 Specificity ( or True Negative Rate)](#12.4) [12.5 F1 Score](#12.5) [12.6 Classification Report](#12.6) [12.7 Precision-Recall vs Threshold Curve](#12.7) [12.8 Precision-Recall Curve](#12.8) [12.9 ROC  Curve & AUC Score ](#12.9)\n* [13.Prediction & Submission](#13) \n* [14.Introduction to Ensemble](#14)\n   * [14.1 Hard Voting Ensemble](#14.1) [14.2 Introduction to PCA](#14.2) [14.3 Soft Voting Ensemble](#14.3) [14.4 Bagging](#14.4) [14.5 Boosting](#14.5) [14.6 Blending](#14.6) [14.7 Stacking](#14.7) [14.8 Evaluating Different Ensembles](#14.8)\n* [15.End Note](#15)",
            "mc_idx": 1,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "# 1.Problem Description and Objective <a id=\"1\"></a>\nThe sinking of the RMS Titanic is one of the most notorious shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crews. This harrowing tragedy shocked the international community and led to better safety regulations for ships.\n\nIn this problem, we're asked to complete the analysis of what sorts of passengers were likely to survive the tragedy using machine learning. So its our job to predict if a passenger survived from the sinking Titanic or not with the help of machine learning. So its a binary classification problem.\n\n# 2.Importing Packages and Collecting Data <a id=\"2\"></a>\nAfter importing required modules, let's read train and test data from csv files.",
            "mc_idx": 2,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Import basic modules.\"\"\"\nimport numpy as np               # For linear algebra\nimport pandas as pd              # For data manipulation\nimport matplotlib.pyplot as plt  # For 2D visualization\nimport seaborn as sns            \nfrom scipy import stats          # For statistics\n\n\"\"\"Plotly visualization.\"\"\"\nimport plotly.graph_objs as go\nfrom plotly.tools import make_subplots\nfrom plotly.offline import iplot, init_notebook_mode\ninit_notebook_mode(connected = True) # Required to use plotly offline in jupyter notebook\n\n\"\"\"Machine learning models.\"\"\"\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom xgboost import XGBClassifier\n\n\n\"\"\"Classification (evaluation) metrices.\"\"\"\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\n\n\"\"\"Ensembling\"\"\"\nfrom mlxtend.classifier import EnsembleVoteClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom mlxtend.plotting import plot_decision_regions\nfrom sklearn.ensemble import BaggingClassifier\nfrom mlens.ensemble import BlendEnsemble\nfrom vecstack import stacking",
            "mc_idx": 3,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2564102564102564,
                "Data_Transform": 0.23076923076923078,
                "Model_Train": 0.5384615384615384,
                "Model_Evaluation": 0.7948717948717948,
                "Model_Interpretation": 0.1794871794871795,
                "Hyperparameter_Tuning": 0.1282051282051282,
                "Visualization": 0.07692307692307693,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 39
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plotly": 5,
                    "matplotlib": 1,
                    ".mode": 4
                },
                "Data_Transform": {
                    "data manipulation": 1,
                    "standardscaler": 1,
                    "pca": 1,
                    "stack": 2,
                    ".mod": 4
                },
                "Model_Train": {
                    "model": 6,
                    "randomforestclassifier": 2,
                    "model_selection": 4,
                    "learning models": 1,
                    "logisticregression": 1,
                    "gradientboostingclassifier": 1,
                    "decisiontreeclassifier": 1,
                    "kneighborsclassifier": 1,
                    "svc": 1,
                    "gaussiannb": 1,
                    "adaboostclassifier": 1,
                    ".linear": 1
                },
                "Model_Evaluation": {
                    "confusion_matrix": 2,
                    "accuracy_score": 2,
                    "precision_score": 4,
                    "recall_score": 2,
                    "f1_score": 3,
                    "precision": 3,
                    "recall": 2,
                    "roc_auc_score": 2,
                    "classification_report": 2,
                    "cross_val_score": 1,
                    "model": 6,
                    "precision_recall_curve": 1,
                    "roc_curve": 1
                },
                "Model_Interpretation": {
                    "model": 6,
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "cross_val_score": 1,
                    "learning_curve": 1
                },
                "Visualization": {
                    "matplotlib": 1,
                    "pyplot": 1,
                    "graph": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    0,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        ",
                        "[MLENS] backend: threading\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning:\n\nThe module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n\n"
                    ]
                },
                "mc_idx": 3,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 0,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Customize visualization.\"\"\"\nplt.style.use(\"bmh\")                    # Use bmh's style for plotting\nsns.set_style({\"axes.grid\":False})      # Remove gridlines\n\n\"\"\"Display markdown formatted output like bold, italic bold etc.\"\"\"\nfrom IPython.display import Markdown\ndef bold(string):\n    return display(Markdown(f\"**{string}**\"))",
            "mc_idx": 4,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    1,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 4,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 1,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Read and preview the train data from csv file.\"\"\"\ntrain = pd.read_csv(\"../input/train.csv\")\nbold(\"Preview of Train Data:\")\ndisplay(train.head(2))\n\n\"\"\"Read and preview the test from csv file.\"\"\"\ntest = pd.read_csv(\"../input/test.csv\")\nbold(\"Preview of Test Data:\")\ndisplay(test.head(2))",
            "mc_idx": 5,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.75,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 4,
                    "pd.read_": 4
                },
                "Exploratory_Data_Analysis": {
                    ".head(": 2,
                    "head": 2,
                    ".head": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    2,
                    3,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "   PassengerId  Survived  Pclass    ...        Fare Cabin  Embarked\n0            1         0       3    ...      7.2500   NaN         S\n1            2         1       1    ...     71.2833   C85         C\n\n[2 rows x 12 columns]",
                        "<IPython.core.display.Markdown object>",
                        "   PassengerId  Pclass   ...    Cabin Embarked\n0          892       3   ...      NaN        Q\n1          893       3   ...      NaN        S\n\n[2 rows x 11 columns]"
                    ]
                },
                "mc_idx": 5,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 2,
                "o_idx": 3
            }
        },
        {
            "source": "**Note:** We don't have Survived variable for test set. This will be our task to infer Survived for test set by learning from the train set.",
            "mc_idx": 6,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "# 3.Variable Description and Identification <a id=\"3\"></a>\nLet's describe what each of the variable indicates and identify our response and predictor variables. Also seperate the categorical variables from numerical variables and finally identify pandas data types (i.e., object, float64 or int64) for every variable.\n\n## 3.1 Variable Description <a id=\"3.1\"></a>",
            "mc_idx": 7,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Merge train and test data together. This eliminates the hassle of handling train and test data seperately for various analysis.\"\"\"\nmerged = pd.concat([train, test], sort = False).reset_index(drop=True)\nbold(\"Preview of Merged Data:\")\ndisplay(merged.head(5))",
            "mc_idx": 8,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".concat(": 1,
                    ".reset_index": 1,
                    ".concat": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    3,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "   PassengerId  Survived  Pclass    ...        Fare Cabin  Embarked\n0            1       0.0       3    ...      7.2500   NaN         S\n1            2       1.0       1    ...     71.2833   C85         C\n2            3       1.0       3    ...      7.9250   NaN         S\n3            4       1.0       1    ...     53.1000  C123         S\n4            5       0.0       3    ...      8.0500   NaN         S\n\n[5 rows x 12 columns]"
                    ]
                },
                "mc_idx": 8,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 3,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Shape of the combined data.\"\"\"\nbold(\"Shape of the Merged Data:\")\ndisplay(merged.shape)\n\n\"\"\"Variables in the combined data.\"\"\"\nbold(\"Name of the Variables in merged data:\")\ndisplay(merged.columns)",
            "mc_idx": 9,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.75,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 2
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1,
                    "shape": 3
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    4,
                    3,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "(1309, 12)",
                        "<IPython.core.display.Markdown object>",
                        "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n      dtype='object')"
                    ]
                },
                "mc_idx": 9,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 4,
                "o_idx": 3
            }
        },
        {
            "source": "### So what can we see??\n**We can see total 12 variables. And each variable has 1309 observations (excluding Survived).**\n### Here comes the description of all variables:\n1. **PassengerId** is a unique identifying number assigned to each passenger.\n2. **Survived** is a flag that indicates if a passenger survived or died ( i.e., 0 = No, 1 = Yes).\n3. **Pclass** is the passenger class (i.e., 1 = 1st class, 2 = 2nd class, 3 = 3rd class).\n4. **Name** is the name of the passenger.\n5. **Sex** indicates the gender of the passenger (i.e., Male or female).\n6. **Age** indicates the age of the passenger.\n7. **Sibsp**  is the number of siblings/spouses aboard.\n8. **Parch** is the number of parents/children aboard.\n9. **Ticket** indicates the ticket number issued to the passenger.\n10. **Fare** indicates the amount of money spent on their ticket.\n11. **Cabin** indicates the cabin category occupied by the passenger.\n12. **Embarked** indicates the port where the passenger embarked from (i.e., C = Cherbourg, Q = Queenstown, S = Southampton).\n\n\n### Here, Survived is the target variable and rest of the variables are predictor variables.\n\n## 3.2 Categorical and Numerical Variables  <a id=\"3.2\"></a>\n**Categorical Variable:** Survived, Sex, Pclass (ordinal), Embarked, Cabin, Name, Ticket, SibSp, and Parch.\n\n**Numerical Variable:** Fare, Age, and PassengerId.\n## 3.3 Variable Data Types <a id=\"3.3\"></a>",
            "mc_idx": 10,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Pandas data types for our different variables.\"\"\"\nbold(\"Data Types of Our Variables:\")\ndisplay(merged.dtypes)",
            "mc_idx": 11,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 2
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "dtypes": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    5,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "PassengerId      int64\nSurvived       float64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object"
                    ]
                },
                "mc_idx": 11,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 5,
                "o_idx": 1
            }
        },
        {
            "source": "1. **int data type variables:** Pclass, SibSp, Parch, and PassengerId.\n2. **float data type variables:** Fare and Age, *Survived (due to concatenation)*\n3. **object (numbers + strings) data type variables:** Name, Sex, Ticket, Cabin, and Embarked.\n\n# 4.Univariate Analysis <a id=\"4\"></a>\nUnivariate analysis separately explores the distribution of each variable in a data set. It looks at the range of values, as well as the central tendency of the values. Univariate data analysis does not look at relationships between various variables (like bivariate and multivariate analysis) rather it summarises each variable on its own. Methods to perform univariate analysis will depend on whether the variable is categorical or numerical. For numerical variable, we would explore its shape of distribution (distribution can either be symmetric or skewed) using histogram and density plots. For categorical variables, we would use bar plots to visualize the absolute and proportional frequency distribution. Knowing the distribution of the feature values becomes important when you use machine learning methods that assume a particular type of it, most often Gaussian. **Let's starts off with categorical variables:**\n\n## 4.1 Categorical Variables  <a id=\"4.1\"></a>\nTo analyse categorical variables, let's create a custom function to display bar chart in absolute and relative scale of a variable in a subplot.",
            "mc_idx": 12,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Create a function to plot a variable's absolute and relative frequency.\"\"\"\ndef plotFrequency(variable):\n    \"\"\"Plots absolute and relative frequency of a avriable.\"\"\"\n    \n    # Calculates absolute frequency\n    absFreq = variable.value_counts()\n    \n    # Calculates relative frequency\n    relFreq = variable.value_counts(normalize=True).round(4)*100\n    \n    # Creates a dataframe off absolute and relative frequency\n    df = pd.DataFrame({\n        \"absoluteFrequency\":absFreq,\n        \"relativeFrequency\":relFreq\n    })\n    \n    # Create two subplots of bar chart\n    fig=make_subplots(\n        rows=1, \n        cols=2,\n        vertical_spacing=0.3,\n        subplot_titles=(\"Absolute Frequency\", \"Relative Frequency\"),\n        print_grid=False) # This suppresses \"This is the format of your plot grid:\" text from popping out.\n\n    # Add trace for absolute frequency\n    fig.add_trace(\n        go.Bar(\n        y=df.index, \n        x=df.absoluteFrequency,\n        orientation=\"h\",\n        text=df.absoluteFrequency,\n        hoverinfo=\"x+y\",\n        textposition=\"auto\", \n        name=\"Abs Freq\",\n        textfont=dict(family=\"sans serif\",size=14),\n        marker = dict(color=df.absoluteFrequency, colorscale=\"Rainbow\")),\n        row=1,\n        col=1\n        )\n\n    # Add another trace for relative frequency\n    fig.add_trace(\n        go.Bar(y=df.index,\n        x=df.relativeFrequency.round(2),\n        orientation=\"h\",\n        text=df.relativeFrequency.round(2),\n        hoverinfo=\"x+y\",\n        textposition=\"auto\", \n        name=\"Rel Freq(%)\",\n        textfont=dict(family=\"sans serif\",size=15),\n        marker=dict(color=df.relativeFrequency.round(2), colorscale=\"Rainbow\")),\n        row=1,\n        col=2\n        )\n\n    # Update the layout. Add title, dimension, and background color\n    fig.layout.update(\n        height=600, \n        width=970,\n        hovermode=\"closest\",\n        title_text=f\"Absolute and Relative Frequency of {variable.name}\",showlegend=False,\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n\n    # Set y-axis title in bold\n    fig.layout.yaxis1.update(title=f\"<b>{variable.name}</b>\")\n    \n    # Set x-axes titles in bold\n    fig.layout.xaxis1.update(title=\"<b>Abs Freq</b>\")\n    fig.layout.xaxis2.update(title=\"<b>Rel Freq(%)</b>\")\n    # or, fig[\"layout\"][\"xaxis2\"].update(title=\"<b>Rel Freq(%)</b>\")\n    return fig.show()",
            "mc_idx": 13,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.7777777777777778,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.3333333333333333,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1,
                    "variable": 6
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    ".bar(": 2,
                    "info": 2,
                    "size": 2,
                    ".value_counts": 2
                },
                "Data_Transform": {
                    ".add": 2,
                    ".abs": 3,
                    ".round": 4
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    ".bar(": 2,
                    "chart": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    6,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 13,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 6,
                "o_idx": 0
            }
        },
        {
            "source": "###  4.1.1 Survived <a id=\"4.1.1\"></a>",
            "mc_idx": 14,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Plot number of survivors and victims in absolute and relative scale in the tragedy.\"\"\"\nplotFrequency(merged.Survived)",
            "mc_idx": 15,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    7,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"b80ac3f2-a20a-4c67-9e48-562f2add226c\" class=\"plotly-graph-div\" style=\"height:600px; width:970px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"b80ac3f2-a20a-4c67-9e48-562f2add226c\")) {\n                    Plotly.newPlot(\n                        'b80ac3f2-a20a-4c67-9e48-562f2add226c',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [549, 342], \"colorscale\": \"Rainbow\"}, \"name\": \"Abs Freq\", \"orientation\": \"h\", \"text\": [549.0, 342.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"6437cf3d-77ed-450c-80d1-88081447e909\", \"x\": [549, 342], \"xaxis\": \"x\", \"y\": [0.0, 1.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [61.62, 38.38], \"colorscale\": \"Rainbow\"}, \"name\": \"Rel Freq(%)\", \"orientation\": \"h\", \"text\": [61.62, 38.38], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"0fad07b8-e744-4515-9939-a31511cc7055\", \"x\": [61.62, 38.38], \"xaxis\": \"x2\", \"y\": [0.0, 1.0], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Frequency\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Relative Frequency\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Absolute and Relative Frequency of Survived\"}, \"width\": 970, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"<b>Abs Freq</b>\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"<b>Rel Freq(%)</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Survived</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('b80ac3f2-a20a-4c67-9e48-562f2add226c');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 15,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 7,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** Variable Survived is imbalanced since the proportion of survivors and victims is not equally represented in its distribution. Out of 891 passengers, only 342 passengers survived and a whopping 549 passengers died. Or put another way, 61.62% passengers died while just 38.38% of passengers were lucky enough to survive.",
            "mc_idx": 16,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "### 4.1.2 Sex <a id=\"4.1.2\"></a>",
            "mc_idx": 17,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Plot the absolute and relative frequency of Sex.\"\"\"\nplotFrequency(merged.Sex)",
            "mc_idx": 18,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    8,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"fde960fc-d331-4896-ba31-df6702692e4b\" class=\"plotly-graph-div\" style=\"height:600px; width:970px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"fde960fc-d331-4896-ba31-df6702692e4b\")) {\n                    Plotly.newPlot(\n                        'fde960fc-d331-4896-ba31-df6702692e4b',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [843, 466], \"colorscale\": \"Rainbow\"}, \"name\": \"Abs Freq\", \"orientation\": \"h\", \"text\": [843.0, 466.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"6694717e-8e49-4a12-b8ad-c8fb22aa3c67\", \"x\": [843, 466], \"xaxis\": \"x\", \"y\": [\"male\", \"female\"], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [64.4, 35.6], \"colorscale\": \"Rainbow\"}, \"name\": \"Rel Freq(%)\", \"orientation\": \"h\", \"text\": [64.4, 35.6], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"f2a74674-5ad4-487e-91e1-6d5dfd581402\", \"x\": [64.4, 35.6], \"xaxis\": \"x2\", \"y\": [\"male\", \"female\"], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Frequency\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Relative Frequency\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Absolute and Relative Frequency of Sex\"}, \"width\": 970, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"<b>Abs Freq</b>\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"<b>Rel Freq(%)</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Sex</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('fde960fc-d331-4896-ba31-df6702692e4b');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 18,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 8,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** Variable Sex is imbalanced as proportion of male vs female in its distribution are not equally represented. Rather Male(843) has outnumbered female (466) in variable Sex. Or, proportionally, over 64% of Sex variable consists of label male while female contibutes to only over 35.5% of Sex.\n\n### 4.1.3 Pclass  <a id=\"4.1.3\"></a>",
            "mc_idx": 19,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Absolute and relative frequency of Pclass.\"\"\"\nplotFrequency(merged.Pclass)",
            "mc_idx": 20,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    9,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"4487e3b3-9ec0-49d3-a04f-fd11ad0518d2\" class=\"plotly-graph-div\" style=\"height:600px; width:970px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"4487e3b3-9ec0-49d3-a04f-fd11ad0518d2\")) {\n                    Plotly.newPlot(\n                        '4487e3b3-9ec0-49d3-a04f-fd11ad0518d2',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [709, 323, 277], \"colorscale\": \"Rainbow\"}, \"name\": \"Abs Freq\", \"orientation\": \"h\", \"text\": [709.0, 323.0, 277.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"12cc02d2-cc07-4985-9e3f-98b6dbcc2d66\", \"x\": [709, 323, 277], \"xaxis\": \"x\", \"y\": [3, 1, 2], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [54.16, 24.68, 21.16], \"colorscale\": \"Rainbow\"}, \"name\": \"Rel Freq(%)\", \"orientation\": \"h\", \"text\": [54.16, 24.68, 21.16], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"10874fec-59a1-47ae-a4b6-539b73e8a2ad\", \"x\": [54.16, 24.68, 21.16], \"xaxis\": \"x2\", \"y\": [3, 1, 2], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Frequency\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Relative Frequency\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Absolute and Relative Frequency of Pclass\"}, \"width\": 970, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"<b>Abs Freq</b>\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"<b>Rel Freq(%)</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Pclass</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('4487e3b3-9ec0-49d3-a04f-fd11ad0518d2');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 20,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 9,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** Again class distribution of Pclass is imbalanced as three categories of Pclass are not evenly represented in its distribution. 3 (Pclass3) is the most occured (709) levels of Pclass while 2 is the least occured (277). Another way of saying that, over  54% of Pclass variable consists of 3(Pclass3) while 1 and 2 both combinedly contribute to nearly 46% of Pclass.\n\n### 4.1.4 Embarked  <a id=\"4.1.4\"></a>",
            "mc_idx": 21,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Plot absolute and relative frequency of Embarked.\"\"\"\nplotFrequency(merged.Embarked)",
            "mc_idx": 22,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    10,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"3213b36e-7976-4924-9c47-eb63ff70b148\" class=\"plotly-graph-div\" style=\"height:600px; width:970px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"3213b36e-7976-4924-9c47-eb63ff70b148\")) {\n                    Plotly.newPlot(\n                        '3213b36e-7976-4924-9c47-eb63ff70b148',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [914, 270, 123], \"colorscale\": \"Rainbow\"}, \"name\": \"Abs Freq\", \"orientation\": \"h\", \"text\": [914.0, 270.0, 123.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"ee613f30-c049-4c2e-ac52-292c2e8dc91a\", \"x\": [914, 270, 123], \"xaxis\": \"x\", \"y\": [\"S\", \"C\", \"Q\"], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [69.93, 20.66, 9.41], \"colorscale\": \"Rainbow\"}, \"name\": \"Rel Freq(%)\", \"orientation\": \"h\", \"text\": [69.93, 20.66, 9.41], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"cc5b53ec-eb0e-49cd-b717-3fce9c92afd9\", \"x\": [69.93, 20.66, 9.41], \"xaxis\": \"x2\", \"y\": [\"S\", \"C\", \"Q\"], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Frequency\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Relative Frequency\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Absolute and Relative Frequency of Embarked\"}, \"width\": 970, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"<b>Abs Freq</b>\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"<b>Rel Freq(%)</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Embarked</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('3213b36e-7976-4924-9c47-eb63ff70b148');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 22,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 10,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** Embarked is also imbalanced since its levels are not equally represented in its distribution. A whopping 914 passengers embarked from Southamton while just 123 embarked from Queenstown. In other words, almost 70% of Embarked consists of S while both C and Q contribute to 30 to Embarked.\n\n### 4.1.5 Cabin <a id=\"4.1.5\"></a>",
            "mc_idx": 23,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Absolute frequency of Cabin.\"\"\"\nabsFreqCabin = merged.Cabin.value_counts(dropna = False)\nbold(\"Categories of Cabin:\")\ndisplay(absFreqCabin.head())",
            "mc_idx": 24,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1,
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    11,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "NaN                1014\nC23 C25 C27           6\nB57 B59 B63 B66       5\nG6                    5\nD                     4\nName: Cabin, dtype: int64"
                    ]
                },
                "mc_idx": 24,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 11,
                "o_idx": 1
            }
        },
        {
            "source": "\n\"\"\"As frequency of Cabin isn't what we expected, let's count total categories in Cabin.\"\"\"\nbold(\"Total Categories in Cabin:\")\ndisplay(absFreqCabin.count())",
            "mc_idx": 25,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    12,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "187"
                    ]
                },
                "mc_idx": 25,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 12,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Finally preview the variable Cabin to see what is causing the irregularity.\"\"\"\nbold(\"Preview of Cabin:\")\ndisplay(merged.Cabin.head(7))",
            "mc_idx": 26,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.3333333333333333,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    13,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "0     NaN\n1     C85\n2     NaN\n3    C123\n4     NaN\n5     NaN\n6     E46\nName: Cabin, dtype: object"
                    ]
                },
                "mc_idx": 26,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 13,
                "o_idx": 1
            }
        },
        {
            "source": "**Findings:** Looks like Cabin is an alphanumeric type variable with 1014 missing obsevations. There are 187 kinds of categories in variable Cabin. Since there are too many categories in Cabin, we must process (i.e., reduce the number of categories) Cabin to check if there is any association between Survived and Cabin.\n\n### 4.1.6 Name <a id=\"4.1.6\"></a>",
            "mc_idx": 27,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Count total categories in Name.\"\"\"\nbold(\"Total Categories in Name:\")\ndisplay(merged.Name.value_counts().count())",
            "mc_idx": 28,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    14,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "1307"
                    ]
                },
                "mc_idx": 28,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 14,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Let's finally check the what's inside the variable Name.\"\"\"\nbold(\"Preview of Name:\")\ndisplay(merged.Name.head())",
            "mc_idx": 29,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.3333333333333333,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    15,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "0                              Braund, Mr. Owen Harris\n1    Cumings, Mrs. John Bradley (Florence Briggs Th...\n2                               Heikkinen, Miss. Laina\n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)\n4                             Allen, Mr. William Henry\nName: Name, dtype: object"
                    ]
                },
                "mc_idx": 29,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 15,
                "o_idx": 1
            }
        },
        {
            "source": "**Findings:** As expected Name contains strings that has 1307 variations. So, like Cabin, we must process Name to get any clue about survival from it.\n\n### 4.1.7 Ticket  <a id=\"4.1.7\"></a>",
            "mc_idx": 30,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Count total groups in variable Ticket.\"\"\"\nbold(\"Total Groups in Ticket:\")\ndisplay(merged.Ticket.value_counts().count())",
            "mc_idx": 31,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    16,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "929"
                    ]
                },
                "mc_idx": 31,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 16,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Lets investigate Ticket.\"\"\"\nbold(\"Preview of Ticket:\")\ndisplay(merged.Ticket.head())",
            "mc_idx": 32,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    17,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "0           A/5 21171\n1            PC 17599\n2    STON/O2. 3101282\n3              113803\n4              373450\nName: Ticket, dtype: object"
                    ]
                },
                "mc_idx": 32,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 17,
                "o_idx": 1
            }
        },
        {
            "source": "**Findings:** It seems Ticket also has too many unique categories (929). Being an alphanumeric type variable, we must process Ticket to get any useful insights about survival.\n\n### 4.1.8 SibSp  <a id=\"4.1.8\"></a>",
            "mc_idx": 33,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Plot the absolute and relative frequency of SibSp to investigate its distribution.\"\"\"\nplotFrequency(merged.SibSp)",
            "mc_idx": 34,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    18,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"1e0006d4-f04b-4644-952e-a95245b5a860\" class=\"plotly-graph-div\" style=\"height:600px; width:970px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"1e0006d4-f04b-4644-952e-a95245b5a860\")) {\n                    Plotly.newPlot(\n                        '1e0006d4-f04b-4644-952e-a95245b5a860',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [891, 319, 42, 22, 20, 9, 6], \"colorscale\": \"Rainbow\"}, \"name\": \"Abs Freq\", \"orientation\": \"h\", \"text\": [891.0, 319.0, 42.0, 22.0, 20.0, 9.0, 6.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"c08a2d74-4510-4d72-ad14-9a21e6689535\", \"x\": [891, 319, 42, 22, 20, 9, 6], \"xaxis\": \"x\", \"y\": [0, 1, 2, 4, 3, 8, 5], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [68.07, 24.37, 3.21, 1.68, 1.53, 0.69, 0.46], \"colorscale\": \"Rainbow\"}, \"name\": \"Rel Freq(%)\", \"orientation\": \"h\", \"text\": [68.07, 24.37, 3.21, 1.68, 1.53, 0.69, 0.46], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"8481fcec-bfde-4c10-91d6-3e79d6a58209\", \"x\": [68.07, 24.37, 3.21, 1.68, 1.53, 0.69, 0.46], \"xaxis\": \"x2\", \"y\": [0, 1, 2, 4, 3, 8, 5], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Frequency\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Relative Frequency\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Absolute and Relative Frequency of SibSp\"}, \"width\": 970, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"<b>Abs Freq</b>\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"<b>Rel Freq(%)</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>SibSp</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('1e0006d4-f04b-4644-952e-a95245b5a860');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 34,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 18,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** Once again, SibSp is not balanced as levels of SibSp(7) are not equally represented in its distribution. 891 passengers were without siblings or spouses. Put another way, over 68% passengers had no siblings or spouses aboard, followed by over 24% passengers had 1 siblings or spouse.\n\n### 4.1.9 Parch  <a id=\"4.1.9\"></a>",
            "mc_idx": 35,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Absolute and relative frequency of Parch.\"\"\"\nplotFrequency(merged.Parch)",
            "mc_idx": 36,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    19,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"c3e1ec62-1a65-4d78-b981-53e1e8e74caa\" class=\"plotly-graph-div\" style=\"height:600px; width:970px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"c3e1ec62-1a65-4d78-b981-53e1e8e74caa\")) {\n                    Plotly.newPlot(\n                        'c3e1ec62-1a65-4d78-b981-53e1e8e74caa',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [1002, 170, 113, 8, 6, 6, 2, 2], \"colorscale\": \"Rainbow\"}, \"name\": \"Abs Freq\", \"orientation\": \"h\", \"text\": [1002.0, 170.0, 113.0, 8.0, 6.0, 6.0, 2.0, 2.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"68584a5b-dc9f-44c4-a74b-75c575348f7e\", \"x\": [1002, 170, 113, 8, 6, 6, 2, 2], \"xaxis\": \"x\", \"y\": [0, 1, 2, 3, 5, 4, 9, 6], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [76.55, 12.99, 8.63, 0.61, 0.46, 0.46, 0.15, 0.15], \"colorscale\": \"Rainbow\"}, \"name\": \"Rel Freq(%)\", \"orientation\": \"h\", \"text\": [76.55, 12.99, 8.63, 0.61, 0.46, 0.46, 0.15, 0.15], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"a1c2c595-3979-4f13-97fe-37b602abaac7\", \"x\": [76.55, 12.99, 8.63, 0.61, 0.46, 0.46, 0.15, 0.15], \"xaxis\": \"x2\", \"y\": [0, 1, 2, 3, 5, 4, 9, 6], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Frequency\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Relative Frequency\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Absolute and Relative Frequency of Parch\"}, \"width\": 970, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"<b>Abs Freq</b>\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"<b>Rel Freq(%)</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Parch</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('c3e1ec62-1a65-4d78-b981-53e1e8e74caa');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 36,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 19,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** Parch isn't balanced as levels of Parch(8) are not equally represented in its distribution. Over one thousand passengers were without parents or children, followed by 170 passengers had one parents or children. In other words, over 76.5% passengers were without parents or children while rest of the 23.5% had few parents or children.\n\n## 4.2 Numerical Variables <a id=\"4.2\"></a>\nWe would like to analyse numerical variables using histogram, density plot, and summary statistics. To analyse numerical variables, we will create 2 custom functions. The 1st one will plot histogram and density plot for each numerical variable. And the 2nd one will calculate summary statistics including skewness.",
            "mc_idx": 37,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"#1.Create a function to plot histogram and density plot.\"\"\"\ndef plotHistogram(variable):\n    \"\"\"Plots histogram and density plot of a variable.\"\"\"\n    \n    # Create subplot object.\n    fig = make_subplots(\n        rows=2,\n        cols=1,\n        print_grid=False,\n    subplot_titles=(f\"Distribution of {variable.name} with Histogram\", f\"Distribution of {variable.name} with Density Plot\"))\n    \n    # This is a count histogram\n    fig.add_trace(\n        go.Histogram(\n            x = variable,\n            hoverinfo=\"x+y\",\n            marker = dict(color = \"chocolate\")\n        ),\n    row=1,col=1)\n    \n    # This is a density histogram\n    fig.add_trace(\n        go.Histogram(\n            x = variable,\n            hoverinfo=\"x+y\",\n            histnorm = \"density\",\n            marker = dict(color = \"darkred\")\n        ),\n    row=2,col=1)\n    \n    # Update layout\n    fig.layout.update(\n        height=800, \n        width=870,\n        hovermode=\"closest\",\n        showlegend=False,\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n    \n    # Update axes\n    fig.layout.yaxis1.update(title=\"<b>Abs Frequency</b>\")\n    fig.layout.yaxis2.update(title=\"<b>Density(%)</b>\")\n    fig.layout.xaxis2.update(title=f\"<b>{variable.name}</b>\")\n    return fig.show()\n    \n\n    \n'''#2.Calculate descriptive statistics.'''\ndef calculateSummaryStats(variable):\n    stats = variable.describe()\n    skewness = pd.Series(variable.skew(), index = [\"skewness\"])\n    statsDf = pd.DataFrame(pd.concat([skewness, stats], sort = False), columns = [variable.name])\n    statsDf = statsDf.reset_index().rename(columns={\"index\":\"summaryStats\"})\n    return display(statsDf.round(2))",
            "mc_idx": 38,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.8333333333333334,
                "Data_Transform": 0.5833333333333334,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.16666666666666666,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1,
                    "variable": 11
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".describe(": 1,
                    ".histogram(": 2,
                    "info": 2,
                    "describe": 1,
                    "columns": 2,
                    ".describe": 1,
                    ".skew": 1
                },
                "Data_Transform": {
                    ".concat(": 1,
                    ".reset_index": 1,
                    ".rename": 1,
                    ".concat": 1,
                    ".add": 2,
                    ".round": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "summary": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    20,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 38,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 20,
                "o_idx": 0
            }
        },
        {
            "source": "### 4.2.1 Fare <a id=\"4.2.1\"></a>",
            "mc_idx": 39,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "'''Plot histogram and density plot of Fare.'''\nplotHistogram(merged.Fare)",
            "mc_idx": 40,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    21,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"8518e726-d9ab-44c6-b352-8ce7646400aa\" class=\"plotly-graph-div\" style=\"height:800px; width:870px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"8518e726-d9ab-44c6-b352-8ce7646400aa\")) {\n                    Plotly.newPlot(\n                        '8518e726-d9ab-44c6-b352-8ce7646400aa',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": \"chocolate\"}, \"type\": \"histogram\", \"uid\": \"bc3aa1c7-981c-4809-84a2-f1ba2791c423\", \"x\": [7.25, 71.2833, 7.925, 53.1, 8.05, 8.4583, 51.8625, 21.075, 11.1333, 30.0708, 16.7, 26.55, 8.05, 31.275, 7.8542, 16.0, 29.125, 13.0, 18.0, 7.225, 26.0, 13.0, 8.0292, 35.5, 21.075, 31.3875, 7.225, 263.0, 7.8792, 7.8958, 27.7208, 146.5208, 7.75, 10.5, 82.1708, 52.0, 7.2292, 8.05, 18.0, 11.2417, 9.475, 21.0, 7.8958, 41.5792, 7.8792, 8.05, 15.5, 7.75, 21.6792, 17.8, 39.6875, 7.8, 76.7292, 26.0, 61.9792, 35.5, 10.5, 7.2292, 27.75, 46.9, 7.2292, 80.0, 83.475, 27.9, 27.7208, 15.2458, 10.5, 8.1583, 7.925, 8.6625, 10.5, 46.9, 73.5, 14.4542, 56.4958, 7.65, 7.8958, 8.05, 29.0, 12.475, 9.0, 9.5, 7.7875, 47.1, 10.5, 15.85, 34.375, 8.05, 263.0, 8.05, 8.05, 7.8542, 61.175, 20.575, 7.25, 8.05, 34.6542, 63.3583, 23.0, 26.0, 7.8958, 7.8958, 77.2875, 8.6542, 7.925, 7.8958, 7.65, 7.775, 7.8958, 24.15, 52.0, 14.4542, 8.05, 9.825, 14.4583, 7.925, 7.75, 21.0, 247.5208, 31.275, 73.5, 8.05, 30.0708, 13.0, 77.2875, 11.2417, 7.75, 7.1417, 22.3583, 6.975, 7.8958, 7.05, 14.5, 26.0, 13.0, 15.0458, 26.2833, 53.1, 9.2167, 79.2, 15.2458, 7.75, 15.85, 6.75, 11.5, 36.75, 7.7958, 34.375, 26.0, 13.0, 12.525, 66.6, 8.05, 14.5, 7.3125, 61.3792, 7.7333, 8.05, 8.6625, 69.55, 16.1, 15.75, 7.775, 8.6625, 39.6875, 20.525, 55.0, 27.9, 25.925, 56.4958, 33.5, 29.125, 11.1333, 7.925, 30.6958, 7.8542, 25.4667, 28.7125, 13.0, 0.0, 69.55, 15.05, 31.3875, 39.0, 22.025, 50.0, 15.5, 26.55, 15.5, 7.8958, 13.0, 13.0, 7.8542, 26.0, 27.7208, 146.5208, 7.75, 8.4042, 7.75, 13.0, 9.5, 69.55, 6.4958, 7.225, 8.05, 10.4625, 15.85, 18.7875, 7.75, 31.0, 7.05, 21.0, 7.25, 13.0, 7.75, 113.275, 7.925, 27.0, 76.2917, 10.5, 8.05, 13.0, 8.05, 7.8958, 90.0, 9.35, 10.5, 7.25, 13.0, 25.4667, 83.475, 7.775, 13.5, 31.3875, 10.5, 7.55, 26.0, 26.25, 10.5, 12.275, 14.4542, 15.5, 10.5, 7.125, 7.225, 90.0, 7.775, 14.5, 52.5542, 26.0, 7.25, 10.4625, 26.55, 16.1, 20.2125, 15.2458, 79.2, 86.5, 512.3292, 26.0, 7.75, 31.3875, 79.65, 0.0, 7.75, 10.5, 39.6875, 7.775, 153.4625, 135.6333, 31.0, 0.0, 19.5, 29.7, 7.75, 77.9583, 7.75, 0.0, 29.125, 20.25, 7.75, 7.8542, 9.5, 8.05, 26.0, 8.6625, 9.5, 7.8958, 13.0, 7.75, 78.85, 91.0792, 12.875, 8.85, 7.8958, 27.7208, 7.2292, 151.55, 30.5, 247.5208, 7.75, 23.25, 0.0, 12.35, 8.05, 151.55, 110.8833, 108.9, 24.0, 56.9292, 83.1583, 262.375, 26.0, 7.8958, 26.25, 7.8542, 26.0, 14.0, 164.8667, 134.5, 7.25, 7.8958, 12.35, 29.0, 69.55, 135.6333, 6.2375, 13.0, 20.525, 57.9792, 23.25, 28.5, 153.4625, 18.0, 133.65, 7.8958, 66.6, 134.5, 8.05, 35.5, 26.0, 263.0, 13.0, 13.0, 13.0, 13.0, 13.0, 16.1, 15.9, 8.6625, 9.225, 35.0, 7.2292, 17.8, 7.225, 9.5, 55.0, 13.0, 7.8792, 7.8792, 27.9, 27.7208, 14.4542, 7.05, 15.5, 7.25, 75.25, 7.2292, 7.75, 69.3, 55.4417, 6.4958, 8.05, 135.6333, 21.075, 82.1708, 7.25, 211.5, 4.0125, 7.775, 227.525, 15.7417, 7.925, 52.0, 7.8958, 73.5, 46.9, 13.0, 7.7292, 12.0, 120.0, 7.7958, 7.925, 113.275, 16.7, 7.7958, 7.8542, 26.0, 10.5, 12.65, 7.925, 8.05, 9.825, 15.85, 8.6625, 21.0, 7.75, 18.75, 7.775, 25.4667, 7.8958, 6.8583, 90.0, 0.0, 7.925, 8.05, 32.5, 13.0, 13.0, 24.15, 7.8958, 7.7333, 7.875, 14.4, 20.2125, 7.25, 26.0, 26.0, 7.75, 8.05, 26.55, 16.1, 26.0, 7.125, 55.9, 120.0, 34.375, 18.75, 263.0, 10.5, 26.25, 9.5, 7.775, 13.0, 8.1125, 81.8583, 19.5, 26.55, 19.2583, 30.5, 27.75, 19.9667, 27.75, 89.1042, 8.05, 7.8958, 26.55, 51.8625, 10.5, 7.75, 26.55, 8.05, 38.5, 13.0, 8.05, 7.05, 0.0, 26.55, 7.725, 19.2583, 7.25, 8.6625, 27.75, 13.7917, 9.8375, 52.0, 21.0, 7.0458, 7.5208, 12.2875, 46.9, 0.0, 8.05, 9.5875, 91.0792, 25.4667, 90.0, 29.7, 8.05, 15.9, 19.9667, 7.25, 30.5, 49.5042, 8.05, 14.4583, 78.2667, 15.1, 151.55, 7.7958, 8.6625, 7.75, 7.6292, 9.5875, 86.5, 108.9, 26.0, 26.55, 22.525, 56.4958, 7.75, 8.05, 26.2875, 59.4, 7.4958, 34.0208, 10.5, 24.15, 26.0, 7.8958, 93.5, 7.8958, 7.225, 57.9792, 7.2292, 7.75, 10.5, 221.7792, 7.925, 11.5, 26.0, 7.2292, 7.2292, 22.3583, 8.6625, 26.25, 26.55, 106.425, 14.5, 49.5, 71.0, 31.275, 31.275, 26.0, 106.425, 26.0, 26.0, 13.8625, 20.525, 36.75, 110.8833, 26.0, 7.8292, 7.225, 7.775, 26.55, 39.6, 227.525, 79.65, 17.4, 7.75, 7.8958, 13.5, 8.05, 8.05, 24.15, 7.8958, 21.075, 7.2292, 7.8542, 10.5, 51.4792, 26.3875, 7.75, 8.05, 14.5, 13.0, 55.9, 14.4583, 7.925, 30.0, 110.8833, 26.0, 40.125, 8.7125, 79.65, 15.0, 79.2, 8.05, 8.05, 7.125, 78.2667, 7.25, 7.75, 26.0, 24.15, 33.0, 0.0, 7.225, 56.9292, 27.0, 7.8958, 42.4, 8.05, 26.55, 15.55, 7.8958, 30.5, 41.5792, 153.4625, 31.275, 7.05, 15.5, 7.75, 8.05, 65.0, 14.4, 16.1, 39.0, 10.5, 14.4542, 52.5542, 15.7417, 7.8542, 16.1, 32.3208, 12.35, 77.9583, 7.8958, 7.7333, 30.0, 7.0542, 30.5, 0.0, 27.9, 13.0, 7.925, 26.25, 39.6875, 16.1, 7.8542, 69.3, 27.9, 56.4958, 19.2583, 76.7292, 7.8958, 35.5, 7.55, 7.55, 7.8958, 23.0, 8.4333, 7.8292, 6.75, 73.5, 7.8958, 15.5, 13.0, 113.275, 133.65, 7.225, 25.5875, 7.4958, 7.925, 73.5, 13.0, 7.775, 8.05, 52.0, 39.0, 52.0, 10.5, 13.0, 0.0, 7.775, 8.05, 9.8417, 46.9, 512.3292, 8.1375, 76.7292, 9.225, 46.9, 39.0, 41.5792, 39.6875, 10.1708, 7.7958, 211.3375, 57.0, 13.4167, 56.4958, 7.225, 26.55, 13.5, 8.05, 7.7333, 110.8833, 7.65, 227.525, 26.2875, 14.4542, 7.7417, 7.8542, 26.0, 13.5, 26.2875, 151.55, 15.2458, 49.5042, 26.55, 52.0, 9.4833, 13.0, 7.65, 227.525, 10.5, 15.5, 7.775, 33.0, 7.0542, 13.0, 13.0, 53.1, 8.6625, 21.0, 7.7375, 26.0, 7.925, 211.3375, 18.7875, 0.0, 13.0, 13.0, 16.1, 34.375, 512.3292, 7.8958, 7.8958, 30.0, 78.85, 262.375, 16.1, 7.925, 71.0, 20.25, 13.0, 53.1, 7.75, 23.0, 12.475, 9.5, 7.8958, 65.0, 14.5, 7.7958, 11.5, 8.05, 86.5, 14.5, 7.125, 7.2292, 120.0, 7.775, 77.9583, 39.6, 7.75, 24.15, 8.3625, 9.5, 7.8542, 10.5, 7.225, 23.0, 7.75, 7.75, 12.475, 7.7375, 211.3375, 7.2292, 57.0, 30.0, 23.45, 7.05, 7.25, 7.4958, 29.125, 20.575, 79.2, 7.75, 26.0, 69.55, 30.6958, 7.8958, 13.0, 25.9292, 8.6833, 7.2292, 24.15, 13.0, 26.25, 120.0, 8.5167, 6.975, 7.775, 0.0, 7.775, 13.0, 53.1, 7.8875, 24.15, 10.5, 31.275, 8.05, 0.0, 7.925, 37.0042, 6.45, 27.9, 93.5, 8.6625, 0.0, 12.475, 39.6875, 6.95, 56.4958, 37.0042, 7.75, 80.0, 14.4542, 18.75, 7.2292, 7.8542, 8.3, 83.1583, 8.6625, 8.05, 56.4958, 29.7, 7.925, 10.5, 31.0, 6.4375, 8.6625, 7.55, 69.55, 7.8958, 33.0, 89.1042, 31.275, 7.775, 15.2458, 39.4, 26.0, 9.35, 164.8667, 26.55, 19.2583, 7.2292, 14.1083, 11.5, 25.9292, 69.55, 13.0, 13.0, 13.8583, 50.4958, 9.5, 11.1333, 7.8958, 52.5542, 5.0, 9.0, 24.0, 7.225, 9.8458, 7.8958, 7.8958, 83.1583, 26.0, 7.8958, 10.5167, 10.5, 7.05, 29.125, 13.0, 30.0, 23.45, 30.0, 7.75, 7.8292, 7.0, 9.6875, 8.6625, 12.2875, 9.225, 7.6292, 29.0, 7.2292, 24.15, 7.8958, 26.0, 82.2667, 26.0, 61.175, 27.7208, 12.35, 7.225, 7.925, 7.225, 59.4, 3.1708, 31.6833, 61.3792, 262.375, 14.5, 61.9792, 7.225, 30.5, 21.6792, 26.0, 31.5, 20.575, 23.45, 57.75, 7.2292, 8.05, 8.6625, 9.5, 56.4958, 13.4167, 26.55, 7.85, 13.0, 52.5542, 7.925, 29.7, 7.75, 76.2917, 15.9, 60.0, 15.0333, 23.0, 263.0, 15.5792, 29.125, 7.8958, 7.65, 16.1, 262.375, 7.8958, 13.5, 7.75, 7.725, 262.375, 21.0, 7.8792, 42.4, 28.5375, 263.0, 7.75, 7.8958, 7.925, 27.7208, 211.5, 211.5, 8.05, 25.7, 13.0, 7.75, 15.2458, 221.7792, 26.0, 7.8958, 10.7083, 14.4542, 7.8792, 8.05, 7.75, 23.0, 13.9, 7.775, 52.0, 8.05, 26.0, 7.7958, 78.85, 7.925, 7.8542, 8.05, 55.4417, 26.0, 7.75, 7.775, 8.5167, 22.525, 7.8208, 7.75, 8.7125, 13.0, 15.0458, 7.7792, 31.6792, 7.2833, 221.7792, 14.4542, 6.4375, 16.7, 75.2417, 26.0, 15.75, 7.75, 57.75, 7.25, 7.75, 16.1, 7.7958, 23.25, 13.0, 8.05, 8.05, 28.5, 25.4667, 6.4375, 7.8958, 7.8542, 7.225, 13.0, 8.05, 46.9, 46.9, 151.55, 262.375, 26.0, 26.55, 18.0, 51.8625, 8.05, 26.55, 26.0, 83.1583, 7.8958, null, 12.1833, 31.3875, 7.55, 221.7792, 7.8542, 26.55, 13.775, 7.7333, 15.2458, 13.5, 7.0, 13.0, 22.025, 50.4958, 34.375, 27.7208, 8.9625, 7.55, 7.225, 13.9, 7.2292, 31.3875, 39.0, 36.75, 55.4417, 39.0, 83.1583, 13.0, 83.1583, 53.1, 7.75, 247.5208, 16.0, 21.0, 8.05, 69.55, 13.0, 26.0, 26.0, 14.5, 12.35, 32.5, 7.8542, 134.5, 7.775, 10.5, 8.1125, 15.5, 14.4, 227.525, 26.0, 10.5, 25.7417, 7.75, 10.5, 27.7208, 7.8958, 22.525, 7.05, 73.5, 26.0, 7.775, 42.5, 7.8792, 164.8667, 211.5, 8.05, 13.8583, 8.05, 10.5, 7.7958, 27.4458, 15.2458, 7.7958, 7.75, 15.1, 13.0, 65.0, 26.55, 6.4958, 7.8792, 71.2833, 7.8542, 75.25, 7.225, 13.0, 106.425, 27.7208, 30.0, 134.5, 7.8875, 23.45, 51.8625, 21.0, 32.5, 26.0, 14.4542, 27.75, 7.925, 136.7792, 9.325, 9.5, 7.55, 7.75, 8.05, 13.0, 7.775, 17.4, 7.8542, 23.0, 12.1833, 12.7375, 7.8958, 0.0, 7.55, 8.05, 8.6625, 75.2417, 7.75, 136.7792, 15.5, 7.225, 26.0, 10.5, 26.0, 21.0, 10.5, 8.6625, 13.775, 7.75, 15.2458, 20.2125, 7.25, 7.25, 82.2667, 7.2292, 8.05, 39.6, 6.95, 7.2292, 81.8583, 9.5, 7.8958, 41.5792, 21.6792, 45.5, 7.8542, 7.775, 15.0458, 21.0, 8.6625, 7.75, 26.55, 151.55, 9.35, 93.5, 14.1083, 8.6625, 7.225, 7.575, 7.75, 135.6333, 7.7333, 146.5208, 10.5, 7.8542, 31.5, 7.775, 7.2292, 13.0, 26.55, 211.3375, 7.05, 39.0, 79.2, 26.0, 13.0, 36.75, 29.7, 7.225, 15.7417, 7.8958, 26.0, 13.0, 7.2292, 31.5, 7.2292, 10.5, 7.5792, 69.55, 512.3292, 14.5, 7.65, 13.0, 7.2292, 13.5, 21.0, 63.3583, 10.5, 73.5, 65.0, 20.575, 26.0, 51.4792, 7.8792, 7.75, 15.55, 69.55, 37.0042, 21.0, 8.6625, 55.4417, 69.55, 14.4583, 39.6875, 59.4, 13.8583, 11.5, 134.5, 0.0, 13.0, 81.8583, 262.375, 8.6625, 11.5, 50.0, 31.3875, 7.75, 7.8792, 14.5, 16.1, 12.875, 65.0, 7.775, 13.0, 7.75, 21.075, 93.5, 39.4, 20.25, 10.5, 22.025, 60.0, 7.25, 79.2, 7.775, 7.7333, 164.8667, 21.0, 59.4, 47.1, 27.7208, 13.8625, 10.5, 211.5, 7.7208, 13.775, 7.75, 90.0, 7.775, 8.05, 108.9, 7.25, 8.05, 22.3583], \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"histnorm\": \"density\", \"hoverinfo\": \"x+y\", \"marker\": {\"color\": \"darkred\"}, \"type\": \"histogram\", \"uid\": \"9a9766ad-fd85-416b-8d7c-232da04efcf6\", \"x\": [7.25, 71.2833, 7.925, 53.1, 8.05, 8.4583, 51.8625, 21.075, 11.1333, 30.0708, 16.7, 26.55, 8.05, 31.275, 7.8542, 16.0, 29.125, 13.0, 18.0, 7.225, 26.0, 13.0, 8.0292, 35.5, 21.075, 31.3875, 7.225, 263.0, 7.8792, 7.8958, 27.7208, 146.5208, 7.75, 10.5, 82.1708, 52.0, 7.2292, 8.05, 18.0, 11.2417, 9.475, 21.0, 7.8958, 41.5792, 7.8792, 8.05, 15.5, 7.75, 21.6792, 17.8, 39.6875, 7.8, 76.7292, 26.0, 61.9792, 35.5, 10.5, 7.2292, 27.75, 46.9, 7.2292, 80.0, 83.475, 27.9, 27.7208, 15.2458, 10.5, 8.1583, 7.925, 8.6625, 10.5, 46.9, 73.5, 14.4542, 56.4958, 7.65, 7.8958, 8.05, 29.0, 12.475, 9.0, 9.5, 7.7875, 47.1, 10.5, 15.85, 34.375, 8.05, 263.0, 8.05, 8.05, 7.8542, 61.175, 20.575, 7.25, 8.05, 34.6542, 63.3583, 23.0, 26.0, 7.8958, 7.8958, 77.2875, 8.6542, 7.925, 7.8958, 7.65, 7.775, 7.8958, 24.15, 52.0, 14.4542, 8.05, 9.825, 14.4583, 7.925, 7.75, 21.0, 247.5208, 31.275, 73.5, 8.05, 30.0708, 13.0, 77.2875, 11.2417, 7.75, 7.1417, 22.3583, 6.975, 7.8958, 7.05, 14.5, 26.0, 13.0, 15.0458, 26.2833, 53.1, 9.2167, 79.2, 15.2458, 7.75, 15.85, 6.75, 11.5, 36.75, 7.7958, 34.375, 26.0, 13.0, 12.525, 66.6, 8.05, 14.5, 7.3125, 61.3792, 7.7333, 8.05, 8.6625, 69.55, 16.1, 15.75, 7.775, 8.6625, 39.6875, 20.525, 55.0, 27.9, 25.925, 56.4958, 33.5, 29.125, 11.1333, 7.925, 30.6958, 7.8542, 25.4667, 28.7125, 13.0, 0.0, 69.55, 15.05, 31.3875, 39.0, 22.025, 50.0, 15.5, 26.55, 15.5, 7.8958, 13.0, 13.0, 7.8542, 26.0, 27.7208, 146.5208, 7.75, 8.4042, 7.75, 13.0, 9.5, 69.55, 6.4958, 7.225, 8.05, 10.4625, 15.85, 18.7875, 7.75, 31.0, 7.05, 21.0, 7.25, 13.0, 7.75, 113.275, 7.925, 27.0, 76.2917, 10.5, 8.05, 13.0, 8.05, 7.8958, 90.0, 9.35, 10.5, 7.25, 13.0, 25.4667, 83.475, 7.775, 13.5, 31.3875, 10.5, 7.55, 26.0, 26.25, 10.5, 12.275, 14.4542, 15.5, 10.5, 7.125, 7.225, 90.0, 7.775, 14.5, 52.5542, 26.0, 7.25, 10.4625, 26.55, 16.1, 20.2125, 15.2458, 79.2, 86.5, 512.3292, 26.0, 7.75, 31.3875, 79.65, 0.0, 7.75, 10.5, 39.6875, 7.775, 153.4625, 135.6333, 31.0, 0.0, 19.5, 29.7, 7.75, 77.9583, 7.75, 0.0, 29.125, 20.25, 7.75, 7.8542, 9.5, 8.05, 26.0, 8.6625, 9.5, 7.8958, 13.0, 7.75, 78.85, 91.0792, 12.875, 8.85, 7.8958, 27.7208, 7.2292, 151.55, 30.5, 247.5208, 7.75, 23.25, 0.0, 12.35, 8.05, 151.55, 110.8833, 108.9, 24.0, 56.9292, 83.1583, 262.375, 26.0, 7.8958, 26.25, 7.8542, 26.0, 14.0, 164.8667, 134.5, 7.25, 7.8958, 12.35, 29.0, 69.55, 135.6333, 6.2375, 13.0, 20.525, 57.9792, 23.25, 28.5, 153.4625, 18.0, 133.65, 7.8958, 66.6, 134.5, 8.05, 35.5, 26.0, 263.0, 13.0, 13.0, 13.0, 13.0, 13.0, 16.1, 15.9, 8.6625, 9.225, 35.0, 7.2292, 17.8, 7.225, 9.5, 55.0, 13.0, 7.8792, 7.8792, 27.9, 27.7208, 14.4542, 7.05, 15.5, 7.25, 75.25, 7.2292, 7.75, 69.3, 55.4417, 6.4958, 8.05, 135.6333, 21.075, 82.1708, 7.25, 211.5, 4.0125, 7.775, 227.525, 15.7417, 7.925, 52.0, 7.8958, 73.5, 46.9, 13.0, 7.7292, 12.0, 120.0, 7.7958, 7.925, 113.275, 16.7, 7.7958, 7.8542, 26.0, 10.5, 12.65, 7.925, 8.05, 9.825, 15.85, 8.6625, 21.0, 7.75, 18.75, 7.775, 25.4667, 7.8958, 6.8583, 90.0, 0.0, 7.925, 8.05, 32.5, 13.0, 13.0, 24.15, 7.8958, 7.7333, 7.875, 14.4, 20.2125, 7.25, 26.0, 26.0, 7.75, 8.05, 26.55, 16.1, 26.0, 7.125, 55.9, 120.0, 34.375, 18.75, 263.0, 10.5, 26.25, 9.5, 7.775, 13.0, 8.1125, 81.8583, 19.5, 26.55, 19.2583, 30.5, 27.75, 19.9667, 27.75, 89.1042, 8.05, 7.8958, 26.55, 51.8625, 10.5, 7.75, 26.55, 8.05, 38.5, 13.0, 8.05, 7.05, 0.0, 26.55, 7.725, 19.2583, 7.25, 8.6625, 27.75, 13.7917, 9.8375, 52.0, 21.0, 7.0458, 7.5208, 12.2875, 46.9, 0.0, 8.05, 9.5875, 91.0792, 25.4667, 90.0, 29.7, 8.05, 15.9, 19.9667, 7.25, 30.5, 49.5042, 8.05, 14.4583, 78.2667, 15.1, 151.55, 7.7958, 8.6625, 7.75, 7.6292, 9.5875, 86.5, 108.9, 26.0, 26.55, 22.525, 56.4958, 7.75, 8.05, 26.2875, 59.4, 7.4958, 34.0208, 10.5, 24.15, 26.0, 7.8958, 93.5, 7.8958, 7.225, 57.9792, 7.2292, 7.75, 10.5, 221.7792, 7.925, 11.5, 26.0, 7.2292, 7.2292, 22.3583, 8.6625, 26.25, 26.55, 106.425, 14.5, 49.5, 71.0, 31.275, 31.275, 26.0, 106.425, 26.0, 26.0, 13.8625, 20.525, 36.75, 110.8833, 26.0, 7.8292, 7.225, 7.775, 26.55, 39.6, 227.525, 79.65, 17.4, 7.75, 7.8958, 13.5, 8.05, 8.05, 24.15, 7.8958, 21.075, 7.2292, 7.8542, 10.5, 51.4792, 26.3875, 7.75, 8.05, 14.5, 13.0, 55.9, 14.4583, 7.925, 30.0, 110.8833, 26.0, 40.125, 8.7125, 79.65, 15.0, 79.2, 8.05, 8.05, 7.125, 78.2667, 7.25, 7.75, 26.0, 24.15, 33.0, 0.0, 7.225, 56.9292, 27.0, 7.8958, 42.4, 8.05, 26.55, 15.55, 7.8958, 30.5, 41.5792, 153.4625, 31.275, 7.05, 15.5, 7.75, 8.05, 65.0, 14.4, 16.1, 39.0, 10.5, 14.4542, 52.5542, 15.7417, 7.8542, 16.1, 32.3208, 12.35, 77.9583, 7.8958, 7.7333, 30.0, 7.0542, 30.5, 0.0, 27.9, 13.0, 7.925, 26.25, 39.6875, 16.1, 7.8542, 69.3, 27.9, 56.4958, 19.2583, 76.7292, 7.8958, 35.5, 7.55, 7.55, 7.8958, 23.0, 8.4333, 7.8292, 6.75, 73.5, 7.8958, 15.5, 13.0, 113.275, 133.65, 7.225, 25.5875, 7.4958, 7.925, 73.5, 13.0, 7.775, 8.05, 52.0, 39.0, 52.0, 10.5, 13.0, 0.0, 7.775, 8.05, 9.8417, 46.9, 512.3292, 8.1375, 76.7292, 9.225, 46.9, 39.0, 41.5792, 39.6875, 10.1708, 7.7958, 211.3375, 57.0, 13.4167, 56.4958, 7.225, 26.55, 13.5, 8.05, 7.7333, 110.8833, 7.65, 227.525, 26.2875, 14.4542, 7.7417, 7.8542, 26.0, 13.5, 26.2875, 151.55, 15.2458, 49.5042, 26.55, 52.0, 9.4833, 13.0, 7.65, 227.525, 10.5, 15.5, 7.775, 33.0, 7.0542, 13.0, 13.0, 53.1, 8.6625, 21.0, 7.7375, 26.0, 7.925, 211.3375, 18.7875, 0.0, 13.0, 13.0, 16.1, 34.375, 512.3292, 7.8958, 7.8958, 30.0, 78.85, 262.375, 16.1, 7.925, 71.0, 20.25, 13.0, 53.1, 7.75, 23.0, 12.475, 9.5, 7.8958, 65.0, 14.5, 7.7958, 11.5, 8.05, 86.5, 14.5, 7.125, 7.2292, 120.0, 7.775, 77.9583, 39.6, 7.75, 24.15, 8.3625, 9.5, 7.8542, 10.5, 7.225, 23.0, 7.75, 7.75, 12.475, 7.7375, 211.3375, 7.2292, 57.0, 30.0, 23.45, 7.05, 7.25, 7.4958, 29.125, 20.575, 79.2, 7.75, 26.0, 69.55, 30.6958, 7.8958, 13.0, 25.9292, 8.6833, 7.2292, 24.15, 13.0, 26.25, 120.0, 8.5167, 6.975, 7.775, 0.0, 7.775, 13.0, 53.1, 7.8875, 24.15, 10.5, 31.275, 8.05, 0.0, 7.925, 37.0042, 6.45, 27.9, 93.5, 8.6625, 0.0, 12.475, 39.6875, 6.95, 56.4958, 37.0042, 7.75, 80.0, 14.4542, 18.75, 7.2292, 7.8542, 8.3, 83.1583, 8.6625, 8.05, 56.4958, 29.7, 7.925, 10.5, 31.0, 6.4375, 8.6625, 7.55, 69.55, 7.8958, 33.0, 89.1042, 31.275, 7.775, 15.2458, 39.4, 26.0, 9.35, 164.8667, 26.55, 19.2583, 7.2292, 14.1083, 11.5, 25.9292, 69.55, 13.0, 13.0, 13.8583, 50.4958, 9.5, 11.1333, 7.8958, 52.5542, 5.0, 9.0, 24.0, 7.225, 9.8458, 7.8958, 7.8958, 83.1583, 26.0, 7.8958, 10.5167, 10.5, 7.05, 29.125, 13.0, 30.0, 23.45, 30.0, 7.75, 7.8292, 7.0, 9.6875, 8.6625, 12.2875, 9.225, 7.6292, 29.0, 7.2292, 24.15, 7.8958, 26.0, 82.2667, 26.0, 61.175, 27.7208, 12.35, 7.225, 7.925, 7.225, 59.4, 3.1708, 31.6833, 61.3792, 262.375, 14.5, 61.9792, 7.225, 30.5, 21.6792, 26.0, 31.5, 20.575, 23.45, 57.75, 7.2292, 8.05, 8.6625, 9.5, 56.4958, 13.4167, 26.55, 7.85, 13.0, 52.5542, 7.925, 29.7, 7.75, 76.2917, 15.9, 60.0, 15.0333, 23.0, 263.0, 15.5792, 29.125, 7.8958, 7.65, 16.1, 262.375, 7.8958, 13.5, 7.75, 7.725, 262.375, 21.0, 7.8792, 42.4, 28.5375, 263.0, 7.75, 7.8958, 7.925, 27.7208, 211.5, 211.5, 8.05, 25.7, 13.0, 7.75, 15.2458, 221.7792, 26.0, 7.8958, 10.7083, 14.4542, 7.8792, 8.05, 7.75, 23.0, 13.9, 7.775, 52.0, 8.05, 26.0, 7.7958, 78.85, 7.925, 7.8542, 8.05, 55.4417, 26.0, 7.75, 7.775, 8.5167, 22.525, 7.8208, 7.75, 8.7125, 13.0, 15.0458, 7.7792, 31.6792, 7.2833, 221.7792, 14.4542, 6.4375, 16.7, 75.2417, 26.0, 15.75, 7.75, 57.75, 7.25, 7.75, 16.1, 7.7958, 23.25, 13.0, 8.05, 8.05, 28.5, 25.4667, 6.4375, 7.8958, 7.8542, 7.225, 13.0, 8.05, 46.9, 46.9, 151.55, 262.375, 26.0, 26.55, 18.0, 51.8625, 8.05, 26.55, 26.0, 83.1583, 7.8958, null, 12.1833, 31.3875, 7.55, 221.7792, 7.8542, 26.55, 13.775, 7.7333, 15.2458, 13.5, 7.0, 13.0, 22.025, 50.4958, 34.375, 27.7208, 8.9625, 7.55, 7.225, 13.9, 7.2292, 31.3875, 39.0, 36.75, 55.4417, 39.0, 83.1583, 13.0, 83.1583, 53.1, 7.75, 247.5208, 16.0, 21.0, 8.05, 69.55, 13.0, 26.0, 26.0, 14.5, 12.35, 32.5, 7.8542, 134.5, 7.775, 10.5, 8.1125, 15.5, 14.4, 227.525, 26.0, 10.5, 25.7417, 7.75, 10.5, 27.7208, 7.8958, 22.525, 7.05, 73.5, 26.0, 7.775, 42.5, 7.8792, 164.8667, 211.5, 8.05, 13.8583, 8.05, 10.5, 7.7958, 27.4458, 15.2458, 7.7958, 7.75, 15.1, 13.0, 65.0, 26.55, 6.4958, 7.8792, 71.2833, 7.8542, 75.25, 7.225, 13.0, 106.425, 27.7208, 30.0, 134.5, 7.8875, 23.45, 51.8625, 21.0, 32.5, 26.0, 14.4542, 27.75, 7.925, 136.7792, 9.325, 9.5, 7.55, 7.75, 8.05, 13.0, 7.775, 17.4, 7.8542, 23.0, 12.1833, 12.7375, 7.8958, 0.0, 7.55, 8.05, 8.6625, 75.2417, 7.75, 136.7792, 15.5, 7.225, 26.0, 10.5, 26.0, 21.0, 10.5, 8.6625, 13.775, 7.75, 15.2458, 20.2125, 7.25, 7.25, 82.2667, 7.2292, 8.05, 39.6, 6.95, 7.2292, 81.8583, 9.5, 7.8958, 41.5792, 21.6792, 45.5, 7.8542, 7.775, 15.0458, 21.0, 8.6625, 7.75, 26.55, 151.55, 9.35, 93.5, 14.1083, 8.6625, 7.225, 7.575, 7.75, 135.6333, 7.7333, 146.5208, 10.5, 7.8542, 31.5, 7.775, 7.2292, 13.0, 26.55, 211.3375, 7.05, 39.0, 79.2, 26.0, 13.0, 36.75, 29.7, 7.225, 15.7417, 7.8958, 26.0, 13.0, 7.2292, 31.5, 7.2292, 10.5, 7.5792, 69.55, 512.3292, 14.5, 7.65, 13.0, 7.2292, 13.5, 21.0, 63.3583, 10.5, 73.5, 65.0, 20.575, 26.0, 51.4792, 7.8792, 7.75, 15.55, 69.55, 37.0042, 21.0, 8.6625, 55.4417, 69.55, 14.4583, 39.6875, 59.4, 13.8583, 11.5, 134.5, 0.0, 13.0, 81.8583, 262.375, 8.6625, 11.5, 50.0, 31.3875, 7.75, 7.8792, 14.5, 16.1, 12.875, 65.0, 7.775, 13.0, 7.75, 21.075, 93.5, 39.4, 20.25, 10.5, 22.025, 60.0, 7.25, 79.2, 7.775, 7.7333, 164.8667, 21.0, 59.4, 47.1, 27.7208, 13.8625, 10.5, 211.5, 7.7208, 13.775, 7.75, 90.0, 7.775, 8.05, 108.9, 7.25, 8.05, 22.3583], \"xaxis\": \"x2\", \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Distribution of Fare with Histogram\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Distribution of Fare with Density Plot\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.375, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 800, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"width\": 870, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Fare</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.625, 1.0], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.375], \"title\": {\"text\": \"<b>Density(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('8518e726-d9ab-44c6-b352-8ce7646400aa');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 40,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 21,
                "o_idx": 0
            }
        },
        {
            "source": "**Reading the histogram, it's clear that Fare's distribution has a high positive skewness. And it seems a number of passengers (653) paid for fare between 5 to 15 (less than 15), followed by 25 to 35 (less than 35).**\n\nThere is also another, often clearer, way to grasp the distribution: density plots or, more formally, Kernel Density Plots. They can be considered a smoothed version of the histogram. One advantage of density plot over histogram is that its shape of distribution isn't affected by the number of bins used.",
            "mc_idx": 41,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Calculate summary statistics of Fare.\"\"\"\nbold(\"Summary Stats of Fare:\")\ncalculateSummaryStats(merged.Fare)",
            "mc_idx": 42,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "summary statistics": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "summary": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    22,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "  summaryStats     Fare\n0     skewness     4.37\n1        count  1308.00\n2         mean    33.30\n3          std    51.76\n4          min     0.00\n5          25%     7.90\n6          50%    14.45\n7          75%    31.28\n8          max   512.33"
                    ]
                },
                "mc_idx": 42,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 22,
                "o_idx": 1
            }
        },
        {
            "source": "**So what does the  value of skewness suggest?**\n1. If skewness is less than \u22121 or greater than +1, the distribution can be considered as highly skewed.\n2. If skewness is between \u22121 and \u2212\u00bd or between +\u00bd and +1, the distribution can be considered as moderately skewed.\n3. And finally if skewness is between \u2212\u00bd and +\u00bd, the distribution can be considered as approximately symmetric.    \n\n**Findings:** Density plot shows the mass of the distribution of Fare is heavily concentrated on the left of the figure due to very long tail on the right side. So it can be said that Fare is substantially skewed(positively) that is also supported by the calculated positive value of skewness of 4.37\n\n### 4.2.2 Age <a id=\"4.2.2\"></a>",
            "mc_idx": 43,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Plot histogram and density plot of Age.\"\"\"\nplotHistogram(merged.Age)",
            "mc_idx": 44,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    23,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"8d123699-c737-4034-a8f5-b695b74cdb50\" class=\"plotly-graph-div\" style=\"height:800px; width:870px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"8d123699-c737-4034-a8f5-b695b74cdb50\")) {\n                    Plotly.newPlot(\n                        '8d123699-c737-4034-a8f5-b695b74cdb50',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": \"chocolate\"}, \"type\": \"histogram\", \"uid\": \"b2f79078-5841-4c15-9ba0-b8b19ae8c4fc\", \"x\": [22.0, 38.0, 26.0, 35.0, 35.0, null, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, null, 31.0, null, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, null, 19.0, null, null, 40.0, null, null, 66.0, 28.0, 42.0, null, 21.0, 18.0, 14.0, 40.0, 27.0, null, 3.0, 19.0, null, null, null, null, 18.0, 7.0, 21.0, 49.0, 29.0, 65.0, null, 21.0, 28.5, 5.0, 11.0, 22.0, 38.0, 45.0, 4.0, null, null, 29.0, 19.0, 17.0, 26.0, 32.0, 16.0, 21.0, 26.0, 32.0, 25.0, null, null, 0.83, 30.0, 22.0, 29.0, null, 28.0, 17.0, 33.0, 16.0, null, 23.0, 24.0, 29.0, 20.0, 46.0, 26.0, 59.0, null, 71.0, 23.0, 34.0, 34.0, 28.0, null, 21.0, 33.0, 37.0, 28.0, 21.0, null, 38.0, null, 47.0, 14.5, 22.0, 20.0, 17.0, 21.0, 70.5, 29.0, 24.0, 2.0, 21.0, null, 32.5, 32.5, 54.0, 12.0, null, 24.0, null, 45.0, 33.0, 20.0, 47.0, 29.0, 25.0, 23.0, 19.0, 37.0, 16.0, 24.0, null, 22.0, 24.0, 19.0, 18.0, 19.0, 27.0, 9.0, 36.5, 42.0, 51.0, 22.0, 55.5, 40.5, null, 51.0, 16.0, 30.0, null, null, 44.0, 40.0, 26.0, 17.0, 1.0, 9.0, null, 45.0, null, 28.0, 61.0, 4.0, 1.0, 21.0, 56.0, 18.0, null, 50.0, 30.0, 36.0, null, null, 9.0, 1.0, 4.0, null, null, 45.0, 40.0, 36.0, 32.0, 19.0, 19.0, 3.0, 44.0, 58.0, null, 42.0, null, 24.0, 28.0, null, 34.0, 45.5, 18.0, 2.0, 32.0, 26.0, 16.0, 40.0, 24.0, 35.0, 22.0, 30.0, null, 31.0, 27.0, 42.0, 32.0, 30.0, 16.0, 27.0, 51.0, null, 38.0, 22.0, 19.0, 20.5, 18.0, null, 35.0, 29.0, 59.0, 5.0, 24.0, null, 44.0, 8.0, 19.0, 33.0, null, null, 29.0, 22.0, 30.0, 44.0, 25.0, 24.0, 37.0, 54.0, null, 29.0, 62.0, 30.0, 41.0, 29.0, null, 30.0, 35.0, 50.0, null, 3.0, 52.0, 40.0, null, 36.0, 16.0, 25.0, 58.0, 35.0, null, 25.0, 41.0, 37.0, null, 63.0, 45.0, null, 7.0, 35.0, 65.0, 28.0, 16.0, 19.0, null, 33.0, 30.0, 22.0, 42.0, 22.0, 26.0, 19.0, 36.0, 24.0, 24.0, null, 23.5, 2.0, null, 50.0, null, null, 19.0, null, null, 0.92, null, 17.0, 30.0, 30.0, 24.0, 18.0, 26.0, 28.0, 43.0, 26.0, 24.0, 54.0, 31.0, 40.0, 22.0, 27.0, 30.0, 22.0, null, 36.0, 61.0, 36.0, 31.0, 16.0, null, 45.5, 38.0, 16.0, null, null, 29.0, 41.0, 45.0, 45.0, 2.0, 24.0, 28.0, 25.0, 36.0, 24.0, 40.0, null, 3.0, 42.0, 23.0, null, 15.0, 25.0, null, 28.0, 22.0, 38.0, null, null, 40.0, 29.0, 45.0, 35.0, null, 30.0, 60.0, null, null, 24.0, 25.0, 18.0, 19.0, 22.0, 3.0, null, 22.0, 27.0, 20.0, 19.0, 42.0, 1.0, 32.0, 35.0, null, 18.0, 1.0, 36.0, null, 17.0, 36.0, 21.0, 28.0, 23.0, 24.0, 22.0, 31.0, 46.0, 23.0, 28.0, 39.0, 26.0, 21.0, 28.0, 20.0, 34.0, 51.0, 3.0, 21.0, null, null, null, 33.0, null, 44.0, null, 34.0, 18.0, 30.0, 10.0, null, 21.0, 29.0, 28.0, 18.0, null, 28.0, 19.0, null, 32.0, 28.0, null, 42.0, 17.0, 50.0, 14.0, 21.0, 24.0, 64.0, 31.0, 45.0, 20.0, 25.0, 28.0, null, 4.0, 13.0, 34.0, 5.0, 52.0, 36.0, null, 30.0, 49.0, null, 29.0, 65.0, null, 50.0, null, 48.0, 34.0, 47.0, 48.0, null, 38.0, null, 56.0, null, 0.75, null, 38.0, 33.0, 23.0, 22.0, null, 34.0, 29.0, 22.0, 2.0, 9.0, null, 50.0, 63.0, 25.0, null, 35.0, 58.0, 30.0, 9.0, null, 21.0, 55.0, 71.0, 21.0, null, 54.0, null, 25.0, 24.0, 17.0, 21.0, null, 37.0, 16.0, 18.0, 33.0, null, 28.0, 26.0, 29.0, null, 36.0, 54.0, 24.0, 47.0, 34.0, null, 36.0, 32.0, 30.0, 22.0, null, 44.0, null, 40.5, 50.0, null, 39.0, 23.0, 2.0, null, 17.0, null, 30.0, 7.0, 45.0, 30.0, null, 22.0, 36.0, 9.0, 11.0, 32.0, 50.0, 64.0, 19.0, null, 33.0, 8.0, 17.0, 27.0, null, 22.0, 22.0, 62.0, 48.0, null, 39.0, 36.0, null, 40.0, 28.0, null, null, 24.0, 19.0, 29.0, null, 32.0, 62.0, 53.0, 36.0, null, 16.0, 19.0, 34.0, 39.0, null, 32.0, 25.0, 39.0, 54.0, 36.0, null, 18.0, 47.0, 60.0, 22.0, null, 35.0, 52.0, 47.0, null, 37.0, 36.0, null, 49.0, null, 49.0, 24.0, null, null, 44.0, 35.0, 36.0, 30.0, 27.0, 22.0, 40.0, 39.0, null, null, null, 35.0, 24.0, 34.0, 26.0, 4.0, 26.0, 27.0, 42.0, 20.0, 21.0, 21.0, 61.0, 57.0, 21.0, 26.0, null, 80.0, 51.0, 32.0, null, 9.0, 28.0, 32.0, 31.0, 41.0, null, 20.0, 24.0, 2.0, null, 0.75, 48.0, 19.0, 56.0, null, 23.0, null, 18.0, 21.0, null, 18.0, 24.0, null, 32.0, 23.0, 58.0, 50.0, 40.0, 47.0, 36.0, 20.0, 32.0, 25.0, null, 43.0, null, 40.0, 31.0, 70.0, 31.0, null, 18.0, 24.5, 18.0, 43.0, 36.0, null, 27.0, 20.0, 14.0, 60.0, 25.0, 14.0, 19.0, 18.0, 15.0, 31.0, 4.0, null, 25.0, 60.0, 52.0, 44.0, null, 49.0, 42.0, 18.0, 35.0, 18.0, 25.0, 26.0, 39.0, 45.0, 42.0, 22.0, null, 24.0, null, 48.0, 29.0, 52.0, 19.0, 38.0, 27.0, null, 33.0, 6.0, 17.0, 34.0, 50.0, 27.0, 20.0, 30.0, null, 25.0, 25.0, 29.0, 11.0, null, 23.0, 23.0, 28.5, 48.0, 35.0, null, null, null, 36.0, 21.0, 24.0, 31.0, 70.0, 16.0, 30.0, 19.0, 31.0, 4.0, 6.0, 33.0, 23.0, 48.0, 0.67, 28.0, 18.0, 34.0, 33.0, null, 41.0, 20.0, 36.0, 16.0, 51.0, null, 30.5, null, 32.0, 24.0, 48.0, 57.0, null, 54.0, 18.0, null, 5.0, null, 43.0, 13.0, 17.0, 29.0, null, 25.0, 25.0, 18.0, 8.0, 1.0, 46.0, null, 16.0, null, null, 25.0, 39.0, 49.0, 31.0, 30.0, 30.0, 34.0, 31.0, 11.0, 0.42, 27.0, 31.0, 39.0, 18.0, 39.0, 33.0, 26.0, 39.0, 35.0, 6.0, 30.5, null, 23.0, 31.0, 43.0, 10.0, 52.0, 27.0, 38.0, 27.0, 2.0, null, null, 1.0, null, 62.0, 15.0, 0.83, null, 23.0, 18.0, 39.0, 21.0, null, 32.0, null, 20.0, 16.0, 30.0, 34.5, 17.0, 42.0, null, 35.0, 28.0, null, 4.0, 74.0, 9.0, 16.0, 44.0, 18.0, 45.0, 51.0, 24.0, null, 41.0, 21.0, 48.0, null, 24.0, 42.0, 27.0, 31.0, null, 4.0, 26.0, 47.0, 33.0, 47.0, 28.0, 15.0, 20.0, 19.0, null, 56.0, 25.0, 33.0, 22.0, 28.0, 25.0, 39.0, 27.0, 19.0, null, 26.0, 32.0, 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0, null, 46.0, 23.0, 63.0, 47.0, 24.0, 35.0, 21.0, 27.0, 45.0, 55.0, 9.0, null, 21.0, 48.0, 50.0, 22.0, 22.5, 41.0, null, 50.0, 24.0, 33.0, null, 30.0, 18.5, null, 21.0, 25.0, null, 39.0, null, 41.0, 30.0, 45.0, 25.0, 45.0, null, 60.0, 36.0, 24.0, 27.0, 20.0, 28.0, null, 10.0, 35.0, 25.0, null, 36.0, 17.0, 32.0, 18.0, 22.0, 13.0, null, 18.0, 47.0, 31.0, 60.0, 24.0, 21.0, 29.0, 28.5, 35.0, 32.5, null, 55.0, 30.0, 24.0, 6.0, 67.0, 49.0, null, null, null, 27.0, 18.0, null, 2.0, 22.0, null, 27.0, null, 25.0, 25.0, 76.0, 29.0, 20.0, 33.0, 43.0, 27.0, null, 26.0, 16.0, 28.0, 21.0, null, null, 18.5, 41.0, null, 36.0, 18.5, 63.0, 18.0, null, 1.0, 36.0, 29.0, 12.0, null, 35.0, 28.0, null, 17.0, 22.0, null, 42.0, 24.0, 32.0, 53.0, null, null, 43.0, 24.0, 26.5, 26.0, 23.0, 40.0, 10.0, 33.0, 61.0, 28.0, 42.0, 31.0, null, 22.0, null, 30.0, 23.0, null, 60.5, 36.0, 13.0, 24.0, 29.0, 23.0, 42.0, 26.0, null, 7.0, 26.0, null, 41.0, 26.0, 48.0, 18.0, null, 22.0, null, 27.0, 23.0, null, 40.0, 15.0, 20.0, 54.0, 36.0, 64.0, 30.0, 37.0, 18.0, null, 27.0, 40.0, 21.0, 17.0, null, 40.0, 34.0, null, 11.5, 61.0, 8.0, 33.0, 6.0, 18.0, 23.0, null, null, 0.33, 47.0, 8.0, 25.0, null, 35.0, 24.0, 33.0, 25.0, 32.0, null, 17.0, 60.0, 38.0, 42.0, null, 57.0, 50.0, null, 30.0, 21.0, 22.0, 21.0, 53.0, null, 23.0, null, 40.5, 36.0, 14.0, 21.0, 21.0, null, 39.0, 20.0, 64.0, 20.0, 18.0, 48.0, 55.0, 45.0, 45.0, null, null, 41.0, 22.0, 42.0, 29.0, null, 0.92, 20.0, 27.0, 24.0, 32.5, null, null, 28.0, 19.0, 21.0, 36.5, 21.0, 29.0, 1.0, 30.0, null, null, null, null, 17.0, 46.0, null, 26.0, null, null, 20.0, 28.0, 40.0, 30.0, 22.0, 23.0, 0.75, null, 9.0, 2.0, 36.0, null, 24.0, null, null, null, 30.0, null, 53.0, 36.0, 26.0, 1.0, null, 30.0, 29.0, 32.0, null, 43.0, 24.0, null, 64.0, 30.0, 0.83, 55.0, 45.0, 18.0, 22.0, null, 37.0, 55.0, 17.0, 57.0, 19.0, 27.0, 22.0, 26.0, 25.0, 26.0, 33.0, 39.0, 23.0, 12.0, 46.0, 29.0, 21.0, 48.0, 39.0, null, 19.0, 27.0, 30.0, 32.0, 39.0, 25.0, null, 18.0, 32.0, null, 58.0, null, 16.0, 26.0, 38.0, 24.0, 31.0, 45.0, 25.0, 18.0, 49.0, 0.17, 50.0, 59.0, null, null, 30.0, 14.5, 24.0, 31.0, 27.0, 25.0, null, null, 22.0, 45.0, 29.0, 21.0, 31.0, 49.0, 44.0, 54.0, 45.0, 22.0, 21.0, 55.0, 5.0, null, 26.0, null, 19.0, null, 24.0, 24.0, 57.0, 21.0, 6.0, 23.0, 51.0, 13.0, 47.0, 29.0, 18.0, 24.0, 48.0, 22.0, 31.0, 30.0, 38.0, 22.0, 17.0, 43.0, 20.0, 23.0, 50.0, null, 3.0, null, 37.0, 28.0, null, 39.0, 38.5, null, null], \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"histnorm\": \"density\", \"hoverinfo\": \"x+y\", \"marker\": {\"color\": \"darkred\"}, \"type\": \"histogram\", \"uid\": \"a4c8b87f-9746-4b1f-aa25-419100a5d2f0\", \"x\": [22.0, 38.0, 26.0, 35.0, 35.0, null, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, null, 31.0, null, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, null, 19.0, null, null, 40.0, null, null, 66.0, 28.0, 42.0, null, 21.0, 18.0, 14.0, 40.0, 27.0, null, 3.0, 19.0, null, null, null, null, 18.0, 7.0, 21.0, 49.0, 29.0, 65.0, null, 21.0, 28.5, 5.0, 11.0, 22.0, 38.0, 45.0, 4.0, null, null, 29.0, 19.0, 17.0, 26.0, 32.0, 16.0, 21.0, 26.0, 32.0, 25.0, null, null, 0.83, 30.0, 22.0, 29.0, null, 28.0, 17.0, 33.0, 16.0, null, 23.0, 24.0, 29.0, 20.0, 46.0, 26.0, 59.0, null, 71.0, 23.0, 34.0, 34.0, 28.0, null, 21.0, 33.0, 37.0, 28.0, 21.0, null, 38.0, null, 47.0, 14.5, 22.0, 20.0, 17.0, 21.0, 70.5, 29.0, 24.0, 2.0, 21.0, null, 32.5, 32.5, 54.0, 12.0, null, 24.0, null, 45.0, 33.0, 20.0, 47.0, 29.0, 25.0, 23.0, 19.0, 37.0, 16.0, 24.0, null, 22.0, 24.0, 19.0, 18.0, 19.0, 27.0, 9.0, 36.5, 42.0, 51.0, 22.0, 55.5, 40.5, null, 51.0, 16.0, 30.0, null, null, 44.0, 40.0, 26.0, 17.0, 1.0, 9.0, null, 45.0, null, 28.0, 61.0, 4.0, 1.0, 21.0, 56.0, 18.0, null, 50.0, 30.0, 36.0, null, null, 9.0, 1.0, 4.0, null, null, 45.0, 40.0, 36.0, 32.0, 19.0, 19.0, 3.0, 44.0, 58.0, null, 42.0, null, 24.0, 28.0, null, 34.0, 45.5, 18.0, 2.0, 32.0, 26.0, 16.0, 40.0, 24.0, 35.0, 22.0, 30.0, null, 31.0, 27.0, 42.0, 32.0, 30.0, 16.0, 27.0, 51.0, null, 38.0, 22.0, 19.0, 20.5, 18.0, null, 35.0, 29.0, 59.0, 5.0, 24.0, null, 44.0, 8.0, 19.0, 33.0, null, null, 29.0, 22.0, 30.0, 44.0, 25.0, 24.0, 37.0, 54.0, null, 29.0, 62.0, 30.0, 41.0, 29.0, null, 30.0, 35.0, 50.0, null, 3.0, 52.0, 40.0, null, 36.0, 16.0, 25.0, 58.0, 35.0, null, 25.0, 41.0, 37.0, null, 63.0, 45.0, null, 7.0, 35.0, 65.0, 28.0, 16.0, 19.0, null, 33.0, 30.0, 22.0, 42.0, 22.0, 26.0, 19.0, 36.0, 24.0, 24.0, null, 23.5, 2.0, null, 50.0, null, null, 19.0, null, null, 0.92, null, 17.0, 30.0, 30.0, 24.0, 18.0, 26.0, 28.0, 43.0, 26.0, 24.0, 54.0, 31.0, 40.0, 22.0, 27.0, 30.0, 22.0, null, 36.0, 61.0, 36.0, 31.0, 16.0, null, 45.5, 38.0, 16.0, null, null, 29.0, 41.0, 45.0, 45.0, 2.0, 24.0, 28.0, 25.0, 36.0, 24.0, 40.0, null, 3.0, 42.0, 23.0, null, 15.0, 25.0, null, 28.0, 22.0, 38.0, null, null, 40.0, 29.0, 45.0, 35.0, null, 30.0, 60.0, null, null, 24.0, 25.0, 18.0, 19.0, 22.0, 3.0, null, 22.0, 27.0, 20.0, 19.0, 42.0, 1.0, 32.0, 35.0, null, 18.0, 1.0, 36.0, null, 17.0, 36.0, 21.0, 28.0, 23.0, 24.0, 22.0, 31.0, 46.0, 23.0, 28.0, 39.0, 26.0, 21.0, 28.0, 20.0, 34.0, 51.0, 3.0, 21.0, null, null, null, 33.0, null, 44.0, null, 34.0, 18.0, 30.0, 10.0, null, 21.0, 29.0, 28.0, 18.0, null, 28.0, 19.0, null, 32.0, 28.0, null, 42.0, 17.0, 50.0, 14.0, 21.0, 24.0, 64.0, 31.0, 45.0, 20.0, 25.0, 28.0, null, 4.0, 13.0, 34.0, 5.0, 52.0, 36.0, null, 30.0, 49.0, null, 29.0, 65.0, null, 50.0, null, 48.0, 34.0, 47.0, 48.0, null, 38.0, null, 56.0, null, 0.75, null, 38.0, 33.0, 23.0, 22.0, null, 34.0, 29.0, 22.0, 2.0, 9.0, null, 50.0, 63.0, 25.0, null, 35.0, 58.0, 30.0, 9.0, null, 21.0, 55.0, 71.0, 21.0, null, 54.0, null, 25.0, 24.0, 17.0, 21.0, null, 37.0, 16.0, 18.0, 33.0, null, 28.0, 26.0, 29.0, null, 36.0, 54.0, 24.0, 47.0, 34.0, null, 36.0, 32.0, 30.0, 22.0, null, 44.0, null, 40.5, 50.0, null, 39.0, 23.0, 2.0, null, 17.0, null, 30.0, 7.0, 45.0, 30.0, null, 22.0, 36.0, 9.0, 11.0, 32.0, 50.0, 64.0, 19.0, null, 33.0, 8.0, 17.0, 27.0, null, 22.0, 22.0, 62.0, 48.0, null, 39.0, 36.0, null, 40.0, 28.0, null, null, 24.0, 19.0, 29.0, null, 32.0, 62.0, 53.0, 36.0, null, 16.0, 19.0, 34.0, 39.0, null, 32.0, 25.0, 39.0, 54.0, 36.0, null, 18.0, 47.0, 60.0, 22.0, null, 35.0, 52.0, 47.0, null, 37.0, 36.0, null, 49.0, null, 49.0, 24.0, null, null, 44.0, 35.0, 36.0, 30.0, 27.0, 22.0, 40.0, 39.0, null, null, null, 35.0, 24.0, 34.0, 26.0, 4.0, 26.0, 27.0, 42.0, 20.0, 21.0, 21.0, 61.0, 57.0, 21.0, 26.0, null, 80.0, 51.0, 32.0, null, 9.0, 28.0, 32.0, 31.0, 41.0, null, 20.0, 24.0, 2.0, null, 0.75, 48.0, 19.0, 56.0, null, 23.0, null, 18.0, 21.0, null, 18.0, 24.0, null, 32.0, 23.0, 58.0, 50.0, 40.0, 47.0, 36.0, 20.0, 32.0, 25.0, null, 43.0, null, 40.0, 31.0, 70.0, 31.0, null, 18.0, 24.5, 18.0, 43.0, 36.0, null, 27.0, 20.0, 14.0, 60.0, 25.0, 14.0, 19.0, 18.0, 15.0, 31.0, 4.0, null, 25.0, 60.0, 52.0, 44.0, null, 49.0, 42.0, 18.0, 35.0, 18.0, 25.0, 26.0, 39.0, 45.0, 42.0, 22.0, null, 24.0, null, 48.0, 29.0, 52.0, 19.0, 38.0, 27.0, null, 33.0, 6.0, 17.0, 34.0, 50.0, 27.0, 20.0, 30.0, null, 25.0, 25.0, 29.0, 11.0, null, 23.0, 23.0, 28.5, 48.0, 35.0, null, null, null, 36.0, 21.0, 24.0, 31.0, 70.0, 16.0, 30.0, 19.0, 31.0, 4.0, 6.0, 33.0, 23.0, 48.0, 0.67, 28.0, 18.0, 34.0, 33.0, null, 41.0, 20.0, 36.0, 16.0, 51.0, null, 30.5, null, 32.0, 24.0, 48.0, 57.0, null, 54.0, 18.0, null, 5.0, null, 43.0, 13.0, 17.0, 29.0, null, 25.0, 25.0, 18.0, 8.0, 1.0, 46.0, null, 16.0, null, null, 25.0, 39.0, 49.0, 31.0, 30.0, 30.0, 34.0, 31.0, 11.0, 0.42, 27.0, 31.0, 39.0, 18.0, 39.0, 33.0, 26.0, 39.0, 35.0, 6.0, 30.5, null, 23.0, 31.0, 43.0, 10.0, 52.0, 27.0, 38.0, 27.0, 2.0, null, null, 1.0, null, 62.0, 15.0, 0.83, null, 23.0, 18.0, 39.0, 21.0, null, 32.0, null, 20.0, 16.0, 30.0, 34.5, 17.0, 42.0, null, 35.0, 28.0, null, 4.0, 74.0, 9.0, 16.0, 44.0, 18.0, 45.0, 51.0, 24.0, null, 41.0, 21.0, 48.0, null, 24.0, 42.0, 27.0, 31.0, null, 4.0, 26.0, 47.0, 33.0, 47.0, 28.0, 15.0, 20.0, 19.0, null, 56.0, 25.0, 33.0, 22.0, 28.0, 25.0, 39.0, 27.0, 19.0, null, 26.0, 32.0, 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0, null, 46.0, 23.0, 63.0, 47.0, 24.0, 35.0, 21.0, 27.0, 45.0, 55.0, 9.0, null, 21.0, 48.0, 50.0, 22.0, 22.5, 41.0, null, 50.0, 24.0, 33.0, null, 30.0, 18.5, null, 21.0, 25.0, null, 39.0, null, 41.0, 30.0, 45.0, 25.0, 45.0, null, 60.0, 36.0, 24.0, 27.0, 20.0, 28.0, null, 10.0, 35.0, 25.0, null, 36.0, 17.0, 32.0, 18.0, 22.0, 13.0, null, 18.0, 47.0, 31.0, 60.0, 24.0, 21.0, 29.0, 28.5, 35.0, 32.5, null, 55.0, 30.0, 24.0, 6.0, 67.0, 49.0, null, null, null, 27.0, 18.0, null, 2.0, 22.0, null, 27.0, null, 25.0, 25.0, 76.0, 29.0, 20.0, 33.0, 43.0, 27.0, null, 26.0, 16.0, 28.0, 21.0, null, null, 18.5, 41.0, null, 36.0, 18.5, 63.0, 18.0, null, 1.0, 36.0, 29.0, 12.0, null, 35.0, 28.0, null, 17.0, 22.0, null, 42.0, 24.0, 32.0, 53.0, null, null, 43.0, 24.0, 26.5, 26.0, 23.0, 40.0, 10.0, 33.0, 61.0, 28.0, 42.0, 31.0, null, 22.0, null, 30.0, 23.0, null, 60.5, 36.0, 13.0, 24.0, 29.0, 23.0, 42.0, 26.0, null, 7.0, 26.0, null, 41.0, 26.0, 48.0, 18.0, null, 22.0, null, 27.0, 23.0, null, 40.0, 15.0, 20.0, 54.0, 36.0, 64.0, 30.0, 37.0, 18.0, null, 27.0, 40.0, 21.0, 17.0, null, 40.0, 34.0, null, 11.5, 61.0, 8.0, 33.0, 6.0, 18.0, 23.0, null, null, 0.33, 47.0, 8.0, 25.0, null, 35.0, 24.0, 33.0, 25.0, 32.0, null, 17.0, 60.0, 38.0, 42.0, null, 57.0, 50.0, null, 30.0, 21.0, 22.0, 21.0, 53.0, null, 23.0, null, 40.5, 36.0, 14.0, 21.0, 21.0, null, 39.0, 20.0, 64.0, 20.0, 18.0, 48.0, 55.0, 45.0, 45.0, null, null, 41.0, 22.0, 42.0, 29.0, null, 0.92, 20.0, 27.0, 24.0, 32.5, null, null, 28.0, 19.0, 21.0, 36.5, 21.0, 29.0, 1.0, 30.0, null, null, null, null, 17.0, 46.0, null, 26.0, null, null, 20.0, 28.0, 40.0, 30.0, 22.0, 23.0, 0.75, null, 9.0, 2.0, 36.0, null, 24.0, null, null, null, 30.0, null, 53.0, 36.0, 26.0, 1.0, null, 30.0, 29.0, 32.0, null, 43.0, 24.0, null, 64.0, 30.0, 0.83, 55.0, 45.0, 18.0, 22.0, null, 37.0, 55.0, 17.0, 57.0, 19.0, 27.0, 22.0, 26.0, 25.0, 26.0, 33.0, 39.0, 23.0, 12.0, 46.0, 29.0, 21.0, 48.0, 39.0, null, 19.0, 27.0, 30.0, 32.0, 39.0, 25.0, null, 18.0, 32.0, null, 58.0, null, 16.0, 26.0, 38.0, 24.0, 31.0, 45.0, 25.0, 18.0, 49.0, 0.17, 50.0, 59.0, null, null, 30.0, 14.5, 24.0, 31.0, 27.0, 25.0, null, null, 22.0, 45.0, 29.0, 21.0, 31.0, 49.0, 44.0, 54.0, 45.0, 22.0, 21.0, 55.0, 5.0, null, 26.0, null, 19.0, null, 24.0, 24.0, 57.0, 21.0, 6.0, 23.0, 51.0, 13.0, 47.0, 29.0, 18.0, 24.0, 48.0, 22.0, 31.0, 30.0, 38.0, 22.0, 17.0, 43.0, 20.0, 23.0, 50.0, null, 3.0, null, 37.0, 28.0, null, 39.0, 38.5, null, null], \"xaxis\": \"x2\", \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Distribution of Age with Histogram\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Distribution of Age with Density Plot\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.375, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 800, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"width\": 870, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Age</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.625, 1.0], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.375], \"title\": {\"text\": \"<b>Density(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('8d123699-c737-4034-a8f5-b695b74cdb50');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 44,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 23,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Calculate summary stats for Age\"\"\"\ncalculateSummaryStats(merged.Age)",
            "mc_idx": 45,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "summary": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    24,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "  summaryStats      Age\n0     skewness     0.41\n1        count  1046.00\n2         mean    29.88\n3          std    14.41\n4          min     0.17\n5          25%    21.00\n6          50%    28.00\n7          75%    39.00\n8          max    80.00"
                    ]
                },
                "mc_idx": 45,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 24,
                "o_idx": 0
            }
        },
        {
            "source": "**At first glance, Age seems to be positively skewed (slightly). 344 passengers' age is between 20 to 30(less than 30). And passengers between age 70 to 80(including 80) was 8 were the least.**",
            "mc_idx": 46,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** What we can see from the density plot is that the mass of the distribution of Age is slightly concentrated on the left of the figure due to comparatively long tail on the right side. So it can be said that Age is almost normally distributed since the tail on the both sides are almost equal and it has a small value of positive skewness of 0.41 (in between -0.5 to 0.5). So it can be said that Age is almost normally distributed.\n\n### 4.2.3 PassengerId <a id=\"4.2.3\"></a>",
            "mc_idx": 47,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"What does passengerId contain?\"\"\"\ndisplay(merged.PassengerId.head())",
            "mc_idx": 48,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    25,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0    1\n1    2\n2    3\n3    4\n4    5\nName: PassengerId, dtype: int64"
                    ]
                },
                "mc_idx": 48,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 25,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** PassengersId is an unique identity number (positive integer) assigned to each passenger.\n\n# 5.Feature Engineering <a id=\"5\"></a>\nIn this section, we would either modify or create new features from the exsisting features which are otherwise hard to analyse in their raw forms that we saw in Univariate Analysis section. We would engineer features like Cabin, Name, SibSp & Parch, and Ticket that could tell us something about survival or death once they're processed.\n\n## 5.1 Process Cabin <a id=\"5.1\"></a>",
            "mc_idx": 49,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Let's preview the Cabin again.\"\"\"\nbold(\"Preview of Cabin:\")\ndisplay(merged.Cabin.head())",
            "mc_idx": 50,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    26,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "0     NaN\n1     C85\n2     NaN\n3    C123\n4     NaN\nName: Cabin, dtype: object"
                    ]
                },
                "mc_idx": 50,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 26,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"It seems Cabin contains some missing values. Let's count them.\"\"\"\nbold(\"Missing Values in Cabin:\")\ndisplay(merged.Cabin.isna().sum())",
            "mc_idx": 51,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "missing values": 2,
                    ".isna": 1,
                    ".sum": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    27,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "1014"
                    ]
                },
                "mc_idx": 51,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 27,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Total categories in Cabin before processing.\"\"\"\nbold(\"Total Categories in Cabin before Processing:\")\ndisplay(merged.Cabin.value_counts(dropna=False).count())",
            "mc_idx": 52,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    28,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "187"
                    ]
                },
                "mc_idx": 52,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 28,
                "o_idx": 1
            }
        },
        {
            "source": "Looks like Cabin is alphanumeric type variable with no special characters (like ., /, % etc) between letters and numbers. It has also 1014 missing obsevations. It is reasonable to presume that those NaNs didn't have a cabin, which could tell us something about 'Survived'. We will flag NaN as 'X' and keep only the 1st character where Cabin has alphanumeric values. Since its a categorical variable, we must reduce the number of categories for further analysis. **To avoid mutability, we won't change any variable's state in place, rather we'll create a brand new variable.**",
            "mc_idx": 53,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Flag all the NaNs of Cabin as 'X'.\"\"\"\nnanReplaced= merged.Cabin.fillna(\"X\")",
            "mc_idx": 54,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".fillna(": 1,
                    ".fillna": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    29,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 54,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 29,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Extract only the 1st character from Cabin, which is only a Letter. And insert it to the dataframe.\"\"\"\nmerged[\"cabinProcessed\"] = nanReplaced.str.get(0) \nbold(\"Cabin Categories after Processing:\")\ndisplay(merged.cabinProcessed.value_counts())",
            "mc_idx": 55,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.5,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "extract": 1
                },
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    30,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "X    1014\nC      94\nB      65\nD      46\nE      41\nA      22\nF      21\nG       5\nT       1\nName: cabinProcessed, dtype: int64"
                    ]
                },
                "mc_idx": 55,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 30,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"After processing, we can visualize the absolute and relative frequency of newly transformed Cabin variable.\"\"\"\nplotFrequency(merged.cabinProcessed)",
            "mc_idx": 56,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "transform": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "visualize": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    31,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"52b98223-66a4-4b48-80de-e96d0937e4ef\" class=\"plotly-graph-div\" style=\"height:600px; width:970px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"52b98223-66a4-4b48-80de-e96d0937e4ef\")) {\n                    Plotly.newPlot(\n                        '52b98223-66a4-4b48-80de-e96d0937e4ef',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [1014, 94, 65, 46, 41, 22, 21, 5, 1], \"colorscale\": \"Rainbow\"}, \"name\": \"Abs Freq\", \"orientation\": \"h\", \"text\": [1014.0, 94.0, 65.0, 46.0, 41.0, 22.0, 21.0, 5.0, 1.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"c273f4e3-c958-490e-9498-f77c6220cce4\", \"x\": [1014, 94, 65, 46, 41, 22, 21, 5, 1], \"xaxis\": \"x\", \"y\": [\"X\", \"C\", \"B\", \"D\", \"E\", \"A\", \"F\", \"G\", \"T\"], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [77.46, 7.18, 4.97, 3.51, 3.13, 1.68, 1.6, 0.38, 0.08], \"colorscale\": \"Rainbow\"}, \"name\": \"Rel Freq(%)\", \"orientation\": \"h\", \"text\": [77.46, 7.18, 4.97, 3.51, 3.13, 1.68, 1.6, 0.38, 0.08], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"bae2ddb6-ab9e-475b-8d68-a093308cf0dc\", \"x\": [77.46, 7.18, 4.97, 3.51, 3.13, 1.68, 1.6, 0.38, 0.08], \"xaxis\": \"x2\", \"y\": [\"X\", \"C\", \"B\", \"D\", \"E\", \"A\", \"F\", \"G\", \"T\"], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Frequency\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Relative Frequency\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Absolute and Relative Frequency of cabinProcessed\"}, \"width\": 970, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"<b>Abs Freq</b>\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"<b>Rel Freq(%)</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>cabinProcessed</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('52b98223-66a4-4b48-80de-e96d0937e4ef');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 56,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 31,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** It seems nearly 77.5% of passengers had X cabin category (formerly NaNs), followed by over 7% had cabin category C and nearly 5% had cabin category B.\n\n## 5.2 Process Name <a id=\"5.2\"></a>",
            "mc_idx": 57,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Lets see what's inside the Name.\"\"\"\ndisplay(merged.Name.head(8))",
            "mc_idx": 58,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    32,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0                              Braund, Mr. Owen Harris\n1    Cumings, Mrs. John Bradley (Florence Briggs Th...\n2                               Heikkinen, Miss. Laina\n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)\n4                             Allen, Mr. William Henry\n5                                     Moran, Mr. James\n6                              McCarthy, Mr. Timothy J\n7                       Palsson, Master. Gosta Leonard\nName: Name, dtype: object"
                    ]
                },
                "mc_idx": 58,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 32,
                "o_idx": 0
            }
        },
        {
            "source": "What we can easily understand from this column, it contains strings that further contains titles such as Mr, Mrs, Master etc. These titles give us some useful information about sex(Mr = male, Mrs = married female), age(Miss is usually younger than Mrs), and profession(Master indicates profession and hence social status) etc which in the end could tell us something more about survival. Now we want to extract these titles from Name to check if there is any association between these titles and Survived.",
            "mc_idx": 59,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Extract those firstName from Name.\"\"\"\nfirstName = merged.Name.str.split(\".\").str.get(0).str.split(\",\").str.get(-1)",
            "mc_idx": 60,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.5,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "extract": 1
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".split": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    33,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 60,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 33,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Count the extracted categories of firstName from Name.\"\"\"\ndisplay(firstName.value_counts())",
            "mc_idx": 61,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.5,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "extract": 1
                },
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    34,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        " Mr              757\n Miss            260\n Mrs             197\n Master           61\n Rev               8\n Dr                8\n Col               4\n Ms                2\n Mlle              2\n Major             2\n Mme               1\n Dona              1\n Sir               1\n Capt              1\n Don               1\n Jonkheer          1\n the Countess      1\n Lady              1\nName: Name, dtype: int64"
                    ]
                },
                "mc_idx": 61,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 34,
                "o_idx": 0
            }
        },
        {
            "source": "We can see there are several titles with the very least frequency. So, it makes sense to put them in fewer buckets. Professionals like Dr, Rev, Col, Major, Capt will be put into 'Officer' bucket. First name such as Dona, Jonkheer, Countess, Sir, Lady, Don were usually entitled to the aristocrats and hence these first name will be put into bucket 'Aristocrat'. We would also replace Mlle and Ms with Miss and Mme by Mrs as these are French titles.",
            "mc_idx": 62,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Create a bucket Officer and put Dr, Rev, Col, Major, Capt titles into it.\"\"\"\nfirstName.replace(to_replace = [\"Dr\", \"Rev\", \"Col\", \"Major\", \"Capt\"], value = \"Officer\", inplace = True,regex=True)\n\n\"\"\"Put Dona, Jonkheer, Countess, Sir, Lady, Don in bucket Aristocrat.\"\"\"\nfirstName.replace(to_replace = [\"Dona\", \"Jonkheer\", \"Countess\", \"Sir\", \"Lady\", \"Don\"], value = \"Aristocrat\", inplace = True,regex=True)\n\n\"\"\"Finally Replace Mlle and Ms with Miss. And Mme with Mrs.\"\"\"\nfirstName.replace({\"Mlle\":\"Miss\", \"Ms\":\"Miss\", \"Mme\":\"Mrs\"}, inplace = True,regex=True)\n\n\"\"\"Replace the Aristocrat with Aristocrat\"\"\"\nfirstName.replace({\"the Aristocrat\":\"Aristocrat\"}, inplace = True,regex=True)\n\n\"\"\"Insert a column named 'nameProcessed'.\"\"\"\nmerged[\"nameProcessed\"] = firstName",
            "mc_idx": 63,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".replace(": 4,
                    ".replace": 4
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    35,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 63,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 35,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"let's see how nameProcessed looks now\"\"\"\ndisplay(merged.nameProcessed.value_counts())",
            "mc_idx": 64,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    36,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        " Mr            757\n Miss          264\n Mrs           198\n Master         61\n Officer        23\n Aristocrat      6\nName: nameProcessed, dtype: int64"
                    ]
                },
                "mc_idx": 64,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 36,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"After processing, visualise and count absolute and relative frequency of transformed Name.\"\"\"\nplotFrequency(merged.nameProcessed)",
            "mc_idx": 65,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "transform": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    37,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"930836e9-5861-4af1-977d-5ed235492dfa\" class=\"plotly-graph-div\" style=\"height:600px; width:970px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"930836e9-5861-4af1-977d-5ed235492dfa\")) {\n                    Plotly.newPlot(\n                        '930836e9-5861-4af1-977d-5ed235492dfa',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [757, 264, 198, 61, 23, 6], \"colorscale\": \"Rainbow\"}, \"name\": \"Abs Freq\", \"orientation\": \"h\", \"text\": [757.0, 264.0, 198.0, 61.0, 23.0, 6.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"c2fc1bbf-bea3-4023-9ffb-56de810bbbe3\", \"x\": [757, 264, 198, 61, 23, 6], \"xaxis\": \"x\", \"y\": [\" Mr\", \" Miss\", \" Mrs\", \" Master\", \" Officer\", \" Aristocrat\"], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [57.83, 20.17, 15.13, 4.66, 1.76, 0.46], \"colorscale\": \"Rainbow\"}, \"name\": \"Rel Freq(%)\", \"orientation\": \"h\", \"text\": [57.83, 20.17, 15.13, 4.66, 1.76, 0.46], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"01afd530-b751-4f05-9ddd-26b63d510cb0\", \"x\": [57.83, 20.17, 15.13, 4.66, 1.76, 0.46], \"xaxis\": \"x2\", \"y\": [\" Mr\", \" Miss\", \" Mrs\", \" Master\", \" Officer\", \" Aristocrat\"], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Frequency\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Relative Frequency\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Absolute and Relative Frequency of nameProcessed\"}, \"width\": 970, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"<b>Abs Freq</b>\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"<b>Rel Freq(%)</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>nameProcessed</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('930836e9-5861-4af1-977d-5ed235492dfa');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 65,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 37,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** Nearly 58% passengers had title Mr(male of course), followed almost 20% passengers had titles Miss(unmarried women hence usually younger than Mrs). Just over 15% passengers were married women (Mrs).\n\n## 5.3 Process SibSp & Parch <a id=\"5.3\"></a>\nIn univariate analysis, we saw some passengers had siblings/spouses and some didn't have. The same is also true for variable Parch. Since these two variables together indicate the size of a family, we would create a new variable 'familySize' from these two variables.",
            "mc_idx": 66,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Merge SibSp and Parch to create a variable Family_size.\"\"\"\nmerged[\"familySize\"] = merged.SibSp + merged.Parch + 1  # Adding 1 for single person\nbold(\"Categoiries in Family_size:\")\ndisplay(merged.familySize.value_counts())",
            "mc_idx": 67,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.16666666666666666,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    "size": 4,
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    38,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "1     790\n2     235\n3     159\n4      43\n6      25\n5      22\n7      16\n11     11\n8       8\nName: familySize, dtype: int64"
                    ]
                },
                "mc_idx": 67,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 38,
                "o_idx": 1
            }
        },
        {
            "source": "We see there are several family sizes with the very least frequency. So its sensible to put them in a fewer buckets. We will create 4 buckets namely single, small, medium, and large for rest of them.",
            "mc_idx": 68,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Create buckets of single, small, medium, and large and then put respective values into them.\"\"\"\nmerged.familySize.replace(to_replace = [1], value = \"single\", inplace = True)\nmerged.familySize.replace(to_replace = [2,3], value = \"small\", inplace = True)\nmerged.familySize.replace(to_replace = [4,5], value = \"medium\", inplace = True)\nmerged.familySize.replace(to_replace = [6, 7, 8, 11], value = \"large\", inplace = True)",
            "mc_idx": 69,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 4
                },
                "Data_Transform": {
                    ".replace(": 4,
                    ".replace": 4
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    39,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 69,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 39,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"After processing, visualise and count the absolute and relative frequency of engineered familySize.\"\"\"\nplotFrequency(merged.familySize)",
            "mc_idx": 70,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    40,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"49b8be5f-6979-4bbb-9c51-e7fa031f6384\" class=\"plotly-graph-div\" style=\"height:600px; width:970px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"49b8be5f-6979-4bbb-9c51-e7fa031f6384\")) {\n                    Plotly.newPlot(\n                        '49b8be5f-6979-4bbb-9c51-e7fa031f6384',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [790, 394, 65, 60], \"colorscale\": \"Rainbow\"}, \"name\": \"Abs Freq\", \"orientation\": \"h\", \"text\": [790.0, 394.0, 65.0, 60.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"05eec60b-91ef-4243-9b52-4df0a35ac494\", \"x\": [790, 394, 65, 60], \"xaxis\": \"x\", \"y\": [\"single\", \"small\", \"medium\", \"large\"], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [60.35, 30.1, 4.97, 4.58], \"colorscale\": \"Rainbow\"}, \"name\": \"Rel Freq(%)\", \"orientation\": \"h\", \"text\": [60.35, 30.1, 4.97, 4.58], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"bbaa75cb-fa6e-480f-bece-2d9c08201de6\", \"x\": [60.35, 30.1, 4.97, 4.58], \"xaxis\": \"x2\", \"y\": [\"single\", \"small\", \"medium\", \"large\"], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Frequency\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Relative Frequency\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Absolute and Relative Frequency of familySize\"}, \"width\": 970, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"<b>Abs Freq</b>\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"<b>Rel Freq(%)</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>familySize</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('49b8be5f-6979-4bbb-9c51-e7fa031f6384');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 70,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 40,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** Looks like most of the passengers (over 60%) were single(without family), followed by 30% passengers had a small family. Almost 5% passengers had medium families and just over 4.5% passengers had large families abroad.\n\n## 5.4 Process Ticket <a id=\"5.4\"></a>",
            "mc_idx": 71,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Let's preview the variable Ticket first.\"\"\"\ndisplay(merged.Ticket.head())",
            "mc_idx": 72,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.3333333333333333,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    41,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0           A/5 21171\n1            PC 17599\n2    STON/O2. 3101282\n3              113803\n4              373450\nName: Ticket, dtype: object"
                    ]
                },
                "mc_idx": 72,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 41,
                "o_idx": 0
            }
        },
        {
            "source": "Ticket is also an alphanumeric type variable. We will create two groups-one will contain just number and other will only contain character extracted from string. If a row contains both character and number, we will keep only character.",
            "mc_idx": 73,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Assign 'N' if there is only digits in Ticket. Otherwise just get the 1st character from Ticket.\"\"\"\notherwise = merged.Ticket.str.split(\" \").str.get(0).str.get(0) # This extracts the 1st character\nmerged[\"ticketProcessed\"] = np.where(merged.Ticket.str.isdigit(), \"N\", otherwise)",
            "mc_idx": 74,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "extract": 1
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".split": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    42,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 74,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 42,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Now calculate the categories in the ticketProcessed column.\"\"\"\nbold(\"Ticket after Processing:\")\ndisplay(merged.ticketProcessed.value_counts())",
            "mc_idx": 75,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    43,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "N    957\nS     98\nP     98\nC     77\nA     42\nW     19\nF     13\nL      5\nName: ticketProcessed, dtype: int64"
                    ]
                },
                "mc_idx": 75,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 43,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"After processing, visualise and count the absolute and relative frequency of updated Ticket.\"\"\"\nplotFrequency(merged.ticketProcessed)",
            "mc_idx": 76,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    44,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"386e07d4-b21c-47f1-b6f5-a46ff52ab65d\" class=\"plotly-graph-div\" style=\"height:600px; width:970px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"386e07d4-b21c-47f1-b6f5-a46ff52ab65d\")) {\n                    Plotly.newPlot(\n                        '386e07d4-b21c-47f1-b6f5-a46ff52ab65d',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [957, 98, 98, 77, 42, 19, 13, 5], \"colorscale\": \"Rainbow\"}, \"name\": \"Abs Freq\", \"orientation\": \"h\", \"text\": [957.0, 98.0, 98.0, 77.0, 42.0, 19.0, 13.0, 5.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"24129760-0eed-420e-b807-87af3a9e248e\", \"x\": [957, 98, 98, 77, 42, 19, 13, 5], \"xaxis\": \"x\", \"y\": [\"N\", \"S\", \"P\", \"C\", \"A\", \"W\", \"F\", \"L\"], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [73.11, 7.49, 7.49, 5.88, 3.21, 1.45, 0.99, 0.38], \"colorscale\": \"Rainbow\"}, \"name\": \"Rel Freq(%)\", \"orientation\": \"h\", \"text\": [73.11, 7.49, 7.49, 5.88, 3.21, 1.45, 0.99, 0.38], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"94d2c23b-b9c7-47d9-94ff-21063a0600f7\", \"x\": [73.11, 7.49, 7.49, 5.88, 3.21, 1.45, 0.99, 0.38], \"xaxis\": \"x2\", \"y\": [\"N\", \"S\", \"P\", \"C\", \"A\", \"W\", \"F\", \"L\"], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Frequency\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Relative Frequency\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Absolute and Relative Frequency of ticketProcessed\"}, \"width\": 970, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"<b>Abs Freq</b>\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"<b>Rel Freq(%)</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>ticketProcessed</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('386e07d4-b21c-47f1-b6f5-a46ff52ab65d');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 76,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 44,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** Over 73% passengers had ticket of category N, followed by nearly 7.5% passengers ticket category were S and P. Passengers with W ticket category were as low as 1.45%.\n\n# 6.Outliers Detection <a id=\"6\"></a>\n**How outliers affect the distribution:** If a value of a variable is significantly above the expected range, it will drag the distribution to the right, making the graph right-skewed or positive-skewed (like Fare). Alternatively, If a value is significantly below the expected range, it will drag the distribution to the left, making the graph left-skewed or negative-skewed.\n\nAnother useful plot for visualizing a continuous variable is box plot. Box plot is particularly helpful to understand the spread of the continus data and whether there are potential unusual observations (outliers) in that variable. It presents information of min, 1st quartile, 2nd quartile(median), 3rd quartile, and max of a variable.**We will use IQR method to detect the outliers for variable Age and Fare though we won't remove them.**",
            "mc_idx": 77,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"#1.Create a function that removes outliers\"\"\"\ndef removeOutliers(variable):\n    \"\"\"Calculates and removes outliers using IQR method.\"\"\"\n    \n    # Calculate 1st, 3rd quartiles and iqr.\n    q1, q3 = variable.quantile(0.25), variable.quantile(0.75)\n    iqr = q3 - q1\n    \n    # Calculate lower fence and upper fence for outliers\n    lowerFence, upperFence = q1-1.5*iqr, q3+1.5*iqr   # Any values less than l_fence and greater than u_fence are outliers.\n    \n    # Observations that are outliers\n    outliers = variable[(variable<lowerFence) | (variable>upperFence)]\n    \n    # Drop obsevations that are outliers\n    filtered = variable.drop(outliers.index, axis = 0).reset_index(drop=True)\n    return filtered\n\n\n\"\"\"#2.Create another function to plot boxplot with and without outliers.\"\"\"\ndef plotBoxPlot(variable,filteredVariable):\n    \"\"\"Plots Box plot of a variable with and without outliers.\n    We will also use the output of removeOutliers function as the input to this function.\n    variable = variable with outliers,\n    filteredVariable = variable without outliers\"\"\"\n    \n    # Create subplot object.\n    fig = make_subplots(\n        rows=2,\n        cols=1,\n        print_grid=False,\n    subplot_titles=(f\"{variable.name} Distribution with Outliers\", f\"{variable.name} Distribution without Outliers\"))\n    \n    # This trace plots boxplot with outliers\n    fig.add_trace(\n        go.Box(\n            x = variable,\n            name = \"\", # This removes trace 0\n            marker = dict(color=\"darkred\")\n        ),\n    row=1,col=1)\n    \n    # This trace plots boxplot without outliers\n    fig.add_trace(\n        go.Box(\n            x = filteredVariable,\n            name = \"\",\n            marker = dict(color=\"green\")\n        ),\n    row=2,col=1)\n    \n    # Update layout\n    fig.layout.update(\n        height=800, \n        width=870,\n        showlegend=False,\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n    \n    # Update axes\n    fig.layout.xaxis2.update(title=f\"<b>{variable.name}</b>\")\n    return fig.show()",
            "mc_idx": 78,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.9,
                "Data_Transform": 0.35,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1,
                    "variable": 19
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "outliers": 18
                },
                "Data_Transform": {
                    "tile": 3,
                    ".drop": 1,
                    ".reset_index": 1,
                    ".add": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    45,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 78,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 45,
                "o_idx": 0
            }
        },
        {
            "source": "## 6.1 Outliers Detection for Age <a id=\"6.1\"></a>",
            "mc_idx": 79,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Plot Age with and without outliers.\"\"\"\nplotBoxPlot(merged.Age,removeOutliers(merged.Age))",
            "mc_idx": 80,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "outliers": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    46,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"8a11c18b-590e-4973-97f9-e610444d56f6\" class=\"plotly-graph-div\" style=\"height:800px; width:870px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"8a11c18b-590e-4973-97f9-e610444d56f6\")) {\n                    Plotly.newPlot(\n                        '8a11c18b-590e-4973-97f9-e610444d56f6',\n                        [{\"marker\": {\"color\": \"darkred\"}, \"name\": \"\", \"type\": \"box\", \"uid\": \"18242ecd-6e17-4fcb-9075-a13da278033c\", \"x\": [22.0, 38.0, 26.0, 35.0, 35.0, null, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, null, 31.0, null, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, null, 19.0, null, null, 40.0, null, null, 66.0, 28.0, 42.0, null, 21.0, 18.0, 14.0, 40.0, 27.0, null, 3.0, 19.0, null, null, null, null, 18.0, 7.0, 21.0, 49.0, 29.0, 65.0, null, 21.0, 28.5, 5.0, 11.0, 22.0, 38.0, 45.0, 4.0, null, null, 29.0, 19.0, 17.0, 26.0, 32.0, 16.0, 21.0, 26.0, 32.0, 25.0, null, null, 0.83, 30.0, 22.0, 29.0, null, 28.0, 17.0, 33.0, 16.0, null, 23.0, 24.0, 29.0, 20.0, 46.0, 26.0, 59.0, null, 71.0, 23.0, 34.0, 34.0, 28.0, null, 21.0, 33.0, 37.0, 28.0, 21.0, null, 38.0, null, 47.0, 14.5, 22.0, 20.0, 17.0, 21.0, 70.5, 29.0, 24.0, 2.0, 21.0, null, 32.5, 32.5, 54.0, 12.0, null, 24.0, null, 45.0, 33.0, 20.0, 47.0, 29.0, 25.0, 23.0, 19.0, 37.0, 16.0, 24.0, null, 22.0, 24.0, 19.0, 18.0, 19.0, 27.0, 9.0, 36.5, 42.0, 51.0, 22.0, 55.5, 40.5, null, 51.0, 16.0, 30.0, null, null, 44.0, 40.0, 26.0, 17.0, 1.0, 9.0, null, 45.0, null, 28.0, 61.0, 4.0, 1.0, 21.0, 56.0, 18.0, null, 50.0, 30.0, 36.0, null, null, 9.0, 1.0, 4.0, null, null, 45.0, 40.0, 36.0, 32.0, 19.0, 19.0, 3.0, 44.0, 58.0, null, 42.0, null, 24.0, 28.0, null, 34.0, 45.5, 18.0, 2.0, 32.0, 26.0, 16.0, 40.0, 24.0, 35.0, 22.0, 30.0, null, 31.0, 27.0, 42.0, 32.0, 30.0, 16.0, 27.0, 51.0, null, 38.0, 22.0, 19.0, 20.5, 18.0, null, 35.0, 29.0, 59.0, 5.0, 24.0, null, 44.0, 8.0, 19.0, 33.0, null, null, 29.0, 22.0, 30.0, 44.0, 25.0, 24.0, 37.0, 54.0, null, 29.0, 62.0, 30.0, 41.0, 29.0, null, 30.0, 35.0, 50.0, null, 3.0, 52.0, 40.0, null, 36.0, 16.0, 25.0, 58.0, 35.0, null, 25.0, 41.0, 37.0, null, 63.0, 45.0, null, 7.0, 35.0, 65.0, 28.0, 16.0, 19.0, null, 33.0, 30.0, 22.0, 42.0, 22.0, 26.0, 19.0, 36.0, 24.0, 24.0, null, 23.5, 2.0, null, 50.0, null, null, 19.0, null, null, 0.92, null, 17.0, 30.0, 30.0, 24.0, 18.0, 26.0, 28.0, 43.0, 26.0, 24.0, 54.0, 31.0, 40.0, 22.0, 27.0, 30.0, 22.0, null, 36.0, 61.0, 36.0, 31.0, 16.0, null, 45.5, 38.0, 16.0, null, null, 29.0, 41.0, 45.0, 45.0, 2.0, 24.0, 28.0, 25.0, 36.0, 24.0, 40.0, null, 3.0, 42.0, 23.0, null, 15.0, 25.0, null, 28.0, 22.0, 38.0, null, null, 40.0, 29.0, 45.0, 35.0, null, 30.0, 60.0, null, null, 24.0, 25.0, 18.0, 19.0, 22.0, 3.0, null, 22.0, 27.0, 20.0, 19.0, 42.0, 1.0, 32.0, 35.0, null, 18.0, 1.0, 36.0, null, 17.0, 36.0, 21.0, 28.0, 23.0, 24.0, 22.0, 31.0, 46.0, 23.0, 28.0, 39.0, 26.0, 21.0, 28.0, 20.0, 34.0, 51.0, 3.0, 21.0, null, null, null, 33.0, null, 44.0, null, 34.0, 18.0, 30.0, 10.0, null, 21.0, 29.0, 28.0, 18.0, null, 28.0, 19.0, null, 32.0, 28.0, null, 42.0, 17.0, 50.0, 14.0, 21.0, 24.0, 64.0, 31.0, 45.0, 20.0, 25.0, 28.0, null, 4.0, 13.0, 34.0, 5.0, 52.0, 36.0, null, 30.0, 49.0, null, 29.0, 65.0, null, 50.0, null, 48.0, 34.0, 47.0, 48.0, null, 38.0, null, 56.0, null, 0.75, null, 38.0, 33.0, 23.0, 22.0, null, 34.0, 29.0, 22.0, 2.0, 9.0, null, 50.0, 63.0, 25.0, null, 35.0, 58.0, 30.0, 9.0, null, 21.0, 55.0, 71.0, 21.0, null, 54.0, null, 25.0, 24.0, 17.0, 21.0, null, 37.0, 16.0, 18.0, 33.0, null, 28.0, 26.0, 29.0, null, 36.0, 54.0, 24.0, 47.0, 34.0, null, 36.0, 32.0, 30.0, 22.0, null, 44.0, null, 40.5, 50.0, null, 39.0, 23.0, 2.0, null, 17.0, null, 30.0, 7.0, 45.0, 30.0, null, 22.0, 36.0, 9.0, 11.0, 32.0, 50.0, 64.0, 19.0, null, 33.0, 8.0, 17.0, 27.0, null, 22.0, 22.0, 62.0, 48.0, null, 39.0, 36.0, null, 40.0, 28.0, null, null, 24.0, 19.0, 29.0, null, 32.0, 62.0, 53.0, 36.0, null, 16.0, 19.0, 34.0, 39.0, null, 32.0, 25.0, 39.0, 54.0, 36.0, null, 18.0, 47.0, 60.0, 22.0, null, 35.0, 52.0, 47.0, null, 37.0, 36.0, null, 49.0, null, 49.0, 24.0, null, null, 44.0, 35.0, 36.0, 30.0, 27.0, 22.0, 40.0, 39.0, null, null, null, 35.0, 24.0, 34.0, 26.0, 4.0, 26.0, 27.0, 42.0, 20.0, 21.0, 21.0, 61.0, 57.0, 21.0, 26.0, null, 80.0, 51.0, 32.0, null, 9.0, 28.0, 32.0, 31.0, 41.0, null, 20.0, 24.0, 2.0, null, 0.75, 48.0, 19.0, 56.0, null, 23.0, null, 18.0, 21.0, null, 18.0, 24.0, null, 32.0, 23.0, 58.0, 50.0, 40.0, 47.0, 36.0, 20.0, 32.0, 25.0, null, 43.0, null, 40.0, 31.0, 70.0, 31.0, null, 18.0, 24.5, 18.0, 43.0, 36.0, null, 27.0, 20.0, 14.0, 60.0, 25.0, 14.0, 19.0, 18.0, 15.0, 31.0, 4.0, null, 25.0, 60.0, 52.0, 44.0, null, 49.0, 42.0, 18.0, 35.0, 18.0, 25.0, 26.0, 39.0, 45.0, 42.0, 22.0, null, 24.0, null, 48.0, 29.0, 52.0, 19.0, 38.0, 27.0, null, 33.0, 6.0, 17.0, 34.0, 50.0, 27.0, 20.0, 30.0, null, 25.0, 25.0, 29.0, 11.0, null, 23.0, 23.0, 28.5, 48.0, 35.0, null, null, null, 36.0, 21.0, 24.0, 31.0, 70.0, 16.0, 30.0, 19.0, 31.0, 4.0, 6.0, 33.0, 23.0, 48.0, 0.67, 28.0, 18.0, 34.0, 33.0, null, 41.0, 20.0, 36.0, 16.0, 51.0, null, 30.5, null, 32.0, 24.0, 48.0, 57.0, null, 54.0, 18.0, null, 5.0, null, 43.0, 13.0, 17.0, 29.0, null, 25.0, 25.0, 18.0, 8.0, 1.0, 46.0, null, 16.0, null, null, 25.0, 39.0, 49.0, 31.0, 30.0, 30.0, 34.0, 31.0, 11.0, 0.42, 27.0, 31.0, 39.0, 18.0, 39.0, 33.0, 26.0, 39.0, 35.0, 6.0, 30.5, null, 23.0, 31.0, 43.0, 10.0, 52.0, 27.0, 38.0, 27.0, 2.0, null, null, 1.0, null, 62.0, 15.0, 0.83, null, 23.0, 18.0, 39.0, 21.0, null, 32.0, null, 20.0, 16.0, 30.0, 34.5, 17.0, 42.0, null, 35.0, 28.0, null, 4.0, 74.0, 9.0, 16.0, 44.0, 18.0, 45.0, 51.0, 24.0, null, 41.0, 21.0, 48.0, null, 24.0, 42.0, 27.0, 31.0, null, 4.0, 26.0, 47.0, 33.0, 47.0, 28.0, 15.0, 20.0, 19.0, null, 56.0, 25.0, 33.0, 22.0, 28.0, 25.0, 39.0, 27.0, 19.0, null, 26.0, 32.0, 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0, null, 46.0, 23.0, 63.0, 47.0, 24.0, 35.0, 21.0, 27.0, 45.0, 55.0, 9.0, null, 21.0, 48.0, 50.0, 22.0, 22.5, 41.0, null, 50.0, 24.0, 33.0, null, 30.0, 18.5, null, 21.0, 25.0, null, 39.0, null, 41.0, 30.0, 45.0, 25.0, 45.0, null, 60.0, 36.0, 24.0, 27.0, 20.0, 28.0, null, 10.0, 35.0, 25.0, null, 36.0, 17.0, 32.0, 18.0, 22.0, 13.0, null, 18.0, 47.0, 31.0, 60.0, 24.0, 21.0, 29.0, 28.5, 35.0, 32.5, null, 55.0, 30.0, 24.0, 6.0, 67.0, 49.0, null, null, null, 27.0, 18.0, null, 2.0, 22.0, null, 27.0, null, 25.0, 25.0, 76.0, 29.0, 20.0, 33.0, 43.0, 27.0, null, 26.0, 16.0, 28.0, 21.0, null, null, 18.5, 41.0, null, 36.0, 18.5, 63.0, 18.0, null, 1.0, 36.0, 29.0, 12.0, null, 35.0, 28.0, null, 17.0, 22.0, null, 42.0, 24.0, 32.0, 53.0, null, null, 43.0, 24.0, 26.5, 26.0, 23.0, 40.0, 10.0, 33.0, 61.0, 28.0, 42.0, 31.0, null, 22.0, null, 30.0, 23.0, null, 60.5, 36.0, 13.0, 24.0, 29.0, 23.0, 42.0, 26.0, null, 7.0, 26.0, null, 41.0, 26.0, 48.0, 18.0, null, 22.0, null, 27.0, 23.0, null, 40.0, 15.0, 20.0, 54.0, 36.0, 64.0, 30.0, 37.0, 18.0, null, 27.0, 40.0, 21.0, 17.0, null, 40.0, 34.0, null, 11.5, 61.0, 8.0, 33.0, 6.0, 18.0, 23.0, null, null, 0.33, 47.0, 8.0, 25.0, null, 35.0, 24.0, 33.0, 25.0, 32.0, null, 17.0, 60.0, 38.0, 42.0, null, 57.0, 50.0, null, 30.0, 21.0, 22.0, 21.0, 53.0, null, 23.0, null, 40.5, 36.0, 14.0, 21.0, 21.0, null, 39.0, 20.0, 64.0, 20.0, 18.0, 48.0, 55.0, 45.0, 45.0, null, null, 41.0, 22.0, 42.0, 29.0, null, 0.92, 20.0, 27.0, 24.0, 32.5, null, null, 28.0, 19.0, 21.0, 36.5, 21.0, 29.0, 1.0, 30.0, null, null, null, null, 17.0, 46.0, null, 26.0, null, null, 20.0, 28.0, 40.0, 30.0, 22.0, 23.0, 0.75, null, 9.0, 2.0, 36.0, null, 24.0, null, null, null, 30.0, null, 53.0, 36.0, 26.0, 1.0, null, 30.0, 29.0, 32.0, null, 43.0, 24.0, null, 64.0, 30.0, 0.83, 55.0, 45.0, 18.0, 22.0, null, 37.0, 55.0, 17.0, 57.0, 19.0, 27.0, 22.0, 26.0, 25.0, 26.0, 33.0, 39.0, 23.0, 12.0, 46.0, 29.0, 21.0, 48.0, 39.0, null, 19.0, 27.0, 30.0, 32.0, 39.0, 25.0, null, 18.0, 32.0, null, 58.0, null, 16.0, 26.0, 38.0, 24.0, 31.0, 45.0, 25.0, 18.0, 49.0, 0.17, 50.0, 59.0, null, null, 30.0, 14.5, 24.0, 31.0, 27.0, 25.0, null, null, 22.0, 45.0, 29.0, 21.0, 31.0, 49.0, 44.0, 54.0, 45.0, 22.0, 21.0, 55.0, 5.0, null, 26.0, null, 19.0, null, 24.0, 24.0, 57.0, 21.0, 6.0, 23.0, 51.0, 13.0, 47.0, 29.0, 18.0, 24.0, 48.0, 22.0, 31.0, 30.0, 38.0, 22.0, 17.0, 43.0, 20.0, 23.0, 50.0, null, 3.0, null, 37.0, 28.0, null, 39.0, 38.5, null, null], \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"green\"}, \"name\": \"\", \"type\": \"box\", \"uid\": \"3bc58a27-f100-4d1c-aa35-b35a57715c37\", \"x\": [22.0, 38.0, 26.0, 35.0, 35.0, null, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, null, 31.0, null, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, null, 19.0, null, null, 40.0, null, null, 66.0, 28.0, 42.0, null, 21.0, 18.0, 14.0, 40.0, 27.0, null, 3.0, 19.0, null, null, null, null, 18.0, 7.0, 21.0, 49.0, 29.0, 65.0, null, 21.0, 28.5, 5.0, 11.0, 22.0, 38.0, 45.0, 4.0, null, null, 29.0, 19.0, 17.0, 26.0, 32.0, 16.0, 21.0, 26.0, 32.0, 25.0, null, null, 0.83, 30.0, 22.0, 29.0, null, 28.0, 17.0, 33.0, 16.0, null, 23.0, 24.0, 29.0, 20.0, 46.0, 26.0, 59.0, null, 23.0, 34.0, 34.0, 28.0, null, 21.0, 33.0, 37.0, 28.0, 21.0, null, 38.0, null, 47.0, 14.5, 22.0, 20.0, 17.0, 21.0, 29.0, 24.0, 2.0, 21.0, null, 32.5, 32.5, 54.0, 12.0, null, 24.0, null, 45.0, 33.0, 20.0, 47.0, 29.0, 25.0, 23.0, 19.0, 37.0, 16.0, 24.0, null, 22.0, 24.0, 19.0, 18.0, 19.0, 27.0, 9.0, 36.5, 42.0, 51.0, 22.0, 55.5, 40.5, null, 51.0, 16.0, 30.0, null, null, 44.0, 40.0, 26.0, 17.0, 1.0, 9.0, null, 45.0, null, 28.0, 61.0, 4.0, 1.0, 21.0, 56.0, 18.0, null, 50.0, 30.0, 36.0, null, null, 9.0, 1.0, 4.0, null, null, 45.0, 40.0, 36.0, 32.0, 19.0, 19.0, 3.0, 44.0, 58.0, null, 42.0, null, 24.0, 28.0, null, 34.0, 45.5, 18.0, 2.0, 32.0, 26.0, 16.0, 40.0, 24.0, 35.0, 22.0, 30.0, null, 31.0, 27.0, 42.0, 32.0, 30.0, 16.0, 27.0, 51.0, null, 38.0, 22.0, 19.0, 20.5, 18.0, null, 35.0, 29.0, 59.0, 5.0, 24.0, null, 44.0, 8.0, 19.0, 33.0, null, null, 29.0, 22.0, 30.0, 44.0, 25.0, 24.0, 37.0, 54.0, null, 29.0, 62.0, 30.0, 41.0, 29.0, null, 30.0, 35.0, 50.0, null, 3.0, 52.0, 40.0, null, 36.0, 16.0, 25.0, 58.0, 35.0, null, 25.0, 41.0, 37.0, null, 63.0, 45.0, null, 7.0, 35.0, 65.0, 28.0, 16.0, 19.0, null, 33.0, 30.0, 22.0, 42.0, 22.0, 26.0, 19.0, 36.0, 24.0, 24.0, null, 23.5, 2.0, null, 50.0, null, null, 19.0, null, null, 0.92, null, 17.0, 30.0, 30.0, 24.0, 18.0, 26.0, 28.0, 43.0, 26.0, 24.0, 54.0, 31.0, 40.0, 22.0, 27.0, 30.0, 22.0, null, 36.0, 61.0, 36.0, 31.0, 16.0, null, 45.5, 38.0, 16.0, null, null, 29.0, 41.0, 45.0, 45.0, 2.0, 24.0, 28.0, 25.0, 36.0, 24.0, 40.0, null, 3.0, 42.0, 23.0, null, 15.0, 25.0, null, 28.0, 22.0, 38.0, null, null, 40.0, 29.0, 45.0, 35.0, null, 30.0, 60.0, null, null, 24.0, 25.0, 18.0, 19.0, 22.0, 3.0, null, 22.0, 27.0, 20.0, 19.0, 42.0, 1.0, 32.0, 35.0, null, 18.0, 1.0, 36.0, null, 17.0, 36.0, 21.0, 28.0, 23.0, 24.0, 22.0, 31.0, 46.0, 23.0, 28.0, 39.0, 26.0, 21.0, 28.0, 20.0, 34.0, 51.0, 3.0, 21.0, null, null, null, 33.0, null, 44.0, null, 34.0, 18.0, 30.0, 10.0, null, 21.0, 29.0, 28.0, 18.0, null, 28.0, 19.0, null, 32.0, 28.0, null, 42.0, 17.0, 50.0, 14.0, 21.0, 24.0, 64.0, 31.0, 45.0, 20.0, 25.0, 28.0, null, 4.0, 13.0, 34.0, 5.0, 52.0, 36.0, null, 30.0, 49.0, null, 29.0, 65.0, null, 50.0, null, 48.0, 34.0, 47.0, 48.0, null, 38.0, null, 56.0, null, 0.75, null, 38.0, 33.0, 23.0, 22.0, null, 34.0, 29.0, 22.0, 2.0, 9.0, null, 50.0, 63.0, 25.0, null, 35.0, 58.0, 30.0, 9.0, null, 21.0, 55.0, 21.0, null, 54.0, null, 25.0, 24.0, 17.0, 21.0, null, 37.0, 16.0, 18.0, 33.0, null, 28.0, 26.0, 29.0, null, 36.0, 54.0, 24.0, 47.0, 34.0, null, 36.0, 32.0, 30.0, 22.0, null, 44.0, null, 40.5, 50.0, null, 39.0, 23.0, 2.0, null, 17.0, null, 30.0, 7.0, 45.0, 30.0, null, 22.0, 36.0, 9.0, 11.0, 32.0, 50.0, 64.0, 19.0, null, 33.0, 8.0, 17.0, 27.0, null, 22.0, 22.0, 62.0, 48.0, null, 39.0, 36.0, null, 40.0, 28.0, null, null, 24.0, 19.0, 29.0, null, 32.0, 62.0, 53.0, 36.0, null, 16.0, 19.0, 34.0, 39.0, null, 32.0, 25.0, 39.0, 54.0, 36.0, null, 18.0, 47.0, 60.0, 22.0, null, 35.0, 52.0, 47.0, null, 37.0, 36.0, null, 49.0, null, 49.0, 24.0, null, null, 44.0, 35.0, 36.0, 30.0, 27.0, 22.0, 40.0, 39.0, null, null, null, 35.0, 24.0, 34.0, 26.0, 4.0, 26.0, 27.0, 42.0, 20.0, 21.0, 21.0, 61.0, 57.0, 21.0, 26.0, null, 51.0, 32.0, null, 9.0, 28.0, 32.0, 31.0, 41.0, null, 20.0, 24.0, 2.0, null, 0.75, 48.0, 19.0, 56.0, null, 23.0, null, 18.0, 21.0, null, 18.0, 24.0, null, 32.0, 23.0, 58.0, 50.0, 40.0, 47.0, 36.0, 20.0, 32.0, 25.0, null, 43.0, null, 40.0, 31.0, 31.0, null, 18.0, 24.5, 18.0, 43.0, 36.0, null, 27.0, 20.0, 14.0, 60.0, 25.0, 14.0, 19.0, 18.0, 15.0, 31.0, 4.0, null, 25.0, 60.0, 52.0, 44.0, null, 49.0, 42.0, 18.0, 35.0, 18.0, 25.0, 26.0, 39.0, 45.0, 42.0, 22.0, null, 24.0, null, 48.0, 29.0, 52.0, 19.0, 38.0, 27.0, null, 33.0, 6.0, 17.0, 34.0, 50.0, 27.0, 20.0, 30.0, null, 25.0, 25.0, 29.0, 11.0, null, 23.0, 23.0, 28.5, 48.0, 35.0, null, null, null, 36.0, 21.0, 24.0, 31.0, 16.0, 30.0, 19.0, 31.0, 4.0, 6.0, 33.0, 23.0, 48.0, 0.67, 28.0, 18.0, 34.0, 33.0, null, 41.0, 20.0, 36.0, 16.0, 51.0, null, 30.5, null, 32.0, 24.0, 48.0, 57.0, null, 54.0, 18.0, null, 5.0, null, 43.0, 13.0, 17.0, 29.0, null, 25.0, 25.0, 18.0, 8.0, 1.0, 46.0, null, 16.0, null, null, 25.0, 39.0, 49.0, 31.0, 30.0, 30.0, 34.0, 31.0, 11.0, 0.42, 27.0, 31.0, 39.0, 18.0, 39.0, 33.0, 26.0, 39.0, 35.0, 6.0, 30.5, null, 23.0, 31.0, 43.0, 10.0, 52.0, 27.0, 38.0, 27.0, 2.0, null, null, 1.0, null, 62.0, 15.0, 0.83, null, 23.0, 18.0, 39.0, 21.0, null, 32.0, null, 20.0, 16.0, 30.0, 34.5, 17.0, 42.0, null, 35.0, 28.0, null, 4.0, 9.0, 16.0, 44.0, 18.0, 45.0, 51.0, 24.0, null, 41.0, 21.0, 48.0, null, 24.0, 42.0, 27.0, 31.0, null, 4.0, 26.0, 47.0, 33.0, 47.0, 28.0, 15.0, 20.0, 19.0, null, 56.0, 25.0, 33.0, 22.0, 28.0, 25.0, 39.0, 27.0, 19.0, null, 26.0, 32.0, 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0, null, 46.0, 23.0, 63.0, 47.0, 24.0, 35.0, 21.0, 27.0, 45.0, 55.0, 9.0, null, 21.0, 48.0, 50.0, 22.0, 22.5, 41.0, null, 50.0, 24.0, 33.0, null, 30.0, 18.5, null, 21.0, 25.0, null, 39.0, null, 41.0, 30.0, 45.0, 25.0, 45.0, null, 60.0, 36.0, 24.0, 27.0, 20.0, 28.0, null, 10.0, 35.0, 25.0, null, 36.0, 17.0, 32.0, 18.0, 22.0, 13.0, null, 18.0, 47.0, 31.0, 60.0, 24.0, 21.0, 29.0, 28.5, 35.0, 32.5, null, 55.0, 30.0, 24.0, 6.0, 49.0, null, null, null, 27.0, 18.0, null, 2.0, 22.0, null, 27.0, null, 25.0, 25.0, 29.0, 20.0, 33.0, 43.0, 27.0, null, 26.0, 16.0, 28.0, 21.0, null, null, 18.5, 41.0, null, 36.0, 18.5, 63.0, 18.0, null, 1.0, 36.0, 29.0, 12.0, null, 35.0, 28.0, null, 17.0, 22.0, null, 42.0, 24.0, 32.0, 53.0, null, null, 43.0, 24.0, 26.5, 26.0, 23.0, 40.0, 10.0, 33.0, 61.0, 28.0, 42.0, 31.0, null, 22.0, null, 30.0, 23.0, null, 60.5, 36.0, 13.0, 24.0, 29.0, 23.0, 42.0, 26.0, null, 7.0, 26.0, null, 41.0, 26.0, 48.0, 18.0, null, 22.0, null, 27.0, 23.0, null, 40.0, 15.0, 20.0, 54.0, 36.0, 64.0, 30.0, 37.0, 18.0, null, 27.0, 40.0, 21.0, 17.0, null, 40.0, 34.0, null, 11.5, 61.0, 8.0, 33.0, 6.0, 18.0, 23.0, null, null, 0.33, 47.0, 8.0, 25.0, null, 35.0, 24.0, 33.0, 25.0, 32.0, null, 17.0, 60.0, 38.0, 42.0, null, 57.0, 50.0, null, 30.0, 21.0, 22.0, 21.0, 53.0, null, 23.0, null, 40.5, 36.0, 14.0, 21.0, 21.0, null, 39.0, 20.0, 64.0, 20.0, 18.0, 48.0, 55.0, 45.0, 45.0, null, null, 41.0, 22.0, 42.0, 29.0, null, 0.92, 20.0, 27.0, 24.0, 32.5, null, null, 28.0, 19.0, 21.0, 36.5, 21.0, 29.0, 1.0, 30.0, null, null, null, null, 17.0, 46.0, null, 26.0, null, null, 20.0, 28.0, 40.0, 30.0, 22.0, 23.0, 0.75, null, 9.0, 2.0, 36.0, null, 24.0, null, null, null, 30.0, null, 53.0, 36.0, 26.0, 1.0, null, 30.0, 29.0, 32.0, null, 43.0, 24.0, null, 64.0, 30.0, 0.83, 55.0, 45.0, 18.0, 22.0, null, 37.0, 55.0, 17.0, 57.0, 19.0, 27.0, 22.0, 26.0, 25.0, 26.0, 33.0, 39.0, 23.0, 12.0, 46.0, 29.0, 21.0, 48.0, 39.0, null, 19.0, 27.0, 30.0, 32.0, 39.0, 25.0, null, 18.0, 32.0, null, 58.0, null, 16.0, 26.0, 38.0, 24.0, 31.0, 45.0, 25.0, 18.0, 49.0, 0.17, 50.0, 59.0, null, null, 30.0, 14.5, 24.0, 31.0, 27.0, 25.0, null, null, 22.0, 45.0, 29.0, 21.0, 31.0, 49.0, 44.0, 54.0, 45.0, 22.0, 21.0, 55.0, 5.0, null, 26.0, null, 19.0, null, 24.0, 24.0, 57.0, 21.0, 6.0, 23.0, 51.0, 13.0, 47.0, 29.0, 18.0, 24.0, 48.0, 22.0, 31.0, 30.0, 38.0, 22.0, 17.0, 43.0, 20.0, 23.0, 50.0, null, 3.0, null, 37.0, 28.0, null, 39.0, 38.5, null, null], \"xaxis\": \"x2\", \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Age Distribution with Outliers\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Age Distribution without Outliers\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.375, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 800, \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"width\": 870, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Age</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.625, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.375]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('8a11c18b-590e-4973-97f9-e610444d56f6');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 80,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 46,
                "o_idx": 0
            }
        },
        {
            "source": "**For a box plot, if the longer part of the box is right (or above) to the median, the data is said to be skewed right. If the longer part is  left (or below) to the median, the data is skewed left. In our case, the bigger part of the box is right to the median**\n\n## 6.2 Outliers Detection for Fare <a id=\"6.2\"></a>",
            "mc_idx": 81,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Plot Fare with and without outliers.\"\"\"\nplotBoxPlot(merged.Fare,removeOutliers(merged.Fare))",
            "mc_idx": 82,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "outliers": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    47,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"7b3f5f43-d255-42bb-9105-c1965d27cf25\" class=\"plotly-graph-div\" style=\"height:800px; width:870px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"7b3f5f43-d255-42bb-9105-c1965d27cf25\")) {\n                    Plotly.newPlot(\n                        '7b3f5f43-d255-42bb-9105-c1965d27cf25',\n                        [{\"marker\": {\"color\": \"darkred\"}, \"name\": \"\", \"type\": \"box\", \"uid\": \"ffc9a7ae-023e-48ff-bf45-58ffa82229a2\", \"x\": [7.25, 71.2833, 7.925, 53.1, 8.05, 8.4583, 51.8625, 21.075, 11.1333, 30.0708, 16.7, 26.55, 8.05, 31.275, 7.8542, 16.0, 29.125, 13.0, 18.0, 7.225, 26.0, 13.0, 8.0292, 35.5, 21.075, 31.3875, 7.225, 263.0, 7.8792, 7.8958, 27.7208, 146.5208, 7.75, 10.5, 82.1708, 52.0, 7.2292, 8.05, 18.0, 11.2417, 9.475, 21.0, 7.8958, 41.5792, 7.8792, 8.05, 15.5, 7.75, 21.6792, 17.8, 39.6875, 7.8, 76.7292, 26.0, 61.9792, 35.5, 10.5, 7.2292, 27.75, 46.9, 7.2292, 80.0, 83.475, 27.9, 27.7208, 15.2458, 10.5, 8.1583, 7.925, 8.6625, 10.5, 46.9, 73.5, 14.4542, 56.4958, 7.65, 7.8958, 8.05, 29.0, 12.475, 9.0, 9.5, 7.7875, 47.1, 10.5, 15.85, 34.375, 8.05, 263.0, 8.05, 8.05, 7.8542, 61.175, 20.575, 7.25, 8.05, 34.6542, 63.3583, 23.0, 26.0, 7.8958, 7.8958, 77.2875, 8.6542, 7.925, 7.8958, 7.65, 7.775, 7.8958, 24.15, 52.0, 14.4542, 8.05, 9.825, 14.4583, 7.925, 7.75, 21.0, 247.5208, 31.275, 73.5, 8.05, 30.0708, 13.0, 77.2875, 11.2417, 7.75, 7.1417, 22.3583, 6.975, 7.8958, 7.05, 14.5, 26.0, 13.0, 15.0458, 26.2833, 53.1, 9.2167, 79.2, 15.2458, 7.75, 15.85, 6.75, 11.5, 36.75, 7.7958, 34.375, 26.0, 13.0, 12.525, 66.6, 8.05, 14.5, 7.3125, 61.3792, 7.7333, 8.05, 8.6625, 69.55, 16.1, 15.75, 7.775, 8.6625, 39.6875, 20.525, 55.0, 27.9, 25.925, 56.4958, 33.5, 29.125, 11.1333, 7.925, 30.6958, 7.8542, 25.4667, 28.7125, 13.0, 0.0, 69.55, 15.05, 31.3875, 39.0, 22.025, 50.0, 15.5, 26.55, 15.5, 7.8958, 13.0, 13.0, 7.8542, 26.0, 27.7208, 146.5208, 7.75, 8.4042, 7.75, 13.0, 9.5, 69.55, 6.4958, 7.225, 8.05, 10.4625, 15.85, 18.7875, 7.75, 31.0, 7.05, 21.0, 7.25, 13.0, 7.75, 113.275, 7.925, 27.0, 76.2917, 10.5, 8.05, 13.0, 8.05, 7.8958, 90.0, 9.35, 10.5, 7.25, 13.0, 25.4667, 83.475, 7.775, 13.5, 31.3875, 10.5, 7.55, 26.0, 26.25, 10.5, 12.275, 14.4542, 15.5, 10.5, 7.125, 7.225, 90.0, 7.775, 14.5, 52.5542, 26.0, 7.25, 10.4625, 26.55, 16.1, 20.2125, 15.2458, 79.2, 86.5, 512.3292, 26.0, 7.75, 31.3875, 79.65, 0.0, 7.75, 10.5, 39.6875, 7.775, 153.4625, 135.6333, 31.0, 0.0, 19.5, 29.7, 7.75, 77.9583, 7.75, 0.0, 29.125, 20.25, 7.75, 7.8542, 9.5, 8.05, 26.0, 8.6625, 9.5, 7.8958, 13.0, 7.75, 78.85, 91.0792, 12.875, 8.85, 7.8958, 27.7208, 7.2292, 151.55, 30.5, 247.5208, 7.75, 23.25, 0.0, 12.35, 8.05, 151.55, 110.8833, 108.9, 24.0, 56.9292, 83.1583, 262.375, 26.0, 7.8958, 26.25, 7.8542, 26.0, 14.0, 164.8667, 134.5, 7.25, 7.8958, 12.35, 29.0, 69.55, 135.6333, 6.2375, 13.0, 20.525, 57.9792, 23.25, 28.5, 153.4625, 18.0, 133.65, 7.8958, 66.6, 134.5, 8.05, 35.5, 26.0, 263.0, 13.0, 13.0, 13.0, 13.0, 13.0, 16.1, 15.9, 8.6625, 9.225, 35.0, 7.2292, 17.8, 7.225, 9.5, 55.0, 13.0, 7.8792, 7.8792, 27.9, 27.7208, 14.4542, 7.05, 15.5, 7.25, 75.25, 7.2292, 7.75, 69.3, 55.4417, 6.4958, 8.05, 135.6333, 21.075, 82.1708, 7.25, 211.5, 4.0125, 7.775, 227.525, 15.7417, 7.925, 52.0, 7.8958, 73.5, 46.9, 13.0, 7.7292, 12.0, 120.0, 7.7958, 7.925, 113.275, 16.7, 7.7958, 7.8542, 26.0, 10.5, 12.65, 7.925, 8.05, 9.825, 15.85, 8.6625, 21.0, 7.75, 18.75, 7.775, 25.4667, 7.8958, 6.8583, 90.0, 0.0, 7.925, 8.05, 32.5, 13.0, 13.0, 24.15, 7.8958, 7.7333, 7.875, 14.4, 20.2125, 7.25, 26.0, 26.0, 7.75, 8.05, 26.55, 16.1, 26.0, 7.125, 55.9, 120.0, 34.375, 18.75, 263.0, 10.5, 26.25, 9.5, 7.775, 13.0, 8.1125, 81.8583, 19.5, 26.55, 19.2583, 30.5, 27.75, 19.9667, 27.75, 89.1042, 8.05, 7.8958, 26.55, 51.8625, 10.5, 7.75, 26.55, 8.05, 38.5, 13.0, 8.05, 7.05, 0.0, 26.55, 7.725, 19.2583, 7.25, 8.6625, 27.75, 13.7917, 9.8375, 52.0, 21.0, 7.0458, 7.5208, 12.2875, 46.9, 0.0, 8.05, 9.5875, 91.0792, 25.4667, 90.0, 29.7, 8.05, 15.9, 19.9667, 7.25, 30.5, 49.5042, 8.05, 14.4583, 78.2667, 15.1, 151.55, 7.7958, 8.6625, 7.75, 7.6292, 9.5875, 86.5, 108.9, 26.0, 26.55, 22.525, 56.4958, 7.75, 8.05, 26.2875, 59.4, 7.4958, 34.0208, 10.5, 24.15, 26.0, 7.8958, 93.5, 7.8958, 7.225, 57.9792, 7.2292, 7.75, 10.5, 221.7792, 7.925, 11.5, 26.0, 7.2292, 7.2292, 22.3583, 8.6625, 26.25, 26.55, 106.425, 14.5, 49.5, 71.0, 31.275, 31.275, 26.0, 106.425, 26.0, 26.0, 13.8625, 20.525, 36.75, 110.8833, 26.0, 7.8292, 7.225, 7.775, 26.55, 39.6, 227.525, 79.65, 17.4, 7.75, 7.8958, 13.5, 8.05, 8.05, 24.15, 7.8958, 21.075, 7.2292, 7.8542, 10.5, 51.4792, 26.3875, 7.75, 8.05, 14.5, 13.0, 55.9, 14.4583, 7.925, 30.0, 110.8833, 26.0, 40.125, 8.7125, 79.65, 15.0, 79.2, 8.05, 8.05, 7.125, 78.2667, 7.25, 7.75, 26.0, 24.15, 33.0, 0.0, 7.225, 56.9292, 27.0, 7.8958, 42.4, 8.05, 26.55, 15.55, 7.8958, 30.5, 41.5792, 153.4625, 31.275, 7.05, 15.5, 7.75, 8.05, 65.0, 14.4, 16.1, 39.0, 10.5, 14.4542, 52.5542, 15.7417, 7.8542, 16.1, 32.3208, 12.35, 77.9583, 7.8958, 7.7333, 30.0, 7.0542, 30.5, 0.0, 27.9, 13.0, 7.925, 26.25, 39.6875, 16.1, 7.8542, 69.3, 27.9, 56.4958, 19.2583, 76.7292, 7.8958, 35.5, 7.55, 7.55, 7.8958, 23.0, 8.4333, 7.8292, 6.75, 73.5, 7.8958, 15.5, 13.0, 113.275, 133.65, 7.225, 25.5875, 7.4958, 7.925, 73.5, 13.0, 7.775, 8.05, 52.0, 39.0, 52.0, 10.5, 13.0, 0.0, 7.775, 8.05, 9.8417, 46.9, 512.3292, 8.1375, 76.7292, 9.225, 46.9, 39.0, 41.5792, 39.6875, 10.1708, 7.7958, 211.3375, 57.0, 13.4167, 56.4958, 7.225, 26.55, 13.5, 8.05, 7.7333, 110.8833, 7.65, 227.525, 26.2875, 14.4542, 7.7417, 7.8542, 26.0, 13.5, 26.2875, 151.55, 15.2458, 49.5042, 26.55, 52.0, 9.4833, 13.0, 7.65, 227.525, 10.5, 15.5, 7.775, 33.0, 7.0542, 13.0, 13.0, 53.1, 8.6625, 21.0, 7.7375, 26.0, 7.925, 211.3375, 18.7875, 0.0, 13.0, 13.0, 16.1, 34.375, 512.3292, 7.8958, 7.8958, 30.0, 78.85, 262.375, 16.1, 7.925, 71.0, 20.25, 13.0, 53.1, 7.75, 23.0, 12.475, 9.5, 7.8958, 65.0, 14.5, 7.7958, 11.5, 8.05, 86.5, 14.5, 7.125, 7.2292, 120.0, 7.775, 77.9583, 39.6, 7.75, 24.15, 8.3625, 9.5, 7.8542, 10.5, 7.225, 23.0, 7.75, 7.75, 12.475, 7.7375, 211.3375, 7.2292, 57.0, 30.0, 23.45, 7.05, 7.25, 7.4958, 29.125, 20.575, 79.2, 7.75, 26.0, 69.55, 30.6958, 7.8958, 13.0, 25.9292, 8.6833, 7.2292, 24.15, 13.0, 26.25, 120.0, 8.5167, 6.975, 7.775, 0.0, 7.775, 13.0, 53.1, 7.8875, 24.15, 10.5, 31.275, 8.05, 0.0, 7.925, 37.0042, 6.45, 27.9, 93.5, 8.6625, 0.0, 12.475, 39.6875, 6.95, 56.4958, 37.0042, 7.75, 80.0, 14.4542, 18.75, 7.2292, 7.8542, 8.3, 83.1583, 8.6625, 8.05, 56.4958, 29.7, 7.925, 10.5, 31.0, 6.4375, 8.6625, 7.55, 69.55, 7.8958, 33.0, 89.1042, 31.275, 7.775, 15.2458, 39.4, 26.0, 9.35, 164.8667, 26.55, 19.2583, 7.2292, 14.1083, 11.5, 25.9292, 69.55, 13.0, 13.0, 13.8583, 50.4958, 9.5, 11.1333, 7.8958, 52.5542, 5.0, 9.0, 24.0, 7.225, 9.8458, 7.8958, 7.8958, 83.1583, 26.0, 7.8958, 10.5167, 10.5, 7.05, 29.125, 13.0, 30.0, 23.45, 30.0, 7.75, 7.8292, 7.0, 9.6875, 8.6625, 12.2875, 9.225, 7.6292, 29.0, 7.2292, 24.15, 7.8958, 26.0, 82.2667, 26.0, 61.175, 27.7208, 12.35, 7.225, 7.925, 7.225, 59.4, 3.1708, 31.6833, 61.3792, 262.375, 14.5, 61.9792, 7.225, 30.5, 21.6792, 26.0, 31.5, 20.575, 23.45, 57.75, 7.2292, 8.05, 8.6625, 9.5, 56.4958, 13.4167, 26.55, 7.85, 13.0, 52.5542, 7.925, 29.7, 7.75, 76.2917, 15.9, 60.0, 15.0333, 23.0, 263.0, 15.5792, 29.125, 7.8958, 7.65, 16.1, 262.375, 7.8958, 13.5, 7.75, 7.725, 262.375, 21.0, 7.8792, 42.4, 28.5375, 263.0, 7.75, 7.8958, 7.925, 27.7208, 211.5, 211.5, 8.05, 25.7, 13.0, 7.75, 15.2458, 221.7792, 26.0, 7.8958, 10.7083, 14.4542, 7.8792, 8.05, 7.75, 23.0, 13.9, 7.775, 52.0, 8.05, 26.0, 7.7958, 78.85, 7.925, 7.8542, 8.05, 55.4417, 26.0, 7.75, 7.775, 8.5167, 22.525, 7.8208, 7.75, 8.7125, 13.0, 15.0458, 7.7792, 31.6792, 7.2833, 221.7792, 14.4542, 6.4375, 16.7, 75.2417, 26.0, 15.75, 7.75, 57.75, 7.25, 7.75, 16.1, 7.7958, 23.25, 13.0, 8.05, 8.05, 28.5, 25.4667, 6.4375, 7.8958, 7.8542, 7.225, 13.0, 8.05, 46.9, 46.9, 151.55, 262.375, 26.0, 26.55, 18.0, 51.8625, 8.05, 26.55, 26.0, 83.1583, 7.8958, null, 12.1833, 31.3875, 7.55, 221.7792, 7.8542, 26.55, 13.775, 7.7333, 15.2458, 13.5, 7.0, 13.0, 22.025, 50.4958, 34.375, 27.7208, 8.9625, 7.55, 7.225, 13.9, 7.2292, 31.3875, 39.0, 36.75, 55.4417, 39.0, 83.1583, 13.0, 83.1583, 53.1, 7.75, 247.5208, 16.0, 21.0, 8.05, 69.55, 13.0, 26.0, 26.0, 14.5, 12.35, 32.5, 7.8542, 134.5, 7.775, 10.5, 8.1125, 15.5, 14.4, 227.525, 26.0, 10.5, 25.7417, 7.75, 10.5, 27.7208, 7.8958, 22.525, 7.05, 73.5, 26.0, 7.775, 42.5, 7.8792, 164.8667, 211.5, 8.05, 13.8583, 8.05, 10.5, 7.7958, 27.4458, 15.2458, 7.7958, 7.75, 15.1, 13.0, 65.0, 26.55, 6.4958, 7.8792, 71.2833, 7.8542, 75.25, 7.225, 13.0, 106.425, 27.7208, 30.0, 134.5, 7.8875, 23.45, 51.8625, 21.0, 32.5, 26.0, 14.4542, 27.75, 7.925, 136.7792, 9.325, 9.5, 7.55, 7.75, 8.05, 13.0, 7.775, 17.4, 7.8542, 23.0, 12.1833, 12.7375, 7.8958, 0.0, 7.55, 8.05, 8.6625, 75.2417, 7.75, 136.7792, 15.5, 7.225, 26.0, 10.5, 26.0, 21.0, 10.5, 8.6625, 13.775, 7.75, 15.2458, 20.2125, 7.25, 7.25, 82.2667, 7.2292, 8.05, 39.6, 6.95, 7.2292, 81.8583, 9.5, 7.8958, 41.5792, 21.6792, 45.5, 7.8542, 7.775, 15.0458, 21.0, 8.6625, 7.75, 26.55, 151.55, 9.35, 93.5, 14.1083, 8.6625, 7.225, 7.575, 7.75, 135.6333, 7.7333, 146.5208, 10.5, 7.8542, 31.5, 7.775, 7.2292, 13.0, 26.55, 211.3375, 7.05, 39.0, 79.2, 26.0, 13.0, 36.75, 29.7, 7.225, 15.7417, 7.8958, 26.0, 13.0, 7.2292, 31.5, 7.2292, 10.5, 7.5792, 69.55, 512.3292, 14.5, 7.65, 13.0, 7.2292, 13.5, 21.0, 63.3583, 10.5, 73.5, 65.0, 20.575, 26.0, 51.4792, 7.8792, 7.75, 15.55, 69.55, 37.0042, 21.0, 8.6625, 55.4417, 69.55, 14.4583, 39.6875, 59.4, 13.8583, 11.5, 134.5, 0.0, 13.0, 81.8583, 262.375, 8.6625, 11.5, 50.0, 31.3875, 7.75, 7.8792, 14.5, 16.1, 12.875, 65.0, 7.775, 13.0, 7.75, 21.075, 93.5, 39.4, 20.25, 10.5, 22.025, 60.0, 7.25, 79.2, 7.775, 7.7333, 164.8667, 21.0, 59.4, 47.1, 27.7208, 13.8625, 10.5, 211.5, 7.7208, 13.775, 7.75, 90.0, 7.775, 8.05, 108.9, 7.25, 8.05, 22.3583], \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"green\"}, \"name\": \"\", \"type\": \"box\", \"uid\": \"fa538510-ef71-47f4-a18d-446a457b61f1\", \"x\": [7.25, 7.925, 53.1, 8.05, 8.4583, 51.8625, 21.075, 11.1333, 30.0708, 16.7, 26.55, 8.05, 31.275, 7.8542, 16.0, 29.125, 13.0, 18.0, 7.225, 26.0, 13.0, 8.0292, 35.5, 21.075, 31.3875, 7.225, 7.8792, 7.8958, 27.7208, 7.75, 10.5, 52.0, 7.2292, 8.05, 18.0, 11.2417, 9.475, 21.0, 7.8958, 41.5792, 7.8792, 8.05, 15.5, 7.75, 21.6792, 17.8, 39.6875, 7.8, 26.0, 61.9792, 35.5, 10.5, 7.2292, 27.75, 46.9, 7.2292, 27.9, 27.7208, 15.2458, 10.5, 8.1583, 7.925, 8.6625, 10.5, 46.9, 14.4542, 56.4958, 7.65, 7.8958, 8.05, 29.0, 12.475, 9.0, 9.5, 7.7875, 47.1, 10.5, 15.85, 34.375, 8.05, 8.05, 8.05, 7.8542, 61.175, 20.575, 7.25, 8.05, 34.6542, 63.3583, 23.0, 26.0, 7.8958, 7.8958, 8.6542, 7.925, 7.8958, 7.65, 7.775, 7.8958, 24.15, 52.0, 14.4542, 8.05, 9.825, 14.4583, 7.925, 7.75, 21.0, 31.275, 8.05, 30.0708, 13.0, 11.2417, 7.75, 7.1417, 22.3583, 6.975, 7.8958, 7.05, 14.5, 26.0, 13.0, 15.0458, 26.2833, 53.1, 9.2167, 15.2458, 7.75, 15.85, 6.75, 11.5, 36.75, 7.7958, 34.375, 26.0, 13.0, 12.525, 8.05, 14.5, 7.3125, 61.3792, 7.7333, 8.05, 8.6625, 16.1, 15.75, 7.775, 8.6625, 39.6875, 20.525, 55.0, 27.9, 25.925, 56.4958, 33.5, 29.125, 11.1333, 7.925, 30.6958, 7.8542, 25.4667, 28.7125, 13.0, 0.0, 15.05, 31.3875, 39.0, 22.025, 50.0, 15.5, 26.55, 15.5, 7.8958, 13.0, 13.0, 7.8542, 26.0, 27.7208, 7.75, 8.4042, 7.75, 13.0, 9.5, 6.4958, 7.225, 8.05, 10.4625, 15.85, 18.7875, 7.75, 31.0, 7.05, 21.0, 7.25, 13.0, 7.75, 7.925, 27.0, 10.5, 8.05, 13.0, 8.05, 7.8958, 9.35, 10.5, 7.25, 13.0, 25.4667, 7.775, 13.5, 31.3875, 10.5, 7.55, 26.0, 26.25, 10.5, 12.275, 14.4542, 15.5, 10.5, 7.125, 7.225, 7.775, 14.5, 52.5542, 26.0, 7.25, 10.4625, 26.55, 16.1, 20.2125, 15.2458, 26.0, 7.75, 31.3875, 0.0, 7.75, 10.5, 39.6875, 7.775, 31.0, 0.0, 19.5, 29.7, 7.75, 7.75, 0.0, 29.125, 20.25, 7.75, 7.8542, 9.5, 8.05, 26.0, 8.6625, 9.5, 7.8958, 13.0, 7.75, 12.875, 8.85, 7.8958, 27.7208, 7.2292, 30.5, 7.75, 23.25, 0.0, 12.35, 8.05, 24.0, 56.9292, 26.0, 7.8958, 26.25, 7.8542, 26.0, 14.0, 7.25, 7.8958, 12.35, 29.0, 6.2375, 13.0, 20.525, 57.9792, 23.25, 28.5, 18.0, 7.8958, 8.05, 35.5, 26.0, 13.0, 13.0, 13.0, 13.0, 13.0, 16.1, 15.9, 8.6625, 9.225, 35.0, 7.2292, 17.8, 7.225, 9.5, 55.0, 13.0, 7.8792, 7.8792, 27.9, 27.7208, 14.4542, 7.05, 15.5, 7.25, 7.2292, 7.75, 55.4417, 6.4958, 8.05, 21.075, 7.25, 4.0125, 7.775, 15.7417, 7.925, 52.0, 7.8958, 46.9, 13.0, 7.7292, 12.0, 7.7958, 7.925, 16.7, 7.7958, 7.8542, 26.0, 10.5, 12.65, 7.925, 8.05, 9.825, 15.85, 8.6625, 21.0, 7.75, 18.75, 7.775, 25.4667, 7.8958, 6.8583, 0.0, 7.925, 8.05, 32.5, 13.0, 13.0, 24.15, 7.8958, 7.7333, 7.875, 14.4, 20.2125, 7.25, 26.0, 26.0, 7.75, 8.05, 26.55, 16.1, 26.0, 7.125, 55.9, 34.375, 18.75, 10.5, 26.25, 9.5, 7.775, 13.0, 8.1125, 19.5, 26.55, 19.2583, 30.5, 27.75, 19.9667, 27.75, 8.05, 7.8958, 26.55, 51.8625, 10.5, 7.75, 26.55, 8.05, 38.5, 13.0, 8.05, 7.05, 0.0, 26.55, 7.725, 19.2583, 7.25, 8.6625, 27.75, 13.7917, 9.8375, 52.0, 21.0, 7.0458, 7.5208, 12.2875, 46.9, 0.0, 8.05, 9.5875, 25.4667, 29.7, 8.05, 15.9, 19.9667, 7.25, 30.5, 49.5042, 8.05, 14.4583, 15.1, 7.7958, 8.6625, 7.75, 7.6292, 9.5875, 26.0, 26.55, 22.525, 56.4958, 7.75, 8.05, 26.2875, 59.4, 7.4958, 34.0208, 10.5, 24.15, 26.0, 7.8958, 7.8958, 7.225, 57.9792, 7.2292, 7.75, 10.5, 7.925, 11.5, 26.0, 7.2292, 7.2292, 22.3583, 8.6625, 26.25, 26.55, 14.5, 49.5, 31.275, 31.275, 26.0, 26.0, 26.0, 13.8625, 20.525, 36.75, 26.0, 7.8292, 7.225, 7.775, 26.55, 39.6, 17.4, 7.75, 7.8958, 13.5, 8.05, 8.05, 24.15, 7.8958, 21.075, 7.2292, 7.8542, 10.5, 51.4792, 26.3875, 7.75, 8.05, 14.5, 13.0, 55.9, 14.4583, 7.925, 30.0, 26.0, 40.125, 8.7125, 15.0, 8.05, 8.05, 7.125, 7.25, 7.75, 26.0, 24.15, 33.0, 0.0, 7.225, 56.9292, 27.0, 7.8958, 42.4, 8.05, 26.55, 15.55, 7.8958, 30.5, 41.5792, 31.275, 7.05, 15.5, 7.75, 8.05, 65.0, 14.4, 16.1, 39.0, 10.5, 14.4542, 52.5542, 15.7417, 7.8542, 16.1, 32.3208, 12.35, 7.8958, 7.7333, 30.0, 7.0542, 30.5, 0.0, 27.9, 13.0, 7.925, 26.25, 39.6875, 16.1, 7.8542, 27.9, 56.4958, 19.2583, 7.8958, 35.5, 7.55, 7.55, 7.8958, 23.0, 8.4333, 7.8292, 6.75, 7.8958, 15.5, 13.0, 7.225, 25.5875, 7.4958, 7.925, 13.0, 7.775, 8.05, 52.0, 39.0, 52.0, 10.5, 13.0, 0.0, 7.775, 8.05, 9.8417, 46.9, 8.1375, 9.225, 46.9, 39.0, 41.5792, 39.6875, 10.1708, 7.7958, 57.0, 13.4167, 56.4958, 7.225, 26.55, 13.5, 8.05, 7.7333, 7.65, 26.2875, 14.4542, 7.7417, 7.8542, 26.0, 13.5, 26.2875, 15.2458, 49.5042, 26.55, 52.0, 9.4833, 13.0, 7.65, 10.5, 15.5, 7.775, 33.0, 7.0542, 13.0, 13.0, 53.1, 8.6625, 21.0, 7.7375, 26.0, 7.925, 18.7875, 0.0, 13.0, 13.0, 16.1, 34.375, 7.8958, 7.8958, 30.0, 16.1, 7.925, 20.25, 13.0, 53.1, 7.75, 23.0, 12.475, 9.5, 7.8958, 65.0, 14.5, 7.7958, 11.5, 8.05, 14.5, 7.125, 7.2292, 7.775, 39.6, 7.75, 24.15, 8.3625, 9.5, 7.8542, 10.5, 7.225, 23.0, 7.75, 7.75, 12.475, 7.7375, 7.2292, 57.0, 30.0, 23.45, 7.05, 7.25, 7.4958, 29.125, 20.575, 7.75, 26.0, 30.6958, 7.8958, 13.0, 25.9292, 8.6833, 7.2292, 24.15, 13.0, 26.25, 8.5167, 6.975, 7.775, 0.0, 7.775, 13.0, 53.1, 7.8875, 24.15, 10.5, 31.275, 8.05, 0.0, 7.925, 37.0042, 6.45, 27.9, 8.6625, 0.0, 12.475, 39.6875, 6.95, 56.4958, 37.0042, 7.75, 14.4542, 18.75, 7.2292, 7.8542, 8.3, 8.6625, 8.05, 56.4958, 29.7, 7.925, 10.5, 31.0, 6.4375, 8.6625, 7.55, 7.8958, 33.0, 31.275, 7.775, 15.2458, 39.4, 26.0, 9.35, 26.55, 19.2583, 7.2292, 14.1083, 11.5, 25.9292, 13.0, 13.0, 13.8583, 50.4958, 9.5, 11.1333, 7.8958, 52.5542, 5.0, 9.0, 24.0, 7.225, 9.8458, 7.8958, 7.8958, 26.0, 7.8958, 10.5167, 10.5, 7.05, 29.125, 13.0, 30.0, 23.45, 30.0, 7.75, 7.8292, 7.0, 9.6875, 8.6625, 12.2875, 9.225, 7.6292, 29.0, 7.2292, 24.15, 7.8958, 26.0, 26.0, 61.175, 27.7208, 12.35, 7.225, 7.925, 7.225, 59.4, 3.1708, 31.6833, 61.3792, 14.5, 61.9792, 7.225, 30.5, 21.6792, 26.0, 31.5, 20.575, 23.45, 57.75, 7.2292, 8.05, 8.6625, 9.5, 56.4958, 13.4167, 26.55, 7.85, 13.0, 52.5542, 7.925, 29.7, 7.75, 15.9, 60.0, 15.0333, 23.0, 15.5792, 29.125, 7.8958, 7.65, 16.1, 7.8958, 13.5, 7.75, 7.725, 21.0, 7.8792, 42.4, 28.5375, 7.75, 7.8958, 7.925, 27.7208, 8.05, 25.7, 13.0, 7.75, 15.2458, 26.0, 7.8958, 10.7083, 14.4542, 7.8792, 8.05, 7.75, 23.0, 13.9, 7.775, 52.0, 8.05, 26.0, 7.7958, 7.925, 7.8542, 8.05, 55.4417, 26.0, 7.75, 7.775, 8.5167, 22.525, 7.8208, 7.75, 8.7125, 13.0, 15.0458, 7.7792, 31.6792, 7.2833, 14.4542, 6.4375, 16.7, 26.0, 15.75, 7.75, 57.75, 7.25, 7.75, 16.1, 7.7958, 23.25, 13.0, 8.05, 8.05, 28.5, 25.4667, 6.4375, 7.8958, 7.8542, 7.225, 13.0, 8.05, 46.9, 46.9, 26.0, 26.55, 18.0, 51.8625, 8.05, 26.55, 26.0, 7.8958, null, 12.1833, 31.3875, 7.55, 7.8542, 26.55, 13.775, 7.7333, 15.2458, 13.5, 7.0, 13.0, 22.025, 50.4958, 34.375, 27.7208, 8.9625, 7.55, 7.225, 13.9, 7.2292, 31.3875, 39.0, 36.75, 55.4417, 39.0, 13.0, 53.1, 7.75, 16.0, 21.0, 8.05, 13.0, 26.0, 26.0, 14.5, 12.35, 32.5, 7.8542, 7.775, 10.5, 8.1125, 15.5, 14.4, 26.0, 10.5, 25.7417, 7.75, 10.5, 27.7208, 7.8958, 22.525, 7.05, 26.0, 7.775, 42.5, 7.8792, 8.05, 13.8583, 8.05, 10.5, 7.7958, 27.4458, 15.2458, 7.7958, 7.75, 15.1, 13.0, 65.0, 26.55, 6.4958, 7.8792, 7.8542, 7.225, 13.0, 27.7208, 30.0, 7.8875, 23.45, 51.8625, 21.0, 32.5, 26.0, 14.4542, 27.75, 7.925, 9.325, 9.5, 7.55, 7.75, 8.05, 13.0, 7.775, 17.4, 7.8542, 23.0, 12.1833, 12.7375, 7.8958, 0.0, 7.55, 8.05, 8.6625, 7.75, 15.5, 7.225, 26.0, 10.5, 26.0, 21.0, 10.5, 8.6625, 13.775, 7.75, 15.2458, 20.2125, 7.25, 7.25, 7.2292, 8.05, 39.6, 6.95, 7.2292, 9.5, 7.8958, 41.5792, 21.6792, 45.5, 7.8542, 7.775, 15.0458, 21.0, 8.6625, 7.75, 26.55, 9.35, 14.1083, 8.6625, 7.225, 7.575, 7.75, 7.7333, 10.5, 7.8542, 31.5, 7.775, 7.2292, 13.0, 26.55, 7.05, 39.0, 26.0, 13.0, 36.75, 29.7, 7.225, 15.7417, 7.8958, 26.0, 13.0, 7.2292, 31.5, 7.2292, 10.5, 7.5792, 14.5, 7.65, 13.0, 7.2292, 13.5, 21.0, 63.3583, 10.5, 65.0, 20.575, 26.0, 51.4792, 7.8792, 7.75, 15.55, 37.0042, 21.0, 8.6625, 55.4417, 14.4583, 39.6875, 59.4, 13.8583, 11.5, 0.0, 13.0, 8.6625, 11.5, 50.0, 31.3875, 7.75, 7.8792, 14.5, 16.1, 12.875, 65.0, 7.775, 13.0, 7.75, 21.075, 39.4, 20.25, 10.5, 22.025, 60.0, 7.25, 7.775, 7.7333, 21.0, 59.4, 47.1, 27.7208, 13.8625, 10.5, 7.7208, 13.775, 7.75, 7.775, 8.05, 7.25, 8.05, 22.3583], \"xaxis\": \"x2\", \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Fare Distribution with Outliers\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Fare Distribution without Outliers\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.375, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 800, \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"width\": 870, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Fare</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.625, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.375]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('7b3f5f43-d255-42bb-9105-c1965d27cf25');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 82,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 47,
                "o_idx": 0
            }
        },
        {
            "source": "# 7.Imputing Missing Variables <a id=\"7\"></a>\nThe simpliest way to impute missing values of a variable is to impute its missing values with its mean, median or mode depending on its distribution and variable type(categorical or numerical). By now, we should have a good idea about the distribution of the variables and the presence of outliers in those variables. For categorical variables mode-imputation is performed and for numerical variable mean-impuation is performed if its distribution is symmetric(or almost symmetric or normal like Age). On the other hand, for a variable with skewed distribution and outliers (like Fare), meadian-imputation is recommended as median is more immune to outliers than mean. \n\nHowever, one clear disadvantage of using mean, median or mode to impute missing values is the addition of bias if the amount of missing values is significant (like Age). So simply replacing them with the mean or the median age might not be the best solution since the age may differ by groups and categories of passengers.\n\nTo solve this, we can group our data by some variables that have no missing values and for each subset compute the median age to impute the missing values. Or we can build a linear regression model that will predict missing values of Age using the features that have no missing values. These two methods may result in better accuracy without high bias, unless a missing value is expected to have a very high variance. We will show the former method of imputation.",
            "mc_idx": 83,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"#1.Create a function to calculate missing values\"\"\"\ndef calculateMissingValues(variable):\n    \"\"\"Calculates missing values of a variable.\"\"\"\n    \n    return merged.isna().sum()[merged.isna().sum()>0] # Returns only columns with missing values\n\n\n\n\"\"\"\"#2.Create a function to plot scatter plot.\nThis can also be used to plot missing values\"\"\"\ndef plotScatterPlot(x, y, title, yaxis):\n    trace = go.Scatter(\n    x = x,\n    y = y,\n    mode = \"markers\",\n    marker = dict(color = y, size = 35, showscale = True, colorscale = \"Rainbow\"))\n    layout = go.Layout(hovermode= \"closest\",\n                       title = title,\n                       yaxis = dict(title = yaxis),\n                       height=600,\n                       width=900,\n                       showlegend=False,\n                        paper_bgcolor=\"rgb(243, 243, 243)\",\n                        plot_bgcolor=\"rgb(243, 243, 243)\"\n                      )\n    fig = go.Figure(data = [trace], layout = layout)\n    return fig.show()      ",
            "mc_idx": 84,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2727272727272727,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.09090909090909091,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1,
                    "variable": 2
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".scatter(": 1,
                    "missing values": 4,
                    "columns": 1,
                    "size": 1,
                    ".isna": 2,
                    ".sum": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    ".scatter(": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    48,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 84,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 48,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Plot variables with their corresponding missing values.\"\"\"\nplotScatterPlot(calculateMissingValues(merged).index,\n               calculateMissingValues(merged),\n               \"Features with Missing Values\",\n               \"Missing Values\")",
            "mc_idx": 85,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.3333333333333333,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "missing values": 3
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    49,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"07c28866-ede4-4712-bd03-5b0380561a19\" class=\"plotly-graph-div\" style=\"height:600px; width:900px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"07c28866-ede4-4712-bd03-5b0380561a19\")) {\n                    Plotly.newPlot(\n                        '07c28866-ede4-4712-bd03-5b0380561a19',\n                        [{\"marker\": {\"color\": [418, 263, 1, 1014, 2], \"colorscale\": \"Rainbow\", \"showscale\": true, \"size\": 35}, \"mode\": \"markers\", \"type\": \"scatter\", \"uid\": \"90a201b3-14a9-4984-895a-9382cee4d172\", \"x\": [\"Survived\", \"Age\", \"Fare\", \"Cabin\", \"Embarked\"], \"y\": [418, 263, 1, 1014, 2]}],\n                        {\"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Features with Missing Values\"}, \"width\": 900, \"yaxis\": {\"title\": {\"text\": \"Missing Values\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('07c28866-ede4-4712-bd03-5b0380561a19');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 85,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 49,
                "o_idx": 0
            }
        },
        {
            "source": "**The above plot shows the most missing values for Cabin, Survived, followed by Age, Embarked and Fare. Since we created a new variable cabinProcessed off Cabin, we don't need to impute Cabin.**",
            "mc_idx": 86,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** \n1. Age has 263 missing values.\n2. Fare has only 1.\n3. Cabin has a whopping 1014 missing values.\n4. Embarked has just 2 missing values.\n5. **Finally Survived has missing values (due to concatenation of train and test set) that we would predict learning from the train dataset.**\n\n**Remember we have total 1309 observations except variable Survived.**\n\n## 7.1 Impute Embarked & Fare <a id=\"7.1\"></a>",
            "mc_idx": 87,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Impute missing values of Embarked. Embarked is a categorical variable where S is the most frequent.\"\"\"\nmerged.Embarked.fillna(value=\"S\", inplace = True)\n\n\"\"\"Impute missing values of Fare. Fare is a numerical variable with outliers. Hence it will be imputed by median.\"\"\"\nmerged.Fare.fillna(value=merged.Fare.median(), inplace = True)",
            "mc_idx": 88,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.4,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.8,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 2
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "missing values": 2,
                    "outliers": 1,
                    ".median": 2
                },
                "Data_Transform": {
                    ".fillna(": 2,
                    ".fillna": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    50,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 88,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 50,
                "o_idx": 0
            }
        },
        {
            "source": "## 7.2 Impute Age <a id=\"7.2\"></a>\nTo impute Age with grouped median, we need to know which features are highly correlated with Age. Let's find out the variables correlated with Age.",
            "mc_idx": 89,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Create a boxplot to view the variables correlated with Age. First extract the variables we're interested in.\"\"\"\ntoSearch = merged.loc[:, [\"Sex\", \"Pclass\", \"Embarked\", \"nameProcessed\", \"familySize\", \"Parch\", \n                             \"SibSp\", \"cabinProcessed\", \"ticketProcessed\"]]\n\nfig, axes = plt.subplots(nrows = 3, ncols = 3, figsize = (25,25))\nfor ax, column in zip(axes.flatten(), toSearch.columns):\n    sns.boxplot(x = toSearch[column], y = merged.Age, ax = ax)\n    ax.set_title(column, fontsize = 23)\n    ax.tick_params(axis = \"both\", which = \"major\", labelsize = 20)\n    ax.tick_params(axis = \"both\", which = \"minor\", labelsize = 20)\n    ax.set_ylabel(\"Age\", fontsize = 20)\n    ax.set_xlabel(\"\")\nfig.suptitle(\"Variables Associated with Age\", fontsize = 30)\nfig.tight_layout(rect = [0, 0.03, 1, 0.95])",
            "mc_idx": 90,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2727272727272727,
                "Data_Extraction": 0.09090909090909091,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.18181818181818182,
                "Visualization": 0.18181818181818182,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 3
                },
                "Data_Extraction": {
                    "extract": 1
                },
                "Exploratory_Data_Analysis": {
                    ".boxplot(": 2,
                    "sns.": 1,
                    "columns": 1,
                    "size": 7
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {
                    ".boxplot(": 1,
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c051_o000_image_0.png",
                    51,
                    0,
                    0
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1800x1800 with 9 Axes>"
                    ]
                },
                "mc_idx": 90,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 51,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** \n1. Age distribution seems to be the same in male and female subpopulations of Sex and S, C, Q subpopulations of Embarked. So Sex and Embarked aren't good predictors for Age.\n2. On the other hand, Age distribution seems to be distinct in Pclass's 1, 2 and 3 subpopulations, so Pclass is informative to predict Age.\n3. Finally, Age distribution seems to be distinct in different categories for nameProcessed, familySize, SibSp, Parch, and cabinProcessed. So they might be good predictors for Age as well.",
            "mc_idx": 91,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Let's plot correlation heatmap to see which variable is highly correlated with Age and if our \nboxplot interpretation holds true. We need to convert categorical variable into numerical to plot \ncorrelation heatmap. So convert categorical variables into numerical.\"\"\"\nfrom sklearn.preprocessing import LabelEncoder\ntoSearch = toSearch.agg(LabelEncoder().fit_transform)\ntoSearch[\"Age\"] = merged.Age # Inserting Age in dataframe \"toSearch\".\ntoSearch = toSearch.set_index(\"Age\").reset_index() # Move Age column at index 0.\n\n# Now create the correlation heatmap\nfig,ax = plt.subplots(nrows=1, ncols=1, figsize=(15,6))\nsns.heatmap(toSearch.corr(), cmap =\"YlGnBu\", annot=True, annot_kws={\"size\":14}, ax=ax)\nax.set_title(\"Variables correlated with Age\", fontsize = 20)\nax.tick_params(axis = \"both\", which = \"major\", labelsize = 14)\nax.tick_params(axis = \"both\", which = \"minor\", labelsize = 14)\nplt.show()",
            "mc_idx": 92,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.6,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.8,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.2,
                "Visualization": 0.3,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 1,
                    ".show": 1,
                    "variable": 4
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".corr": 2,
                    "sns.heatmap": 1,
                    ".heatmap(": 1,
                    "sns.": 1,
                    "size": 5
                },
                "Data_Transform": {
                    "fit_transform": 1,
                    "transform": 1,
                    "labelencoder": 4,
                    ".reset_index": 1,
                    ".set_index": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {
                    "sns.heatmap": 1,
                    ".heatmap(": 1,
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c052_o000_image_1.png",
                    52,
                    0,
                    1
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1080x432 with 2 Axes>"
                    ]
                },
                "mc_idx": 92,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 52,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** As expected Sex, Embarked, and ticketProcessed have the weakest correlation with Age what we could guess beforehand from boxplot. Parch and familySize are moderately correlated with Age. nameProcessed, Pclass, Cabin, and SibSp have the highest correlation with Age. But we are gonna use nameProcessed and Pclass only in order to impute Age since they have the strongest correlation with Age. So the tactic is to impute missing values of Age with the median age of similar rows according to nameProcessed and Pclass.",
            "mc_idx": 93,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Impute Age with median of respective columns (i.e., nameProcessed and Pclass).\"\"\"\nmerged.Age = merged.groupby([\"nameProcessed\", \"Pclass\"])[\"Age\"].transform(lambda x: x.fillna(x.median()))\n\n\"\"\"So by now we should have variables with no missing values.\"\"\"\nbold(\"Missing Values after Imputation:\")\ndisplay(merged.isnull().sum())",
            "mc_idx": 94,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.125,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.5,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "missing values": 2,
                    ".median": 2,
                    "columns": 1,
                    ".isnull": 1,
                    ".sum": 1,
                    ".groupby": 1
                },
                "Data_Transform": {
                    ".groupby(": 1,
                    ".fillna(": 1,
                    "transform": 1,
                    ".fillna": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    53,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "PassengerId           0\nSurvived            418\nPclass                0\nName                  0\nSex                   0\nAge                   0\nSibSp                 0\nParch                 0\nTicket                0\nFare                  0\nCabin              1014\nEmbarked              0\ncabinProcessed        0\nnameProcessed         0\nfamilySize            0\nticketProcessed       0\ndtype: int64"
                    ]
                },
                "mc_idx": 94,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 53,
                "o_idx": 1
            }
        },
        {
            "source": "# 8.Bivariate Analysis <a id=\"8\"></a>\nBeing the most important part, bivariate analysis tries to find the relationship between two variables. We will look for correlation or association between our predictor and target variables. Bivariate analysis is performed for any combination of categorical and numerical variables. The combination can be: Numerical & Numerical, Numerical & Categorical and Categorical & Categorical. Different methods are used to tackle these combinations during analysis process. The methods are:\n1. Numerical & Numerical: Pearson's correlation, or Spearman correlation (the later doesn't require normal distribution).\n2. Numerical & Categorical: Point biserial correlation (only  if categorical variable is binary type), or ANOVA test. For this problem, you can use either biserial correlation or ANOVA. But I will perform both test just to learn because ANOVA will come in handy if categorical variable has more than two classes.\n3. Categorical & Categorical: We would use Chi-square test for bivariate analysis between categorical variables.\n\n## 8.1 Numerical & Categorical Variables <a id=\"8.1\"></a>\nFirst we create a boxplot between our numerical and categorical variables to check if the distribution of numerical variable is distinct in different classes of nominal variables. Then we find the mean of numerical variable for every class of categorical variable. Again we plot a histogram of numerical variable for every class of categorical variable. Finally anova or point biserial correlation (in case of two class categorical variable) is calculated to find association between nominal and numerical variables.   ",
            "mc_idx": 95,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Let's split the train and test data for bivariate analysis since test data has no Survived values. We need our target variable without missing values to conduct the association test with predictor variables.\"\"\"\ndf_train = merged.iloc[:891, :]\ndf_test = merged.iloc[891:, :]\ndf_test = df_test.drop(columns = [\"Survived\"], axis = 1)\n\n\"\"\"#1.Create a function that creates boxplot between categorical and numerical variables and calculates biserial correlation.\"\"\"\ndef boxplotAndCorrelation(numVariable,catVariable=df_train.Survived):\n    \"\"\"Return boxplot between a categorical and numerical variable. Also calculates biserial correlation.\n    numVariable = a numerical variable of interest.\"\"\"\n    \n    # Calculate point biserial correlation and p value\n    biserialCorr = stats.pointbiserialr(numVariable,catVariable)[0].round(2)\n    pValue = stats.pointbiserialr(numVariable,catVariable)[1].round(5)\n    \n    # Create subplot object.\n    fig = make_subplots(\n        rows=1,\n        cols=1,\n        print_grid=False,\n    )\n    \n    # This trace plots boxplot of categorical variable vs numerical variable\n    fig.add_trace(\n        go.Box(\n            x = catVariable,\n            y = numVariable,\n            marker_color=\"lightseagreen\",\n            ))\n    \n    \n    # Update layout\n    fig.layout.update(\n        height=500, \n        width=900,\n        showlegend=False,\n        title_text= f\"Association between {catVariable.name} and {numVariable.name} (corr: {biserialCorr}, p: {pValue})\",\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n    \n    # Update axes\n    fig.layout.xaxis1.update(title=f\"<b>{catVariable.name}</b>\")\n    fig.layout.yaxis1.update(title=f\"<b>{numVariable.name}</b>\")\n    return fig.show()\n\n\n\"\"\"#2.Create another function to calculate mean when grouped by categorical variable. And also plot the grouped mean.\"\"\"\ndef numGroupedByCat(numVariable,catVariable=df_train.Survived):\n    \"\"\"Returns a barplot showing mean of numerical variable across the class of categorical variable.\"\"\"\n    \n    # Calculates mean across different classes of categorical variable\n    numGroupedByCat = numVariable.groupby(catVariable).mean().round(2)\n    \n    # Create subplot object.\n    fig = make_subplots(\n        rows=1,\n        cols=1,\n        print_grid=False,\n    )\n    \n    # This trace plots barplot\n    fig.add_trace(\n        go.Bar(\n            x = numGroupedByCat.index,\n            y = numGroupedByCat,\n            text=numGroupedByCat,\n            hoverinfo=\"x+y\",\n            textposition=\"auto\",\n            textfont=dict(family=\"sans serif\",size=15)\n        ))\n    \n    # Update layout\n    fig.layout.update(\n        height=500, \n        width=900,\n        showlegend=False,\n        title_text= f\"Mean {numVariable.name} across {catVariable.name}\",\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n    \n    # Update axes\n    fig.layout.xaxis1.update(title=f\"<b>{catVariable.name}</b>\")\n    fig.layout.yaxis1.update(title=f\"<b>Mean {numVariable.name}</b>\")\n    return fig.show()\n\n    \n\"\"\"#3.This function plots histogram of numerical variable for every class of categorical variable.\"\"\"\ndef numHistByCat(numVariable,catVariable=df_train.Survived):\n    \"\"\"Returns numerical variable distribution across classes of categorical variable.\"\"\"\n    fig,ax = plt.subplots(1,1,figsize = (18,7))\n    font_size = 15\n    title_size = 18\n    numVariable[catVariable==1].hist(bins=50,color=\"green\", label = \"survived\", grid = False, alpha=0.5)\n    numVariable[catVariable==0].hist(bins=50,color=\"red\", label = \"died\", grid = False, alpha=0.5)\n    ax.set_yticks([])\n    ax.tick_params(axis=\"x\", labelsize=font_size)\n    ax.set_xlabel(f\"{numVariable.name}\", fontsize = font_size)\n    ax.set_title(f\"{numVariable.name} Distribution of Survivors vs Victims\", fontsize = title_size)\n    plt.legend()\n    return plt.show()\n\n   \n\"\"\"#4.Create a function to calculate anova between numerical and categorical variable.\"\"\"\ndef calculateAnova(numVariable, catVariable=df_train.Survived):\n    \"\"\"Returns f statistics and p value after anova calculation.\"\"\"\n    \n    groupNumVariableByCatVariable1 = numVariable[catVariable==1] # Group our numerical variable by categorical variable(1). Group Fair by survivors\n    groupNumVariableByCatVariable0 = numVariable[catVariable==0] # Group our numerical variable by categorical variable(0). Group Fare by victims\n    # Calculate one way anova\n    fValue, pValue = stats.f_oneway(groupNumVariableByCatVariable1, groupNumVariableByCatVariable0) # Calculate f statistics and p value\n    return f\"Anova Result between {numVariable.name} & {catVariable.name}: f=> {fValue}, p=> {pValue}\"",
            "mc_idx": 96,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.27941176470588236,
                "Data_Transform": 0.10294117647058823,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.014705882352941176,
                "Visualization": 0.04411764705882353,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 3,
                    "variable": 65
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".hist(": 2,
                    ".bar(": 1,
                    "missing values": 1,
                    ".mean(": 1,
                    "info": 1,
                    "columns": 1,
                    "size": 10,
                    ".mean": 1,
                    ".groupby": 1
                },
                "Data_Transform": {
                    ".groupby(": 1,
                    ".drop": 1,
                    ".add": 2,
                    ".round": 3
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 1
                },
                "Visualization": {
                    ".hist(": 2,
                    ".bar(": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    54,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 96,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 54,
                "o_idx": 0
            }
        },
        {
            "source": "### 8.1.1 Fare & Survived <a id=\"8.1.1\"></a>",
            "mc_idx": 97,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Create a boxplot to visualize the strength of association of Survived with Fare. Also calculate biserial correlation.\"\"\"\nboxplotAndCorrelation(df_train.Fare)",
            "mc_idx": 98,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Visualization",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "visualize": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    55,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"b00d8582-d878-4b7d-8992-7f9922221173\" class=\"plotly-graph-div\" style=\"height:500px; width:900px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"b00d8582-d878-4b7d-8992-7f9922221173\")) {\n                    Plotly.newPlot(\n                        'b00d8582-d878-4b7d-8992-7f9922221173',\n                        [{\"marker\": {\"color\": \"lightseagreen\"}, \"type\": \"box\", \"uid\": \"56fa6ee9-61fe-4869-98ef-f156a9f0a74a\", \"x\": [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0], \"y\": [7.25, 71.2833, 7.925, 53.1, 8.05, 8.4583, 51.8625, 21.075, 11.1333, 30.0708, 16.7, 26.55, 8.05, 31.275, 7.8542, 16.0, 29.125, 13.0, 18.0, 7.225, 26.0, 13.0, 8.0292, 35.5, 21.075, 31.3875, 7.225, 263.0, 7.8792, 7.8958, 27.7208, 146.5208, 7.75, 10.5, 82.1708, 52.0, 7.2292, 8.05, 18.0, 11.2417, 9.475, 21.0, 7.8958, 41.5792, 7.8792, 8.05, 15.5, 7.75, 21.6792, 17.8, 39.6875, 7.8, 76.7292, 26.0, 61.9792, 35.5, 10.5, 7.2292, 27.75, 46.9, 7.2292, 80.0, 83.475, 27.9, 27.7208, 15.2458, 10.5, 8.1583, 7.925, 8.6625, 10.5, 46.9, 73.5, 14.4542, 56.4958, 7.65, 7.8958, 8.05, 29.0, 12.475, 9.0, 9.5, 7.7875, 47.1, 10.5, 15.85, 34.375, 8.05, 263.0, 8.05, 8.05, 7.8542, 61.175, 20.575, 7.25, 8.05, 34.6542, 63.3583, 23.0, 26.0, 7.8958, 7.8958, 77.2875, 8.6542, 7.925, 7.8958, 7.65, 7.775, 7.8958, 24.15, 52.0, 14.4542, 8.05, 9.825, 14.4583, 7.925, 7.75, 21.0, 247.5208, 31.275, 73.5, 8.05, 30.0708, 13.0, 77.2875, 11.2417, 7.75, 7.1417, 22.3583, 6.975, 7.8958, 7.05, 14.5, 26.0, 13.0, 15.0458, 26.2833, 53.1, 9.2167, 79.2, 15.2458, 7.75, 15.85, 6.75, 11.5, 36.75, 7.7958, 34.375, 26.0, 13.0, 12.525, 66.6, 8.05, 14.5, 7.3125, 61.3792, 7.7333, 8.05, 8.6625, 69.55, 16.1, 15.75, 7.775, 8.6625, 39.6875, 20.525, 55.0, 27.9, 25.925, 56.4958, 33.5, 29.125, 11.1333, 7.925, 30.6958, 7.8542, 25.4667, 28.7125, 13.0, 0.0, 69.55, 15.05, 31.3875, 39.0, 22.025, 50.0, 15.5, 26.55, 15.5, 7.8958, 13.0, 13.0, 7.8542, 26.0, 27.7208, 146.5208, 7.75, 8.4042, 7.75, 13.0, 9.5, 69.55, 6.4958, 7.225, 8.05, 10.4625, 15.85, 18.7875, 7.75, 31.0, 7.05, 21.0, 7.25, 13.0, 7.75, 113.275, 7.925, 27.0, 76.2917, 10.5, 8.05, 13.0, 8.05, 7.8958, 90.0, 9.35, 10.5, 7.25, 13.0, 25.4667, 83.475, 7.775, 13.5, 31.3875, 10.5, 7.55, 26.0, 26.25, 10.5, 12.275, 14.4542, 15.5, 10.5, 7.125, 7.225, 90.0, 7.775, 14.5, 52.5542, 26.0, 7.25, 10.4625, 26.55, 16.1, 20.2125, 15.2458, 79.2, 86.5, 512.3292, 26.0, 7.75, 31.3875, 79.65, 0.0, 7.75, 10.5, 39.6875, 7.775, 153.4625, 135.6333, 31.0, 0.0, 19.5, 29.7, 7.75, 77.9583, 7.75, 0.0, 29.125, 20.25, 7.75, 7.8542, 9.5, 8.05, 26.0, 8.6625, 9.5, 7.8958, 13.0, 7.75, 78.85, 91.0792, 12.875, 8.85, 7.8958, 27.7208, 7.2292, 151.55, 30.5, 247.5208, 7.75, 23.25, 0.0, 12.35, 8.05, 151.55, 110.8833, 108.9, 24.0, 56.9292, 83.1583, 262.375, 26.0, 7.8958, 26.25, 7.8542, 26.0, 14.0, 164.8667, 134.5, 7.25, 7.8958, 12.35, 29.0, 69.55, 135.6333, 6.2375, 13.0, 20.525, 57.9792, 23.25, 28.5, 153.4625, 18.0, 133.65, 7.8958, 66.6, 134.5, 8.05, 35.5, 26.0, 263.0, 13.0, 13.0, 13.0, 13.0, 13.0, 16.1, 15.9, 8.6625, 9.225, 35.0, 7.2292, 17.8, 7.225, 9.5, 55.0, 13.0, 7.8792, 7.8792, 27.9, 27.7208, 14.4542, 7.05, 15.5, 7.25, 75.25, 7.2292, 7.75, 69.3, 55.4417, 6.4958, 8.05, 135.6333, 21.075, 82.1708, 7.25, 211.5, 4.0125, 7.775, 227.525, 15.7417, 7.925, 52.0, 7.8958, 73.5, 46.9, 13.0, 7.7292, 12.0, 120.0, 7.7958, 7.925, 113.275, 16.7, 7.7958, 7.8542, 26.0, 10.5, 12.65, 7.925, 8.05, 9.825, 15.85, 8.6625, 21.0, 7.75, 18.75, 7.775, 25.4667, 7.8958, 6.8583, 90.0, 0.0, 7.925, 8.05, 32.5, 13.0, 13.0, 24.15, 7.8958, 7.7333, 7.875, 14.4, 20.2125, 7.25, 26.0, 26.0, 7.75, 8.05, 26.55, 16.1, 26.0, 7.125, 55.9, 120.0, 34.375, 18.75, 263.0, 10.5, 26.25, 9.5, 7.775, 13.0, 8.1125, 81.8583, 19.5, 26.55, 19.2583, 30.5, 27.75, 19.9667, 27.75, 89.1042, 8.05, 7.8958, 26.55, 51.8625, 10.5, 7.75, 26.55, 8.05, 38.5, 13.0, 8.05, 7.05, 0.0, 26.55, 7.725, 19.2583, 7.25, 8.6625, 27.75, 13.7917, 9.8375, 52.0, 21.0, 7.0458, 7.5208, 12.2875, 46.9, 0.0, 8.05, 9.5875, 91.0792, 25.4667, 90.0, 29.7, 8.05, 15.9, 19.9667, 7.25, 30.5, 49.5042, 8.05, 14.4583, 78.2667, 15.1, 151.55, 7.7958, 8.6625, 7.75, 7.6292, 9.5875, 86.5, 108.9, 26.0, 26.55, 22.525, 56.4958, 7.75, 8.05, 26.2875, 59.4, 7.4958, 34.0208, 10.5, 24.15, 26.0, 7.8958, 93.5, 7.8958, 7.225, 57.9792, 7.2292, 7.75, 10.5, 221.7792, 7.925, 11.5, 26.0, 7.2292, 7.2292, 22.3583, 8.6625, 26.25, 26.55, 106.425, 14.5, 49.5, 71.0, 31.275, 31.275, 26.0, 106.425, 26.0, 26.0, 13.8625, 20.525, 36.75, 110.8833, 26.0, 7.8292, 7.225, 7.775, 26.55, 39.6, 227.525, 79.65, 17.4, 7.75, 7.8958, 13.5, 8.05, 8.05, 24.15, 7.8958, 21.075, 7.2292, 7.8542, 10.5, 51.4792, 26.3875, 7.75, 8.05, 14.5, 13.0, 55.9, 14.4583, 7.925, 30.0, 110.8833, 26.0, 40.125, 8.7125, 79.65, 15.0, 79.2, 8.05, 8.05, 7.125, 78.2667, 7.25, 7.75, 26.0, 24.15, 33.0, 0.0, 7.225, 56.9292, 27.0, 7.8958, 42.4, 8.05, 26.55, 15.55, 7.8958, 30.5, 41.5792, 153.4625, 31.275, 7.05, 15.5, 7.75, 8.05, 65.0, 14.4, 16.1, 39.0, 10.5, 14.4542, 52.5542, 15.7417, 7.8542, 16.1, 32.3208, 12.35, 77.9583, 7.8958, 7.7333, 30.0, 7.0542, 30.5, 0.0, 27.9, 13.0, 7.925, 26.25, 39.6875, 16.1, 7.8542, 69.3, 27.9, 56.4958, 19.2583, 76.7292, 7.8958, 35.5, 7.55, 7.55, 7.8958, 23.0, 8.4333, 7.8292, 6.75, 73.5, 7.8958, 15.5, 13.0, 113.275, 133.65, 7.225, 25.5875, 7.4958, 7.925, 73.5, 13.0, 7.775, 8.05, 52.0, 39.0, 52.0, 10.5, 13.0, 0.0, 7.775, 8.05, 9.8417, 46.9, 512.3292, 8.1375, 76.7292, 9.225, 46.9, 39.0, 41.5792, 39.6875, 10.1708, 7.7958, 211.3375, 57.0, 13.4167, 56.4958, 7.225, 26.55, 13.5, 8.05, 7.7333, 110.8833, 7.65, 227.525, 26.2875, 14.4542, 7.7417, 7.8542, 26.0, 13.5, 26.2875, 151.55, 15.2458, 49.5042, 26.55, 52.0, 9.4833, 13.0, 7.65, 227.525, 10.5, 15.5, 7.775, 33.0, 7.0542, 13.0, 13.0, 53.1, 8.6625, 21.0, 7.7375, 26.0, 7.925, 211.3375, 18.7875, 0.0, 13.0, 13.0, 16.1, 34.375, 512.3292, 7.8958, 7.8958, 30.0, 78.85, 262.375, 16.1, 7.925, 71.0, 20.25, 13.0, 53.1, 7.75, 23.0, 12.475, 9.5, 7.8958, 65.0, 14.5, 7.7958, 11.5, 8.05, 86.5, 14.5, 7.125, 7.2292, 120.0, 7.775, 77.9583, 39.6, 7.75, 24.15, 8.3625, 9.5, 7.8542, 10.5, 7.225, 23.0, 7.75, 7.75, 12.475, 7.7375, 211.3375, 7.2292, 57.0, 30.0, 23.45, 7.05, 7.25, 7.4958, 29.125, 20.575, 79.2, 7.75, 26.0, 69.55, 30.6958, 7.8958, 13.0, 25.9292, 8.6833, 7.2292, 24.15, 13.0, 26.25, 120.0, 8.5167, 6.975, 7.775, 0.0, 7.775, 13.0, 53.1, 7.8875, 24.15, 10.5, 31.275, 8.05, 0.0, 7.925, 37.0042, 6.45, 27.9, 93.5, 8.6625, 0.0, 12.475, 39.6875, 6.95, 56.4958, 37.0042, 7.75, 80.0, 14.4542, 18.75, 7.2292, 7.8542, 8.3, 83.1583, 8.6625, 8.05, 56.4958, 29.7, 7.925, 10.5, 31.0, 6.4375, 8.6625, 7.55, 69.55, 7.8958, 33.0, 89.1042, 31.275, 7.775, 15.2458, 39.4, 26.0, 9.35, 164.8667, 26.55, 19.2583, 7.2292, 14.1083, 11.5, 25.9292, 69.55, 13.0, 13.0, 13.8583, 50.4958, 9.5, 11.1333, 7.8958, 52.5542, 5.0, 9.0, 24.0, 7.225, 9.8458, 7.8958, 7.8958, 83.1583, 26.0, 7.8958, 10.5167, 10.5, 7.05, 29.125, 13.0, 30.0, 23.45, 30.0, 7.75]}],\n                        {\"height\": 500, \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Association between Survived and Fare (corr: 0.26, p: 0.0)\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Survived</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Fare</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('b00d8582-d878-4b7d-8992-7f9922221173');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 98,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 55,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** The distribution of Fare between different categories of Survived (0 and 1) are distinct (very least overlap) that makes it comparatively strong predictor for Survived what is kind of true from the correlation value of  0.257307 and the p value (less than 0.01) that suggests we're 99% confident that this correlation is statistically significant. Also survival is positively correlated to Fare, so the more you pay for fare, the more your chances are to survive that is quite evident from the box plot.",
            "mc_idx": 99,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"So the mean fare of survivors should be much more (from positive correlation or boxplot interpretation) than those who died. Calculate mean fare paid by the survivors as well as by the victims.\"\"\"\nnumGroupedByCat(df_train.Fare)",
            "mc_idx": 100,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    56,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"91ab7c0f-99c8-40e4-aea1-0ad81504fb97\" class=\"plotly-graph-div\" style=\"height:500px; width:900px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"91ab7c0f-99c8-40e4-aea1-0ad81504fb97\")) {\n                    Plotly.newPlot(\n                        '91ab7c0f-99c8-40e4-aea1-0ad81504fb97',\n                        [{\"hoverinfo\": \"x+y\", \"text\": [22.12, 48.4], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"2157779b-7853-4052-9e9a-841993f2f335\", \"x\": [0.0, 1.0], \"y\": [22.12, 48.4]}],\n                        {\"height\": 500, \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Mean Fare across Survived\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Survived</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Mean Fare</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('91ab7c0f-99c8-40e4-aea1-0ad81504fb97');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 100,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 56,
                "o_idx": 0
            }
        },
        {
            "source": "**Looks like, on average, if you pay more for your ticket, you are more likely to survive. Let's plot histogram of survivors and victims fare together to validate our intuition:**",
            "mc_idx": 101,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Plot histogram of survivor's vs victims fare.\"\"\"\nnumHistByCat(df_train.Fare)",
            "mc_idx": 102,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c057_o000_image_2.png",
                    57,
                    0,
                    2
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x504 with 1 Axes>"
                    ]
                },
                "mc_idx": 102,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 57,
                "o_idx": 0
            }
        },
        {
            "source": "**That's true. Passengers who paid more for their fair, mostly survived.**\n\n**ANOVA:** \nThe ANOVA(ANalysis Of VAriance) test lets us check whether a numeric response variable varies according to the levels (or class) of a categorical variable. When we simply refer to 'ANOVA', we usually mean the 'one way' ANOVA which is a test for exploring the impact of one single factor on three or more groups (but two groups would also do, as we explain below).\n\nThough one should use either point biserial correlation (if categorical variable is of binary type) or ANOVA method for this problem to find any association between a categorical and a numerical variable, I would perform ANOVA too to have an intuition of how ANOVA works. Though ANOVA is usually prefered if the categorical variable having more than two groups, it is also possible to perform ANOVA for a categorical variable with two groups.\n\nThe one-way ANOVA tests whether the mean of some numeric variable differs across the levels of one categorical variable. It essentially answers the question: do any of the group means differ from one another? The null hypothesis is all of the group means are equal. And the alternate hypothesis is any of the group means differ from one another.",
            "mc_idx": 103,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Let's perform ANOVA between Fare and Survived. One can omit this step. I perform just to show how anova is performed if there were more than two groups in our categorical variable.\"\"\"\ncalculateAnova(df_train.Fare)",
            "mc_idx": 104,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    58,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "'Anova Result between Fare & Survived: f=> 63.03076422804448, p=> 6.120189341921873e-15'"
                    ]
                },
                "mc_idx": 104,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 58,
                "o_idx": 0
            }
        },
        {
            "source": "**Interpretation of ANOVA result:**\nAs p < 0.05 we state that we have a main interaction effect. This simply means that amongst the groups at least any of the group(or groups) means statistically significantly  differ from one another (true for only more than two groups). However, this result does not identify the sample pair (or pairs) which cause this significance (again true for more than two groups of categorical variable but we have just two groups..i.e., 0 and 1).\nSo, when ANOVA reports 'interaction effect' we need to further identify the group pairs by applying pair-wise controls(required for more than two groups of categorical variable). Although these controls could be done by implementing ordinary t-test but this is not the right approach. So a post hoc-test ( usually Tukey's test) is performed to find the pair or pairs that cause the difference. Though Tukey's test is not required with a categorical variable less than three groups.\n\n***Note:*** Tukey's test is not required if ANOVA gives a p value greater than 0.05 and nominal variable has less than three groups. ",
            "mc_idx": 105,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\n### 8.1.2 Age & Survived <a id=\"8.1.2\"></a>",
            "mc_idx": 106,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Let's create a box plot between Age and Survived to have an idea by how much Age is associated with Survived. Also find point biserial correlation between them.\"\"\"\nboxplotAndCorrelation(df_train.Age)",
            "mc_idx": 107,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    59,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"06ed7de7-9c79-419a-9886-a04230f09a5f\" class=\"plotly-graph-div\" style=\"height:500px; width:900px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"06ed7de7-9c79-419a-9886-a04230f09a5f\")) {\n                    Plotly.newPlot(\n                        '06ed7de7-9c79-419a-9886-a04230f09a5f',\n                        [{\"marker\": {\"color\": \"lightseagreen\"}, \"type\": \"box\", \"uid\": \"88220c66-8b87-4cc7-8983-6561df0abc62\", \"x\": [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0], \"y\": [22.0, 38.0, 26.0, 35.0, 35.0, 26.0, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, 30.0, 31.0, 31.0, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, 26.0, 19.0, 18.0, 26.0, 40.0, 45.0, 18.0, 66.0, 28.0, 42.0, 26.0, 21.0, 18.0, 14.0, 40.0, 27.0, 26.0, 3.0, 19.0, 26.0, 26.0, 18.0, 26.0, 18.0, 7.0, 21.0, 49.0, 29.0, 65.0, 41.5, 21.0, 28.5, 5.0, 11.0, 22.0, 38.0, 45.0, 4.0, 41.5, 6.0, 29.0, 19.0, 17.0, 26.0, 32.0, 16.0, 21.0, 26.0, 32.0, 25.0, 26.0, 26.0, 0.83, 30.0, 22.0, 29.0, 18.0, 28.0, 17.0, 33.0, 16.0, 26.0, 23.0, 24.0, 29.0, 20.0, 46.0, 26.0, 59.0, 26.0, 71.0, 23.0, 34.0, 34.0, 28.0, 26.0, 21.0, 33.0, 37.0, 28.0, 21.0, 26.0, 38.0, 18.0, 47.0, 14.5, 22.0, 20.0, 17.0, 21.0, 70.5, 29.0, 24.0, 2.0, 21.0, 26.0, 32.5, 32.5, 54.0, 12.0, 26.0, 24.0, 18.0, 45.0, 33.0, 20.0, 47.0, 29.0, 25.0, 23.0, 19.0, 37.0, 16.0, 24.0, 31.0, 22.0, 24.0, 19.0, 18.0, 19.0, 27.0, 9.0, 36.5, 42.0, 51.0, 22.0, 55.5, 40.5, 26.0, 51.0, 16.0, 30.0, 26.0, 6.0, 44.0, 40.0, 26.0, 17.0, 1.0, 9.0, 45.0, 45.0, 41.5, 28.0, 61.0, 4.0, 1.0, 21.0, 56.0, 18.0, 6.0, 50.0, 30.0, 36.0, 18.0, 30.0, 9.0, 1.0, 4.0, 41.5, 31.0, 45.0, 40.0, 36.0, 32.0, 19.0, 19.0, 3.0, 44.0, 58.0, 26.0, 42.0, 18.0, 24.0, 28.0, 26.0, 34.0, 45.5, 18.0, 2.0, 32.0, 26.0, 16.0, 40.0, 24.0, 35.0, 22.0, 30.0, 26.0, 31.0, 27.0, 42.0, 32.0, 30.0, 16.0, 27.0, 51.0, 26.0, 38.0, 22.0, 19.0, 20.5, 18.0, 18.0, 35.0, 29.0, 59.0, 5.0, 24.0, 18.0, 44.0, 8.0, 19.0, 33.0, 18.0, 18.0, 29.0, 22.0, 30.0, 44.0, 25.0, 24.0, 37.0, 54.0, 26.0, 29.0, 62.0, 30.0, 41.0, 29.0, 45.0, 30.0, 35.0, 50.0, 26.0, 3.0, 52.0, 40.0, 18.0, 36.0, 16.0, 25.0, 58.0, 35.0, 41.5, 25.0, 41.0, 37.0, 18.0, 63.0, 45.0, 30.0, 7.0, 35.0, 65.0, 28.0, 16.0, 19.0, 41.5, 33.0, 30.0, 22.0, 42.0, 22.0, 26.0, 19.0, 36.0, 24.0, 24.0, 41.5, 23.5, 2.0, 41.5, 50.0, 18.0, 26.0, 19.0, 20.0, 26.0, 0.92, 30.0, 17.0, 30.0, 30.0, 24.0, 18.0, 26.0, 28.0, 43.0, 26.0, 24.0, 54.0, 31.0, 40.0, 22.0, 27.0, 30.0, 22.0, 26.0, 36.0, 61.0, 36.0, 31.0, 16.0, 18.0, 45.5, 38.0, 16.0, 45.0, 26.0, 29.0, 41.0, 45.0, 45.0, 2.0, 24.0, 28.0, 25.0, 36.0, 24.0, 40.0, 31.0, 3.0, 42.0, 23.0, 41.5, 15.0, 25.0, 26.0, 28.0, 22.0, 38.0, 18.0, 18.0, 40.0, 29.0, 45.0, 35.0, 26.0, 30.0, 60.0, 31.0, 18.0, 24.0, 25.0, 18.0, 19.0, 22.0, 3.0, 45.0, 22.0, 27.0, 20.0, 19.0, 42.0, 1.0, 32.0, 35.0, 26.0, 18.0, 1.0, 36.0, 26.0, 17.0, 36.0, 21.0, 28.0, 23.0, 24.0, 22.0, 31.0, 46.0, 23.0, 28.0, 39.0, 26.0, 21.0, 28.0, 20.0, 34.0, 51.0, 3.0, 21.0, 18.0, 26.0, 26.0, 33.0, 30.0, 44.0, 31.0, 34.0, 18.0, 30.0, 10.0, 26.0, 21.0, 29.0, 28.0, 18.0, 26.0, 28.0, 19.0, 26.0, 32.0, 28.0, 31.0, 42.0, 17.0, 50.0, 14.0, 21.0, 24.0, 64.0, 31.0, 45.0, 20.0, 25.0, 28.0, 26.0, 4.0, 13.0, 34.0, 5.0, 52.0, 36.0, 26.0, 30.0, 49.0, 26.0, 29.0, 65.0, 45.0, 50.0, 26.0, 48.0, 34.0, 47.0, 48.0, 26.0, 38.0, 30.0, 56.0, 26.0, 0.75, 26.0, 38.0, 33.0, 23.0, 22.0, 41.5, 34.0, 29.0, 22.0, 2.0, 9.0, 30.0, 50.0, 63.0, 25.0, 18.0, 35.0, 58.0, 30.0, 9.0, 26.0, 21.0, 55.0, 71.0, 21.0, 26.0, 54.0, 26.0, 25.0, 24.0, 17.0, 21.0, 18.0, 37.0, 16.0, 18.0, 33.0, 41.5, 28.0, 26.0, 29.0, 26.0, 36.0, 54.0, 24.0, 47.0, 34.0, 26.0, 36.0, 32.0, 30.0, 22.0, 26.0, 44.0, 26.0, 40.5, 50.0, 41.5, 39.0, 23.0, 2.0, 26.0, 17.0, 31.0, 30.0, 7.0, 45.0, 30.0, 26.0, 22.0, 36.0, 9.0, 11.0, 32.0, 50.0, 64.0, 19.0, 30.0, 33.0, 8.0, 17.0, 27.0, 26.0, 22.0, 22.0, 62.0, 48.0, 41.5, 39.0, 36.0, 26.0, 40.0, 28.0, 26.0, 18.0, 24.0, 19.0, 29.0, 26.0, 32.0, 62.0, 53.0, 36.0, 18.0, 16.0, 19.0, 34.0, 39.0, 31.0, 32.0, 25.0, 39.0, 54.0, 36.0, 26.0, 18.0, 47.0, 60.0, 22.0, 26.0, 35.0, 52.0, 47.0, 18.0, 37.0, 36.0, 20.0, 49.0, 26.0, 49.0, 24.0, 26.0, 41.5, 44.0, 35.0, 36.0, 30.0, 27.0, 22.0, 40.0, 39.0, 26.0, 18.0, 26.0, 35.0, 24.0, 34.0, 26.0, 4.0, 26.0, 27.0, 42.0, 20.0, 21.0, 21.0, 61.0, 57.0, 21.0, 26.0, 26.0, 80.0, 51.0, 32.0, 41.5, 9.0, 28.0, 32.0, 31.0, 41.0, 26.0, 20.0, 24.0, 2.0, 26.0, 0.75, 48.0, 19.0, 56.0, 26.0, 23.0, 26.0, 18.0, 21.0, 18.0, 18.0, 24.0, 26.0, 32.0, 23.0, 58.0, 50.0, 40.0, 47.0, 36.0, 20.0, 32.0, 25.0, 26.0, 43.0, 45.0, 40.0, 31.0, 70.0, 31.0, 30.0, 18.0, 24.5, 18.0, 43.0, 36.0, 18.0, 27.0, 20.0, 14.0, 60.0, 25.0, 14.0, 19.0, 18.0, 15.0, 31.0, 4.0, 26.0, 25.0, 60.0, 52.0, 44.0, 18.0, 49.0, 42.0, 18.0, 35.0, 18.0, 25.0, 26.0, 39.0, 45.0, 42.0, 22.0, 6.0, 24.0, 41.5, 48.0, 29.0, 52.0, 19.0, 38.0, 27.0, 26.0, 33.0, 6.0, 17.0, 34.0, 50.0, 27.0, 20.0, 30.0, 18.0, 25.0, 25.0, 29.0, 11.0, 30.0, 23.0, 23.0, 28.5, 48.0, 35.0, 26.0, 26.0, 41.5, 36.0, 21.0, 24.0, 31.0, 70.0, 16.0, 30.0, 19.0, 31.0, 4.0, 6.0, 33.0, 23.0, 48.0, 0.67, 28.0, 18.0, 34.0, 33.0, 26.0, 41.0, 20.0, 36.0, 16.0, 51.0, 51.0, 30.5, 26.0, 32.0, 24.0, 48.0, 57.0, 26.0, 54.0, 18.0, 26.0, 5.0, 26.0, 43.0, 13.0, 17.0, 29.0, 26.0, 25.0, 25.0, 18.0, 8.0, 1.0, 46.0, 26.0, 16.0, 18.0, 41.5, 25.0, 39.0, 49.0, 31.0, 30.0, 30.0, 34.0, 31.0, 11.0, 0.42, 27.0, 31.0, 39.0, 18.0, 39.0, 33.0, 26.0, 39.0, 35.0, 6.0, 30.5, 41.5, 23.0, 31.0, 43.0, 10.0, 52.0, 27.0, 38.0, 27.0, 2.0, 26.0, 26.0, 1.0, 26.0, 62.0, 15.0, 0.83, 26.0, 23.0, 18.0, 39.0, 21.0, 26.0, 32.0, 41.5, 20.0, 16.0, 30.0, 34.5, 17.0, 42.0, 26.0, 35.0, 28.0, 45.0, 4.0, 74.0, 9.0, 16.0, 44.0, 18.0, 45.0, 51.0, 24.0, 26.0, 41.0, 21.0, 48.0, 18.0, 24.0, 42.0, 27.0, 31.0, 26.0, 4.0, 26.0, 47.0, 33.0, 47.0, 28.0, 15.0, 20.0, 19.0, 26.0, 56.0, 25.0, 33.0, 22.0, 28.0, 25.0, 39.0, 27.0, 19.0, 18.0, 26.0, 32.0]}],\n                        {\"height\": 500, \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Association between Survived and Age (corr: -0.06, p: 0.07569)\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Survived</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Age</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('06ed7de7-9c79-419a-9886-a04230f09a5f');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 107,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 59,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** Box plot shows the distribution of Age between categories of Survived (1 and 0) has significant overlap which is also kind of true from a small correlation value of -0.05939. And a p value greater than 0.05 indicates that there is no evidence that the correlation is statistically significant. As we can see that Survived is inversly correlated to Age, so if you are younger, you are just likely to survive.",
            "mc_idx": 108,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"So the mean age of survivors should be just less than those who died (small negative correlation and reading boxplot). Calculate the mean age of survivors and victims.\"\"\"\nnumGroupedByCat(df_train.Age)",
            "mc_idx": 109,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    60,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"aaa3122a-366a-44b8-be3f-937130f8e738\" class=\"plotly-graph-div\" style=\"height:500px; width:900px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"aaa3122a-366a-44b8-be3f-937130f8e738\")) {\n                    Plotly.newPlot(\n                        'aaa3122a-366a-44b8-be3f-937130f8e738',\n                        [{\"hoverinfo\": \"x+y\", \"text\": [29.84, 28.18], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"35a36412-c009-4046-b1f1-715be85c1526\", \"x\": [0.0, 1.0], \"y\": [29.84, 28.18]}],\n                        {\"height\": 500, \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Mean Age across Survived\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Survived</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Mean Age</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('aaa3122a-366a-44b8-be3f-937130f8e738');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 109,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 60,
                "o_idx": 0
            }
        },
        {
            "source": "**Analysing box and above bar plot, we have a feeling that younger people, on average, were just more likely to survive. Let's plot one histogram of survivors' age and another of victims' age to validate our intuition.**",
            "mc_idx": 110,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Histogram of survivors vs victims age.\"\"\"\nnumHistByCat(df_train.Age)",
            "mc_idx": 111,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c061_o000_image_3.png",
                    61,
                    0,
                    3
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x504 with 1 Axes>"
                    ]
                },
                "mc_idx": 111,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 61,
                "o_idx": 0
            }
        },
        {
            "source": "**We see infants and children had high survival rate. The oldest passengers (Age = 80) also survived. A large number of passengers aged from 16 to 30 died.**",
            "mc_idx": 112,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Perform ANOVA between all the levels of Survived (i.e., 0 and 1) and Age.\"\"\"\ncalculateAnova(df_train.Age)",
            "mc_idx": 113,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    62,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "'Anova Result between Age & Survived: f=> 3.162396652163441, p=> 0.07569419096180038'"
                    ]
                },
                "mc_idx": 113,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 62,
                "o_idx": 0
            }
        },
        {
            "source": "**Note:** Choose either biserial correlation (if categorical variable has two groups) or Anova. If anova states main interaction effect(i.e.,p<0.05) and categorical variable has more than two categories ( like good, better, best), then perform tukey test to find out the pair or pairs that cause the difference(i.e., main interaction effect).\n\n**Interpretation of ANOVA result:**\nSince p>0.05, we can say that survival chance is not statistically associated with Age.\n\n## 8.2 Categorical & Categorical Variables <a id=\"8.2\"></a>\nWe will calculate and plot absolute and relative frequency of output categorical variable by predictor nominal variables. We would calculate the chi square test between target nominal and predictor nominal variables. Finally we will calculate Bonferroni-adjusted P value if the contingency table has dimension more than 2x2.",
            "mc_idx": 114,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"#1.Create a function that calculates absolute and relative frequency of Survived variable by a categorical variable. And then plots the absolute and relative frequency of Survived by a categorical variable.\"\"\"\ndef calculateCrosstabulation(catVariable, targetCatVariable=df_train.Survived):\n    \"\"\" Plots cross tabulation in absolute and relative scale.\n    catVariable = input categorical variable, \n    targetCatVariable = our target categorical variable.\"\"\"\n    \n    # Calculate cross tabulation in abs and relative scale\n    absCount = pd.crosstab(index = catVariable, columns = targetCatVariable)\\\n    .rename(columns={0:\"Victims\",1:\"Survivors\"})\n    relCount = pd.crosstab(index = catVariable, columns = targetCatVariable, normalize=\"index\")\\\n    .rename(columns={0:\"Victims\",1:\"Survivors\"})*100\n    relCount = relCount.round(1)\n    \n    # Create two subplots of bar chart\n    fig=make_subplots(\n        rows=2, \n        cols=1,\n        vertical_spacing=0.3,\n        subplot_titles=(f\"Absolute Count of Survival and Death by {catVariable.name}\", \n                        f\"Percentage Count of Survival and Death by {catVariable.name}\"),\n        print_grid=False) # This suppresses \"This is the format of your plot grid:\" text from popping out.\n\n    # Add trace for absolute frequency\n    for col in absCount.columns:\n        fig.add_trace(go.Bar(x=absCount.index,\n                             y=absCount[col],\n                             text=absCount[col],\n                             hoverinfo=\"x+y\",\n                             textposition=\"auto\",\n                             name=f\"{col}\",\n                             textfont=dict(family=\"sans serif\",size=14),\n                             ),\n                     row=1,\n                     col=1\n                     )\n\n\n    # Add another trace for relative frequency\n    for col in relCount.columns:\n        fig.add_trace(go.Bar(x=relCount.index,\n                             y=relCount[col],\n                             text=relCount[col],\n                             hoverinfo=\"x+y\",\n                             textposition=\"auto\",\n                             name=f\"{col}\",\n                             textfont=dict(family=\"sans serif\",size=14),\n                            ),\n                     row=2,\n                     col=1\n                     )\n        \n    # Update the layout. Add title, dimension, and background color\n    fig.layout.update(\n        height=600, \n        width=1000,\n        hovermode=\"closest\",\n        barmode = \"group\",\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n\n    # Set y-axes titles in bold\n    fig.layout.yaxis1.update(title=\"<b>Abs Frequency</b>\")\n    fig.layout.yaxis2.update(title=\"<b>Rel Frequency(%)</b>\")\n    \n    # Set x-axis title in bold\n    fig.layout.xaxis2.update(title=f\"<b>{catVariable.name}</b>\")\n    return fig.show()\n\n    \n\"\"\"#2.Create a function to calculate chi square test between a categorical and target categorical variable.\"\"\"\ndef calculateChiSquare(catVariable, targetCatVariable=df_train.Survived):\n    \"\"\"Returns chi square test restult between independent and dependent target variables.\"\"\"\n    \n    catGroupedByCatTarget = pd.crosstab(index = catVariable, columns = targetCatVariable)\n    testResult = stats.chi2_contingency(catGroupedByCatTarget)\n    print(f\"Chi Square Test Result between {targetCatVariable.name} & {catVariable.name}:\")\n    return print(testResult)\n\n\n\"\"\"#3.Finally create another function to calculate Bonferroni-adjusted pvalue for a categorical and target categorical variable.\"\"\"\ndef calculateBonferroniAdjusted(catVariable, targetCatVariable=df_train.Survived):\n    \"\"\"Returns bonferroni-adjusted pvalue between independent and dependent target variables.\"\"\"\n    \n    # Create one hot encoding for the independent categorical variable\n    catEncoded = pd.get_dummies(catVariable)\n    for column in catEncoded.columns:\n        catGroupedByCatTarget = pd.crosstab(index = catEncoded[column], columns = targetCatVariable)\n        testResult = stats.chi2_contingency(catGroupedByCatTarget)\n        print(f\"Bonferroni-adjusted pvalue between {catVariable.name}({column}) and {targetCatVariable.name}:\")\n        print(f\"{testResult}\\n\")",
            "mc_idx": 115,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.4411764705882353,
                "Data_Transform": 0.29411764705882354,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.08823529411764706,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1,
                    "variable": 33
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".bar(": 2,
                    "info": 2,
                    "columns": 9,
                    "size": 2
                },
                "Data_Transform": {
                    ".cross": 4,
                    ".rename": 2,
                    ".get_dummies": 1,
                    ".add": 2,
                    ".round": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    ".bar(": 2,
                    "chart": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    63,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 115,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 63,
                "o_idx": 0
            }
        },
        {
            "source": "### 8.2.1 Sex & Survived <a id=\"8.2.1\"></a>",
            "mc_idx": 116,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Plot the no of passergers who survived and died due to their sex in absolute and relative scale.\"\"\"\ncalculateCrosstabulation(df_train.Sex)",
            "mc_idx": 117,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    64,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"a18b3156-9af1-4d64-be89-21bcf52bc02b\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"a18b3156-9af1-4d64-be89-21bcf52bc02b\")) {\n                    Plotly.newPlot(\n                        'a18b3156-9af1-4d64-be89-21bcf52bc02b',\n                        [{\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [81.0, 468.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"41f856a7-bf8b-4ee5-9390-8e0062eda6f3\", \"x\": [\"female\", \"male\"], \"xaxis\": \"x\", \"y\": [81, 468], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [233.0, 109.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"aaa349a5-954d-4114-9491-32db757e3322\", \"x\": [\"female\", \"male\"], \"xaxis\": \"x\", \"y\": [233, 109], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [25.8, 81.1], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"25cff0d3-75f6-4e31-90d2-daf2a5423fe4\", \"x\": [\"female\", \"male\"], \"xaxis\": \"x2\", \"y\": [25.8, 81.1], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [74.2, 18.9], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"726fc11e-734f-4616-9b5b-d1ea4b58cfa3\", \"x\": [\"female\", \"male\"], \"xaxis\": \"x2\", \"y\": [74.2, 18.9], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Count of Survival and Death by Sex\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.9999999999999999, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Percentage Count of Survival and Death by Sex\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.35, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"barmode\": \"group\", \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"width\": 1000, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Sex</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.6499999999999999, 0.9999999999999999], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.35], \"title\": {\"text\": \"<b>Rel Frequency(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('a18b3156-9af1-4d64-be89-21bcf52bc02b');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 117,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 64,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** Out of 342 survivors, 233 passergers were female while only 109 passengers were male. So female survivors were more than double the male survivors. Proportion tells a female has over 74% chance of survival while male has almost 19% chance of survival. So female has the best chance of survival.\n\n***Chi-square Test***: The Chi-square test of independence tests if there is a significant relationship between two categorical variables.The data is usually displayed in a cross-tabulation format with each row representing a category for one variable and each column representing a category for another variable. Chi-square test of independence is an omnibus test.That is it tests the data as a whole. This means that one will not be able to tell which levels (categories) of the variables are responsible for the relationship **if the Chi-square table is larger than 2\u00d72. If the test is larger than 2\u00d72, it requires post hoc testing.**\n\n**The H0 (Null Hypothesis): There is no relationship between variable 1 and variable 2.**\n\n**The H1 (Alternative Hypothesis): There is a relationship between variable 1 and variable 2.**\n\nIf the p-value is significant (less than 0.05), you can reject the null hypothesis and claim that the findings support the alternate hypothesis. While we check the results of the chi2 test, we need also to check that the expected cell frequencies are greater than or equal to 5. If a cell has an expected frequency less that 5, then the Fisher\u2019s Exact test should be use to overcome this problem.\n\nThe chi2_contingency() method conducts the Chi-square test on a contingency table (crosstab).",
            "mc_idx": 118,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Perform chi-square test of independence between Survived and Sex.\"\"\"\ncalculateChiSquare(df_train.Sex)",
            "mc_idx": 119,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    65,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Chi Square Test Result between Survived & Sex:\n(260.71702016732104, 1.1973570627755645e-58, 1, array([[193.47474747, 120.52525253],\n       [355.52525253, 221.47474747]]))\n"
                    ]
                },
                "mc_idx": 119,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 65,
                "o_idx": 0
            }
        },
        {
            "source": "***Interpretation of chi-square test outcome***: The first value (260.717) is the Chi-square value, followed by the p-value (1.197e-58), then comes the degrees of freedom (1), and lastly it outputs the expected frequencies as an array. Since all of the expected frequencies are greater than 5, the chi2 test results can be trusted. We can reject the null hypothesis as the p-value is less than 0.05(infact p value is almost 0).  Thus, the results indicate that there is a statistically significant relationship between Sex and Survived.\n\n### 8.2.2 Pclass & Survived <a id=\"8.2.2\"></a>",
            "mc_idx": 120,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Plot the number of passengers who survived and died due to their pclass in absolute and relative scale.\"\"\"\ncalculateCrosstabulation(df_train.Pclass)",
            "mc_idx": 121,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    66,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"96b57ebd-fdca-4b6b-a50e-277d1230232e\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"96b57ebd-fdca-4b6b-a50e-277d1230232e\")) {\n                    Plotly.newPlot(\n                        '96b57ebd-fdca-4b6b-a50e-277d1230232e',\n                        [{\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [80.0, 97.0, 372.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"2554fb76-d1c0-47f7-bc0d-90a2c780eeb7\", \"x\": [1, 2, 3], \"xaxis\": \"x\", \"y\": [80, 97, 372], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [136.0, 87.0, 119.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"5f66aeb1-4577-48fa-b587-e8750b82d657\", \"x\": [1, 2, 3], \"xaxis\": \"x\", \"y\": [136, 87, 119], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [37.0, 52.7, 75.8], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"d1d0fa20-0389-4cc6-96a3-27a26873a06b\", \"x\": [1, 2, 3], \"xaxis\": \"x2\", \"y\": [37.0, 52.7, 75.8], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [63.0, 47.3, 24.2], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"3752d256-1619-4e7a-a191-51f7b4e6723e\", \"x\": [1, 2, 3], \"xaxis\": \"x2\", \"y\": [63.0, 47.3, 24.2], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Count of Survival and Death by Pclass\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.9999999999999999, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Percentage Count of Survival and Death by Pclass\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.35, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"barmode\": \"group\", \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"width\": 1000, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Pclass</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.6499999999999999, 0.9999999999999999], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.35], \"title\": {\"text\": \"<b>Rel Frequency(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('96b57ebd-fdca-4b6b-a50e-277d1230232e');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 121,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 66,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** Out of 342 survivors, pclass1(136) has the most number of survivors followed by pclass3(119) and pclass2(87). But the percentage tells different story. If you're in class1, your survival chance is nearly 63% while pclass2 has just over 47% survival chance. But if you are in class3, your chance of survival is very bleak, i.e.,just over 24%.",
            "mc_idx": 122,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Perform chi-square test of independence between Survived and Pclass.\"\"\"\ncalculateChiSquare(df_train.Pclass)",
            "mc_idx": 123,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    67,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Chi Square Test Result between Survived & Pclass:\n(102.88898875696056, 4.549251711298793e-23, 2, array([[133.09090909,  82.90909091],\n       [113.37373737,  70.62626263],\n       [302.53535354, 188.46464646]]))\n"
                    ]
                },
                "mc_idx": 123,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 67,
                "o_idx": 0
            }
        },
        {
            "source": "**Interpretation of chi-square test outcome:** The overall 3x2 table has a chi-square value of 102.889, pvalue  of 4.549e-23, degrees of freedom of 2 and the rest are the expected frequencies of array. Since all of the expected frequencies are greater than 5, the chi2 test results can be trusted. We can reject the null hypothesis as the p-value is less than 0.05(infact p value is almost 0). Thus, the results indicate that there is a statistically significant relationship between Pclass and titanic's survivors. \n\n\n**Post Hoc Test**: Although our Chi-square test was signficant, since our analysis is 3x2 we don't know which levels of Pclass(1, 2 or 3) have the strongest association with variable Survived. Hence we need to perform a post hoc test to verify if and which combinations are actually significantly associated with Survived. In order to do this, we need to conduct multiple 2\u00d72 Chi-square tests using the *Bonferroni-adjusted p-value.*\n\nTo conduct multiple 2\u00d72 Chi-square tests, one needs to regroup the variables for each test to where it is one category against the rest. For us, it will be:\n\n1. 1 vs 2\n2. 1 vs 3\n3. And finally 2 vs 3\n\n**Because there are 3 comparisons, the Bonferroni-adjusted P value needed for significance is 0.05/3, or 0.017. So for our any planned pairwise comparisons to be significant, the p-value must be less than 0.017.**",
            "mc_idx": 124,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Calculate Bonferroni-adjusted pvalue for Pclass (1,2,3) and Survived.\"\"\"\ncalculateBonferroniAdjusted(df_train.Pclass)",
            "mc_idx": 125,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    68,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Bonferroni-adjusted pvalue between Pclass(1) and Survived:\n(71.46583854616047, 2.821002116713357e-17, 1, array([[415.90909091, 259.09090909],\n       [133.09090909,  82.90909091]]))\n\nBonferroni-adjusted pvalue between Pclass(2) and Survived:\n(7.2971925540056475, 0.006906243870048795, 1, array([[435.62626263, 271.37373737],\n       [113.37373737,  70.62626263]]))\n\nBonferroni-adjusted pvalue between Pclass(3) and Survived:\n(91.23179223158795, 1.277904920294387e-21, 1, array([[246.46464646, 153.53535354],\n       [302.53535354, 188.46464646]]))\n\n"
                    ]
                },
                "mc_idx": 125,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 68,
                "o_idx": 0
            }
        },
        {
            "source": "**Interpretation of the outcome of  Bonferroni-adjusted p-value test:** Using the Bonferroni-adjusted p-value of 0.017, 3 out of 3 planned pairwise comparisons are significant. Though p value suggests Pclass2 has the weakest association with Survived compared to Pclass1 and Pclass3.\n\n###  8.2.3 Embarked & Survived <a id=\"8.2.3\"></a>",
            "mc_idx": 126,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Count and plot the survivors and victims by place of embarkation in absolute and relative scale.\"\"\"\ncalculateCrosstabulation(df_train.Embarked)",
            "mc_idx": 127,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    69,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"eaa98b99-98ea-4ea2-a693-d16d16058dc9\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"eaa98b99-98ea-4ea2-a693-d16d16058dc9\")) {\n                    Plotly.newPlot(\n                        'eaa98b99-98ea-4ea2-a693-d16d16058dc9',\n                        [{\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [75.0, 47.0, 427.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"def30687-d5ca-4ee1-915d-26134dc5e6a6\", \"x\": [\"C\", \"Q\", \"S\"], \"xaxis\": \"x\", \"y\": [75, 47, 427], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [93.0, 30.0, 219.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"6da5fdf0-926f-49b2-b5ff-8e6ae52cbd8a\", \"x\": [\"C\", \"Q\", \"S\"], \"xaxis\": \"x\", \"y\": [93, 30, 219], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [44.6, 61.0, 66.1], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"e12e6997-d692-4f45-993b-d67e40cabd03\", \"x\": [\"C\", \"Q\", \"S\"], \"xaxis\": \"x2\", \"y\": [44.6, 61.0, 66.1], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [55.4, 39.0, 33.9], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"c482cf53-e213-42db-aa1f-f6608970fa49\", \"x\": [\"C\", \"Q\", \"S\"], \"xaxis\": \"x2\", \"y\": [55.4, 39.0, 33.9], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Count of Survival and Death by Embarked\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.9999999999999999, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Percentage Count of Survival and Death by Embarked\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.35, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"barmode\": \"group\", \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"width\": 1000, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Embarked</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.6499999999999999, 0.9999999999999999], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.35], \"title\": {\"text\": \"<b>Rel Frequency(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('eaa98b99-98ea-4ea2-a693-d16d16058dc9');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 127,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 69,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** Though people embarked from Southampton have the most survivors count (219) but proportion-wise it has only nearly 34% chance of survival. Because 427 passengers embarked from Southampton died. On the contrary, if you would embark from Cherbourg, you have a very decent chance of survival of over 55%.  Finally, people embarked from  Queenstown have a chance of survival more than 5% from those who embarked from Southampton.",
            "mc_idx": 128,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Now perform chi-square test to find the association between Embarked and Survived.\"\"\"\ncalculateChiSquare(df_train.Embarked)",
            "mc_idx": 129,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    70,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Chi Square Test Result between Survived & Embarked:\n(25.964452881874784, 2.3008626481449577e-06, 2, array([[103.51515152,  64.48484848],\n       [ 47.44444444,  29.55555556],\n       [398.04040404, 247.95959596]]))\n"
                    ]
                },
                "mc_idx": 129,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 70,
                "o_idx": 0
            }
        },
        {
            "source": "**Interpretation of chi-square test result:** The  3x2 table has a chi-square value of 25.96, pvalue of 2.3e-06, degrees of freedom of 2 and the rest are the expected frequencies of array. Since all of the expected frequencies are greater than 5, the chi2 test results can be trusted. We can reject the null hypothesis as the p-value is less than 0.05(infact p value is less than 0.01). Thus, the results indicate that there is a statistically significant relationship between the variables Embarked and Survived.\n\n**Because there are three comparisons, the Bonferroni-adjusted P value needed for significance is 0.05/3, or 0.017. So for our any planned pairwise comparisons to be significant, the p-value must be less than 0.017.**",
            "mc_idx": 130,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Calculate Bonferroni-adjusted pvalue  between Embarked (C,Q,S one by one) and Survived.\"\"\"\ncalculateBonferroniAdjusted(df_train.Embarked)",
            "mc_idx": 131,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    71,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Bonferroni-adjusted pvalue between Embarked(C) and Survived:\n(24.34294028991685, 8.062166851376562e-07, 1, array([[445.48484848, 277.51515152],\n       [103.51515152,  64.48484848]]))\n\nBonferroni-adjusted pvalue between Embarked(Q) and Survived:\n(0.00018551307377882246, 0.9891328942213099, 1, array([[501.55555556, 312.44444444],\n       [ 47.44444444,  29.55555556]]))\n\nBonferroni-adjusted pvalue between Embarked(S) and Survived:\n(19.279400244953347, 1.1291808110540787e-05, 1, array([[150.95959596,  94.04040404],\n       [398.04040404, 247.95959596]]))\n\n"
                    ]
                },
                "mc_idx": 131,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 71,
                "o_idx": 0
            }
        },
        {
            "source": "**Interpreting the result of pair-wise Bonferroni-adjusted pvalue:** Using the Bonferroni-adjusted p-value of 0.017, 2 of the 3 planned pairwise comparisons are significant. Bonferroni-adjusted p-value for Q and Survived is 0.989 which is way greater than 0.017. So it can be said that level Q of variable Embarked is not statistically associated with variable Survived.\n\n### 8.2.4 SibSp & Survived <a id=\"8.2.4\"></a>",
            "mc_idx": 132,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Count and plot absolute and relative number of survivors and victims due to SibSp.\"\"\"\ncalculateCrosstabulation(df_train.SibSp)",
            "mc_idx": 133,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    72,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"3af60cd9-1e4b-425e-aa5b-234f5192e9eb\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"3af60cd9-1e4b-425e-aa5b-234f5192e9eb\")) {\n                    Plotly.newPlot(\n                        '3af60cd9-1e4b-425e-aa5b-234f5192e9eb',\n                        [{\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [398.0, 97.0, 15.0, 12.0, 15.0, 5.0, 7.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"5a431ce7-ad3f-40c9-8903-b150d6f7d1cf\", \"x\": [0, 1, 2, 3, 4, 5, 8], \"xaxis\": \"x\", \"y\": [398, 97, 15, 12, 15, 5, 7], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [210.0, 112.0, 13.0, 4.0, 3.0, 0.0, 0.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"fbf06ef2-98f7-4ea9-9aa3-d05f19bb6597\", \"x\": [0, 1, 2, 3, 4, 5, 8], \"xaxis\": \"x\", \"y\": [210, 112, 13, 4, 3, 0, 0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [65.5, 46.4, 53.6, 75.0, 83.3, 100.0, 100.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"61593f05-8172-47f3-a316-3e4c480fae2c\", \"x\": [0, 1, 2, 3, 4, 5, 8], \"xaxis\": \"x2\", \"y\": [65.5, 46.4, 53.6, 75.0, 83.3, 100.0, 100.0], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [34.5, 53.6, 46.4, 25.0, 16.7, 0.0, 0.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"af7bdfa2-6ecc-4e61-ba96-6b59a1a503e9\", \"x\": [0, 1, 2, 3, 4, 5, 8], \"xaxis\": \"x2\", \"y\": [34.5, 53.6, 46.4, 25.0, 16.7, 0.0, 0.0], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Count of Survival and Death by SibSp\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.9999999999999999, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Percentage Count of Survival and Death by SibSp\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.35, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"barmode\": \"group\", \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"width\": 1000, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>SibSp</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.6499999999999999, 0.9999999999999999], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.35], \"title\": {\"text\": \"<b>Rel Frequency(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('3af60cd9-1e4b-425e-aa5b-234f5192e9eb');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 133,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 72,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** A large number of passengers (210) who survived were without (0) any siblings or spouse, followed by 112 passengers with 1 spouse or siblings. Percentage-wise, passengers with 1 spouse or siblings had over 53.5% chance of survival, followed by passengers with 2 siblings or spouse had over 46% chance of survival. Passengers with 5 or 8 siblings or spouse had all died.",
            "mc_idx": 134,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Chi-square test between SibSp and Survived.\"\"\"\ncalculateChiSquare(df_train.SibSp)",
            "mc_idx": 135,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    73,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Chi Square Test Result between Survived & SibSp:\n(37.2717929152043, 1.5585810465902147e-06, 6, array([[374.62626263, 233.37373737],\n       [128.77777778,  80.22222222],\n       [ 17.25252525,  10.74747475],\n       [  9.85858586,   6.14141414],\n       [ 11.09090909,   6.90909091],\n       [  3.08080808,   1.91919192],\n       [  4.31313131,   2.68686869]]))\n"
                    ]
                },
                "mc_idx": 135,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 73,
                "o_idx": 0
            }
        },
        {
            "source": "**Interpretation of Chi-square Test:**  Since all the expected frequencies aren't greater than 5, chi-square test result can't be trusted.\n\n### 8.2.5 Parch & Survived  <a id=\"8.2.5\"></a>",
            "mc_idx": 136,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Visualize absolute and relative number of survivors and victims by Parch.\"\"\"\ncalculateCrosstabulation(df_train.Parch)",
            "mc_idx": 137,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Visualization",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "visualize": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    74,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"47871508-6f80-4039-8ebf-66f27b659301\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"47871508-6f80-4039-8ebf-66f27b659301\")) {\n                    Plotly.newPlot(\n                        '47871508-6f80-4039-8ebf-66f27b659301',\n                        [{\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [445.0, 53.0, 40.0, 2.0, 4.0, 4.0, 1.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"70b22dee-7665-41e0-965f-63fb790beaad\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"xaxis\": \"x\", \"y\": [445, 53, 40, 2, 4, 4, 1], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [233.0, 65.0, 40.0, 3.0, 0.0, 1.0, 0.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"ce505159-d1d9-4ba1-be1e-6617417b8009\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"xaxis\": \"x\", \"y\": [233, 65, 40, 3, 0, 1, 0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [65.6, 44.9, 50.0, 40.0, 100.0, 80.0, 100.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"d161d978-bbe8-4ef2-ad77-a1fdcb52b180\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"xaxis\": \"x2\", \"y\": [65.6, 44.9, 50.0, 40.0, 100.0, 80.0, 100.0], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [34.4, 55.1, 50.0, 60.0, 0.0, 20.0, 0.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"7916b7ca-19aa-4815-80ae-c3f5a6d4028a\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"xaxis\": \"x2\", \"y\": [34.4, 55.1, 50.0, 60.0, 0.0, 20.0, 0.0], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Count of Survival and Death by Parch\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.9999999999999999, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Percentage Count of Survival and Death by Parch\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.35, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"barmode\": \"group\", \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"width\": 1000, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Parch</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.6499999999999999, 0.9999999999999999], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.35], \"title\": {\"text\": \"<b>Rel Frequency(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('47871508-6f80-4039-8ebf-66f27b659301');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 137,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 74,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** Passengers with 3 children/parent had 60% survival rate, followed by passengers with 2 children/parent has a 50% survival rate. No passengers survived with 4 or 6 children/parent.",
            "mc_idx": 138,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Perform Chi-square test of independence between Parch and Survived.\"\"\"\ncalculateChiSquare(df_train.Parch)",
            "mc_idx": 139,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    75,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Chi Square Test Result between Survived & Parch:\n(27.925784060236168, 9.703526421039997e-05, 6, array([[4.17757576e+02, 2.60242424e+02],\n       [7.27070707e+01, 4.52929293e+01],\n       [4.92929293e+01, 3.07070707e+01],\n       [3.08080808e+00, 1.91919192e+00],\n       [2.46464646e+00, 1.53535354e+00],\n       [3.08080808e+00, 1.91919192e+00],\n       [6.16161616e-01, 3.83838384e-01]]))\n"
                    ]
                },
                "mc_idx": 139,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 75,
                "o_idx": 0
            }
        },
        {
            "source": "**Interpretation of Chi-square Test Outcome:**  Since all the expected frequencies aren't greater than 5, chi-square test result can't be trusted.\n\n### 8.2.6 nameProcessed & Survived <a id=\"8.2.6\"></a>",
            "mc_idx": 140,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Visualize absolute and relative number of survivors and victims by nameProcessed.\"\"\"\ncalculateCrosstabulation(df_train.nameProcessed)",
            "mc_idx": 141,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Visualization",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "visualize": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    76,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"11498e74-08de-40e0-a377-3b1ef8d8d19b\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"11498e74-08de-40e0-a377-3b1ef8d8d19b\")) {\n                    Plotly.newPlot(\n                        '11498e74-08de-40e0-a377-3b1ef8d8d19b',\n                        [{\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [2.0, 17.0, 55.0, 436.0, 26.0, 13.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"413e46d6-8539-4d38-9b96-9fe3e66ca1b0\", \"x\": [\" Aristocrat\", \" Master\", \" Miss\", \" Mr\", \" Mrs\", \" Officer\"], \"xaxis\": \"x\", \"y\": [2, 17, 55, 436, 26, 13], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [3.0, 23.0, 130.0, 81.0, 100.0, 5.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"5e897e5f-ac6d-4750-9c06-000027023987\", \"x\": [\" Aristocrat\", \" Master\", \" Miss\", \" Mr\", \" Mrs\", \" Officer\"], \"xaxis\": \"x\", \"y\": [3, 23, 130, 81, 100, 5], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [40.0, 42.5, 29.7, 84.3, 20.6, 72.2], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"a65f232f-e514-4bb5-8bda-c5640dc9b28f\", \"x\": [\" Aristocrat\", \" Master\", \" Miss\", \" Mr\", \" Mrs\", \" Officer\"], \"xaxis\": \"x2\", \"y\": [40.0, 42.5, 29.7, 84.3, 20.6, 72.2], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [60.0, 57.5, 70.3, 15.7, 79.4, 27.8], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"94e5f80f-64e5-4502-86c9-5b46b12c7bf0\", \"x\": [\" Aristocrat\", \" Master\", \" Miss\", \" Mr\", \" Mrs\", \" Officer\"], \"xaxis\": \"x2\", \"y\": [60.0, 57.5, 70.3, 15.7, 79.4, 27.8], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Count of Survival and Death by nameProcessed\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.9999999999999999, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Percentage Count of Survival and Death by nameProcessed\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.35, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"barmode\": \"group\", \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"width\": 1000, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>nameProcessed</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.6499999999999999, 0.9999999999999999], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.35], \"title\": {\"text\": \"<b>Rel Frequency(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('11498e74-08de-40e0-a377-3b1ef8d8d19b');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 141,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 76,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** Women had the best survival rate, i.e., Mrs(over 79%) and Miss(over 70%) that reminds us the variable Sex where we have seen female were more likely to survive in. Mr is the worst title to have when it comes to survival situation since just over 15% of passengers with title Mr survived that again indicates the importance of Sex as a deal breaker for survival.",
            "mc_idx": 142,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Perform Chi-square test of independence between nameProcessed and Survived.\"\"\"\ncalculateChiSquare(df_train.nameProcessed)",
            "mc_idx": 143,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    77,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Chi Square Test Result between Survived & nameProcessed:\n(289.8360961873925, 1.5325912223703196e-60, 5, array([[  3.08080808,   1.91919192],\n       [ 24.64646465,  15.35353535],\n       [113.98989899,  71.01010101],\n       [318.55555556, 198.44444444],\n       [ 77.63636364,  48.36363636],\n       [ 11.09090909,   6.90909091]]))\n"
                    ]
                },
                "mc_idx": 143,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 77,
                "o_idx": 0
            }
        },
        {
            "source": "**Interpretation of chi-square test result**: Since all the expected frequencies aren't greater than 5, chi-square test result can't be trusted.\n\n### 8.2.7 familySize & Survived <a id=\"8.2.7\"></a>",
            "mc_idx": 144,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Plot the Survived's absolute and percentage count by familySize.\"\"\"\ncalculateCrosstabulation(df_train.familySize)",
            "mc_idx": 145,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    78,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"e97cd754-f971-4b78-bb0c-5677a5f3e737\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"e97cd754-f971-4b78-bb0c-5677a5f3e737\")) {\n                    Plotly.newPlot(\n                        'e97cd754-f971-4b78-bb0c-5677a5f3e737',\n                        [{\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [40.0, 20.0, 374.0, 115.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"c31c33da-f974-4a3c-baee-2c0dd18beec6\", \"x\": [\"large\", \"medium\", \"single\", \"small\"], \"xaxis\": \"x\", \"y\": [40, 20, 374, 115], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [7.0, 24.0, 163.0, 148.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"1b616278-aa5e-46ba-b40a-f5816c5b8a55\", \"x\": [\"large\", \"medium\", \"single\", \"small\"], \"xaxis\": \"x\", \"y\": [7, 24, 163, 148], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [85.1, 45.5, 69.6, 43.7], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"31637492-8722-48b5-8efb-ffcc4ab2c2e5\", \"x\": [\"large\", \"medium\", \"single\", \"small\"], \"xaxis\": \"x2\", \"y\": [85.1, 45.5, 69.6, 43.7], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [14.9, 54.5, 30.4, 56.3], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"eab0726b-c9b9-498b-a7d3-c38791f81128\", \"x\": [\"large\", \"medium\", \"single\", \"small\"], \"xaxis\": \"x2\", \"y\": [14.9, 54.5, 30.4, 56.3], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Count of Survival and Death by familySize\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.9999999999999999, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Percentage Count of Survival and Death by familySize\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.35, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"barmode\": \"group\", \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"width\": 1000, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>familySize</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.6499999999999999, 0.9999999999999999], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.35], \"title\": {\"text\": \"<b>Rel Frequency(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('e97cd754-f971-4b78-bb0c-5677a5f3e737');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 145,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 78,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** Passengers with small and medium familiy size had good survival rate. Single passengers had survival chance of just over 30%. And passengers with large families has a survival rate below 15%.",
            "mc_idx": 146,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Perform Chi-square test of independence between familySize and Survived.\"\"\"\ncalculateChiSquare(df_train.familySize)",
            "mc_idx": 147,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    79,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Chi Square Test Result between Survived & familySize:\n(66.05581680279249, 2.981870009647575e-14, 3, array([[ 28.95959596,  18.04040404],\n       [ 27.11111111,  16.88888889],\n       [330.87878788, 206.12121212],\n       [162.05050505, 100.94949495]]))\n"
                    ]
                },
                "mc_idx": 147,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 79,
                "o_idx": 0
            }
        },
        {
            "source": "**Interpretation of chi-square test result**:Since all of the expected frequencies are greater than 5, the chi2 test results can be trusted. We can reject the null hypothesis as the p-value is less than 0.05(infact p value is almost 0). Thus, the results indicate that there is a statistically significant relationship between variable Family_size and Survived.\n\n**Because there are 8 comparisons, the Bonferroni-adjusted P value needed for significance is 0.05/8, or 0.0063. So for our any planned pairwise comparisons to be significant, the p-value must be less than 0.0063.**",
            "mc_idx": 148,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Calculate Bonferroni-adjusted pvalue  between familySize and Survived.\"\"\"\ncalculateBonferroniAdjusted(df_train.familySize)",
            "mc_idx": 149,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    80,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Bonferroni-adjusted pvalue between familySize(large) and Survived:\n(10.55137053799774, 0.0011610196650239893, 1, array([[520.04040404, 323.95959596],\n       [ 28.95959596,  18.04040404]]))\n\nBonferroni-adjusted pvalue between familySize(medium) and Survived:\n(4.418221527178599, 0.03555707818485421, 1, array([[521.88888889, 325.11111111],\n       [ 27.11111111,  16.88888889]]))\n\nBonferroni-adjusted pvalue between familySize(single) and Survived:\n(36.00051446773865, 1.9726543846517113e-09, 1, array([[218.12121212, 135.87878788],\n       [330.87878788, 206.12121212]]))\n\nBonferroni-adjusted pvalue between familySize(small) and Survived:\n(49.42743388214718, 2.058468013374345e-12, 1, array([[386.94949495, 241.05050505],\n       [162.05050505, 100.94949495]]))\n\n"
                    ]
                },
                "mc_idx": 149,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 80,
                "o_idx": 0
            }
        },
        {
            "source": "**Interpretation of Bonferroni-adjusted Post-hoc test result:** Using the Bonferroni-adjusted p-value of 0.0063, 3 of the 4 planned pairwise comparisons are significant. Bonferroni-adjusted p-value for medium and Survived is 0.03555 which is way greater than 0.0063. So it can be said that level medium of variable familySize is not statistically associated with variable Survived.\n\n### 8.2.8 cabinProcessed & Survived <a id=\"8.2.8\"></a>",
            "mc_idx": 150,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Count and plot absolute and relative number of survivors and victims due to cabin possession.\"\"\"\ncalculateCrosstabulation(df_train.cabinProcessed)",
            "mc_idx": 151,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "session": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    81,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"ace67f98-4f66-43b5-ac3f-25c299b8fec4\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"ace67f98-4f66-43b5-ac3f-25c299b8fec4\")) {\n                    Plotly.newPlot(\n                        'ace67f98-4f66-43b5-ac3f-25c299b8fec4',\n                        [{\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [8.0, 12.0, 24.0, 8.0, 8.0, 5.0, 2.0, 1.0, 481.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"7d5e9c93-a345-49e9-bef8-26102e309f3c\", \"x\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"T\", \"X\"], \"xaxis\": \"x\", \"y\": [8, 12, 24, 8, 8, 5, 2, 1, 481], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [7.0, 35.0, 35.0, 25.0, 24.0, 8.0, 2.0, 0.0, 206.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"6d97fcc1-1798-4d79-9330-bb6cf23ed940\", \"x\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"T\", \"X\"], \"xaxis\": \"x\", \"y\": [7, 35, 35, 25, 24, 8, 2, 0, 206], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [53.3, 25.5, 40.7, 24.2, 25.0, 38.5, 50.0, 100.0, 70.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"2dcd5c9c-8022-4c77-802c-7727097d4068\", \"x\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"T\", \"X\"], \"xaxis\": \"x2\", \"y\": [53.3, 25.5, 40.7, 24.2, 25.0, 38.5, 50.0, 100.0, 70.0], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [46.7, 74.5, 59.3, 75.8, 75.0, 61.5, 50.0, 0.0, 30.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"72d47914-7b4c-4436-9b58-596db453c073\", \"x\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"T\", \"X\"], \"xaxis\": \"x2\", \"y\": [46.7, 74.5, 59.3, 75.8, 75.0, 61.5, 50.0, 0.0, 30.0], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Count of Survival and Death by cabinProcessed\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.9999999999999999, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Percentage Count of Survival and Death by cabinProcessed\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.35, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"barmode\": \"group\", \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"width\": 1000, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>cabinProcessed</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.6499999999999999, 0.9999999999999999], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.35], \"title\": {\"text\": \"<b>Rel Frequency(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('ace67f98-4f66-43b5-ac3f-25c299b8fec4');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 151,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 81,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** Most of the passengers survived and died were from cabin X. But percentage-wise, its category B, D, and E that had impressive chance of survival. People from cabin category X had just 30% chance of survival.",
            "mc_idx": 152,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Perform Chi-square test of independence between Cabin and Survived.\"\"\"\ncalculateChiSquare(df_train.cabinProcessed)",
            "mc_idx": 153,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    82,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Chi Square Test Result between Survived & cabinProcessed:\n(99.16416061888009, 6.326020042314704e-18, 8, array([[9.24242424e+00, 5.75757576e+00],\n       [2.89595960e+01, 1.80404040e+01],\n       [3.63535354e+01, 2.26464646e+01],\n       [2.03333333e+01, 1.26666667e+01],\n       [1.97171717e+01, 1.22828283e+01],\n       [8.01010101e+00, 4.98989899e+00],\n       [2.46464646e+00, 1.53535354e+00],\n       [6.16161616e-01, 3.83838384e-01],\n       [4.23303030e+02, 2.63696970e+02]]))\n"
                    ]
                },
                "mc_idx": 153,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 82,
                "o_idx": 0
            }
        },
        {
            "source": "**Interpretation of chi-square test result**: Since all of the expected frequencies aren't greater than 5, the chi2 test results can't be trusted.\n\n### 8.2.9 ticketProcessed & Survived <a id=\"8.2.9\"></a>",
            "mc_idx": 154,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Count and plot absolute and relative number of survivors and victims due to ticketProcessed category.\"\"\"\ncalculateCrosstabulation(df_train.ticketProcessed)",
            "mc_idx": 155,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    83,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"39f72251-7158-48b5-b74d-f8667e8749f0\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"39f72251-7158-48b5-b74d-f8667e8749f0\")) {\n                    Plotly.newPlot(\n                        '39f72251-7158-48b5-b74d-f8667e8749f0',\n                        [{\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [27.0, 31.0, 3.0, 3.0, 407.0, 23.0, 44.0, 11.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"6b9151aa-1b1a-4a2e-bbf2-dccb27c57cec\", \"x\": [\"A\", \"C\", \"F\", \"L\", \"N\", \"P\", \"S\", \"W\"], \"xaxis\": \"x\", \"y\": [27, 31, 3, 3, 407, 23, 44, 11], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [2.0, 16.0, 4.0, 1.0, 254.0, 42.0, 21.0, 2.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"f1af477d-d66c-4b30-8dfb-fc8d29b698d5\", \"x\": [\"A\", \"C\", \"F\", \"L\", \"N\", \"P\", \"S\", \"W\"], \"xaxis\": \"x\", \"y\": [2, 16, 4, 1, 254, 42, 21, 2], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [93.1, 66.0, 42.9, 75.0, 61.6, 35.4, 67.7, 84.6], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"09611d58-bbd5-42f0-8d92-b23606ba1f0e\", \"x\": [\"A\", \"C\", \"F\", \"L\", \"N\", \"P\", \"S\", \"W\"], \"xaxis\": \"x2\", \"y\": [93.1, 66.0, 42.9, 75.0, 61.6, 35.4, 67.7, 84.6], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [6.9, 34.0, 57.1, 25.0, 38.4, 64.6, 32.3, 15.4], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"3d5243d6-bdc7-4152-98de-e6f2ecf6aea9\", \"x\": [\"A\", \"C\", \"F\", \"L\", \"N\", \"P\", \"S\", \"W\"], \"xaxis\": \"x2\", \"y\": [6.9, 34.0, 57.1, 25.0, 38.4, 64.6, 32.3, 15.4], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Count of Survival and Death by ticketProcessed\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.9999999999999999, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Percentage Count of Survival and Death by ticketProcessed\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.35, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"barmode\": \"group\", \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"width\": 1000, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>ticketProcessed</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.6499999999999999, 0.9999999999999999], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.35], \"title\": {\"text\": \"<b>Rel Frequency(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('39f72251-7158-48b5-b74d-f8667e8749f0');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 155,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 83,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** 93% passengers died with ticket category A, over 64% survived from category P. Over 57% survived from F and just over 15% passengers survived from ticket category W.",
            "mc_idx": 156,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Perform Chi-square test of independence between ticketProcessed and Survived.\"\"\"\ncalculateChiSquare(df_train.ticketProcessed)",
            "mc_idx": 157,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    84,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Chi Square Test Result between Survived & ticketProcessed:\n(36.7098892616397, 5.323006335674428e-06, 7, array([[ 17.86868687,  11.13131313],\n       [ 28.95959596,  18.04040404],\n       [  4.31313131,   2.68686869],\n       [  2.46464646,   1.53535354],\n       [407.28282828, 253.71717172],\n       [ 40.05050505,  24.94949495],\n       [ 40.05050505,  24.94949495],\n       [  8.01010101,   4.98989899]]))\n"
                    ]
                },
                "mc_idx": 157,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 84,
                "o_idx": 0
            }
        },
        {
            "source": "**Interpretation of chi-square test result**: Since all of the expected frequencies aren't greater than 5, the chi2 test results can't be trusted.\n\n# 9.Multivariate Analysis <a id=\"9\"></a>\nIn multivariate analysis, we try to find the relationship among more than two variables. Number of predictor variable in bivariate analysis was one. On the contrary, number of predictor variables for multivariate analysis are more than one. More specifically, we will try to associate more than one predictor variable with the response variable. We will just visualize the impact of different predictor variables (3 variables) at a time on variable Survived.",
            "mc_idx": 158,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Create a function that plots the impact of 3 predictor variables at a time on a target variable.\"\"\"\ndef doMultivariateAnalysis(catVar1, catVar2, catVar3, targetCatVariable=df_train.Survived):\n    \"\"\"Plots the impact of 3 variables on Survived variable at the same time.\n    catVar1 = independent categorical variable 1,\n    catVar2 = independent categorical variable 2,\n    catVar3 = independent categorical variable 3.\n    targetCatVariable = our dependent categorical variable.\"\"\"\n    \n    fig,ax = plt.subplots(1,1,figsize = (18,5))\n    fontSize = 15\n    catGroupedByCatTarget = pd.crosstab(index = [catVar1, catVar2, catVar3],\n                                        columns = targetCatVariable, normalize = \"index\")*100\n    catGroupedByCatTarget.rename({0:\"%Died\", 1:\"%Survived\"}, axis = 1, inplace = True)\n    catGroupedByCatTarget.plot.bar(color = [\"red\", \"green\"],ax=ax)\n    ax.set_xlabel(f\"{catVar1.name},{catVar2.name},{catVar3.name}\", fontsize = fontSize)\n    ax.set_ylabel(\"Relative Frequency(%)\", fontsize = fontSize)\n    ax.tick_params(axis=\"x\", labelsize=fontSize)\n    ax.tick_params(axis=\"x\", labelsize=fontSize)\n    plt.legend(loc = \"best\")\n    return plt.show()",
            "mc_idx": 159,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.16666666666666666,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.16666666666666666,
                "Hyperparameter_Tuning": 0.16666666666666666,
                "Visualization": 0.08333333333333333,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1,
                    "variable": 11
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".bar(": 1,
                    "columns": 1,
                    "size": 10
                },
                "Data_Transform": {
                    ".cross": 1,
                    ".rename": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "impact": 2
                },
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {
                    ".bar(": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    85,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 159,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 85,
                "o_idx": 0
            }
        },
        {
            "source": "## 9.1 (Pclass, Sex, cabinProcessed) vs Survived <a id=\"9.1\"></a>",
            "mc_idx": 160,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to pclass, sex, and cabinProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.cabinProcessed)\nbold(\"Findings: Sex male seems to be deciding factor for death.\")",
            "mc_idx": 161,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    86,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 161,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 86,
                "o_idx": 1
            }
        },
        {
            "source": "## 9.2 (Pclass, Sex, Embarked) vs Survived <a id=\"9.2\"></a>",
            "mc_idx": 162,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to pclass, sex, and embarked.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.Embarked)\nbold(\"Findings: Again Sex male seems to be deciding factor for death and female for survival.\")",
            "mc_idx": 163,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    87,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 163,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 87,
                "o_idx": 1
            }
        },
        {
            "source": "## 9.3 (Pclass, Sex, SibSp) vs Survived <a id=\"9.3\"></a>",
            "mc_idx": 164,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to pclass, sex, and SibSp.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.SibSp)\nbold(\"Findings: Bigger SibSp and male Sex is responsible more for death.\")",
            "mc_idx": 165,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    88,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 165,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 88,
                "o_idx": 1
            }
        },
        {
            "source": "## 9.4 (Pclass, Sex, Parch) vs Survived <a id=\"9.4\"></a>",
            "mc_idx": 166,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to pclass, sex, and Parch.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.Parch)\nbold(\"indings: Bigger Parch and Sex male is responsible more for death.\")",
            "mc_idx": 167,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    89,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 167,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 89,
                "o_idx": 1
            }
        },
        {
            "source": "## 9.5 (Pclass, Sex, nameProcessed) vs Survived <a id=\"9.5\"></a>",
            "mc_idx": 168,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to pclass, sex, and nameProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.nameProcessed)\nbold(\"Findings: Findings: Passengers with sex male and title mr mostly died.\")",
            "mc_idx": 169,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    90,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 169,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 90,
                "o_idx": 1
            }
        },
        {
            "source": "## 9.6 (Pclass, Sex, familySize) vs Survived <a id=\"9.6\"></a>",
            "mc_idx": 170,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to pclass, sex, and familySize.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.familySize)\nbold(\"Findings: Sex male, family size single and large greatly influence the death ratio.\")",
            "mc_idx": 171,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 3
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    91,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 171,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 91,
                "o_idx": 1
            }
        },
        {
            "source": "## 9.7 (Pclass, Sex, ticketProcessed) vs Survived <a id=\"9.7\"></a>",
            "mc_idx": 172,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to pclass, sex, and ticketProcessed category.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.ticketProcessed)\nbold(\"Findings: Sex female, ticketProcessed p and w mostly survived.\")",
            "mc_idx": 173,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    92,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 173,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 92,
                "o_idx": 1
            }
        },
        {
            "source": "## 9.8 (Pclass, nameProcessed, cabinProcessed) vs Survived <a id=\"9.8\"></a>",
            "mc_idx": 174,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to pclass, nameProcessed, and cabinProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.nameProcessed, df_train.cabinProcessed)\nbold(\"Findings: Title mrs, master and cabin x had best survival ratio.\")",
            "mc_idx": 175,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    93,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 175,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 93,
                "o_idx": 1
            }
        },
        {
            "source": "## 9.9 (familySize, Sex, cabinProcessed) vs Survived <a id=\"9.9\"></a>",
            "mc_idx": 176,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to familSize, sex, and cabinProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.familySize, df_train.Sex, df_train.cabinProcessed)\nbold(\"Findings: family size small, medium and sex female had best survival chance.\")",
            "mc_idx": 177,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 3
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    94,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 177,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 94,
                "o_idx": 1
            }
        },
        {
            "source": "## 9.10 (Sex, nameProcessed, familySize) vs Survived <a id=\"9.10\"></a>",
            "mc_idx": 178,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to sex, nameProcessed, and familySize.\"\"\"\ndoMultivariateAnalysis(df_train.Sex, df_train.nameProcessed, df_train.familySize)\nbold(\"Findings: Title aristocrat, sex female and familySize small mostly survived.\")",
            "mc_idx": 179,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 3
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    95,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 179,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 95,
                "o_idx": 1
            }
        },
        {
            "source": "## 9.11 (Sex, nameProcessed, cabinProcessed) vs Survived <a id=\"9.11\"></a>",
            "mc_idx": 180,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to sex, nameProcessed, and cabinProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.Sex, df_train.nameProcessed, df_train.cabinProcessed)\nbold(\"Findings: Title aristocrat, miss, mrs and sex female mostly survived.\")",
            "mc_idx": 181,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    96,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 181,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 96,
                "o_idx": 1
            }
        },
        {
            "source": "## 9.12 (Sex, nameProcessed, Embarked) vs Survived <a id=\"9.12\"></a>",
            "mc_idx": 182,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to sex, nameProcessed, and embarked.\"\"\"\ndoMultivariateAnalysis(df_train.Sex, df_train.nameProcessed, df_train.Embarked)\nbold(\"Findings: Embarked c, sex female and title master and aristocrat had best survival rate.\")",
            "mc_idx": 183,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    97,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 183,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 97,
                "o_idx": 1
            }
        },
        {
            "source": "## 9.13 (Sex, nameProcessed, ticketProcessed) vs Survived <a id=\"9.13\"></a>",
            "mc_idx": 184,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to sex, nameProcessed, and ticketProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.Sex, df_train.nameProcessed, df_train.ticketProcessed)\nbold(\"Findings: ticketProcessed n, w and sex male and title mr mostly died.\")",
            "mc_idx": 185,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    98,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 185,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 98,
                "o_idx": 1
            }
        },
        {
            "source": "# 10.Data Transformation <a id=\"10\"></a>\nIn this section, we will categorize our continuous variables. After that, redundant and useless features will be dropped. And finally categorical variables will be encoded into numerical variables to feed our machine learning models.\n\n## 10.1 Binning Continuous Variables <a id=\"10.1\"></a>\nWe saw Age is inversely correlated with survival and infants were more likely to survive. We will create some categories of age to check which categories of age  are more likely to survive. We would do the same for Fare except Fair is posivively correlated with Survived.\n\n**Note:** Binning continuous variables prevents overfitting which is a common problem for tree based models like decision trees and random forest etc.\n\n### 10.1.1 Binning Age <a id=\"10.1.1\"></a>",
            "mc_idx": 186,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Create bin categories for Age.\"\"\"\nageGroups = [\"infant\",\"child\",\"teenager\",\"youngAdult\",\"adult\",\"aged\"]\n\n\"\"\"Create range for each bin categories of Age.\"\"\"\ngroupRanges = [0,5,12,18,35,60,81]\n\n\"\"\"Create and view categorized Age with original Age.\"\"\"\nmerged[\"ageBinned\"] = pd.cut(merged.Age, groupRanges, labels = ageGroups)\nbold('**Age with Categorized Age:**')\ndisplay(merged[['Age', 'ageBinned']].head(2))",
            "mc_idx": 187,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.6666666666666666,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".cut(": 1,
                    ".cut": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    99,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "    Age   ageBinned\n0  22.0  youngAdult\n1  38.0       adult"
                    ]
                },
                "mc_idx": 187,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 99,
                "o_idx": 1
            }
        },
        {
            "source": "### 10.1.2 Binning Fare <a id=\"10.1.2\"></a>",
            "mc_idx": 188,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Create bin categories for Fare.\"\"\"\nfareGroups = [\"low\",\"medium\",\"high\",\"veryHigh\"]\n\n\"\"\"Create range for each bin categories of Fare.\"\"\"\nfareGroupRanges = [-1, 130, 260, 390, 520]\n\n\"\"\"Create and view categorized Fare with original Fare.\"\"\"\nmerged[\"fareBinned\"] = pd.cut(merged.Fare, fareGroupRanges, labels = fareGroups)\nbold(\"Fare with Categorized Fare:\")\ndisplay(merged[[\"Fare\", \"fareBinned\"]].head(2))",
            "mc_idx": 189,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.6666666666666666,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".cut(": 1,
                    ".cut": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    100,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "      Fare fareBinned\n0   7.2500        low\n1  71.2833        low"
                    ]
                },
                "mc_idx": 189,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 100,
                "o_idx": 1
            }
        },
        {
            "source": "##  10.2 Dropping Features <a id=\"10.2\"></a>\nNow we have both transformed and the original variables transformation have been made from. So we should safely drop the variables that we think would not be useful anymore for our survival analysis since they are very unlikely to be analyzed in their raw forms.",
            "mc_idx": 190,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "display(merged.head(2))",
            "mc_idx": 191,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    101,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived    ...       ageBinned fareBinned\n0            1       0.0    ...      youngAdult        low\n1            2       1.0    ...           adult        low\n\n[2 rows x 18 columns]"
                    ]
                },
                "mc_idx": 191,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 101,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Let's see all the variables we currently have with their category.\"\"\"\ndisplay(merged.head(2))\n\n\"\"\"Drop the features that would not be useful anymore.\"\"\"\nmerged.drop(columns = [\"Name\", \"Age\", \"Fare\", \"Ticket\", \"Cabin\"], inplace = True, axis = 1)\n\n\"\"\"Features after dropping.\"\"\"\nbold(\"Features Remaining after Dropping:\")\ndisplay(merged.columns)",
            "mc_idx": 192,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.2,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    "columns": 2,
                    ".head": 1
                },
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    102,
                    2,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived    ...       ageBinned fareBinned\n0            1       0.0    ...      youngAdult        low\n1            2       1.0    ...           adult        low\n\n[2 rows x 18 columns]",
                        "<IPython.core.display.Markdown object>",
                        "Index(['PassengerId', 'Survived', 'Pclass', 'Sex', 'SibSp', 'Parch',\n       'Embarked', 'cabinProcessed', 'nameProcessed', 'familySize',\n       'ticketProcessed', 'ageBinned', 'fareBinned'],\n      dtype='object')"
                    ]
                },
                "mc_idx": 192,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 102,
                "o_idx": 2
            }
        },
        {
            "source": "## 10.3 Correcting Data Types <a id=\"10.3\"></a>",
            "mc_idx": 193,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Checking current data types.\"\"\"\nbold(\"Current Variable Data Types:\")\ndisplay(merged.dtypes)",
            "mc_idx": 194,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "dtypes": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    103,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "PassengerId           int64\nSurvived            float64\nPclass                int64\nSex                  object\nSibSp                 int64\nParch                 int64\nEmbarked             object\ncabinProcessed       object\nnameProcessed        object\nfamilySize           object\nticketProcessed      object\nageBinned          category\nfareBinned         category\ndtype: object"
                    ]
                },
                "mc_idx": 194,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 103,
                "o_idx": 1
            }
        },
        {
            "source": "1. PassengerId, SibSp, and Parch data types will be kept same (integer).\n2. Survived data type will be converted into integer and rest of the variables' data types will be converted into categorical data types.",
            "mc_idx": 195,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Correcting data types, converting into categorical variables.\"\"\"\nmerged.loc[:, [\"Pclass\", \"Sex\", \"Embarked\", \"cabinProcessed\", \"nameProcessed\", \"familySize\", \"ticketProcessed\"]]\\\n= merged.loc[:, [\"Pclass\", \"Sex\", \"Embarked\", \"cabinProcessed\", \"nameProcessed\", \"familySize\", \"ticketProcessed\"]]\\\n.astype('category')",
            "mc_idx": 196,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.5,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 2
                },
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    104,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 196,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 104,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Check if data types have been corrected.\"\"\"\nbold(\"Data Types after Correction:\")\ndisplay(merged.dtypes)",
            "mc_idx": 197,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "dtypes": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    105,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "PassengerId           int64\nSurvived            float64\nPclass             category\nSex                category\nSibSp                 int64\nParch                 int64\nEmbarked           category\ncabinProcessed     category\nnameProcessed      category\nfamilySize         category\nticketProcessed    category\nageBinned          category\nfareBinned         category\ndtype: object"
                    ]
                },
                "mc_idx": 197,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 105,
                "o_idx": 1
            }
        },
        {
            "source": "## 10.4 Encoding Categorical Variables <a id=\"10.4\"></a>\nWe would like to use one hot encoding instead of label encoding because algorithm might give weights to higher values if label encoding is used to encode numeric variables.",
            "mc_idx": 198,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Convert categorical data into numeric to feed our machine learning model.\"\"\"\nmerged = pd.get_dummies(merged)\n\n\"\"\"Let's visualize the updated dataset that would be fed to our machine learning algorithms.\"\"\"\nbold(\"Preview of Processed Data:\")\ndisplay(merged.head(2))",
            "mc_idx": 199,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.3333333333333333,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.6666666666666666,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 0.3333333333333333,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.3333333333333333,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "dataset": 1
                },
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".get_dummies": 1
                },
                "Model_Train": {
                    "learning algorithm": 1,
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "visualize": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    106,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "   PassengerId         ...           fareBinned_veryHigh\n0            1         ...                             0\n1            2         ...                             0\n\n[2 rows x 49 columns]"
                    ]
                },
                "mc_idx": 199,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 106,
                "o_idx": 1
            }
        },
        {
            "source": "# 11.Model Building and Evaluation <a id=\"11\"></a>\nWith all the preprocessings done and dusted, we're ready to train classifiers with the processed data. First extract train and test data from variable merged. Then feed the training data to the classifiers we're interested in for this problem.",
            "mc_idx": 200,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Set a seed for reproducibility\"\"\"\nseed = 43\n\n\"\"\"Let's split the train and test set to feed machine learning algorithm.\"\"\"\ntrain = merged.iloc[:891, :]\ntest  = merged.iloc[891:, :]",
            "mc_idx": 201,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "learning algorithm": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    107,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 201,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 107,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Drop passengerid from train set and Survived from test set.\"\"\"\ntrain = train.drop(columns = [\"PassengerId\"], axis = 1)\ntrain.Survived = train.Survived.astype(int) # Converts Survived to int requored for submission, otherwise\ntest = test.drop(columns = [\"Survived\"], axis = 1) # you will scored 0 on submission.",
            "mc_idx": 202,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.6666666666666666,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 2
                },
                "Data_Transform": {
                    ".astype(": 1,
                    ".drop": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    108,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 202,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 108,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Extract data sets as input and output for machine learning models.\"\"\"\nxTrain = train.drop(columns = [\"Survived\"], axis = 1) # Input matrix as pandas dataframe (dim:891*47).\nyTrain = train['Survived'] # Output vector as pandas series (dim:891*1)\n\n\"\"\"Extract test set\"\"\"\nxTest  = test.drop(\"PassengerId\", axis = 1).copy()",
            "mc_idx": 203,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 1.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "extract": 2
                },
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {
                    ".drop": 2
                },
                "Model_Train": {
                    "model": 1,
                    "learning models": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    109,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 203,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 109,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"See the dimensions of input and output data set.\"\"\"\nprint(f\"Input Matrix Dimension: {xTrain.shape}\")\nprint(f\"Output Vector Dimension: {yTrain.shape}\")\nprint(f\"Test Data Dimension: {xTest.shape}\")",
            "mc_idx": 204,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "shape": 3
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    110,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Input Matrix Dimension: (891, 47)\nOutput Vector Dimension: (891,)\nTest Data Dimension: (418, 47)\n"
                    ]
                },
                "mc_idx": 204,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 110,
                "o_idx": 0
            }
        },
        {
            "source": "## 11.1 Training Model <a id=\"11.1\"></a>\nWe would train 10 different classifiers for this binary classification problem.",
            "mc_idx": 205,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Building machine learning models: \nWe will try 10 different classifiers to find the best classifier after tunning model's hyperparameters that will best generalize the unseen(test) data.\"\"\"\n\n\"\"\"Now initialize all the classifiers object.\"\"\"\n\"\"\"#1.Logistic Regression\"\"\"\nlr = LogisticRegression()\n\n\"\"\"#2.Support Vector Machines\"\"\"\nsvc = SVC(gamma = \"auto\")\n\n\"\"\"#3.Random Forest Classifier\"\"\"\nrf = RandomForestClassifier(random_state = seed, n_estimators = 100)\n\n\"\"\"#4.KNN\"\"\"\nknn = KNeighborsClassifier()\n\n\"\"\"#5.Gaussian Naive Bayes\"\"\"\ngnb = GaussianNB()\n\n\"\"\"#6.Decision Tree Classifier\"\"\"\ndt = DecisionTreeClassifier(random_state = seed)\n\n\"\"\"#7.Gradient Boosting Classifier\"\"\"\ngbc = GradientBoostingClassifier(random_state = seed)\n\n\"\"\"#8.Adaboost Classifier\"\"\"\nabc = AdaBoostClassifier(random_state = seed)\n\n\"\"\"#9.ExtraTrees Classifier\"\"\"\netc = ExtraTreesClassifier(random_state = seed)\n\n\"\"\"#10.Extreme Gradient Boosting\"\"\"\nxgbc = XGBClassifier(random_state = seed)\n\n\n\"\"\"List of all the models with their indices.\"\"\"\nmodelNames = [\"LR\", \"SVC\", \"RF\", \"KNN\", \"GNB\", \"DT\", \"GBC\", \"ABC\", \"ETC\", \"XGBC\"]\nmodels = [lr, svc, rf, knn, gnb, dt, gbc, abc, etc, xgbc]",
            "mc_idx": 206,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.05555555555555555,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.2777777777777778,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.16666666666666666,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".log": 1
                },
                "Model_Train": {
                    "model": 5,
                    "randomforestclassifier": 2,
                    "learning models": 1,
                    "logisticregression": 1,
                    "gradientboostingclassifier": 1,
                    "decisiontreeclassifier": 1,
                    "kneighborsclassifier": 1,
                    "svc": 4,
                    "gaussiannb": 1,
                    "adaboostclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 5
                },
                "Model_Interpretation": {
                    "model": 5,
                    "gradient": 3,
                    ".gradient": 1
                },
                "Hyperparameter_Tuning": {
                    "param": 1,
                    "hyperparameter": 1,
                    "hyperparameters": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    111,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 206,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 111,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Create a function that returns train accuracy of different models.\"\"\"\ndef calculateTrainAccuracy(model):\n    \"\"\"Returns training accuracy of a model.\"\"\"\n    \n    model.fit(xTrain, yTrain)\n    trainAccuracy = model.score(xTrain, yTrain)\n    trainAccuracy = round(trainAccuracy*100, 2)\n    return trainAccuracy\n\n# Calculate train accuracy of all the models and store them in a dataframe\nmodelScores = list(map(calculateTrainAccuracy, models))\ntrainAccuracy = pd.DataFrame(modelScores, columns = [\"trainAccuracy\"], index=modelNames)\ntrainAccuracySorted = trainAccuracy.sort_values(by=\"trainAccuracy\", ascending=False)\nbold(\"Training Accuracy of the Classifiers:\")\ndisplay(trainAccuracySorted)",
            "mc_idx": 207,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.08333333333333333,
                "Data_Transform": 0.08333333333333333,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.9166666666666666,
                "Model_Interpretation": 0.8333333333333334,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.08333333333333333,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {
                    "model.fit": 1,
                    ".fit(": 1,
                    "model": 10
                },
                "Model_Evaluation": {
                    "model": 10,
                    ".score(": 1
                },
                "Model_Interpretation": {
                    "model": 10
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    "store": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    112,
                    2,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning:\n\nThe default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n\n",
                        "<IPython.core.display.Markdown object>",
                        "      trainAccuracy\nRF            90.91\nDT            90.91\nETC           90.91\nGBC           86.64\nXGBC          86.31\nKNN           85.30\nLR            84.06\nABC           84.06\nSVC           83.05\nGNB           80.02"
                    ]
                },
                "mc_idx": 207,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 112,
                "o_idx": 2
            }
        },
        {
            "source": "**Looks like all the tree based models have highest train accuracy followed KNN, LR, ABC and SVC. But train accuracy of a model is not enough to tell if a model can be able to generalize the unseen data or not. Because training data is something our model has been trained with, i.e., data our model has already seen it. We all know that, the purpose of building a machine learning model is to generalize the unseen data, i.e., data our model has not yet seen. Hence we can't use training accuracy for our model evaluation rather we must know how our model will perform on the data our model is yet to see.**\n\n## 11.2 Model Evaluation <a id=\"11.2\"></a>\nSo basically, to evaluate a model's performance, we need some data (input) for which we know the ground truth(label). For this problem, we don't know the ground truth for the test set but we do know for the train set. So the idea is to train and evaluate the model performance on different data. One thing we can do is to split the train set in two groups, usually in 80:20 ratio. That means we would train our model on 80% of the training data and we reserve the rest 20% for evaluating the model since we know the ground truth for this 20% data. Then we can compare our model prediction with this ground truth (for 20% data). That's how we can tell how our model would perform on unseen data. This is the first model evaluation technique. In sklearn we have a train_test_split method for that.\n\nTrain_test split has its drawbacks. Because this approach introduces bias as we are not using all of our observations for testing and also we're  reducing the train data size. To overcome this we can use a technique called cross validation where all the data is used for training and testing periodically. Thus we may reduce the bias introduced by train_test_split. From different cross validation methods, we would use k-fold cross validation. In sklearn we have a method cross_val_score for calculating k-fold cross validation score.\n\nHowever,  as the train set gets larger, train_test_split has its advantage over k-fold cross validation. Train_test_split is k-times faster than k-fold cross validation. If the training set is very large, both train_test_split and k-fold cross validation perform identically. So for a large training data, train_test_split is prefered over k-fold cross validation to accelerate the training process.\n\n### 11.2.1 K-Fold Cross Validation <a id=\"11.2.1\"></a>\nLet's say we will use 10-fold cross validation. So k = 10 and we have total 891 observations. Each fold would have 891/10 = 89.1 observations. So basically k-fold cross validation uses fold-1 (89.1 samples) as the testing set and k-1 (9 folds) as the training sets and calculates test accuracy.This procedure is repeated k times (if k = 10, then 10 times); each time, a different group of observations is treated as a validation or test set. This process results in k estimates of the test accuracy which are then averaged out.",
            "mc_idx": 208,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Create a function that returns mean cross validation score for different models.\"\"\"\ndef calculateXValScore(model):\n    \"\"\"Returns models' cross validation scores.\"\"\"\n    \n    xValScore = cross_val_score(model, xTrain, yTrain, cv = 10, scoring=\"accuracy\").mean()\n    xValScore = round(xValScore*100, 2)\n    return xValScore\n\n# Calculate cross validation scores of all the models and store them in a dataframe\nmodelScores = list(map(calculateXValScore, models))\nxValScores = pd.DataFrame(modelScores, columns = [\"xValScore\"], index=modelNames)\nxValScoresSorted = xValScores.sort_values(by=\"xValScore\", ascending=False)\nbold(\"Models 10-fold Cross Validation Score:\")\ndisplay(xValScoresSorted)",
            "mc_idx": 209,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2727272727272727,
                "Data_Transform": 0.09090909090909091,
                "Model_Train": 0.9090909090909091,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.9090909090909091,
                "Hyperparameter_Tuning": 0.09090909090909091,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.09090909090909091,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    "columns": 1,
                    ".mean": 1
                },
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {
                    "model": 10
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    "model": 10
                },
                "Model_Interpretation": {
                    "model": 10
                },
                "Hyperparameter_Tuning": {
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    "store": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    113,
                    2,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "<IPython.core.display.Markdown object>",
                        "      xValScore\nLR        82.72\nGBC       82.72\nSVC       82.71\nXGBC      82.27\nKNN       81.61\nABC       81.48\nRF        81.15\nDT        80.26\nETC       80.03\nGNB       77.69"
                    ]
                },
                "mc_idx": 209,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 113,
                "o_idx": 2
            }
        },
        {
            "source": "**I've always found that trying out multiple algorithms on the same problem reveals very interesting differences in the patterns the algorithms pick up well. Algorithms disagree on predictions because they've different ways of viewing the data.**\n\n**Findings:** Looks like LR and SVC have the highest cross validation accuracy among the classifiers, followed by GBC, XGBC, KNN, ABC, RF, and ETC.\n\n## 11.2.2 Tuning Hyperparameters  <a id=\"11.2.2\"></a>\n**Now let's add Grid Search to all the classifiers with the hopes of optimizing their hyperparameters and thus improving their accuracy. Are the default model parameters the best bet? Let's find out.**\n\n**Note:** Hyperparameters should be tuned for all the models you try because only then you will be able to tell what is the best you can get out of that particular model.",
            "mc_idx": 210,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Define all the models\" hyperparameters one by one first::\"\"\"\n\n\"\"\"Define hyperparameters the logistic regression will be tuned with. For LR, the following hyperparameters are usually tunned.\"\"\"\nlrParams = {\"penalty\":[\"l1\", \"l2\"],\n            \"C\": np.logspace(0, 4, 10),\n            \"max_iter\":[5000]}\n\n\"\"\"For GBC, the following hyperparameters are usually tunned.\"\"\"\ngbcParams = {\"learning_rate\": [0.01, 0.02, 0.05, 0.01],\n              \"max_depth\": [4, 6, 8],\n              \"max_features\": [1.0, 0.3, 0.1], \n              \"min_samples_split\": [ 2, 3, 4],\n              \"random_state\":[seed]}\n\n\"\"\"For SVC, the following hyperparameters are usually tunned.\"\"\"\nsvcParams = {\"C\": np.arange(6,13), \n              \"kernel\": [\"linear\",\"rbf\"],\n              \"gamma\": [0.5, 0.2, 0.1, 0.001, 0.0001]}\n\n\"\"\"For DT, the following hyperparameters are usually tunned.\"\"\"\ndtParams = {\"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n             \"min_samples_split\": np.arange(2,16), \n             \"min_samples_leaf\":np.arange(1,12),\n             \"random_state\":[seed]}\n\n\"\"\"For RF, the following hyperparameters are usually tunned.\"\"\"\nrfParams = {\"criterion\":[\"gini\",\"entropy\"],\n             \"n_estimators\":[10, 15, 20, 25, 30],\n             \"min_samples_leaf\":[1, 2, 3],\n             \"min_samples_split\":np.arange(3,8), \n             \"max_features\":[\"sqrt\", \"auto\", \"log2\"],\n             \"random_state\":[44]}\n\n\"\"\"For KNN, the following hyperparameters are usually tunned.\"\"\"\nknnParams = {\"n_neighbors\":np.arange(3,9),\n              \"leaf_size\":[1, 2, 3, 5],\n              \"weights\":[\"uniform\", \"distance\"],\n              \"algorithm\":[\"auto\", \"ball_tree\",\"kd_tree\",\"brute\"]}\n\n\"\"\"For ABC, the following hyperparameters are usually tunned.\"\"\"\nabcParams = {\"n_estimators\":[1, 5, 10, 15, 20, 25, 40, 50, 60, 80, 100, 130, 160, 200, 250, 300],\n              \"learning_rate\":[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5],\n              \"random_state\":[seed]}\n\n\"\"\"For ETC, the following hyperparameters are usually tunned.\"\"\"\netcParams = {\"max_depth\":[None],\n              \"max_features\":[1, 3, 10],\n              \"min_samples_split\":[2, 3, 10],\n              \"min_samples_leaf\":[1, 3, 10],\n              \"bootstrap\":[False],\n              \"n_estimators\":[100, 300],\n              \"criterion\":[\"gini\"], \n              \"random_state\":[seed]}\n\n\"\"\"For XGBC, the following hyperparameters are usually tunned.\"\"\"\nxgbcParams = {\"n_estimators\": (150, 250, 350, 450, 550, 650, 700, 800, 850, 1000),\n              \"learning_rate\": (0.01, 0.6),\n              \"subsample\": (0.3, 0.9),\n              \"max_depth\": np.arange(3,10),\n              \"colsample_bytree\": (0.5, 0.9),\n              \"min_child_weight\": [1, 2, 3, 4],\n              \"random_state\":[seed]}",
            "mc_idx": 211,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.023809523809523808,
                "Data_Transform": 0.023809523809523808,
                "Model_Train": 0.07142857142857142,
                "Model_Evaluation": 0.023809523809523808,
                "Model_Interpretation": 0.023809523809523808,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {
                    ".log": 1
                },
                "Model_Train": {
                    "model": 1,
                    "svc": 2
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {
                    "param": 20,
                    "hyperparameter": 11,
                    "hyperparameters": 11
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    114,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 211,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 114,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Create a function to tune hyperparameters of the selected models.\"\"\"\ndef tuneHyperparameters(model, params):\n    \"\"\"Returns best score of a model and its corresponding hyperparameters.\n    model = model to be optimized.\n    params = hyperparameters the models will be optimized with.\"\"\"\n    \n    # Construct grid search object with 10 fold cross validation.\n    gridSearch = GridSearchCV(model, params, verbose=0, cv=10, scoring=\"accuracy\", n_jobs = -1)\n    # Fit using grid search.\n    gridSearch.fit(xTrain, yTrain)\n    bestParams, bestScore = gridSearch.best_params_, round(gridSearch.best_score_*100, 2)\n    return bestScore, bestParams",
            "mc_idx": 212,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.36363636363636365,
                "Model_Evaluation": 0.3181818181818182,
                "Model_Interpretation": 0.3181818181818182,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "model": 7
                },
                "Model_Evaluation": {
                    "model": 7
                },
                "Model_Interpretation": {
                    "model": 7
                },
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "tune hyperparameters": 1,
                    "param": 10,
                    "hyperparameter": 4,
                    "hyperparameters": 4
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    115,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 212,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 115,
                "o_idx": 0
            }
        },
        {
            "source": "**Note:** GridSearchCV will only consider the values for each hyperparameter that you explicitly define here. If you don't \ndefine it in the parameter dictionary object, it will not be included in the grid search.This process of finding the best \nparameters is called exhaustive grid-search because its trying every combination.",
            "mc_idx": 213,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Due to computational restrictions, I won't optimise xgbc's hyperparameters.\"\"\"\nmodelNamesToTune = [x for x in modelNames if x not in [\"GNB\",\"XGBC\"]]\nmodelsToTune = [lr, svc, rf, knn, dt, gbc, abc, etc]\nparametersLists = [lrParams, svcParams, rfParams, knnParams, dtParams, gbcParams, abcParams, etcParams]\nbestScoreAndHyperparameters = list(map(tuneHyperparameters, modelsToTune, parametersLists))",
            "mc_idx": 214,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.3157894736842105,
                "Model_Evaluation": 0.21052631578947367,
                "Model_Interpretation": 0.21052631578947367,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 4,
                    "svc": 2
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4
                },
                "Hyperparameter_Tuning": {
                    "param": 13,
                    "hyperparameter": 3,
                    "hyperparameters": 3
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    116,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning:\n\nThe default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n\n"
                    ]
                },
                "mc_idx": 214,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 116,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Let's create a dataframe to store best score and best params.\"\"\"\nbestScoreAndHyperparameters = pd.DataFrame(bestScoreAndHyperparameters,\n                                             index=modelNamesToTune,\n                                             columns=[\"tunedAccuracy\", \"bestHyperparameters\"])\nbestScoreAndHyperparametersSorted = bestScoreAndHyperparameters.sort_values(by=\"tunedAccuracy\",\n                                                                                ascending=False)\nbold(\"Model's Accuracy after Tuning Hyperparameters:\")\ndisplay(bestScoreAndHyperparametersSorted.iloc[:,0].to_frame())",
            "mc_idx": 215,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.045454545454545456,
                "Data_Transform": 0.045454545454545456,
                "Model_Train": 0.09090909090909091,
                "Model_Evaluation": 0.09090909090909091,
                "Model_Interpretation": 0.09090909090909091,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.045454545454545456,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {
                    "model": 2
                },
                "Model_Evaluation": {
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {
                    "param": 8,
                    "hyperparameter": 7,
                    "hyperparameters": 7
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    "store": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    117,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "     tunedAccuracy\nRF           84.40\nGBC          83.95\nETC          83.50\nABC          83.39\nSVC          83.28\nLR           82.94\nKNN          82.94\nDT           81.37"
                    ]
                },
                "mc_idx": 215,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 117,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Let's check out LR separately.\"\"\"\nprint(f\"LR Best Score: {bestScoreAndHyperparametersSorted.loc['LR'][0]}\")\nprint(f\"And Best Parameters: {bestScoreAndHyperparametersSorted.loc['LR'][1]}\")",
            "mc_idx": 216,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 3,
                    "hyperparameter": 2,
                    "hyperparameters": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    118,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "LR Best Score: 82.94\nAnd Best Parameters: {'C': 2.7825594022071245, 'max_iter': 5000, 'penalty': 'l1'}\n"
                    ]
                },
                "mc_idx": 216,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 118,
                "o_idx": 0
            }
        },
        {
            "source": "**Since accuracy increases, it can be said that the most accurate logistic regression model uses C = 2.7825594022071245 and penalty = l2 as hyperparameters.**",
            "mc_idx": 217,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 11.2.3  Model Selection <a id=\"11.2.3\"></a>\nLet's compare our models according to their accuracy score after tunning hyperparameters with cross validation scores to select the best models for further study on this classification problem.",
            "mc_idx": 218,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Create a function that compares cross validation scores with tunned scores for different models by\nplotting them.\"\"\"\ndef compareModelsAccuracy():\n    \"\"\"Returns a stack bar chart of tuned and x validation scores of models.\"\"\"\n    \n    # Sort by index and converting to series object to plot.\n    xValScore = xValScoresSorted[~xValScoresSorted.index.isin([\"XGBC\",\"GNB\"])].sort_index().T.squeeze()\n    tunedScore = bestScoreAndHyperparametersSorted.iloc[:,0].sort_index().T.squeeze()\n    \n    # Create two subplots of stack bar chart\n    fig=make_subplots(\n        rows=1, \n        cols=1,\n        vertical_spacing=0.3,\n        print_grid=False) # This suppresses \"This is the format of your plot grid:\" text from popping out.\n\n    # Add trace for stack bar\n    fig.add_trace(go.Bar(x=xValScore.index,\n                             y=xValScore,\n                             text=xValScore,\n                             hoverinfo=\"x+y\",\n                             textposition=\"auto\",\n                             name=\"xValScore\",\n                             textfont=dict(family=\"sans serif\",size=14),\n                             ),\n                     row=1,\n                     col=1\n                     )\n\n    # Add another trace for stack bar\n    fig.add_trace(go.Bar(x=tunedScore.index,\n                             y=tunedScore,\n                             text=tunedScore,\n                             hoverinfo=\"x+y\",\n                             textposition=\"auto\",\n                             name=\"tunedScores\",\n                             textfont=dict(family=\"sans serif\",size=14),\n                             ),\n                     row=1,\n                     col=1\n                     )\n        \n    # Update the layout. Add title, dimension, and background color\n    fig.layout.update(\n        height=600, \n        width=950,\n        hovermode=\"closest\",\n        barmode = \"stack\",\n        title_text = \"Cross Vaidation Scores vs Optimized Scores\",\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n\n    # Set y-axis titles in bold\n    fig.layout.yaxis1.update(title=\"<b>%Accuracy</b>\")\n    \n    # Set x-axis title in bold\n    fig.layout.xaxis1.update(title=\"<b>Models</b>\")\n    return fig.show()\n\n\"\"\"Call the function to plot the scores.\"\"\"\ncompareModelsAccuracy()",
            "mc_idx": 219,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.1111111111111111,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.6666666666666666,
                "Data_Transform": 1.0,
                "Model_Train": 0.5555555555555556,
                "Model_Evaluation": 0.5555555555555556,
                "Model_Interpretation": 0.5555555555555556,
                "Hyperparameter_Tuning": 0.3333333333333333,
                "Visualization": 0.4444444444444444,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".bar(": 2,
                    "info": 2,
                    "size": 2
                },
                "Data_Transform": {
                    "stack": 5,
                    ".sort_index": 2,
                    ".add": 2
                },
                "Model_Train": {
                    "model": 5
                },
                "Model_Evaluation": {
                    "model": 5
                },
                "Model_Interpretation": {
                    "model": 5
                },
                "Hyperparameter_Tuning": {
                    "param": 1,
                    "hyperparameter": 1,
                    "hyperparameters": 1
                },
                "Visualization": {
                    ".bar(": 2,
                    "chart": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    119,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"bd5d9db6-7af1-4518-bb34-98a18c2a1f09\" class=\"plotly-graph-div\" style=\"height:600px; width:950px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"bd5d9db6-7af1-4518-bb34-98a18c2a1f09\")) {\n                    Plotly.newPlot(\n                        'bd5d9db6-7af1-4518-bb34-98a18c2a1f09',\n                        [{\"hoverinfo\": \"x+y\", \"name\": \"xValScore\", \"text\": [81.48, 80.26, 80.03, 82.72, 81.61, 82.72, 81.15, 82.71], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"26beac71-2583-4be5-bc8f-5e86a8039049\", \"x\": [\"ABC\", \"DT\", \"ETC\", \"GBC\", \"KNN\", \"LR\", \"RF\", \"SVC\"], \"xaxis\": \"x\", \"y\": [81.48, 80.26, 80.03, 82.72, 81.61, 82.72, 81.15, 82.71], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"tunedScores\", \"text\": [83.39, 81.37, 83.5, 83.95, 82.94, 82.94, 84.4, 83.28], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"645600d8-c59e-415a-accf-130661c0d98e\", \"x\": [\"ABC\", \"DT\", \"ETC\", \"GBC\", \"KNN\", \"LR\", \"RF\", \"SVC\"], \"xaxis\": \"x\", \"y\": [83.39, 81.37, 83.5, 83.95, 82.94, 82.94, 84.4, 83.28], \"yaxis\": \"y\"}],\n                        {\"barmode\": \"stack\", \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"title\": {\"text\": \"Cross Vaidation Scores vs Optimized Scores\"}, \"width\": 950, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Models</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>%Accuracy</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('bd5d9db6-7af1-4518-bb34-98a18c2a1f09');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 219,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 119,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** Among the classifiers, RF and GBC have the highest accuracy after  tunning hyperparameters. So RF and GBC are perhaps worthy of further study on this classification problem. Hence we choose RF and GBC.\n\n**Note:** Please note that if we chose our classifier based on cross validation scores, we would not get RF and GBC as our best classifiers instead we would end up choosing LR and SVC. So it is recommended to select best classifiers based on accuracy after tunning hyperparameters though it is computationally intensive.\n\n## 11.3 Retrain and Predict Using Optimized Hyperparameters <a id=\"11.3\"></a>\nSo we have our best classifiers with their best hyperparameters that produces best accuracy out of a model. That means if we retrain the classifiers using their best hyperparameters, we will be able to get the very same score that we got after tunning hyperparameters (see part 14.4). Let's retrain our classifiers and then use cross validation to calculate the accuracy of the trained model. That's how we will have the same accuracy score as after tunning hyperparameters. Let's retrain models with optimized hyperparameters.",
            "mc_idx": 220,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Instantiate the models with optimized hyperparameters.\"\"\"\n# Sort the dataframe by index and select bestHyperparameters column\ntunedParams = bestScoreAndHyperparametersSorted.sort_index().loc[:,\"bestHyperparameters\"]\nabc = AdaBoostClassifier(**tunedParams[\"ABC\"])\ndt  = DecisionTreeClassifier(**tunedParams[\"DT\"])\netc = ExtraTreesClassifier(**tunedParams[\"ETC\"])\ngbc = GradientBoostingClassifier(**tunedParams[\"GBC\"])\nknn = KNeighborsClassifier(**tunedParams[\"KNN\"])\nlr  = LogisticRegression(**tunedParams[\"LR\"])\nrf  = RandomForestClassifier(**tunedParams[\"RF\"])\nsvc = SVC(**tunedParams[\"SVC\"])\n\n\n\n\"\"\"Train all the models with optimised hyperparameters.\"\"\"\nmodels = [abc, dt, etc, gbc, knn, lr, rf, svc]\nmodelNames = tunedParams.index.values\nkeyValue = dict(zip(modelNames, models))\nbold(\"10-fold Cross Validation after Optimization:\")\nxValScore = []\nfor key, value in keyValue.items():\n    # Train the models with optimized parameters using cross validation.\n    # No need to fit the data. cross_val_score does that for us.\n    # But we need to fit train data for prediction in the follow session.\n    value.fit(xTrain, yTrain)\n    scores = cross_val_score(value, xTrain, yTrain, cv = 10, scoring=\"accuracy\")*100\n    xValScore.append(scores.mean())\n    print(\"Mean Accuracy: {:.4f} (+/- {:.4f}) [{}]\".format(scores.mean(), scores.std(), key))",
            "mc_idx": 221,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.03571428571428571,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.21428571428571427,
                "Data_Transform": 0.03571428571428571,
                "Model_Train": 0.6785714285714286,
                "Model_Evaluation": 0.32142857142857145,
                "Model_Interpretation": 0.2857142857142857,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "session": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 2,
                    ".std(": 1,
                    ".mean": 2,
                    ".std": 1
                },
                "Data_Transform": {
                    ".sort_index": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "model": 7,
                    "randomforestclassifier": 2,
                    "logisticregression": 1,
                    "gradientboostingclassifier": 1,
                    "decisiontreeclassifier": 1,
                    "kneighborsclassifier": 1,
                    "svc": 4,
                    "adaboostclassifier": 1
                },
                "Model_Evaluation": {
                    "cross_val_score": 2,
                    "model": 7
                },
                "Model_Interpretation": {
                    "model": 7,
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {
                    "param": 16,
                    "hyperparameter": 5,
                    "hyperparameters": 5,
                    "cross_val_score": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    120,
                    3,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "Mean Accuracy: 83.3929 (+/- 2.6246) [ABC]\nMean Accuracy: 81.3741 (+/- 3.2704) [DT]\nMean Accuracy: 83.5103 (+/- 4.1688) [ETC]\nMean Accuracy: 83.9535 (+/- 3.1242) [GBC]\nMean Accuracy: 82.9484 (+/- 2.6408) [KNN]\n",
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "Mean Accuracy: 82.9434 (+/- 2.9448) [LR]\nMean Accuracy: 84.4067 (+/- 3.9454) [RF]\nMean Accuracy: 83.2830 (+/- 3.7460) [SVC]\n"
                    ]
                },
                "mc_idx": 221,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 120,
                "o_idx": 3
            }
        },
        {
            "source": "**See! We've successfully managed to reproduce the same score that we achived only after tunning hyperparameters. Now if we predict using these trained models, we should have the best test accuracy possible out of those model. So let's predict using those trained models:**",
            "mc_idx": 222,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Make prediction using all the trained models.\"\"\"\nmodelPrediction = pd.DataFrame({\"RF\":rf.predict(xTest),\n                                 \"GBC\":gbc.predict(xTest),\n                                 \"ABC\":abc.predict(xTest),\n                                 \"ETC\":etc.predict(xTest), \n                                 \"DT\":dt.predict(xTest),\n                                 \"SVC\":svc.predict(xTest), \n                                 \"KNN\":knn.predict(xTest), \n                                 \"LR\":lr.predict(xTest)\n                                })\n\n\"\"\"Let\"s see how each model classifies a prticular class.\"\"\"\nbold(\"All the Models Prediction:\")\ndisplay(modelPrediction.head())",
            "mc_idx": 223,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.23076923076923078,
                "Data_Transform": 0.0,
                "Model_Train": 0.5384615384615384,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.38461538461538464,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 5,
                    "svc": 2
                },
                "Model_Evaluation": {
                    "model": 5,
                    ".predict(": 8
                },
                "Model_Interpretation": {
                    "model": 5
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    121,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "   RF  GBC  ABC  ETC  DT  SVC  KNN  LR\n0   0    0    0    0   0    0    0   0\n1   0    1    1    0   0    0    0   1\n2   0    0    0    0   0    0    0   0\n3   0    0    0    0   0    0    0   0\n4   1    1    1    1   1    0    0   1"
                    ]
                },
                "mc_idx": 223,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 121,
                "o_idx": 1
            }
        },
        {
            "source": "## 11.4 Feature Importance <a id=\"11.4\"></a>\nDo the classifiers give the same priority to every feature? Let's visualize the features importance given by our classifiers.",
            "mc_idx": 224,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Create a function that plot feature importance by the selected tree based models.\"\"\"\ndef plotFeatureImportance(model):\n    \"\"\"Return a plot of feature importance by model.\"\"\"\n    \n    importance = pd.DataFrame({\"feature\": xTrain.columns,\n                              \"importance\": np.round(model.feature_importances_,3)})\n    importanceSorted = importance.sort_values(by = \"importance\", ascending = False).set_index(\"feature\")\n    return importanceSorted\n\n\"\"\"Create subplots of feature impotance of rf, gbc, dt, etc, and abc.\"\"\"\nfig, axes = plt.subplots(3,2, figsize = (20,40))\nfig.suptitle(\"Tree Based Models Feature Importance\", fontsize = 28)\ntreeModels = [rf, gbc, dt, etc, abc]\ntreeModelNames = [\"RF\", \"GBC\", \"DT\", \"ETC\", \"ABC\"]\nfor ax, model, name in zip(axes.flatten(), treeModels, treeModelNames):\n    plotFeatureImportance(model).plot.barh(ax=ax, title=name, fontsize=18, color=\"green\")\n    ax.set_ylabel(\"Features\", fontsize = 15)\nfig.delaxes(ax = axes[2,1]) # We don\"t need the last subplot.\nfig.tight_layout(rect = [0, 0.03, 1, 0.97])",
            "mc_idx": 225,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2777777777777778,
                "Data_Transform": 0.16666666666666666,
                "Model_Train": 0.6111111111111112,
                "Model_Evaluation": 0.6111111111111112,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1,
                    "size": 4
                },
                "Data_Transform": {
                    ".sort_values": 1,
                    ".set_index": 1,
                    ".round": 1
                },
                "Model_Train": {
                    "model": 11
                },
                "Model_Evaluation": {
                    "model": 11
                },
                "Model_Interpretation": {
                    "feature_importances_": 2,
                    "feature importance": 3,
                    "model": 11,
                    "featureimportance": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c122_o000_image_17.png",
                    122,
                    0,
                    17
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1440x2880 with 5 Axes>"
                    ]
                },
                "mc_idx": 225,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 122,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** RF, DT, ETC, and ABC (in particular) give some features no importance (zero importance). On the other hand, GBC give all the features more or less importance but it doesn't give zero importance to any features. These are the tree based models that have 'feature_importances_' method by default. LR, KNN and SVC don't have this method. In this problem, SVC uses rbf kernel (only possible for linear kernel to plot feature importance), so its not possible to view feature importance given by SVC. Though its trickier, we would try to get the feature importance given by LR.",
            "mc_idx": 226,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Let's plot feature importance of LR.\"\"\"\nfig, ax = plt.subplots(figsize=(18,4))\ncoeff = pd.DataFrame({\"feature\":xTrain.columns,\n                      \"importance\":np.transpose(lr.coef_[0])})\n\ncoeff.sort_values(by = \"importance\").set_index(\"feature\")\\\n.plot.bar(title = \"Feature Importance of Linear Model (LR)\", color=\"chocolate\", ax=ax)\nax.tick_params(axis = \"both\", which = \"major\", labelsize = 15)\nax.tick_params(axis = \"both\", which = \"minor\", labelsize = 15)\nax.set_xlabel(\"Feature\", fontsize = 15)\nplt.show()",
            "mc_idx": 227,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.14285714285714285,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.42857142857142855,
                "Model_Train": 0.14285714285714285,
                "Model_Evaluation": 0.14285714285714285,
                "Model_Interpretation": 0.5714285714285714,
                "Hyperparameter_Tuning": 0.2857142857142857,
                "Visualization": 0.2857142857142857,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "fig, ax = plt.subplots": 1,
                    ".bar(": 1,
                    "columns": 1,
                    "size": 4
                },
                "Data_Transform": {
                    ".transpose": 1,
                    ".sort_values": 1,
                    ".set_index": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "feature importance": 2,
                    "model": 1,
                    "coef_": 1
                },
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {
                    "fig, ax = plt.subplots": 1,
                    ".bar(": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c123_o000_image_18.png",
                    123,
                    0,
                    18
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x288 with 1 Axes>"
                    ]
                },
                "mc_idx": 227,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 123,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:** We can see some negative values that means that higher value of the corresponding feature pushes the classification more towards the negative class (in our case 0) that is, of course, something we're already aware of. Some features like Family_size_single, Embarked_Q, Embarked_C, and Cabin_F were given zero importance by lr.\n\n## 11.5 Learning Curves  <a id=\"11.5\"></a>\nLet's plot the learning curves for the optimized classifiers to see their bias-variance tradeoff.",
            "mc_idx": 228,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Create a function that returns learning curves for different classifiers.\"\"\"\ndef plotLearningCurve(model):\n    \"\"\"Returns a plot of learning curve of a model.\"\"\"\n    \n    # Create feature matrix and target vector\n    X, y = xTrain, yTrain\n    # Create CV training and test scores for various training set sizes\n    trainSizes, trainScores, testScores = learning_curve(model, X, y, cv = 10,\n                                                    scoring=\"accuracy\", n_jobs = -1, \n                                                    train_sizes = np.linspace(0.01, 1.0, 17), # 17 different sizes of the training set\n                                                    random_state = seed)\n                                                    \n\n    # Create means and standard deviations of training set scores\n    trainMean = np.mean(trainScores, axis = 1)\n    trainStd = np.std(trainScores, axis = 1)\n\n    # Create means and standard deviations of test set scores\n    testMean = np.mean(testScores, axis = 1)\n    testStd = np.std(testScores, axis = 1)\n\n    # Draw lines\n    plt.plot(trainSizes, trainMean, \"o-\", color = \"red\",  label = \"training score\")\n    plt.plot(trainSizes, testMean, \"o-\", color = \"green\", label = \"cross-validation score\")\n    \n    # Draw bands\n    plt.fill_between(trainSizes, trainMean - trainStd, trainMean + trainStd, alpha = 0.1, color = \"r\") # Alpha controls band transparency.\n    plt.fill_between(trainSizes, testMean - testStd, testMean + testStd, alpha = 0.1, color = \"g\")\n\n    # Create plot\n    font_size = 15\n    plt.xlabel(\"Training Set Size\", fontsize = font_size)\n    plt.ylabel(\"Accuracy Score\", fontsize = font_size)\n    plt.xticks(fontsize = font_size)\n    plt.yticks(fontsize = font_size)\n    plt.legend(loc = \"best\")\n    plt.grid()",
            "mc_idx": 229,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.08333333333333333,
                "Model_Evaluation": 0.08333333333333333,
                "Model_Interpretation": 0.08333333333333333,
                "Hyperparameter_Tuning": 0.027777777777777776,
                "Visualization": 0.1111111111111111,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plt.plot": 2,
                    ".plot(": 4,
                    ".mean(": 2,
                    ".std(": 2,
                    "np.mean": 2,
                    "np.std": 2,
                    "size": 18,
                    ".mean": 2,
                    ".std": 2
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 3
                },
                "Model_Evaluation": {
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {
                    "learning_curve": 1
                },
                "Visualization": {
                    "plt.plot": 2,
                    ".plot(": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    124,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 229,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 124,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Now plot learning curves of the optimized models in subplots.\"\"\"\nplt.figure(figsize = (25,25))\nlcModels = [rf, gbc, dt, etc, abc, knn, svc, lr]\nlcLabels = [\"RF\", \"GBC\", \"DT\", \"ETC\", \"ABC\", \"KNN\", \"SVC\", \"LR\"]\n\nfor ax, model, label in zip (range(1,9), lcModels, lcLabels):\n    plt.subplot(4,2,ax)\n    plotLearningCurve(model)\n    plt.title(label, fontsize = 18)\nplt.suptitle(\"Learning Curves of Optimized Models\", fontsize = 28)\nplt.tight_layout(rect = [0, 0.03, 1, 0.97])",
            "mc_idx": 230,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.375,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.75,
                "Model_Interpretation": 0.75,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 3
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 6,
                    "svc": 2
                },
                "Model_Evaluation": {
                    "model": 6
                },
                "Model_Interpretation": {
                    "model": 6
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c125_o000_image_19.png",
                    125,
                    0,
                    19
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1800x1800 with 8 Axes>"
                    ]
                },
                "mc_idx": 230,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 125,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:**\n1. RF, DT, SVC and ETC are just doing okay. Among them, SVC is doing the best in terms of bias-variance tradeoff since svc's train accuracy and cross validation accuracy are almost equal. Since training and validation curves haven't yet converged for these classifiers, adding more instances (rows) might help.\n\n2. On the other hand, learning curve of GBC, ABC, KNN and LR indicates a little bit high bias or low variance (underfitting) and as the curves have already converged, adding more training data just might not help. Rather adding more features (columns) and increasing model's complexity might help.\n\n# 12.More Evaluation Metrics  <a id=\"12\"></a>\nWe've so far used accuracy score to evaluate our classifiers. But sometimes accuracy score isn't all enough to evaluate a classifier properly as accuracy score doesn't tell exactly which class (positive or negative) is being wrongly classified by our classifier in case of low accuracy score. **Again for imbalanced classification problem, accuracy score isn't the best metric to choose between different classifiers. To clarify this, in this section, we will calculate confusion matrix, precision score, recall score, specificity, f1 score, classification report for both random forest and gradient boosting classifier. And then we will compare our two best classifiers (rf and gbc) using these calculated metrics to see exactly where one classifier excels the other.**\n\n## 12.1 Confusion Matrix  <a id=\"12.1\"></a>\nThe confusion matrix shows the number of correct classifications along with misclassifications when a classifier make predictions for each class (positive or negative). The diagonal elements are correct classification while the off diagonal elements are misscalssifications. Some basic terms associated with confusion matrix:\n1. True positives (TP): These are cases in which we predicted 1(yes), and the actual is also 1(yes).\n2. True negatives (TN): We predicted 0(no), and the actual is also 0(no).\n3. False positives (FP): We predicted 1(yes), but the actual is 0(no). (Also known as a \"Type I error.\")\n4. False negatives (FN): We predicted 0(no), but the actual is 1(yes). (Also known as a \"Type II error.\")",
            "mc_idx": 231,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Return prediction to use it in another function.\"\"\"\ndef xValPredict(model):\n    \"\"\"Returns prediction by which we can calculate different classification metrices.\"\"\"\n    \n    predicted = cross_val_predict(model, xTrain, yTrain, cv = 10)\n    return predicted # Now we can use it in another function by assigning the function to its return value.\n\n\"\"\"Function to return confusion matrix.\"\"\"\ndef calculateConfusionMatrix(model):\n    \"\"\"returns a models confusion matrix\"\"\"\n    \n    predicted = xValPredict(model)\n    confusionMatrix = pd.crosstab(yTrain, predicted, rownames = [\"Actual\"],\n                                   colnames = [\"Predicted/Classified\"], margins = True)\n    return display(confusionMatrix)\n\n\"\"\"Now calculate confusion matrix of rf and gbc.\"\"\"\nbold(\"RF Confusion Matrix:\")\ncalculateConfusionMatrix(rf)\nbold(\"GBC Confusion Matrix:\")\ncalculateConfusionMatrix(gbc)",
            "mc_idx": 232,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".cross": 1
                },
                "Model_Train": {
                    "model": 5
                },
                "Model_Evaluation": {
                    "model": 5
                },
                "Model_Interpretation": {
                    "model": 5
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    126,
                    3,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "Predicted/Classified    0    1  All\nActual                             \n0                     510   39  549\n1                     100  242  342\nAll                   610  281  891",
                        "<IPython.core.display.Markdown object>",
                        "Predicted/Classified    0    1  All\nActual                             \n0                     489   60  549\n1                      83  259  342\nAll                   572  319  891"
                    ]
                },
                "mc_idx": 232,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 126,
                "o_idx": 3
            }
        },
        {
            "source": "The 1st row of our confusion matrix( or sometimes called error matrix) is about the negative class (because of 0 and hence non-survived) and The 2nd row of our confusion matrix( or sometimes called error matrix) is about the positive class (because of 1 and hence survived).\n\nFor rf, passengers correctly classified as survived are 243 (true positives) and passengers correctly classified as non-survived (died) are 506(true negatives). While 43 passengers (false positives) from class 0 (non-survived) were misclassified as survived and 99 (false negatives) passengers who actually survived were classified as non-survived.\n\nAnd for gbc, passengers correctly classified as survived are 248(true positives) and passengers correctly classified as non-survived (died) are 501(true negatives). While 48 (false positives) passengers from class 0 (non-survived) were misclassified as survived and 94 (false negatives) passengers who actually survived were misclassified as non-survived.\n\n**RF (749) makes exactly same correct predictions (true positives+true negatives) as gbc (749), hence rf and gbc have exactly same accuracy score that we saw when we calculated both model's accuracy score.**\n\n## 12.2 Precision Score  <a id=\"12.2\"></a>\nPrecision is the ratio of true positive to total predicted positive(true positive + false positive). So precision score tells how many true positives our model can capture out of total predicted positives.",
            "mc_idx": 233,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Function to calculate precision score.\"\"\"\ndef calculatePrecisionScore(model):\n    \"\"\"Calculates a model's precision score.\"\"\"\n    \n    predicted = xValPredict(model)\n    precisionScore = precision_score(yTrain, predicted)\n    return round(precisionScore*100, 2)\n\n\"\"\"Compute precision score for rf and gbc.\"\"\"\nprint(f\"RF  Precision Score: {calculatePrecisionScore(rf)}\")\nprint(f\"GBC Precision Score: {calculatePrecisionScore(gbc)}\")",
            "mc_idx": 234,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.1875,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.1875,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 3
                },
                "Model_Evaluation": {
                    "precision_score": 2,
                    "precision": 11,
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    127,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "RF  Precision Score: 86.12\nGBC Precision Score: 81.19\n"
                    ]
                },
                "mc_idx": 234,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 127,
                "o_idx": 0
            }
        },
        {
            "source": "**RF's precision score tells when it predicts a passenger as a survivor (=class1), it is correct nearly 85% of the time. And gbc's precision score tells when gbc predicts a passenger as a survivor, it is correct nearly 84% of the time. So rf has a better precision score than gbc.**\n\n## 12.3 Recall (or Sensitivity or True Positive Rate)  <a id=\"12.3\"></a>\nRecall is the ratio of true positive to total actual positive(true positive + false negative). So recall score basically calculates true positives from total actual positives.",
            "mc_idx": 235,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Function to calculate recall score.\"\"\"\ndef calculateRecallScore(model):\n    \"\"\"Calculate a model's recall score.\"\"\"\n    \n    predicted = xValPredict(model)\n    recallScore = recall_score(yTrain, predicted)\n    return round(recallScore*100, 2)\n\n\"\"\"Compute recall score for rf and gbc.\"\"\"\nprint(f\"RF  Recall Score: {calculateRecallScore(rf)}\")\nprint(f\"GBC Recall Score: {calculateRecallScore(gbc)}\")",
            "mc_idx": 236,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.1875,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.1875,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 3
                },
                "Model_Evaluation": {
                    "recall_score": 2,
                    "recall": 11,
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    128,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "RF  Recall Score: 70.76\nGBC Recall Score: 75.73\n"
                    ]
                },
                "mc_idx": 236,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 128,
                "o_idx": 0
            }
        },
        {
            "source": "**RF's recall score tells it correctly identifies over 71% of all the survivors. Or put another way, it predicts over 71.5% of the survivors as a survivor. On the other hand, gbc predicts just over 72.5% of the survivors as survivor. So gbc is more capable of capturing true positives than rf that we also observed from confusion matrix.**\n\n## 12.4 Specificity ( or True Negative Rate)  <a id=\"12.4\"></a>\nSpecificity is the ratio of true negative to total actual negative(true negative + false positive). Specificity  is exactly the opposite of recall. So specificity score basically calculates true negatives from total actual negatives.",
            "mc_idx": 237,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Function for specificity score.\"\"\"\ndef calculateSpecificityScore(model):\n    \"\"\"Returns a model's specificity score.\"\"\"\n    \n    predicted = xValPredict(model)\n    tn, fp, fn, tp = confusion_matrix(yTrain, predicted).ravel()\n    specificityScore = tn / (tn + fp)\n    return round(specificityScore*100, 2)\n\n\"\"\"Calculate specificity score for rf and gbc.\"\"\"\nprint(f\"RF  Specificity Score: {calculateSpecificityScore(rf)}\")\nprint(f\"GBC Specificity Score: {calculateSpecificityScore(gbc)}\")",
            "mc_idx": 238,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2,
                "Model_Train": 0.6,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.6,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "ravel": 1
                },
                "Model_Train": {
                    "model": 3
                },
                "Model_Evaluation": {
                    "confusion_matrix": 2,
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    129,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "RF  Specificity Score: 92.9\nGBC Specificity Score: 89.07\n"
                    ]
                },
                "mc_idx": 238,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 129,
                "o_idx": 0
            }
        },
        {
            "source": "**RF's specificity score indicates it correctly predicts over 92% of the victims as a victim. Comparing recall score with specificity, it looks like our rf model is more accurate on predicting negative class (victims = 0) than predicting positive class (survivors = 1).**\n\n**While  gbc's specificity score indicates it correctly predicts over 91% of the victims as a victim. Comparing recall score with specificity, it looks like our gbc also is more accurate on predicting negative class (victims = 0) than predicting positive class (survivors = 1).**\n\n**Interesting! RF is better than capturing true negatives than gbc. So if we were to choose a model between rf and gbc where our priority is the negative class (0), we would choose rf. And if our priority is positive class(1), we would choose gbc.**\n\n## 12.5 F1 Score  <a id=\"12.5\"></a>\nWe can't choose classifiers solely depending on their precision or recall score. Rather we need to consider both to find out the best classifiers. Here comes the f1 score which is  the balanced harmonic mean of Recall and Precision, giving both metrics equal weight. The higher the f1 score is, the better.",
            "mc_idx": 239,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Function for F1 score.\"\"\"\ndef calculateF1Score(model):\n    \"\"\"Returns a model's f1 score.\"\"\"\n    \n    predicted = xValPredict(model)\n    f1Score = f1_score(yTrain, predicted)\n    return round(f1Score*100, 2)\n\n\"\"\"Calculate f1 score for rf and gbc.\"\"\"\nprint(f\"RF  F1 Score: {calculateF1Score(rf)}\")\nprint(f\"GBC F1 Score: {calculateF1Score(gbc)}\")",
            "mc_idx": 240,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.5,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 3
                },
                "Model_Evaluation": {
                    "f1_score": 3,
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    130,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "RF  F1 Score: 77.69\nGBC F1 Score: 78.37\n"
                    ]
                },
                "mc_idx": 240,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 130,
                "o_idx": 0
            }
        },
        {
            "source": "**Looks like gbc is better than rf in terms of f1 score.**\n## 12.6 Classification Report  <a id=\"12.6\"></a>\nPrecision, recall, and f1 score is only associated with true positives. But what if we want to measure true negatives? We can measure them with true positives and count of each class (0 and 1) in  a classification report. It provides precision, recall, f1 score and class count altogether for both classs (0 and 1) but at the cost of less hassle.",
            "mc_idx": 241,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Function to compute classification report.\"\"\"\ndef calculateClassificationReport(model):\n    \"\"\"Returns a model\"s classification report.\"\"\"\n    \n    predicted = xValPredict(model)\n    classificationReport = classification_report(yTrain, predicted)\n    return print(classificationReport)\n\n\"\"\"Now calculate classification report for rf and gbc.\"\"\"\nbold(\"RF Classification Report:\")\ncalculateClassificationReport(rf)\nbold(\"GBC Classification Report:\")\ncalculateClassificationReport(gbc)",
            "mc_idx": 242,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.6,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.6,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 3
                },
                "Model_Evaluation": {
                    "classification_report": 2,
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    131,
                    3,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "              precision    recall  f1-score   support\n\n           0       0.84      0.93      0.88       549\n           1       0.86      0.71      0.78       342\n\n    accuracy                           0.84       891\n   macro avg       0.85      0.82      0.83       891\nweighted avg       0.85      0.84      0.84       891\n\n",
                        "<IPython.core.display.Markdown object>",
                        "              precision    recall  f1-score   support\n\n           0       0.85      0.89      0.87       549\n           1       0.81      0.76      0.78       342\n\n    accuracy                           0.84       891\n   macro avg       0.83      0.82      0.83       891\nweighted avg       0.84      0.84      0.84       891\n\n"
                    ]
                },
                "mc_idx": 242,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 131,
                "o_idx": 3
            }
        },
        {
            "source": "**We can see precision, recall, f1 score and class count for both class (0 and 1) of our two models.**\n## 12.7 Precision-Recall vs Threshold Curve  <a id=\"12.7\"></a>\nSometimes we want a high precision and sometimes a high recall depending on our classification problem. The thing is that an increasing precision results in a decreasing recall and vice versa. This is called the precision-recall tradeoff that can be illustrated using precision-recall curve as a function of the decision threshold.",
            "mc_idx": 243,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Function for plotting precision-recall vs threshold curve.\"\"\"\ndef plotPrecisionRecallVsThresholdCurve(model, title):\n    \"\"\"Plots precision-recall vs threshold curve for a model.\"\"\"\n\n    probablity = model.predict_proba(xTrain)[:, 1]\n    plt.figure(figsize = (18, 5))\n    precision, recall, threshold = precision_recall_curve(yTrain, probablity)\n    plt.plot(threshold, precision[:-1], \"b-\", label = \"precision\", lw = 3.7)\n    plt.plot(threshold, recall[:-1], \"g\", label = \"recall\", lw = 3.7)\n    plt.xlabel(\"Threshold\")\n    plt.legend(loc = \"best\")\n    plt.ylim([0, 1])\n    plt.title(title)\n    plt.show()\n\n\"\"\"Now plot precision-recall vs threshold curve for rf and gbc.\"\"\"\nplotPrecisionRecallVsThresholdCurve(rf, title = \"RF Precision-Recall vs Threshold Curve\" )\nplotPrecisionRecallVsThresholdCurve(gbc, title = \"GBC Precision-Recall vs Threshold Curve\")",
            "mc_idx": 244,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.03571428571428571,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 0.10714285714285714,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.14285714285714285,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.14285714285714285,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plt.plot": 2,
                    ".plot(": 4,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 3
                },
                "Model_Evaluation": {
                    "precision": 12,
                    "recall": 12,
                    "model": 3,
                    "precision_recall_curve": 1
                },
                "Model_Interpretation": {
                    "model": 3,
                    "predict_proba": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "plt.plot": 2,
                    ".plot(": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c132_o001_image_21.png",
                    132,
                    1,
                    21
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<Figure size 1296x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 244,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 132,
                "o_idx": 1
            }
        },
        {
            "source": "**We can see for RF, the recall falls quickly at a precision of around 84%. So therefore, we need to select the precision-recall tradeoff before 84% of precision which could be at around 82%. Now, for example, if we want a precision of 80% off RF we would need a threshold of around 0.4**\n\n**On the other hand, for GBC, the recall falls fast at a precision of around 84% and hence we would select precision-recall tradeoff at around 80% of precision. If we want a precision of around 81% off GBC, we would need a threshold of around 0.38**\n\n## 12.8 Precision-Recall Curve  <a id=\"12.8\"></a>\nWe can also plot precision against recall to get an idea of precision-recall tradeoff where y-axis represents precision and x-axis represents recall. In my plot, I plot recall on y-axis and precision on x-axis.",
            "mc_idx": 245,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Function to plot recall vs precision curve.\"\"\"\ndef plotPrecisionVsRecallCurve(model, title):\n    \"\"\"Return amodel's recall vs precision curve.\"\"\"\n    \n    probablity = model.predict_proba(xTrain)[:, 1]\n    plt.figure(figsize = (18, 5))\n    precision, recall, threshold = precision_recall_curve(yTrain, probablity)\n    plt.plot(recall, precision, \"r-\", lw = 3.7)\n    plt.ylabel(\"Recall\")\n    plt.xlabel(\"Precision\")\n    plt.axis([0, 1.5, 0, 1.5])\n    plt.title(title)\n    plt.show()\n\n\"\"\"Now plot recall vs precision curve of rf and gbc.\"\"\"\nplotPrecisionVsRecallCurve(rf, title = \"RF Precision-Recall Curve\")\nplotPrecisionVsRecallCurve(gbc, title = \"GBC Precision-Recall Curve\")",
            "mc_idx": 246,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.03571428571428571,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.14285714285714285,
                "Data_Transform": 0.0,
                "Model_Train": 0.10714285714285714,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.14285714285714285,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.07142857142857142,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plt.plot": 1,
                    ".plot(": 2,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 3
                },
                "Model_Evaluation": {
                    "precision": 12,
                    "recall": 12,
                    "model": 3,
                    "precision_recall_curve": 1
                },
                "Model_Interpretation": {
                    "model": 3,
                    "predict_proba": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "plt.plot": 1,
                    ".plot(": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c133_o001_image_23.png",
                    133,
                    1,
                    23
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<Figure size 1296x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 246,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 133,
                "o_idx": 1
            }
        },
        {
            "source": "**We can see recall falls rapidly at around a precision of 0.84 for both RF and 0.82 for GBC that we've observed in the previous section.**\n\n## 12.9 ROC  Curve & AUC Score  <a id=\"12.9\"></a>\nROC (Reicever Operating Characteristic Curve) is a plot of the true positive rate against the false positive rate of a classifier. It shows the tradeoff between sensitivity and specificity (any increase in sensitivity will be accompanied by a decrease in specificity). AUC (Area under the ROC Curve) score is the corresponding score to the AUC Curve. It is simply computed by measuring the area under the ROC curve, which is called AUC. We will plot ROC curve and AUC score together for our two classifiers.",
            "mc_idx": 247,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Function to plot ROC curve with AUC score.\"\"\"\ndef plotRocAndAucScore(model, title):\n    \"\"\"Returns roc and auc score of a model.\"\"\"\n    \n    probablity = model.predict_proba(xTrain)[:, 1]\n    plt.figure(figsize = (18, 5))\n    false_positive_rate, true_positive_rate, threshold = roc_curve(yTrain, probablity)\n    auc_score = roc_auc_score(yTrain, probablity)\n    plt.plot(false_positive_rate, true_positive_rate, label = \"ROC CURVE, AREA = \"+ str(auc_score))\n    plt.plot([0, 1], [0, 1], \"red\", lw = 3.7)\n    plt.xlabel(\"False Positive Rate (1-Specificity)\")\n    plt.ylabel(\"True Positive Rate (Sensitivity)\")\n    plt.axis([0, 1, 0, 1])\n    plt.legend(loc = 4)\n    plt.title(title)\n    plt.show()\n\n\"\"\"Plot roc curve and auc score for rf and gbc.\"\"\"\nplotRocAndAucScore(rf, title = \"RF ROC Curve with AUC Score\")\nplotRocAndAucScore(gbc, title = \"GBC ROC Curve with AUC Score\")",
            "mc_idx": 248,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.14285714285714285,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.42857142857142855,
                "Model_Evaluation": 0.8571428571428571,
                "Model_Interpretation": 0.5714285714285714,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.5714285714285714,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plt.plot": 2,
                    ".plot(": 4,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 3
                },
                "Model_Evaluation": {
                    "roc_auc_score": 2,
                    "model": 3,
                    "roc_curve": 1
                },
                "Model_Interpretation": {
                    "model": 3,
                    "predict_proba": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "plt.plot": 2,
                    ".plot(": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c134_o001_image_25.png",
                    134,
                    1,
                    25
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<Figure size 1296x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 248,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 134,
                "o_idx": 1
            }
        },
        {
            "source": "This two plots tells few different things:\n\n1. A model that predicts at chance will have an ROC curve that looks like the diagonal red line. That is not a discriminating model.\n\n2. The further the curve is off the diagonal red line, the better the model is at discriminating between positives and negatives in general.\n\n3. There are useful statistics that can be calculated from this curve, like the Area Under the Curve (AUC). This tells you how well the model predicts and the optimal cut point for any given model (under specific circumstances).\n\n**Comparing the two ROC curves, we can see the distance between blue and red line of RF is greater than the distance between blue and red line of GBC. Hence it can safely be said that RF, in general, is better at discriminating between positives and negatives than GBC. Also RF(92.11%) auc score (which is the area under the roc curve) is greater than gbc(91.94%). It seems the higher the area, the further the classifier is off the red diagonal line and vice versa and hence more accurate. Since RF has more area under the ROC curve than GBC, RF is more accurate.**\n\n# 13.Prediction & Submission  <a id=\"13\"></a>\nFirst we will predict using both rf and gbc. Then we will create two prediction files in csv format for kaggle submission.",
            "mc_idx": 249,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Submission with the most accurate random forest classifier.\"\"\"\nsubmissionRF = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": rf.predict(xTest)})\nsubmissionRF.to_csv(\"rfSubmission.csv\", index = False)\n\n\n\"\"\"Submission with the most accurate gradient boosting classifier.\"\"\"\nsubmissionGBC = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": gbc.predict(xTest)})\nsubmissionGBC.to_csv(\"gbcSubmission.csv\", index = False)",
            "mc_idx": 250,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.25,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {
                    ".predict(": 2
                },
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 2,
                    "to_csv": 2
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    135,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 250,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 135,
                "o_idx": 0
            }
        },
        {
            "source": "**Though both RF and GBC have the identical validation accuracy (in our case optimized accuracy ~0.8406), RF scored 0.79425 while GBC scored 0.78468 on kaggle leaderboard. The fact that gbc's accuracy on the holdout data is 0.78468 compared with the 0.8406 accuracy we got with cross-validation indicates that GBC underfits the training data that we obsetved from the learning curve (see part 11.7). Hence it performs poorly on kaggle hold out set compared to RF.**\n\n### Can we further improve our classifiers' accuracy? May be we can! In the next few section, we will try to improve our models' accuracy with the help of ensemble method.",
            "mc_idx": 251,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 14.Introduction to Ensemble <a id=\"14\"></a>\nCan we further boost the accuracy of our best models? That's what we will try to do using ensemble method. Ensembles combine predictions from different models to generate a final prediction, and the more models we include the better it performs. Better still, because ensembles combine baseline predictions, they perform at least as well as the best baseline model. Most of the errors from a model\u2019s learning are from three main factors: variance, noise, and bias. By using ensemble methods, we\u2019re able to increase the stability of the final model and reduce the errors caused by bias, variance, and noise. By combining many models, we\u2019re able to (mostly) reduce the variance, even when they are individually not great, as we won\u2019t suffer from random errors from a single source. **The main principle behind ensemble modelling is to group weak learners together to form one strong learner. The most basic ensemble is majority voting rule (where the prediction or vote given by the majority of the models used as final prediction).But there are many other ways to combine predictions, and more generally we can use a model to learn how to best combine predictions.**",
            "mc_idx": 252,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**To implement an ensemble we need three basic things:**\n1. A group of base learners that generate predictions.\n2. A meta learner that learns how to best combine these predictions outputed by base learners.\n3. And finally a method for splitting the training data between the base learners and the meta learner.\n\n**An ensemble works best if:**\n1. There is a less correlation in the base models' predictions.\n2. We increase the number of base learners though it might slow the process down.\n\n\n## 14.1 Different Ensemble Methods\nWe would first categorize ensemble methods into two subcategories like 1.Simple Ensemble Methods and 2.Advanced Ensemble Methods\n\n### 14.1.1 Simple Ensemble Methods\nThey're the simpliest yet so useful form of enselbles. They can be further categorised into \n1. Voting, \n2. Averaging and \n3. Weighted Average. \n\nFirst one is usually used for classification while the later two are used for regression problems.\n\n#### 14.1.1.1 Voting Ensemble  \nVoting ensemble is further classified into \n1. Hard voting and \n2. Soft voting.\n\n##### 14.1.1.1.1 Hard Voting (or Majority Voting or Max Voting) <a id=\"14.1\"></a>\nThis hard voting method is usually used for classification problems. The idea is to train multiple models to make predictions for each data point. The predictions by each model are considered as a \u2018vote\u2019. The predictions which we get from the majority of the models are used as the final prediction. Say rf and lr predict a class as 1 while knn predicts the same class as 0. Since the majority of the vots is casted in favour of class 1, the voting classifier would predict the very same class as 1. See the table below to understand how hard voting ensemble works.",
            "mc_idx": 253,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "bold(\"How hard voting works:\")\ndata = [[1, 1, 1, 0, 1], \n        [0, 0, 0, 1, 0]]\ndisplay(pd.DataFrame(data, columns= [\"Class\",\"RF\", \"LR\", \"KNN\", \"Hard_voting\"]).set_index(\"Class\"))",
            "mc_idx": 254,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {
                    ".set_index": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    136,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "       RF  LR  KNN  Hard_voting\nClass                          \n1       1   1    0            1\n0       0   0    1            0"
                    ]
                },
                "mc_idx": 254,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 136,
                "o_idx": 1
            }
        },
        {
            "source": "**Correlation among Base Models Predictions:** How base models' predictions are correlated? If base models' predictions are weakly correlated with each other, the ensemble will likely to perform better. On the other hand, for a strong correlation of predictions among the base models, the ensemble will unlikely to perform better. To sumarize, diversity of predictions among the base models is inversely proportional to the ensemble accuracy. Let's make prediction for the test set.",
            "mc_idx": 255,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Create a data frame to store base models prediction.\nFirst 5 in the dataframe are tree based models. Then two are kernel based. \nAnd the last is a linear model.\"\"\"\nbasePrediction = modelPrediction # We\"ve a df of all the models prediction.\n\n\"\"\"Let\"s see how each model classifies a prticular class.\"\"\"\nbold(\"All the Base Models Prediction:\")\ndisplay(basePrediction.head())\n\n\"\"\"Let\"s visualize the correlations among the predictions of base models.\"\"\"\nfig,ax = plt.subplots(nrows=1, ncols=1, figsize=(15,6))\nsns.heatmap(basePrediction.corr(), cmap =\"YlGnBu\", annot=True, annot_kws={\"size\":14}, ax=ax)\nax.set_title(\"Prediction Correlation among the Base Models\", fontsize = 20)\nax.tick_params(axis = \"both\", which = \"major\", labelsize = 14)\nax.tick_params(axis = \"both\", which = \"minor\", labelsize = 14)\nplt.show()",
            "mc_idx": 256,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.07692307692307693,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.6923076923076923,
                "Model_Evaluation": 0.6923076923076923,
                "Model_Interpretation": 0.6923076923076923,
                "Hyperparameter_Tuning": 0.15384615384615385,
                "Visualization": 0.3076923076923077,
                "Debug": 0.0,
                "Data_Export": 0.07692307692307693,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".corr": 2,
                    ".head(": 1,
                    "sns.heatmap": 1,
                    ".heatmap(": 1,
                    "sns.": 1,
                    "head": 1,
                    "size": 5,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 9
                },
                "Model_Evaluation": {
                    "model": 9
                },
                "Model_Interpretation": {
                    "model": 9
                },
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {
                    "sns.heatmap": 1,
                    ".heatmap(": 1,
                    "sns.": 1,
                    "visualize": 1
                },
                "Debug": {},
                "Data_Export": {
                    "store": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c137_o002_image_26.png",
                    137,
                    2,
                    26
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "   RF  GBC  ABC  ETC  DT  SVC  KNN  LR\n0   0    0    0    0   0    0    0   0\n1   0    1    1    0   0    0    0   1\n2   0    0    0    0   0    0    0   0\n3   0    0    0    0   0    0    0   0\n4   1    1    1    1   1    0    0   1",
                        "<Figure size 1080x432 with 2 Axes>"
                    ]
                },
                "mc_idx": 256,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 137,
                "o_idx": 2
            }
        },
        {
            "source": "**Findings:** The prediction looks quite similar for the 8 classifiers except when DT is compared to the others classifiers. Now we will create an ensemble with the base models RF, GBC, DT, KNN and LR. This ensemble can be called heterogeneous ensemble since we have three tree based, one kernel based and one linear models. We would use **EnsembleVotingClassifier method from mlxtend module** for both hard and soft voting ensembles. The advantage is it requires lesser codes to plot decision regions and I find it a bit faster than sklearn's voting classifier.",
            "mc_idx": 257,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"We will use mlxtend library to train, predict and plot decision regions of hard voting ensemble classifier.\"\"\"\n\"\"\"Define base models for hard voting ensemble.\"\"\"\nbaseModels = [rf, gbc, dt, knn, lr]\n\n\"\"\"Initialize hard voting ensemble.\"\"\"\nhardVct = EnsembleVoteClassifier(clfs = baseModels, voting=\"hard\")\nprint(\"Training Hard Voting Ensemble Classifier...\")\ndisplay(hardVct.fit(xTrain, yTrain))\nprint(\"Done.\")\n\n\"\"\"Predict with hard voting ensemble.\"\"\"\nyPredHardVct = pd.DataFrame(hardVct.predict(xTest), columns = [\"hardVct\"])\n\n\"\"\"Hard voting cross validation score.\"\"\"\nprint(\"\\nComputing Hard Voting Cross Val Score...\")\nhardXValScore = cross_val_score(hardVct, xTrain, yTrain, cv = 10, scoring = \"accuracy\")\nhardXValScore = round(hardXValScore.mean()*100, 2)\nprint(\"Done.\")\n\n\"\"\"Our tunned scores\"\"\"\ntunedScore = bestScoreAndHyperparametersSorted.iloc[:,0]\n\n\"\"\"Compare hard voting score with best base models scores.\"\"\"\nhardVctVsBaseScore = pd.DataFrame({\"hardVsBaseScore(%)\": [hardXValScore,\n                                                          tunedScore[\"RF\"],\n                                                          tunedScore[\"GBC\"], \n                                                          tunedScore[\"DT\"],\n                                                          tunedScore[\"KNN\"], \n                                                          tunedScore[\"LR\"]]\n                                  })\n\n\"\"\"So basically we\"re comparing hard voting x_val_score with base models\"s tunned score.\"\"\"\nhardVctVsBaseScore.index = [\"hardVct\", \"RF\", \"GBC\", \"DT\", \"KNN\", \"LR\"]\nbold(\"Hard Voting vs Base Models Scores:\")\ndisplay(hardVctVsBaseScore)",
            "mc_idx": 258,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.375,
                "Data_Transform": 0.0,
                "Model_Train": 0.875,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.75,
                "Hyperparameter_Tuning": 0.5,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    "columns": 1,
                    ".mean": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "model": 6
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    "model": 6,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "model": 6
                },
                "Hyperparameter_Tuning": {
                    "param": 1,
                    "hyperparameter": 1,
                    "hyperparameters": 1,
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    138,
                    8,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Training Hard Voting Ensemble Classifier...\n",
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "EnsembleVoteClassifier(clfs=[RandomForestClassifier(bootstrap=True,\n                                                    class_weight=None,\n                                                    criterion='entropy',\n                                                    max_depth=None,\n                                                    max_features='sqrt',\n                                                    max_leaf_nodes=None,\n                                                    min_impurity_decrease=0.0,\n                                                    min_impurity_split=None,\n                                                    min_samples_leaf=2,\n                                                    min_samples_split=6,\n                                                    min_weight_fraction_leaf=0.0,\n                                                    n_estimators=15,\n                                                    n_jobs=None,\n                                                    oob_score=False,\n                                                    random_state=44, verbose=0,\n                                                    wa...\n                                                  metric_params=None,\n                                                  n_jobs=None, n_neighbors=8,\n                                                  p=2, weights='uniform'),\n                             LogisticRegression(C=2.7825594022071245,\n                                                class_weight=None, dual=False,\n                                                fit_intercept=True,\n                                                intercept_scaling=1,\n                                                l1_ratio=None, max_iter=5000,\n                                                multi_class='warn', n_jobs=None,\n                                                penalty='l1', random_state=None,\n                                                solver='warn', tol=0.0001,\n                                                verbose=0, warm_start=False)],\n                       refit=True, verbose=0, voting='hard', weights=None)",
                        "Done.\n\nComputing Hard Voting Cross Val Score...\n",
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "Done.\n",
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "<IPython.core.display.Markdown object>",
                        "         hardVsBaseScore(%)\nhardVct               84.63\nRF                    84.40\nGBC                   83.95\nDT                    81.37\nKNN                   82.94\nLR                    82.94"
                    ]
                },
                "mc_idx": 258,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 138,
                "o_idx": 8
            }
        },
        {
            "source": "**Findings:** We can see Hard voting classifier uses RF as meta learner for this problem that beats the best base learners (rf and gbc) by some margin. So we may want to further investigate how hard voting is using its decision boundary to excel our best base learners. Let's visualize the decision regions of hard voting classifier with base classifiers.\n\n**Now we have a new challenge. In machine learning, visualizing 2 or 3 dimensional data is not that challenging. But we have 47 dimensions (47 input features). That's way too much to visualize. So we need to reduce the dimensionality- may be into 2 or 3 dimensionality. That's where PCA comes into play.**\n\n### **Introduction to Principal Component Analysis (PCA) <a id=\"14.2\"></a>\nThe main goal of a PCA analysis is to identify patterns in data. PCA aims to detect the correlation between variables. If a strong correlation between variables exists, the attempt to reduce the dimensionality only makes sense. In a nutshell, this is what PCA is all about: Finding the directions of maximum variance in high-dimensional data and project it onto a smaller dimensional subspace while retaining most of the information. PCA is very useful in the following two cases:\n1. When the training process takes too long due to large input dimension of training data.\n2. Reducing dimensions, it make data visualization a breeze.\n\nPCA is often effected if your input features have different ranges. So to make PCA work better we shoud scale the input features. We would use sklearn's StandardScaler to standarize our input features. The idea behind StandardScaler is that it will transform our data such that its distribution will have a mean value 0 and standard deviation of 1. **If the variables are correlated, PCA can achieve dimension reduction. If not, PCA just orders them according to their variances.**\n\n**Now let's perform standarization and then PCA to plot decision regions of different trained classifiers.**",
            "mc_idx": 259,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Perform Standarization:\nVariables have very different ranges (diffenence between max and  min).\nThe purpose of standarization is to reduce the dispersion of these variables.\"\"\"\n\n\"\"\"Initialize standard scaler object.\"\"\"\nstdScaler = StandardScaler()\n\"\"\"Fit standard scaler object to train data.\"\"\"\nstdScaler.fit(xTrain)\n\"\"\"Apply the standard scaler to training set.\"\"\"\nxTrainScaled = stdScaler.transform(xTrain)\n\n\n\"\"\"Perform PCA:\"\"\"\n\"\"\"Initialize pca object with two components. i.e., converting into 2d from 47d.\"\"\"\npca = PCA(n_components = 2) # Projection to 2d from 47d\n\"\"\"Fit pca to scaled data.\"\"\"\npca.fit(xTrainScaled)\n\"\"\"Apply pca to scaled data.\"\"\"\npcaTrain = pca.transform(xTrainScaled)\n\"\"\"Create a data frame consisting of two pca.\"\"\"\ntrainPca = pd.DataFrame(data = pcaTrain, columns = [\"pca-1\", \"pca-2\"])\nbold(\"Projection to 2D from 47D:\")\ndisplay(trainPca.head())\n\n\"\"\"let\"s merge our two pca components with our target feature.\"\"\"\nfinalDf = pd.concat([trainPca, yTrain], axis = 1)\nbold(\"Target with 2-PCA Components:\")\ndisplay(finalDf.head())",
            "mc_idx": 260,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.08695652173913043,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.30434782608695654,
                "Data_Transform": 1.0,
                "Model_Train": 0.08695652173913043,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 2
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 2,
                    "head": 2,
                    "columns": 1,
                    ".head": 2
                },
                "Data_Transform": {
                    ".concat(": 1,
                    "transform": 2,
                    "standardscaler": 1,
                    "pca": 18,
                    ".concat": 1
                },
                "Model_Train": {
                    ".fit(": 2
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    139,
                    3,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "      pca-1     pca-2\n0 -1.864392  0.350562\n1  5.210965 -2.822320\n2 -0.351195  1.056633\n3  3.273593 -0.823716\n4 -2.557838 -0.168374",
                        "<IPython.core.display.Markdown object>",
                        "      pca-1     pca-2  Survived\n0 -1.864392  0.350562         0\n1  5.210965 -2.822320         1\n2 -0.351195  1.056633         1\n3  3.273593 -0.823716         1\n4 -2.557838 -0.168374         0"
                    ]
                },
                "mc_idx": 260,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 139,
                "o_idx": 3
            }
        },
        {
            "source": "**So there we have it! We're down to 2 features only from 47 features. Now we want to calculate how much variance we're able to extract off these 2 components.**",
            "mc_idx": 261,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Now calculate how much variance we get off these two components.\"\"\"\nbold(\"Total Variance Explained by 2 PCA Components:\")\ndisplay(round((pca.explained_variance_ratio_[0] + pca.explained_variance_ratio_[1])*100, 2))",
            "mc_idx": 262,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "pca": 3,
                    ".exp": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    140,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "19.9"
                    ]
                },
                "mc_idx": 262,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 140,
                "o_idx": 1
            }
        },
        {
            "source": "**Not so much! But considering the number of features we have, its not either too less. Let's visualize our two components (transformed features) in a scatter plot.**",
            "mc_idx": 263,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Visualize our newly transformed samples with class labels.\"\"\"\nfig,ax = plt.subplots(1,1, figsize = (18,7))\nax.set_xlabel(\"PCA_1\", fontsize = 15)\nax.set_ylabel(\"PCA_2\", fontsize = 15)\nax.set_title(\"2-Component PCA (2D-Transformed Samples)\", fontsize = 20)\ntargets = [1, 0]\ncolors = [\"g\", \"r\"]\nfor target, color in zip(targets,colors):\n    indices = finalDf[\"Survived\"] == target\n    ax.scatter(finalDf.loc[indices, \"pca-1\"],\n               finalDf.loc[indices, \"pca-2\"],\n               c = color, s = 37)\nplt.legend(targets)\nplt.show()",
            "mc_idx": 264,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.14285714285714285,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.7142857142857143,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2857142857142857,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".scatter(": 1,
                    "size": 4
                },
                "Data_Transform": {
                    "transform": 2,
                    "pca": 5
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    ".scatter(": 1,
                    "visualize": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c141_o000_image_27.png",
                    141,
                    0,
                    27
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x504 with 1 Axes>"
                    ]
                },
                "mc_idx": 264,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 141,
                "o_idx": 0
            }
        },
        {
            "source": "**Looking at this plot, one thing we can say that a linear decision boundary will not be a good choice to separate these two classes. Now we would train our models on this 2d transformed samples to visualize decision regions created by them.**\n\n**Note:** PCA gives you an intuition if a linear or non-linear algorithms would be suitable for a problem. For example, if we look at the scatter plot, we see a non-linear trend between the two class that is, of course better seperable by a non-linear decision boundary. So a non-linear model would be a better bet than a linear one. That's why rf(non-linear) performs better than lr(linear model) for this problem.",
            "mc_idx": 265,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"We will use mlxtend for plotting decision regions of base and ensemble models. Initialize base models and hard voting ensemble.\"\"\"\nrfPca = RandomForestClassifier(random_state = seed)\ngbcPca = GradientBoostingClassifier(random_state = seed)\ndtPca = DecisionTreeClassifier(random_state = seed)\nknnPca = KNeighborsClassifier()\nlrPca = LogisticRegression(random_state = seed)\nbaseModelPca = [rfPca, gbcPca, dtPca, knnPca, lrPca]\nhardVctPca = EnsembleVoteClassifier(clfs = baseModelPca, voting=\"hard\")\n\n\"\"\"Function to plot decision region.\"\"\"\ndef plotDecisionRegion(model):\n    \"\"\"Returns a model's decision region.\"\"\"\n    \n    \"\"\"Train models with data pca returned. Get the train data.\"\"\"\n    X = trainPca.values # Must be converted into numpy array.\n    y = yTrain.values\n    model.fit(X, y) \n    decisionRegion = plot_decision_regions(X = X, y = y.astype(np.integer), clf=model)\n    plt.xlabel(\"PCA-1\", fontsize = 15)\n    plt.ylabel(\"PCA_2\", fontsize = 15)\n    plt.xticks(fontsize = 15)\n    plt.yticks(fontsize = 15)\n    return decisionRegion\n\n\"\"\"Now plot decison regions for hard voting ensemble vs base models in subplots.\"\"\"\nplt.figure(figsize = (25,25))\nenModels = [hardVctPca, rfPca, gbcPca, dtPca, knnPca, lrPca]\nenLabels = [\"Hard_vct\", \"RF\", \"GBC\", \"DT\", \"KNN\", \"LR\"]\nfor ax, model, label in zip(range(1,7), enModels, enLabels):\n    plt.subplot(3,2,ax)\n    plotDecisionRegion(model)\n    plt.title(label, fontsize = 18)\nplt.suptitle(\"Hard Voting vs Base Models Decision Regions\", fontsize = 28)\nplt.tight_layout(rect = [0, 0.03, 1, 0.97])",
            "mc_idx": 266,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2916666666666667,
                "Data_Transform": 1.0,
                "Model_Train": 0.9583333333333334,
                "Model_Evaluation": 0.625,
                "Model_Interpretation": 0.6666666666666666,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 7
                },
                "Data_Transform": {
                    ".astype(": 1,
                    "pca": 23
                },
                "Model_Train": {
                    "model.fit": 1,
                    ".fit(": 1,
                    "model": 15,
                    "randomforestclassifier": 2,
                    "logisticregression": 1,
                    "gradientboostingclassifier": 1,
                    "decisiontreeclassifier": 1,
                    "kneighborsclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 15
                },
                "Model_Interpretation": {
                    "model": 15,
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c142_o001_image_28.png",
                    142,
                    1,
                    28
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning:\n\nThe default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning:\n\nThe default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "<Figure size 1800x1800 with 6 Axes>"
                    ]
                },
                "mc_idx": 266,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 142,
                "o_idx": 1
            }
        },
        {
            "source": "**Findings:** There seems to be lesser misclassifications made by hard voting decision region compared to both rf and gbc's decision regions. Let's see how and where hard voting ensemble corrects base learners prediction in a data frame together.",
            "mc_idx": 267,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Create a data frame consisting of base models and hard voting ensemble predictions. Revised base models are now rf, gbc, dt, knn, lr without svc and etc.\"\"\"\nbasePrediction = basePrediction.drop(columns = [\"ABC\", \"SVC\", \"ETC\"], axis = 1)\n\n\"\"\"See base models prediction with hard voting prediction.\"\"\"\nhardBase = pd.concat([basePrediction, yPredHardVct], sort = False, axis = 1)\ndisplay(hardBase.head(7))",
            "mc_idx": 268,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.8,
                "Data_Transform": 0.6,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.6,
                "Model_Interpretation": 0.6,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    "columns": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".concat(": 1,
                    ".drop": 1,
                    ".concat": 1
                },
                "Model_Train": {
                    "model": 3,
                    "svc": 2
                },
                "Model_Evaluation": {
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    143,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   RF  GBC  DT  KNN  LR  hardVct\n0   0    0   0    0   0        0\n1   0    1   0    0   1        0\n2   0    0   0    0   0        0\n3   0    0   0    0   0        0\n4   1    1   1    0   1        1\n5   0    0   0    0   0        0\n6   1    1   0    1   1        1"
                    ]
                },
                "mc_idx": 268,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 143,
                "o_idx": 0
            }
        },
        {
            "source": "**Great! We can see hard voting ensemble is considering majority of the models vote(prediction) to label a particular class. Thus it can reduce prediction errors when predicted by a single base learners.**\n\n##### 14.1.1.1.2 Soft Voting <a id=\"14.3\"></a>\nOn the other hand, When an ensembles averages based on probabilities  we refer to it as soft voting. In an ensemble model, all classifiers (algorithms) are able to estimate class probabilities (i.e., they all have predict_proba() method), then we can specify Scikit-Learn to predict the class with the highest probability, averaged over all the individual classifiers. In a voting classifier setting the voting parameter to 'soft' enables the models to calculate their probability(also known as confidence score) individually and present it to the voting classifier, then the voting classifier averages them and outputs the class with the highest probability. If average probablity of class-1 is greater than class-0, it outputs predicted class is 1 otherwise 0. \n\n**Note:** This soft-voting classifier often work better than hard-voting as it gives more weight to highly confident votes. We Need to specify voting=\u201dsoft\u201d and ensure that all classifiers can estimate class probabilities. One algorithm where we need to be careful is SVC, by default SVC will not give probabilities, we have to specify 'probability' hyperparameter to True.\nSee the table below to understand how soft voting ensemble works.",
            "mc_idx": 269,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "bold(\"How soft voting works:\")\ndata = [[0.49, 0.99, 0.49, 0.66, 1], \n        [0.51, 0.01, 0.51, 0.34, 0]]\ndisplay(pd.DataFrame(data, columns= [\"RF\", \"LR\", \"KNN\", \"Average\", \"Soft_voting\"]))",
            "mc_idx": 270,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    144,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "     RF    LR   KNN  Average  Soft_voting\n0  0.49  0.99  0.49     0.66            1\n1  0.51  0.01  0.51     0.34            0"
                    ]
                },
                "mc_idx": 270,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 144,
                "o_idx": 1
            }
        },
        {
            "source": "**Let's implement soft voting ensemble in mlxtend.**",
            "mc_idx": 271,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Base models for soft voting is the base models of hard voting.\"\"\"\n\"\"\"Initialize soft voting ensemble.\"\"\"\nbaseModels = [rf, gbc, dt, knn, lr]\nsoftVct = EnsembleVoteClassifier(clfs = baseModels, voting = \"soft\")\nprint(\"Fitting Soft Voting Ensemble...\")\ndisplay(softVct.fit(xTrain, yTrain))\nprint(\"Done.\")\n\n\"\"\"Predict with soft voting ensemble.\"\"\"\nyPredSoftVct = pd.DataFrame(softVct.predict(xTest), columns = [\"Soft_vct\"])\n\n\"\"\"Hard voting cross validation score.\"\"\"\nprint(\"\\nComputing Soft Voting X Val Score...\")\nsoftXValScore = cross_val_score(softVct, xTrain, yTrain, cv = 10, scoring = \"accuracy\")\nsoftXValScore = round(softXValScore.mean()*100, 2)\nprint(\"Done.\")\n\n\"\"\"Compare hard voting score with best base models scores.\"\"\"\nsoftVsBaseScore = pd.DataFrame({\"Soft_vs_base_score(%)\": [softXValScore,\n                                                          tunedScore[\"RF\"],\n                                                          tunedScore[\"GBC\"], \n                                                          tunedScore[\"DT\"],\n                                                          tunedScore[\"KNN\"], \n                                                          tunedScore[\"LR\"]]\n                               })\n\"\"\"So basically we\"re comparing soft voting x_val_score with base models\"s tunned score.\"\"\"\nsoftVsBaseScore.index = [\"Soft_vct\", \"RF\", \"GBC\", \"DT\", \"KNN\", \"LR\"]\nbold(\"Soft Voting vs Base Models Scores:\")\ndisplay(softVsBaseScore)",
            "mc_idx": 272,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 0.0,
                "Model_Train": 0.8888888888888888,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.7777777777777778,
                "Hyperparameter_Tuning": 0.1111111111111111,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    "columns": 1,
                    ".mean": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "model": 7
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    "model": 7,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "model": 7
                },
                "Hyperparameter_Tuning": {
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    145,
                    8,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Fitting Soft Voting Ensemble...\n",
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "EnsembleVoteClassifier(clfs=[RandomForestClassifier(bootstrap=True,\n                                                    class_weight=None,\n                                                    criterion='entropy',\n                                                    max_depth=None,\n                                                    max_features='sqrt',\n                                                    max_leaf_nodes=None,\n                                                    min_impurity_decrease=0.0,\n                                                    min_impurity_split=None,\n                                                    min_samples_leaf=2,\n                                                    min_samples_split=6,\n                                                    min_weight_fraction_leaf=0.0,\n                                                    n_estimators=15,\n                                                    n_jobs=None,\n                                                    oob_score=False,\n                                                    random_state=44, verbose=0,\n                                                    wa...\n                                                  metric_params=None,\n                                                  n_jobs=None, n_neighbors=8,\n                                                  p=2, weights='uniform'),\n                             LogisticRegression(C=2.7825594022071245,\n                                                class_weight=None, dual=False,\n                                                fit_intercept=True,\n                                                intercept_scaling=1,\n                                                l1_ratio=None, max_iter=5000,\n                                                multi_class='warn', n_jobs=None,\n                                                penalty='l1', random_state=None,\n                                                solver='warn', tol=0.0001,\n                                                verbose=0, warm_start=False)],\n                       refit=True, verbose=0, voting='soft', weights=None)",
                        "Done.\n\nComputing Soft Voting X Val Score...\n",
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "Done.\n",
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "<IPython.core.display.Markdown object>",
                        "          Soft_vs_base_score(%)\nSoft_vct                  83.39\nRF                        84.40\nGBC                       83.95\nDT                        81.37\nKNN                       82.94\nLR                        82.94"
                    ]
                },
                "mc_idx": 272,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 145,
                "o_idx": 8
            }
        },
        {
            "source": "**Findings:** Soft voting ensemble fails to beat our two best models (rf and gbc). In fact, it produces way to inferior results compared to hard voting ensemble (83.95 vs 84.18). So hard voting ensemble, for this problem, seems to be superior to soft voting ensemble method. WE can visualize soft voting ensemble decision region along with base models decision regions.",
            "mc_idx": 273,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"We would use the same data to plot decision region we got analysing PCA.\"\"\"\nsoftVctPca = EnsembleVoteClassifier(clfs = baseModelPca, voting = \"soft\")\n\n\"\"\"Plot decision regions for soft voting ensemble vs base models in subplots.\"\"\"\nplt.figure(figsize = (25,25))\nenModels = [softVctPca, rfPca, gbcPca, dtPca, knnPca, lrPca]\nenLabels = [\"Soft_vct\", \"RF\", \"GBC\", \"DT\", \"KNN\", \"LR\"]\nfor ax, model, label in zip(range(1,7), enModels, enLabels):\n    plt.subplot(3,2,ax)\n    plotDecisionRegion(model)\n    plt.title(label, fontsize = 18)\nplt.suptitle(\"Soft Voting vs Base Models Decision Regions\", fontsize = 28)\nplt.tight_layout(rect = [0, 0.03, 1, 0.97])",
            "mc_idx": 274,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 1.0,
                "Model_Train": 0.7777777777777778,
                "Model_Evaluation": 0.7777777777777778,
                "Model_Interpretation": 0.7777777777777778,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 3
                },
                "Data_Transform": {
                    "pca": 9
                },
                "Model_Train": {
                    "model": 7
                },
                "Model_Evaluation": {
                    "model": 7
                },
                "Model_Interpretation": {
                    "model": 7
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c146_o001_image_29.png",
                    146,
                    1,
                    29
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "<Figure size 1800x1800 with 6 Axes>"
                    ]
                },
                "mc_idx": 274,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 146,
                "o_idx": 1
            }
        },
        {
            "source": "**Findings:** Soft voting decision region just seems to be creating more misclassification than rf and gbc.",
            "mc_idx": 275,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"See base models prediction with soft voting prediction.\"\"\"\nsoftBase = pd.concat([basePrediction,yPredSoftVct], sort = False, axis = 1)\ndisplay(softBase.head())",
            "mc_idx": 276,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.6666666666666666,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 0.3333333333333333,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".concat(": 1,
                    ".concat": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    147,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   RF  GBC  DT  KNN  LR  Soft_vct\n0   0    0   0    0   0         0\n1   0    1   0    0   1         0\n2   0    0   0    0   0         0\n3   0    0   0    0   0         0\n4   1    1   1    0   1         1"
                    ]
                },
                "mc_idx": 276,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 147,
                "o_idx": 0
            }
        },
        {
            "source": "### 14.1.2 Advanced Ensemble Methods\nAdvanced ensemble methods can further be classified into \n1. Bagging\n2. Boostoing\n3. Stacking\n4. Blending\n\n#### 14.1.2.1 Bagging  <a id=\"14.4\"></a>\nBagging, is shorthand for the combination of bootstrapping and aggregating. Bootstrapping is a method to help decrease the variance of the classifier and thus reduce overfitting. So the model created should be less overfitted than a single individual model. Bagging is more suitable for high variance low bias models (complex models). Random forest itself is an ensemble machine learning algorithm that follows the bagging technique. We would use rf as the base estimator for bagging instead of default dt. Let's try to implement bagging in sklearn:",
            "mc_idx": 277,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Initialize bagging classifier.\"\"\"\nbagg = BaggingClassifier(base_estimator = rf, verbose = 0, n_jobs = -1, random_state = seed)\n\"\"\"We use rf as the base estimator for bagging technique.\"\"\"\nprint(\"Fitting Bagging Ensemble...\")\ndisplay(bagg.fit(xTrain, yTrain))\nprint(\"Done.\")\n\n\"\"\"Bagging cross validation score.\"\"\"\nprint(\"\\nComputing Bagging X Val Score..\")\nbaggXValScore = cross_val_score(bagg, xTrain, yTrain, cv = 10, scoring = \"accuracy\")\nbaggXValScore = np.round(baggXValScore.mean()*100, 2)\nprint(\"Done.\")\n\n\"\"\"Compare bagging ensemble score with best base models scores.\"\"\"\nbaggVsBaseScore = pd.DataFrame({\"Bagging_vs_base_score(%)\": [baggXValScore,\n                                                          tunedScore[\"RF\"],\n                                                          tunedScore[\"GBC\"], \n                                                          tunedScore[\"DT\"],\n                                                          tunedScore[\"KNN\"], \n                                                          tunedScore[\"LR\"]]\n                               })\n\n\"\"\"So basically we\"re comparing bagging x_val_score with base models\"s tunned score.\"\"\"\nbaggVsBaseScore.index = [\"Bagg\", \"RF\", \"GBC\", \"DT\", \"KNN\", \"LR\"]\nbold(\"Bagging vs Base Models Scores:\")\ndisplay(baggVsBaseScore)",
            "mc_idx": 278,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 0.25,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.75,
                "Hyperparameter_Tuning": 0.25,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1
                },
                "Data_Transform": {
                    ".round": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "model": 3
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    148,
                    4,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Fitting Bagging Ensemble...\n",
                        "BaggingClassifier(base_estimator=RandomForestClassifier(bootstrap=True,\n                                                        class_weight=None,\n                                                        criterion='entropy',\n                                                        max_depth=None,\n                                                        max_features='sqrt',\n                                                        max_leaf_nodes=None,\n                                                        min_impurity_decrease=0.0,\n                                                        min_impurity_split=None,\n                                                        min_samples_leaf=2,\n                                                        min_samples_split=6,\n                                                        min_weight_fraction_leaf=0.0,\n                                                        n_estimators=15,\n                                                        n_jobs=None,\n                                                        oob_score=False,\n                                                        random_state=44,\n                                                        verbose=0,\n                                                        warm_start=False),\n                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n                  max_samples=1.0, n_estimators=10, n_jobs=-1, oob_score=False,\n                  random_state=43, verbose=0, warm_start=False)",
                        "Done.\n\nComputing Bagging X Val Score..\nDone.\n",
                        "<IPython.core.display.Markdown object>",
                        "      Bagging_vs_base_score(%)\nBagg                     82.83\nRF                       84.40\nGBC                      83.95\nDT                       81.37\nKNN                      82.94\nLR                       82.94"
                    ]
                },
                "mc_idx": 278,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 148,
                "o_idx": 4
            }
        },
        {
            "source": "**Findings:** Bagging can't beat our best base learners.\n\n#### 14.1.2.2 Boosting  <a id=\"14.5\"></a>\nBoosting refers to any Ensemble method that can combine several weak learners into a strong learner. It does this through a weighted majority vote (classification) or a weighted sum (regression). Ada boost and Gradient boost, and Extreme gradient boost are popular models that uses boosting technique. Boosting is particularly suitable for low variance high bias models (less complex models). Unlike bagging, its a sequential ensemble technique. We will perform a simple voting ensemble of boosting classifiers rather performing boosting ensemble using only a single classifer with a base estimator (for ada boost). I found this method to give higher accuracy than adaboost(with a base estimator), gradient boosting, or extreme gradient boosting for this problem. Let's perform boosting ensemble(infact voting of boosting classifiers) in mlxtend.",
            "mc_idx": 279,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"We will use adaptive boosting, gradient boosting and extreme gradient boosting classifiers for boosting ensemble method.\"\"\"\n\"\"\"Initialize boosting classifier. Base models for boosting:\"\"\"\nboostModels = [abc, gbc, xgbc] # Unoptimized xgbc\nboost = EnsembleVoteClassifier(clfs = boostModels, voting=\"hard\")\n\n\"\"\"Fitting boosting.\"\"\"\nprint(\"Fitting Boosting Ensemble...\")\ndisplay(boost.fit(xTrain, yTrain))\nprint(\"Done.\")\n\n\"\"\"Boosting cross validation score.\"\"\"\nprint(\"\\nCalculating Boosting X Val Score...\")\nboosXValScore = cross_val_score(boost, xTrain, yTrain, cv = 10, scoring = \"accuracy\")\nboosXValScore = round(boosXValScore.mean()*100, 2)\nprint(\"Done.\")\n\n\"\"\"Compare boosting ensemble score with best base models scores.\"\"\"\nxgbcXValScore = 82.27  # xgbc\"s x_val_score.\nboostVsBaseScore = pd.DataFrame({\"Boosting_vs_base_score(%)\": [boosXValScore,\n                                                                  tunedScore[\"ABC\"],\n                                                                  tunedScore[\"GBC\"], \n                                                                  xgbcXValScore]})\n\"\"\"So basically we\"re comparing boosting x_val_score with base models\"s tunned score except xgbc.\"\"\"\nboostVsBaseScore.index = [\"Boost\", \"ABC\", \"GBC\", \"XGBC\"]\nbold(\"Boosting vs Base Models Scores:\")\ndisplay(boostVsBaseScore)",
            "mc_idx": 280,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 0.875,
                "Model_Evaluation": 0.875,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.125,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "model": 6
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    "model": 6
                },
                "Model_Interpretation": {
                    "model": 6,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    149,
                    4,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Fitting Boosting Ensemble...\n",
                        "EnsembleVoteClassifier(clfs=[AdaBoostClassifier(algorithm='SAMME.R',\n                                                base_estimator=None,\n                                                learning_rate=0.1,\n                                                n_estimators=250,\n                                                random_state=43),\n                             GradientBoostingClassifier(criterion='friedman_mse',\n                                                        init=None,\n                                                        learning_rate=0.05,\n                                                        loss='deviance',\n                                                        max_depth=4,\n                                                        max_features=0.1,\n                                                        max_leaf_nodes=None,\n                                                        min_impurity_decrease=0.0,\n                                                        min_impurity_split=None,\n                                                        min_samples_le...\n                                           colsample_bylevel=1,\n                                           colsample_bynode=1,\n                                           colsample_bytree=1, gamma=0,\n                                           learning_rate=0.1, max_delta_step=0,\n                                           max_depth=3, min_child_weight=1,\n                                           missing=None, n_estimators=100,\n                                           n_jobs=1, nthread=None,\n                                           objective='binary:logistic',\n                                           random_state=43, reg_alpha=0,\n                                           reg_lambda=1, scale_pos_weight=1,\n                                           seed=None, silent=None, subsample=1,\n                                           verbosity=1)],\n                       refit=True, verbose=0, voting='hard', weights=None)",
                        "Done.\n\nCalculating Boosting X Val Score...\nDone.\n",
                        "<IPython.core.display.Markdown object>",
                        "       Boosting_vs_base_score(%)\nBoost                      83.73\nABC                        83.39\nGBC                        83.95\nXGBC                       82.27"
                    ]
                },
                "mc_idx": 280,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 149,
                "o_idx": 4
            }
        },
        {
            "source": "**Findings:** Boosting method can't beat best boosting base learner gbc. Though it could beat, if we would have optimized xgbc. If you have time and infrastructure, you can tune xgbc's hyperparameters. Then compare boosting accuracy with its base models accuracy.\n\n#### 14.1.2.3 Blending  <a id=\"14.6\"></a>\nIn blending, full training data is split into training and prediction sets. The base models (also called level 0 models) are trained on this train set and then predictions are made on this prediction set. These predictions made by base learers are then fed as an input to the meta learner (also called level 1 model). That is meta learner are trained with the output (predictions) of base learners. Blending ensemble uses only a subset of data to train base learners and another subset of data to make predictions. By only fitting every base learner once on a subset of the full training data, Blend ensemble is a fast ensemble that can handle very large datasets simply by only using portion of it at each stage. The cost of this approach is that information is thrown out at each stage, as one layer will not see the training data used by the previous layer. **We will use BlendEnsemble method from mlens.ensemble module to perform blending.**",
            "mc_idx": 281,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Perform blending in mlens.\"\"\"\n\"\"\"Initialize blend ensembler.\"\"\"\nblend = BlendEnsemble(n_jobs = -1, test_size = 0.5, random_state = seed)\n\"\"\"Base models for blending.\"\"\"\nbaseModels = [gbc, rf, dt, knn, abc]\nblend.add(baseModels)\n\"\"\"Meta learner for blending. We will use lr.\"\"\"\nblend.add_meta(lr)\n\"\"\"Train the blend ensemble.\"\"\"\nprint(\"Fitting Blending...\")\ndisplay(blend.fit(xTrain, yTrain))\nprint(\"Done.\")",
            "mc_idx": 282,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.5,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.75,
                "Model_Interpretation": 0.75,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    ".fit(": 1,
                    "model": 3
                },
                "Model_Evaluation": {
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    150,
                    3,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Fitting Blending...\n",
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "BlendEnsemble(array_check=None, backend=None,\n       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n   name='layer-1', propagate_features=None, raise_on_exception=True,\n   random_state=3392, shuffle=False,\n   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n   indexer=BlendIndex(X=None, raise_on_exception=...rer=None)],\n   n_jobs=-1, name='group-1', raise_on_exception=True, transformers=[])],\n   verbose=0)],\n       model_selection=False, n_jobs=None, raise_on_exception=True,\n       random_state=43, sample_size=20, scorer=None, shuffle=False,\n       test_size=0.5, verbose=False)",
                        "Done.\n"
                    ]
                },
                "mc_idx": 282,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 150,
                "o_idx": 3
            }
        },
        {
            "source": "#### 14.1.2.4 Stacking (Or Stacked Generalization)  <a id=\"14.7\"></a>\nIn blending, we trained the base learners and the meta learner on only half the data, so a lot of information is lost. To prevent this, we need to use a cross-validation strategy. Fitting an ensemble with cross-validation is often referred to as stacking, while the ensemble itself is known as the Super Learner. So basically in stacking, the individual classification models (or base models) are trained on the complete training set; then, the meta-classifier is fitted on the outputs (predictions) of those base learners. The meta-classifier can either be trained on the predicted class labels or probabilities from the ensemble.\n\n**The basic difference between blending and stacking is therefore that stacking allows both base learners and the meta learner to train on the full data set.The outcome of stacking is improved accuracy which is typical for small and medium-sized data sets, where the effect of blending can be severe. As the data set size increases, blending and stacking performs similarly and hence for large data sets blending is preferred over stacking since stacking takes significant amount of time to train the ensemble. We will use package vecstack to perform stacking that can save you from writing a lot of codes if you implement stacking from scratch.**",
            "mc_idx": 283,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Initialize base models. We will use the same base models as blending.\"\"\"\nbaseModels = [rf, dt, gbc, abc, knn]\n\"\"\"Perform stacking.\"\"\"\nsTrain, sTest = stacking(baseModels,                # list of base models\n                           xTrain, yTrain, xTest,   # data\n                           regression = False,         # classification task (if you need \n                                                       # regression - set to True)\n                           mode = \"oof_pred_bag\",      # mode: oof for train set, predict test \n                                                       # set in each fold and vote\n                           needs_proba = False,        # predict class labels (if you need \n                                                       # probabilities - set to True) \n                           save_dir = None,            # do not save result and log (to save \n                                                       # in current dir - set to \".\")\n                           metric = accuracy_score,    # metric: callable\n                           n_folds = 10,               # number of folds\n                           stratified = True,          # stratified split for folds\n                           shuffle = True,             # shuffle the data\n                           random_state= seed,         # ensure reproducibility\n                           verbose = 1)                # print progress",
            "mc_idx": 284,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 0.7142857142857143,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.7142857142857143,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.42857142857142855,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "stack": 2
                },
                "Model_Train": {
                    "model": 5
                },
                "Model_Evaluation": {
                    "accuracy_score": 2,
                    "model": 5
                },
                "Model_Interpretation": {
                    "model": 5
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    "save": 3
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    151,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "task:         [classification]\nn_classes:    [2]\nmetric:       [accuracy_score]\nmode:         [oof_pred_bag]\nn_models:     [5]\n\nmodel  0:     [RandomForestClassifier]\n    ----\n    MEAN:     [0.81598712] + [0.05415289]\n    FULL:     [0.81593715]\n\nmodel  1:     [DecisionTreeClassifier]\n    ----\n    MEAN:     [0.80251674] + [0.04118991]\n    FULL:     [0.80246914]\n\nmodel  2:     [GradientBoostingClassifier]\n    ----\n    MEAN:     [0.83622517] + [0.04595903]\n    FULL:     [0.83613917]\n\nmodel  3:     [AdaBoostClassifier]\n    ----\n    MEAN:     [0.82719754] + [0.04885911]\n    FULL:     [0.82716049]\n\nmodel  4:     [KNeighborsClassifier]\n    ----\n    MEAN:     [0.82381568] + [0.03815719]\n    FULL:     [0.82379349]\n\n"
                    ]
                },
                "mc_idx": 284,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 151,
                "o_idx": 0
            }
        },
        {
            "source": "**So now we have OOF from base (or 0 level models) models and we can build level 1 model. We have 5 base models (level 0 models), so we expect to get 5 columns in sTrain and sTest. sTrain will be our input feature to train our meta learner and then prediction will be made on sTest after we train our meta learner. And this prediction on sTest is actually the prediction for our test set (xTest). Before we train our meta learner we can investigate sTrain and sTest.**",
            "mc_idx": 285,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Input features for meta learner.\"\"\"\ndisplay(sTrain[:5])\ndisplay(sTrain.shape)",
            "mc_idx": 286,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "shape": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    152,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([[0, 0, 0, 0, 0],\n       [1, 1, 1, 1, 1],\n       [0, 0, 1, 1, 0],\n       [1, 1, 1, 1, 1],\n       [0, 0, 0, 0, 0]])",
                        "(891, 5)"
                    ]
                },
                "mc_idx": 286,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 152,
                "o_idx": 1
            }
        },
        {
            "source": "'''Test (prediction) set for meta learner.'''\ndisplay(sTest[:5].shape)\ndisplay(sTest.shape)",
            "mc_idx": 287,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "shape": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    153,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "(5, 5)",
                        "(418, 5)"
                    ]
                },
                "mc_idx": 287,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 153,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Initialize 1st level model that is our meta learner. We will use lr.\"\"\"\nsuperLearner = lr \n    \n\"\"\"Fit meta learner on the output of base learners.\"\"\"\nprint(\"Fitting Stacking...\")\nsuperLearner.fit(sTrain, yTrain)\nprint(\"Done.\")\n\"\"\"Finally predict using super learner.\"\"\"\nyPredSuper = superLearner.predict(sTest)",
            "mc_idx": 288,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "stack": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    154,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Fitting Stacking...\nDone.\n",
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n"
                    ]
                },
                "mc_idx": 288,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 154,
                "o_idx": 1
            }
        },
        {
            "source": "## 14.2  Evaluating Different Ensembles <a id=\"14.8\"></a>\nI've tried to demonstrate various ensemble methods. Let's make predictions with them to see how they perform on our test set on kaggle submission.",
            "mc_idx": 289,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Predicting with different ensembles.\"\"\"\n\n\"\"\"Hard voting.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": hardVct.predict(xTest)})\nsubmission.to_csv(\"hardVctSubmission.csv\", index = False)\n\n\"\"\"Soft voting.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": softVct.predict(xTest)})\nsubmission.to_csv(\"softVctSubmission.csv\", index = False)\n\n\"\"\"Bagging.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": bagg.predict(xTest)})\nsubmission.to_csv(\"baggSubmission.csv\", index = False)\n\n\"\"\"Boosting.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": boost.predict(xTest)})\nsubmission.to_csv(\"boostSubmission.csv\", index = False)\n\n\"\"\"Blending.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": blend.predict(xTest).astype(int)})\nsubmission.to_csv(\"blendSubmission.csv\", index = False)\n\n\"\"\"Stacking.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": yPredSuper.astype(int)})\nsubmission.to_csv(\"stackingSubmission.csv\", index = False)",
            "mc_idx": 290,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.4166666666666667,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 2,
                    "stack": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {
                    ".predict(": 5
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 6,
                    "to_csv": 6
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    155,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 290,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 155,
                "o_idx": 0
            }
        },
        {
            "source": "**We've made our submissions using different ensembles. Let's now compare their submission scores with our best base models'  submission scores.**",
            "mc_idx": 291,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\"\"\"Create a df of different ensemble submission scores and base models.\"\"\"\nsubmissionScore = pd.DataFrame({\"models\":[\"bagging(en)\", \"boosting(en)\", \"blending(en)\", \"stacking(en)\", \n                                          \"hardVoting(en)\", \"softVoting(en)\", \"rf(base)\", \"gbc(base)\"],\n             \"scoredOnSubmission\":[0.81339, 0.78947, 0.79425, 0.79904, 0.79904, 0.79904, 0.80382, 0.78947]})\nsubmissionScore = submissionScore.set_index(\"models\").sort_values(by=\"scoredOnSubmission\", ascending = False)\nbold(\"Ensemble vs Base Models Scores on Submission:\")\ndisplay(submissionScore)",
            "mc_idx": 292,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.75,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "stack": 1,
                    ".sort_values": 1,
                    ".set_index": 1
                },
                "Model_Train": {
                    "model": 4
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    156,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "                scoredOnSubmission\nmodels                            \nbagging(en)                0.81339\nrf(base)                   0.80382\nstacking(en)               0.79904\nhardVoting(en)             0.79904\nsoftVoting(en)             0.79904\nblending(en)               0.79425\nboosting(en)               0.78947\ngbc(base)                  0.78947"
                    ]
                },
                "mc_idx": 292,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 156,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Let's plot models' submission score for the last time.\"\"\"\ndef plotSubmissionScore():\n    \"\"\"Returns a bar chart of different models scored on submission.\"\"\"\n    \n    # Create a subplot of bar chart\n    fig=make_subplots(\n        rows=1, \n        cols=1,\n        vertical_spacing=0.3,\n        print_grid=False) # This suppresses \"This is the format of your plot grid:\" text from popping out.\n\n    # Add trace for bar chart\n    fig.add_trace(go.Bar(x=submissionScore.index,\n                             y=submissionScore.T.squeeze(), # Converts df to series\n                             text=submissionScore.T.squeeze(),\n                             hoverinfo=\"x+y\",\n                             textposition=\"auto\",\n                             marker = dict(color=submissionScore.T.squeeze(), colorscale=\"Rainbow\"),\n                             textfont=dict(family=\"sans serif\",size=14),\n                             ),\n                     row=1,\n                     col=1\n                     )\n\n        \n    # Update the layout. Add title, dimension, and background color\n    fig.layout.update(\n        height=600, \n        width=950,\n        hovermode=\"closest\",\n        title_text = \"Models Score on Submission\",\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n\n    # Set y-axis titles in bold\n    fig.layout.yaxis1.update(title=\"<b>Submission score</b>\")\n    \n    # Set x-axis title in bold\n    fig.layout.xaxis1.update(title=\"<b>Models</b>\")\n    return fig.show()\n\n\"\"\"Call the function to plot the scores.\"\"\"\nplotSubmissionScore()",
            "mc_idx": 293,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.25,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.75,
                "Data_Transform": 0.25,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".bar(": 1,
                    "info": 1,
                    "size": 1
                },
                "Data_Transform": {
                    ".add": 1
                },
                "Model_Train": {
                    "model": 4
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    ".bar(": 1,
                    "chart": 3
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    157,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"9dd7e112-c210-4fc2-8f23-f9eddbfe42fc\" class=\"plotly-graph-div\" style=\"height:600px; width:950px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"9dd7e112-c210-4fc2-8f23-f9eddbfe42fc\")) {\n                    Plotly.newPlot(\n                        '9dd7e112-c210-4fc2-8f23-f9eddbfe42fc',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [0.81339, 0.80382, 0.79904, 0.79904, 0.79904, 0.79425, 0.78947, 0.78947], \"colorscale\": \"Rainbow\"}, \"text\": [0.81339, 0.80382, 0.79904, 0.79904, 0.79904, 0.79425, 0.78947, 0.78947], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"b0a34a6d-03da-4c9d-8c31-1be527f8b2c8\", \"x\": [\"bagging(en)\", \"rf(base)\", \"stacking(en)\", \"hardVoting(en)\", \"softVoting(en)\", \"blending(en)\", \"boosting(en)\", \"gbc(base)\"], \"xaxis\": \"x\", \"y\": [0.81339, 0.80382, 0.79904, 0.79904, 0.79904, 0.79425, 0.78947, 0.78947], \"yaxis\": \"y\"}],\n                        {\"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"title\": {\"text\": \"Models Score on Submission\"}, \"width\": 950, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Models</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Submission score</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('9dd7e112-c210-4fc2-8f23-f9eddbfe42fc');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 293,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 157,
                "o_idx": 0
            }
        },
        {
            "source": "**Findings:**So there you have it! Surprisingly its bagging that comes out on top with a score of *0.81339* that can take you to the top *4%* on the leaderboard! Random forest (base model) comes second with score 0.80382. Hard voting, stacking and soft voting perform identical and can't beat best base rf. Since bagging performs well for high variance model, we have a feeling that we might have overfitted the training data because cross validation score for bagging is 82.61% and it still scores over 81% on kaggle leaderboard. So its possible to overfit though your cross validation score is high since some models with higher cross validation score perform poorly on kaggle leaderboard compared to bagging ensemble.",
            "mc_idx": 294,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 15.End Note <a id=\"15\"></a>\n**If you're still with me, I congratulate you because you've learned all those things that I learned after months of study, practice and of course patience. Of course, there is always room for improvement. I'm still learning. I've tried to explain everything I could possibly know. Any suggestion is cordially welcomed. May be trying out different base learners and meta learner to improve ensemble further or may be by tunning xgbc. And if you find my kernel useful, some upvotes will be appreciated.  I have also another kernel for advanced house price regression problem that you might find useful as well.**\n\n**Finally I provide some links that I've found useful in creating this notebook.**\n\n**Recommended Readings:**\n1. Mlxtend package for voting ensemble and decision region: https://rasbt.github.io/mlxtend/user_guide/classifier/EnsembleVoteClassifier/ and\nhttps://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/\n2. Mlens package for blending ensemble: https://github.com/flennerhag/mlens/blob/master/mlens/ensemble/blend.py\n3. Vecstack package for stacking ensemble: https://github.com/vecxoz/vecstack\n4. Introduction to Python Ensembles by Dataquest: https://www.dataquest.io/blog/introduction-to-ensembles/\n5. Kaggle ensemble guide by MLWave: https://mlwave.com/kaggle-ensembling-guide/",
            "mc_idx": 295,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        }
    ],
    "code_cells": [
        {
            "source": "\"\"\"Import basic modules.\"\"\"\nimport numpy as np               # For linear algebra\nimport pandas as pd              # For data manipulation\nimport matplotlib.pyplot as plt  # For 2D visualization\nimport seaborn as sns            \nfrom scipy import stats          # For statistics\n\n\"\"\"Plotly visualization.\"\"\"\nimport plotly.graph_objs as go\nfrom plotly.tools import make_subplots\nfrom plotly.offline import iplot, init_notebook_mode\ninit_notebook_mode(connected = True) # Required to use plotly offline in jupyter notebook\n\n\"\"\"Machine learning models.\"\"\"\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom xgboost import XGBClassifier\n\n\n\"\"\"Classification (evaluation) metrices.\"\"\"\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\n\n\"\"\"Ensembling\"\"\"\nfrom mlxtend.classifier import EnsembleVoteClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom mlxtend.plotting import plot_decision_regions\nfrom sklearn.ensemble import BaggingClassifier\nfrom mlens.ensemble import BlendEnsemble\nfrom vecstack import stacking",
            "mc_idx": 3,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2564102564102564,
                "Data_Transform": 0.23076923076923078,
                "Model_Train": 0.5384615384615384,
                "Model_Evaluation": 0.7948717948717948,
                "Model_Interpretation": 0.1794871794871795,
                "Hyperparameter_Tuning": 0.1282051282051282,
                "Visualization": 0.07692307692307693,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 39
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plotly": 5,
                    "matplotlib": 1,
                    ".mode": 4
                },
                "Data_Transform": {
                    "data manipulation": 1,
                    "standardscaler": 1,
                    "pca": 1,
                    "stack": 2,
                    ".mod": 4
                },
                "Model_Train": {
                    "model": 6,
                    "randomforestclassifier": 2,
                    "model_selection": 4,
                    "learning models": 1,
                    "logisticregression": 1,
                    "gradientboostingclassifier": 1,
                    "decisiontreeclassifier": 1,
                    "kneighborsclassifier": 1,
                    "svc": 1,
                    "gaussiannb": 1,
                    "adaboostclassifier": 1,
                    ".linear": 1
                },
                "Model_Evaluation": {
                    "confusion_matrix": 2,
                    "accuracy_score": 2,
                    "precision_score": 4,
                    "recall_score": 2,
                    "f1_score": 3,
                    "precision": 3,
                    "recall": 2,
                    "roc_auc_score": 2,
                    "classification_report": 2,
                    "cross_val_score": 1,
                    "model": 6,
                    "precision_recall_curve": 1,
                    "roc_curve": 1
                },
                "Model_Interpretation": {
                    "model": 6,
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "cross_val_score": 1,
                    "learning_curve": 1
                },
                "Visualization": {
                    "matplotlib": 1,
                    "pyplot": 1,
                    "graph": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    0,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        ",
                        "[MLENS] backend: threading\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning:\n\nThe module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n\n"
                    ]
                },
                "mc_idx": 3,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 0,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Customize visualization.\"\"\"\nplt.style.use(\"bmh\")                    # Use bmh's style for plotting\nsns.set_style({\"axes.grid\":False})      # Remove gridlines\n\n\"\"\"Display markdown formatted output like bold, italic bold etc.\"\"\"\nfrom IPython.display import Markdown\ndef bold(string):\n    return display(Markdown(f\"**{string}**\"))",
            "mc_idx": 4,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    1,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 4,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 1,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Read and preview the train data from csv file.\"\"\"\ntrain = pd.read_csv(\"../input/train.csv\")\nbold(\"Preview of Train Data:\")\ndisplay(train.head(2))\n\n\"\"\"Read and preview the test from csv file.\"\"\"\ntest = pd.read_csv(\"../input/test.csv\")\nbold(\"Preview of Test Data:\")\ndisplay(test.head(2))",
            "mc_idx": 5,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.75,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 4,
                    "pd.read_": 4
                },
                "Exploratory_Data_Analysis": {
                    ".head(": 2,
                    "head": 2,
                    ".head": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    2,
                    3,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "   PassengerId  Survived  Pclass    ...        Fare Cabin  Embarked\n0            1         0       3    ...      7.2500   NaN         S\n1            2         1       1    ...     71.2833   C85         C\n\n[2 rows x 12 columns]",
                        "<IPython.core.display.Markdown object>",
                        "   PassengerId  Pclass   ...    Cabin Embarked\n0          892       3   ...      NaN        Q\n1          893       3   ...      NaN        S\n\n[2 rows x 11 columns]"
                    ]
                },
                "mc_idx": 5,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 2,
                "o_idx": 3
            }
        },
        {
            "source": "\"\"\"Merge train and test data together. This eliminates the hassle of handling train and test data seperately for various analysis.\"\"\"\nmerged = pd.concat([train, test], sort = False).reset_index(drop=True)\nbold(\"Preview of Merged Data:\")\ndisplay(merged.head(5))",
            "mc_idx": 8,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".concat(": 1,
                    ".reset_index": 1,
                    ".concat": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    3,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "   PassengerId  Survived  Pclass    ...        Fare Cabin  Embarked\n0            1       0.0       3    ...      7.2500   NaN         S\n1            2       1.0       1    ...     71.2833   C85         C\n2            3       1.0       3    ...      7.9250   NaN         S\n3            4       1.0       1    ...     53.1000  C123         S\n4            5       0.0       3    ...      8.0500   NaN         S\n\n[5 rows x 12 columns]"
                    ]
                },
                "mc_idx": 8,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 3,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Shape of the combined data.\"\"\"\nbold(\"Shape of the Merged Data:\")\ndisplay(merged.shape)\n\n\"\"\"Variables in the combined data.\"\"\"\nbold(\"Name of the Variables in merged data:\")\ndisplay(merged.columns)",
            "mc_idx": 9,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.75,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 2
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1,
                    "shape": 3
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    4,
                    3,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "(1309, 12)",
                        "<IPython.core.display.Markdown object>",
                        "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n      dtype='object')"
                    ]
                },
                "mc_idx": 9,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 4,
                "o_idx": 3
            }
        },
        {
            "source": "\"\"\"Pandas data types for our different variables.\"\"\"\nbold(\"Data Types of Our Variables:\")\ndisplay(merged.dtypes)",
            "mc_idx": 11,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 2
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "dtypes": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    5,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "PassengerId      int64\nSurvived       float64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object"
                    ]
                },
                "mc_idx": 11,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 5,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Create a function to plot a variable's absolute and relative frequency.\"\"\"\ndef plotFrequency(variable):\n    \"\"\"Plots absolute and relative frequency of a avriable.\"\"\"\n    \n    # Calculates absolute frequency\n    absFreq = variable.value_counts()\n    \n    # Calculates relative frequency\n    relFreq = variable.value_counts(normalize=True).round(4)*100\n    \n    # Creates a dataframe off absolute and relative frequency\n    df = pd.DataFrame({\n        \"absoluteFrequency\":absFreq,\n        \"relativeFrequency\":relFreq\n    })\n    \n    # Create two subplots of bar chart\n    fig=make_subplots(\n        rows=1, \n        cols=2,\n        vertical_spacing=0.3,\n        subplot_titles=(\"Absolute Frequency\", \"Relative Frequency\"),\n        print_grid=False) # This suppresses \"This is the format of your plot grid:\" text from popping out.\n\n    # Add trace for absolute frequency\n    fig.add_trace(\n        go.Bar(\n        y=df.index, \n        x=df.absoluteFrequency,\n        orientation=\"h\",\n        text=df.absoluteFrequency,\n        hoverinfo=\"x+y\",\n        textposition=\"auto\", \n        name=\"Abs Freq\",\n        textfont=dict(family=\"sans serif\",size=14),\n        marker = dict(color=df.absoluteFrequency, colorscale=\"Rainbow\")),\n        row=1,\n        col=1\n        )\n\n    # Add another trace for relative frequency\n    fig.add_trace(\n        go.Bar(y=df.index,\n        x=df.relativeFrequency.round(2),\n        orientation=\"h\",\n        text=df.relativeFrequency.round(2),\n        hoverinfo=\"x+y\",\n        textposition=\"auto\", \n        name=\"Rel Freq(%)\",\n        textfont=dict(family=\"sans serif\",size=15),\n        marker=dict(color=df.relativeFrequency.round(2), colorscale=\"Rainbow\")),\n        row=1,\n        col=2\n        )\n\n    # Update the layout. Add title, dimension, and background color\n    fig.layout.update(\n        height=600, \n        width=970,\n        hovermode=\"closest\",\n        title_text=f\"Absolute and Relative Frequency of {variable.name}\",showlegend=False,\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n\n    # Set y-axis title in bold\n    fig.layout.yaxis1.update(title=f\"<b>{variable.name}</b>\")\n    \n    # Set x-axes titles in bold\n    fig.layout.xaxis1.update(title=\"<b>Abs Freq</b>\")\n    fig.layout.xaxis2.update(title=\"<b>Rel Freq(%)</b>\")\n    # or, fig[\"layout\"][\"xaxis2\"].update(title=\"<b>Rel Freq(%)</b>\")\n    return fig.show()",
            "mc_idx": 13,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.7777777777777778,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.3333333333333333,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1,
                    "variable": 6
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    ".bar(": 2,
                    "info": 2,
                    "size": 2,
                    ".value_counts": 2
                },
                "Data_Transform": {
                    ".add": 2,
                    ".abs": 3,
                    ".round": 4
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    ".bar(": 2,
                    "chart": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    6,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 13,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 6,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Plot number of survivors and victims in absolute and relative scale in the tragedy.\"\"\"\nplotFrequency(merged.Survived)",
            "mc_idx": 15,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    7,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"b80ac3f2-a20a-4c67-9e48-562f2add226c\" class=\"plotly-graph-div\" style=\"height:600px; width:970px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"b80ac3f2-a20a-4c67-9e48-562f2add226c\")) {\n                    Plotly.newPlot(\n                        'b80ac3f2-a20a-4c67-9e48-562f2add226c',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [549, 342], \"colorscale\": \"Rainbow\"}, \"name\": \"Abs Freq\", \"orientation\": \"h\", \"text\": [549.0, 342.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"6437cf3d-77ed-450c-80d1-88081447e909\", \"x\": [549, 342], \"xaxis\": \"x\", \"y\": [0.0, 1.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [61.62, 38.38], \"colorscale\": \"Rainbow\"}, \"name\": \"Rel Freq(%)\", \"orientation\": \"h\", \"text\": [61.62, 38.38], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"0fad07b8-e744-4515-9939-a31511cc7055\", \"x\": [61.62, 38.38], \"xaxis\": \"x2\", \"y\": [0.0, 1.0], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Frequency\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Relative Frequency\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Absolute and Relative Frequency of Survived\"}, \"width\": 970, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"<b>Abs Freq</b>\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"<b>Rel Freq(%)</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Survived</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('b80ac3f2-a20a-4c67-9e48-562f2add226c');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 15,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 7,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Plot the absolute and relative frequency of Sex.\"\"\"\nplotFrequency(merged.Sex)",
            "mc_idx": 18,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    8,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"fde960fc-d331-4896-ba31-df6702692e4b\" class=\"plotly-graph-div\" style=\"height:600px; width:970px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"fde960fc-d331-4896-ba31-df6702692e4b\")) {\n                    Plotly.newPlot(\n                        'fde960fc-d331-4896-ba31-df6702692e4b',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [843, 466], \"colorscale\": \"Rainbow\"}, \"name\": \"Abs Freq\", \"orientation\": \"h\", \"text\": [843.0, 466.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"6694717e-8e49-4a12-b8ad-c8fb22aa3c67\", \"x\": [843, 466], \"xaxis\": \"x\", \"y\": [\"male\", \"female\"], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [64.4, 35.6], \"colorscale\": \"Rainbow\"}, \"name\": \"Rel Freq(%)\", \"orientation\": \"h\", \"text\": [64.4, 35.6], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"f2a74674-5ad4-487e-91e1-6d5dfd581402\", \"x\": [64.4, 35.6], \"xaxis\": \"x2\", \"y\": [\"male\", \"female\"], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Frequency\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Relative Frequency\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Absolute and Relative Frequency of Sex\"}, \"width\": 970, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"<b>Abs Freq</b>\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"<b>Rel Freq(%)</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Sex</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('fde960fc-d331-4896-ba31-df6702692e4b');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 18,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 8,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Absolute and relative frequency of Pclass.\"\"\"\nplotFrequency(merged.Pclass)",
            "mc_idx": 20,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    9,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"4487e3b3-9ec0-49d3-a04f-fd11ad0518d2\" class=\"plotly-graph-div\" style=\"height:600px; width:970px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"4487e3b3-9ec0-49d3-a04f-fd11ad0518d2\")) {\n                    Plotly.newPlot(\n                        '4487e3b3-9ec0-49d3-a04f-fd11ad0518d2',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [709, 323, 277], \"colorscale\": \"Rainbow\"}, \"name\": \"Abs Freq\", \"orientation\": \"h\", \"text\": [709.0, 323.0, 277.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"12cc02d2-cc07-4985-9e3f-98b6dbcc2d66\", \"x\": [709, 323, 277], \"xaxis\": \"x\", \"y\": [3, 1, 2], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [54.16, 24.68, 21.16], \"colorscale\": \"Rainbow\"}, \"name\": \"Rel Freq(%)\", \"orientation\": \"h\", \"text\": [54.16, 24.68, 21.16], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"10874fec-59a1-47ae-a4b6-539b73e8a2ad\", \"x\": [54.16, 24.68, 21.16], \"xaxis\": \"x2\", \"y\": [3, 1, 2], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Frequency\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Relative Frequency\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Absolute and Relative Frequency of Pclass\"}, \"width\": 970, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"<b>Abs Freq</b>\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"<b>Rel Freq(%)</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Pclass</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('4487e3b3-9ec0-49d3-a04f-fd11ad0518d2');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 20,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 9,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Plot absolute and relative frequency of Embarked.\"\"\"\nplotFrequency(merged.Embarked)",
            "mc_idx": 22,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    10,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"3213b36e-7976-4924-9c47-eb63ff70b148\" class=\"plotly-graph-div\" style=\"height:600px; width:970px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"3213b36e-7976-4924-9c47-eb63ff70b148\")) {\n                    Plotly.newPlot(\n                        '3213b36e-7976-4924-9c47-eb63ff70b148',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [914, 270, 123], \"colorscale\": \"Rainbow\"}, \"name\": \"Abs Freq\", \"orientation\": \"h\", \"text\": [914.0, 270.0, 123.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"ee613f30-c049-4c2e-ac52-292c2e8dc91a\", \"x\": [914, 270, 123], \"xaxis\": \"x\", \"y\": [\"S\", \"C\", \"Q\"], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [69.93, 20.66, 9.41], \"colorscale\": \"Rainbow\"}, \"name\": \"Rel Freq(%)\", \"orientation\": \"h\", \"text\": [69.93, 20.66, 9.41], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"cc5b53ec-eb0e-49cd-b717-3fce9c92afd9\", \"x\": [69.93, 20.66, 9.41], \"xaxis\": \"x2\", \"y\": [\"S\", \"C\", \"Q\"], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Frequency\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Relative Frequency\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Absolute and Relative Frequency of Embarked\"}, \"width\": 970, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"<b>Abs Freq</b>\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"<b>Rel Freq(%)</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Embarked</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('3213b36e-7976-4924-9c47-eb63ff70b148');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 22,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 10,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Absolute frequency of Cabin.\"\"\"\nabsFreqCabin = merged.Cabin.value_counts(dropna = False)\nbold(\"Categories of Cabin:\")\ndisplay(absFreqCabin.head())",
            "mc_idx": 24,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1,
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    11,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "NaN                1014\nC23 C25 C27           6\nB57 B59 B63 B66       5\nG6                    5\nD                     4\nName: Cabin, dtype: int64"
                    ]
                },
                "mc_idx": 24,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 11,
                "o_idx": 1
            }
        },
        {
            "source": "\n\"\"\"As frequency of Cabin isn't what we expected, let's count total categories in Cabin.\"\"\"\nbold(\"Total Categories in Cabin:\")\ndisplay(absFreqCabin.count())",
            "mc_idx": 25,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    12,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "187"
                    ]
                },
                "mc_idx": 25,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 12,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Finally preview the variable Cabin to see what is causing the irregularity.\"\"\"\nbold(\"Preview of Cabin:\")\ndisplay(merged.Cabin.head(7))",
            "mc_idx": 26,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.3333333333333333,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    13,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "0     NaN\n1     C85\n2     NaN\n3    C123\n4     NaN\n5     NaN\n6     E46\nName: Cabin, dtype: object"
                    ]
                },
                "mc_idx": 26,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 13,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Count total categories in Name.\"\"\"\nbold(\"Total Categories in Name:\")\ndisplay(merged.Name.value_counts().count())",
            "mc_idx": 28,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    14,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "1307"
                    ]
                },
                "mc_idx": 28,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 14,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Let's finally check the what's inside the variable Name.\"\"\"\nbold(\"Preview of Name:\")\ndisplay(merged.Name.head())",
            "mc_idx": 29,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.3333333333333333,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    15,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "0                              Braund, Mr. Owen Harris\n1    Cumings, Mrs. John Bradley (Florence Briggs Th...\n2                               Heikkinen, Miss. Laina\n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)\n4                             Allen, Mr. William Henry\nName: Name, dtype: object"
                    ]
                },
                "mc_idx": 29,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 15,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Count total groups in variable Ticket.\"\"\"\nbold(\"Total Groups in Ticket:\")\ndisplay(merged.Ticket.value_counts().count())",
            "mc_idx": 31,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    16,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "929"
                    ]
                },
                "mc_idx": 31,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 16,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Lets investigate Ticket.\"\"\"\nbold(\"Preview of Ticket:\")\ndisplay(merged.Ticket.head())",
            "mc_idx": 32,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    17,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "0           A/5 21171\n1            PC 17599\n2    STON/O2. 3101282\n3              113803\n4              373450\nName: Ticket, dtype: object"
                    ]
                },
                "mc_idx": 32,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 17,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Plot the absolute and relative frequency of SibSp to investigate its distribution.\"\"\"\nplotFrequency(merged.SibSp)",
            "mc_idx": 34,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    18,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"1e0006d4-f04b-4644-952e-a95245b5a860\" class=\"plotly-graph-div\" style=\"height:600px; width:970px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"1e0006d4-f04b-4644-952e-a95245b5a860\")) {\n                    Plotly.newPlot(\n                        '1e0006d4-f04b-4644-952e-a95245b5a860',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [891, 319, 42, 22, 20, 9, 6], \"colorscale\": \"Rainbow\"}, \"name\": \"Abs Freq\", \"orientation\": \"h\", \"text\": [891.0, 319.0, 42.0, 22.0, 20.0, 9.0, 6.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"c08a2d74-4510-4d72-ad14-9a21e6689535\", \"x\": [891, 319, 42, 22, 20, 9, 6], \"xaxis\": \"x\", \"y\": [0, 1, 2, 4, 3, 8, 5], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [68.07, 24.37, 3.21, 1.68, 1.53, 0.69, 0.46], \"colorscale\": \"Rainbow\"}, \"name\": \"Rel Freq(%)\", \"orientation\": \"h\", \"text\": [68.07, 24.37, 3.21, 1.68, 1.53, 0.69, 0.46], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"8481fcec-bfde-4c10-91d6-3e79d6a58209\", \"x\": [68.07, 24.37, 3.21, 1.68, 1.53, 0.69, 0.46], \"xaxis\": \"x2\", \"y\": [0, 1, 2, 4, 3, 8, 5], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Frequency\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Relative Frequency\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Absolute and Relative Frequency of SibSp\"}, \"width\": 970, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"<b>Abs Freq</b>\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"<b>Rel Freq(%)</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>SibSp</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('1e0006d4-f04b-4644-952e-a95245b5a860');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 34,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 18,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Absolute and relative frequency of Parch.\"\"\"\nplotFrequency(merged.Parch)",
            "mc_idx": 36,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    19,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"c3e1ec62-1a65-4d78-b981-53e1e8e74caa\" class=\"plotly-graph-div\" style=\"height:600px; width:970px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"c3e1ec62-1a65-4d78-b981-53e1e8e74caa\")) {\n                    Plotly.newPlot(\n                        'c3e1ec62-1a65-4d78-b981-53e1e8e74caa',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [1002, 170, 113, 8, 6, 6, 2, 2], \"colorscale\": \"Rainbow\"}, \"name\": \"Abs Freq\", \"orientation\": \"h\", \"text\": [1002.0, 170.0, 113.0, 8.0, 6.0, 6.0, 2.0, 2.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"68584a5b-dc9f-44c4-a74b-75c575348f7e\", \"x\": [1002, 170, 113, 8, 6, 6, 2, 2], \"xaxis\": \"x\", \"y\": [0, 1, 2, 3, 5, 4, 9, 6], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [76.55, 12.99, 8.63, 0.61, 0.46, 0.46, 0.15, 0.15], \"colorscale\": \"Rainbow\"}, \"name\": \"Rel Freq(%)\", \"orientation\": \"h\", \"text\": [76.55, 12.99, 8.63, 0.61, 0.46, 0.46, 0.15, 0.15], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"a1c2c595-3979-4f13-97fe-37b602abaac7\", \"x\": [76.55, 12.99, 8.63, 0.61, 0.46, 0.46, 0.15, 0.15], \"xaxis\": \"x2\", \"y\": [0, 1, 2, 3, 5, 4, 9, 6], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Frequency\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Relative Frequency\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Absolute and Relative Frequency of Parch\"}, \"width\": 970, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"<b>Abs Freq</b>\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"<b>Rel Freq(%)</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Parch</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('c3e1ec62-1a65-4d78-b981-53e1e8e74caa');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 36,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 19,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"#1.Create a function to plot histogram and density plot.\"\"\"\ndef plotHistogram(variable):\n    \"\"\"Plots histogram and density plot of a variable.\"\"\"\n    \n    # Create subplot object.\n    fig = make_subplots(\n        rows=2,\n        cols=1,\n        print_grid=False,\n    subplot_titles=(f\"Distribution of {variable.name} with Histogram\", f\"Distribution of {variable.name} with Density Plot\"))\n    \n    # This is a count histogram\n    fig.add_trace(\n        go.Histogram(\n            x = variable,\n            hoverinfo=\"x+y\",\n            marker = dict(color = \"chocolate\")\n        ),\n    row=1,col=1)\n    \n    # This is a density histogram\n    fig.add_trace(\n        go.Histogram(\n            x = variable,\n            hoverinfo=\"x+y\",\n            histnorm = \"density\",\n            marker = dict(color = \"darkred\")\n        ),\n    row=2,col=1)\n    \n    # Update layout\n    fig.layout.update(\n        height=800, \n        width=870,\n        hovermode=\"closest\",\n        showlegend=False,\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n    \n    # Update axes\n    fig.layout.yaxis1.update(title=\"<b>Abs Frequency</b>\")\n    fig.layout.yaxis2.update(title=\"<b>Density(%)</b>\")\n    fig.layout.xaxis2.update(title=f\"<b>{variable.name}</b>\")\n    return fig.show()\n    \n\n    \n'''#2.Calculate descriptive statistics.'''\ndef calculateSummaryStats(variable):\n    stats = variable.describe()\n    skewness = pd.Series(variable.skew(), index = [\"skewness\"])\n    statsDf = pd.DataFrame(pd.concat([skewness, stats], sort = False), columns = [variable.name])\n    statsDf = statsDf.reset_index().rename(columns={\"index\":\"summaryStats\"})\n    return display(statsDf.round(2))",
            "mc_idx": 38,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.8333333333333334,
                "Data_Transform": 0.5833333333333334,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.16666666666666666,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1,
                    "variable": 11
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".describe(": 1,
                    ".histogram(": 2,
                    "info": 2,
                    "describe": 1,
                    "columns": 2,
                    ".describe": 1,
                    ".skew": 1
                },
                "Data_Transform": {
                    ".concat(": 1,
                    ".reset_index": 1,
                    ".rename": 1,
                    ".concat": 1,
                    ".add": 2,
                    ".round": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "summary": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    20,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 38,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 20,
                "o_idx": 0
            }
        },
        {
            "source": "'''Plot histogram and density plot of Fare.'''\nplotHistogram(merged.Fare)",
            "mc_idx": 40,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    21,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"8518e726-d9ab-44c6-b352-8ce7646400aa\" class=\"plotly-graph-div\" style=\"height:800px; width:870px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"8518e726-d9ab-44c6-b352-8ce7646400aa\")) {\n                    Plotly.newPlot(\n                        '8518e726-d9ab-44c6-b352-8ce7646400aa',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": \"chocolate\"}, \"type\": \"histogram\", \"uid\": \"bc3aa1c7-981c-4809-84a2-f1ba2791c423\", \"x\": [7.25, 71.2833, 7.925, 53.1, 8.05, 8.4583, 51.8625, 21.075, 11.1333, 30.0708, 16.7, 26.55, 8.05, 31.275, 7.8542, 16.0, 29.125, 13.0, 18.0, 7.225, 26.0, 13.0, 8.0292, 35.5, 21.075, 31.3875, 7.225, 263.0, 7.8792, 7.8958, 27.7208, 146.5208, 7.75, 10.5, 82.1708, 52.0, 7.2292, 8.05, 18.0, 11.2417, 9.475, 21.0, 7.8958, 41.5792, 7.8792, 8.05, 15.5, 7.75, 21.6792, 17.8, 39.6875, 7.8, 76.7292, 26.0, 61.9792, 35.5, 10.5, 7.2292, 27.75, 46.9, 7.2292, 80.0, 83.475, 27.9, 27.7208, 15.2458, 10.5, 8.1583, 7.925, 8.6625, 10.5, 46.9, 73.5, 14.4542, 56.4958, 7.65, 7.8958, 8.05, 29.0, 12.475, 9.0, 9.5, 7.7875, 47.1, 10.5, 15.85, 34.375, 8.05, 263.0, 8.05, 8.05, 7.8542, 61.175, 20.575, 7.25, 8.05, 34.6542, 63.3583, 23.0, 26.0, 7.8958, 7.8958, 77.2875, 8.6542, 7.925, 7.8958, 7.65, 7.775, 7.8958, 24.15, 52.0, 14.4542, 8.05, 9.825, 14.4583, 7.925, 7.75, 21.0, 247.5208, 31.275, 73.5, 8.05, 30.0708, 13.0, 77.2875, 11.2417, 7.75, 7.1417, 22.3583, 6.975, 7.8958, 7.05, 14.5, 26.0, 13.0, 15.0458, 26.2833, 53.1, 9.2167, 79.2, 15.2458, 7.75, 15.85, 6.75, 11.5, 36.75, 7.7958, 34.375, 26.0, 13.0, 12.525, 66.6, 8.05, 14.5, 7.3125, 61.3792, 7.7333, 8.05, 8.6625, 69.55, 16.1, 15.75, 7.775, 8.6625, 39.6875, 20.525, 55.0, 27.9, 25.925, 56.4958, 33.5, 29.125, 11.1333, 7.925, 30.6958, 7.8542, 25.4667, 28.7125, 13.0, 0.0, 69.55, 15.05, 31.3875, 39.0, 22.025, 50.0, 15.5, 26.55, 15.5, 7.8958, 13.0, 13.0, 7.8542, 26.0, 27.7208, 146.5208, 7.75, 8.4042, 7.75, 13.0, 9.5, 69.55, 6.4958, 7.225, 8.05, 10.4625, 15.85, 18.7875, 7.75, 31.0, 7.05, 21.0, 7.25, 13.0, 7.75, 113.275, 7.925, 27.0, 76.2917, 10.5, 8.05, 13.0, 8.05, 7.8958, 90.0, 9.35, 10.5, 7.25, 13.0, 25.4667, 83.475, 7.775, 13.5, 31.3875, 10.5, 7.55, 26.0, 26.25, 10.5, 12.275, 14.4542, 15.5, 10.5, 7.125, 7.225, 90.0, 7.775, 14.5, 52.5542, 26.0, 7.25, 10.4625, 26.55, 16.1, 20.2125, 15.2458, 79.2, 86.5, 512.3292, 26.0, 7.75, 31.3875, 79.65, 0.0, 7.75, 10.5, 39.6875, 7.775, 153.4625, 135.6333, 31.0, 0.0, 19.5, 29.7, 7.75, 77.9583, 7.75, 0.0, 29.125, 20.25, 7.75, 7.8542, 9.5, 8.05, 26.0, 8.6625, 9.5, 7.8958, 13.0, 7.75, 78.85, 91.0792, 12.875, 8.85, 7.8958, 27.7208, 7.2292, 151.55, 30.5, 247.5208, 7.75, 23.25, 0.0, 12.35, 8.05, 151.55, 110.8833, 108.9, 24.0, 56.9292, 83.1583, 262.375, 26.0, 7.8958, 26.25, 7.8542, 26.0, 14.0, 164.8667, 134.5, 7.25, 7.8958, 12.35, 29.0, 69.55, 135.6333, 6.2375, 13.0, 20.525, 57.9792, 23.25, 28.5, 153.4625, 18.0, 133.65, 7.8958, 66.6, 134.5, 8.05, 35.5, 26.0, 263.0, 13.0, 13.0, 13.0, 13.0, 13.0, 16.1, 15.9, 8.6625, 9.225, 35.0, 7.2292, 17.8, 7.225, 9.5, 55.0, 13.0, 7.8792, 7.8792, 27.9, 27.7208, 14.4542, 7.05, 15.5, 7.25, 75.25, 7.2292, 7.75, 69.3, 55.4417, 6.4958, 8.05, 135.6333, 21.075, 82.1708, 7.25, 211.5, 4.0125, 7.775, 227.525, 15.7417, 7.925, 52.0, 7.8958, 73.5, 46.9, 13.0, 7.7292, 12.0, 120.0, 7.7958, 7.925, 113.275, 16.7, 7.7958, 7.8542, 26.0, 10.5, 12.65, 7.925, 8.05, 9.825, 15.85, 8.6625, 21.0, 7.75, 18.75, 7.775, 25.4667, 7.8958, 6.8583, 90.0, 0.0, 7.925, 8.05, 32.5, 13.0, 13.0, 24.15, 7.8958, 7.7333, 7.875, 14.4, 20.2125, 7.25, 26.0, 26.0, 7.75, 8.05, 26.55, 16.1, 26.0, 7.125, 55.9, 120.0, 34.375, 18.75, 263.0, 10.5, 26.25, 9.5, 7.775, 13.0, 8.1125, 81.8583, 19.5, 26.55, 19.2583, 30.5, 27.75, 19.9667, 27.75, 89.1042, 8.05, 7.8958, 26.55, 51.8625, 10.5, 7.75, 26.55, 8.05, 38.5, 13.0, 8.05, 7.05, 0.0, 26.55, 7.725, 19.2583, 7.25, 8.6625, 27.75, 13.7917, 9.8375, 52.0, 21.0, 7.0458, 7.5208, 12.2875, 46.9, 0.0, 8.05, 9.5875, 91.0792, 25.4667, 90.0, 29.7, 8.05, 15.9, 19.9667, 7.25, 30.5, 49.5042, 8.05, 14.4583, 78.2667, 15.1, 151.55, 7.7958, 8.6625, 7.75, 7.6292, 9.5875, 86.5, 108.9, 26.0, 26.55, 22.525, 56.4958, 7.75, 8.05, 26.2875, 59.4, 7.4958, 34.0208, 10.5, 24.15, 26.0, 7.8958, 93.5, 7.8958, 7.225, 57.9792, 7.2292, 7.75, 10.5, 221.7792, 7.925, 11.5, 26.0, 7.2292, 7.2292, 22.3583, 8.6625, 26.25, 26.55, 106.425, 14.5, 49.5, 71.0, 31.275, 31.275, 26.0, 106.425, 26.0, 26.0, 13.8625, 20.525, 36.75, 110.8833, 26.0, 7.8292, 7.225, 7.775, 26.55, 39.6, 227.525, 79.65, 17.4, 7.75, 7.8958, 13.5, 8.05, 8.05, 24.15, 7.8958, 21.075, 7.2292, 7.8542, 10.5, 51.4792, 26.3875, 7.75, 8.05, 14.5, 13.0, 55.9, 14.4583, 7.925, 30.0, 110.8833, 26.0, 40.125, 8.7125, 79.65, 15.0, 79.2, 8.05, 8.05, 7.125, 78.2667, 7.25, 7.75, 26.0, 24.15, 33.0, 0.0, 7.225, 56.9292, 27.0, 7.8958, 42.4, 8.05, 26.55, 15.55, 7.8958, 30.5, 41.5792, 153.4625, 31.275, 7.05, 15.5, 7.75, 8.05, 65.0, 14.4, 16.1, 39.0, 10.5, 14.4542, 52.5542, 15.7417, 7.8542, 16.1, 32.3208, 12.35, 77.9583, 7.8958, 7.7333, 30.0, 7.0542, 30.5, 0.0, 27.9, 13.0, 7.925, 26.25, 39.6875, 16.1, 7.8542, 69.3, 27.9, 56.4958, 19.2583, 76.7292, 7.8958, 35.5, 7.55, 7.55, 7.8958, 23.0, 8.4333, 7.8292, 6.75, 73.5, 7.8958, 15.5, 13.0, 113.275, 133.65, 7.225, 25.5875, 7.4958, 7.925, 73.5, 13.0, 7.775, 8.05, 52.0, 39.0, 52.0, 10.5, 13.0, 0.0, 7.775, 8.05, 9.8417, 46.9, 512.3292, 8.1375, 76.7292, 9.225, 46.9, 39.0, 41.5792, 39.6875, 10.1708, 7.7958, 211.3375, 57.0, 13.4167, 56.4958, 7.225, 26.55, 13.5, 8.05, 7.7333, 110.8833, 7.65, 227.525, 26.2875, 14.4542, 7.7417, 7.8542, 26.0, 13.5, 26.2875, 151.55, 15.2458, 49.5042, 26.55, 52.0, 9.4833, 13.0, 7.65, 227.525, 10.5, 15.5, 7.775, 33.0, 7.0542, 13.0, 13.0, 53.1, 8.6625, 21.0, 7.7375, 26.0, 7.925, 211.3375, 18.7875, 0.0, 13.0, 13.0, 16.1, 34.375, 512.3292, 7.8958, 7.8958, 30.0, 78.85, 262.375, 16.1, 7.925, 71.0, 20.25, 13.0, 53.1, 7.75, 23.0, 12.475, 9.5, 7.8958, 65.0, 14.5, 7.7958, 11.5, 8.05, 86.5, 14.5, 7.125, 7.2292, 120.0, 7.775, 77.9583, 39.6, 7.75, 24.15, 8.3625, 9.5, 7.8542, 10.5, 7.225, 23.0, 7.75, 7.75, 12.475, 7.7375, 211.3375, 7.2292, 57.0, 30.0, 23.45, 7.05, 7.25, 7.4958, 29.125, 20.575, 79.2, 7.75, 26.0, 69.55, 30.6958, 7.8958, 13.0, 25.9292, 8.6833, 7.2292, 24.15, 13.0, 26.25, 120.0, 8.5167, 6.975, 7.775, 0.0, 7.775, 13.0, 53.1, 7.8875, 24.15, 10.5, 31.275, 8.05, 0.0, 7.925, 37.0042, 6.45, 27.9, 93.5, 8.6625, 0.0, 12.475, 39.6875, 6.95, 56.4958, 37.0042, 7.75, 80.0, 14.4542, 18.75, 7.2292, 7.8542, 8.3, 83.1583, 8.6625, 8.05, 56.4958, 29.7, 7.925, 10.5, 31.0, 6.4375, 8.6625, 7.55, 69.55, 7.8958, 33.0, 89.1042, 31.275, 7.775, 15.2458, 39.4, 26.0, 9.35, 164.8667, 26.55, 19.2583, 7.2292, 14.1083, 11.5, 25.9292, 69.55, 13.0, 13.0, 13.8583, 50.4958, 9.5, 11.1333, 7.8958, 52.5542, 5.0, 9.0, 24.0, 7.225, 9.8458, 7.8958, 7.8958, 83.1583, 26.0, 7.8958, 10.5167, 10.5, 7.05, 29.125, 13.0, 30.0, 23.45, 30.0, 7.75, 7.8292, 7.0, 9.6875, 8.6625, 12.2875, 9.225, 7.6292, 29.0, 7.2292, 24.15, 7.8958, 26.0, 82.2667, 26.0, 61.175, 27.7208, 12.35, 7.225, 7.925, 7.225, 59.4, 3.1708, 31.6833, 61.3792, 262.375, 14.5, 61.9792, 7.225, 30.5, 21.6792, 26.0, 31.5, 20.575, 23.45, 57.75, 7.2292, 8.05, 8.6625, 9.5, 56.4958, 13.4167, 26.55, 7.85, 13.0, 52.5542, 7.925, 29.7, 7.75, 76.2917, 15.9, 60.0, 15.0333, 23.0, 263.0, 15.5792, 29.125, 7.8958, 7.65, 16.1, 262.375, 7.8958, 13.5, 7.75, 7.725, 262.375, 21.0, 7.8792, 42.4, 28.5375, 263.0, 7.75, 7.8958, 7.925, 27.7208, 211.5, 211.5, 8.05, 25.7, 13.0, 7.75, 15.2458, 221.7792, 26.0, 7.8958, 10.7083, 14.4542, 7.8792, 8.05, 7.75, 23.0, 13.9, 7.775, 52.0, 8.05, 26.0, 7.7958, 78.85, 7.925, 7.8542, 8.05, 55.4417, 26.0, 7.75, 7.775, 8.5167, 22.525, 7.8208, 7.75, 8.7125, 13.0, 15.0458, 7.7792, 31.6792, 7.2833, 221.7792, 14.4542, 6.4375, 16.7, 75.2417, 26.0, 15.75, 7.75, 57.75, 7.25, 7.75, 16.1, 7.7958, 23.25, 13.0, 8.05, 8.05, 28.5, 25.4667, 6.4375, 7.8958, 7.8542, 7.225, 13.0, 8.05, 46.9, 46.9, 151.55, 262.375, 26.0, 26.55, 18.0, 51.8625, 8.05, 26.55, 26.0, 83.1583, 7.8958, null, 12.1833, 31.3875, 7.55, 221.7792, 7.8542, 26.55, 13.775, 7.7333, 15.2458, 13.5, 7.0, 13.0, 22.025, 50.4958, 34.375, 27.7208, 8.9625, 7.55, 7.225, 13.9, 7.2292, 31.3875, 39.0, 36.75, 55.4417, 39.0, 83.1583, 13.0, 83.1583, 53.1, 7.75, 247.5208, 16.0, 21.0, 8.05, 69.55, 13.0, 26.0, 26.0, 14.5, 12.35, 32.5, 7.8542, 134.5, 7.775, 10.5, 8.1125, 15.5, 14.4, 227.525, 26.0, 10.5, 25.7417, 7.75, 10.5, 27.7208, 7.8958, 22.525, 7.05, 73.5, 26.0, 7.775, 42.5, 7.8792, 164.8667, 211.5, 8.05, 13.8583, 8.05, 10.5, 7.7958, 27.4458, 15.2458, 7.7958, 7.75, 15.1, 13.0, 65.0, 26.55, 6.4958, 7.8792, 71.2833, 7.8542, 75.25, 7.225, 13.0, 106.425, 27.7208, 30.0, 134.5, 7.8875, 23.45, 51.8625, 21.0, 32.5, 26.0, 14.4542, 27.75, 7.925, 136.7792, 9.325, 9.5, 7.55, 7.75, 8.05, 13.0, 7.775, 17.4, 7.8542, 23.0, 12.1833, 12.7375, 7.8958, 0.0, 7.55, 8.05, 8.6625, 75.2417, 7.75, 136.7792, 15.5, 7.225, 26.0, 10.5, 26.0, 21.0, 10.5, 8.6625, 13.775, 7.75, 15.2458, 20.2125, 7.25, 7.25, 82.2667, 7.2292, 8.05, 39.6, 6.95, 7.2292, 81.8583, 9.5, 7.8958, 41.5792, 21.6792, 45.5, 7.8542, 7.775, 15.0458, 21.0, 8.6625, 7.75, 26.55, 151.55, 9.35, 93.5, 14.1083, 8.6625, 7.225, 7.575, 7.75, 135.6333, 7.7333, 146.5208, 10.5, 7.8542, 31.5, 7.775, 7.2292, 13.0, 26.55, 211.3375, 7.05, 39.0, 79.2, 26.0, 13.0, 36.75, 29.7, 7.225, 15.7417, 7.8958, 26.0, 13.0, 7.2292, 31.5, 7.2292, 10.5, 7.5792, 69.55, 512.3292, 14.5, 7.65, 13.0, 7.2292, 13.5, 21.0, 63.3583, 10.5, 73.5, 65.0, 20.575, 26.0, 51.4792, 7.8792, 7.75, 15.55, 69.55, 37.0042, 21.0, 8.6625, 55.4417, 69.55, 14.4583, 39.6875, 59.4, 13.8583, 11.5, 134.5, 0.0, 13.0, 81.8583, 262.375, 8.6625, 11.5, 50.0, 31.3875, 7.75, 7.8792, 14.5, 16.1, 12.875, 65.0, 7.775, 13.0, 7.75, 21.075, 93.5, 39.4, 20.25, 10.5, 22.025, 60.0, 7.25, 79.2, 7.775, 7.7333, 164.8667, 21.0, 59.4, 47.1, 27.7208, 13.8625, 10.5, 211.5, 7.7208, 13.775, 7.75, 90.0, 7.775, 8.05, 108.9, 7.25, 8.05, 22.3583], \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"histnorm\": \"density\", \"hoverinfo\": \"x+y\", \"marker\": {\"color\": \"darkred\"}, \"type\": \"histogram\", \"uid\": \"9a9766ad-fd85-416b-8d7c-232da04efcf6\", \"x\": [7.25, 71.2833, 7.925, 53.1, 8.05, 8.4583, 51.8625, 21.075, 11.1333, 30.0708, 16.7, 26.55, 8.05, 31.275, 7.8542, 16.0, 29.125, 13.0, 18.0, 7.225, 26.0, 13.0, 8.0292, 35.5, 21.075, 31.3875, 7.225, 263.0, 7.8792, 7.8958, 27.7208, 146.5208, 7.75, 10.5, 82.1708, 52.0, 7.2292, 8.05, 18.0, 11.2417, 9.475, 21.0, 7.8958, 41.5792, 7.8792, 8.05, 15.5, 7.75, 21.6792, 17.8, 39.6875, 7.8, 76.7292, 26.0, 61.9792, 35.5, 10.5, 7.2292, 27.75, 46.9, 7.2292, 80.0, 83.475, 27.9, 27.7208, 15.2458, 10.5, 8.1583, 7.925, 8.6625, 10.5, 46.9, 73.5, 14.4542, 56.4958, 7.65, 7.8958, 8.05, 29.0, 12.475, 9.0, 9.5, 7.7875, 47.1, 10.5, 15.85, 34.375, 8.05, 263.0, 8.05, 8.05, 7.8542, 61.175, 20.575, 7.25, 8.05, 34.6542, 63.3583, 23.0, 26.0, 7.8958, 7.8958, 77.2875, 8.6542, 7.925, 7.8958, 7.65, 7.775, 7.8958, 24.15, 52.0, 14.4542, 8.05, 9.825, 14.4583, 7.925, 7.75, 21.0, 247.5208, 31.275, 73.5, 8.05, 30.0708, 13.0, 77.2875, 11.2417, 7.75, 7.1417, 22.3583, 6.975, 7.8958, 7.05, 14.5, 26.0, 13.0, 15.0458, 26.2833, 53.1, 9.2167, 79.2, 15.2458, 7.75, 15.85, 6.75, 11.5, 36.75, 7.7958, 34.375, 26.0, 13.0, 12.525, 66.6, 8.05, 14.5, 7.3125, 61.3792, 7.7333, 8.05, 8.6625, 69.55, 16.1, 15.75, 7.775, 8.6625, 39.6875, 20.525, 55.0, 27.9, 25.925, 56.4958, 33.5, 29.125, 11.1333, 7.925, 30.6958, 7.8542, 25.4667, 28.7125, 13.0, 0.0, 69.55, 15.05, 31.3875, 39.0, 22.025, 50.0, 15.5, 26.55, 15.5, 7.8958, 13.0, 13.0, 7.8542, 26.0, 27.7208, 146.5208, 7.75, 8.4042, 7.75, 13.0, 9.5, 69.55, 6.4958, 7.225, 8.05, 10.4625, 15.85, 18.7875, 7.75, 31.0, 7.05, 21.0, 7.25, 13.0, 7.75, 113.275, 7.925, 27.0, 76.2917, 10.5, 8.05, 13.0, 8.05, 7.8958, 90.0, 9.35, 10.5, 7.25, 13.0, 25.4667, 83.475, 7.775, 13.5, 31.3875, 10.5, 7.55, 26.0, 26.25, 10.5, 12.275, 14.4542, 15.5, 10.5, 7.125, 7.225, 90.0, 7.775, 14.5, 52.5542, 26.0, 7.25, 10.4625, 26.55, 16.1, 20.2125, 15.2458, 79.2, 86.5, 512.3292, 26.0, 7.75, 31.3875, 79.65, 0.0, 7.75, 10.5, 39.6875, 7.775, 153.4625, 135.6333, 31.0, 0.0, 19.5, 29.7, 7.75, 77.9583, 7.75, 0.0, 29.125, 20.25, 7.75, 7.8542, 9.5, 8.05, 26.0, 8.6625, 9.5, 7.8958, 13.0, 7.75, 78.85, 91.0792, 12.875, 8.85, 7.8958, 27.7208, 7.2292, 151.55, 30.5, 247.5208, 7.75, 23.25, 0.0, 12.35, 8.05, 151.55, 110.8833, 108.9, 24.0, 56.9292, 83.1583, 262.375, 26.0, 7.8958, 26.25, 7.8542, 26.0, 14.0, 164.8667, 134.5, 7.25, 7.8958, 12.35, 29.0, 69.55, 135.6333, 6.2375, 13.0, 20.525, 57.9792, 23.25, 28.5, 153.4625, 18.0, 133.65, 7.8958, 66.6, 134.5, 8.05, 35.5, 26.0, 263.0, 13.0, 13.0, 13.0, 13.0, 13.0, 16.1, 15.9, 8.6625, 9.225, 35.0, 7.2292, 17.8, 7.225, 9.5, 55.0, 13.0, 7.8792, 7.8792, 27.9, 27.7208, 14.4542, 7.05, 15.5, 7.25, 75.25, 7.2292, 7.75, 69.3, 55.4417, 6.4958, 8.05, 135.6333, 21.075, 82.1708, 7.25, 211.5, 4.0125, 7.775, 227.525, 15.7417, 7.925, 52.0, 7.8958, 73.5, 46.9, 13.0, 7.7292, 12.0, 120.0, 7.7958, 7.925, 113.275, 16.7, 7.7958, 7.8542, 26.0, 10.5, 12.65, 7.925, 8.05, 9.825, 15.85, 8.6625, 21.0, 7.75, 18.75, 7.775, 25.4667, 7.8958, 6.8583, 90.0, 0.0, 7.925, 8.05, 32.5, 13.0, 13.0, 24.15, 7.8958, 7.7333, 7.875, 14.4, 20.2125, 7.25, 26.0, 26.0, 7.75, 8.05, 26.55, 16.1, 26.0, 7.125, 55.9, 120.0, 34.375, 18.75, 263.0, 10.5, 26.25, 9.5, 7.775, 13.0, 8.1125, 81.8583, 19.5, 26.55, 19.2583, 30.5, 27.75, 19.9667, 27.75, 89.1042, 8.05, 7.8958, 26.55, 51.8625, 10.5, 7.75, 26.55, 8.05, 38.5, 13.0, 8.05, 7.05, 0.0, 26.55, 7.725, 19.2583, 7.25, 8.6625, 27.75, 13.7917, 9.8375, 52.0, 21.0, 7.0458, 7.5208, 12.2875, 46.9, 0.0, 8.05, 9.5875, 91.0792, 25.4667, 90.0, 29.7, 8.05, 15.9, 19.9667, 7.25, 30.5, 49.5042, 8.05, 14.4583, 78.2667, 15.1, 151.55, 7.7958, 8.6625, 7.75, 7.6292, 9.5875, 86.5, 108.9, 26.0, 26.55, 22.525, 56.4958, 7.75, 8.05, 26.2875, 59.4, 7.4958, 34.0208, 10.5, 24.15, 26.0, 7.8958, 93.5, 7.8958, 7.225, 57.9792, 7.2292, 7.75, 10.5, 221.7792, 7.925, 11.5, 26.0, 7.2292, 7.2292, 22.3583, 8.6625, 26.25, 26.55, 106.425, 14.5, 49.5, 71.0, 31.275, 31.275, 26.0, 106.425, 26.0, 26.0, 13.8625, 20.525, 36.75, 110.8833, 26.0, 7.8292, 7.225, 7.775, 26.55, 39.6, 227.525, 79.65, 17.4, 7.75, 7.8958, 13.5, 8.05, 8.05, 24.15, 7.8958, 21.075, 7.2292, 7.8542, 10.5, 51.4792, 26.3875, 7.75, 8.05, 14.5, 13.0, 55.9, 14.4583, 7.925, 30.0, 110.8833, 26.0, 40.125, 8.7125, 79.65, 15.0, 79.2, 8.05, 8.05, 7.125, 78.2667, 7.25, 7.75, 26.0, 24.15, 33.0, 0.0, 7.225, 56.9292, 27.0, 7.8958, 42.4, 8.05, 26.55, 15.55, 7.8958, 30.5, 41.5792, 153.4625, 31.275, 7.05, 15.5, 7.75, 8.05, 65.0, 14.4, 16.1, 39.0, 10.5, 14.4542, 52.5542, 15.7417, 7.8542, 16.1, 32.3208, 12.35, 77.9583, 7.8958, 7.7333, 30.0, 7.0542, 30.5, 0.0, 27.9, 13.0, 7.925, 26.25, 39.6875, 16.1, 7.8542, 69.3, 27.9, 56.4958, 19.2583, 76.7292, 7.8958, 35.5, 7.55, 7.55, 7.8958, 23.0, 8.4333, 7.8292, 6.75, 73.5, 7.8958, 15.5, 13.0, 113.275, 133.65, 7.225, 25.5875, 7.4958, 7.925, 73.5, 13.0, 7.775, 8.05, 52.0, 39.0, 52.0, 10.5, 13.0, 0.0, 7.775, 8.05, 9.8417, 46.9, 512.3292, 8.1375, 76.7292, 9.225, 46.9, 39.0, 41.5792, 39.6875, 10.1708, 7.7958, 211.3375, 57.0, 13.4167, 56.4958, 7.225, 26.55, 13.5, 8.05, 7.7333, 110.8833, 7.65, 227.525, 26.2875, 14.4542, 7.7417, 7.8542, 26.0, 13.5, 26.2875, 151.55, 15.2458, 49.5042, 26.55, 52.0, 9.4833, 13.0, 7.65, 227.525, 10.5, 15.5, 7.775, 33.0, 7.0542, 13.0, 13.0, 53.1, 8.6625, 21.0, 7.7375, 26.0, 7.925, 211.3375, 18.7875, 0.0, 13.0, 13.0, 16.1, 34.375, 512.3292, 7.8958, 7.8958, 30.0, 78.85, 262.375, 16.1, 7.925, 71.0, 20.25, 13.0, 53.1, 7.75, 23.0, 12.475, 9.5, 7.8958, 65.0, 14.5, 7.7958, 11.5, 8.05, 86.5, 14.5, 7.125, 7.2292, 120.0, 7.775, 77.9583, 39.6, 7.75, 24.15, 8.3625, 9.5, 7.8542, 10.5, 7.225, 23.0, 7.75, 7.75, 12.475, 7.7375, 211.3375, 7.2292, 57.0, 30.0, 23.45, 7.05, 7.25, 7.4958, 29.125, 20.575, 79.2, 7.75, 26.0, 69.55, 30.6958, 7.8958, 13.0, 25.9292, 8.6833, 7.2292, 24.15, 13.0, 26.25, 120.0, 8.5167, 6.975, 7.775, 0.0, 7.775, 13.0, 53.1, 7.8875, 24.15, 10.5, 31.275, 8.05, 0.0, 7.925, 37.0042, 6.45, 27.9, 93.5, 8.6625, 0.0, 12.475, 39.6875, 6.95, 56.4958, 37.0042, 7.75, 80.0, 14.4542, 18.75, 7.2292, 7.8542, 8.3, 83.1583, 8.6625, 8.05, 56.4958, 29.7, 7.925, 10.5, 31.0, 6.4375, 8.6625, 7.55, 69.55, 7.8958, 33.0, 89.1042, 31.275, 7.775, 15.2458, 39.4, 26.0, 9.35, 164.8667, 26.55, 19.2583, 7.2292, 14.1083, 11.5, 25.9292, 69.55, 13.0, 13.0, 13.8583, 50.4958, 9.5, 11.1333, 7.8958, 52.5542, 5.0, 9.0, 24.0, 7.225, 9.8458, 7.8958, 7.8958, 83.1583, 26.0, 7.8958, 10.5167, 10.5, 7.05, 29.125, 13.0, 30.0, 23.45, 30.0, 7.75, 7.8292, 7.0, 9.6875, 8.6625, 12.2875, 9.225, 7.6292, 29.0, 7.2292, 24.15, 7.8958, 26.0, 82.2667, 26.0, 61.175, 27.7208, 12.35, 7.225, 7.925, 7.225, 59.4, 3.1708, 31.6833, 61.3792, 262.375, 14.5, 61.9792, 7.225, 30.5, 21.6792, 26.0, 31.5, 20.575, 23.45, 57.75, 7.2292, 8.05, 8.6625, 9.5, 56.4958, 13.4167, 26.55, 7.85, 13.0, 52.5542, 7.925, 29.7, 7.75, 76.2917, 15.9, 60.0, 15.0333, 23.0, 263.0, 15.5792, 29.125, 7.8958, 7.65, 16.1, 262.375, 7.8958, 13.5, 7.75, 7.725, 262.375, 21.0, 7.8792, 42.4, 28.5375, 263.0, 7.75, 7.8958, 7.925, 27.7208, 211.5, 211.5, 8.05, 25.7, 13.0, 7.75, 15.2458, 221.7792, 26.0, 7.8958, 10.7083, 14.4542, 7.8792, 8.05, 7.75, 23.0, 13.9, 7.775, 52.0, 8.05, 26.0, 7.7958, 78.85, 7.925, 7.8542, 8.05, 55.4417, 26.0, 7.75, 7.775, 8.5167, 22.525, 7.8208, 7.75, 8.7125, 13.0, 15.0458, 7.7792, 31.6792, 7.2833, 221.7792, 14.4542, 6.4375, 16.7, 75.2417, 26.0, 15.75, 7.75, 57.75, 7.25, 7.75, 16.1, 7.7958, 23.25, 13.0, 8.05, 8.05, 28.5, 25.4667, 6.4375, 7.8958, 7.8542, 7.225, 13.0, 8.05, 46.9, 46.9, 151.55, 262.375, 26.0, 26.55, 18.0, 51.8625, 8.05, 26.55, 26.0, 83.1583, 7.8958, null, 12.1833, 31.3875, 7.55, 221.7792, 7.8542, 26.55, 13.775, 7.7333, 15.2458, 13.5, 7.0, 13.0, 22.025, 50.4958, 34.375, 27.7208, 8.9625, 7.55, 7.225, 13.9, 7.2292, 31.3875, 39.0, 36.75, 55.4417, 39.0, 83.1583, 13.0, 83.1583, 53.1, 7.75, 247.5208, 16.0, 21.0, 8.05, 69.55, 13.0, 26.0, 26.0, 14.5, 12.35, 32.5, 7.8542, 134.5, 7.775, 10.5, 8.1125, 15.5, 14.4, 227.525, 26.0, 10.5, 25.7417, 7.75, 10.5, 27.7208, 7.8958, 22.525, 7.05, 73.5, 26.0, 7.775, 42.5, 7.8792, 164.8667, 211.5, 8.05, 13.8583, 8.05, 10.5, 7.7958, 27.4458, 15.2458, 7.7958, 7.75, 15.1, 13.0, 65.0, 26.55, 6.4958, 7.8792, 71.2833, 7.8542, 75.25, 7.225, 13.0, 106.425, 27.7208, 30.0, 134.5, 7.8875, 23.45, 51.8625, 21.0, 32.5, 26.0, 14.4542, 27.75, 7.925, 136.7792, 9.325, 9.5, 7.55, 7.75, 8.05, 13.0, 7.775, 17.4, 7.8542, 23.0, 12.1833, 12.7375, 7.8958, 0.0, 7.55, 8.05, 8.6625, 75.2417, 7.75, 136.7792, 15.5, 7.225, 26.0, 10.5, 26.0, 21.0, 10.5, 8.6625, 13.775, 7.75, 15.2458, 20.2125, 7.25, 7.25, 82.2667, 7.2292, 8.05, 39.6, 6.95, 7.2292, 81.8583, 9.5, 7.8958, 41.5792, 21.6792, 45.5, 7.8542, 7.775, 15.0458, 21.0, 8.6625, 7.75, 26.55, 151.55, 9.35, 93.5, 14.1083, 8.6625, 7.225, 7.575, 7.75, 135.6333, 7.7333, 146.5208, 10.5, 7.8542, 31.5, 7.775, 7.2292, 13.0, 26.55, 211.3375, 7.05, 39.0, 79.2, 26.0, 13.0, 36.75, 29.7, 7.225, 15.7417, 7.8958, 26.0, 13.0, 7.2292, 31.5, 7.2292, 10.5, 7.5792, 69.55, 512.3292, 14.5, 7.65, 13.0, 7.2292, 13.5, 21.0, 63.3583, 10.5, 73.5, 65.0, 20.575, 26.0, 51.4792, 7.8792, 7.75, 15.55, 69.55, 37.0042, 21.0, 8.6625, 55.4417, 69.55, 14.4583, 39.6875, 59.4, 13.8583, 11.5, 134.5, 0.0, 13.0, 81.8583, 262.375, 8.6625, 11.5, 50.0, 31.3875, 7.75, 7.8792, 14.5, 16.1, 12.875, 65.0, 7.775, 13.0, 7.75, 21.075, 93.5, 39.4, 20.25, 10.5, 22.025, 60.0, 7.25, 79.2, 7.775, 7.7333, 164.8667, 21.0, 59.4, 47.1, 27.7208, 13.8625, 10.5, 211.5, 7.7208, 13.775, 7.75, 90.0, 7.775, 8.05, 108.9, 7.25, 8.05, 22.3583], \"xaxis\": \"x2\", \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Distribution of Fare with Histogram\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Distribution of Fare with Density Plot\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.375, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 800, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"width\": 870, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Fare</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.625, 1.0], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.375], \"title\": {\"text\": \"<b>Density(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('8518e726-d9ab-44c6-b352-8ce7646400aa');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 40,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 21,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Calculate summary statistics of Fare.\"\"\"\nbold(\"Summary Stats of Fare:\")\ncalculateSummaryStats(merged.Fare)",
            "mc_idx": 42,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "summary statistics": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "summary": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    22,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "  summaryStats     Fare\n0     skewness     4.37\n1        count  1308.00\n2         mean    33.30\n3          std    51.76\n4          min     0.00\n5          25%     7.90\n6          50%    14.45\n7          75%    31.28\n8          max   512.33"
                    ]
                },
                "mc_idx": 42,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 22,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Plot histogram and density plot of Age.\"\"\"\nplotHistogram(merged.Age)",
            "mc_idx": 44,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    23,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"8d123699-c737-4034-a8f5-b695b74cdb50\" class=\"plotly-graph-div\" style=\"height:800px; width:870px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"8d123699-c737-4034-a8f5-b695b74cdb50\")) {\n                    Plotly.newPlot(\n                        '8d123699-c737-4034-a8f5-b695b74cdb50',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": \"chocolate\"}, \"type\": \"histogram\", \"uid\": \"b2f79078-5841-4c15-9ba0-b8b19ae8c4fc\", \"x\": [22.0, 38.0, 26.0, 35.0, 35.0, null, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, null, 31.0, null, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, null, 19.0, null, null, 40.0, null, null, 66.0, 28.0, 42.0, null, 21.0, 18.0, 14.0, 40.0, 27.0, null, 3.0, 19.0, null, null, null, null, 18.0, 7.0, 21.0, 49.0, 29.0, 65.0, null, 21.0, 28.5, 5.0, 11.0, 22.0, 38.0, 45.0, 4.0, null, null, 29.0, 19.0, 17.0, 26.0, 32.0, 16.0, 21.0, 26.0, 32.0, 25.0, null, null, 0.83, 30.0, 22.0, 29.0, null, 28.0, 17.0, 33.0, 16.0, null, 23.0, 24.0, 29.0, 20.0, 46.0, 26.0, 59.0, null, 71.0, 23.0, 34.0, 34.0, 28.0, null, 21.0, 33.0, 37.0, 28.0, 21.0, null, 38.0, null, 47.0, 14.5, 22.0, 20.0, 17.0, 21.0, 70.5, 29.0, 24.0, 2.0, 21.0, null, 32.5, 32.5, 54.0, 12.0, null, 24.0, null, 45.0, 33.0, 20.0, 47.0, 29.0, 25.0, 23.0, 19.0, 37.0, 16.0, 24.0, null, 22.0, 24.0, 19.0, 18.0, 19.0, 27.0, 9.0, 36.5, 42.0, 51.0, 22.0, 55.5, 40.5, null, 51.0, 16.0, 30.0, null, null, 44.0, 40.0, 26.0, 17.0, 1.0, 9.0, null, 45.0, null, 28.0, 61.0, 4.0, 1.0, 21.0, 56.0, 18.0, null, 50.0, 30.0, 36.0, null, null, 9.0, 1.0, 4.0, null, null, 45.0, 40.0, 36.0, 32.0, 19.0, 19.0, 3.0, 44.0, 58.0, null, 42.0, null, 24.0, 28.0, null, 34.0, 45.5, 18.0, 2.0, 32.0, 26.0, 16.0, 40.0, 24.0, 35.0, 22.0, 30.0, null, 31.0, 27.0, 42.0, 32.0, 30.0, 16.0, 27.0, 51.0, null, 38.0, 22.0, 19.0, 20.5, 18.0, null, 35.0, 29.0, 59.0, 5.0, 24.0, null, 44.0, 8.0, 19.0, 33.0, null, null, 29.0, 22.0, 30.0, 44.0, 25.0, 24.0, 37.0, 54.0, null, 29.0, 62.0, 30.0, 41.0, 29.0, null, 30.0, 35.0, 50.0, null, 3.0, 52.0, 40.0, null, 36.0, 16.0, 25.0, 58.0, 35.0, null, 25.0, 41.0, 37.0, null, 63.0, 45.0, null, 7.0, 35.0, 65.0, 28.0, 16.0, 19.0, null, 33.0, 30.0, 22.0, 42.0, 22.0, 26.0, 19.0, 36.0, 24.0, 24.0, null, 23.5, 2.0, null, 50.0, null, null, 19.0, null, null, 0.92, null, 17.0, 30.0, 30.0, 24.0, 18.0, 26.0, 28.0, 43.0, 26.0, 24.0, 54.0, 31.0, 40.0, 22.0, 27.0, 30.0, 22.0, null, 36.0, 61.0, 36.0, 31.0, 16.0, null, 45.5, 38.0, 16.0, null, null, 29.0, 41.0, 45.0, 45.0, 2.0, 24.0, 28.0, 25.0, 36.0, 24.0, 40.0, null, 3.0, 42.0, 23.0, null, 15.0, 25.0, null, 28.0, 22.0, 38.0, null, null, 40.0, 29.0, 45.0, 35.0, null, 30.0, 60.0, null, null, 24.0, 25.0, 18.0, 19.0, 22.0, 3.0, null, 22.0, 27.0, 20.0, 19.0, 42.0, 1.0, 32.0, 35.0, null, 18.0, 1.0, 36.0, null, 17.0, 36.0, 21.0, 28.0, 23.0, 24.0, 22.0, 31.0, 46.0, 23.0, 28.0, 39.0, 26.0, 21.0, 28.0, 20.0, 34.0, 51.0, 3.0, 21.0, null, null, null, 33.0, null, 44.0, null, 34.0, 18.0, 30.0, 10.0, null, 21.0, 29.0, 28.0, 18.0, null, 28.0, 19.0, null, 32.0, 28.0, null, 42.0, 17.0, 50.0, 14.0, 21.0, 24.0, 64.0, 31.0, 45.0, 20.0, 25.0, 28.0, null, 4.0, 13.0, 34.0, 5.0, 52.0, 36.0, null, 30.0, 49.0, null, 29.0, 65.0, null, 50.0, null, 48.0, 34.0, 47.0, 48.0, null, 38.0, null, 56.0, null, 0.75, null, 38.0, 33.0, 23.0, 22.0, null, 34.0, 29.0, 22.0, 2.0, 9.0, null, 50.0, 63.0, 25.0, null, 35.0, 58.0, 30.0, 9.0, null, 21.0, 55.0, 71.0, 21.0, null, 54.0, null, 25.0, 24.0, 17.0, 21.0, null, 37.0, 16.0, 18.0, 33.0, null, 28.0, 26.0, 29.0, null, 36.0, 54.0, 24.0, 47.0, 34.0, null, 36.0, 32.0, 30.0, 22.0, null, 44.0, null, 40.5, 50.0, null, 39.0, 23.0, 2.0, null, 17.0, null, 30.0, 7.0, 45.0, 30.0, null, 22.0, 36.0, 9.0, 11.0, 32.0, 50.0, 64.0, 19.0, null, 33.0, 8.0, 17.0, 27.0, null, 22.0, 22.0, 62.0, 48.0, null, 39.0, 36.0, null, 40.0, 28.0, null, null, 24.0, 19.0, 29.0, null, 32.0, 62.0, 53.0, 36.0, null, 16.0, 19.0, 34.0, 39.0, null, 32.0, 25.0, 39.0, 54.0, 36.0, null, 18.0, 47.0, 60.0, 22.0, null, 35.0, 52.0, 47.0, null, 37.0, 36.0, null, 49.0, null, 49.0, 24.0, null, null, 44.0, 35.0, 36.0, 30.0, 27.0, 22.0, 40.0, 39.0, null, null, null, 35.0, 24.0, 34.0, 26.0, 4.0, 26.0, 27.0, 42.0, 20.0, 21.0, 21.0, 61.0, 57.0, 21.0, 26.0, null, 80.0, 51.0, 32.0, null, 9.0, 28.0, 32.0, 31.0, 41.0, null, 20.0, 24.0, 2.0, null, 0.75, 48.0, 19.0, 56.0, null, 23.0, null, 18.0, 21.0, null, 18.0, 24.0, null, 32.0, 23.0, 58.0, 50.0, 40.0, 47.0, 36.0, 20.0, 32.0, 25.0, null, 43.0, null, 40.0, 31.0, 70.0, 31.0, null, 18.0, 24.5, 18.0, 43.0, 36.0, null, 27.0, 20.0, 14.0, 60.0, 25.0, 14.0, 19.0, 18.0, 15.0, 31.0, 4.0, null, 25.0, 60.0, 52.0, 44.0, null, 49.0, 42.0, 18.0, 35.0, 18.0, 25.0, 26.0, 39.0, 45.0, 42.0, 22.0, null, 24.0, null, 48.0, 29.0, 52.0, 19.0, 38.0, 27.0, null, 33.0, 6.0, 17.0, 34.0, 50.0, 27.0, 20.0, 30.0, null, 25.0, 25.0, 29.0, 11.0, null, 23.0, 23.0, 28.5, 48.0, 35.0, null, null, null, 36.0, 21.0, 24.0, 31.0, 70.0, 16.0, 30.0, 19.0, 31.0, 4.0, 6.0, 33.0, 23.0, 48.0, 0.67, 28.0, 18.0, 34.0, 33.0, null, 41.0, 20.0, 36.0, 16.0, 51.0, null, 30.5, null, 32.0, 24.0, 48.0, 57.0, null, 54.0, 18.0, null, 5.0, null, 43.0, 13.0, 17.0, 29.0, null, 25.0, 25.0, 18.0, 8.0, 1.0, 46.0, null, 16.0, null, null, 25.0, 39.0, 49.0, 31.0, 30.0, 30.0, 34.0, 31.0, 11.0, 0.42, 27.0, 31.0, 39.0, 18.0, 39.0, 33.0, 26.0, 39.0, 35.0, 6.0, 30.5, null, 23.0, 31.0, 43.0, 10.0, 52.0, 27.0, 38.0, 27.0, 2.0, null, null, 1.0, null, 62.0, 15.0, 0.83, null, 23.0, 18.0, 39.0, 21.0, null, 32.0, null, 20.0, 16.0, 30.0, 34.5, 17.0, 42.0, null, 35.0, 28.0, null, 4.0, 74.0, 9.0, 16.0, 44.0, 18.0, 45.0, 51.0, 24.0, null, 41.0, 21.0, 48.0, null, 24.0, 42.0, 27.0, 31.0, null, 4.0, 26.0, 47.0, 33.0, 47.0, 28.0, 15.0, 20.0, 19.0, null, 56.0, 25.0, 33.0, 22.0, 28.0, 25.0, 39.0, 27.0, 19.0, null, 26.0, 32.0, 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0, null, 46.0, 23.0, 63.0, 47.0, 24.0, 35.0, 21.0, 27.0, 45.0, 55.0, 9.0, null, 21.0, 48.0, 50.0, 22.0, 22.5, 41.0, null, 50.0, 24.0, 33.0, null, 30.0, 18.5, null, 21.0, 25.0, null, 39.0, null, 41.0, 30.0, 45.0, 25.0, 45.0, null, 60.0, 36.0, 24.0, 27.0, 20.0, 28.0, null, 10.0, 35.0, 25.0, null, 36.0, 17.0, 32.0, 18.0, 22.0, 13.0, null, 18.0, 47.0, 31.0, 60.0, 24.0, 21.0, 29.0, 28.5, 35.0, 32.5, null, 55.0, 30.0, 24.0, 6.0, 67.0, 49.0, null, null, null, 27.0, 18.0, null, 2.0, 22.0, null, 27.0, null, 25.0, 25.0, 76.0, 29.0, 20.0, 33.0, 43.0, 27.0, null, 26.0, 16.0, 28.0, 21.0, null, null, 18.5, 41.0, null, 36.0, 18.5, 63.0, 18.0, null, 1.0, 36.0, 29.0, 12.0, null, 35.0, 28.0, null, 17.0, 22.0, null, 42.0, 24.0, 32.0, 53.0, null, null, 43.0, 24.0, 26.5, 26.0, 23.0, 40.0, 10.0, 33.0, 61.0, 28.0, 42.0, 31.0, null, 22.0, null, 30.0, 23.0, null, 60.5, 36.0, 13.0, 24.0, 29.0, 23.0, 42.0, 26.0, null, 7.0, 26.0, null, 41.0, 26.0, 48.0, 18.0, null, 22.0, null, 27.0, 23.0, null, 40.0, 15.0, 20.0, 54.0, 36.0, 64.0, 30.0, 37.0, 18.0, null, 27.0, 40.0, 21.0, 17.0, null, 40.0, 34.0, null, 11.5, 61.0, 8.0, 33.0, 6.0, 18.0, 23.0, null, null, 0.33, 47.0, 8.0, 25.0, null, 35.0, 24.0, 33.0, 25.0, 32.0, null, 17.0, 60.0, 38.0, 42.0, null, 57.0, 50.0, null, 30.0, 21.0, 22.0, 21.0, 53.0, null, 23.0, null, 40.5, 36.0, 14.0, 21.0, 21.0, null, 39.0, 20.0, 64.0, 20.0, 18.0, 48.0, 55.0, 45.0, 45.0, null, null, 41.0, 22.0, 42.0, 29.0, null, 0.92, 20.0, 27.0, 24.0, 32.5, null, null, 28.0, 19.0, 21.0, 36.5, 21.0, 29.0, 1.0, 30.0, null, null, null, null, 17.0, 46.0, null, 26.0, null, null, 20.0, 28.0, 40.0, 30.0, 22.0, 23.0, 0.75, null, 9.0, 2.0, 36.0, null, 24.0, null, null, null, 30.0, null, 53.0, 36.0, 26.0, 1.0, null, 30.0, 29.0, 32.0, null, 43.0, 24.0, null, 64.0, 30.0, 0.83, 55.0, 45.0, 18.0, 22.0, null, 37.0, 55.0, 17.0, 57.0, 19.0, 27.0, 22.0, 26.0, 25.0, 26.0, 33.0, 39.0, 23.0, 12.0, 46.0, 29.0, 21.0, 48.0, 39.0, null, 19.0, 27.0, 30.0, 32.0, 39.0, 25.0, null, 18.0, 32.0, null, 58.0, null, 16.0, 26.0, 38.0, 24.0, 31.0, 45.0, 25.0, 18.0, 49.0, 0.17, 50.0, 59.0, null, null, 30.0, 14.5, 24.0, 31.0, 27.0, 25.0, null, null, 22.0, 45.0, 29.0, 21.0, 31.0, 49.0, 44.0, 54.0, 45.0, 22.0, 21.0, 55.0, 5.0, null, 26.0, null, 19.0, null, 24.0, 24.0, 57.0, 21.0, 6.0, 23.0, 51.0, 13.0, 47.0, 29.0, 18.0, 24.0, 48.0, 22.0, 31.0, 30.0, 38.0, 22.0, 17.0, 43.0, 20.0, 23.0, 50.0, null, 3.0, null, 37.0, 28.0, null, 39.0, 38.5, null, null], \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"histnorm\": \"density\", \"hoverinfo\": \"x+y\", \"marker\": {\"color\": \"darkred\"}, \"type\": \"histogram\", \"uid\": \"a4c8b87f-9746-4b1f-aa25-419100a5d2f0\", \"x\": [22.0, 38.0, 26.0, 35.0, 35.0, null, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, null, 31.0, null, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, null, 19.0, null, null, 40.0, null, null, 66.0, 28.0, 42.0, null, 21.0, 18.0, 14.0, 40.0, 27.0, null, 3.0, 19.0, null, null, null, null, 18.0, 7.0, 21.0, 49.0, 29.0, 65.0, null, 21.0, 28.5, 5.0, 11.0, 22.0, 38.0, 45.0, 4.0, null, null, 29.0, 19.0, 17.0, 26.0, 32.0, 16.0, 21.0, 26.0, 32.0, 25.0, null, null, 0.83, 30.0, 22.0, 29.0, null, 28.0, 17.0, 33.0, 16.0, null, 23.0, 24.0, 29.0, 20.0, 46.0, 26.0, 59.0, null, 71.0, 23.0, 34.0, 34.0, 28.0, null, 21.0, 33.0, 37.0, 28.0, 21.0, null, 38.0, null, 47.0, 14.5, 22.0, 20.0, 17.0, 21.0, 70.5, 29.0, 24.0, 2.0, 21.0, null, 32.5, 32.5, 54.0, 12.0, null, 24.0, null, 45.0, 33.0, 20.0, 47.0, 29.0, 25.0, 23.0, 19.0, 37.0, 16.0, 24.0, null, 22.0, 24.0, 19.0, 18.0, 19.0, 27.0, 9.0, 36.5, 42.0, 51.0, 22.0, 55.5, 40.5, null, 51.0, 16.0, 30.0, null, null, 44.0, 40.0, 26.0, 17.0, 1.0, 9.0, null, 45.0, null, 28.0, 61.0, 4.0, 1.0, 21.0, 56.0, 18.0, null, 50.0, 30.0, 36.0, null, null, 9.0, 1.0, 4.0, null, null, 45.0, 40.0, 36.0, 32.0, 19.0, 19.0, 3.0, 44.0, 58.0, null, 42.0, null, 24.0, 28.0, null, 34.0, 45.5, 18.0, 2.0, 32.0, 26.0, 16.0, 40.0, 24.0, 35.0, 22.0, 30.0, null, 31.0, 27.0, 42.0, 32.0, 30.0, 16.0, 27.0, 51.0, null, 38.0, 22.0, 19.0, 20.5, 18.0, null, 35.0, 29.0, 59.0, 5.0, 24.0, null, 44.0, 8.0, 19.0, 33.0, null, null, 29.0, 22.0, 30.0, 44.0, 25.0, 24.0, 37.0, 54.0, null, 29.0, 62.0, 30.0, 41.0, 29.0, null, 30.0, 35.0, 50.0, null, 3.0, 52.0, 40.0, null, 36.0, 16.0, 25.0, 58.0, 35.0, null, 25.0, 41.0, 37.0, null, 63.0, 45.0, null, 7.0, 35.0, 65.0, 28.0, 16.0, 19.0, null, 33.0, 30.0, 22.0, 42.0, 22.0, 26.0, 19.0, 36.0, 24.0, 24.0, null, 23.5, 2.0, null, 50.0, null, null, 19.0, null, null, 0.92, null, 17.0, 30.0, 30.0, 24.0, 18.0, 26.0, 28.0, 43.0, 26.0, 24.0, 54.0, 31.0, 40.0, 22.0, 27.0, 30.0, 22.0, null, 36.0, 61.0, 36.0, 31.0, 16.0, null, 45.5, 38.0, 16.0, null, null, 29.0, 41.0, 45.0, 45.0, 2.0, 24.0, 28.0, 25.0, 36.0, 24.0, 40.0, null, 3.0, 42.0, 23.0, null, 15.0, 25.0, null, 28.0, 22.0, 38.0, null, null, 40.0, 29.0, 45.0, 35.0, null, 30.0, 60.0, null, null, 24.0, 25.0, 18.0, 19.0, 22.0, 3.0, null, 22.0, 27.0, 20.0, 19.0, 42.0, 1.0, 32.0, 35.0, null, 18.0, 1.0, 36.0, null, 17.0, 36.0, 21.0, 28.0, 23.0, 24.0, 22.0, 31.0, 46.0, 23.0, 28.0, 39.0, 26.0, 21.0, 28.0, 20.0, 34.0, 51.0, 3.0, 21.0, null, null, null, 33.0, null, 44.0, null, 34.0, 18.0, 30.0, 10.0, null, 21.0, 29.0, 28.0, 18.0, null, 28.0, 19.0, null, 32.0, 28.0, null, 42.0, 17.0, 50.0, 14.0, 21.0, 24.0, 64.0, 31.0, 45.0, 20.0, 25.0, 28.0, null, 4.0, 13.0, 34.0, 5.0, 52.0, 36.0, null, 30.0, 49.0, null, 29.0, 65.0, null, 50.0, null, 48.0, 34.0, 47.0, 48.0, null, 38.0, null, 56.0, null, 0.75, null, 38.0, 33.0, 23.0, 22.0, null, 34.0, 29.0, 22.0, 2.0, 9.0, null, 50.0, 63.0, 25.0, null, 35.0, 58.0, 30.0, 9.0, null, 21.0, 55.0, 71.0, 21.0, null, 54.0, null, 25.0, 24.0, 17.0, 21.0, null, 37.0, 16.0, 18.0, 33.0, null, 28.0, 26.0, 29.0, null, 36.0, 54.0, 24.0, 47.0, 34.0, null, 36.0, 32.0, 30.0, 22.0, null, 44.0, null, 40.5, 50.0, null, 39.0, 23.0, 2.0, null, 17.0, null, 30.0, 7.0, 45.0, 30.0, null, 22.0, 36.0, 9.0, 11.0, 32.0, 50.0, 64.0, 19.0, null, 33.0, 8.0, 17.0, 27.0, null, 22.0, 22.0, 62.0, 48.0, null, 39.0, 36.0, null, 40.0, 28.0, null, null, 24.0, 19.0, 29.0, null, 32.0, 62.0, 53.0, 36.0, null, 16.0, 19.0, 34.0, 39.0, null, 32.0, 25.0, 39.0, 54.0, 36.0, null, 18.0, 47.0, 60.0, 22.0, null, 35.0, 52.0, 47.0, null, 37.0, 36.0, null, 49.0, null, 49.0, 24.0, null, null, 44.0, 35.0, 36.0, 30.0, 27.0, 22.0, 40.0, 39.0, null, null, null, 35.0, 24.0, 34.0, 26.0, 4.0, 26.0, 27.0, 42.0, 20.0, 21.0, 21.0, 61.0, 57.0, 21.0, 26.0, null, 80.0, 51.0, 32.0, null, 9.0, 28.0, 32.0, 31.0, 41.0, null, 20.0, 24.0, 2.0, null, 0.75, 48.0, 19.0, 56.0, null, 23.0, null, 18.0, 21.0, null, 18.0, 24.0, null, 32.0, 23.0, 58.0, 50.0, 40.0, 47.0, 36.0, 20.0, 32.0, 25.0, null, 43.0, null, 40.0, 31.0, 70.0, 31.0, null, 18.0, 24.5, 18.0, 43.0, 36.0, null, 27.0, 20.0, 14.0, 60.0, 25.0, 14.0, 19.0, 18.0, 15.0, 31.0, 4.0, null, 25.0, 60.0, 52.0, 44.0, null, 49.0, 42.0, 18.0, 35.0, 18.0, 25.0, 26.0, 39.0, 45.0, 42.0, 22.0, null, 24.0, null, 48.0, 29.0, 52.0, 19.0, 38.0, 27.0, null, 33.0, 6.0, 17.0, 34.0, 50.0, 27.0, 20.0, 30.0, null, 25.0, 25.0, 29.0, 11.0, null, 23.0, 23.0, 28.5, 48.0, 35.0, null, null, null, 36.0, 21.0, 24.0, 31.0, 70.0, 16.0, 30.0, 19.0, 31.0, 4.0, 6.0, 33.0, 23.0, 48.0, 0.67, 28.0, 18.0, 34.0, 33.0, null, 41.0, 20.0, 36.0, 16.0, 51.0, null, 30.5, null, 32.0, 24.0, 48.0, 57.0, null, 54.0, 18.0, null, 5.0, null, 43.0, 13.0, 17.0, 29.0, null, 25.0, 25.0, 18.0, 8.0, 1.0, 46.0, null, 16.0, null, null, 25.0, 39.0, 49.0, 31.0, 30.0, 30.0, 34.0, 31.0, 11.0, 0.42, 27.0, 31.0, 39.0, 18.0, 39.0, 33.0, 26.0, 39.0, 35.0, 6.0, 30.5, null, 23.0, 31.0, 43.0, 10.0, 52.0, 27.0, 38.0, 27.0, 2.0, null, null, 1.0, null, 62.0, 15.0, 0.83, null, 23.0, 18.0, 39.0, 21.0, null, 32.0, null, 20.0, 16.0, 30.0, 34.5, 17.0, 42.0, null, 35.0, 28.0, null, 4.0, 74.0, 9.0, 16.0, 44.0, 18.0, 45.0, 51.0, 24.0, null, 41.0, 21.0, 48.0, null, 24.0, 42.0, 27.0, 31.0, null, 4.0, 26.0, 47.0, 33.0, 47.0, 28.0, 15.0, 20.0, 19.0, null, 56.0, 25.0, 33.0, 22.0, 28.0, 25.0, 39.0, 27.0, 19.0, null, 26.0, 32.0, 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0, null, 46.0, 23.0, 63.0, 47.0, 24.0, 35.0, 21.0, 27.0, 45.0, 55.0, 9.0, null, 21.0, 48.0, 50.0, 22.0, 22.5, 41.0, null, 50.0, 24.0, 33.0, null, 30.0, 18.5, null, 21.0, 25.0, null, 39.0, null, 41.0, 30.0, 45.0, 25.0, 45.0, null, 60.0, 36.0, 24.0, 27.0, 20.0, 28.0, null, 10.0, 35.0, 25.0, null, 36.0, 17.0, 32.0, 18.0, 22.0, 13.0, null, 18.0, 47.0, 31.0, 60.0, 24.0, 21.0, 29.0, 28.5, 35.0, 32.5, null, 55.0, 30.0, 24.0, 6.0, 67.0, 49.0, null, null, null, 27.0, 18.0, null, 2.0, 22.0, null, 27.0, null, 25.0, 25.0, 76.0, 29.0, 20.0, 33.0, 43.0, 27.0, null, 26.0, 16.0, 28.0, 21.0, null, null, 18.5, 41.0, null, 36.0, 18.5, 63.0, 18.0, null, 1.0, 36.0, 29.0, 12.0, null, 35.0, 28.0, null, 17.0, 22.0, null, 42.0, 24.0, 32.0, 53.0, null, null, 43.0, 24.0, 26.5, 26.0, 23.0, 40.0, 10.0, 33.0, 61.0, 28.0, 42.0, 31.0, null, 22.0, null, 30.0, 23.0, null, 60.5, 36.0, 13.0, 24.0, 29.0, 23.0, 42.0, 26.0, null, 7.0, 26.0, null, 41.0, 26.0, 48.0, 18.0, null, 22.0, null, 27.0, 23.0, null, 40.0, 15.0, 20.0, 54.0, 36.0, 64.0, 30.0, 37.0, 18.0, null, 27.0, 40.0, 21.0, 17.0, null, 40.0, 34.0, null, 11.5, 61.0, 8.0, 33.0, 6.0, 18.0, 23.0, null, null, 0.33, 47.0, 8.0, 25.0, null, 35.0, 24.0, 33.0, 25.0, 32.0, null, 17.0, 60.0, 38.0, 42.0, null, 57.0, 50.0, null, 30.0, 21.0, 22.0, 21.0, 53.0, null, 23.0, null, 40.5, 36.0, 14.0, 21.0, 21.0, null, 39.0, 20.0, 64.0, 20.0, 18.0, 48.0, 55.0, 45.0, 45.0, null, null, 41.0, 22.0, 42.0, 29.0, null, 0.92, 20.0, 27.0, 24.0, 32.5, null, null, 28.0, 19.0, 21.0, 36.5, 21.0, 29.0, 1.0, 30.0, null, null, null, null, 17.0, 46.0, null, 26.0, null, null, 20.0, 28.0, 40.0, 30.0, 22.0, 23.0, 0.75, null, 9.0, 2.0, 36.0, null, 24.0, null, null, null, 30.0, null, 53.0, 36.0, 26.0, 1.0, null, 30.0, 29.0, 32.0, null, 43.0, 24.0, null, 64.0, 30.0, 0.83, 55.0, 45.0, 18.0, 22.0, null, 37.0, 55.0, 17.0, 57.0, 19.0, 27.0, 22.0, 26.0, 25.0, 26.0, 33.0, 39.0, 23.0, 12.0, 46.0, 29.0, 21.0, 48.0, 39.0, null, 19.0, 27.0, 30.0, 32.0, 39.0, 25.0, null, 18.0, 32.0, null, 58.0, null, 16.0, 26.0, 38.0, 24.0, 31.0, 45.0, 25.0, 18.0, 49.0, 0.17, 50.0, 59.0, null, null, 30.0, 14.5, 24.0, 31.0, 27.0, 25.0, null, null, 22.0, 45.0, 29.0, 21.0, 31.0, 49.0, 44.0, 54.0, 45.0, 22.0, 21.0, 55.0, 5.0, null, 26.0, null, 19.0, null, 24.0, 24.0, 57.0, 21.0, 6.0, 23.0, 51.0, 13.0, 47.0, 29.0, 18.0, 24.0, 48.0, 22.0, 31.0, 30.0, 38.0, 22.0, 17.0, 43.0, 20.0, 23.0, 50.0, null, 3.0, null, 37.0, 28.0, null, 39.0, 38.5, null, null], \"xaxis\": \"x2\", \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Distribution of Age with Histogram\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Distribution of Age with Density Plot\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.375, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 800, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"width\": 870, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Age</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.625, 1.0], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.375], \"title\": {\"text\": \"<b>Density(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('8d123699-c737-4034-a8f5-b695b74cdb50');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 44,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 23,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Calculate summary stats for Age\"\"\"\ncalculateSummaryStats(merged.Age)",
            "mc_idx": 45,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "summary": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    24,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "  summaryStats      Age\n0     skewness     0.41\n1        count  1046.00\n2         mean    29.88\n3          std    14.41\n4          min     0.17\n5          25%    21.00\n6          50%    28.00\n7          75%    39.00\n8          max    80.00"
                    ]
                },
                "mc_idx": 45,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 24,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"What does passengerId contain?\"\"\"\ndisplay(merged.PassengerId.head())",
            "mc_idx": 48,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    25,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0    1\n1    2\n2    3\n3    4\n4    5\nName: PassengerId, dtype: int64"
                    ]
                },
                "mc_idx": 48,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 25,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Let's preview the Cabin again.\"\"\"\nbold(\"Preview of Cabin:\")\ndisplay(merged.Cabin.head())",
            "mc_idx": 50,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 512,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    26,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "0     NaN\n1     C85\n2     NaN\n3    C123\n4     NaN\nName: Cabin, dtype: object"
                    ]
                },
                "mc_idx": 50,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 26,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"It seems Cabin contains some missing values. Let's count them.\"\"\"\nbold(\"Missing Values in Cabin:\")\ndisplay(merged.Cabin.isna().sum())",
            "mc_idx": 51,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "missing values": 2,
                    ".isna": 1,
                    ".sum": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    27,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "1014"
                    ]
                },
                "mc_idx": 51,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 27,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Total categories in Cabin before processing.\"\"\"\nbold(\"Total Categories in Cabin before Processing:\")\ndisplay(merged.Cabin.value_counts(dropna=False).count())",
            "mc_idx": 52,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    28,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "187"
                    ]
                },
                "mc_idx": 52,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 28,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Flag all the NaNs of Cabin as 'X'.\"\"\"\nnanReplaced= merged.Cabin.fillna(\"X\")",
            "mc_idx": 54,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".fillna(": 1,
                    ".fillna": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    29,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 54,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 29,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Extract only the 1st character from Cabin, which is only a Letter. And insert it to the dataframe.\"\"\"\nmerged[\"cabinProcessed\"] = nanReplaced.str.get(0) \nbold(\"Cabin Categories after Processing:\")\ndisplay(merged.cabinProcessed.value_counts())",
            "mc_idx": 55,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.5,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "extract": 1
                },
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    30,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "X    1014\nC      94\nB      65\nD      46\nE      41\nA      22\nF      21\nG       5\nT       1\nName: cabinProcessed, dtype: int64"
                    ]
                },
                "mc_idx": 55,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 30,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"After processing, we can visualize the absolute and relative frequency of newly transformed Cabin variable.\"\"\"\nplotFrequency(merged.cabinProcessed)",
            "mc_idx": 56,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "transform": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "visualize": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    31,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"52b98223-66a4-4b48-80de-e96d0937e4ef\" class=\"plotly-graph-div\" style=\"height:600px; width:970px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"52b98223-66a4-4b48-80de-e96d0937e4ef\")) {\n                    Plotly.newPlot(\n                        '52b98223-66a4-4b48-80de-e96d0937e4ef',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [1014, 94, 65, 46, 41, 22, 21, 5, 1], \"colorscale\": \"Rainbow\"}, \"name\": \"Abs Freq\", \"orientation\": \"h\", \"text\": [1014.0, 94.0, 65.0, 46.0, 41.0, 22.0, 21.0, 5.0, 1.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"c273f4e3-c958-490e-9498-f77c6220cce4\", \"x\": [1014, 94, 65, 46, 41, 22, 21, 5, 1], \"xaxis\": \"x\", \"y\": [\"X\", \"C\", \"B\", \"D\", \"E\", \"A\", \"F\", \"G\", \"T\"], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [77.46, 7.18, 4.97, 3.51, 3.13, 1.68, 1.6, 0.38, 0.08], \"colorscale\": \"Rainbow\"}, \"name\": \"Rel Freq(%)\", \"orientation\": \"h\", \"text\": [77.46, 7.18, 4.97, 3.51, 3.13, 1.68, 1.6, 0.38, 0.08], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"bae2ddb6-ab9e-475b-8d68-a093308cf0dc\", \"x\": [77.46, 7.18, 4.97, 3.51, 3.13, 1.68, 1.6, 0.38, 0.08], \"xaxis\": \"x2\", \"y\": [\"X\", \"C\", \"B\", \"D\", \"E\", \"A\", \"F\", \"G\", \"T\"], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Frequency\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Relative Frequency\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Absolute and Relative Frequency of cabinProcessed\"}, \"width\": 970, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"<b>Abs Freq</b>\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"<b>Rel Freq(%)</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>cabinProcessed</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('52b98223-66a4-4b48-80de-e96d0937e4ef');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 56,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 31,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Lets see what's inside the Name.\"\"\"\ndisplay(merged.Name.head(8))",
            "mc_idx": 58,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    32,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0                              Braund, Mr. Owen Harris\n1    Cumings, Mrs. John Bradley (Florence Briggs Th...\n2                               Heikkinen, Miss. Laina\n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)\n4                             Allen, Mr. William Henry\n5                                     Moran, Mr. James\n6                              McCarthy, Mr. Timothy J\n7                       Palsson, Master. Gosta Leonard\nName: Name, dtype: object"
                    ]
                },
                "mc_idx": 58,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 32,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Extract those firstName from Name.\"\"\"\nfirstName = merged.Name.str.split(\".\").str.get(0).str.split(\",\").str.get(-1)",
            "mc_idx": 60,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.5,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "extract": 1
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".split": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    33,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 60,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 33,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Count the extracted categories of firstName from Name.\"\"\"\ndisplay(firstName.value_counts())",
            "mc_idx": 61,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.5,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "extract": 1
                },
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    34,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        " Mr              757\n Miss            260\n Mrs             197\n Master           61\n Rev               8\n Dr                8\n Col               4\n Ms                2\n Mlle              2\n Major             2\n Mme               1\n Dona              1\n Sir               1\n Capt              1\n Don               1\n Jonkheer          1\n the Countess      1\n Lady              1\nName: Name, dtype: int64"
                    ]
                },
                "mc_idx": 61,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 34,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Create a bucket Officer and put Dr, Rev, Col, Major, Capt titles into it.\"\"\"\nfirstName.replace(to_replace = [\"Dr\", \"Rev\", \"Col\", \"Major\", \"Capt\"], value = \"Officer\", inplace = True,regex=True)\n\n\"\"\"Put Dona, Jonkheer, Countess, Sir, Lady, Don in bucket Aristocrat.\"\"\"\nfirstName.replace(to_replace = [\"Dona\", \"Jonkheer\", \"Countess\", \"Sir\", \"Lady\", \"Don\"], value = \"Aristocrat\", inplace = True,regex=True)\n\n\"\"\"Finally Replace Mlle and Ms with Miss. And Mme with Mrs.\"\"\"\nfirstName.replace({\"Mlle\":\"Miss\", \"Ms\":\"Miss\", \"Mme\":\"Mrs\"}, inplace = True,regex=True)\n\n\"\"\"Replace the Aristocrat with Aristocrat\"\"\"\nfirstName.replace({\"the Aristocrat\":\"Aristocrat\"}, inplace = True,regex=True)\n\n\"\"\"Insert a column named 'nameProcessed'.\"\"\"\nmerged[\"nameProcessed\"] = firstName",
            "mc_idx": 63,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".replace(": 4,
                    ".replace": 4
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    35,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 63,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 35,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"let's see how nameProcessed looks now\"\"\"\ndisplay(merged.nameProcessed.value_counts())",
            "mc_idx": 64,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    36,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        " Mr            757\n Miss          264\n Mrs           198\n Master         61\n Officer        23\n Aristocrat      6\nName: nameProcessed, dtype: int64"
                    ]
                },
                "mc_idx": 64,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 36,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"After processing, visualise and count absolute and relative frequency of transformed Name.\"\"\"\nplotFrequency(merged.nameProcessed)",
            "mc_idx": 65,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "transform": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    37,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"930836e9-5861-4af1-977d-5ed235492dfa\" class=\"plotly-graph-div\" style=\"height:600px; width:970px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"930836e9-5861-4af1-977d-5ed235492dfa\")) {\n                    Plotly.newPlot(\n                        '930836e9-5861-4af1-977d-5ed235492dfa',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [757, 264, 198, 61, 23, 6], \"colorscale\": \"Rainbow\"}, \"name\": \"Abs Freq\", \"orientation\": \"h\", \"text\": [757.0, 264.0, 198.0, 61.0, 23.0, 6.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"c2fc1bbf-bea3-4023-9ffb-56de810bbbe3\", \"x\": [757, 264, 198, 61, 23, 6], \"xaxis\": \"x\", \"y\": [\" Mr\", \" Miss\", \" Mrs\", \" Master\", \" Officer\", \" Aristocrat\"], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [57.83, 20.17, 15.13, 4.66, 1.76, 0.46], \"colorscale\": \"Rainbow\"}, \"name\": \"Rel Freq(%)\", \"orientation\": \"h\", \"text\": [57.83, 20.17, 15.13, 4.66, 1.76, 0.46], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"01afd530-b751-4f05-9ddd-26b63d510cb0\", \"x\": [57.83, 20.17, 15.13, 4.66, 1.76, 0.46], \"xaxis\": \"x2\", \"y\": [\" Mr\", \" Miss\", \" Mrs\", \" Master\", \" Officer\", \" Aristocrat\"], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Frequency\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Relative Frequency\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Absolute and Relative Frequency of nameProcessed\"}, \"width\": 970, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"<b>Abs Freq</b>\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"<b>Rel Freq(%)</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>nameProcessed</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('930836e9-5861-4af1-977d-5ed235492dfa');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 65,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 37,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Merge SibSp and Parch to create a variable Family_size.\"\"\"\nmerged[\"familySize\"] = merged.SibSp + merged.Parch + 1  # Adding 1 for single person\nbold(\"Categoiries in Family_size:\")\ndisplay(merged.familySize.value_counts())",
            "mc_idx": 67,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.16666666666666666,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    "size": 4,
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    38,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "1     790\n2     235\n3     159\n4      43\n6      25\n5      22\n7      16\n11     11\n8       8\nName: familySize, dtype: int64"
                    ]
                },
                "mc_idx": 67,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 38,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Create buckets of single, small, medium, and large and then put respective values into them.\"\"\"\nmerged.familySize.replace(to_replace = [1], value = \"single\", inplace = True)\nmerged.familySize.replace(to_replace = [2,3], value = \"small\", inplace = True)\nmerged.familySize.replace(to_replace = [4,5], value = \"medium\", inplace = True)\nmerged.familySize.replace(to_replace = [6, 7, 8, 11], value = \"large\", inplace = True)",
            "mc_idx": 69,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 4
                },
                "Data_Transform": {
                    ".replace(": 4,
                    ".replace": 4
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    39,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 69,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 39,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"After processing, visualise and count the absolute and relative frequency of engineered familySize.\"\"\"\nplotFrequency(merged.familySize)",
            "mc_idx": 70,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    40,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"49b8be5f-6979-4bbb-9c51-e7fa031f6384\" class=\"plotly-graph-div\" style=\"height:600px; width:970px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"49b8be5f-6979-4bbb-9c51-e7fa031f6384\")) {\n                    Plotly.newPlot(\n                        '49b8be5f-6979-4bbb-9c51-e7fa031f6384',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [790, 394, 65, 60], \"colorscale\": \"Rainbow\"}, \"name\": \"Abs Freq\", \"orientation\": \"h\", \"text\": [790.0, 394.0, 65.0, 60.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"05eec60b-91ef-4243-9b52-4df0a35ac494\", \"x\": [790, 394, 65, 60], \"xaxis\": \"x\", \"y\": [\"single\", \"small\", \"medium\", \"large\"], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [60.35, 30.1, 4.97, 4.58], \"colorscale\": \"Rainbow\"}, \"name\": \"Rel Freq(%)\", \"orientation\": \"h\", \"text\": [60.35, 30.1, 4.97, 4.58], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"bbaa75cb-fa6e-480f-bece-2d9c08201de6\", \"x\": [60.35, 30.1, 4.97, 4.58], \"xaxis\": \"x2\", \"y\": [\"single\", \"small\", \"medium\", \"large\"], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Frequency\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Relative Frequency\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Absolute and Relative Frequency of familySize\"}, \"width\": 970, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"<b>Abs Freq</b>\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"<b>Rel Freq(%)</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>familySize</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('49b8be5f-6979-4bbb-9c51-e7fa031f6384');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 70,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 40,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Let's preview the variable Ticket first.\"\"\"\ndisplay(merged.Ticket.head())",
            "mc_idx": 72,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.3333333333333333,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    41,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0           A/5 21171\n1            PC 17599\n2    STON/O2. 3101282\n3              113803\n4              373450\nName: Ticket, dtype: object"
                    ]
                },
                "mc_idx": 72,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 41,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Assign 'N' if there is only digits in Ticket. Otherwise just get the 1st character from Ticket.\"\"\"\notherwise = merged.Ticket.str.split(\" \").str.get(0).str.get(0) # This extracts the 1st character\nmerged[\"ticketProcessed\"] = np.where(merged.Ticket.str.isdigit(), \"N\", otherwise)",
            "mc_idx": 74,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "extract": 1
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".split": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    42,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 74,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 42,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Now calculate the categories in the ticketProcessed column.\"\"\"\nbold(\"Ticket after Processing:\")\ndisplay(merged.ticketProcessed.value_counts())",
            "mc_idx": 75,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "value_counts()": 1,
                    ".value_counts": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    43,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "N    957\nS     98\nP     98\nC     77\nA     42\nW     19\nF     13\nL      5\nName: ticketProcessed, dtype: int64"
                    ]
                },
                "mc_idx": 75,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 43,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"After processing, visualise and count the absolute and relative frequency of updated Ticket.\"\"\"\nplotFrequency(merged.ticketProcessed)",
            "mc_idx": 76,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    44,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"386e07d4-b21c-47f1-b6f5-a46ff52ab65d\" class=\"plotly-graph-div\" style=\"height:600px; width:970px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"386e07d4-b21c-47f1-b6f5-a46ff52ab65d\")) {\n                    Plotly.newPlot(\n                        '386e07d4-b21c-47f1-b6f5-a46ff52ab65d',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [957, 98, 98, 77, 42, 19, 13, 5], \"colorscale\": \"Rainbow\"}, \"name\": \"Abs Freq\", \"orientation\": \"h\", \"text\": [957.0, 98.0, 98.0, 77.0, 42.0, 19.0, 13.0, 5.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"24129760-0eed-420e-b807-87af3a9e248e\", \"x\": [957, 98, 98, 77, 42, 19, 13, 5], \"xaxis\": \"x\", \"y\": [\"N\", \"S\", \"P\", \"C\", \"A\", \"W\", \"F\", \"L\"], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [73.11, 7.49, 7.49, 5.88, 3.21, 1.45, 0.99, 0.38], \"colorscale\": \"Rainbow\"}, \"name\": \"Rel Freq(%)\", \"orientation\": \"h\", \"text\": [73.11, 7.49, 7.49, 5.88, 3.21, 1.45, 0.99, 0.38], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"94d2c23b-b9c7-47d9-94ff-21063a0600f7\", \"x\": [73.11, 7.49, 7.49, 5.88, 3.21, 1.45, 0.99, 0.38], \"xaxis\": \"x2\", \"y\": [\"N\", \"S\", \"P\", \"C\", \"A\", \"W\", \"F\", \"L\"], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Frequency\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Relative Frequency\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Absolute and Relative Frequency of ticketProcessed\"}, \"width\": 970, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"<b>Abs Freq</b>\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"<b>Rel Freq(%)</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>ticketProcessed</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('386e07d4-b21c-47f1-b6f5-a46ff52ab65d');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 76,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 44,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"#1.Create a function that removes outliers\"\"\"\ndef removeOutliers(variable):\n    \"\"\"Calculates and removes outliers using IQR method.\"\"\"\n    \n    # Calculate 1st, 3rd quartiles and iqr.\n    q1, q3 = variable.quantile(0.25), variable.quantile(0.75)\n    iqr = q3 - q1\n    \n    # Calculate lower fence and upper fence for outliers\n    lowerFence, upperFence = q1-1.5*iqr, q3+1.5*iqr   # Any values less than l_fence and greater than u_fence are outliers.\n    \n    # Observations that are outliers\n    outliers = variable[(variable<lowerFence) | (variable>upperFence)]\n    \n    # Drop obsevations that are outliers\n    filtered = variable.drop(outliers.index, axis = 0).reset_index(drop=True)\n    return filtered\n\n\n\"\"\"#2.Create another function to plot boxplot with and without outliers.\"\"\"\ndef plotBoxPlot(variable,filteredVariable):\n    \"\"\"Plots Box plot of a variable with and without outliers.\n    We will also use the output of removeOutliers function as the input to this function.\n    variable = variable with outliers,\n    filteredVariable = variable without outliers\"\"\"\n    \n    # Create subplot object.\n    fig = make_subplots(\n        rows=2,\n        cols=1,\n        print_grid=False,\n    subplot_titles=(f\"{variable.name} Distribution with Outliers\", f\"{variable.name} Distribution without Outliers\"))\n    \n    # This trace plots boxplot with outliers\n    fig.add_trace(\n        go.Box(\n            x = variable,\n            name = \"\", # This removes trace 0\n            marker = dict(color=\"darkred\")\n        ),\n    row=1,col=1)\n    \n    # This trace plots boxplot without outliers\n    fig.add_trace(\n        go.Box(\n            x = filteredVariable,\n            name = \"\",\n            marker = dict(color=\"green\")\n        ),\n    row=2,col=1)\n    \n    # Update layout\n    fig.layout.update(\n        height=800, \n        width=870,\n        showlegend=False,\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n    \n    # Update axes\n    fig.layout.xaxis2.update(title=f\"<b>{variable.name}</b>\")\n    return fig.show()",
            "mc_idx": 78,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.9,
                "Data_Transform": 0.35,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1,
                    "variable": 19
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "outliers": 18
                },
                "Data_Transform": {
                    "tile": 3,
                    ".drop": 1,
                    ".reset_index": 1,
                    ".add": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    45,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 78,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 45,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Plot Age with and without outliers.\"\"\"\nplotBoxPlot(merged.Age,removeOutliers(merged.Age))",
            "mc_idx": 80,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "outliers": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    46,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"8a11c18b-590e-4973-97f9-e610444d56f6\" class=\"plotly-graph-div\" style=\"height:800px; width:870px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"8a11c18b-590e-4973-97f9-e610444d56f6\")) {\n                    Plotly.newPlot(\n                        '8a11c18b-590e-4973-97f9-e610444d56f6',\n                        [{\"marker\": {\"color\": \"darkred\"}, \"name\": \"\", \"type\": \"box\", \"uid\": \"18242ecd-6e17-4fcb-9075-a13da278033c\", \"x\": [22.0, 38.0, 26.0, 35.0, 35.0, null, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, null, 31.0, null, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, null, 19.0, null, null, 40.0, null, null, 66.0, 28.0, 42.0, null, 21.0, 18.0, 14.0, 40.0, 27.0, null, 3.0, 19.0, null, null, null, null, 18.0, 7.0, 21.0, 49.0, 29.0, 65.0, null, 21.0, 28.5, 5.0, 11.0, 22.0, 38.0, 45.0, 4.0, null, null, 29.0, 19.0, 17.0, 26.0, 32.0, 16.0, 21.0, 26.0, 32.0, 25.0, null, null, 0.83, 30.0, 22.0, 29.0, null, 28.0, 17.0, 33.0, 16.0, null, 23.0, 24.0, 29.0, 20.0, 46.0, 26.0, 59.0, null, 71.0, 23.0, 34.0, 34.0, 28.0, null, 21.0, 33.0, 37.0, 28.0, 21.0, null, 38.0, null, 47.0, 14.5, 22.0, 20.0, 17.0, 21.0, 70.5, 29.0, 24.0, 2.0, 21.0, null, 32.5, 32.5, 54.0, 12.0, null, 24.0, null, 45.0, 33.0, 20.0, 47.0, 29.0, 25.0, 23.0, 19.0, 37.0, 16.0, 24.0, null, 22.0, 24.0, 19.0, 18.0, 19.0, 27.0, 9.0, 36.5, 42.0, 51.0, 22.0, 55.5, 40.5, null, 51.0, 16.0, 30.0, null, null, 44.0, 40.0, 26.0, 17.0, 1.0, 9.0, null, 45.0, null, 28.0, 61.0, 4.0, 1.0, 21.0, 56.0, 18.0, null, 50.0, 30.0, 36.0, null, null, 9.0, 1.0, 4.0, null, null, 45.0, 40.0, 36.0, 32.0, 19.0, 19.0, 3.0, 44.0, 58.0, null, 42.0, null, 24.0, 28.0, null, 34.0, 45.5, 18.0, 2.0, 32.0, 26.0, 16.0, 40.0, 24.0, 35.0, 22.0, 30.0, null, 31.0, 27.0, 42.0, 32.0, 30.0, 16.0, 27.0, 51.0, null, 38.0, 22.0, 19.0, 20.5, 18.0, null, 35.0, 29.0, 59.0, 5.0, 24.0, null, 44.0, 8.0, 19.0, 33.0, null, null, 29.0, 22.0, 30.0, 44.0, 25.0, 24.0, 37.0, 54.0, null, 29.0, 62.0, 30.0, 41.0, 29.0, null, 30.0, 35.0, 50.0, null, 3.0, 52.0, 40.0, null, 36.0, 16.0, 25.0, 58.0, 35.0, null, 25.0, 41.0, 37.0, null, 63.0, 45.0, null, 7.0, 35.0, 65.0, 28.0, 16.0, 19.0, null, 33.0, 30.0, 22.0, 42.0, 22.0, 26.0, 19.0, 36.0, 24.0, 24.0, null, 23.5, 2.0, null, 50.0, null, null, 19.0, null, null, 0.92, null, 17.0, 30.0, 30.0, 24.0, 18.0, 26.0, 28.0, 43.0, 26.0, 24.0, 54.0, 31.0, 40.0, 22.0, 27.0, 30.0, 22.0, null, 36.0, 61.0, 36.0, 31.0, 16.0, null, 45.5, 38.0, 16.0, null, null, 29.0, 41.0, 45.0, 45.0, 2.0, 24.0, 28.0, 25.0, 36.0, 24.0, 40.0, null, 3.0, 42.0, 23.0, null, 15.0, 25.0, null, 28.0, 22.0, 38.0, null, null, 40.0, 29.0, 45.0, 35.0, null, 30.0, 60.0, null, null, 24.0, 25.0, 18.0, 19.0, 22.0, 3.0, null, 22.0, 27.0, 20.0, 19.0, 42.0, 1.0, 32.0, 35.0, null, 18.0, 1.0, 36.0, null, 17.0, 36.0, 21.0, 28.0, 23.0, 24.0, 22.0, 31.0, 46.0, 23.0, 28.0, 39.0, 26.0, 21.0, 28.0, 20.0, 34.0, 51.0, 3.0, 21.0, null, null, null, 33.0, null, 44.0, null, 34.0, 18.0, 30.0, 10.0, null, 21.0, 29.0, 28.0, 18.0, null, 28.0, 19.0, null, 32.0, 28.0, null, 42.0, 17.0, 50.0, 14.0, 21.0, 24.0, 64.0, 31.0, 45.0, 20.0, 25.0, 28.0, null, 4.0, 13.0, 34.0, 5.0, 52.0, 36.0, null, 30.0, 49.0, null, 29.0, 65.0, null, 50.0, null, 48.0, 34.0, 47.0, 48.0, null, 38.0, null, 56.0, null, 0.75, null, 38.0, 33.0, 23.0, 22.0, null, 34.0, 29.0, 22.0, 2.0, 9.0, null, 50.0, 63.0, 25.0, null, 35.0, 58.0, 30.0, 9.0, null, 21.0, 55.0, 71.0, 21.0, null, 54.0, null, 25.0, 24.0, 17.0, 21.0, null, 37.0, 16.0, 18.0, 33.0, null, 28.0, 26.0, 29.0, null, 36.0, 54.0, 24.0, 47.0, 34.0, null, 36.0, 32.0, 30.0, 22.0, null, 44.0, null, 40.5, 50.0, null, 39.0, 23.0, 2.0, null, 17.0, null, 30.0, 7.0, 45.0, 30.0, null, 22.0, 36.0, 9.0, 11.0, 32.0, 50.0, 64.0, 19.0, null, 33.0, 8.0, 17.0, 27.0, null, 22.0, 22.0, 62.0, 48.0, null, 39.0, 36.0, null, 40.0, 28.0, null, null, 24.0, 19.0, 29.0, null, 32.0, 62.0, 53.0, 36.0, null, 16.0, 19.0, 34.0, 39.0, null, 32.0, 25.0, 39.0, 54.0, 36.0, null, 18.0, 47.0, 60.0, 22.0, null, 35.0, 52.0, 47.0, null, 37.0, 36.0, null, 49.0, null, 49.0, 24.0, null, null, 44.0, 35.0, 36.0, 30.0, 27.0, 22.0, 40.0, 39.0, null, null, null, 35.0, 24.0, 34.0, 26.0, 4.0, 26.0, 27.0, 42.0, 20.0, 21.0, 21.0, 61.0, 57.0, 21.0, 26.0, null, 80.0, 51.0, 32.0, null, 9.0, 28.0, 32.0, 31.0, 41.0, null, 20.0, 24.0, 2.0, null, 0.75, 48.0, 19.0, 56.0, null, 23.0, null, 18.0, 21.0, null, 18.0, 24.0, null, 32.0, 23.0, 58.0, 50.0, 40.0, 47.0, 36.0, 20.0, 32.0, 25.0, null, 43.0, null, 40.0, 31.0, 70.0, 31.0, null, 18.0, 24.5, 18.0, 43.0, 36.0, null, 27.0, 20.0, 14.0, 60.0, 25.0, 14.0, 19.0, 18.0, 15.0, 31.0, 4.0, null, 25.0, 60.0, 52.0, 44.0, null, 49.0, 42.0, 18.0, 35.0, 18.0, 25.0, 26.0, 39.0, 45.0, 42.0, 22.0, null, 24.0, null, 48.0, 29.0, 52.0, 19.0, 38.0, 27.0, null, 33.0, 6.0, 17.0, 34.0, 50.0, 27.0, 20.0, 30.0, null, 25.0, 25.0, 29.0, 11.0, null, 23.0, 23.0, 28.5, 48.0, 35.0, null, null, null, 36.0, 21.0, 24.0, 31.0, 70.0, 16.0, 30.0, 19.0, 31.0, 4.0, 6.0, 33.0, 23.0, 48.0, 0.67, 28.0, 18.0, 34.0, 33.0, null, 41.0, 20.0, 36.0, 16.0, 51.0, null, 30.5, null, 32.0, 24.0, 48.0, 57.0, null, 54.0, 18.0, null, 5.0, null, 43.0, 13.0, 17.0, 29.0, null, 25.0, 25.0, 18.0, 8.0, 1.0, 46.0, null, 16.0, null, null, 25.0, 39.0, 49.0, 31.0, 30.0, 30.0, 34.0, 31.0, 11.0, 0.42, 27.0, 31.0, 39.0, 18.0, 39.0, 33.0, 26.0, 39.0, 35.0, 6.0, 30.5, null, 23.0, 31.0, 43.0, 10.0, 52.0, 27.0, 38.0, 27.0, 2.0, null, null, 1.0, null, 62.0, 15.0, 0.83, null, 23.0, 18.0, 39.0, 21.0, null, 32.0, null, 20.0, 16.0, 30.0, 34.5, 17.0, 42.0, null, 35.0, 28.0, null, 4.0, 74.0, 9.0, 16.0, 44.0, 18.0, 45.0, 51.0, 24.0, null, 41.0, 21.0, 48.0, null, 24.0, 42.0, 27.0, 31.0, null, 4.0, 26.0, 47.0, 33.0, 47.0, 28.0, 15.0, 20.0, 19.0, null, 56.0, 25.0, 33.0, 22.0, 28.0, 25.0, 39.0, 27.0, 19.0, null, 26.0, 32.0, 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0, null, 46.0, 23.0, 63.0, 47.0, 24.0, 35.0, 21.0, 27.0, 45.0, 55.0, 9.0, null, 21.0, 48.0, 50.0, 22.0, 22.5, 41.0, null, 50.0, 24.0, 33.0, null, 30.0, 18.5, null, 21.0, 25.0, null, 39.0, null, 41.0, 30.0, 45.0, 25.0, 45.0, null, 60.0, 36.0, 24.0, 27.0, 20.0, 28.0, null, 10.0, 35.0, 25.0, null, 36.0, 17.0, 32.0, 18.0, 22.0, 13.0, null, 18.0, 47.0, 31.0, 60.0, 24.0, 21.0, 29.0, 28.5, 35.0, 32.5, null, 55.0, 30.0, 24.0, 6.0, 67.0, 49.0, null, null, null, 27.0, 18.0, null, 2.0, 22.0, null, 27.0, null, 25.0, 25.0, 76.0, 29.0, 20.0, 33.0, 43.0, 27.0, null, 26.0, 16.0, 28.0, 21.0, null, null, 18.5, 41.0, null, 36.0, 18.5, 63.0, 18.0, null, 1.0, 36.0, 29.0, 12.0, null, 35.0, 28.0, null, 17.0, 22.0, null, 42.0, 24.0, 32.0, 53.0, null, null, 43.0, 24.0, 26.5, 26.0, 23.0, 40.0, 10.0, 33.0, 61.0, 28.0, 42.0, 31.0, null, 22.0, null, 30.0, 23.0, null, 60.5, 36.0, 13.0, 24.0, 29.0, 23.0, 42.0, 26.0, null, 7.0, 26.0, null, 41.0, 26.0, 48.0, 18.0, null, 22.0, null, 27.0, 23.0, null, 40.0, 15.0, 20.0, 54.0, 36.0, 64.0, 30.0, 37.0, 18.0, null, 27.0, 40.0, 21.0, 17.0, null, 40.0, 34.0, null, 11.5, 61.0, 8.0, 33.0, 6.0, 18.0, 23.0, null, null, 0.33, 47.0, 8.0, 25.0, null, 35.0, 24.0, 33.0, 25.0, 32.0, null, 17.0, 60.0, 38.0, 42.0, null, 57.0, 50.0, null, 30.0, 21.0, 22.0, 21.0, 53.0, null, 23.0, null, 40.5, 36.0, 14.0, 21.0, 21.0, null, 39.0, 20.0, 64.0, 20.0, 18.0, 48.0, 55.0, 45.0, 45.0, null, null, 41.0, 22.0, 42.0, 29.0, null, 0.92, 20.0, 27.0, 24.0, 32.5, null, null, 28.0, 19.0, 21.0, 36.5, 21.0, 29.0, 1.0, 30.0, null, null, null, null, 17.0, 46.0, null, 26.0, null, null, 20.0, 28.0, 40.0, 30.0, 22.0, 23.0, 0.75, null, 9.0, 2.0, 36.0, null, 24.0, null, null, null, 30.0, null, 53.0, 36.0, 26.0, 1.0, null, 30.0, 29.0, 32.0, null, 43.0, 24.0, null, 64.0, 30.0, 0.83, 55.0, 45.0, 18.0, 22.0, null, 37.0, 55.0, 17.0, 57.0, 19.0, 27.0, 22.0, 26.0, 25.0, 26.0, 33.0, 39.0, 23.0, 12.0, 46.0, 29.0, 21.0, 48.0, 39.0, null, 19.0, 27.0, 30.0, 32.0, 39.0, 25.0, null, 18.0, 32.0, null, 58.0, null, 16.0, 26.0, 38.0, 24.0, 31.0, 45.0, 25.0, 18.0, 49.0, 0.17, 50.0, 59.0, null, null, 30.0, 14.5, 24.0, 31.0, 27.0, 25.0, null, null, 22.0, 45.0, 29.0, 21.0, 31.0, 49.0, 44.0, 54.0, 45.0, 22.0, 21.0, 55.0, 5.0, null, 26.0, null, 19.0, null, 24.0, 24.0, 57.0, 21.0, 6.0, 23.0, 51.0, 13.0, 47.0, 29.0, 18.0, 24.0, 48.0, 22.0, 31.0, 30.0, 38.0, 22.0, 17.0, 43.0, 20.0, 23.0, 50.0, null, 3.0, null, 37.0, 28.0, null, 39.0, 38.5, null, null], \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"green\"}, \"name\": \"\", \"type\": \"box\", \"uid\": \"3bc58a27-f100-4d1c-aa35-b35a57715c37\", \"x\": [22.0, 38.0, 26.0, 35.0, 35.0, null, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, null, 31.0, null, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, null, 19.0, null, null, 40.0, null, null, 66.0, 28.0, 42.0, null, 21.0, 18.0, 14.0, 40.0, 27.0, null, 3.0, 19.0, null, null, null, null, 18.0, 7.0, 21.0, 49.0, 29.0, 65.0, null, 21.0, 28.5, 5.0, 11.0, 22.0, 38.0, 45.0, 4.0, null, null, 29.0, 19.0, 17.0, 26.0, 32.0, 16.0, 21.0, 26.0, 32.0, 25.0, null, null, 0.83, 30.0, 22.0, 29.0, null, 28.0, 17.0, 33.0, 16.0, null, 23.0, 24.0, 29.0, 20.0, 46.0, 26.0, 59.0, null, 23.0, 34.0, 34.0, 28.0, null, 21.0, 33.0, 37.0, 28.0, 21.0, null, 38.0, null, 47.0, 14.5, 22.0, 20.0, 17.0, 21.0, 29.0, 24.0, 2.0, 21.0, null, 32.5, 32.5, 54.0, 12.0, null, 24.0, null, 45.0, 33.0, 20.0, 47.0, 29.0, 25.0, 23.0, 19.0, 37.0, 16.0, 24.0, null, 22.0, 24.0, 19.0, 18.0, 19.0, 27.0, 9.0, 36.5, 42.0, 51.0, 22.0, 55.5, 40.5, null, 51.0, 16.0, 30.0, null, null, 44.0, 40.0, 26.0, 17.0, 1.0, 9.0, null, 45.0, null, 28.0, 61.0, 4.0, 1.0, 21.0, 56.0, 18.0, null, 50.0, 30.0, 36.0, null, null, 9.0, 1.0, 4.0, null, null, 45.0, 40.0, 36.0, 32.0, 19.0, 19.0, 3.0, 44.0, 58.0, null, 42.0, null, 24.0, 28.0, null, 34.0, 45.5, 18.0, 2.0, 32.0, 26.0, 16.0, 40.0, 24.0, 35.0, 22.0, 30.0, null, 31.0, 27.0, 42.0, 32.0, 30.0, 16.0, 27.0, 51.0, null, 38.0, 22.0, 19.0, 20.5, 18.0, null, 35.0, 29.0, 59.0, 5.0, 24.0, null, 44.0, 8.0, 19.0, 33.0, null, null, 29.0, 22.0, 30.0, 44.0, 25.0, 24.0, 37.0, 54.0, null, 29.0, 62.0, 30.0, 41.0, 29.0, null, 30.0, 35.0, 50.0, null, 3.0, 52.0, 40.0, null, 36.0, 16.0, 25.0, 58.0, 35.0, null, 25.0, 41.0, 37.0, null, 63.0, 45.0, null, 7.0, 35.0, 65.0, 28.0, 16.0, 19.0, null, 33.0, 30.0, 22.0, 42.0, 22.0, 26.0, 19.0, 36.0, 24.0, 24.0, null, 23.5, 2.0, null, 50.0, null, null, 19.0, null, null, 0.92, null, 17.0, 30.0, 30.0, 24.0, 18.0, 26.0, 28.0, 43.0, 26.0, 24.0, 54.0, 31.0, 40.0, 22.0, 27.0, 30.0, 22.0, null, 36.0, 61.0, 36.0, 31.0, 16.0, null, 45.5, 38.0, 16.0, null, null, 29.0, 41.0, 45.0, 45.0, 2.0, 24.0, 28.0, 25.0, 36.0, 24.0, 40.0, null, 3.0, 42.0, 23.0, null, 15.0, 25.0, null, 28.0, 22.0, 38.0, null, null, 40.0, 29.0, 45.0, 35.0, null, 30.0, 60.0, null, null, 24.0, 25.0, 18.0, 19.0, 22.0, 3.0, null, 22.0, 27.0, 20.0, 19.0, 42.0, 1.0, 32.0, 35.0, null, 18.0, 1.0, 36.0, null, 17.0, 36.0, 21.0, 28.0, 23.0, 24.0, 22.0, 31.0, 46.0, 23.0, 28.0, 39.0, 26.0, 21.0, 28.0, 20.0, 34.0, 51.0, 3.0, 21.0, null, null, null, 33.0, null, 44.0, null, 34.0, 18.0, 30.0, 10.0, null, 21.0, 29.0, 28.0, 18.0, null, 28.0, 19.0, null, 32.0, 28.0, null, 42.0, 17.0, 50.0, 14.0, 21.0, 24.0, 64.0, 31.0, 45.0, 20.0, 25.0, 28.0, null, 4.0, 13.0, 34.0, 5.0, 52.0, 36.0, null, 30.0, 49.0, null, 29.0, 65.0, null, 50.0, null, 48.0, 34.0, 47.0, 48.0, null, 38.0, null, 56.0, null, 0.75, null, 38.0, 33.0, 23.0, 22.0, null, 34.0, 29.0, 22.0, 2.0, 9.0, null, 50.0, 63.0, 25.0, null, 35.0, 58.0, 30.0, 9.0, null, 21.0, 55.0, 21.0, null, 54.0, null, 25.0, 24.0, 17.0, 21.0, null, 37.0, 16.0, 18.0, 33.0, null, 28.0, 26.0, 29.0, null, 36.0, 54.0, 24.0, 47.0, 34.0, null, 36.0, 32.0, 30.0, 22.0, null, 44.0, null, 40.5, 50.0, null, 39.0, 23.0, 2.0, null, 17.0, null, 30.0, 7.0, 45.0, 30.0, null, 22.0, 36.0, 9.0, 11.0, 32.0, 50.0, 64.0, 19.0, null, 33.0, 8.0, 17.0, 27.0, null, 22.0, 22.0, 62.0, 48.0, null, 39.0, 36.0, null, 40.0, 28.0, null, null, 24.0, 19.0, 29.0, null, 32.0, 62.0, 53.0, 36.0, null, 16.0, 19.0, 34.0, 39.0, null, 32.0, 25.0, 39.0, 54.0, 36.0, null, 18.0, 47.0, 60.0, 22.0, null, 35.0, 52.0, 47.0, null, 37.0, 36.0, null, 49.0, null, 49.0, 24.0, null, null, 44.0, 35.0, 36.0, 30.0, 27.0, 22.0, 40.0, 39.0, null, null, null, 35.0, 24.0, 34.0, 26.0, 4.0, 26.0, 27.0, 42.0, 20.0, 21.0, 21.0, 61.0, 57.0, 21.0, 26.0, null, 51.0, 32.0, null, 9.0, 28.0, 32.0, 31.0, 41.0, null, 20.0, 24.0, 2.0, null, 0.75, 48.0, 19.0, 56.0, null, 23.0, null, 18.0, 21.0, null, 18.0, 24.0, null, 32.0, 23.0, 58.0, 50.0, 40.0, 47.0, 36.0, 20.0, 32.0, 25.0, null, 43.0, null, 40.0, 31.0, 31.0, null, 18.0, 24.5, 18.0, 43.0, 36.0, null, 27.0, 20.0, 14.0, 60.0, 25.0, 14.0, 19.0, 18.0, 15.0, 31.0, 4.0, null, 25.0, 60.0, 52.0, 44.0, null, 49.0, 42.0, 18.0, 35.0, 18.0, 25.0, 26.0, 39.0, 45.0, 42.0, 22.0, null, 24.0, null, 48.0, 29.0, 52.0, 19.0, 38.0, 27.0, null, 33.0, 6.0, 17.0, 34.0, 50.0, 27.0, 20.0, 30.0, null, 25.0, 25.0, 29.0, 11.0, null, 23.0, 23.0, 28.5, 48.0, 35.0, null, null, null, 36.0, 21.0, 24.0, 31.0, 16.0, 30.0, 19.0, 31.0, 4.0, 6.0, 33.0, 23.0, 48.0, 0.67, 28.0, 18.0, 34.0, 33.0, null, 41.0, 20.0, 36.0, 16.0, 51.0, null, 30.5, null, 32.0, 24.0, 48.0, 57.0, null, 54.0, 18.0, null, 5.0, null, 43.0, 13.0, 17.0, 29.0, null, 25.0, 25.0, 18.0, 8.0, 1.0, 46.0, null, 16.0, null, null, 25.0, 39.0, 49.0, 31.0, 30.0, 30.0, 34.0, 31.0, 11.0, 0.42, 27.0, 31.0, 39.0, 18.0, 39.0, 33.0, 26.0, 39.0, 35.0, 6.0, 30.5, null, 23.0, 31.0, 43.0, 10.0, 52.0, 27.0, 38.0, 27.0, 2.0, null, null, 1.0, null, 62.0, 15.0, 0.83, null, 23.0, 18.0, 39.0, 21.0, null, 32.0, null, 20.0, 16.0, 30.0, 34.5, 17.0, 42.0, null, 35.0, 28.0, null, 4.0, 9.0, 16.0, 44.0, 18.0, 45.0, 51.0, 24.0, null, 41.0, 21.0, 48.0, null, 24.0, 42.0, 27.0, 31.0, null, 4.0, 26.0, 47.0, 33.0, 47.0, 28.0, 15.0, 20.0, 19.0, null, 56.0, 25.0, 33.0, 22.0, 28.0, 25.0, 39.0, 27.0, 19.0, null, 26.0, 32.0, 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0, null, 46.0, 23.0, 63.0, 47.0, 24.0, 35.0, 21.0, 27.0, 45.0, 55.0, 9.0, null, 21.0, 48.0, 50.0, 22.0, 22.5, 41.0, null, 50.0, 24.0, 33.0, null, 30.0, 18.5, null, 21.0, 25.0, null, 39.0, null, 41.0, 30.0, 45.0, 25.0, 45.0, null, 60.0, 36.0, 24.0, 27.0, 20.0, 28.0, null, 10.0, 35.0, 25.0, null, 36.0, 17.0, 32.0, 18.0, 22.0, 13.0, null, 18.0, 47.0, 31.0, 60.0, 24.0, 21.0, 29.0, 28.5, 35.0, 32.5, null, 55.0, 30.0, 24.0, 6.0, 49.0, null, null, null, 27.0, 18.0, null, 2.0, 22.0, null, 27.0, null, 25.0, 25.0, 29.0, 20.0, 33.0, 43.0, 27.0, null, 26.0, 16.0, 28.0, 21.0, null, null, 18.5, 41.0, null, 36.0, 18.5, 63.0, 18.0, null, 1.0, 36.0, 29.0, 12.0, null, 35.0, 28.0, null, 17.0, 22.0, null, 42.0, 24.0, 32.0, 53.0, null, null, 43.0, 24.0, 26.5, 26.0, 23.0, 40.0, 10.0, 33.0, 61.0, 28.0, 42.0, 31.0, null, 22.0, null, 30.0, 23.0, null, 60.5, 36.0, 13.0, 24.0, 29.0, 23.0, 42.0, 26.0, null, 7.0, 26.0, null, 41.0, 26.0, 48.0, 18.0, null, 22.0, null, 27.0, 23.0, null, 40.0, 15.0, 20.0, 54.0, 36.0, 64.0, 30.0, 37.0, 18.0, null, 27.0, 40.0, 21.0, 17.0, null, 40.0, 34.0, null, 11.5, 61.0, 8.0, 33.0, 6.0, 18.0, 23.0, null, null, 0.33, 47.0, 8.0, 25.0, null, 35.0, 24.0, 33.0, 25.0, 32.0, null, 17.0, 60.0, 38.0, 42.0, null, 57.0, 50.0, null, 30.0, 21.0, 22.0, 21.0, 53.0, null, 23.0, null, 40.5, 36.0, 14.0, 21.0, 21.0, null, 39.0, 20.0, 64.0, 20.0, 18.0, 48.0, 55.0, 45.0, 45.0, null, null, 41.0, 22.0, 42.0, 29.0, null, 0.92, 20.0, 27.0, 24.0, 32.5, null, null, 28.0, 19.0, 21.0, 36.5, 21.0, 29.0, 1.0, 30.0, null, null, null, null, 17.0, 46.0, null, 26.0, null, null, 20.0, 28.0, 40.0, 30.0, 22.0, 23.0, 0.75, null, 9.0, 2.0, 36.0, null, 24.0, null, null, null, 30.0, null, 53.0, 36.0, 26.0, 1.0, null, 30.0, 29.0, 32.0, null, 43.0, 24.0, null, 64.0, 30.0, 0.83, 55.0, 45.0, 18.0, 22.0, null, 37.0, 55.0, 17.0, 57.0, 19.0, 27.0, 22.0, 26.0, 25.0, 26.0, 33.0, 39.0, 23.0, 12.0, 46.0, 29.0, 21.0, 48.0, 39.0, null, 19.0, 27.0, 30.0, 32.0, 39.0, 25.0, null, 18.0, 32.0, null, 58.0, null, 16.0, 26.0, 38.0, 24.0, 31.0, 45.0, 25.0, 18.0, 49.0, 0.17, 50.0, 59.0, null, null, 30.0, 14.5, 24.0, 31.0, 27.0, 25.0, null, null, 22.0, 45.0, 29.0, 21.0, 31.0, 49.0, 44.0, 54.0, 45.0, 22.0, 21.0, 55.0, 5.0, null, 26.0, null, 19.0, null, 24.0, 24.0, 57.0, 21.0, 6.0, 23.0, 51.0, 13.0, 47.0, 29.0, 18.0, 24.0, 48.0, 22.0, 31.0, 30.0, 38.0, 22.0, 17.0, 43.0, 20.0, 23.0, 50.0, null, 3.0, null, 37.0, 28.0, null, 39.0, 38.5, null, null], \"xaxis\": \"x2\", \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Age Distribution with Outliers\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Age Distribution without Outliers\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.375, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 800, \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"width\": 870, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Age</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.625, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.375]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('8a11c18b-590e-4973-97f9-e610444d56f6');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 80,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 46,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Plot Fare with and without outliers.\"\"\"\nplotBoxPlot(merged.Fare,removeOutliers(merged.Fare))",
            "mc_idx": 82,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "outliers": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    47,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"7b3f5f43-d255-42bb-9105-c1965d27cf25\" class=\"plotly-graph-div\" style=\"height:800px; width:870px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"7b3f5f43-d255-42bb-9105-c1965d27cf25\")) {\n                    Plotly.newPlot(\n                        '7b3f5f43-d255-42bb-9105-c1965d27cf25',\n                        [{\"marker\": {\"color\": \"darkred\"}, \"name\": \"\", \"type\": \"box\", \"uid\": \"ffc9a7ae-023e-48ff-bf45-58ffa82229a2\", \"x\": [7.25, 71.2833, 7.925, 53.1, 8.05, 8.4583, 51.8625, 21.075, 11.1333, 30.0708, 16.7, 26.55, 8.05, 31.275, 7.8542, 16.0, 29.125, 13.0, 18.0, 7.225, 26.0, 13.0, 8.0292, 35.5, 21.075, 31.3875, 7.225, 263.0, 7.8792, 7.8958, 27.7208, 146.5208, 7.75, 10.5, 82.1708, 52.0, 7.2292, 8.05, 18.0, 11.2417, 9.475, 21.0, 7.8958, 41.5792, 7.8792, 8.05, 15.5, 7.75, 21.6792, 17.8, 39.6875, 7.8, 76.7292, 26.0, 61.9792, 35.5, 10.5, 7.2292, 27.75, 46.9, 7.2292, 80.0, 83.475, 27.9, 27.7208, 15.2458, 10.5, 8.1583, 7.925, 8.6625, 10.5, 46.9, 73.5, 14.4542, 56.4958, 7.65, 7.8958, 8.05, 29.0, 12.475, 9.0, 9.5, 7.7875, 47.1, 10.5, 15.85, 34.375, 8.05, 263.0, 8.05, 8.05, 7.8542, 61.175, 20.575, 7.25, 8.05, 34.6542, 63.3583, 23.0, 26.0, 7.8958, 7.8958, 77.2875, 8.6542, 7.925, 7.8958, 7.65, 7.775, 7.8958, 24.15, 52.0, 14.4542, 8.05, 9.825, 14.4583, 7.925, 7.75, 21.0, 247.5208, 31.275, 73.5, 8.05, 30.0708, 13.0, 77.2875, 11.2417, 7.75, 7.1417, 22.3583, 6.975, 7.8958, 7.05, 14.5, 26.0, 13.0, 15.0458, 26.2833, 53.1, 9.2167, 79.2, 15.2458, 7.75, 15.85, 6.75, 11.5, 36.75, 7.7958, 34.375, 26.0, 13.0, 12.525, 66.6, 8.05, 14.5, 7.3125, 61.3792, 7.7333, 8.05, 8.6625, 69.55, 16.1, 15.75, 7.775, 8.6625, 39.6875, 20.525, 55.0, 27.9, 25.925, 56.4958, 33.5, 29.125, 11.1333, 7.925, 30.6958, 7.8542, 25.4667, 28.7125, 13.0, 0.0, 69.55, 15.05, 31.3875, 39.0, 22.025, 50.0, 15.5, 26.55, 15.5, 7.8958, 13.0, 13.0, 7.8542, 26.0, 27.7208, 146.5208, 7.75, 8.4042, 7.75, 13.0, 9.5, 69.55, 6.4958, 7.225, 8.05, 10.4625, 15.85, 18.7875, 7.75, 31.0, 7.05, 21.0, 7.25, 13.0, 7.75, 113.275, 7.925, 27.0, 76.2917, 10.5, 8.05, 13.0, 8.05, 7.8958, 90.0, 9.35, 10.5, 7.25, 13.0, 25.4667, 83.475, 7.775, 13.5, 31.3875, 10.5, 7.55, 26.0, 26.25, 10.5, 12.275, 14.4542, 15.5, 10.5, 7.125, 7.225, 90.0, 7.775, 14.5, 52.5542, 26.0, 7.25, 10.4625, 26.55, 16.1, 20.2125, 15.2458, 79.2, 86.5, 512.3292, 26.0, 7.75, 31.3875, 79.65, 0.0, 7.75, 10.5, 39.6875, 7.775, 153.4625, 135.6333, 31.0, 0.0, 19.5, 29.7, 7.75, 77.9583, 7.75, 0.0, 29.125, 20.25, 7.75, 7.8542, 9.5, 8.05, 26.0, 8.6625, 9.5, 7.8958, 13.0, 7.75, 78.85, 91.0792, 12.875, 8.85, 7.8958, 27.7208, 7.2292, 151.55, 30.5, 247.5208, 7.75, 23.25, 0.0, 12.35, 8.05, 151.55, 110.8833, 108.9, 24.0, 56.9292, 83.1583, 262.375, 26.0, 7.8958, 26.25, 7.8542, 26.0, 14.0, 164.8667, 134.5, 7.25, 7.8958, 12.35, 29.0, 69.55, 135.6333, 6.2375, 13.0, 20.525, 57.9792, 23.25, 28.5, 153.4625, 18.0, 133.65, 7.8958, 66.6, 134.5, 8.05, 35.5, 26.0, 263.0, 13.0, 13.0, 13.0, 13.0, 13.0, 16.1, 15.9, 8.6625, 9.225, 35.0, 7.2292, 17.8, 7.225, 9.5, 55.0, 13.0, 7.8792, 7.8792, 27.9, 27.7208, 14.4542, 7.05, 15.5, 7.25, 75.25, 7.2292, 7.75, 69.3, 55.4417, 6.4958, 8.05, 135.6333, 21.075, 82.1708, 7.25, 211.5, 4.0125, 7.775, 227.525, 15.7417, 7.925, 52.0, 7.8958, 73.5, 46.9, 13.0, 7.7292, 12.0, 120.0, 7.7958, 7.925, 113.275, 16.7, 7.7958, 7.8542, 26.0, 10.5, 12.65, 7.925, 8.05, 9.825, 15.85, 8.6625, 21.0, 7.75, 18.75, 7.775, 25.4667, 7.8958, 6.8583, 90.0, 0.0, 7.925, 8.05, 32.5, 13.0, 13.0, 24.15, 7.8958, 7.7333, 7.875, 14.4, 20.2125, 7.25, 26.0, 26.0, 7.75, 8.05, 26.55, 16.1, 26.0, 7.125, 55.9, 120.0, 34.375, 18.75, 263.0, 10.5, 26.25, 9.5, 7.775, 13.0, 8.1125, 81.8583, 19.5, 26.55, 19.2583, 30.5, 27.75, 19.9667, 27.75, 89.1042, 8.05, 7.8958, 26.55, 51.8625, 10.5, 7.75, 26.55, 8.05, 38.5, 13.0, 8.05, 7.05, 0.0, 26.55, 7.725, 19.2583, 7.25, 8.6625, 27.75, 13.7917, 9.8375, 52.0, 21.0, 7.0458, 7.5208, 12.2875, 46.9, 0.0, 8.05, 9.5875, 91.0792, 25.4667, 90.0, 29.7, 8.05, 15.9, 19.9667, 7.25, 30.5, 49.5042, 8.05, 14.4583, 78.2667, 15.1, 151.55, 7.7958, 8.6625, 7.75, 7.6292, 9.5875, 86.5, 108.9, 26.0, 26.55, 22.525, 56.4958, 7.75, 8.05, 26.2875, 59.4, 7.4958, 34.0208, 10.5, 24.15, 26.0, 7.8958, 93.5, 7.8958, 7.225, 57.9792, 7.2292, 7.75, 10.5, 221.7792, 7.925, 11.5, 26.0, 7.2292, 7.2292, 22.3583, 8.6625, 26.25, 26.55, 106.425, 14.5, 49.5, 71.0, 31.275, 31.275, 26.0, 106.425, 26.0, 26.0, 13.8625, 20.525, 36.75, 110.8833, 26.0, 7.8292, 7.225, 7.775, 26.55, 39.6, 227.525, 79.65, 17.4, 7.75, 7.8958, 13.5, 8.05, 8.05, 24.15, 7.8958, 21.075, 7.2292, 7.8542, 10.5, 51.4792, 26.3875, 7.75, 8.05, 14.5, 13.0, 55.9, 14.4583, 7.925, 30.0, 110.8833, 26.0, 40.125, 8.7125, 79.65, 15.0, 79.2, 8.05, 8.05, 7.125, 78.2667, 7.25, 7.75, 26.0, 24.15, 33.0, 0.0, 7.225, 56.9292, 27.0, 7.8958, 42.4, 8.05, 26.55, 15.55, 7.8958, 30.5, 41.5792, 153.4625, 31.275, 7.05, 15.5, 7.75, 8.05, 65.0, 14.4, 16.1, 39.0, 10.5, 14.4542, 52.5542, 15.7417, 7.8542, 16.1, 32.3208, 12.35, 77.9583, 7.8958, 7.7333, 30.0, 7.0542, 30.5, 0.0, 27.9, 13.0, 7.925, 26.25, 39.6875, 16.1, 7.8542, 69.3, 27.9, 56.4958, 19.2583, 76.7292, 7.8958, 35.5, 7.55, 7.55, 7.8958, 23.0, 8.4333, 7.8292, 6.75, 73.5, 7.8958, 15.5, 13.0, 113.275, 133.65, 7.225, 25.5875, 7.4958, 7.925, 73.5, 13.0, 7.775, 8.05, 52.0, 39.0, 52.0, 10.5, 13.0, 0.0, 7.775, 8.05, 9.8417, 46.9, 512.3292, 8.1375, 76.7292, 9.225, 46.9, 39.0, 41.5792, 39.6875, 10.1708, 7.7958, 211.3375, 57.0, 13.4167, 56.4958, 7.225, 26.55, 13.5, 8.05, 7.7333, 110.8833, 7.65, 227.525, 26.2875, 14.4542, 7.7417, 7.8542, 26.0, 13.5, 26.2875, 151.55, 15.2458, 49.5042, 26.55, 52.0, 9.4833, 13.0, 7.65, 227.525, 10.5, 15.5, 7.775, 33.0, 7.0542, 13.0, 13.0, 53.1, 8.6625, 21.0, 7.7375, 26.0, 7.925, 211.3375, 18.7875, 0.0, 13.0, 13.0, 16.1, 34.375, 512.3292, 7.8958, 7.8958, 30.0, 78.85, 262.375, 16.1, 7.925, 71.0, 20.25, 13.0, 53.1, 7.75, 23.0, 12.475, 9.5, 7.8958, 65.0, 14.5, 7.7958, 11.5, 8.05, 86.5, 14.5, 7.125, 7.2292, 120.0, 7.775, 77.9583, 39.6, 7.75, 24.15, 8.3625, 9.5, 7.8542, 10.5, 7.225, 23.0, 7.75, 7.75, 12.475, 7.7375, 211.3375, 7.2292, 57.0, 30.0, 23.45, 7.05, 7.25, 7.4958, 29.125, 20.575, 79.2, 7.75, 26.0, 69.55, 30.6958, 7.8958, 13.0, 25.9292, 8.6833, 7.2292, 24.15, 13.0, 26.25, 120.0, 8.5167, 6.975, 7.775, 0.0, 7.775, 13.0, 53.1, 7.8875, 24.15, 10.5, 31.275, 8.05, 0.0, 7.925, 37.0042, 6.45, 27.9, 93.5, 8.6625, 0.0, 12.475, 39.6875, 6.95, 56.4958, 37.0042, 7.75, 80.0, 14.4542, 18.75, 7.2292, 7.8542, 8.3, 83.1583, 8.6625, 8.05, 56.4958, 29.7, 7.925, 10.5, 31.0, 6.4375, 8.6625, 7.55, 69.55, 7.8958, 33.0, 89.1042, 31.275, 7.775, 15.2458, 39.4, 26.0, 9.35, 164.8667, 26.55, 19.2583, 7.2292, 14.1083, 11.5, 25.9292, 69.55, 13.0, 13.0, 13.8583, 50.4958, 9.5, 11.1333, 7.8958, 52.5542, 5.0, 9.0, 24.0, 7.225, 9.8458, 7.8958, 7.8958, 83.1583, 26.0, 7.8958, 10.5167, 10.5, 7.05, 29.125, 13.0, 30.0, 23.45, 30.0, 7.75, 7.8292, 7.0, 9.6875, 8.6625, 12.2875, 9.225, 7.6292, 29.0, 7.2292, 24.15, 7.8958, 26.0, 82.2667, 26.0, 61.175, 27.7208, 12.35, 7.225, 7.925, 7.225, 59.4, 3.1708, 31.6833, 61.3792, 262.375, 14.5, 61.9792, 7.225, 30.5, 21.6792, 26.0, 31.5, 20.575, 23.45, 57.75, 7.2292, 8.05, 8.6625, 9.5, 56.4958, 13.4167, 26.55, 7.85, 13.0, 52.5542, 7.925, 29.7, 7.75, 76.2917, 15.9, 60.0, 15.0333, 23.0, 263.0, 15.5792, 29.125, 7.8958, 7.65, 16.1, 262.375, 7.8958, 13.5, 7.75, 7.725, 262.375, 21.0, 7.8792, 42.4, 28.5375, 263.0, 7.75, 7.8958, 7.925, 27.7208, 211.5, 211.5, 8.05, 25.7, 13.0, 7.75, 15.2458, 221.7792, 26.0, 7.8958, 10.7083, 14.4542, 7.8792, 8.05, 7.75, 23.0, 13.9, 7.775, 52.0, 8.05, 26.0, 7.7958, 78.85, 7.925, 7.8542, 8.05, 55.4417, 26.0, 7.75, 7.775, 8.5167, 22.525, 7.8208, 7.75, 8.7125, 13.0, 15.0458, 7.7792, 31.6792, 7.2833, 221.7792, 14.4542, 6.4375, 16.7, 75.2417, 26.0, 15.75, 7.75, 57.75, 7.25, 7.75, 16.1, 7.7958, 23.25, 13.0, 8.05, 8.05, 28.5, 25.4667, 6.4375, 7.8958, 7.8542, 7.225, 13.0, 8.05, 46.9, 46.9, 151.55, 262.375, 26.0, 26.55, 18.0, 51.8625, 8.05, 26.55, 26.0, 83.1583, 7.8958, null, 12.1833, 31.3875, 7.55, 221.7792, 7.8542, 26.55, 13.775, 7.7333, 15.2458, 13.5, 7.0, 13.0, 22.025, 50.4958, 34.375, 27.7208, 8.9625, 7.55, 7.225, 13.9, 7.2292, 31.3875, 39.0, 36.75, 55.4417, 39.0, 83.1583, 13.0, 83.1583, 53.1, 7.75, 247.5208, 16.0, 21.0, 8.05, 69.55, 13.0, 26.0, 26.0, 14.5, 12.35, 32.5, 7.8542, 134.5, 7.775, 10.5, 8.1125, 15.5, 14.4, 227.525, 26.0, 10.5, 25.7417, 7.75, 10.5, 27.7208, 7.8958, 22.525, 7.05, 73.5, 26.0, 7.775, 42.5, 7.8792, 164.8667, 211.5, 8.05, 13.8583, 8.05, 10.5, 7.7958, 27.4458, 15.2458, 7.7958, 7.75, 15.1, 13.0, 65.0, 26.55, 6.4958, 7.8792, 71.2833, 7.8542, 75.25, 7.225, 13.0, 106.425, 27.7208, 30.0, 134.5, 7.8875, 23.45, 51.8625, 21.0, 32.5, 26.0, 14.4542, 27.75, 7.925, 136.7792, 9.325, 9.5, 7.55, 7.75, 8.05, 13.0, 7.775, 17.4, 7.8542, 23.0, 12.1833, 12.7375, 7.8958, 0.0, 7.55, 8.05, 8.6625, 75.2417, 7.75, 136.7792, 15.5, 7.225, 26.0, 10.5, 26.0, 21.0, 10.5, 8.6625, 13.775, 7.75, 15.2458, 20.2125, 7.25, 7.25, 82.2667, 7.2292, 8.05, 39.6, 6.95, 7.2292, 81.8583, 9.5, 7.8958, 41.5792, 21.6792, 45.5, 7.8542, 7.775, 15.0458, 21.0, 8.6625, 7.75, 26.55, 151.55, 9.35, 93.5, 14.1083, 8.6625, 7.225, 7.575, 7.75, 135.6333, 7.7333, 146.5208, 10.5, 7.8542, 31.5, 7.775, 7.2292, 13.0, 26.55, 211.3375, 7.05, 39.0, 79.2, 26.0, 13.0, 36.75, 29.7, 7.225, 15.7417, 7.8958, 26.0, 13.0, 7.2292, 31.5, 7.2292, 10.5, 7.5792, 69.55, 512.3292, 14.5, 7.65, 13.0, 7.2292, 13.5, 21.0, 63.3583, 10.5, 73.5, 65.0, 20.575, 26.0, 51.4792, 7.8792, 7.75, 15.55, 69.55, 37.0042, 21.0, 8.6625, 55.4417, 69.55, 14.4583, 39.6875, 59.4, 13.8583, 11.5, 134.5, 0.0, 13.0, 81.8583, 262.375, 8.6625, 11.5, 50.0, 31.3875, 7.75, 7.8792, 14.5, 16.1, 12.875, 65.0, 7.775, 13.0, 7.75, 21.075, 93.5, 39.4, 20.25, 10.5, 22.025, 60.0, 7.25, 79.2, 7.775, 7.7333, 164.8667, 21.0, 59.4, 47.1, 27.7208, 13.8625, 10.5, 211.5, 7.7208, 13.775, 7.75, 90.0, 7.775, 8.05, 108.9, 7.25, 8.05, 22.3583], \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"green\"}, \"name\": \"\", \"type\": \"box\", \"uid\": \"fa538510-ef71-47f4-a18d-446a457b61f1\", \"x\": [7.25, 7.925, 53.1, 8.05, 8.4583, 51.8625, 21.075, 11.1333, 30.0708, 16.7, 26.55, 8.05, 31.275, 7.8542, 16.0, 29.125, 13.0, 18.0, 7.225, 26.0, 13.0, 8.0292, 35.5, 21.075, 31.3875, 7.225, 7.8792, 7.8958, 27.7208, 7.75, 10.5, 52.0, 7.2292, 8.05, 18.0, 11.2417, 9.475, 21.0, 7.8958, 41.5792, 7.8792, 8.05, 15.5, 7.75, 21.6792, 17.8, 39.6875, 7.8, 26.0, 61.9792, 35.5, 10.5, 7.2292, 27.75, 46.9, 7.2292, 27.9, 27.7208, 15.2458, 10.5, 8.1583, 7.925, 8.6625, 10.5, 46.9, 14.4542, 56.4958, 7.65, 7.8958, 8.05, 29.0, 12.475, 9.0, 9.5, 7.7875, 47.1, 10.5, 15.85, 34.375, 8.05, 8.05, 8.05, 7.8542, 61.175, 20.575, 7.25, 8.05, 34.6542, 63.3583, 23.0, 26.0, 7.8958, 7.8958, 8.6542, 7.925, 7.8958, 7.65, 7.775, 7.8958, 24.15, 52.0, 14.4542, 8.05, 9.825, 14.4583, 7.925, 7.75, 21.0, 31.275, 8.05, 30.0708, 13.0, 11.2417, 7.75, 7.1417, 22.3583, 6.975, 7.8958, 7.05, 14.5, 26.0, 13.0, 15.0458, 26.2833, 53.1, 9.2167, 15.2458, 7.75, 15.85, 6.75, 11.5, 36.75, 7.7958, 34.375, 26.0, 13.0, 12.525, 8.05, 14.5, 7.3125, 61.3792, 7.7333, 8.05, 8.6625, 16.1, 15.75, 7.775, 8.6625, 39.6875, 20.525, 55.0, 27.9, 25.925, 56.4958, 33.5, 29.125, 11.1333, 7.925, 30.6958, 7.8542, 25.4667, 28.7125, 13.0, 0.0, 15.05, 31.3875, 39.0, 22.025, 50.0, 15.5, 26.55, 15.5, 7.8958, 13.0, 13.0, 7.8542, 26.0, 27.7208, 7.75, 8.4042, 7.75, 13.0, 9.5, 6.4958, 7.225, 8.05, 10.4625, 15.85, 18.7875, 7.75, 31.0, 7.05, 21.0, 7.25, 13.0, 7.75, 7.925, 27.0, 10.5, 8.05, 13.0, 8.05, 7.8958, 9.35, 10.5, 7.25, 13.0, 25.4667, 7.775, 13.5, 31.3875, 10.5, 7.55, 26.0, 26.25, 10.5, 12.275, 14.4542, 15.5, 10.5, 7.125, 7.225, 7.775, 14.5, 52.5542, 26.0, 7.25, 10.4625, 26.55, 16.1, 20.2125, 15.2458, 26.0, 7.75, 31.3875, 0.0, 7.75, 10.5, 39.6875, 7.775, 31.0, 0.0, 19.5, 29.7, 7.75, 7.75, 0.0, 29.125, 20.25, 7.75, 7.8542, 9.5, 8.05, 26.0, 8.6625, 9.5, 7.8958, 13.0, 7.75, 12.875, 8.85, 7.8958, 27.7208, 7.2292, 30.5, 7.75, 23.25, 0.0, 12.35, 8.05, 24.0, 56.9292, 26.0, 7.8958, 26.25, 7.8542, 26.0, 14.0, 7.25, 7.8958, 12.35, 29.0, 6.2375, 13.0, 20.525, 57.9792, 23.25, 28.5, 18.0, 7.8958, 8.05, 35.5, 26.0, 13.0, 13.0, 13.0, 13.0, 13.0, 16.1, 15.9, 8.6625, 9.225, 35.0, 7.2292, 17.8, 7.225, 9.5, 55.0, 13.0, 7.8792, 7.8792, 27.9, 27.7208, 14.4542, 7.05, 15.5, 7.25, 7.2292, 7.75, 55.4417, 6.4958, 8.05, 21.075, 7.25, 4.0125, 7.775, 15.7417, 7.925, 52.0, 7.8958, 46.9, 13.0, 7.7292, 12.0, 7.7958, 7.925, 16.7, 7.7958, 7.8542, 26.0, 10.5, 12.65, 7.925, 8.05, 9.825, 15.85, 8.6625, 21.0, 7.75, 18.75, 7.775, 25.4667, 7.8958, 6.8583, 0.0, 7.925, 8.05, 32.5, 13.0, 13.0, 24.15, 7.8958, 7.7333, 7.875, 14.4, 20.2125, 7.25, 26.0, 26.0, 7.75, 8.05, 26.55, 16.1, 26.0, 7.125, 55.9, 34.375, 18.75, 10.5, 26.25, 9.5, 7.775, 13.0, 8.1125, 19.5, 26.55, 19.2583, 30.5, 27.75, 19.9667, 27.75, 8.05, 7.8958, 26.55, 51.8625, 10.5, 7.75, 26.55, 8.05, 38.5, 13.0, 8.05, 7.05, 0.0, 26.55, 7.725, 19.2583, 7.25, 8.6625, 27.75, 13.7917, 9.8375, 52.0, 21.0, 7.0458, 7.5208, 12.2875, 46.9, 0.0, 8.05, 9.5875, 25.4667, 29.7, 8.05, 15.9, 19.9667, 7.25, 30.5, 49.5042, 8.05, 14.4583, 15.1, 7.7958, 8.6625, 7.75, 7.6292, 9.5875, 26.0, 26.55, 22.525, 56.4958, 7.75, 8.05, 26.2875, 59.4, 7.4958, 34.0208, 10.5, 24.15, 26.0, 7.8958, 7.8958, 7.225, 57.9792, 7.2292, 7.75, 10.5, 7.925, 11.5, 26.0, 7.2292, 7.2292, 22.3583, 8.6625, 26.25, 26.55, 14.5, 49.5, 31.275, 31.275, 26.0, 26.0, 26.0, 13.8625, 20.525, 36.75, 26.0, 7.8292, 7.225, 7.775, 26.55, 39.6, 17.4, 7.75, 7.8958, 13.5, 8.05, 8.05, 24.15, 7.8958, 21.075, 7.2292, 7.8542, 10.5, 51.4792, 26.3875, 7.75, 8.05, 14.5, 13.0, 55.9, 14.4583, 7.925, 30.0, 26.0, 40.125, 8.7125, 15.0, 8.05, 8.05, 7.125, 7.25, 7.75, 26.0, 24.15, 33.0, 0.0, 7.225, 56.9292, 27.0, 7.8958, 42.4, 8.05, 26.55, 15.55, 7.8958, 30.5, 41.5792, 31.275, 7.05, 15.5, 7.75, 8.05, 65.0, 14.4, 16.1, 39.0, 10.5, 14.4542, 52.5542, 15.7417, 7.8542, 16.1, 32.3208, 12.35, 7.8958, 7.7333, 30.0, 7.0542, 30.5, 0.0, 27.9, 13.0, 7.925, 26.25, 39.6875, 16.1, 7.8542, 27.9, 56.4958, 19.2583, 7.8958, 35.5, 7.55, 7.55, 7.8958, 23.0, 8.4333, 7.8292, 6.75, 7.8958, 15.5, 13.0, 7.225, 25.5875, 7.4958, 7.925, 13.0, 7.775, 8.05, 52.0, 39.0, 52.0, 10.5, 13.0, 0.0, 7.775, 8.05, 9.8417, 46.9, 8.1375, 9.225, 46.9, 39.0, 41.5792, 39.6875, 10.1708, 7.7958, 57.0, 13.4167, 56.4958, 7.225, 26.55, 13.5, 8.05, 7.7333, 7.65, 26.2875, 14.4542, 7.7417, 7.8542, 26.0, 13.5, 26.2875, 15.2458, 49.5042, 26.55, 52.0, 9.4833, 13.0, 7.65, 10.5, 15.5, 7.775, 33.0, 7.0542, 13.0, 13.0, 53.1, 8.6625, 21.0, 7.7375, 26.0, 7.925, 18.7875, 0.0, 13.0, 13.0, 16.1, 34.375, 7.8958, 7.8958, 30.0, 16.1, 7.925, 20.25, 13.0, 53.1, 7.75, 23.0, 12.475, 9.5, 7.8958, 65.0, 14.5, 7.7958, 11.5, 8.05, 14.5, 7.125, 7.2292, 7.775, 39.6, 7.75, 24.15, 8.3625, 9.5, 7.8542, 10.5, 7.225, 23.0, 7.75, 7.75, 12.475, 7.7375, 7.2292, 57.0, 30.0, 23.45, 7.05, 7.25, 7.4958, 29.125, 20.575, 7.75, 26.0, 30.6958, 7.8958, 13.0, 25.9292, 8.6833, 7.2292, 24.15, 13.0, 26.25, 8.5167, 6.975, 7.775, 0.0, 7.775, 13.0, 53.1, 7.8875, 24.15, 10.5, 31.275, 8.05, 0.0, 7.925, 37.0042, 6.45, 27.9, 8.6625, 0.0, 12.475, 39.6875, 6.95, 56.4958, 37.0042, 7.75, 14.4542, 18.75, 7.2292, 7.8542, 8.3, 8.6625, 8.05, 56.4958, 29.7, 7.925, 10.5, 31.0, 6.4375, 8.6625, 7.55, 7.8958, 33.0, 31.275, 7.775, 15.2458, 39.4, 26.0, 9.35, 26.55, 19.2583, 7.2292, 14.1083, 11.5, 25.9292, 13.0, 13.0, 13.8583, 50.4958, 9.5, 11.1333, 7.8958, 52.5542, 5.0, 9.0, 24.0, 7.225, 9.8458, 7.8958, 7.8958, 26.0, 7.8958, 10.5167, 10.5, 7.05, 29.125, 13.0, 30.0, 23.45, 30.0, 7.75, 7.8292, 7.0, 9.6875, 8.6625, 12.2875, 9.225, 7.6292, 29.0, 7.2292, 24.15, 7.8958, 26.0, 26.0, 61.175, 27.7208, 12.35, 7.225, 7.925, 7.225, 59.4, 3.1708, 31.6833, 61.3792, 14.5, 61.9792, 7.225, 30.5, 21.6792, 26.0, 31.5, 20.575, 23.45, 57.75, 7.2292, 8.05, 8.6625, 9.5, 56.4958, 13.4167, 26.55, 7.85, 13.0, 52.5542, 7.925, 29.7, 7.75, 15.9, 60.0, 15.0333, 23.0, 15.5792, 29.125, 7.8958, 7.65, 16.1, 7.8958, 13.5, 7.75, 7.725, 21.0, 7.8792, 42.4, 28.5375, 7.75, 7.8958, 7.925, 27.7208, 8.05, 25.7, 13.0, 7.75, 15.2458, 26.0, 7.8958, 10.7083, 14.4542, 7.8792, 8.05, 7.75, 23.0, 13.9, 7.775, 52.0, 8.05, 26.0, 7.7958, 7.925, 7.8542, 8.05, 55.4417, 26.0, 7.75, 7.775, 8.5167, 22.525, 7.8208, 7.75, 8.7125, 13.0, 15.0458, 7.7792, 31.6792, 7.2833, 14.4542, 6.4375, 16.7, 26.0, 15.75, 7.75, 57.75, 7.25, 7.75, 16.1, 7.7958, 23.25, 13.0, 8.05, 8.05, 28.5, 25.4667, 6.4375, 7.8958, 7.8542, 7.225, 13.0, 8.05, 46.9, 46.9, 26.0, 26.55, 18.0, 51.8625, 8.05, 26.55, 26.0, 7.8958, null, 12.1833, 31.3875, 7.55, 7.8542, 26.55, 13.775, 7.7333, 15.2458, 13.5, 7.0, 13.0, 22.025, 50.4958, 34.375, 27.7208, 8.9625, 7.55, 7.225, 13.9, 7.2292, 31.3875, 39.0, 36.75, 55.4417, 39.0, 13.0, 53.1, 7.75, 16.0, 21.0, 8.05, 13.0, 26.0, 26.0, 14.5, 12.35, 32.5, 7.8542, 7.775, 10.5, 8.1125, 15.5, 14.4, 26.0, 10.5, 25.7417, 7.75, 10.5, 27.7208, 7.8958, 22.525, 7.05, 26.0, 7.775, 42.5, 7.8792, 8.05, 13.8583, 8.05, 10.5, 7.7958, 27.4458, 15.2458, 7.7958, 7.75, 15.1, 13.0, 65.0, 26.55, 6.4958, 7.8792, 7.8542, 7.225, 13.0, 27.7208, 30.0, 7.8875, 23.45, 51.8625, 21.0, 32.5, 26.0, 14.4542, 27.75, 7.925, 9.325, 9.5, 7.55, 7.75, 8.05, 13.0, 7.775, 17.4, 7.8542, 23.0, 12.1833, 12.7375, 7.8958, 0.0, 7.55, 8.05, 8.6625, 7.75, 15.5, 7.225, 26.0, 10.5, 26.0, 21.0, 10.5, 8.6625, 13.775, 7.75, 15.2458, 20.2125, 7.25, 7.25, 7.2292, 8.05, 39.6, 6.95, 7.2292, 9.5, 7.8958, 41.5792, 21.6792, 45.5, 7.8542, 7.775, 15.0458, 21.0, 8.6625, 7.75, 26.55, 9.35, 14.1083, 8.6625, 7.225, 7.575, 7.75, 7.7333, 10.5, 7.8542, 31.5, 7.775, 7.2292, 13.0, 26.55, 7.05, 39.0, 26.0, 13.0, 36.75, 29.7, 7.225, 15.7417, 7.8958, 26.0, 13.0, 7.2292, 31.5, 7.2292, 10.5, 7.5792, 14.5, 7.65, 13.0, 7.2292, 13.5, 21.0, 63.3583, 10.5, 65.0, 20.575, 26.0, 51.4792, 7.8792, 7.75, 15.55, 37.0042, 21.0, 8.6625, 55.4417, 14.4583, 39.6875, 59.4, 13.8583, 11.5, 0.0, 13.0, 8.6625, 11.5, 50.0, 31.3875, 7.75, 7.8792, 14.5, 16.1, 12.875, 65.0, 7.775, 13.0, 7.75, 21.075, 39.4, 20.25, 10.5, 22.025, 60.0, 7.25, 7.775, 7.7333, 21.0, 59.4, 47.1, 27.7208, 13.8625, 10.5, 7.7208, 13.775, 7.75, 7.775, 8.05, 7.25, 8.05, 22.3583], \"xaxis\": \"x2\", \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Fare Distribution with Outliers\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Fare Distribution without Outliers\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.375, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 800, \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"width\": 870, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Fare</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.625, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.375]}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('7b3f5f43-d255-42bb-9105-c1965d27cf25');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 82,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 47,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"#1.Create a function to calculate missing values\"\"\"\ndef calculateMissingValues(variable):\n    \"\"\"Calculates missing values of a variable.\"\"\"\n    \n    return merged.isna().sum()[merged.isna().sum()>0] # Returns only columns with missing values\n\n\n\n\"\"\"\"#2.Create a function to plot scatter plot.\nThis can also be used to plot missing values\"\"\"\ndef plotScatterPlot(x, y, title, yaxis):\n    trace = go.Scatter(\n    x = x,\n    y = y,\n    mode = \"markers\",\n    marker = dict(color = y, size = 35, showscale = True, colorscale = \"Rainbow\"))\n    layout = go.Layout(hovermode= \"closest\",\n                       title = title,\n                       yaxis = dict(title = yaxis),\n                       height=600,\n                       width=900,\n                       showlegend=False,\n                        paper_bgcolor=\"rgb(243, 243, 243)\",\n                        plot_bgcolor=\"rgb(243, 243, 243)\"\n                      )\n    fig = go.Figure(data = [trace], layout = layout)\n    return fig.show()      ",
            "mc_idx": 84,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2727272727272727,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.09090909090909091,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1,
                    "variable": 2
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".scatter(": 1,
                    "missing values": 4,
                    "columns": 1,
                    "size": 1,
                    ".isna": 2,
                    ".sum": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    ".scatter(": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    48,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 84,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 48,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Plot variables with their corresponding missing values.\"\"\"\nplotScatterPlot(calculateMissingValues(merged).index,\n               calculateMissingValues(merged),\n               \"Features with Missing Values\",\n               \"Missing Values\")",
            "mc_idx": 85,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.3333333333333333,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "missing values": 3
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    49,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"07c28866-ede4-4712-bd03-5b0380561a19\" class=\"plotly-graph-div\" style=\"height:600px; width:900px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"07c28866-ede4-4712-bd03-5b0380561a19\")) {\n                    Plotly.newPlot(\n                        '07c28866-ede4-4712-bd03-5b0380561a19',\n                        [{\"marker\": {\"color\": [418, 263, 1, 1014, 2], \"colorscale\": \"Rainbow\", \"showscale\": true, \"size\": 35}, \"mode\": \"markers\", \"type\": \"scatter\", \"uid\": \"90a201b3-14a9-4984-895a-9382cee4d172\", \"x\": [\"Survived\", \"Age\", \"Fare\", \"Cabin\", \"Embarked\"], \"y\": [418, 263, 1, 1014, 2]}],\n                        {\"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Features with Missing Values\"}, \"width\": 900, \"yaxis\": {\"title\": {\"text\": \"Missing Values\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('07c28866-ede4-4712-bd03-5b0380561a19');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 85,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 49,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Impute missing values of Embarked. Embarked is a categorical variable where S is the most frequent.\"\"\"\nmerged.Embarked.fillna(value=\"S\", inplace = True)\n\n\"\"\"Impute missing values of Fare. Fare is a numerical variable with outliers. Hence it will be imputed by median.\"\"\"\nmerged.Fare.fillna(value=merged.Fare.median(), inplace = True)",
            "mc_idx": 88,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.4,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.8,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 2
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "missing values": 2,
                    "outliers": 1,
                    ".median": 2
                },
                "Data_Transform": {
                    ".fillna(": 2,
                    ".fillna": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    50,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 88,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 50,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Create a boxplot to view the variables correlated with Age. First extract the variables we're interested in.\"\"\"\ntoSearch = merged.loc[:, [\"Sex\", \"Pclass\", \"Embarked\", \"nameProcessed\", \"familySize\", \"Parch\", \n                             \"SibSp\", \"cabinProcessed\", \"ticketProcessed\"]]\n\nfig, axes = plt.subplots(nrows = 3, ncols = 3, figsize = (25,25))\nfor ax, column in zip(axes.flatten(), toSearch.columns):\n    sns.boxplot(x = toSearch[column], y = merged.Age, ax = ax)\n    ax.set_title(column, fontsize = 23)\n    ax.tick_params(axis = \"both\", which = \"major\", labelsize = 20)\n    ax.tick_params(axis = \"both\", which = \"minor\", labelsize = 20)\n    ax.set_ylabel(\"Age\", fontsize = 20)\n    ax.set_xlabel(\"\")\nfig.suptitle(\"Variables Associated with Age\", fontsize = 30)\nfig.tight_layout(rect = [0, 0.03, 1, 0.95])",
            "mc_idx": 90,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2727272727272727,
                "Data_Extraction": 0.09090909090909091,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.18181818181818182,
                "Visualization": 0.18181818181818182,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 3
                },
                "Data_Extraction": {
                    "extract": 1
                },
                "Exploratory_Data_Analysis": {
                    ".boxplot(": 2,
                    "sns.": 1,
                    "columns": 1,
                    "size": 7
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {
                    ".boxplot(": 1,
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c051_o000_image_0.png",
                    51,
                    0,
                    0
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1800x1800 with 9 Axes>"
                    ]
                },
                "mc_idx": 90,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 51,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Let's plot correlation heatmap to see which variable is highly correlated with Age and if our \nboxplot interpretation holds true. We need to convert categorical variable into numerical to plot \ncorrelation heatmap. So convert categorical variables into numerical.\"\"\"\nfrom sklearn.preprocessing import LabelEncoder\ntoSearch = toSearch.agg(LabelEncoder().fit_transform)\ntoSearch[\"Age\"] = merged.Age # Inserting Age in dataframe \"toSearch\".\ntoSearch = toSearch.set_index(\"Age\").reset_index() # Move Age column at index 0.\n\n# Now create the correlation heatmap\nfig,ax = plt.subplots(nrows=1, ncols=1, figsize=(15,6))\nsns.heatmap(toSearch.corr(), cmap =\"YlGnBu\", annot=True, annot_kws={\"size\":14}, ax=ax)\nax.set_title(\"Variables correlated with Age\", fontsize = 20)\nax.tick_params(axis = \"both\", which = \"major\", labelsize = 14)\nax.tick_params(axis = \"both\", which = \"minor\", labelsize = 14)\nplt.show()",
            "mc_idx": 92,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.6,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.8,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.2,
                "Visualization": 0.3,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 1,
                    ".show": 1,
                    "variable": 4
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".corr": 2,
                    "sns.heatmap": 1,
                    ".heatmap(": 1,
                    "sns.": 1,
                    "size": 5
                },
                "Data_Transform": {
                    "fit_transform": 1,
                    "transform": 1,
                    "labelencoder": 4,
                    ".reset_index": 1,
                    ".set_index": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {
                    "sns.heatmap": 1,
                    ".heatmap(": 1,
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c052_o000_image_1.png",
                    52,
                    0,
                    1
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1080x432 with 2 Axes>"
                    ]
                },
                "mc_idx": 92,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 52,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Impute Age with median of respective columns (i.e., nameProcessed and Pclass).\"\"\"\nmerged.Age = merged.groupby([\"nameProcessed\", \"Pclass\"])[\"Age\"].transform(lambda x: x.fillna(x.median()))\n\n\"\"\"So by now we should have variables with no missing values.\"\"\"\nbold(\"Missing Values after Imputation:\")\ndisplay(merged.isnull().sum())",
            "mc_idx": 94,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.125,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.5,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "missing values": 2,
                    ".median": 2,
                    "columns": 1,
                    ".isnull": 1,
                    ".sum": 1,
                    ".groupby": 1
                },
                "Data_Transform": {
                    ".groupby(": 1,
                    ".fillna(": 1,
                    "transform": 1,
                    ".fillna": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    53,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "PassengerId           0\nSurvived            418\nPclass                0\nName                  0\nSex                   0\nAge                   0\nSibSp                 0\nParch                 0\nTicket                0\nFare                  0\nCabin              1014\nEmbarked              0\ncabinProcessed        0\nnameProcessed         0\nfamilySize            0\nticketProcessed       0\ndtype: int64"
                    ]
                },
                "mc_idx": 94,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 53,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Let's split the train and test data for bivariate analysis since test data has no Survived values. We need our target variable without missing values to conduct the association test with predictor variables.\"\"\"\ndf_train = merged.iloc[:891, :]\ndf_test = merged.iloc[891:, :]\ndf_test = df_test.drop(columns = [\"Survived\"], axis = 1)\n\n\"\"\"#1.Create a function that creates boxplot between categorical and numerical variables and calculates biserial correlation.\"\"\"\ndef boxplotAndCorrelation(numVariable,catVariable=df_train.Survived):\n    \"\"\"Return boxplot between a categorical and numerical variable. Also calculates biserial correlation.\n    numVariable = a numerical variable of interest.\"\"\"\n    \n    # Calculate point biserial correlation and p value\n    biserialCorr = stats.pointbiserialr(numVariable,catVariable)[0].round(2)\n    pValue = stats.pointbiserialr(numVariable,catVariable)[1].round(5)\n    \n    # Create subplot object.\n    fig = make_subplots(\n        rows=1,\n        cols=1,\n        print_grid=False,\n    )\n    \n    # This trace plots boxplot of categorical variable vs numerical variable\n    fig.add_trace(\n        go.Box(\n            x = catVariable,\n            y = numVariable,\n            marker_color=\"lightseagreen\",\n            ))\n    \n    \n    # Update layout\n    fig.layout.update(\n        height=500, \n        width=900,\n        showlegend=False,\n        title_text= f\"Association between {catVariable.name} and {numVariable.name} (corr: {biserialCorr}, p: {pValue})\",\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n    \n    # Update axes\n    fig.layout.xaxis1.update(title=f\"<b>{catVariable.name}</b>\")\n    fig.layout.yaxis1.update(title=f\"<b>{numVariable.name}</b>\")\n    return fig.show()\n\n\n\"\"\"#2.Create another function to calculate mean when grouped by categorical variable. And also plot the grouped mean.\"\"\"\ndef numGroupedByCat(numVariable,catVariable=df_train.Survived):\n    \"\"\"Returns a barplot showing mean of numerical variable across the class of categorical variable.\"\"\"\n    \n    # Calculates mean across different classes of categorical variable\n    numGroupedByCat = numVariable.groupby(catVariable).mean().round(2)\n    \n    # Create subplot object.\n    fig = make_subplots(\n        rows=1,\n        cols=1,\n        print_grid=False,\n    )\n    \n    # This trace plots barplot\n    fig.add_trace(\n        go.Bar(\n            x = numGroupedByCat.index,\n            y = numGroupedByCat,\n            text=numGroupedByCat,\n            hoverinfo=\"x+y\",\n            textposition=\"auto\",\n            textfont=dict(family=\"sans serif\",size=15)\n        ))\n    \n    # Update layout\n    fig.layout.update(\n        height=500, \n        width=900,\n        showlegend=False,\n        title_text= f\"Mean {numVariable.name} across {catVariable.name}\",\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n    \n    # Update axes\n    fig.layout.xaxis1.update(title=f\"<b>{catVariable.name}</b>\")\n    fig.layout.yaxis1.update(title=f\"<b>Mean {numVariable.name}</b>\")\n    return fig.show()\n\n    \n\"\"\"#3.This function plots histogram of numerical variable for every class of categorical variable.\"\"\"\ndef numHistByCat(numVariable,catVariable=df_train.Survived):\n    \"\"\"Returns numerical variable distribution across classes of categorical variable.\"\"\"\n    fig,ax = plt.subplots(1,1,figsize = (18,7))\n    font_size = 15\n    title_size = 18\n    numVariable[catVariable==1].hist(bins=50,color=\"green\", label = \"survived\", grid = False, alpha=0.5)\n    numVariable[catVariable==0].hist(bins=50,color=\"red\", label = \"died\", grid = False, alpha=0.5)\n    ax.set_yticks([])\n    ax.tick_params(axis=\"x\", labelsize=font_size)\n    ax.set_xlabel(f\"{numVariable.name}\", fontsize = font_size)\n    ax.set_title(f\"{numVariable.name} Distribution of Survivors vs Victims\", fontsize = title_size)\n    plt.legend()\n    return plt.show()\n\n   \n\"\"\"#4.Create a function to calculate anova between numerical and categorical variable.\"\"\"\ndef calculateAnova(numVariable, catVariable=df_train.Survived):\n    \"\"\"Returns f statistics and p value after anova calculation.\"\"\"\n    \n    groupNumVariableByCatVariable1 = numVariable[catVariable==1] # Group our numerical variable by categorical variable(1). Group Fair by survivors\n    groupNumVariableByCatVariable0 = numVariable[catVariable==0] # Group our numerical variable by categorical variable(0). Group Fare by victims\n    # Calculate one way anova\n    fValue, pValue = stats.f_oneway(groupNumVariableByCatVariable1, groupNumVariableByCatVariable0) # Calculate f statistics and p value\n    return f\"Anova Result between {numVariable.name} & {catVariable.name}: f=> {fValue}, p=> {pValue}\"",
            "mc_idx": 96,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.27941176470588236,
                "Data_Transform": 0.10294117647058823,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.014705882352941176,
                "Visualization": 0.04411764705882353,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 3,
                    "variable": 65
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".hist(": 2,
                    ".bar(": 1,
                    "missing values": 1,
                    ".mean(": 1,
                    "info": 1,
                    "columns": 1,
                    "size": 10,
                    ".mean": 1,
                    ".groupby": 1
                },
                "Data_Transform": {
                    ".groupby(": 1,
                    ".drop": 1,
                    ".add": 2,
                    ".round": 3
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 1
                },
                "Visualization": {
                    ".hist(": 2,
                    ".bar(": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    54,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 96,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 54,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Create a boxplot to visualize the strength of association of Survived with Fare. Also calculate biserial correlation.\"\"\"\nboxplotAndCorrelation(df_train.Fare)",
            "mc_idx": 98,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Visualization",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "visualize": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    55,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"b00d8582-d878-4b7d-8992-7f9922221173\" class=\"plotly-graph-div\" style=\"height:500px; width:900px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"b00d8582-d878-4b7d-8992-7f9922221173\")) {\n                    Plotly.newPlot(\n                        'b00d8582-d878-4b7d-8992-7f9922221173',\n                        [{\"marker\": {\"color\": \"lightseagreen\"}, \"type\": \"box\", \"uid\": \"56fa6ee9-61fe-4869-98ef-f156a9f0a74a\", \"x\": [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0], \"y\": [7.25, 71.2833, 7.925, 53.1, 8.05, 8.4583, 51.8625, 21.075, 11.1333, 30.0708, 16.7, 26.55, 8.05, 31.275, 7.8542, 16.0, 29.125, 13.0, 18.0, 7.225, 26.0, 13.0, 8.0292, 35.5, 21.075, 31.3875, 7.225, 263.0, 7.8792, 7.8958, 27.7208, 146.5208, 7.75, 10.5, 82.1708, 52.0, 7.2292, 8.05, 18.0, 11.2417, 9.475, 21.0, 7.8958, 41.5792, 7.8792, 8.05, 15.5, 7.75, 21.6792, 17.8, 39.6875, 7.8, 76.7292, 26.0, 61.9792, 35.5, 10.5, 7.2292, 27.75, 46.9, 7.2292, 80.0, 83.475, 27.9, 27.7208, 15.2458, 10.5, 8.1583, 7.925, 8.6625, 10.5, 46.9, 73.5, 14.4542, 56.4958, 7.65, 7.8958, 8.05, 29.0, 12.475, 9.0, 9.5, 7.7875, 47.1, 10.5, 15.85, 34.375, 8.05, 263.0, 8.05, 8.05, 7.8542, 61.175, 20.575, 7.25, 8.05, 34.6542, 63.3583, 23.0, 26.0, 7.8958, 7.8958, 77.2875, 8.6542, 7.925, 7.8958, 7.65, 7.775, 7.8958, 24.15, 52.0, 14.4542, 8.05, 9.825, 14.4583, 7.925, 7.75, 21.0, 247.5208, 31.275, 73.5, 8.05, 30.0708, 13.0, 77.2875, 11.2417, 7.75, 7.1417, 22.3583, 6.975, 7.8958, 7.05, 14.5, 26.0, 13.0, 15.0458, 26.2833, 53.1, 9.2167, 79.2, 15.2458, 7.75, 15.85, 6.75, 11.5, 36.75, 7.7958, 34.375, 26.0, 13.0, 12.525, 66.6, 8.05, 14.5, 7.3125, 61.3792, 7.7333, 8.05, 8.6625, 69.55, 16.1, 15.75, 7.775, 8.6625, 39.6875, 20.525, 55.0, 27.9, 25.925, 56.4958, 33.5, 29.125, 11.1333, 7.925, 30.6958, 7.8542, 25.4667, 28.7125, 13.0, 0.0, 69.55, 15.05, 31.3875, 39.0, 22.025, 50.0, 15.5, 26.55, 15.5, 7.8958, 13.0, 13.0, 7.8542, 26.0, 27.7208, 146.5208, 7.75, 8.4042, 7.75, 13.0, 9.5, 69.55, 6.4958, 7.225, 8.05, 10.4625, 15.85, 18.7875, 7.75, 31.0, 7.05, 21.0, 7.25, 13.0, 7.75, 113.275, 7.925, 27.0, 76.2917, 10.5, 8.05, 13.0, 8.05, 7.8958, 90.0, 9.35, 10.5, 7.25, 13.0, 25.4667, 83.475, 7.775, 13.5, 31.3875, 10.5, 7.55, 26.0, 26.25, 10.5, 12.275, 14.4542, 15.5, 10.5, 7.125, 7.225, 90.0, 7.775, 14.5, 52.5542, 26.0, 7.25, 10.4625, 26.55, 16.1, 20.2125, 15.2458, 79.2, 86.5, 512.3292, 26.0, 7.75, 31.3875, 79.65, 0.0, 7.75, 10.5, 39.6875, 7.775, 153.4625, 135.6333, 31.0, 0.0, 19.5, 29.7, 7.75, 77.9583, 7.75, 0.0, 29.125, 20.25, 7.75, 7.8542, 9.5, 8.05, 26.0, 8.6625, 9.5, 7.8958, 13.0, 7.75, 78.85, 91.0792, 12.875, 8.85, 7.8958, 27.7208, 7.2292, 151.55, 30.5, 247.5208, 7.75, 23.25, 0.0, 12.35, 8.05, 151.55, 110.8833, 108.9, 24.0, 56.9292, 83.1583, 262.375, 26.0, 7.8958, 26.25, 7.8542, 26.0, 14.0, 164.8667, 134.5, 7.25, 7.8958, 12.35, 29.0, 69.55, 135.6333, 6.2375, 13.0, 20.525, 57.9792, 23.25, 28.5, 153.4625, 18.0, 133.65, 7.8958, 66.6, 134.5, 8.05, 35.5, 26.0, 263.0, 13.0, 13.0, 13.0, 13.0, 13.0, 16.1, 15.9, 8.6625, 9.225, 35.0, 7.2292, 17.8, 7.225, 9.5, 55.0, 13.0, 7.8792, 7.8792, 27.9, 27.7208, 14.4542, 7.05, 15.5, 7.25, 75.25, 7.2292, 7.75, 69.3, 55.4417, 6.4958, 8.05, 135.6333, 21.075, 82.1708, 7.25, 211.5, 4.0125, 7.775, 227.525, 15.7417, 7.925, 52.0, 7.8958, 73.5, 46.9, 13.0, 7.7292, 12.0, 120.0, 7.7958, 7.925, 113.275, 16.7, 7.7958, 7.8542, 26.0, 10.5, 12.65, 7.925, 8.05, 9.825, 15.85, 8.6625, 21.0, 7.75, 18.75, 7.775, 25.4667, 7.8958, 6.8583, 90.0, 0.0, 7.925, 8.05, 32.5, 13.0, 13.0, 24.15, 7.8958, 7.7333, 7.875, 14.4, 20.2125, 7.25, 26.0, 26.0, 7.75, 8.05, 26.55, 16.1, 26.0, 7.125, 55.9, 120.0, 34.375, 18.75, 263.0, 10.5, 26.25, 9.5, 7.775, 13.0, 8.1125, 81.8583, 19.5, 26.55, 19.2583, 30.5, 27.75, 19.9667, 27.75, 89.1042, 8.05, 7.8958, 26.55, 51.8625, 10.5, 7.75, 26.55, 8.05, 38.5, 13.0, 8.05, 7.05, 0.0, 26.55, 7.725, 19.2583, 7.25, 8.6625, 27.75, 13.7917, 9.8375, 52.0, 21.0, 7.0458, 7.5208, 12.2875, 46.9, 0.0, 8.05, 9.5875, 91.0792, 25.4667, 90.0, 29.7, 8.05, 15.9, 19.9667, 7.25, 30.5, 49.5042, 8.05, 14.4583, 78.2667, 15.1, 151.55, 7.7958, 8.6625, 7.75, 7.6292, 9.5875, 86.5, 108.9, 26.0, 26.55, 22.525, 56.4958, 7.75, 8.05, 26.2875, 59.4, 7.4958, 34.0208, 10.5, 24.15, 26.0, 7.8958, 93.5, 7.8958, 7.225, 57.9792, 7.2292, 7.75, 10.5, 221.7792, 7.925, 11.5, 26.0, 7.2292, 7.2292, 22.3583, 8.6625, 26.25, 26.55, 106.425, 14.5, 49.5, 71.0, 31.275, 31.275, 26.0, 106.425, 26.0, 26.0, 13.8625, 20.525, 36.75, 110.8833, 26.0, 7.8292, 7.225, 7.775, 26.55, 39.6, 227.525, 79.65, 17.4, 7.75, 7.8958, 13.5, 8.05, 8.05, 24.15, 7.8958, 21.075, 7.2292, 7.8542, 10.5, 51.4792, 26.3875, 7.75, 8.05, 14.5, 13.0, 55.9, 14.4583, 7.925, 30.0, 110.8833, 26.0, 40.125, 8.7125, 79.65, 15.0, 79.2, 8.05, 8.05, 7.125, 78.2667, 7.25, 7.75, 26.0, 24.15, 33.0, 0.0, 7.225, 56.9292, 27.0, 7.8958, 42.4, 8.05, 26.55, 15.55, 7.8958, 30.5, 41.5792, 153.4625, 31.275, 7.05, 15.5, 7.75, 8.05, 65.0, 14.4, 16.1, 39.0, 10.5, 14.4542, 52.5542, 15.7417, 7.8542, 16.1, 32.3208, 12.35, 77.9583, 7.8958, 7.7333, 30.0, 7.0542, 30.5, 0.0, 27.9, 13.0, 7.925, 26.25, 39.6875, 16.1, 7.8542, 69.3, 27.9, 56.4958, 19.2583, 76.7292, 7.8958, 35.5, 7.55, 7.55, 7.8958, 23.0, 8.4333, 7.8292, 6.75, 73.5, 7.8958, 15.5, 13.0, 113.275, 133.65, 7.225, 25.5875, 7.4958, 7.925, 73.5, 13.0, 7.775, 8.05, 52.0, 39.0, 52.0, 10.5, 13.0, 0.0, 7.775, 8.05, 9.8417, 46.9, 512.3292, 8.1375, 76.7292, 9.225, 46.9, 39.0, 41.5792, 39.6875, 10.1708, 7.7958, 211.3375, 57.0, 13.4167, 56.4958, 7.225, 26.55, 13.5, 8.05, 7.7333, 110.8833, 7.65, 227.525, 26.2875, 14.4542, 7.7417, 7.8542, 26.0, 13.5, 26.2875, 151.55, 15.2458, 49.5042, 26.55, 52.0, 9.4833, 13.0, 7.65, 227.525, 10.5, 15.5, 7.775, 33.0, 7.0542, 13.0, 13.0, 53.1, 8.6625, 21.0, 7.7375, 26.0, 7.925, 211.3375, 18.7875, 0.0, 13.0, 13.0, 16.1, 34.375, 512.3292, 7.8958, 7.8958, 30.0, 78.85, 262.375, 16.1, 7.925, 71.0, 20.25, 13.0, 53.1, 7.75, 23.0, 12.475, 9.5, 7.8958, 65.0, 14.5, 7.7958, 11.5, 8.05, 86.5, 14.5, 7.125, 7.2292, 120.0, 7.775, 77.9583, 39.6, 7.75, 24.15, 8.3625, 9.5, 7.8542, 10.5, 7.225, 23.0, 7.75, 7.75, 12.475, 7.7375, 211.3375, 7.2292, 57.0, 30.0, 23.45, 7.05, 7.25, 7.4958, 29.125, 20.575, 79.2, 7.75, 26.0, 69.55, 30.6958, 7.8958, 13.0, 25.9292, 8.6833, 7.2292, 24.15, 13.0, 26.25, 120.0, 8.5167, 6.975, 7.775, 0.0, 7.775, 13.0, 53.1, 7.8875, 24.15, 10.5, 31.275, 8.05, 0.0, 7.925, 37.0042, 6.45, 27.9, 93.5, 8.6625, 0.0, 12.475, 39.6875, 6.95, 56.4958, 37.0042, 7.75, 80.0, 14.4542, 18.75, 7.2292, 7.8542, 8.3, 83.1583, 8.6625, 8.05, 56.4958, 29.7, 7.925, 10.5, 31.0, 6.4375, 8.6625, 7.55, 69.55, 7.8958, 33.0, 89.1042, 31.275, 7.775, 15.2458, 39.4, 26.0, 9.35, 164.8667, 26.55, 19.2583, 7.2292, 14.1083, 11.5, 25.9292, 69.55, 13.0, 13.0, 13.8583, 50.4958, 9.5, 11.1333, 7.8958, 52.5542, 5.0, 9.0, 24.0, 7.225, 9.8458, 7.8958, 7.8958, 83.1583, 26.0, 7.8958, 10.5167, 10.5, 7.05, 29.125, 13.0, 30.0, 23.45, 30.0, 7.75]}],\n                        {\"height\": 500, \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Association between Survived and Fare (corr: 0.26, p: 0.0)\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Survived</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Fare</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('b00d8582-d878-4b7d-8992-7f9922221173');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 98,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 55,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"So the mean fare of survivors should be much more (from positive correlation or boxplot interpretation) than those who died. Calculate mean fare paid by the survivors as well as by the victims.\"\"\"\nnumGroupedByCat(df_train.Fare)",
            "mc_idx": 100,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    56,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"91ab7c0f-99c8-40e4-aea1-0ad81504fb97\" class=\"plotly-graph-div\" style=\"height:500px; width:900px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"91ab7c0f-99c8-40e4-aea1-0ad81504fb97\")) {\n                    Plotly.newPlot(\n                        '91ab7c0f-99c8-40e4-aea1-0ad81504fb97',\n                        [{\"hoverinfo\": \"x+y\", \"text\": [22.12, 48.4], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"2157779b-7853-4052-9e9a-841993f2f335\", \"x\": [0.0, 1.0], \"y\": [22.12, 48.4]}],\n                        {\"height\": 500, \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Mean Fare across Survived\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Survived</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Mean Fare</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('91ab7c0f-99c8-40e4-aea1-0ad81504fb97');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 100,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 56,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Plot histogram of survivor's vs victims fare.\"\"\"\nnumHistByCat(df_train.Fare)",
            "mc_idx": 102,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c057_o000_image_2.png",
                    57,
                    0,
                    2
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x504 with 1 Axes>"
                    ]
                },
                "mc_idx": 102,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 57,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Let's perform ANOVA between Fare and Survived. One can omit this step. I perform just to show how anova is performed if there were more than two groups in our categorical variable.\"\"\"\ncalculateAnova(df_train.Fare)",
            "mc_idx": 104,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    58,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "'Anova Result between Fare & Survived: f=> 63.03076422804448, p=> 6.120189341921873e-15'"
                    ]
                },
                "mc_idx": 104,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 58,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Let's create a box plot between Age and Survived to have an idea by how much Age is associated with Survived. Also find point biserial correlation between them.\"\"\"\nboxplotAndCorrelation(df_train.Age)",
            "mc_idx": 107,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    59,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"06ed7de7-9c79-419a-9886-a04230f09a5f\" class=\"plotly-graph-div\" style=\"height:500px; width:900px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"06ed7de7-9c79-419a-9886-a04230f09a5f\")) {\n                    Plotly.newPlot(\n                        '06ed7de7-9c79-419a-9886-a04230f09a5f',\n                        [{\"marker\": {\"color\": \"lightseagreen\"}, \"type\": \"box\", \"uid\": \"88220c66-8b87-4cc7-8983-6561df0abc62\", \"x\": [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0], \"y\": [22.0, 38.0, 26.0, 35.0, 35.0, 26.0, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, 30.0, 31.0, 31.0, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, 26.0, 19.0, 18.0, 26.0, 40.0, 45.0, 18.0, 66.0, 28.0, 42.0, 26.0, 21.0, 18.0, 14.0, 40.0, 27.0, 26.0, 3.0, 19.0, 26.0, 26.0, 18.0, 26.0, 18.0, 7.0, 21.0, 49.0, 29.0, 65.0, 41.5, 21.0, 28.5, 5.0, 11.0, 22.0, 38.0, 45.0, 4.0, 41.5, 6.0, 29.0, 19.0, 17.0, 26.0, 32.0, 16.0, 21.0, 26.0, 32.0, 25.0, 26.0, 26.0, 0.83, 30.0, 22.0, 29.0, 18.0, 28.0, 17.0, 33.0, 16.0, 26.0, 23.0, 24.0, 29.0, 20.0, 46.0, 26.0, 59.0, 26.0, 71.0, 23.0, 34.0, 34.0, 28.0, 26.0, 21.0, 33.0, 37.0, 28.0, 21.0, 26.0, 38.0, 18.0, 47.0, 14.5, 22.0, 20.0, 17.0, 21.0, 70.5, 29.0, 24.0, 2.0, 21.0, 26.0, 32.5, 32.5, 54.0, 12.0, 26.0, 24.0, 18.0, 45.0, 33.0, 20.0, 47.0, 29.0, 25.0, 23.0, 19.0, 37.0, 16.0, 24.0, 31.0, 22.0, 24.0, 19.0, 18.0, 19.0, 27.0, 9.0, 36.5, 42.0, 51.0, 22.0, 55.5, 40.5, 26.0, 51.0, 16.0, 30.0, 26.0, 6.0, 44.0, 40.0, 26.0, 17.0, 1.0, 9.0, 45.0, 45.0, 41.5, 28.0, 61.0, 4.0, 1.0, 21.0, 56.0, 18.0, 6.0, 50.0, 30.0, 36.0, 18.0, 30.0, 9.0, 1.0, 4.0, 41.5, 31.0, 45.0, 40.0, 36.0, 32.0, 19.0, 19.0, 3.0, 44.0, 58.0, 26.0, 42.0, 18.0, 24.0, 28.0, 26.0, 34.0, 45.5, 18.0, 2.0, 32.0, 26.0, 16.0, 40.0, 24.0, 35.0, 22.0, 30.0, 26.0, 31.0, 27.0, 42.0, 32.0, 30.0, 16.0, 27.0, 51.0, 26.0, 38.0, 22.0, 19.0, 20.5, 18.0, 18.0, 35.0, 29.0, 59.0, 5.0, 24.0, 18.0, 44.0, 8.0, 19.0, 33.0, 18.0, 18.0, 29.0, 22.0, 30.0, 44.0, 25.0, 24.0, 37.0, 54.0, 26.0, 29.0, 62.0, 30.0, 41.0, 29.0, 45.0, 30.0, 35.0, 50.0, 26.0, 3.0, 52.0, 40.0, 18.0, 36.0, 16.0, 25.0, 58.0, 35.0, 41.5, 25.0, 41.0, 37.0, 18.0, 63.0, 45.0, 30.0, 7.0, 35.0, 65.0, 28.0, 16.0, 19.0, 41.5, 33.0, 30.0, 22.0, 42.0, 22.0, 26.0, 19.0, 36.0, 24.0, 24.0, 41.5, 23.5, 2.0, 41.5, 50.0, 18.0, 26.0, 19.0, 20.0, 26.0, 0.92, 30.0, 17.0, 30.0, 30.0, 24.0, 18.0, 26.0, 28.0, 43.0, 26.0, 24.0, 54.0, 31.0, 40.0, 22.0, 27.0, 30.0, 22.0, 26.0, 36.0, 61.0, 36.0, 31.0, 16.0, 18.0, 45.5, 38.0, 16.0, 45.0, 26.0, 29.0, 41.0, 45.0, 45.0, 2.0, 24.0, 28.0, 25.0, 36.0, 24.0, 40.0, 31.0, 3.0, 42.0, 23.0, 41.5, 15.0, 25.0, 26.0, 28.0, 22.0, 38.0, 18.0, 18.0, 40.0, 29.0, 45.0, 35.0, 26.0, 30.0, 60.0, 31.0, 18.0, 24.0, 25.0, 18.0, 19.0, 22.0, 3.0, 45.0, 22.0, 27.0, 20.0, 19.0, 42.0, 1.0, 32.0, 35.0, 26.0, 18.0, 1.0, 36.0, 26.0, 17.0, 36.0, 21.0, 28.0, 23.0, 24.0, 22.0, 31.0, 46.0, 23.0, 28.0, 39.0, 26.0, 21.0, 28.0, 20.0, 34.0, 51.0, 3.0, 21.0, 18.0, 26.0, 26.0, 33.0, 30.0, 44.0, 31.0, 34.0, 18.0, 30.0, 10.0, 26.0, 21.0, 29.0, 28.0, 18.0, 26.0, 28.0, 19.0, 26.0, 32.0, 28.0, 31.0, 42.0, 17.0, 50.0, 14.0, 21.0, 24.0, 64.0, 31.0, 45.0, 20.0, 25.0, 28.0, 26.0, 4.0, 13.0, 34.0, 5.0, 52.0, 36.0, 26.0, 30.0, 49.0, 26.0, 29.0, 65.0, 45.0, 50.0, 26.0, 48.0, 34.0, 47.0, 48.0, 26.0, 38.0, 30.0, 56.0, 26.0, 0.75, 26.0, 38.0, 33.0, 23.0, 22.0, 41.5, 34.0, 29.0, 22.0, 2.0, 9.0, 30.0, 50.0, 63.0, 25.0, 18.0, 35.0, 58.0, 30.0, 9.0, 26.0, 21.0, 55.0, 71.0, 21.0, 26.0, 54.0, 26.0, 25.0, 24.0, 17.0, 21.0, 18.0, 37.0, 16.0, 18.0, 33.0, 41.5, 28.0, 26.0, 29.0, 26.0, 36.0, 54.0, 24.0, 47.0, 34.0, 26.0, 36.0, 32.0, 30.0, 22.0, 26.0, 44.0, 26.0, 40.5, 50.0, 41.5, 39.0, 23.0, 2.0, 26.0, 17.0, 31.0, 30.0, 7.0, 45.0, 30.0, 26.0, 22.0, 36.0, 9.0, 11.0, 32.0, 50.0, 64.0, 19.0, 30.0, 33.0, 8.0, 17.0, 27.0, 26.0, 22.0, 22.0, 62.0, 48.0, 41.5, 39.0, 36.0, 26.0, 40.0, 28.0, 26.0, 18.0, 24.0, 19.0, 29.0, 26.0, 32.0, 62.0, 53.0, 36.0, 18.0, 16.0, 19.0, 34.0, 39.0, 31.0, 32.0, 25.0, 39.0, 54.0, 36.0, 26.0, 18.0, 47.0, 60.0, 22.0, 26.0, 35.0, 52.0, 47.0, 18.0, 37.0, 36.0, 20.0, 49.0, 26.0, 49.0, 24.0, 26.0, 41.5, 44.0, 35.0, 36.0, 30.0, 27.0, 22.0, 40.0, 39.0, 26.0, 18.0, 26.0, 35.0, 24.0, 34.0, 26.0, 4.0, 26.0, 27.0, 42.0, 20.0, 21.0, 21.0, 61.0, 57.0, 21.0, 26.0, 26.0, 80.0, 51.0, 32.0, 41.5, 9.0, 28.0, 32.0, 31.0, 41.0, 26.0, 20.0, 24.0, 2.0, 26.0, 0.75, 48.0, 19.0, 56.0, 26.0, 23.0, 26.0, 18.0, 21.0, 18.0, 18.0, 24.0, 26.0, 32.0, 23.0, 58.0, 50.0, 40.0, 47.0, 36.0, 20.0, 32.0, 25.0, 26.0, 43.0, 45.0, 40.0, 31.0, 70.0, 31.0, 30.0, 18.0, 24.5, 18.0, 43.0, 36.0, 18.0, 27.0, 20.0, 14.0, 60.0, 25.0, 14.0, 19.0, 18.0, 15.0, 31.0, 4.0, 26.0, 25.0, 60.0, 52.0, 44.0, 18.0, 49.0, 42.0, 18.0, 35.0, 18.0, 25.0, 26.0, 39.0, 45.0, 42.0, 22.0, 6.0, 24.0, 41.5, 48.0, 29.0, 52.0, 19.0, 38.0, 27.0, 26.0, 33.0, 6.0, 17.0, 34.0, 50.0, 27.0, 20.0, 30.0, 18.0, 25.0, 25.0, 29.0, 11.0, 30.0, 23.0, 23.0, 28.5, 48.0, 35.0, 26.0, 26.0, 41.5, 36.0, 21.0, 24.0, 31.0, 70.0, 16.0, 30.0, 19.0, 31.0, 4.0, 6.0, 33.0, 23.0, 48.0, 0.67, 28.0, 18.0, 34.0, 33.0, 26.0, 41.0, 20.0, 36.0, 16.0, 51.0, 51.0, 30.5, 26.0, 32.0, 24.0, 48.0, 57.0, 26.0, 54.0, 18.0, 26.0, 5.0, 26.0, 43.0, 13.0, 17.0, 29.0, 26.0, 25.0, 25.0, 18.0, 8.0, 1.0, 46.0, 26.0, 16.0, 18.0, 41.5, 25.0, 39.0, 49.0, 31.0, 30.0, 30.0, 34.0, 31.0, 11.0, 0.42, 27.0, 31.0, 39.0, 18.0, 39.0, 33.0, 26.0, 39.0, 35.0, 6.0, 30.5, 41.5, 23.0, 31.0, 43.0, 10.0, 52.0, 27.0, 38.0, 27.0, 2.0, 26.0, 26.0, 1.0, 26.0, 62.0, 15.0, 0.83, 26.0, 23.0, 18.0, 39.0, 21.0, 26.0, 32.0, 41.5, 20.0, 16.0, 30.0, 34.5, 17.0, 42.0, 26.0, 35.0, 28.0, 45.0, 4.0, 74.0, 9.0, 16.0, 44.0, 18.0, 45.0, 51.0, 24.0, 26.0, 41.0, 21.0, 48.0, 18.0, 24.0, 42.0, 27.0, 31.0, 26.0, 4.0, 26.0, 47.0, 33.0, 47.0, 28.0, 15.0, 20.0, 19.0, 26.0, 56.0, 25.0, 33.0, 22.0, 28.0, 25.0, 39.0, 27.0, 19.0, 18.0, 26.0, 32.0]}],\n                        {\"height\": 500, \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Association between Survived and Age (corr: -0.06, p: 0.07569)\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Survived</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Age</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('06ed7de7-9c79-419a-9886-a04230f09a5f');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 107,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 59,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"So the mean age of survivors should be just less than those who died (small negative correlation and reading boxplot). Calculate the mean age of survivors and victims.\"\"\"\nnumGroupedByCat(df_train.Age)",
            "mc_idx": 109,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    60,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"aaa3122a-366a-44b8-be3f-937130f8e738\" class=\"plotly-graph-div\" style=\"height:500px; width:900px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"aaa3122a-366a-44b8-be3f-937130f8e738\")) {\n                    Plotly.newPlot(\n                        'aaa3122a-366a-44b8-be3f-937130f8e738',\n                        [{\"hoverinfo\": \"x+y\", \"text\": [29.84, 28.18], \"textfont\": {\"family\": \"sans serif\", \"size\": 15}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"35a36412-c009-4046-b1f1-715be85c1526\", \"x\": [0.0, 1.0], \"y\": [29.84, 28.18]}],\n                        {\"height\": 500, \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"showlegend\": false, \"title\": {\"text\": \"Mean Age across Survived\"}, \"width\": 900, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Survived</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Mean Age</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('aaa3122a-366a-44b8-be3f-937130f8e738');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 109,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 60,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Histogram of survivors vs victims age.\"\"\"\nnumHistByCat(df_train.Age)",
            "mc_idx": 111,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c061_o000_image_3.png",
                    61,
                    0,
                    3
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x504 with 1 Axes>"
                    ]
                },
                "mc_idx": 111,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 61,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Perform ANOVA between all the levels of Survived (i.e., 0 and 1) and Age.\"\"\"\ncalculateAnova(df_train.Age)",
            "mc_idx": 113,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    62,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "'Anova Result between Age & Survived: f=> 3.162396652163441, p=> 0.07569419096180038'"
                    ]
                },
                "mc_idx": 113,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 62,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"#1.Create a function that calculates absolute and relative frequency of Survived variable by a categorical variable. And then plots the absolute and relative frequency of Survived by a categorical variable.\"\"\"\ndef calculateCrosstabulation(catVariable, targetCatVariable=df_train.Survived):\n    \"\"\" Plots cross tabulation in absolute and relative scale.\n    catVariable = input categorical variable, \n    targetCatVariable = our target categorical variable.\"\"\"\n    \n    # Calculate cross tabulation in abs and relative scale\n    absCount = pd.crosstab(index = catVariable, columns = targetCatVariable)\\\n    .rename(columns={0:\"Victims\",1:\"Survivors\"})\n    relCount = pd.crosstab(index = catVariable, columns = targetCatVariable, normalize=\"index\")\\\n    .rename(columns={0:\"Victims\",1:\"Survivors\"})*100\n    relCount = relCount.round(1)\n    \n    # Create two subplots of bar chart\n    fig=make_subplots(\n        rows=2, \n        cols=1,\n        vertical_spacing=0.3,\n        subplot_titles=(f\"Absolute Count of Survival and Death by {catVariable.name}\", \n                        f\"Percentage Count of Survival and Death by {catVariable.name}\"),\n        print_grid=False) # This suppresses \"This is the format of your plot grid:\" text from popping out.\n\n    # Add trace for absolute frequency\n    for col in absCount.columns:\n        fig.add_trace(go.Bar(x=absCount.index,\n                             y=absCount[col],\n                             text=absCount[col],\n                             hoverinfo=\"x+y\",\n                             textposition=\"auto\",\n                             name=f\"{col}\",\n                             textfont=dict(family=\"sans serif\",size=14),\n                             ),\n                     row=1,\n                     col=1\n                     )\n\n\n    # Add another trace for relative frequency\n    for col in relCount.columns:\n        fig.add_trace(go.Bar(x=relCount.index,\n                             y=relCount[col],\n                             text=relCount[col],\n                             hoverinfo=\"x+y\",\n                             textposition=\"auto\",\n                             name=f\"{col}\",\n                             textfont=dict(family=\"sans serif\",size=14),\n                            ),\n                     row=2,\n                     col=1\n                     )\n        \n    # Update the layout. Add title, dimension, and background color\n    fig.layout.update(\n        height=600, \n        width=1000,\n        hovermode=\"closest\",\n        barmode = \"group\",\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n\n    # Set y-axes titles in bold\n    fig.layout.yaxis1.update(title=\"<b>Abs Frequency</b>\")\n    fig.layout.yaxis2.update(title=\"<b>Rel Frequency(%)</b>\")\n    \n    # Set x-axis title in bold\n    fig.layout.xaxis2.update(title=f\"<b>{catVariable.name}</b>\")\n    return fig.show()\n\n    \n\"\"\"#2.Create a function to calculate chi square test between a categorical and target categorical variable.\"\"\"\ndef calculateChiSquare(catVariable, targetCatVariable=df_train.Survived):\n    \"\"\"Returns chi square test restult between independent and dependent target variables.\"\"\"\n    \n    catGroupedByCatTarget = pd.crosstab(index = catVariable, columns = targetCatVariable)\n    testResult = stats.chi2_contingency(catGroupedByCatTarget)\n    print(f\"Chi Square Test Result between {targetCatVariable.name} & {catVariable.name}:\")\n    return print(testResult)\n\n\n\"\"\"#3.Finally create another function to calculate Bonferroni-adjusted pvalue for a categorical and target categorical variable.\"\"\"\ndef calculateBonferroniAdjusted(catVariable, targetCatVariable=df_train.Survived):\n    \"\"\"Returns bonferroni-adjusted pvalue between independent and dependent target variables.\"\"\"\n    \n    # Create one hot encoding for the independent categorical variable\n    catEncoded = pd.get_dummies(catVariable)\n    for column in catEncoded.columns:\n        catGroupedByCatTarget = pd.crosstab(index = catEncoded[column], columns = targetCatVariable)\n        testResult = stats.chi2_contingency(catGroupedByCatTarget)\n        print(f\"Bonferroni-adjusted pvalue between {catVariable.name}({column}) and {targetCatVariable.name}:\")\n        print(f\"{testResult}\\n\")",
            "mc_idx": 115,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.4411764705882353,
                "Data_Transform": 0.29411764705882354,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.08823529411764706,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1,
                    "variable": 33
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".bar(": 2,
                    "info": 2,
                    "columns": 9,
                    "size": 2
                },
                "Data_Transform": {
                    ".cross": 4,
                    ".rename": 2,
                    ".get_dummies": 1,
                    ".add": 2,
                    ".round": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    ".bar(": 2,
                    "chart": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    63,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 115,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 63,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Plot the no of passergers who survived and died due to their sex in absolute and relative scale.\"\"\"\ncalculateCrosstabulation(df_train.Sex)",
            "mc_idx": 117,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    64,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"a18b3156-9af1-4d64-be89-21bcf52bc02b\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"a18b3156-9af1-4d64-be89-21bcf52bc02b\")) {\n                    Plotly.newPlot(\n                        'a18b3156-9af1-4d64-be89-21bcf52bc02b',\n                        [{\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [81.0, 468.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"41f856a7-bf8b-4ee5-9390-8e0062eda6f3\", \"x\": [\"female\", \"male\"], \"xaxis\": \"x\", \"y\": [81, 468], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [233.0, 109.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"aaa349a5-954d-4114-9491-32db757e3322\", \"x\": [\"female\", \"male\"], \"xaxis\": \"x\", \"y\": [233, 109], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [25.8, 81.1], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"25cff0d3-75f6-4e31-90d2-daf2a5423fe4\", \"x\": [\"female\", \"male\"], \"xaxis\": \"x2\", \"y\": [25.8, 81.1], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [74.2, 18.9], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"726fc11e-734f-4616-9b5b-d1ea4b58cfa3\", \"x\": [\"female\", \"male\"], \"xaxis\": \"x2\", \"y\": [74.2, 18.9], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Count of Survival and Death by Sex\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.9999999999999999, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Percentage Count of Survival and Death by Sex\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.35, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"barmode\": \"group\", \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"width\": 1000, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Sex</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.6499999999999999, 0.9999999999999999], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.35], \"title\": {\"text\": \"<b>Rel Frequency(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('a18b3156-9af1-4d64-be89-21bcf52bc02b');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 117,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 64,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Perform chi-square test of independence between Survived and Sex.\"\"\"\ncalculateChiSquare(df_train.Sex)",
            "mc_idx": 119,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    65,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Chi Square Test Result between Survived & Sex:\n(260.71702016732104, 1.1973570627755645e-58, 1, array([[193.47474747, 120.52525253],\n       [355.52525253, 221.47474747]]))\n"
                    ]
                },
                "mc_idx": 119,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 65,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Plot the number of passengers who survived and died due to their pclass in absolute and relative scale.\"\"\"\ncalculateCrosstabulation(df_train.Pclass)",
            "mc_idx": 121,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    66,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"96b57ebd-fdca-4b6b-a50e-277d1230232e\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"96b57ebd-fdca-4b6b-a50e-277d1230232e\")) {\n                    Plotly.newPlot(\n                        '96b57ebd-fdca-4b6b-a50e-277d1230232e',\n                        [{\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [80.0, 97.0, 372.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"2554fb76-d1c0-47f7-bc0d-90a2c780eeb7\", \"x\": [1, 2, 3], \"xaxis\": \"x\", \"y\": [80, 97, 372], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [136.0, 87.0, 119.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"5f66aeb1-4577-48fa-b587-e8750b82d657\", \"x\": [1, 2, 3], \"xaxis\": \"x\", \"y\": [136, 87, 119], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [37.0, 52.7, 75.8], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"d1d0fa20-0389-4cc6-96a3-27a26873a06b\", \"x\": [1, 2, 3], \"xaxis\": \"x2\", \"y\": [37.0, 52.7, 75.8], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [63.0, 47.3, 24.2], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"3752d256-1619-4e7a-a191-51f7b4e6723e\", \"x\": [1, 2, 3], \"xaxis\": \"x2\", \"y\": [63.0, 47.3, 24.2], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Count of Survival and Death by Pclass\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.9999999999999999, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Percentage Count of Survival and Death by Pclass\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.35, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"barmode\": \"group\", \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"width\": 1000, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Pclass</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.6499999999999999, 0.9999999999999999], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.35], \"title\": {\"text\": \"<b>Rel Frequency(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('96b57ebd-fdca-4b6b-a50e-277d1230232e');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 121,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 66,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Perform chi-square test of independence between Survived and Pclass.\"\"\"\ncalculateChiSquare(df_train.Pclass)",
            "mc_idx": 123,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    67,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Chi Square Test Result between Survived & Pclass:\n(102.88898875696056, 4.549251711298793e-23, 2, array([[133.09090909,  82.90909091],\n       [113.37373737,  70.62626263],\n       [302.53535354, 188.46464646]]))\n"
                    ]
                },
                "mc_idx": 123,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 67,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Calculate Bonferroni-adjusted pvalue for Pclass (1,2,3) and Survived.\"\"\"\ncalculateBonferroniAdjusted(df_train.Pclass)",
            "mc_idx": 125,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    68,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Bonferroni-adjusted pvalue between Pclass(1) and Survived:\n(71.46583854616047, 2.821002116713357e-17, 1, array([[415.90909091, 259.09090909],\n       [133.09090909,  82.90909091]]))\n\nBonferroni-adjusted pvalue between Pclass(2) and Survived:\n(7.2971925540056475, 0.006906243870048795, 1, array([[435.62626263, 271.37373737],\n       [113.37373737,  70.62626263]]))\n\nBonferroni-adjusted pvalue between Pclass(3) and Survived:\n(91.23179223158795, 1.277904920294387e-21, 1, array([[246.46464646, 153.53535354],\n       [302.53535354, 188.46464646]]))\n\n"
                    ]
                },
                "mc_idx": 125,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 68,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Count and plot the survivors and victims by place of embarkation in absolute and relative scale.\"\"\"\ncalculateCrosstabulation(df_train.Embarked)",
            "mc_idx": 127,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    69,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"eaa98b99-98ea-4ea2-a693-d16d16058dc9\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"eaa98b99-98ea-4ea2-a693-d16d16058dc9\")) {\n                    Plotly.newPlot(\n                        'eaa98b99-98ea-4ea2-a693-d16d16058dc9',\n                        [{\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [75.0, 47.0, 427.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"def30687-d5ca-4ee1-915d-26134dc5e6a6\", \"x\": [\"C\", \"Q\", \"S\"], \"xaxis\": \"x\", \"y\": [75, 47, 427], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [93.0, 30.0, 219.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"6da5fdf0-926f-49b2-b5ff-8e6ae52cbd8a\", \"x\": [\"C\", \"Q\", \"S\"], \"xaxis\": \"x\", \"y\": [93, 30, 219], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [44.6, 61.0, 66.1], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"e12e6997-d692-4f45-993b-d67e40cabd03\", \"x\": [\"C\", \"Q\", \"S\"], \"xaxis\": \"x2\", \"y\": [44.6, 61.0, 66.1], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [55.4, 39.0, 33.9], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"c482cf53-e213-42db-aa1f-f6608970fa49\", \"x\": [\"C\", \"Q\", \"S\"], \"xaxis\": \"x2\", \"y\": [55.4, 39.0, 33.9], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Count of Survival and Death by Embarked\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.9999999999999999, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Percentage Count of Survival and Death by Embarked\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.35, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"barmode\": \"group\", \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"width\": 1000, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Embarked</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.6499999999999999, 0.9999999999999999], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.35], \"title\": {\"text\": \"<b>Rel Frequency(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('eaa98b99-98ea-4ea2-a693-d16d16058dc9');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 127,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 69,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Now perform chi-square test to find the association between Embarked and Survived.\"\"\"\ncalculateChiSquare(df_train.Embarked)",
            "mc_idx": 129,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    70,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Chi Square Test Result between Survived & Embarked:\n(25.964452881874784, 2.3008626481449577e-06, 2, array([[103.51515152,  64.48484848],\n       [ 47.44444444,  29.55555556],\n       [398.04040404, 247.95959596]]))\n"
                    ]
                },
                "mc_idx": 129,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 70,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Calculate Bonferroni-adjusted pvalue  between Embarked (C,Q,S one by one) and Survived.\"\"\"\ncalculateBonferroniAdjusted(df_train.Embarked)",
            "mc_idx": 131,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    71,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Bonferroni-adjusted pvalue between Embarked(C) and Survived:\n(24.34294028991685, 8.062166851376562e-07, 1, array([[445.48484848, 277.51515152],\n       [103.51515152,  64.48484848]]))\n\nBonferroni-adjusted pvalue between Embarked(Q) and Survived:\n(0.00018551307377882246, 0.9891328942213099, 1, array([[501.55555556, 312.44444444],\n       [ 47.44444444,  29.55555556]]))\n\nBonferroni-adjusted pvalue between Embarked(S) and Survived:\n(19.279400244953347, 1.1291808110540787e-05, 1, array([[150.95959596,  94.04040404],\n       [398.04040404, 247.95959596]]))\n\n"
                    ]
                },
                "mc_idx": 131,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 71,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Count and plot absolute and relative number of survivors and victims due to SibSp.\"\"\"\ncalculateCrosstabulation(df_train.SibSp)",
            "mc_idx": 133,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    72,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"3af60cd9-1e4b-425e-aa5b-234f5192e9eb\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"3af60cd9-1e4b-425e-aa5b-234f5192e9eb\")) {\n                    Plotly.newPlot(\n                        '3af60cd9-1e4b-425e-aa5b-234f5192e9eb',\n                        [{\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [398.0, 97.0, 15.0, 12.0, 15.0, 5.0, 7.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"5a431ce7-ad3f-40c9-8903-b150d6f7d1cf\", \"x\": [0, 1, 2, 3, 4, 5, 8], \"xaxis\": \"x\", \"y\": [398, 97, 15, 12, 15, 5, 7], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [210.0, 112.0, 13.0, 4.0, 3.0, 0.0, 0.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"fbf06ef2-98f7-4ea9-9aa3-d05f19bb6597\", \"x\": [0, 1, 2, 3, 4, 5, 8], \"xaxis\": \"x\", \"y\": [210, 112, 13, 4, 3, 0, 0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [65.5, 46.4, 53.6, 75.0, 83.3, 100.0, 100.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"61593f05-8172-47f3-a316-3e4c480fae2c\", \"x\": [0, 1, 2, 3, 4, 5, 8], \"xaxis\": \"x2\", \"y\": [65.5, 46.4, 53.6, 75.0, 83.3, 100.0, 100.0], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [34.5, 53.6, 46.4, 25.0, 16.7, 0.0, 0.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"af7bdfa2-6ecc-4e61-ba96-6b59a1a503e9\", \"x\": [0, 1, 2, 3, 4, 5, 8], \"xaxis\": \"x2\", \"y\": [34.5, 53.6, 46.4, 25.0, 16.7, 0.0, 0.0], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Count of Survival and Death by SibSp\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.9999999999999999, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Percentage Count of Survival and Death by SibSp\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.35, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"barmode\": \"group\", \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"width\": 1000, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>SibSp</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.6499999999999999, 0.9999999999999999], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.35], \"title\": {\"text\": \"<b>Rel Frequency(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('3af60cd9-1e4b-425e-aa5b-234f5192e9eb');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 133,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 72,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Chi-square test between SibSp and Survived.\"\"\"\ncalculateChiSquare(df_train.SibSp)",
            "mc_idx": 135,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    73,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Chi Square Test Result between Survived & SibSp:\n(37.2717929152043, 1.5585810465902147e-06, 6, array([[374.62626263, 233.37373737],\n       [128.77777778,  80.22222222],\n       [ 17.25252525,  10.74747475],\n       [  9.85858586,   6.14141414],\n       [ 11.09090909,   6.90909091],\n       [  3.08080808,   1.91919192],\n       [  4.31313131,   2.68686869]]))\n"
                    ]
                },
                "mc_idx": 135,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 73,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Visualize absolute and relative number of survivors and victims by Parch.\"\"\"\ncalculateCrosstabulation(df_train.Parch)",
            "mc_idx": 137,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Visualization",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "visualize": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    74,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"47871508-6f80-4039-8ebf-66f27b659301\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"47871508-6f80-4039-8ebf-66f27b659301\")) {\n                    Plotly.newPlot(\n                        '47871508-6f80-4039-8ebf-66f27b659301',\n                        [{\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [445.0, 53.0, 40.0, 2.0, 4.0, 4.0, 1.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"70b22dee-7665-41e0-965f-63fb790beaad\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"xaxis\": \"x\", \"y\": [445, 53, 40, 2, 4, 4, 1], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [233.0, 65.0, 40.0, 3.0, 0.0, 1.0, 0.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"ce505159-d1d9-4ba1-be1e-6617417b8009\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"xaxis\": \"x\", \"y\": [233, 65, 40, 3, 0, 1, 0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [65.6, 44.9, 50.0, 40.0, 100.0, 80.0, 100.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"d161d978-bbe8-4ef2-ad77-a1fdcb52b180\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"xaxis\": \"x2\", \"y\": [65.6, 44.9, 50.0, 40.0, 100.0, 80.0, 100.0], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [34.4, 55.1, 50.0, 60.0, 0.0, 20.0, 0.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"7916b7ca-19aa-4815-80ae-c3f5a6d4028a\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"xaxis\": \"x2\", \"y\": [34.4, 55.1, 50.0, 60.0, 0.0, 20.0, 0.0], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Count of Survival and Death by Parch\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.9999999999999999, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Percentage Count of Survival and Death by Parch\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.35, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"barmode\": \"group\", \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"width\": 1000, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Parch</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.6499999999999999, 0.9999999999999999], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.35], \"title\": {\"text\": \"<b>Rel Frequency(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('47871508-6f80-4039-8ebf-66f27b659301');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 137,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 74,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Perform Chi-square test of independence between Parch and Survived.\"\"\"\ncalculateChiSquare(df_train.Parch)",
            "mc_idx": 139,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    75,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Chi Square Test Result between Survived & Parch:\n(27.925784060236168, 9.703526421039997e-05, 6, array([[4.17757576e+02, 2.60242424e+02],\n       [7.27070707e+01, 4.52929293e+01],\n       [4.92929293e+01, 3.07070707e+01],\n       [3.08080808e+00, 1.91919192e+00],\n       [2.46464646e+00, 1.53535354e+00],\n       [3.08080808e+00, 1.91919192e+00],\n       [6.16161616e-01, 3.83838384e-01]]))\n"
                    ]
                },
                "mc_idx": 139,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 75,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Visualize absolute and relative number of survivors and victims by nameProcessed.\"\"\"\ncalculateCrosstabulation(df_train.nameProcessed)",
            "mc_idx": 141,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Visualization",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "visualize": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    76,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"11498e74-08de-40e0-a377-3b1ef8d8d19b\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"11498e74-08de-40e0-a377-3b1ef8d8d19b\")) {\n                    Plotly.newPlot(\n                        '11498e74-08de-40e0-a377-3b1ef8d8d19b',\n                        [{\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [2.0, 17.0, 55.0, 436.0, 26.0, 13.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"413e46d6-8539-4d38-9b96-9fe3e66ca1b0\", \"x\": [\" Aristocrat\", \" Master\", \" Miss\", \" Mr\", \" Mrs\", \" Officer\"], \"xaxis\": \"x\", \"y\": [2, 17, 55, 436, 26, 13], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [3.0, 23.0, 130.0, 81.0, 100.0, 5.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"5e897e5f-ac6d-4750-9c06-000027023987\", \"x\": [\" Aristocrat\", \" Master\", \" Miss\", \" Mr\", \" Mrs\", \" Officer\"], \"xaxis\": \"x\", \"y\": [3, 23, 130, 81, 100, 5], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [40.0, 42.5, 29.7, 84.3, 20.6, 72.2], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"a65f232f-e514-4bb5-8bda-c5640dc9b28f\", \"x\": [\" Aristocrat\", \" Master\", \" Miss\", \" Mr\", \" Mrs\", \" Officer\"], \"xaxis\": \"x2\", \"y\": [40.0, 42.5, 29.7, 84.3, 20.6, 72.2], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [60.0, 57.5, 70.3, 15.7, 79.4, 27.8], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"94e5f80f-64e5-4502-86c9-5b46b12c7bf0\", \"x\": [\" Aristocrat\", \" Master\", \" Miss\", \" Mr\", \" Mrs\", \" Officer\"], \"xaxis\": \"x2\", \"y\": [60.0, 57.5, 70.3, 15.7, 79.4, 27.8], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Count of Survival and Death by nameProcessed\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.9999999999999999, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Percentage Count of Survival and Death by nameProcessed\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.35, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"barmode\": \"group\", \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"width\": 1000, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>nameProcessed</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.6499999999999999, 0.9999999999999999], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.35], \"title\": {\"text\": \"<b>Rel Frequency(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('11498e74-08de-40e0-a377-3b1ef8d8d19b');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 141,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 76,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Perform Chi-square test of independence between nameProcessed and Survived.\"\"\"\ncalculateChiSquare(df_train.nameProcessed)",
            "mc_idx": 143,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    77,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Chi Square Test Result between Survived & nameProcessed:\n(289.8360961873925, 1.5325912223703196e-60, 5, array([[  3.08080808,   1.91919192],\n       [ 24.64646465,  15.35353535],\n       [113.98989899,  71.01010101],\n       [318.55555556, 198.44444444],\n       [ 77.63636364,  48.36363636],\n       [ 11.09090909,   6.90909091]]))\n"
                    ]
                },
                "mc_idx": 143,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 77,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Plot the Survived's absolute and percentage count by familySize.\"\"\"\ncalculateCrosstabulation(df_train.familySize)",
            "mc_idx": 145,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    78,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"e97cd754-f971-4b78-bb0c-5677a5f3e737\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"e97cd754-f971-4b78-bb0c-5677a5f3e737\")) {\n                    Plotly.newPlot(\n                        'e97cd754-f971-4b78-bb0c-5677a5f3e737',\n                        [{\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [40.0, 20.0, 374.0, 115.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"c31c33da-f974-4a3c-baee-2c0dd18beec6\", \"x\": [\"large\", \"medium\", \"single\", \"small\"], \"xaxis\": \"x\", \"y\": [40, 20, 374, 115], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [7.0, 24.0, 163.0, 148.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"1b616278-aa5e-46ba-b40a-f5816c5b8a55\", \"x\": [\"large\", \"medium\", \"single\", \"small\"], \"xaxis\": \"x\", \"y\": [7, 24, 163, 148], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [85.1, 45.5, 69.6, 43.7], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"31637492-8722-48b5-8efb-ffcc4ab2c2e5\", \"x\": [\"large\", \"medium\", \"single\", \"small\"], \"xaxis\": \"x2\", \"y\": [85.1, 45.5, 69.6, 43.7], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [14.9, 54.5, 30.4, 56.3], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"eab0726b-c9b9-498b-a7d3-c38791f81128\", \"x\": [\"large\", \"medium\", \"single\", \"small\"], \"xaxis\": \"x2\", \"y\": [14.9, 54.5, 30.4, 56.3], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Count of Survival and Death by familySize\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.9999999999999999, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Percentage Count of Survival and Death by familySize\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.35, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"barmode\": \"group\", \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"width\": 1000, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>familySize</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.6499999999999999, 0.9999999999999999], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.35], \"title\": {\"text\": \"<b>Rel Frequency(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('e97cd754-f971-4b78-bb0c-5677a5f3e737');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 145,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 78,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Perform Chi-square test of independence between familySize and Survived.\"\"\"\ncalculateChiSquare(df_train.familySize)",
            "mc_idx": 147,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    79,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Chi Square Test Result between Survived & familySize:\n(66.05581680279249, 2.981870009647575e-14, 3, array([[ 28.95959596,  18.04040404],\n       [ 27.11111111,  16.88888889],\n       [330.87878788, 206.12121212],\n       [162.05050505, 100.94949495]]))\n"
                    ]
                },
                "mc_idx": 147,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 79,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Calculate Bonferroni-adjusted pvalue  between familySize and Survived.\"\"\"\ncalculateBonferroniAdjusted(df_train.familySize)",
            "mc_idx": 149,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    80,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Bonferroni-adjusted pvalue between familySize(large) and Survived:\n(10.55137053799774, 0.0011610196650239893, 1, array([[520.04040404, 323.95959596],\n       [ 28.95959596,  18.04040404]]))\n\nBonferroni-adjusted pvalue between familySize(medium) and Survived:\n(4.418221527178599, 0.03555707818485421, 1, array([[521.88888889, 325.11111111],\n       [ 27.11111111,  16.88888889]]))\n\nBonferroni-adjusted pvalue between familySize(single) and Survived:\n(36.00051446773865, 1.9726543846517113e-09, 1, array([[218.12121212, 135.87878788],\n       [330.87878788, 206.12121212]]))\n\nBonferroni-adjusted pvalue between familySize(small) and Survived:\n(49.42743388214718, 2.058468013374345e-12, 1, array([[386.94949495, 241.05050505],\n       [162.05050505, 100.94949495]]))\n\n"
                    ]
                },
                "mc_idx": 149,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 80,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Count and plot absolute and relative number of survivors and victims due to cabin possession.\"\"\"\ncalculateCrosstabulation(df_train.cabinProcessed)",
            "mc_idx": 151,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "session": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    81,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"ace67f98-4f66-43b5-ac3f-25c299b8fec4\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"ace67f98-4f66-43b5-ac3f-25c299b8fec4\")) {\n                    Plotly.newPlot(\n                        'ace67f98-4f66-43b5-ac3f-25c299b8fec4',\n                        [{\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [8.0, 12.0, 24.0, 8.0, 8.0, 5.0, 2.0, 1.0, 481.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"7d5e9c93-a345-49e9-bef8-26102e309f3c\", \"x\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"T\", \"X\"], \"xaxis\": \"x\", \"y\": [8, 12, 24, 8, 8, 5, 2, 1, 481], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [7.0, 35.0, 35.0, 25.0, 24.0, 8.0, 2.0, 0.0, 206.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"6d97fcc1-1798-4d79-9330-bb6cf23ed940\", \"x\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"T\", \"X\"], \"xaxis\": \"x\", \"y\": [7, 35, 35, 25, 24, 8, 2, 0, 206], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [53.3, 25.5, 40.7, 24.2, 25.0, 38.5, 50.0, 100.0, 70.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"2dcd5c9c-8022-4c77-802c-7727097d4068\", \"x\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"T\", \"X\"], \"xaxis\": \"x2\", \"y\": [53.3, 25.5, 40.7, 24.2, 25.0, 38.5, 50.0, 100.0, 70.0], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [46.7, 74.5, 59.3, 75.8, 75.0, 61.5, 50.0, 0.0, 30.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"72d47914-7b4c-4436-9b58-596db453c073\", \"x\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"T\", \"X\"], \"xaxis\": \"x2\", \"y\": [46.7, 74.5, 59.3, 75.8, 75.0, 61.5, 50.0, 0.0, 30.0], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Count of Survival and Death by cabinProcessed\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.9999999999999999, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Percentage Count of Survival and Death by cabinProcessed\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.35, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"barmode\": \"group\", \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"width\": 1000, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>cabinProcessed</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.6499999999999999, 0.9999999999999999], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.35], \"title\": {\"text\": \"<b>Rel Frequency(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('ace67f98-4f66-43b5-ac3f-25c299b8fec4');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 151,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 81,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Perform Chi-square test of independence between Cabin and Survived.\"\"\"\ncalculateChiSquare(df_train.cabinProcessed)",
            "mc_idx": 153,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    82,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Chi Square Test Result between Survived & cabinProcessed:\n(99.16416061888009, 6.326020042314704e-18, 8, array([[9.24242424e+00, 5.75757576e+00],\n       [2.89595960e+01, 1.80404040e+01],\n       [3.63535354e+01, 2.26464646e+01],\n       [2.03333333e+01, 1.26666667e+01],\n       [1.97171717e+01, 1.22828283e+01],\n       [8.01010101e+00, 4.98989899e+00],\n       [2.46464646e+00, 1.53535354e+00],\n       [6.16161616e-01, 3.83838384e-01],\n       [4.23303030e+02, 2.63696970e+02]]))\n"
                    ]
                },
                "mc_idx": 153,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 82,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Count and plot absolute and relative number of survivors and victims due to ticketProcessed category.\"\"\"\ncalculateCrosstabulation(df_train.ticketProcessed)",
            "mc_idx": 155,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    83,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"39f72251-7158-48b5-b74d-f8667e8749f0\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"39f72251-7158-48b5-b74d-f8667e8749f0\")) {\n                    Plotly.newPlot(\n                        '39f72251-7158-48b5-b74d-f8667e8749f0',\n                        [{\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [27.0, 31.0, 3.0, 3.0, 407.0, 23.0, 44.0, 11.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"6b9151aa-1b1a-4a2e-bbf2-dccb27c57cec\", \"x\": [\"A\", \"C\", \"F\", \"L\", \"N\", \"P\", \"S\", \"W\"], \"xaxis\": \"x\", \"y\": [27, 31, 3, 3, 407, 23, 44, 11], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [2.0, 16.0, 4.0, 1.0, 254.0, 42.0, 21.0, 2.0], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"f1af477d-d66c-4b30-8dfb-fc8d29b698d5\", \"x\": [\"A\", \"C\", \"F\", \"L\", \"N\", \"P\", \"S\", \"W\"], \"xaxis\": \"x\", \"y\": [2, 16, 4, 1, 254, 42, 21, 2], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Victims\", \"text\": [93.1, 66.0, 42.9, 75.0, 61.6, 35.4, 67.7, 84.6], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"09611d58-bbd5-42f0-8d92-b23606ba1f0e\", \"x\": [\"A\", \"C\", \"F\", \"L\", \"N\", \"P\", \"S\", \"W\"], \"xaxis\": \"x2\", \"y\": [93.1, 66.0, 42.9, 75.0, 61.6, 35.4, 67.7, 84.6], \"yaxis\": \"y2\"}, {\"hoverinfo\": \"x+y\", \"name\": \"Survivors\", \"text\": [6.9, 34.0, 57.1, 25.0, 38.4, 64.6, 32.3, 15.4], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"3d5243d6-bdc7-4152-98de-e6f2ecf6aea9\", \"x\": [\"A\", \"C\", \"F\", \"L\", \"N\", \"P\", \"S\", \"W\"], \"xaxis\": \"x2\", \"y\": [6.9, 34.0, 57.1, 25.0, 38.4, 64.6, 32.3, 15.4], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Absolute Count of Survival and Death by ticketProcessed\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.9999999999999999, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Percentage Count of Survival and Death by ticketProcessed\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.35, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"barmode\": \"group\", \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"width\": 1000, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>ticketProcessed</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.6499999999999999, 0.9999999999999999], \"title\": {\"text\": \"<b>Abs Frequency</b>\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.35], \"title\": {\"text\": \"<b>Rel Frequency(%)</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('39f72251-7158-48b5-b74d-f8667e8749f0');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 155,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 83,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Perform Chi-square test of independence between ticketProcessed and Survived.\"\"\"\ncalculateChiSquare(df_train.ticketProcessed)",
            "mc_idx": 157,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    84,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Chi Square Test Result between Survived & ticketProcessed:\n(36.7098892616397, 5.323006335674428e-06, 7, array([[ 17.86868687,  11.13131313],\n       [ 28.95959596,  18.04040404],\n       [  4.31313131,   2.68686869],\n       [  2.46464646,   1.53535354],\n       [407.28282828, 253.71717172],\n       [ 40.05050505,  24.94949495],\n       [ 40.05050505,  24.94949495],\n       [  8.01010101,   4.98989899]]))\n"
                    ]
                },
                "mc_idx": 157,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 84,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Create a function that plots the impact of 3 predictor variables at a time on a target variable.\"\"\"\ndef doMultivariateAnalysis(catVar1, catVar2, catVar3, targetCatVariable=df_train.Survived):\n    \"\"\"Plots the impact of 3 variables on Survived variable at the same time.\n    catVar1 = independent categorical variable 1,\n    catVar2 = independent categorical variable 2,\n    catVar3 = independent categorical variable 3.\n    targetCatVariable = our dependent categorical variable.\"\"\"\n    \n    fig,ax = plt.subplots(1,1,figsize = (18,5))\n    fontSize = 15\n    catGroupedByCatTarget = pd.crosstab(index = [catVar1, catVar2, catVar3],\n                                        columns = targetCatVariable, normalize = \"index\")*100\n    catGroupedByCatTarget.rename({0:\"%Died\", 1:\"%Survived\"}, axis = 1, inplace = True)\n    catGroupedByCatTarget.plot.bar(color = [\"red\", \"green\"],ax=ax)\n    ax.set_xlabel(f\"{catVar1.name},{catVar2.name},{catVar3.name}\", fontsize = fontSize)\n    ax.set_ylabel(\"Relative Frequency(%)\", fontsize = fontSize)\n    ax.tick_params(axis=\"x\", labelsize=fontSize)\n    ax.tick_params(axis=\"x\", labelsize=fontSize)\n    plt.legend(loc = \"best\")\n    return plt.show()",
            "mc_idx": 159,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.16666666666666666,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.16666666666666666,
                "Hyperparameter_Tuning": 0.16666666666666666,
                "Visualization": 0.08333333333333333,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1,
                    "variable": 11
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".bar(": 1,
                    "columns": 1,
                    "size": 10
                },
                "Data_Transform": {
                    ".cross": 1,
                    ".rename": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "impact": 2
                },
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {
                    ".bar(": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    85,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 159,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 85,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to pclass, sex, and cabinProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.cabinProcessed)\nbold(\"Findings: Sex male seems to be deciding factor for death.\")",
            "mc_idx": 161,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    86,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 161,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 86,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to pclass, sex, and embarked.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.Embarked)\nbold(\"Findings: Again Sex male seems to be deciding factor for death and female for survival.\")",
            "mc_idx": 163,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    87,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 163,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 87,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to pclass, sex, and SibSp.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.SibSp)\nbold(\"Findings: Bigger SibSp and male Sex is responsible more for death.\")",
            "mc_idx": 165,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    88,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 165,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 88,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to pclass, sex, and Parch.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.Parch)\nbold(\"indings: Bigger Parch and Sex male is responsible more for death.\")",
            "mc_idx": 167,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    89,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 167,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 89,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to pclass, sex, and nameProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.nameProcessed)\nbold(\"Findings: Findings: Passengers with sex male and title mr mostly died.\")",
            "mc_idx": 169,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    90,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 169,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 90,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to pclass, sex, and familySize.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.familySize)\nbold(\"Findings: Sex male, family size single and large greatly influence the death ratio.\")",
            "mc_idx": 171,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 3
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    91,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 171,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 91,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to pclass, sex, and ticketProcessed category.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.Sex, df_train.ticketProcessed)\nbold(\"Findings: Sex female, ticketProcessed p and w mostly survived.\")",
            "mc_idx": 173,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    92,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 173,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 92,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to pclass, nameProcessed, and cabinProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.Pclass, df_train.nameProcessed, df_train.cabinProcessed)\nbold(\"Findings: Title mrs, master and cabin x had best survival ratio.\")",
            "mc_idx": 175,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    93,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 175,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 93,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to familSize, sex, and cabinProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.familySize, df_train.Sex, df_train.cabinProcessed)\nbold(\"Findings: family size small, medium and sex female had best survival chance.\")",
            "mc_idx": 177,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 3
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    94,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 177,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 94,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to sex, nameProcessed, and familySize.\"\"\"\ndoMultivariateAnalysis(df_train.Sex, df_train.nameProcessed, df_train.familySize)\nbold(\"Findings: Title aristocrat, sex female and familySize small mostly survived.\")",
            "mc_idx": 179,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 3
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    95,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 179,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 95,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to sex, nameProcessed, and cabinProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.Sex, df_train.nameProcessed, df_train.cabinProcessed)\nbold(\"Findings: Title aristocrat, miss, mrs and sex female mostly survived.\")",
            "mc_idx": 181,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    96,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 181,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 96,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to sex, nameProcessed, and embarked.\"\"\"\ndoMultivariateAnalysis(df_train.Sex, df_train.nameProcessed, df_train.Embarked)\nbold(\"Findings: Embarked c, sex female and title master and aristocrat had best survival rate.\")",
            "mc_idx": 183,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    97,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 183,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 97,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Proportion of survivors and victims due to sex, nameProcessed, and ticketProcessed.\"\"\"\ndoMultivariateAnalysis(df_train.Sex, df_train.nameProcessed, df_train.ticketProcessed)\nbold(\"Findings: ticketProcessed n, w and sex male and title mr mostly died.\")",
            "mc_idx": 185,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    98,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<IPython.core.display.Markdown object>"
                    ]
                },
                "mc_idx": 185,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 98,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Create bin categories for Age.\"\"\"\nageGroups = [\"infant\",\"child\",\"teenager\",\"youngAdult\",\"adult\",\"aged\"]\n\n\"\"\"Create range for each bin categories of Age.\"\"\"\ngroupRanges = [0,5,12,18,35,60,81]\n\n\"\"\"Create and view categorized Age with original Age.\"\"\"\nmerged[\"ageBinned\"] = pd.cut(merged.Age, groupRanges, labels = ageGroups)\nbold('**Age with Categorized Age:**')\ndisplay(merged[['Age', 'ageBinned']].head(2))",
            "mc_idx": 187,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.6666666666666666,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".cut(": 1,
                    ".cut": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    99,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "    Age   ageBinned\n0  22.0  youngAdult\n1  38.0       adult"
                    ]
                },
                "mc_idx": 187,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 99,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Create bin categories for Fare.\"\"\"\nfareGroups = [\"low\",\"medium\",\"high\",\"veryHigh\"]\n\n\"\"\"Create range for each bin categories of Fare.\"\"\"\nfareGroupRanges = [-1, 130, 260, 390, 520]\n\n\"\"\"Create and view categorized Fare with original Fare.\"\"\"\nmerged[\"fareBinned\"] = pd.cut(merged.Fare, fareGroupRanges, labels = fareGroups)\nbold(\"Fare with Categorized Fare:\")\ndisplay(merged[[\"Fare\", \"fareBinned\"]].head(2))",
            "mc_idx": 189,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.6666666666666666,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".cut(": 1,
                    ".cut": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    100,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "      Fare fareBinned\n0   7.2500        low\n1  71.2833        low"
                    ]
                },
                "mc_idx": 189,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 100,
                "o_idx": 1
            }
        },
        {
            "source": "display(merged.head(2))",
            "mc_idx": 191,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    101,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived    ...       ageBinned fareBinned\n0            1       0.0    ...      youngAdult        low\n1            2       1.0    ...           adult        low\n\n[2 rows x 18 columns]"
                    ]
                },
                "mc_idx": 191,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 101,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Let's see all the variables we currently have with their category.\"\"\"\ndisplay(merged.head(2))\n\n\"\"\"Drop the features that would not be useful anymore.\"\"\"\nmerged.drop(columns = [\"Name\", \"Age\", \"Fare\", \"Ticket\", \"Cabin\"], inplace = True, axis = 1)\n\n\"\"\"Features after dropping.\"\"\"\nbold(\"Features Remaining after Dropping:\")\ndisplay(merged.columns)",
            "mc_idx": 192,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.2,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    "columns": 2,
                    ".head": 1
                },
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    102,
                    2,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived    ...       ageBinned fareBinned\n0            1       0.0    ...      youngAdult        low\n1            2       1.0    ...           adult        low\n\n[2 rows x 18 columns]",
                        "<IPython.core.display.Markdown object>",
                        "Index(['PassengerId', 'Survived', 'Pclass', 'Sex', 'SibSp', 'Parch',\n       'Embarked', 'cabinProcessed', 'nameProcessed', 'familySize',\n       'ticketProcessed', 'ageBinned', 'fareBinned'],\n      dtype='object')"
                    ]
                },
                "mc_idx": 192,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 102,
                "o_idx": 2
            }
        },
        {
            "source": "\"\"\"Checking current data types.\"\"\"\nbold(\"Current Variable Data Types:\")\ndisplay(merged.dtypes)",
            "mc_idx": 194,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "dtypes": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    103,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "PassengerId           int64\nSurvived            float64\nPclass                int64\nSex                  object\nSibSp                 int64\nParch                 int64\nEmbarked             object\ncabinProcessed       object\nnameProcessed        object\nfamilySize           object\nticketProcessed      object\nageBinned          category\nfareBinned         category\ndtype: object"
                    ]
                },
                "mc_idx": 194,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 103,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Correcting data types, converting into categorical variables.\"\"\"\nmerged.loc[:, [\"Pclass\", \"Sex\", \"Embarked\", \"cabinProcessed\", \"nameProcessed\", \"familySize\", \"ticketProcessed\"]]\\\n= merged.loc[:, [\"Pclass\", \"Sex\", \"Embarked\", \"cabinProcessed\", \"nameProcessed\", \"familySize\", \"ticketProcessed\"]]\\\n.astype('category')",
            "mc_idx": 196,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.5,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 2
                },
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    104,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 196,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 104,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Check if data types have been corrected.\"\"\"\nbold(\"Data Types after Correction:\")\ndisplay(merged.dtypes)",
            "mc_idx": 197,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "dtypes": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    105,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "PassengerId           int64\nSurvived            float64\nPclass             category\nSex                category\nSibSp                 int64\nParch                 int64\nEmbarked           category\ncabinProcessed     category\nnameProcessed      category\nfamilySize         category\nticketProcessed    category\nageBinned          category\nfareBinned         category\ndtype: object"
                    ]
                },
                "mc_idx": 197,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 105,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Convert categorical data into numeric to feed our machine learning model.\"\"\"\nmerged = pd.get_dummies(merged)\n\n\"\"\"Let's visualize the updated dataset that would be fed to our machine learning algorithms.\"\"\"\nbold(\"Preview of Processed Data:\")\ndisplay(merged.head(2))",
            "mc_idx": 199,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.3333333333333333,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.6666666666666666,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 0.3333333333333333,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.3333333333333333,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "dataset": 1
                },
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".get_dummies": 1
                },
                "Model_Train": {
                    "learning algorithm": 1,
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "visualize": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    106,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "   PassengerId         ...           fareBinned_veryHigh\n0            1         ...                             0\n1            2         ...                             0\n\n[2 rows x 49 columns]"
                    ]
                },
                "mc_idx": 199,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 106,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Set a seed for reproducibility\"\"\"\nseed = 43\n\n\"\"\"Let's split the train and test set to feed machine learning algorithm.\"\"\"\ntrain = merged.iloc[:891, :]\ntest  = merged.iloc[891:, :]",
            "mc_idx": 201,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "learning algorithm": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    107,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 201,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 107,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Drop passengerid from train set and Survived from test set.\"\"\"\ntrain = train.drop(columns = [\"PassengerId\"], axis = 1)\ntrain.Survived = train.Survived.astype(int) # Converts Survived to int requored for submission, otherwise\ntest = test.drop(columns = [\"Survived\"], axis = 1) # you will scored 0 on submission.",
            "mc_idx": 202,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.6666666666666666,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 2
                },
                "Data_Transform": {
                    ".astype(": 1,
                    ".drop": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    108,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 202,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 108,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Extract data sets as input and output for machine learning models.\"\"\"\nxTrain = train.drop(columns = [\"Survived\"], axis = 1) # Input matrix as pandas dataframe (dim:891*47).\nyTrain = train['Survived'] # Output vector as pandas series (dim:891*1)\n\n\"\"\"Extract test set\"\"\"\nxTest  = test.drop(\"PassengerId\", axis = 1).copy()",
            "mc_idx": 203,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 1.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "extract": 2
                },
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {
                    ".drop": 2
                },
                "Model_Train": {
                    "model": 1,
                    "learning models": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    109,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 203,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 109,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"See the dimensions of input and output data set.\"\"\"\nprint(f\"Input Matrix Dimension: {xTrain.shape}\")\nprint(f\"Output Vector Dimension: {yTrain.shape}\")\nprint(f\"Test Data Dimension: {xTest.shape}\")",
            "mc_idx": 204,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "shape": 3
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    110,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Input Matrix Dimension: (891, 47)\nOutput Vector Dimension: (891,)\nTest Data Dimension: (418, 47)\n"
                    ]
                },
                "mc_idx": 204,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 110,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Building machine learning models: \nWe will try 10 different classifiers to find the best classifier after tunning model's hyperparameters that will best generalize the unseen(test) data.\"\"\"\n\n\"\"\"Now initialize all the classifiers object.\"\"\"\n\"\"\"#1.Logistic Regression\"\"\"\nlr = LogisticRegression()\n\n\"\"\"#2.Support Vector Machines\"\"\"\nsvc = SVC(gamma = \"auto\")\n\n\"\"\"#3.Random Forest Classifier\"\"\"\nrf = RandomForestClassifier(random_state = seed, n_estimators = 100)\n\n\"\"\"#4.KNN\"\"\"\nknn = KNeighborsClassifier()\n\n\"\"\"#5.Gaussian Naive Bayes\"\"\"\ngnb = GaussianNB()\n\n\"\"\"#6.Decision Tree Classifier\"\"\"\ndt = DecisionTreeClassifier(random_state = seed)\n\n\"\"\"#7.Gradient Boosting Classifier\"\"\"\ngbc = GradientBoostingClassifier(random_state = seed)\n\n\"\"\"#8.Adaboost Classifier\"\"\"\nabc = AdaBoostClassifier(random_state = seed)\n\n\"\"\"#9.ExtraTrees Classifier\"\"\"\netc = ExtraTreesClassifier(random_state = seed)\n\n\"\"\"#10.Extreme Gradient Boosting\"\"\"\nxgbc = XGBClassifier(random_state = seed)\n\n\n\"\"\"List of all the models with their indices.\"\"\"\nmodelNames = [\"LR\", \"SVC\", \"RF\", \"KNN\", \"GNB\", \"DT\", \"GBC\", \"ABC\", \"ETC\", \"XGBC\"]\nmodels = [lr, svc, rf, knn, gnb, dt, gbc, abc, etc, xgbc]",
            "mc_idx": 206,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.05555555555555555,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.2777777777777778,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.16666666666666666,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".log": 1
                },
                "Model_Train": {
                    "model": 5,
                    "randomforestclassifier": 2,
                    "learning models": 1,
                    "logisticregression": 1,
                    "gradientboostingclassifier": 1,
                    "decisiontreeclassifier": 1,
                    "kneighborsclassifier": 1,
                    "svc": 4,
                    "gaussiannb": 1,
                    "adaboostclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 5
                },
                "Model_Interpretation": {
                    "model": 5,
                    "gradient": 3,
                    ".gradient": 1
                },
                "Hyperparameter_Tuning": {
                    "param": 1,
                    "hyperparameter": 1,
                    "hyperparameters": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    111,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 206,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 111,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Create a function that returns train accuracy of different models.\"\"\"\ndef calculateTrainAccuracy(model):\n    \"\"\"Returns training accuracy of a model.\"\"\"\n    \n    model.fit(xTrain, yTrain)\n    trainAccuracy = model.score(xTrain, yTrain)\n    trainAccuracy = round(trainAccuracy*100, 2)\n    return trainAccuracy\n\n# Calculate train accuracy of all the models and store them in a dataframe\nmodelScores = list(map(calculateTrainAccuracy, models))\ntrainAccuracy = pd.DataFrame(modelScores, columns = [\"trainAccuracy\"], index=modelNames)\ntrainAccuracySorted = trainAccuracy.sort_values(by=\"trainAccuracy\", ascending=False)\nbold(\"Training Accuracy of the Classifiers:\")\ndisplay(trainAccuracySorted)",
            "mc_idx": 207,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.08333333333333333,
                "Data_Transform": 0.08333333333333333,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.9166666666666666,
                "Model_Interpretation": 0.8333333333333334,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.08333333333333333,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {
                    "model.fit": 1,
                    ".fit(": 1,
                    "model": 10
                },
                "Model_Evaluation": {
                    "model": 10,
                    ".score(": 1
                },
                "Model_Interpretation": {
                    "model": 10
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    "store": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    112,
                    2,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning:\n\nThe default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n\n",
                        "<IPython.core.display.Markdown object>",
                        "      trainAccuracy\nRF            90.91\nDT            90.91\nETC           90.91\nGBC           86.64\nXGBC          86.31\nKNN           85.30\nLR            84.06\nABC           84.06\nSVC           83.05\nGNB           80.02"
                    ]
                },
                "mc_idx": 207,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 112,
                "o_idx": 2
            }
        },
        {
            "source": "\"\"\"Create a function that returns mean cross validation score for different models.\"\"\"\ndef calculateXValScore(model):\n    \"\"\"Returns models' cross validation scores.\"\"\"\n    \n    xValScore = cross_val_score(model, xTrain, yTrain, cv = 10, scoring=\"accuracy\").mean()\n    xValScore = round(xValScore*100, 2)\n    return xValScore\n\n# Calculate cross validation scores of all the models and store them in a dataframe\nmodelScores = list(map(calculateXValScore, models))\nxValScores = pd.DataFrame(modelScores, columns = [\"xValScore\"], index=modelNames)\nxValScoresSorted = xValScores.sort_values(by=\"xValScore\", ascending=False)\nbold(\"Models 10-fold Cross Validation Score:\")\ndisplay(xValScoresSorted)",
            "mc_idx": 209,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2727272727272727,
                "Data_Transform": 0.09090909090909091,
                "Model_Train": 0.9090909090909091,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.9090909090909091,
                "Hyperparameter_Tuning": 0.09090909090909091,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.09090909090909091,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    "columns": 1,
                    ".mean": 1
                },
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {
                    "model": 10
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    "model": 10
                },
                "Model_Interpretation": {
                    "model": 10
                },
                "Hyperparameter_Tuning": {
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    "store": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    113,
                    2,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "<IPython.core.display.Markdown object>",
                        "      xValScore\nLR        82.72\nGBC       82.72\nSVC       82.71\nXGBC      82.27\nKNN       81.61\nABC       81.48\nRF        81.15\nDT        80.26\nETC       80.03\nGNB       77.69"
                    ]
                },
                "mc_idx": 209,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 113,
                "o_idx": 2
            }
        },
        {
            "source": "\"\"\"Define all the models\" hyperparameters one by one first::\"\"\"\n\n\"\"\"Define hyperparameters the logistic regression will be tuned with. For LR, the following hyperparameters are usually tunned.\"\"\"\nlrParams = {\"penalty\":[\"l1\", \"l2\"],\n            \"C\": np.logspace(0, 4, 10),\n            \"max_iter\":[5000]}\n\n\"\"\"For GBC, the following hyperparameters are usually tunned.\"\"\"\ngbcParams = {\"learning_rate\": [0.01, 0.02, 0.05, 0.01],\n              \"max_depth\": [4, 6, 8],\n              \"max_features\": [1.0, 0.3, 0.1], \n              \"min_samples_split\": [ 2, 3, 4],\n              \"random_state\":[seed]}\n\n\"\"\"For SVC, the following hyperparameters are usually tunned.\"\"\"\nsvcParams = {\"C\": np.arange(6,13), \n              \"kernel\": [\"linear\",\"rbf\"],\n              \"gamma\": [0.5, 0.2, 0.1, 0.001, 0.0001]}\n\n\"\"\"For DT, the following hyperparameters are usually tunned.\"\"\"\ndtParams = {\"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n             \"min_samples_split\": np.arange(2,16), \n             \"min_samples_leaf\":np.arange(1,12),\n             \"random_state\":[seed]}\n\n\"\"\"For RF, the following hyperparameters are usually tunned.\"\"\"\nrfParams = {\"criterion\":[\"gini\",\"entropy\"],\n             \"n_estimators\":[10, 15, 20, 25, 30],\n             \"min_samples_leaf\":[1, 2, 3],\n             \"min_samples_split\":np.arange(3,8), \n             \"max_features\":[\"sqrt\", \"auto\", \"log2\"],\n             \"random_state\":[44]}\n\n\"\"\"For KNN, the following hyperparameters are usually tunned.\"\"\"\nknnParams = {\"n_neighbors\":np.arange(3,9),\n              \"leaf_size\":[1, 2, 3, 5],\n              \"weights\":[\"uniform\", \"distance\"],\n              \"algorithm\":[\"auto\", \"ball_tree\",\"kd_tree\",\"brute\"]}\n\n\"\"\"For ABC, the following hyperparameters are usually tunned.\"\"\"\nabcParams = {\"n_estimators\":[1, 5, 10, 15, 20, 25, 40, 50, 60, 80, 100, 130, 160, 200, 250, 300],\n              \"learning_rate\":[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5],\n              \"random_state\":[seed]}\n\n\"\"\"For ETC, the following hyperparameters are usually tunned.\"\"\"\netcParams = {\"max_depth\":[None],\n              \"max_features\":[1, 3, 10],\n              \"min_samples_split\":[2, 3, 10],\n              \"min_samples_leaf\":[1, 3, 10],\n              \"bootstrap\":[False],\n              \"n_estimators\":[100, 300],\n              \"criterion\":[\"gini\"], \n              \"random_state\":[seed]}\n\n\"\"\"For XGBC, the following hyperparameters are usually tunned.\"\"\"\nxgbcParams = {\"n_estimators\": (150, 250, 350, 450, 550, 650, 700, 800, 850, 1000),\n              \"learning_rate\": (0.01, 0.6),\n              \"subsample\": (0.3, 0.9),\n              \"max_depth\": np.arange(3,10),\n              \"colsample_bytree\": (0.5, 0.9),\n              \"min_child_weight\": [1, 2, 3, 4],\n              \"random_state\":[seed]}",
            "mc_idx": 211,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.023809523809523808,
                "Data_Transform": 0.023809523809523808,
                "Model_Train": 0.07142857142857142,
                "Model_Evaluation": 0.023809523809523808,
                "Model_Interpretation": 0.023809523809523808,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {
                    ".log": 1
                },
                "Model_Train": {
                    "model": 1,
                    "svc": 2
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {
                    "param": 20,
                    "hyperparameter": 11,
                    "hyperparameters": 11
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    114,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 211,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 114,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Create a function to tune hyperparameters of the selected models.\"\"\"\ndef tuneHyperparameters(model, params):\n    \"\"\"Returns best score of a model and its corresponding hyperparameters.\n    model = model to be optimized.\n    params = hyperparameters the models will be optimized with.\"\"\"\n    \n    # Construct grid search object with 10 fold cross validation.\n    gridSearch = GridSearchCV(model, params, verbose=0, cv=10, scoring=\"accuracy\", n_jobs = -1)\n    # Fit using grid search.\n    gridSearch.fit(xTrain, yTrain)\n    bestParams, bestScore = gridSearch.best_params_, round(gridSearch.best_score_*100, 2)\n    return bestScore, bestParams",
            "mc_idx": 212,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.36363636363636365,
                "Model_Evaluation": 0.3181818181818182,
                "Model_Interpretation": 0.3181818181818182,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "model": 7
                },
                "Model_Evaluation": {
                    "model": 7
                },
                "Model_Interpretation": {
                    "model": 7
                },
                "Hyperparameter_Tuning": {
                    "gridsearchcv": 3,
                    "tune hyperparameters": 1,
                    "param": 10,
                    "hyperparameter": 4,
                    "hyperparameters": 4
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    115,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 212,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 115,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Due to computational restrictions, I won't optimise xgbc's hyperparameters.\"\"\"\nmodelNamesToTune = [x for x in modelNames if x not in [\"GNB\",\"XGBC\"]]\nmodelsToTune = [lr, svc, rf, knn, dt, gbc, abc, etc]\nparametersLists = [lrParams, svcParams, rfParams, knnParams, dtParams, gbcParams, abcParams, etcParams]\nbestScoreAndHyperparameters = list(map(tuneHyperparameters, modelsToTune, parametersLists))",
            "mc_idx": 214,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.3157894736842105,
                "Model_Evaluation": 0.21052631578947367,
                "Model_Interpretation": 0.21052631578947367,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 4,
                    "svc": 2
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4
                },
                "Hyperparameter_Tuning": {
                    "param": 13,
                    "hyperparameter": 3,
                    "hyperparameters": 3
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    116,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning:\n\nThe default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n\n"
                    ]
                },
                "mc_idx": 214,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 116,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Let's create a dataframe to store best score and best params.\"\"\"\nbestScoreAndHyperparameters = pd.DataFrame(bestScoreAndHyperparameters,\n                                             index=modelNamesToTune,\n                                             columns=[\"tunedAccuracy\", \"bestHyperparameters\"])\nbestScoreAndHyperparametersSorted = bestScoreAndHyperparameters.sort_values(by=\"tunedAccuracy\",\n                                                                                ascending=False)\nbold(\"Model's Accuracy after Tuning Hyperparameters:\")\ndisplay(bestScoreAndHyperparametersSorted.iloc[:,0].to_frame())",
            "mc_idx": 215,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.045454545454545456,
                "Data_Transform": 0.045454545454545456,
                "Model_Train": 0.09090909090909091,
                "Model_Evaluation": 0.09090909090909091,
                "Model_Interpretation": 0.09090909090909091,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.045454545454545456,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {
                    "model": 2
                },
                "Model_Evaluation": {
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {
                    "param": 8,
                    "hyperparameter": 7,
                    "hyperparameters": 7
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    "store": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    117,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "     tunedAccuracy\nRF           84.40\nGBC          83.95\nETC          83.50\nABC          83.39\nSVC          83.28\nLR           82.94\nKNN          82.94\nDT           81.37"
                    ]
                },
                "mc_idx": 215,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 117,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Let's check out LR separately.\"\"\"\nprint(f\"LR Best Score: {bestScoreAndHyperparametersSorted.loc['LR'][0]}\")\nprint(f\"And Best Parameters: {bestScoreAndHyperparametersSorted.loc['LR'][1]}\")",
            "mc_idx": 216,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 3,
                    "hyperparameter": 2,
                    "hyperparameters": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    118,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "LR Best Score: 82.94\nAnd Best Parameters: {'C': 2.7825594022071245, 'max_iter': 5000, 'penalty': 'l1'}\n"
                    ]
                },
                "mc_idx": 216,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 118,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Create a function that compares cross validation scores with tunned scores for different models by\nplotting them.\"\"\"\ndef compareModelsAccuracy():\n    \"\"\"Returns a stack bar chart of tuned and x validation scores of models.\"\"\"\n    \n    # Sort by index and converting to series object to plot.\n    xValScore = xValScoresSorted[~xValScoresSorted.index.isin([\"XGBC\",\"GNB\"])].sort_index().T.squeeze()\n    tunedScore = bestScoreAndHyperparametersSorted.iloc[:,0].sort_index().T.squeeze()\n    \n    # Create two subplots of stack bar chart\n    fig=make_subplots(\n        rows=1, \n        cols=1,\n        vertical_spacing=0.3,\n        print_grid=False) # This suppresses \"This is the format of your plot grid:\" text from popping out.\n\n    # Add trace for stack bar\n    fig.add_trace(go.Bar(x=xValScore.index,\n                             y=xValScore,\n                             text=xValScore,\n                             hoverinfo=\"x+y\",\n                             textposition=\"auto\",\n                             name=\"xValScore\",\n                             textfont=dict(family=\"sans serif\",size=14),\n                             ),\n                     row=1,\n                     col=1\n                     )\n\n    # Add another trace for stack bar\n    fig.add_trace(go.Bar(x=tunedScore.index,\n                             y=tunedScore,\n                             text=tunedScore,\n                             hoverinfo=\"x+y\",\n                             textposition=\"auto\",\n                             name=\"tunedScores\",\n                             textfont=dict(family=\"sans serif\",size=14),\n                             ),\n                     row=1,\n                     col=1\n                     )\n        \n    # Update the layout. Add title, dimension, and background color\n    fig.layout.update(\n        height=600, \n        width=950,\n        hovermode=\"closest\",\n        barmode = \"stack\",\n        title_text = \"Cross Vaidation Scores vs Optimized Scores\",\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n\n    # Set y-axis titles in bold\n    fig.layout.yaxis1.update(title=\"<b>%Accuracy</b>\")\n    \n    # Set x-axis title in bold\n    fig.layout.xaxis1.update(title=\"<b>Models</b>\")\n    return fig.show()\n\n\"\"\"Call the function to plot the scores.\"\"\"\ncompareModelsAccuracy()",
            "mc_idx": 219,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.1111111111111111,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.6666666666666666,
                "Data_Transform": 1.0,
                "Model_Train": 0.5555555555555556,
                "Model_Evaluation": 0.5555555555555556,
                "Model_Interpretation": 0.5555555555555556,
                "Hyperparameter_Tuning": 0.3333333333333333,
                "Visualization": 0.4444444444444444,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".bar(": 2,
                    "info": 2,
                    "size": 2
                },
                "Data_Transform": {
                    "stack": 5,
                    ".sort_index": 2,
                    ".add": 2
                },
                "Model_Train": {
                    "model": 5
                },
                "Model_Evaluation": {
                    "model": 5
                },
                "Model_Interpretation": {
                    "model": 5
                },
                "Hyperparameter_Tuning": {
                    "param": 1,
                    "hyperparameter": 1,
                    "hyperparameters": 1
                },
                "Visualization": {
                    ".bar(": 2,
                    "chart": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    119,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"bd5d9db6-7af1-4518-bb34-98a18c2a1f09\" class=\"plotly-graph-div\" style=\"height:600px; width:950px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"bd5d9db6-7af1-4518-bb34-98a18c2a1f09\")) {\n                    Plotly.newPlot(\n                        'bd5d9db6-7af1-4518-bb34-98a18c2a1f09',\n                        [{\"hoverinfo\": \"x+y\", \"name\": \"xValScore\", \"text\": [81.48, 80.26, 80.03, 82.72, 81.61, 82.72, 81.15, 82.71], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"26beac71-2583-4be5-bc8f-5e86a8039049\", \"x\": [\"ABC\", \"DT\", \"ETC\", \"GBC\", \"KNN\", \"LR\", \"RF\", \"SVC\"], \"xaxis\": \"x\", \"y\": [81.48, 80.26, 80.03, 82.72, 81.61, 82.72, 81.15, 82.71], \"yaxis\": \"y\"}, {\"hoverinfo\": \"x+y\", \"name\": \"tunedScores\", \"text\": [83.39, 81.37, 83.5, 83.95, 82.94, 82.94, 84.4, 83.28], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"645600d8-c59e-415a-accf-130661c0d98e\", \"x\": [\"ABC\", \"DT\", \"ETC\", \"GBC\", \"KNN\", \"LR\", \"RF\", \"SVC\"], \"xaxis\": \"x\", \"y\": [83.39, 81.37, 83.5, 83.95, 82.94, 82.94, 84.4, 83.28], \"yaxis\": \"y\"}],\n                        {\"barmode\": \"stack\", \"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"title\": {\"text\": \"Cross Vaidation Scores vs Optimized Scores\"}, \"width\": 950, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Models</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>%Accuracy</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('bd5d9db6-7af1-4518-bb34-98a18c2a1f09');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 219,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 119,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Instantiate the models with optimized hyperparameters.\"\"\"\n# Sort the dataframe by index and select bestHyperparameters column\ntunedParams = bestScoreAndHyperparametersSorted.sort_index().loc[:,\"bestHyperparameters\"]\nabc = AdaBoostClassifier(**tunedParams[\"ABC\"])\ndt  = DecisionTreeClassifier(**tunedParams[\"DT\"])\netc = ExtraTreesClassifier(**tunedParams[\"ETC\"])\ngbc = GradientBoostingClassifier(**tunedParams[\"GBC\"])\nknn = KNeighborsClassifier(**tunedParams[\"KNN\"])\nlr  = LogisticRegression(**tunedParams[\"LR\"])\nrf  = RandomForestClassifier(**tunedParams[\"RF\"])\nsvc = SVC(**tunedParams[\"SVC\"])\n\n\n\n\"\"\"Train all the models with optimised hyperparameters.\"\"\"\nmodels = [abc, dt, etc, gbc, knn, lr, rf, svc]\nmodelNames = tunedParams.index.values\nkeyValue = dict(zip(modelNames, models))\nbold(\"10-fold Cross Validation after Optimization:\")\nxValScore = []\nfor key, value in keyValue.items():\n    # Train the models with optimized parameters using cross validation.\n    # No need to fit the data. cross_val_score does that for us.\n    # But we need to fit train data for prediction in the follow session.\n    value.fit(xTrain, yTrain)\n    scores = cross_val_score(value, xTrain, yTrain, cv = 10, scoring=\"accuracy\")*100\n    xValScore.append(scores.mean())\n    print(\"Mean Accuracy: {:.4f} (+/- {:.4f}) [{}]\".format(scores.mean(), scores.std(), key))",
            "mc_idx": 221,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Hyperparameter_Tuning",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.03571428571428571,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.21428571428571427,
                "Data_Transform": 0.03571428571428571,
                "Model_Train": 0.6785714285714286,
                "Model_Evaluation": 0.32142857142857145,
                "Model_Interpretation": 0.2857142857142857,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "session": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 2,
                    ".std(": 1,
                    ".mean": 2,
                    ".std": 1
                },
                "Data_Transform": {
                    ".sort_index": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "model": 7,
                    "randomforestclassifier": 2,
                    "logisticregression": 1,
                    "gradientboostingclassifier": 1,
                    "decisiontreeclassifier": 1,
                    "kneighborsclassifier": 1,
                    "svc": 4,
                    "adaboostclassifier": 1
                },
                "Model_Evaluation": {
                    "cross_val_score": 2,
                    "model": 7
                },
                "Model_Interpretation": {
                    "model": 7,
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {
                    "param": 16,
                    "hyperparameter": 5,
                    "hyperparameters": 5,
                    "cross_val_score": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    120,
                    3,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "Mean Accuracy: 83.3929 (+/- 2.6246) [ABC]\nMean Accuracy: 81.3741 (+/- 3.2704) [DT]\nMean Accuracy: 83.5103 (+/- 4.1688) [ETC]\nMean Accuracy: 83.9535 (+/- 3.1242) [GBC]\nMean Accuracy: 82.9484 (+/- 2.6408) [KNN]\n",
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "Mean Accuracy: 82.9434 (+/- 2.9448) [LR]\nMean Accuracy: 84.4067 (+/- 3.9454) [RF]\nMean Accuracy: 83.2830 (+/- 3.7460) [SVC]\n"
                    ]
                },
                "mc_idx": 221,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 120,
                "o_idx": 3
            }
        },
        {
            "source": "\"\"\"Make prediction using all the trained models.\"\"\"\nmodelPrediction = pd.DataFrame({\"RF\":rf.predict(xTest),\n                                 \"GBC\":gbc.predict(xTest),\n                                 \"ABC\":abc.predict(xTest),\n                                 \"ETC\":etc.predict(xTest), \n                                 \"DT\":dt.predict(xTest),\n                                 \"SVC\":svc.predict(xTest), \n                                 \"KNN\":knn.predict(xTest), \n                                 \"LR\":lr.predict(xTest)\n                                })\n\n\"\"\"Let\"s see how each model classifies a prticular class.\"\"\"\nbold(\"All the Models Prediction:\")\ndisplay(modelPrediction.head())",
            "mc_idx": 223,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.23076923076923078,
                "Data_Transform": 0.0,
                "Model_Train": 0.5384615384615384,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.38461538461538464,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 5,
                    "svc": 2
                },
                "Model_Evaluation": {
                    "model": 5,
                    ".predict(": 8
                },
                "Model_Interpretation": {
                    "model": 5
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    121,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "   RF  GBC  ABC  ETC  DT  SVC  KNN  LR\n0   0    0    0    0   0    0    0   0\n1   0    1    1    0   0    0    0   1\n2   0    0    0    0   0    0    0   0\n3   0    0    0    0   0    0    0   0\n4   1    1    1    1   1    0    0   1"
                    ]
                },
                "mc_idx": 223,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 121,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Create a function that plot feature importance by the selected tree based models.\"\"\"\ndef plotFeatureImportance(model):\n    \"\"\"Return a plot of feature importance by model.\"\"\"\n    \n    importance = pd.DataFrame({\"feature\": xTrain.columns,\n                              \"importance\": np.round(model.feature_importances_,3)})\n    importanceSorted = importance.sort_values(by = \"importance\", ascending = False).set_index(\"feature\")\n    return importanceSorted\n\n\"\"\"Create subplots of feature impotance of rf, gbc, dt, etc, and abc.\"\"\"\nfig, axes = plt.subplots(3,2, figsize = (20,40))\nfig.suptitle(\"Tree Based Models Feature Importance\", fontsize = 28)\ntreeModels = [rf, gbc, dt, etc, abc]\ntreeModelNames = [\"RF\", \"GBC\", \"DT\", \"ETC\", \"ABC\"]\nfor ax, model, name in zip(axes.flatten(), treeModels, treeModelNames):\n    plotFeatureImportance(model).plot.barh(ax=ax, title=name, fontsize=18, color=\"green\")\n    ax.set_ylabel(\"Features\", fontsize = 15)\nfig.delaxes(ax = axes[2,1]) # We don\"t need the last subplot.\nfig.tight_layout(rect = [0, 0.03, 1, 0.97])",
            "mc_idx": 225,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2777777777777778,
                "Data_Transform": 0.16666666666666666,
                "Model_Train": 0.6111111111111112,
                "Model_Evaluation": 0.6111111111111112,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1,
                    "size": 4
                },
                "Data_Transform": {
                    ".sort_values": 1,
                    ".set_index": 1,
                    ".round": 1
                },
                "Model_Train": {
                    "model": 11
                },
                "Model_Evaluation": {
                    "model": 11
                },
                "Model_Interpretation": {
                    "feature_importances_": 2,
                    "feature importance": 3,
                    "model": 11,
                    "featureimportance": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c122_o000_image_17.png",
                    122,
                    0,
                    17
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1440x2880 with 5 Axes>"
                    ]
                },
                "mc_idx": 225,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 122,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Let's plot feature importance of LR.\"\"\"\nfig, ax = plt.subplots(figsize=(18,4))\ncoeff = pd.DataFrame({\"feature\":xTrain.columns,\n                      \"importance\":np.transpose(lr.coef_[0])})\n\ncoeff.sort_values(by = \"importance\").set_index(\"feature\")\\\n.plot.bar(title = \"Feature Importance of Linear Model (LR)\", color=\"chocolate\", ax=ax)\nax.tick_params(axis = \"both\", which = \"major\", labelsize = 15)\nax.tick_params(axis = \"both\", which = \"minor\", labelsize = 15)\nax.set_xlabel(\"Feature\", fontsize = 15)\nplt.show()",
            "mc_idx": 227,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.14285714285714285,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.42857142857142855,
                "Model_Train": 0.14285714285714285,
                "Model_Evaluation": 0.14285714285714285,
                "Model_Interpretation": 0.5714285714285714,
                "Hyperparameter_Tuning": 0.2857142857142857,
                "Visualization": 0.2857142857142857,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "fig, ax = plt.subplots": 1,
                    ".bar(": 1,
                    "columns": 1,
                    "size": 4
                },
                "Data_Transform": {
                    ".transpose": 1,
                    ".sort_values": 1,
                    ".set_index": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "feature importance": 2,
                    "model": 1,
                    "coef_": 1
                },
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {
                    "fig, ax = plt.subplots": 1,
                    ".bar(": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c123_o000_image_18.png",
                    123,
                    0,
                    18
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x288 with 1 Axes>"
                    ]
                },
                "mc_idx": 227,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 123,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Create a function that returns learning curves for different classifiers.\"\"\"\ndef plotLearningCurve(model):\n    \"\"\"Returns a plot of learning curve of a model.\"\"\"\n    \n    # Create feature matrix and target vector\n    X, y = xTrain, yTrain\n    # Create CV training and test scores for various training set sizes\n    trainSizes, trainScores, testScores = learning_curve(model, X, y, cv = 10,\n                                                    scoring=\"accuracy\", n_jobs = -1, \n                                                    train_sizes = np.linspace(0.01, 1.0, 17), # 17 different sizes of the training set\n                                                    random_state = seed)\n                                                    \n\n    # Create means and standard deviations of training set scores\n    trainMean = np.mean(trainScores, axis = 1)\n    trainStd = np.std(trainScores, axis = 1)\n\n    # Create means and standard deviations of test set scores\n    testMean = np.mean(testScores, axis = 1)\n    testStd = np.std(testScores, axis = 1)\n\n    # Draw lines\n    plt.plot(trainSizes, trainMean, \"o-\", color = \"red\",  label = \"training score\")\n    plt.plot(trainSizes, testMean, \"o-\", color = \"green\", label = \"cross-validation score\")\n    \n    # Draw bands\n    plt.fill_between(trainSizes, trainMean - trainStd, trainMean + trainStd, alpha = 0.1, color = \"r\") # Alpha controls band transparency.\n    plt.fill_between(trainSizes, testMean - testStd, testMean + testStd, alpha = 0.1, color = \"g\")\n\n    # Create plot\n    font_size = 15\n    plt.xlabel(\"Training Set Size\", fontsize = font_size)\n    plt.ylabel(\"Accuracy Score\", fontsize = font_size)\n    plt.xticks(fontsize = font_size)\n    plt.yticks(fontsize = font_size)\n    plt.legend(loc = \"best\")\n    plt.grid()",
            "mc_idx": 229,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.08333333333333333,
                "Model_Evaluation": 0.08333333333333333,
                "Model_Interpretation": 0.08333333333333333,
                "Hyperparameter_Tuning": 0.027777777777777776,
                "Visualization": 0.1111111111111111,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plt.plot": 2,
                    ".plot(": 4,
                    ".mean(": 2,
                    ".std(": 2,
                    "np.mean": 2,
                    "np.std": 2,
                    "size": 18,
                    ".mean": 2,
                    ".std": 2
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 3
                },
                "Model_Evaluation": {
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {
                    "learning_curve": 1
                },
                "Visualization": {
                    "plt.plot": 2,
                    ".plot(": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    124,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 229,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 124,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Now plot learning curves of the optimized models in subplots.\"\"\"\nplt.figure(figsize = (25,25))\nlcModels = [rf, gbc, dt, etc, abc, knn, svc, lr]\nlcLabels = [\"RF\", \"GBC\", \"DT\", \"ETC\", \"ABC\", \"KNN\", \"SVC\", \"LR\"]\n\nfor ax, model, label in zip (range(1,9), lcModels, lcLabels):\n    plt.subplot(4,2,ax)\n    plotLearningCurve(model)\n    plt.title(label, fontsize = 18)\nplt.suptitle(\"Learning Curves of Optimized Models\", fontsize = 28)\nplt.tight_layout(rect = [0, 0.03, 1, 0.97])",
            "mc_idx": 230,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.375,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.75,
                "Model_Interpretation": 0.75,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 3
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 6,
                    "svc": 2
                },
                "Model_Evaluation": {
                    "model": 6
                },
                "Model_Interpretation": {
                    "model": 6
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c125_o000_image_19.png",
                    125,
                    0,
                    19
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1800x1800 with 8 Axes>"
                    ]
                },
                "mc_idx": 230,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 125,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Return prediction to use it in another function.\"\"\"\ndef xValPredict(model):\n    \"\"\"Returns prediction by which we can calculate different classification metrices.\"\"\"\n    \n    predicted = cross_val_predict(model, xTrain, yTrain, cv = 10)\n    return predicted # Now we can use it in another function by assigning the function to its return value.\n\n\"\"\"Function to return confusion matrix.\"\"\"\ndef calculateConfusionMatrix(model):\n    \"\"\"returns a models confusion matrix\"\"\"\n    \n    predicted = xValPredict(model)\n    confusionMatrix = pd.crosstab(yTrain, predicted, rownames = [\"Actual\"],\n                                   colnames = [\"Predicted/Classified\"], margins = True)\n    return display(confusionMatrix)\n\n\"\"\"Now calculate confusion matrix of rf and gbc.\"\"\"\nbold(\"RF Confusion Matrix:\")\ncalculateConfusionMatrix(rf)\nbold(\"GBC Confusion Matrix:\")\ncalculateConfusionMatrix(gbc)",
            "mc_idx": 232,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".cross": 1
                },
                "Model_Train": {
                    "model": 5
                },
                "Model_Evaluation": {
                    "model": 5
                },
                "Model_Interpretation": {
                    "model": 5
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    126,
                    3,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "Predicted/Classified    0    1  All\nActual                             \n0                     510   39  549\n1                     100  242  342\nAll                   610  281  891",
                        "<IPython.core.display.Markdown object>",
                        "Predicted/Classified    0    1  All\nActual                             \n0                     489   60  549\n1                      83  259  342\nAll                   572  319  891"
                    ]
                },
                "mc_idx": 232,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 126,
                "o_idx": 3
            }
        },
        {
            "source": "\"\"\"Function to calculate precision score.\"\"\"\ndef calculatePrecisionScore(model):\n    \"\"\"Calculates a model's precision score.\"\"\"\n    \n    predicted = xValPredict(model)\n    precisionScore = precision_score(yTrain, predicted)\n    return round(precisionScore*100, 2)\n\n\"\"\"Compute precision score for rf and gbc.\"\"\"\nprint(f\"RF  Precision Score: {calculatePrecisionScore(rf)}\")\nprint(f\"GBC Precision Score: {calculatePrecisionScore(gbc)}\")",
            "mc_idx": 234,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.1875,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.1875,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 3
                },
                "Model_Evaluation": {
                    "precision_score": 2,
                    "precision": 11,
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    127,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "RF  Precision Score: 86.12\nGBC Precision Score: 81.19\n"
                    ]
                },
                "mc_idx": 234,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 127,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Function to calculate recall score.\"\"\"\ndef calculateRecallScore(model):\n    \"\"\"Calculate a model's recall score.\"\"\"\n    \n    predicted = xValPredict(model)\n    recallScore = recall_score(yTrain, predicted)\n    return round(recallScore*100, 2)\n\n\"\"\"Compute recall score for rf and gbc.\"\"\"\nprint(f\"RF  Recall Score: {calculateRecallScore(rf)}\")\nprint(f\"GBC Recall Score: {calculateRecallScore(gbc)}\")",
            "mc_idx": 236,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.1875,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.1875,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 3
                },
                "Model_Evaluation": {
                    "recall_score": 2,
                    "recall": 11,
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    128,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "RF  Recall Score: 70.76\nGBC Recall Score: 75.73\n"
                    ]
                },
                "mc_idx": 236,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 128,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Function for specificity score.\"\"\"\ndef calculateSpecificityScore(model):\n    \"\"\"Returns a model's specificity score.\"\"\"\n    \n    predicted = xValPredict(model)\n    tn, fp, fn, tp = confusion_matrix(yTrain, predicted).ravel()\n    specificityScore = tn / (tn + fp)\n    return round(specificityScore*100, 2)\n\n\"\"\"Calculate specificity score for rf and gbc.\"\"\"\nprint(f\"RF  Specificity Score: {calculateSpecificityScore(rf)}\")\nprint(f\"GBC Specificity Score: {calculateSpecificityScore(gbc)}\")",
            "mc_idx": 238,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2,
                "Model_Train": 0.6,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.6,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "ravel": 1
                },
                "Model_Train": {
                    "model": 3
                },
                "Model_Evaluation": {
                    "confusion_matrix": 2,
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    129,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "RF  Specificity Score: 92.9\nGBC Specificity Score: 89.07\n"
                    ]
                },
                "mc_idx": 238,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 129,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Function for F1 score.\"\"\"\ndef calculateF1Score(model):\n    \"\"\"Returns a model's f1 score.\"\"\"\n    \n    predicted = xValPredict(model)\n    f1Score = f1_score(yTrain, predicted)\n    return round(f1Score*100, 2)\n\n\"\"\"Calculate f1 score for rf and gbc.\"\"\"\nprint(f\"RF  F1 Score: {calculateF1Score(rf)}\")\nprint(f\"GBC F1 Score: {calculateF1Score(gbc)}\")",
            "mc_idx": 240,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.5,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 3
                },
                "Model_Evaluation": {
                    "f1_score": 3,
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    130,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "RF  F1 Score: 77.69\nGBC F1 Score: 78.37\n"
                    ]
                },
                "mc_idx": 240,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 130,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Function to compute classification report.\"\"\"\ndef calculateClassificationReport(model):\n    \"\"\"Returns a model\"s classification report.\"\"\"\n    \n    predicted = xValPredict(model)\n    classificationReport = classification_report(yTrain, predicted)\n    return print(classificationReport)\n\n\"\"\"Now calculate classification report for rf and gbc.\"\"\"\nbold(\"RF Classification Report:\")\ncalculateClassificationReport(rf)\nbold(\"GBC Classification Report:\")\ncalculateClassificationReport(gbc)",
            "mc_idx": 242,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.6,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.6,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 3
                },
                "Model_Evaluation": {
                    "classification_report": 2,
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    131,
                    3,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "              precision    recall  f1-score   support\n\n           0       0.84      0.93      0.88       549\n           1       0.86      0.71      0.78       342\n\n    accuracy                           0.84       891\n   macro avg       0.85      0.82      0.83       891\nweighted avg       0.85      0.84      0.84       891\n\n",
                        "<IPython.core.display.Markdown object>",
                        "              precision    recall  f1-score   support\n\n           0       0.85      0.89      0.87       549\n           1       0.81      0.76      0.78       342\n\n    accuracy                           0.84       891\n   macro avg       0.83      0.82      0.83       891\nweighted avg       0.84      0.84      0.84       891\n\n"
                    ]
                },
                "mc_idx": 242,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 131,
                "o_idx": 3
            }
        },
        {
            "source": "\"\"\"Function for plotting precision-recall vs threshold curve.\"\"\"\ndef plotPrecisionRecallVsThresholdCurve(model, title):\n    \"\"\"Plots precision-recall vs threshold curve for a model.\"\"\"\n\n    probablity = model.predict_proba(xTrain)[:, 1]\n    plt.figure(figsize = (18, 5))\n    precision, recall, threshold = precision_recall_curve(yTrain, probablity)\n    plt.plot(threshold, precision[:-1], \"b-\", label = \"precision\", lw = 3.7)\n    plt.plot(threshold, recall[:-1], \"g\", label = \"recall\", lw = 3.7)\n    plt.xlabel(\"Threshold\")\n    plt.legend(loc = \"best\")\n    plt.ylim([0, 1])\n    plt.title(title)\n    plt.show()\n\n\"\"\"Now plot precision-recall vs threshold curve for rf and gbc.\"\"\"\nplotPrecisionRecallVsThresholdCurve(rf, title = \"RF Precision-Recall vs Threshold Curve\" )\nplotPrecisionRecallVsThresholdCurve(gbc, title = \"GBC Precision-Recall vs Threshold Curve\")",
            "mc_idx": 244,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.03571428571428571,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 0.10714285714285714,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.14285714285714285,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.14285714285714285,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plt.plot": 2,
                    ".plot(": 4,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 3
                },
                "Model_Evaluation": {
                    "precision": 12,
                    "recall": 12,
                    "model": 3,
                    "precision_recall_curve": 1
                },
                "Model_Interpretation": {
                    "model": 3,
                    "predict_proba": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "plt.plot": 2,
                    ".plot(": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c132_o001_image_21.png",
                    132,
                    1,
                    21
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<Figure size 1296x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 244,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 132,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Function to plot recall vs precision curve.\"\"\"\ndef plotPrecisionVsRecallCurve(model, title):\n    \"\"\"Return amodel's recall vs precision curve.\"\"\"\n    \n    probablity = model.predict_proba(xTrain)[:, 1]\n    plt.figure(figsize = (18, 5))\n    precision, recall, threshold = precision_recall_curve(yTrain, probablity)\n    plt.plot(recall, precision, \"r-\", lw = 3.7)\n    plt.ylabel(\"Recall\")\n    plt.xlabel(\"Precision\")\n    plt.axis([0, 1.5, 0, 1.5])\n    plt.title(title)\n    plt.show()\n\n\"\"\"Now plot recall vs precision curve of rf and gbc.\"\"\"\nplotPrecisionVsRecallCurve(rf, title = \"RF Precision-Recall Curve\")\nplotPrecisionVsRecallCurve(gbc, title = \"GBC Precision-Recall Curve\")",
            "mc_idx": 246,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.03571428571428571,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.14285714285714285,
                "Data_Transform": 0.0,
                "Model_Train": 0.10714285714285714,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.14285714285714285,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.07142857142857142,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plt.plot": 1,
                    ".plot(": 2,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 3
                },
                "Model_Evaluation": {
                    "precision": 12,
                    "recall": 12,
                    "model": 3,
                    "precision_recall_curve": 1
                },
                "Model_Interpretation": {
                    "model": 3,
                    "predict_proba": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "plt.plot": 1,
                    ".plot(": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c133_o001_image_23.png",
                    133,
                    1,
                    23
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<Figure size 1296x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 246,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 133,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Function to plot ROC curve with AUC score.\"\"\"\ndef plotRocAndAucScore(model, title):\n    \"\"\"Returns roc and auc score of a model.\"\"\"\n    \n    probablity = model.predict_proba(xTrain)[:, 1]\n    plt.figure(figsize = (18, 5))\n    false_positive_rate, true_positive_rate, threshold = roc_curve(yTrain, probablity)\n    auc_score = roc_auc_score(yTrain, probablity)\n    plt.plot(false_positive_rate, true_positive_rate, label = \"ROC CURVE, AREA = \"+ str(auc_score))\n    plt.plot([0, 1], [0, 1], \"red\", lw = 3.7)\n    plt.xlabel(\"False Positive Rate (1-Specificity)\")\n    plt.ylabel(\"True Positive Rate (Sensitivity)\")\n    plt.axis([0, 1, 0, 1])\n    plt.legend(loc = 4)\n    plt.title(title)\n    plt.show()\n\n\"\"\"Plot roc curve and auc score for rf and gbc.\"\"\"\nplotRocAndAucScore(rf, title = \"RF ROC Curve with AUC Score\")\nplotRocAndAucScore(gbc, title = \"GBC ROC Curve with AUC Score\")",
            "mc_idx": 248,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.14285714285714285,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.42857142857142855,
                "Model_Evaluation": 0.8571428571428571,
                "Model_Interpretation": 0.5714285714285714,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.5714285714285714,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plt.plot": 2,
                    ".plot(": 4,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 3
                },
                "Model_Evaluation": {
                    "roc_auc_score": 2,
                    "model": 3,
                    "roc_curve": 1
                },
                "Model_Interpretation": {
                    "model": 3,
                    "predict_proba": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "plt.plot": 2,
                    ".plot(": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c134_o001_image_25.png",
                    134,
                    1,
                    25
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x360 with 1 Axes>",
                        "<Figure size 1296x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 248,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 134,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Submission with the most accurate random forest classifier.\"\"\"\nsubmissionRF = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": rf.predict(xTest)})\nsubmissionRF.to_csv(\"rfSubmission.csv\", index = False)\n\n\n\"\"\"Submission with the most accurate gradient boosting classifier.\"\"\"\nsubmissionGBC = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": gbc.predict(xTest)})\nsubmissionGBC.to_csv(\"gbcSubmission.csv\", index = False)",
            "mc_idx": 250,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.25,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {
                    ".predict(": 2
                },
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 2,
                    "to_csv": 2
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    135,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 250,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 135,
                "o_idx": 0
            }
        },
        {
            "source": "bold(\"How hard voting works:\")\ndata = [[1, 1, 1, 0, 1], \n        [0, 0, 0, 1, 0]]\ndisplay(pd.DataFrame(data, columns= [\"Class\",\"RF\", \"LR\", \"KNN\", \"Hard_voting\"]).set_index(\"Class\"))",
            "mc_idx": 254,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {
                    ".set_index": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    136,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "       RF  LR  KNN  Hard_voting\nClass                          \n1       1   1    0            1\n0       0   0    1            0"
                    ]
                },
                "mc_idx": 254,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 136,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Create a data frame to store base models prediction.\nFirst 5 in the dataframe are tree based models. Then two are kernel based. \nAnd the last is a linear model.\"\"\"\nbasePrediction = modelPrediction # We\"ve a df of all the models prediction.\n\n\"\"\"Let\"s see how each model classifies a prticular class.\"\"\"\nbold(\"All the Base Models Prediction:\")\ndisplay(basePrediction.head())\n\n\"\"\"Let\"s visualize the correlations among the predictions of base models.\"\"\"\nfig,ax = plt.subplots(nrows=1, ncols=1, figsize=(15,6))\nsns.heatmap(basePrediction.corr(), cmap =\"YlGnBu\", annot=True, annot_kws={\"size\":14}, ax=ax)\nax.set_title(\"Prediction Correlation among the Base Models\", fontsize = 20)\nax.tick_params(axis = \"both\", which = \"major\", labelsize = 14)\nax.tick_params(axis = \"both\", which = \"minor\", labelsize = 14)\nplt.show()",
            "mc_idx": 256,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.07692307692307693,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.6923076923076923,
                "Model_Evaluation": 0.6923076923076923,
                "Model_Interpretation": 0.6923076923076923,
                "Hyperparameter_Tuning": 0.15384615384615385,
                "Visualization": 0.3076923076923077,
                "Debug": 0.0,
                "Data_Export": 0.07692307692307693,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".corr": 2,
                    ".head(": 1,
                    "sns.heatmap": 1,
                    ".heatmap(": 1,
                    "sns.": 1,
                    "head": 1,
                    "size": 5,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 9
                },
                "Model_Evaluation": {
                    "model": 9
                },
                "Model_Interpretation": {
                    "model": 9
                },
                "Hyperparameter_Tuning": {
                    "param": 2
                },
                "Visualization": {
                    "sns.heatmap": 1,
                    ".heatmap(": 1,
                    "sns.": 1,
                    "visualize": 1
                },
                "Debug": {},
                "Data_Export": {
                    "store": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c137_o002_image_26.png",
                    137,
                    2,
                    26
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "   RF  GBC  ABC  ETC  DT  SVC  KNN  LR\n0   0    0    0    0   0    0    0   0\n1   0    1    1    0   0    0    0   1\n2   0    0    0    0   0    0    0   0\n3   0    0    0    0   0    0    0   0\n4   1    1    1    1   1    0    0   1",
                        "<Figure size 1080x432 with 2 Axes>"
                    ]
                },
                "mc_idx": 256,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 137,
                "o_idx": 2
            }
        },
        {
            "source": "\"\"\"We will use mlxtend library to train, predict and plot decision regions of hard voting ensemble classifier.\"\"\"\n\"\"\"Define base models for hard voting ensemble.\"\"\"\nbaseModels = [rf, gbc, dt, knn, lr]\n\n\"\"\"Initialize hard voting ensemble.\"\"\"\nhardVct = EnsembleVoteClassifier(clfs = baseModels, voting=\"hard\")\nprint(\"Training Hard Voting Ensemble Classifier...\")\ndisplay(hardVct.fit(xTrain, yTrain))\nprint(\"Done.\")\n\n\"\"\"Predict with hard voting ensemble.\"\"\"\nyPredHardVct = pd.DataFrame(hardVct.predict(xTest), columns = [\"hardVct\"])\n\n\"\"\"Hard voting cross validation score.\"\"\"\nprint(\"\\nComputing Hard Voting Cross Val Score...\")\nhardXValScore = cross_val_score(hardVct, xTrain, yTrain, cv = 10, scoring = \"accuracy\")\nhardXValScore = round(hardXValScore.mean()*100, 2)\nprint(\"Done.\")\n\n\"\"\"Our tunned scores\"\"\"\ntunedScore = bestScoreAndHyperparametersSorted.iloc[:,0]\n\n\"\"\"Compare hard voting score with best base models scores.\"\"\"\nhardVctVsBaseScore = pd.DataFrame({\"hardVsBaseScore(%)\": [hardXValScore,\n                                                          tunedScore[\"RF\"],\n                                                          tunedScore[\"GBC\"], \n                                                          tunedScore[\"DT\"],\n                                                          tunedScore[\"KNN\"], \n                                                          tunedScore[\"LR\"]]\n                                  })\n\n\"\"\"So basically we\"re comparing hard voting x_val_score with base models\"s tunned score.\"\"\"\nhardVctVsBaseScore.index = [\"hardVct\", \"RF\", \"GBC\", \"DT\", \"KNN\", \"LR\"]\nbold(\"Hard Voting vs Base Models Scores:\")\ndisplay(hardVctVsBaseScore)",
            "mc_idx": 258,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.375,
                "Data_Transform": 0.0,
                "Model_Train": 0.875,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.75,
                "Hyperparameter_Tuning": 0.5,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    "columns": 1,
                    ".mean": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "model": 6
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    "model": 6,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "model": 6
                },
                "Hyperparameter_Tuning": {
                    "param": 1,
                    "hyperparameter": 1,
                    "hyperparameters": 1,
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    138,
                    8,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Training Hard Voting Ensemble Classifier...\n",
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "EnsembleVoteClassifier(clfs=[RandomForestClassifier(bootstrap=True,\n                                                    class_weight=None,\n                                                    criterion='entropy',\n                                                    max_depth=None,\n                                                    max_features='sqrt',\n                                                    max_leaf_nodes=None,\n                                                    min_impurity_decrease=0.0,\n                                                    min_impurity_split=None,\n                                                    min_samples_leaf=2,\n                                                    min_samples_split=6,\n                                                    min_weight_fraction_leaf=0.0,\n                                                    n_estimators=15,\n                                                    n_jobs=None,\n                                                    oob_score=False,\n                                                    random_state=44, verbose=0,\n                                                    wa...\n                                                  metric_params=None,\n                                                  n_jobs=None, n_neighbors=8,\n                                                  p=2, weights='uniform'),\n                             LogisticRegression(C=2.7825594022071245,\n                                                class_weight=None, dual=False,\n                                                fit_intercept=True,\n                                                intercept_scaling=1,\n                                                l1_ratio=None, max_iter=5000,\n                                                multi_class='warn', n_jobs=None,\n                                                penalty='l1', random_state=None,\n                                                solver='warn', tol=0.0001,\n                                                verbose=0, warm_start=False)],\n                       refit=True, verbose=0, voting='hard', weights=None)",
                        "Done.\n\nComputing Hard Voting Cross Val Score...\n",
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "Done.\n",
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "<IPython.core.display.Markdown object>",
                        "         hardVsBaseScore(%)\nhardVct               84.63\nRF                    84.40\nGBC                   83.95\nDT                    81.37\nKNN                   82.94\nLR                    82.94"
                    ]
                },
                "mc_idx": 258,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 138,
                "o_idx": 8
            }
        },
        {
            "source": "\"\"\"Perform Standarization:\nVariables have very different ranges (diffenence between max and  min).\nThe purpose of standarization is to reduce the dispersion of these variables.\"\"\"\n\n\"\"\"Initialize standard scaler object.\"\"\"\nstdScaler = StandardScaler()\n\"\"\"Fit standard scaler object to train data.\"\"\"\nstdScaler.fit(xTrain)\n\"\"\"Apply the standard scaler to training set.\"\"\"\nxTrainScaled = stdScaler.transform(xTrain)\n\n\n\"\"\"Perform PCA:\"\"\"\n\"\"\"Initialize pca object with two components. i.e., converting into 2d from 47d.\"\"\"\npca = PCA(n_components = 2) # Projection to 2d from 47d\n\"\"\"Fit pca to scaled data.\"\"\"\npca.fit(xTrainScaled)\n\"\"\"Apply pca to scaled data.\"\"\"\npcaTrain = pca.transform(xTrainScaled)\n\"\"\"Create a data frame consisting of two pca.\"\"\"\ntrainPca = pd.DataFrame(data = pcaTrain, columns = [\"pca-1\", \"pca-2\"])\nbold(\"Projection to 2D from 47D:\")\ndisplay(trainPca.head())\n\n\"\"\"let\"s merge our two pca components with our target feature.\"\"\"\nfinalDf = pd.concat([trainPca, yTrain], axis = 1)\nbold(\"Target with 2-PCA Components:\")\ndisplay(finalDf.head())",
            "mc_idx": 260,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.08695652173913043,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.30434782608695654,
                "Data_Transform": 1.0,
                "Model_Train": 0.08695652173913043,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 2
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 2,
                    "head": 2,
                    "columns": 1,
                    ".head": 2
                },
                "Data_Transform": {
                    ".concat(": 1,
                    "transform": 2,
                    "standardscaler": 1,
                    "pca": 18,
                    ".concat": 1
                },
                "Model_Train": {
                    ".fit(": 2
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    139,
                    3,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "      pca-1     pca-2\n0 -1.864392  0.350562\n1  5.210965 -2.822320\n2 -0.351195  1.056633\n3  3.273593 -0.823716\n4 -2.557838 -0.168374",
                        "<IPython.core.display.Markdown object>",
                        "      pca-1     pca-2  Survived\n0 -1.864392  0.350562         0\n1  5.210965 -2.822320         1\n2 -0.351195  1.056633         1\n3  3.273593 -0.823716         1\n4 -2.557838 -0.168374         0"
                    ]
                },
                "mc_idx": 260,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 139,
                "o_idx": 3
            }
        },
        {
            "source": "\"\"\"Now calculate how much variance we get off these two components.\"\"\"\nbold(\"Total Variance Explained by 2 PCA Components:\")\ndisplay(round((pca.explained_variance_ratio_[0] + pca.explained_variance_ratio_[1])*100, 2))",
            "mc_idx": 262,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "pca": 3,
                    ".exp": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    140,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "19.9"
                    ]
                },
                "mc_idx": 262,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 140,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Visualize our newly transformed samples with class labels.\"\"\"\nfig,ax = plt.subplots(1,1, figsize = (18,7))\nax.set_xlabel(\"PCA_1\", fontsize = 15)\nax.set_ylabel(\"PCA_2\", fontsize = 15)\nax.set_title(\"2-Component PCA (2D-Transformed Samples)\", fontsize = 20)\ntargets = [1, 0]\ncolors = [\"g\", \"r\"]\nfor target, color in zip(targets,colors):\n    indices = finalDf[\"Survived\"] == target\n    ax.scatter(finalDf.loc[indices, \"pca-1\"],\n               finalDf.loc[indices, \"pca-2\"],\n               c = color, s = 37)\nplt.legend(targets)\nplt.show()",
            "mc_idx": 264,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.14285714285714285,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.7142857142857143,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2857142857142857,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".scatter(": 1,
                    "size": 4
                },
                "Data_Transform": {
                    "transform": 2,
                    "pca": 5
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    ".scatter(": 1,
                    "visualize": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c141_o000_image_27.png",
                    141,
                    0,
                    27
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1296x504 with 1 Axes>"
                    ]
                },
                "mc_idx": 264,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 141,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"We will use mlxtend for plotting decision regions of base and ensemble models. Initialize base models and hard voting ensemble.\"\"\"\nrfPca = RandomForestClassifier(random_state = seed)\ngbcPca = GradientBoostingClassifier(random_state = seed)\ndtPca = DecisionTreeClassifier(random_state = seed)\nknnPca = KNeighborsClassifier()\nlrPca = LogisticRegression(random_state = seed)\nbaseModelPca = [rfPca, gbcPca, dtPca, knnPca, lrPca]\nhardVctPca = EnsembleVoteClassifier(clfs = baseModelPca, voting=\"hard\")\n\n\"\"\"Function to plot decision region.\"\"\"\ndef plotDecisionRegion(model):\n    \"\"\"Returns a model's decision region.\"\"\"\n    \n    \"\"\"Train models with data pca returned. Get the train data.\"\"\"\n    X = trainPca.values # Must be converted into numpy array.\n    y = yTrain.values\n    model.fit(X, y) \n    decisionRegion = plot_decision_regions(X = X, y = y.astype(np.integer), clf=model)\n    plt.xlabel(\"PCA-1\", fontsize = 15)\n    plt.ylabel(\"PCA_2\", fontsize = 15)\n    plt.xticks(fontsize = 15)\n    plt.yticks(fontsize = 15)\n    return decisionRegion\n\n\"\"\"Now plot decison regions for hard voting ensemble vs base models in subplots.\"\"\"\nplt.figure(figsize = (25,25))\nenModels = [hardVctPca, rfPca, gbcPca, dtPca, knnPca, lrPca]\nenLabels = [\"Hard_vct\", \"RF\", \"GBC\", \"DT\", \"KNN\", \"LR\"]\nfor ax, model, label in zip(range(1,7), enModels, enLabels):\n    plt.subplot(3,2,ax)\n    plotDecisionRegion(model)\n    plt.title(label, fontsize = 18)\nplt.suptitle(\"Hard Voting vs Base Models Decision Regions\", fontsize = 28)\nplt.tight_layout(rect = [0, 0.03, 1, 0.97])",
            "mc_idx": 266,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.2916666666666667,
                "Data_Transform": 1.0,
                "Model_Train": 0.9583333333333334,
                "Model_Evaluation": 0.625,
                "Model_Interpretation": 0.6666666666666666,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 7
                },
                "Data_Transform": {
                    ".astype(": 1,
                    "pca": 23
                },
                "Model_Train": {
                    "model.fit": 1,
                    ".fit(": 1,
                    "model": 15,
                    "randomforestclassifier": 2,
                    "logisticregression": 1,
                    "gradientboostingclassifier": 1,
                    "decisiontreeclassifier": 1,
                    "kneighborsclassifier": 1
                },
                "Model_Evaluation": {
                    "model": 15
                },
                "Model_Interpretation": {
                    "model": 15,
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c142_o001_image_28.png",
                    142,
                    1,
                    28
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning:\n\nThe default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning:\n\nThe default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "<Figure size 1800x1800 with 6 Axes>"
                    ]
                },
                "mc_idx": 266,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 142,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Create a data frame consisting of base models and hard voting ensemble predictions. Revised base models are now rf, gbc, dt, knn, lr without svc and etc.\"\"\"\nbasePrediction = basePrediction.drop(columns = [\"ABC\", \"SVC\", \"ETC\"], axis = 1)\n\n\"\"\"See base models prediction with hard voting prediction.\"\"\"\nhardBase = pd.concat([basePrediction, yPredHardVct], sort = False, axis = 1)\ndisplay(hardBase.head(7))",
            "mc_idx": 268,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.8,
                "Data_Transform": 0.6,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.6,
                "Model_Interpretation": 0.6,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    "columns": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".concat(": 1,
                    ".drop": 1,
                    ".concat": 1
                },
                "Model_Train": {
                    "model": 3,
                    "svc": 2
                },
                "Model_Evaluation": {
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    143,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   RF  GBC  DT  KNN  LR  hardVct\n0   0    0   0    0   0        0\n1   0    1   0    0   1        0\n2   0    0   0    0   0        0\n3   0    0   0    0   0        0\n4   1    1   1    0   1        1\n5   0    0   0    0   0        0\n6   1    1   0    1   1        1"
                    ]
                },
                "mc_idx": 268,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 143,
                "o_idx": 0
            }
        },
        {
            "source": "bold(\"How soft voting works:\")\ndata = [[0.49, 0.99, 0.49, 0.66, 1], \n        [0.51, 0.01, 0.51, 0.34, 0]]\ndisplay(pd.DataFrame(data, columns= [\"RF\", \"LR\", \"KNN\", \"Average\", \"Soft_voting\"]))",
            "mc_idx": 270,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    144,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "     RF    LR   KNN  Average  Soft_voting\n0  0.49  0.99  0.49     0.66            1\n1  0.51  0.01  0.51     0.34            0"
                    ]
                },
                "mc_idx": 270,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 144,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Base models for soft voting is the base models of hard voting.\"\"\"\n\"\"\"Initialize soft voting ensemble.\"\"\"\nbaseModels = [rf, gbc, dt, knn, lr]\nsoftVct = EnsembleVoteClassifier(clfs = baseModels, voting = \"soft\")\nprint(\"Fitting Soft Voting Ensemble...\")\ndisplay(softVct.fit(xTrain, yTrain))\nprint(\"Done.\")\n\n\"\"\"Predict with soft voting ensemble.\"\"\"\nyPredSoftVct = pd.DataFrame(softVct.predict(xTest), columns = [\"Soft_vct\"])\n\n\"\"\"Hard voting cross validation score.\"\"\"\nprint(\"\\nComputing Soft Voting X Val Score...\")\nsoftXValScore = cross_val_score(softVct, xTrain, yTrain, cv = 10, scoring = \"accuracy\")\nsoftXValScore = round(softXValScore.mean()*100, 2)\nprint(\"Done.\")\n\n\"\"\"Compare hard voting score with best base models scores.\"\"\"\nsoftVsBaseScore = pd.DataFrame({\"Soft_vs_base_score(%)\": [softXValScore,\n                                                          tunedScore[\"RF\"],\n                                                          tunedScore[\"GBC\"], \n                                                          tunedScore[\"DT\"],\n                                                          tunedScore[\"KNN\"], \n                                                          tunedScore[\"LR\"]]\n                               })\n\"\"\"So basically we\"re comparing soft voting x_val_score with base models\"s tunned score.\"\"\"\nsoftVsBaseScore.index = [\"Soft_vct\", \"RF\", \"GBC\", \"DT\", \"KNN\", \"LR\"]\nbold(\"Soft Voting vs Base Models Scores:\")\ndisplay(softVsBaseScore)",
            "mc_idx": 272,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 0.0,
                "Model_Train": 0.8888888888888888,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.7777777777777778,
                "Hyperparameter_Tuning": 0.1111111111111111,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    "columns": 1,
                    ".mean": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "model": 7
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    "model": 7,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "model": 7
                },
                "Hyperparameter_Tuning": {
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    145,
                    8,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Fitting Soft Voting Ensemble...\n",
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "EnsembleVoteClassifier(clfs=[RandomForestClassifier(bootstrap=True,\n                                                    class_weight=None,\n                                                    criterion='entropy',\n                                                    max_depth=None,\n                                                    max_features='sqrt',\n                                                    max_leaf_nodes=None,\n                                                    min_impurity_decrease=0.0,\n                                                    min_impurity_split=None,\n                                                    min_samples_leaf=2,\n                                                    min_samples_split=6,\n                                                    min_weight_fraction_leaf=0.0,\n                                                    n_estimators=15,\n                                                    n_jobs=None,\n                                                    oob_score=False,\n                                                    random_state=44, verbose=0,\n                                                    wa...\n                                                  metric_params=None,\n                                                  n_jobs=None, n_neighbors=8,\n                                                  p=2, weights='uniform'),\n                             LogisticRegression(C=2.7825594022071245,\n                                                class_weight=None, dual=False,\n                                                fit_intercept=True,\n                                                intercept_scaling=1,\n                                                l1_ratio=None, max_iter=5000,\n                                                multi_class='warn', n_jobs=None,\n                                                penalty='l1', random_state=None,\n                                                solver='warn', tol=0.0001,\n                                                verbose=0, warm_start=False)],\n                       refit=True, verbose=0, voting='soft', weights=None)",
                        "Done.\n\nComputing Soft Voting X Val Score...\n",
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "Done.\n",
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "<IPython.core.display.Markdown object>",
                        "          Soft_vs_base_score(%)\nSoft_vct                  83.39\nRF                        84.40\nGBC                       83.95\nDT                        81.37\nKNN                       82.94\nLR                        82.94"
                    ]
                },
                "mc_idx": 272,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 145,
                "o_idx": 8
            }
        },
        {
            "source": "\"\"\"We would use the same data to plot decision region we got analysing PCA.\"\"\"\nsoftVctPca = EnsembleVoteClassifier(clfs = baseModelPca, voting = \"soft\")\n\n\"\"\"Plot decision regions for soft voting ensemble vs base models in subplots.\"\"\"\nplt.figure(figsize = (25,25))\nenModels = [softVctPca, rfPca, gbcPca, dtPca, knnPca, lrPca]\nenLabels = [\"Soft_vct\", \"RF\", \"GBC\", \"DT\", \"KNN\", \"LR\"]\nfor ax, model, label in zip(range(1,7), enModels, enLabels):\n    plt.subplot(3,2,ax)\n    plotDecisionRegion(model)\n    plt.title(label, fontsize = 18)\nplt.suptitle(\"Soft Voting vs Base Models Decision Regions\", fontsize = 28)\nplt.tight_layout(rect = [0, 0.03, 1, 0.97])",
            "mc_idx": 274,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 1.0,
                "Model_Train": 0.7777777777777778,
                "Model_Evaluation": 0.7777777777777778,
                "Model_Interpretation": 0.7777777777777778,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 3
                },
                "Data_Transform": {
                    "pca": 9
                },
                "Model_Train": {
                    "model": 7
                },
                "Model_Evaluation": {
                    "model": 7
                },
                "Model_Interpretation": {
                    "model": 7
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/images/d0004_c146_o001_image_29.png",
                    146,
                    1,
                    29
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "<Figure size 1800x1800 with 6 Axes>"
                    ]
                },
                "mc_idx": 274,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 146,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"See base models prediction with soft voting prediction.\"\"\"\nsoftBase = pd.concat([basePrediction,yPredSoftVct], sort = False, axis = 1)\ndisplay(softBase.head())",
            "mc_idx": 276,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.6666666666666666,
                "Model_Train": 0.3333333333333333,
                "Model_Evaluation": 0.3333333333333333,
                "Model_Interpretation": 0.3333333333333333,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".concat(": 1,
                    ".concat": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    147,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   RF  GBC  DT  KNN  LR  Soft_vct\n0   0    0   0    0   0         0\n1   0    1   0    0   1         0\n2   0    0   0    0   0         0\n3   0    0   0    0   0         0\n4   1    1   1    0   1         1"
                    ]
                },
                "mc_idx": 276,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 147,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Initialize bagging classifier.\"\"\"\nbagg = BaggingClassifier(base_estimator = rf, verbose = 0, n_jobs = -1, random_state = seed)\n\"\"\"We use rf as the base estimator for bagging technique.\"\"\"\nprint(\"Fitting Bagging Ensemble...\")\ndisplay(bagg.fit(xTrain, yTrain))\nprint(\"Done.\")\n\n\"\"\"Bagging cross validation score.\"\"\"\nprint(\"\\nComputing Bagging X Val Score..\")\nbaggXValScore = cross_val_score(bagg, xTrain, yTrain, cv = 10, scoring = \"accuracy\")\nbaggXValScore = np.round(baggXValScore.mean()*100, 2)\nprint(\"Done.\")\n\n\"\"\"Compare bagging ensemble score with best base models scores.\"\"\"\nbaggVsBaseScore = pd.DataFrame({\"Bagging_vs_base_score(%)\": [baggXValScore,\n                                                          tunedScore[\"RF\"],\n                                                          tunedScore[\"GBC\"], \n                                                          tunedScore[\"DT\"],\n                                                          tunedScore[\"KNN\"], \n                                                          tunedScore[\"LR\"]]\n                               })\n\n\"\"\"So basically we\"re comparing bagging x_val_score with base models\"s tunned score.\"\"\"\nbaggVsBaseScore.index = [\"Bagg\", \"RF\", \"GBC\", \"DT\", \"KNN\", \"LR\"]\nbold(\"Bagging vs Base Models Scores:\")\ndisplay(baggVsBaseScore)",
            "mc_idx": 278,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.5,
                "Data_Transform": 0.25,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.75,
                "Hyperparameter_Tuning": 0.25,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1
                },
                "Data_Transform": {
                    ".round": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "model": 3
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    148,
                    4,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Fitting Bagging Ensemble...\n",
                        "BaggingClassifier(base_estimator=RandomForestClassifier(bootstrap=True,\n                                                        class_weight=None,\n                                                        criterion='entropy',\n                                                        max_depth=None,\n                                                        max_features='sqrt',\n                                                        max_leaf_nodes=None,\n                                                        min_impurity_decrease=0.0,\n                                                        min_impurity_split=None,\n                                                        min_samples_leaf=2,\n                                                        min_samples_split=6,\n                                                        min_weight_fraction_leaf=0.0,\n                                                        n_estimators=15,\n                                                        n_jobs=None,\n                                                        oob_score=False,\n                                                        random_state=44,\n                                                        verbose=0,\n                                                        warm_start=False),\n                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n                  max_samples=1.0, n_estimators=10, n_jobs=-1, oob_score=False,\n                  random_state=43, verbose=0, warm_start=False)",
                        "Done.\n\nComputing Bagging X Val Score..\nDone.\n",
                        "<IPython.core.display.Markdown object>",
                        "      Bagging_vs_base_score(%)\nBagg                     82.83\nRF                       84.40\nGBC                      83.95\nDT                       81.37\nKNN                      82.94\nLR                       82.94"
                    ]
                },
                "mc_idx": 278,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 148,
                "o_idx": 4
            }
        },
        {
            "source": "\"\"\"We will use adaptive boosting, gradient boosting and extreme gradient boosting classifiers for boosting ensemble method.\"\"\"\n\"\"\"Initialize boosting classifier. Base models for boosting:\"\"\"\nboostModels = [abc, gbc, xgbc] # Unoptimized xgbc\nboost = EnsembleVoteClassifier(clfs = boostModels, voting=\"hard\")\n\n\"\"\"Fitting boosting.\"\"\"\nprint(\"Fitting Boosting Ensemble...\")\ndisplay(boost.fit(xTrain, yTrain))\nprint(\"Done.\")\n\n\"\"\"Boosting cross validation score.\"\"\"\nprint(\"\\nCalculating Boosting X Val Score...\")\nboosXValScore = cross_val_score(boost, xTrain, yTrain, cv = 10, scoring = \"accuracy\")\nboosXValScore = round(boosXValScore.mean()*100, 2)\nprint(\"Done.\")\n\n\"\"\"Compare boosting ensemble score with best base models scores.\"\"\"\nxgbcXValScore = 82.27  # xgbc\"s x_val_score.\nboostVsBaseScore = pd.DataFrame({\"Boosting_vs_base_score(%)\": [boosXValScore,\n                                                                  tunedScore[\"ABC\"],\n                                                                  tunedScore[\"GBC\"], \n                                                                  xgbcXValScore]})\n\"\"\"So basically we\"re comparing boosting x_val_score with base models\"s tunned score except xgbc.\"\"\"\nboostVsBaseScore.index = [\"Boost\", \"ABC\", \"GBC\", \"XGBC\"]\nbold(\"Boosting vs Base Models Scores:\")\ndisplay(boostVsBaseScore)",
            "mc_idx": 280,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 0.875,
                "Model_Evaluation": 0.875,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.125,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    ".mean": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1,
                    "model": 6
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    "model": 6
                },
                "Model_Interpretation": {
                    "model": 6,
                    "gradient": 2
                },
                "Hyperparameter_Tuning": {
                    "cross_val_score": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    149,
                    4,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Fitting Boosting Ensemble...\n",
                        "EnsembleVoteClassifier(clfs=[AdaBoostClassifier(algorithm='SAMME.R',\n                                                base_estimator=None,\n                                                learning_rate=0.1,\n                                                n_estimators=250,\n                                                random_state=43),\n                             GradientBoostingClassifier(criterion='friedman_mse',\n                                                        init=None,\n                                                        learning_rate=0.05,\n                                                        loss='deviance',\n                                                        max_depth=4,\n                                                        max_features=0.1,\n                                                        max_leaf_nodes=None,\n                                                        min_impurity_decrease=0.0,\n                                                        min_impurity_split=None,\n                                                        min_samples_le...\n                                           colsample_bylevel=1,\n                                           colsample_bynode=1,\n                                           colsample_bytree=1, gamma=0,\n                                           learning_rate=0.1, max_delta_step=0,\n                                           max_depth=3, min_child_weight=1,\n                                           missing=None, n_estimators=100,\n                                           n_jobs=1, nthread=None,\n                                           objective='binary:logistic',\n                                           random_state=43, reg_alpha=0,\n                                           reg_lambda=1, scale_pos_weight=1,\n                                           seed=None, silent=None, subsample=1,\n                                           verbosity=1)],\n                       refit=True, verbose=0, voting='hard', weights=None)",
                        "Done.\n\nCalculating Boosting X Val Score...\nDone.\n",
                        "<IPython.core.display.Markdown object>",
                        "       Boosting_vs_base_score(%)\nBoost                      83.73\nABC                        83.39\nGBC                        83.95\nXGBC                       82.27"
                    ]
                },
                "mc_idx": 280,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 149,
                "o_idx": 4
            }
        },
        {
            "source": "\"\"\"Perform blending in mlens.\"\"\"\n\"\"\"Initialize blend ensembler.\"\"\"\nblend = BlendEnsemble(n_jobs = -1, test_size = 0.5, random_state = seed)\n\"\"\"Base models for blending.\"\"\"\nbaseModels = [gbc, rf, dt, knn, abc]\nblend.add(baseModels)\n\"\"\"Meta learner for blending. We will use lr.\"\"\"\nblend.add_meta(lr)\n\"\"\"Train the blend ensemble.\"\"\"\nprint(\"Fitting Blending...\")\ndisplay(blend.fit(xTrain, yTrain))\nprint(\"Done.\")",
            "mc_idx": 282,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.5,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.75,
                "Model_Interpretation": 0.75,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {
                    ".add": 2
                },
                "Model_Train": {
                    ".fit(": 1,
                    "model": 3
                },
                "Model_Evaluation": {
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    150,
                    3,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Fitting Blending...\n",
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n",
                        "BlendEnsemble(array_check=None, backend=None,\n       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n   name='layer-1', propagate_features=None, raise_on_exception=True,\n   random_state=3392, shuffle=False,\n   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n   indexer=BlendIndex(X=None, raise_on_exception=...rer=None)],\n   n_jobs=-1, name='group-1', raise_on_exception=True, transformers=[])],\n   verbose=0)],\n       model_selection=False, n_jobs=None, raise_on_exception=True,\n       random_state=43, sample_size=20, scorer=None, shuffle=False,\n       test_size=0.5, verbose=False)",
                        "Done.\n"
                    ]
                },
                "mc_idx": 282,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 150,
                "o_idx": 3
            }
        },
        {
            "source": "\"\"\"Initialize base models. We will use the same base models as blending.\"\"\"\nbaseModels = [rf, dt, gbc, abc, knn]\n\"\"\"Perform stacking.\"\"\"\nsTrain, sTest = stacking(baseModels,                # list of base models\n                           xTrain, yTrain, xTest,   # data\n                           regression = False,         # classification task (if you need \n                                                       # regression - set to True)\n                           mode = \"oof_pred_bag\",      # mode: oof for train set, predict test \n                                                       # set in each fold and vote\n                           needs_proba = False,        # predict class labels (if you need \n                                                       # probabilities - set to True) \n                           save_dir = None,            # do not save result and log (to save \n                                                       # in current dir - set to \".\")\n                           metric = accuracy_score,    # metric: callable\n                           n_folds = 10,               # number of folds\n                           stratified = True,          # stratified split for folds\n                           shuffle = True,             # shuffle the data\n                           random_state= seed,         # ensure reproducibility\n                           verbose = 1)                # print progress",
            "mc_idx": 284,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 0.7142857142857143,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.7142857142857143,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.42857142857142855,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "stack": 2
                },
                "Model_Train": {
                    "model": 5
                },
                "Model_Evaluation": {
                    "accuracy_score": 2,
                    "model": 5
                },
                "Model_Interpretation": {
                    "model": 5
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    "save": 3
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    151,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "task:         [classification]\nn_classes:    [2]\nmetric:       [accuracy_score]\nmode:         [oof_pred_bag]\nn_models:     [5]\n\nmodel  0:     [RandomForestClassifier]\n    ----\n    MEAN:     [0.81598712] + [0.05415289]\n    FULL:     [0.81593715]\n\nmodel  1:     [DecisionTreeClassifier]\n    ----\n    MEAN:     [0.80251674] + [0.04118991]\n    FULL:     [0.80246914]\n\nmodel  2:     [GradientBoostingClassifier]\n    ----\n    MEAN:     [0.83622517] + [0.04595903]\n    FULL:     [0.83613917]\n\nmodel  3:     [AdaBoostClassifier]\n    ----\n    MEAN:     [0.82719754] + [0.04885911]\n    FULL:     [0.82716049]\n\nmodel  4:     [KNeighborsClassifier]\n    ----\n    MEAN:     [0.82381568] + [0.03815719]\n    FULL:     [0.82379349]\n\n"
                    ]
                },
                "mc_idx": 284,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 151,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Input features for meta learner.\"\"\"\ndisplay(sTrain[:5])\ndisplay(sTrain.shape)",
            "mc_idx": 286,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "shape": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    152,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "array([[0, 0, 0, 0, 0],\n       [1, 1, 1, 1, 1],\n       [0, 0, 1, 1, 0],\n       [1, 1, 1, 1, 1],\n       [0, 0, 0, 0, 0]])",
                        "(891, 5)"
                    ]
                },
                "mc_idx": 286,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 152,
                "o_idx": 1
            }
        },
        {
            "source": "'''Test (prediction) set for meta learner.'''\ndisplay(sTest[:5].shape)\ndisplay(sTest.shape)",
            "mc_idx": 287,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "shape": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    153,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "(5, 5)",
                        "(418, 5)"
                    ]
                },
                "mc_idx": 287,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 153,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Initialize 1st level model that is our meta learner. We will use lr.\"\"\"\nsuperLearner = lr \n    \n\"\"\"Fit meta learner on the output of base learners.\"\"\"\nprint(\"Fitting Stacking...\")\nsuperLearner.fit(sTrain, yTrain)\nprint(\"Done.\")\n\"\"\"Finally predict using super learner.\"\"\"\nyPredSuper = superLearner.predict(sTest)",
            "mc_idx": 288,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.5,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "stack": 1
                },
                "Model_Train": {
                    ".fit(": 1,
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    154,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Fitting Stacking...\nDone.\n",
                        "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n"
                    ]
                },
                "mc_idx": 288,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 154,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Predicting with different ensembles.\"\"\"\n\n\"\"\"Hard voting.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": hardVct.predict(xTest)})\nsubmission.to_csv(\"hardVctSubmission.csv\", index = False)\n\n\"\"\"Soft voting.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": softVct.predict(xTest)})\nsubmission.to_csv(\"softVctSubmission.csv\", index = False)\n\n\"\"\"Bagging.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": bagg.predict(xTest)})\nsubmission.to_csv(\"baggSubmission.csv\", index = False)\n\n\"\"\"Boosting.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": boost.predict(xTest)})\nsubmission.to_csv(\"boostSubmission.csv\", index = False)\n\n\"\"\"Blending.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": blend.predict(xTest).astype(int)})\nsubmission.to_csv(\"blendSubmission.csv\", index = False)\n\n\"\"\"Stacking.\"\"\"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": yPredSuper.astype(int)})\nsubmission.to_csv(\"stackingSubmission.csv\", index = False)",
            "mc_idx": 290,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Data_Export",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.4166666666666667,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 2,
                    "stack": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {
                    ".predict(": 5
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 6,
                    "to_csv": 6
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    155,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 290,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 155,
                "o_idx": 0
            }
        },
        {
            "source": "\"\"\"Create a df of different ensemble submission scores and base models.\"\"\"\nsubmissionScore = pd.DataFrame({\"models\":[\"bagging(en)\", \"boosting(en)\", \"blending(en)\", \"stacking(en)\", \n                                          \"hardVoting(en)\", \"softVoting(en)\", \"rf(base)\", \"gbc(base)\"],\n             \"scoredOnSubmission\":[0.81339, 0.78947, 0.79425, 0.79904, 0.79904, 0.79904, 0.80382, 0.78947]})\nsubmissionScore = submissionScore.set_index(\"models\").sort_values(by=\"scoredOnSubmission\", ascending = False)\nbold(\"Ensemble vs Base Models Scores on Submission:\")\ndisplay(submissionScore)",
            "mc_idx": 292,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.75,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "stack": 1,
                    ".sort_values": 1,
                    ".set_index": 1
                },
                "Model_Train": {
                    "model": 4
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    156,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.Markdown object>",
                        "                scoredOnSubmission\nmodels                            \nbagging(en)                0.81339\nrf(base)                   0.80382\nstacking(en)               0.79904\nhardVoting(en)             0.79904\nsoftVoting(en)             0.79904\nblending(en)               0.79425\nboosting(en)               0.78947\ngbc(base)                  0.78947"
                    ]
                },
                "mc_idx": 292,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 156,
                "o_idx": 1
            }
        },
        {
            "source": "\"\"\"Let's plot models' submission score for the last time.\"\"\"\ndef plotSubmissionScore():\n    \"\"\"Returns a bar chart of different models scored on submission.\"\"\"\n    \n    # Create a subplot of bar chart\n    fig=make_subplots(\n        rows=1, \n        cols=1,\n        vertical_spacing=0.3,\n        print_grid=False) # This suppresses \"This is the format of your plot grid:\" text from popping out.\n\n    # Add trace for bar chart\n    fig.add_trace(go.Bar(x=submissionScore.index,\n                             y=submissionScore.T.squeeze(), # Converts df to series\n                             text=submissionScore.T.squeeze(),\n                             hoverinfo=\"x+y\",\n                             textposition=\"auto\",\n                             marker = dict(color=submissionScore.T.squeeze(), colorscale=\"Rainbow\"),\n                             textfont=dict(family=\"sans serif\",size=14),\n                             ),\n                     row=1,\n                     col=1\n                     )\n\n        \n    # Update the layout. Add title, dimension, and background color\n    fig.layout.update(\n        height=600, \n        width=950,\n        hovermode=\"closest\",\n        title_text = \"Models Score on Submission\",\n        paper_bgcolor=\"rgb(243, 243, 243)\",\n        plot_bgcolor=\"rgb(243, 243, 243)\"\n        )\n\n    # Set y-axis titles in bold\n    fig.layout.yaxis1.update(title=\"<b>Submission score</b>\")\n    \n    # Set x-axis title in bold\n    fig.layout.xaxis1.update(title=\"<b>Models</b>\")\n    return fig.show()\n\n\"\"\"Call the function to plot the scores.\"\"\"\nplotSubmissionScore()",
            "mc_idx": 293,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.25,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.75,
                "Data_Transform": 0.25,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".bar(": 1,
                    "info": 1,
                    "size": 1
                },
                "Data_Transform": {
                    ".add": 1
                },
                "Model_Train": {
                    "model": 4
                },
                "Model_Evaluation": {
                    "model": 4
                },
                "Model_Interpretation": {
                    "model": 4
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    ".bar(": 1,
                    "chart": 3
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    157,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<div>\n        \n        \n            <div id=\"9dd7e112-c210-4fc2-8f23-f9eddbfe42fc\" class=\"plotly-graph-div\" style=\"height:600px; width:950px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n                    \n                if (document.getElementById(\"9dd7e112-c210-4fc2-8f23-f9eddbfe42fc\")) {\n                    Plotly.newPlot(\n                        '9dd7e112-c210-4fc2-8f23-f9eddbfe42fc',\n                        [{\"hoverinfo\": \"x+y\", \"marker\": {\"color\": [0.81339, 0.80382, 0.79904, 0.79904, 0.79904, 0.79425, 0.78947, 0.78947], \"colorscale\": \"Rainbow\"}, \"text\": [0.81339, 0.80382, 0.79904, 0.79904, 0.79904, 0.79425, 0.78947, 0.78947], \"textfont\": {\"family\": \"sans serif\", \"size\": 14}, \"textposition\": \"auto\", \"type\": \"bar\", \"uid\": \"b0a34a6d-03da-4c9d-8c31-1be527f8b2c8\", \"x\": [\"bagging(en)\", \"rf(base)\", \"stacking(en)\", \"hardVoting(en)\", \"softVoting(en)\", \"blending(en)\", \"boosting(en)\", \"gbc(base)\"], \"xaxis\": \"x\", \"y\": [0.81339, 0.80382, 0.79904, 0.79904, 0.79904, 0.79425, 0.78947, 0.78947], \"yaxis\": \"y\"}],\n                        {\"height\": 600, \"hovermode\": \"closest\", \"paper_bgcolor\": \"rgb(243, 243, 243)\", \"plot_bgcolor\": \"rgb(243, 243, 243)\", \"title\": {\"text\": \"Models Score on Submission\"}, \"width\": 950, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Models</b>\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"<b>Submission score</b>\"}}},\n                        {\"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('9dd7e112-c210-4fc2-8f23-f9eddbfe42fc');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    ]
                },
                "mc_idx": 293,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 157,
                "o_idx": 0
            }
        }
    ],
    "markdown_cells": [
        {
            "source": "# About this Kernel\nThis kernel may (or may not) be helpful in your long and often tedious machine learning journey. Sometimes you may find this notebook verbose and overwhelming particularly if you're a beginner. This verbosity tries to explain everything I could possibly know. Once you get through the notebook, you could expect to have a good grasp of the fundamentals. I've also tried to write reusable codes as much as possible using custom functions so that we can avoid writing the same code again and again. Let's get started.",
            "mc_idx": 0,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "# Outlines\n\n* [1.Problem Description and Objective](#1)\n* [2.Importing Packages and Collecting Data](#2)\n* [3.Variable Description and Identification](#3)\n   * [3.1 Variable Description](#3.1) [3.2 Categorical and Numerical Variables](#3.2) [3.3 Variable Data Types](#3.3)\n* [4.Univariate Analysis](#4)\n   * [4.1 Categorical Variables](#4.1)\n      * [4.1.1 Survived](#4.1.1) [4.1.2 Sex](#4.1.2) [4.1.3 Pclass](#4.1.3) [4.1.4 Embarked](#4.1.4) [4.1.5 Cabin](#4.1.5) [4.1.6 Name](#4.1.6) [4.1.7 Ticket](#4.1.7) [4.1.8 SibSp](#4.1.8) [4.1.9 Parch](#4.1.9)\n   * [4.2 Numerical Variables](#4.2)    \n      * [4.2.1 Fare](#4.2.1)  [4.2.2 Age](#4.2.2)  [4.2.3 PassengerId](#4.2.3)\n* [5.Feature Engineering](#5)\n   * [5.1 Process Cabin](#5.1) [5.2 Process Name](#5.2) [5.3 Process SibSp & Parch](#5.3)  [5.4 Process Ticket](#5.4)\n* [6.Outliers Detection](#6)\n   * [6.1 Outliers Detection of Age](#6.1)  [6.1 Outliers Detection of Fare](#6.2)\n* [7.Imputing Missing Variables](#7)\n   * [7.1 Impute Embarked & Fare](#7.1)  [7.2 Impute Age](#7.2)\n* [8.Bivariate Analysis](#8)\n   * [8.1 Numerical & Categorical Variables](#8.1)\n      * [8.1.1 Fare & Survived](#8.1.1)   [8.1.2 Age & Survived](#8.1.2)\n   * [8.2 Categorical & Categorical Variables](#8.2)\n      * [8.2.1 Sex & Survived](#8.2.1) [8.2.2 Pclass & Survived](#8.2.2) [8.2.3 Embarked & Survived](#8.2.3) [8.2.4 SIbSp & Survived](#8.2.4) [8.2.5 Parch & Survived](#8.2.5) [8.2.6 nameProcessed & Survived](#8.2.6) [8.2.7 familySize & Survived](#8.2.7) [8.2.8 cabinProcessed & Survived](#8.2.8) [ 8.2.9 ticketProcessed & Survived](#8.2.9)\n* [9.Multivariate Analysis](#9)  \n   * [9.1 (Pclass, Sex, cabinProcessed) vs Survived](#9.1) [9.2 (Pclass, Sex, Embarked) vs Survived](#9.2) [9.3 (Pclass, Sex, SibSp) vs Survived](#9.3) [9.4 (Pclass, Sex, Parch) vs Survived](#9.4) [9.5 (Pclass, Sex, nameProcessed) vs Survived](#9.5) [9.6 (Pclass, Sex, familySize) vs Survived](#9.6) [9.7 (Pclass, Sex, ticketProcessed) vs Survived](#9.7) [9.8 (Pclass, nameProcessed, cabinProcessed) vs Survived](#9.8) [9.9 (familySize, Sex, cabinProcessed) vs Survived](#9.9) [9.10 (Sex, nameProcessed, familySize) vs Survived](#9.10) [9.11 (Sex, nameProcessed, cabinProcessed) vs Survived](#9.11) [9.12 (Sex, nameProcessed, Embarked) vs Survived](#9.12) [9.13 (Sex, nameProcessed, ticketProcessed) vs Survived ](#9.13)\n* [10.Data Transformation](#10) \n   * [10.1 Binning Continuous Variables](#10.1)\n      * [10.1.1 Binning Age](#10.1.1) [10.1.2 Binning Fare](#10.1.2)\n   * [10.2 Dropping Features](#10.2) [10.3 Correcting Data Types](#10.3) [10.4 Encoding Categorical Variables](#10.4)\n* [11.Model Building and Evaluation](#11)   \n   * [11.1 Training Model](#11.1) [11.2 Model Evaluation](#11.2) [11.2.1 Cross Validation](#11.2.1) [11.2.2 Tunning Hyperparameters](#11.2.2) [11.2.3 Model Selection](#11.2.3) [11.3 Retrain & Predict Using Optimized Hyperparameters](#11.3) [11.4 Feature Importance](#11.4) [11.5 Learning Curves](#11.5)\n* [12.More Evaluation Metrics](#12)  \n   * [12.1 Confusion Matrix](#12.1) [12.2 Precision Score](#12.2) [12.3 Recall (or Sensitivity or True Positive Rate)](#12.3) [12.4 Specificity ( or True Negative Rate)](#12.4) [12.5 F1 Score](#12.5) [12.6 Classification Report](#12.6) [12.7 Precision-Recall vs Threshold Curve](#12.7) [12.8 Precision-Recall Curve](#12.8) [12.9 ROC  Curve & AUC Score ](#12.9)\n* [13.Prediction & Submission](#13) \n* [14.Introduction to Ensemble](#14)\n   * [14.1 Hard Voting Ensemble](#14.1) [14.2 Introduction to PCA](#14.2) [14.3 Soft Voting Ensemble](#14.3) [14.4 Bagging](#14.4) [14.5 Boosting](#14.5) [14.6 Blending](#14.6) [14.7 Stacking](#14.7) [14.8 Evaluating Different Ensembles](#14.8)\n* [15.End Note](#15)",
            "mc_idx": 1,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "# 1.Problem Description and Objective <a id=\"1\"></a>\nThe sinking of the RMS Titanic is one of the most notorious shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crews. This harrowing tragedy shocked the international community and led to better safety regulations for ships.\n\nIn this problem, we're asked to complete the analysis of what sorts of passengers were likely to survive the tragedy using machine learning. So its our job to predict if a passenger survived from the sinking Titanic or not with the help of machine learning. So its a binary classification problem.\n\n# 2.Importing Packages and Collecting Data <a id=\"2\"></a>\nAfter importing required modules, let's read train and test data from csv files.",
            "mc_idx": 2,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "**Note:** We don't have Survived variable for test set. This will be our task to infer Survived for test set by learning from the train set.",
            "mc_idx": 6,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "# 3.Variable Description and Identification <a id=\"3\"></a>\nLet's describe what each of the variable indicates and identify our response and predictor variables. Also seperate the categorical variables from numerical variables and finally identify pandas data types (i.e., object, float64 or int64) for every variable.\n\n## 3.1 Variable Description <a id=\"3.1\"></a>",
            "mc_idx": 7,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "### So what can we see??\n**We can see total 12 variables. And each variable has 1309 observations (excluding Survived).**\n### Here comes the description of all variables:\n1. **PassengerId** is a unique identifying number assigned to each passenger.\n2. **Survived** is a flag that indicates if a passenger survived or died ( i.e., 0 = No, 1 = Yes).\n3. **Pclass** is the passenger class (i.e., 1 = 1st class, 2 = 2nd class, 3 = 3rd class).\n4. **Name** is the name of the passenger.\n5. **Sex** indicates the gender of the passenger (i.e., Male or female).\n6. **Age** indicates the age of the passenger.\n7. **Sibsp**  is the number of siblings/spouses aboard.\n8. **Parch** is the number of parents/children aboard.\n9. **Ticket** indicates the ticket number issued to the passenger.\n10. **Fare** indicates the amount of money spent on their ticket.\n11. **Cabin** indicates the cabin category occupied by the passenger.\n12. **Embarked** indicates the port where the passenger embarked from (i.e., C = Cherbourg, Q = Queenstown, S = Southampton).\n\n\n### Here, Survived is the target variable and rest of the variables are predictor variables.\n\n## 3.2 Categorical and Numerical Variables  <a id=\"3.2\"></a>\n**Categorical Variable:** Survived, Sex, Pclass (ordinal), Embarked, Cabin, Name, Ticket, SibSp, and Parch.\n\n**Numerical Variable:** Fare, Age, and PassengerId.\n## 3.3 Variable Data Types <a id=\"3.3\"></a>",
            "mc_idx": 10,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "1. **int data type variables:** Pclass, SibSp, Parch, and PassengerId.\n2. **float data type variables:** Fare and Age, *Survived (due to concatenation)*\n3. **object (numbers + strings) data type variables:** Name, Sex, Ticket, Cabin, and Embarked.\n\n# 4.Univariate Analysis <a id=\"4\"></a>\nUnivariate analysis separately explores the distribution of each variable in a data set. It looks at the range of values, as well as the central tendency of the values. Univariate data analysis does not look at relationships between various variables (like bivariate and multivariate analysis) rather it summarises each variable on its own. Methods to perform univariate analysis will depend on whether the variable is categorical or numerical. For numerical variable, we would explore its shape of distribution (distribution can either be symmetric or skewed) using histogram and density plots. For categorical variables, we would use bar plots to visualize the absolute and proportional frequency distribution. Knowing the distribution of the feature values becomes important when you use machine learning methods that assume a particular type of it, most often Gaussian. **Let's starts off with categorical variables:**\n\n## 4.1 Categorical Variables  <a id=\"4.1\"></a>\nTo analyse categorical variables, let's create a custom function to display bar chart in absolute and relative scale of a variable in a subplot.",
            "mc_idx": 12,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "###  4.1.1 Survived <a id=\"4.1.1\"></a>",
            "mc_idx": 14,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Variable Survived is imbalanced since the proportion of survivors and victims is not equally represented in its distribution. Out of 891 passengers, only 342 passengers survived and a whopping 549 passengers died. Or put another way, 61.62% passengers died while just 38.38% of passengers were lucky enough to survive.",
            "mc_idx": 16,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "### 4.1.2 Sex <a id=\"4.1.2\"></a>",
            "mc_idx": 17,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Variable Sex is imbalanced as proportion of male vs female in its distribution are not equally represented. Rather Male(843) has outnumbered female (466) in variable Sex. Or, proportionally, over 64% of Sex variable consists of label male while female contibutes to only over 35.5% of Sex.\n\n### 4.1.3 Pclass  <a id=\"4.1.3\"></a>",
            "mc_idx": 19,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Again class distribution of Pclass is imbalanced as three categories of Pclass are not evenly represented in its distribution. 3 (Pclass3) is the most occured (709) levels of Pclass while 2 is the least occured (277). Another way of saying that, over  54% of Pclass variable consists of 3(Pclass3) while 1 and 2 both combinedly contribute to nearly 46% of Pclass.\n\n### 4.1.4 Embarked  <a id=\"4.1.4\"></a>",
            "mc_idx": 21,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Embarked is also imbalanced since its levels are not equally represented in its distribution. A whopping 914 passengers embarked from Southamton while just 123 embarked from Queenstown. In other words, almost 70% of Embarked consists of S while both C and Q contribute to 30 to Embarked.\n\n### 4.1.5 Cabin <a id=\"4.1.5\"></a>",
            "mc_idx": 23,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Looks like Cabin is an alphanumeric type variable with 1014 missing obsevations. There are 187 kinds of categories in variable Cabin. Since there are too many categories in Cabin, we must process (i.e., reduce the number of categories) Cabin to check if there is any association between Survived and Cabin.\n\n### 4.1.6 Name <a id=\"4.1.6\"></a>",
            "mc_idx": 27,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** As expected Name contains strings that has 1307 variations. So, like Cabin, we must process Name to get any clue about survival from it.\n\n### 4.1.7 Ticket  <a id=\"4.1.7\"></a>",
            "mc_idx": 30,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** It seems Ticket also has too many unique categories (929). Being an alphanumeric type variable, we must process Ticket to get any useful insights about survival.\n\n### 4.1.8 SibSp  <a id=\"4.1.8\"></a>",
            "mc_idx": 33,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Once again, SibSp is not balanced as levels of SibSp(7) are not equally represented in its distribution. 891 passengers were without siblings or spouses. Put another way, over 68% passengers had no siblings or spouses aboard, followed by over 24% passengers had 1 siblings or spouse.\n\n### 4.1.9 Parch  <a id=\"4.1.9\"></a>",
            "mc_idx": 35,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Parch isn't balanced as levels of Parch(8) are not equally represented in its distribution. Over one thousand passengers were without parents or children, followed by 170 passengers had one parents or children. In other words, over 76.5% passengers were without parents or children while rest of the 23.5% had few parents or children.\n\n## 4.2 Numerical Variables <a id=\"4.2\"></a>\nWe would like to analyse numerical variables using histogram, density plot, and summary statistics. To analyse numerical variables, we will create 2 custom functions. The 1st one will plot histogram and density plot for each numerical variable. And the 2nd one will calculate summary statistics including skewness.",
            "mc_idx": 37,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "### 4.2.1 Fare <a id=\"4.2.1\"></a>",
            "mc_idx": 39,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "**Reading the histogram, it's clear that Fare's distribution has a high positive skewness. And it seems a number of passengers (653) paid for fare between 5 to 15 (less than 15), followed by 25 to 35 (less than 35).**\n\nThere is also another, often clearer, way to grasp the distribution: density plots or, more formally, Kernel Density Plots. They can be considered a smoothed version of the histogram. One advantage of density plot over histogram is that its shape of distribution isn't affected by the number of bins used.",
            "mc_idx": 41,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "**So what does the  value of skewness suggest?**\n1. If skewness is less than \u22121 or greater than +1, the distribution can be considered as highly skewed.\n2. If skewness is between \u22121 and \u2212\u00bd or between +\u00bd and +1, the distribution can be considered as moderately skewed.\n3. And finally if skewness is between \u2212\u00bd and +\u00bd, the distribution can be considered as approximately symmetric.    \n\n**Findings:** Density plot shows the mass of the distribution of Fare is heavily concentrated on the left of the figure due to very long tail on the right side. So it can be said that Fare is substantially skewed(positively) that is also supported by the calculated positive value of skewness of 4.37\n\n### 4.2.2 Age <a id=\"4.2.2\"></a>",
            "mc_idx": 43,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "**At first glance, Age seems to be positively skewed (slightly). 344 passengers' age is between 20 to 30(less than 30). And passengers between age 70 to 80(including 80) was 8 were the least.**",
            "mc_idx": 46,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** What we can see from the density plot is that the mass of the distribution of Age is slightly concentrated on the left of the figure due to comparatively long tail on the right side. So it can be said that Age is almost normally distributed since the tail on the both sides are almost equal and it has a small value of positive skewness of 0.41 (in between -0.5 to 0.5). So it can be said that Age is almost normally distributed.\n\n### 4.2.3 PassengerId <a id=\"4.2.3\"></a>",
            "mc_idx": 47,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** PassengersId is an unique identity number (positive integer) assigned to each passenger.\n\n# 5.Feature Engineering <a id=\"5\"></a>\nIn this section, we would either modify or create new features from the exsisting features which are otherwise hard to analyse in their raw forms that we saw in Univariate Analysis section. We would engineer features like Cabin, Name, SibSp & Parch, and Ticket that could tell us something about survival or death once they're processed.\n\n## 5.1 Process Cabin <a id=\"5.1\"></a>",
            "mc_idx": 49,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 512,
            "cell_type": "markdown"
        },
        {
            "source": "Looks like Cabin is alphanumeric type variable with no special characters (like ., /, % etc) between letters and numbers. It has also 1014 missing obsevations. It is reasonable to presume that those NaNs didn't have a cabin, which could tell us something about 'Survived'. We will flag NaN as 'X' and keep only the 1st character where Cabin has alphanumeric values. Since its a categorical variable, we must reduce the number of categories for further analysis. **To avoid mutability, we won't change any variable's state in place, rather we'll create a brand new variable.**",
            "mc_idx": 53,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** It seems nearly 77.5% of passengers had X cabin category (formerly NaNs), followed by over 7% had cabin category C and nearly 5% had cabin category B.\n\n## 5.2 Process Name <a id=\"5.2\"></a>",
            "mc_idx": 57,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "What we can easily understand from this column, it contains strings that further contains titles such as Mr, Mrs, Master etc. These titles give us some useful information about sex(Mr = male, Mrs = married female), age(Miss is usually younger than Mrs), and profession(Master indicates profession and hence social status) etc which in the end could tell us something more about survival. Now we want to extract these titles from Name to check if there is any association between these titles and Survived.",
            "mc_idx": 59,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "We can see there are several titles with the very least frequency. So, it makes sense to put them in fewer buckets. Professionals like Dr, Rev, Col, Major, Capt will be put into 'Officer' bucket. First name such as Dona, Jonkheer, Countess, Sir, Lady, Don were usually entitled to the aristocrats and hence these first name will be put into bucket 'Aristocrat'. We would also replace Mlle and Ms with Miss and Mme by Mrs as these are French titles.",
            "mc_idx": 62,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Nearly 58% passengers had title Mr(male of course), followed almost 20% passengers had titles Miss(unmarried women hence usually younger than Mrs). Just over 15% passengers were married women (Mrs).\n\n## 5.3 Process SibSp & Parch <a id=\"5.3\"></a>\nIn univariate analysis, we saw some passengers had siblings/spouses and some didn't have. The same is also true for variable Parch. Since these two variables together indicate the size of a family, we would create a new variable 'familySize' from these two variables.",
            "mc_idx": 66,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "We see there are several family sizes with the very least frequency. So its sensible to put them in a fewer buckets. We will create 4 buckets namely single, small, medium, and large for rest of them.",
            "mc_idx": 68,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Looks like most of the passengers (over 60%) were single(without family), followed by 30% passengers had a small family. Almost 5% passengers had medium families and just over 4.5% passengers had large families abroad.\n\n## 5.4 Process Ticket <a id=\"5.4\"></a>",
            "mc_idx": 71,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Ticket is also an alphanumeric type variable. We will create two groups-one will contain just number and other will only contain character extracted from string. If a row contains both character and number, we will keep only character.",
            "mc_idx": 73,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Over 73% passengers had ticket of category N, followed by nearly 7.5% passengers ticket category were S and P. Passengers with W ticket category were as low as 1.45%.\n\n# 6.Outliers Detection <a id=\"6\"></a>\n**How outliers affect the distribution:** If a value of a variable is significantly above the expected range, it will drag the distribution to the right, making the graph right-skewed or positive-skewed (like Fare). Alternatively, If a value is significantly below the expected range, it will drag the distribution to the left, making the graph left-skewed or negative-skewed.\n\nAnother useful plot for visualizing a continuous variable is box plot. Box plot is particularly helpful to understand the spread of the continus data and whether there are potential unusual observations (outliers) in that variable. It presents information of min, 1st quartile, 2nd quartile(median), 3rd quartile, and max of a variable.**We will use IQR method to detect the outliers for variable Age and Fare though we won't remove them.**",
            "mc_idx": 77,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 6.1 Outliers Detection for Age <a id=\"6.1\"></a>",
            "mc_idx": 79,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**For a box plot, if the longer part of the box is right (or above) to the median, the data is said to be skewed right. If the longer part is  left (or below) to the median, the data is skewed left. In our case, the bigger part of the box is right to the median**\n\n## 6.2 Outliers Detection for Fare <a id=\"6.2\"></a>",
            "mc_idx": 81,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 7.Imputing Missing Variables <a id=\"7\"></a>\nThe simpliest way to impute missing values of a variable is to impute its missing values with its mean, median or mode depending on its distribution and variable type(categorical or numerical). By now, we should have a good idea about the distribution of the variables and the presence of outliers in those variables. For categorical variables mode-imputation is performed and for numerical variable mean-impuation is performed if its distribution is symmetric(or almost symmetric or normal like Age). On the other hand, for a variable with skewed distribution and outliers (like Fare), meadian-imputation is recommended as median is more immune to outliers than mean. \n\nHowever, one clear disadvantage of using mean, median or mode to impute missing values is the addition of bias if the amount of missing values is significant (like Age). So simply replacing them with the mean or the median age might not be the best solution since the age may differ by groups and categories of passengers.\n\nTo solve this, we can group our data by some variables that have no missing values and for each subset compute the median age to impute the missing values. Or we can build a linear regression model that will predict missing values of Age using the features that have no missing values. These two methods may result in better accuracy without high bias, unless a missing value is expected to have a very high variance. We will show the former method of imputation.",
            "mc_idx": 83,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**The above plot shows the most missing values for Cabin, Survived, followed by Age, Embarked and Fare. Since we created a new variable cabinProcessed off Cabin, we don't need to impute Cabin.**",
            "mc_idx": 86,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** \n1. Age has 263 missing values.\n2. Fare has only 1.\n3. Cabin has a whopping 1014 missing values.\n4. Embarked has just 2 missing values.\n5. **Finally Survived has missing values (due to concatenation of train and test set) that we would predict learning from the train dataset.**\n\n**Remember we have total 1309 observations except variable Survived.**\n\n## 7.1 Impute Embarked & Fare <a id=\"7.1\"></a>",
            "mc_idx": 87,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 7.2 Impute Age <a id=\"7.2\"></a>\nTo impute Age with grouped median, we need to know which features are highly correlated with Age. Let's find out the variables correlated with Age.",
            "mc_idx": 89,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** \n1. Age distribution seems to be the same in male and female subpopulations of Sex and S, C, Q subpopulations of Embarked. So Sex and Embarked aren't good predictors for Age.\n2. On the other hand, Age distribution seems to be distinct in Pclass's 1, 2 and 3 subpopulations, so Pclass is informative to predict Age.\n3. Finally, Age distribution seems to be distinct in different categories for nameProcessed, familySize, SibSp, Parch, and cabinProcessed. So they might be good predictors for Age as well.",
            "mc_idx": 91,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** As expected Sex, Embarked, and ticketProcessed have the weakest correlation with Age what we could guess beforehand from boxplot. Parch and familySize are moderately correlated with Age. nameProcessed, Pclass, Cabin, and SibSp have the highest correlation with Age. But we are gonna use nameProcessed and Pclass only in order to impute Age since they have the strongest correlation with Age. So the tactic is to impute missing values of Age with the median age of similar rows according to nameProcessed and Pclass.",
            "mc_idx": 93,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 8.Bivariate Analysis <a id=\"8\"></a>\nBeing the most important part, bivariate analysis tries to find the relationship between two variables. We will look for correlation or association between our predictor and target variables. Bivariate analysis is performed for any combination of categorical and numerical variables. The combination can be: Numerical & Numerical, Numerical & Categorical and Categorical & Categorical. Different methods are used to tackle these combinations during analysis process. The methods are:\n1. Numerical & Numerical: Pearson's correlation, or Spearman correlation (the later doesn't require normal distribution).\n2. Numerical & Categorical: Point biserial correlation (only  if categorical variable is binary type), or ANOVA test. For this problem, you can use either biserial correlation or ANOVA. But I will perform both test just to learn because ANOVA will come in handy if categorical variable has more than two classes.\n3. Categorical & Categorical: We would use Chi-square test for bivariate analysis between categorical variables.\n\n## 8.1 Numerical & Categorical Variables <a id=\"8.1\"></a>\nFirst we create a boxplot between our numerical and categorical variables to check if the distribution of numerical variable is distinct in different classes of nominal variables. Then we find the mean of numerical variable for every class of categorical variable. Again we plot a histogram of numerical variable for every class of categorical variable. Finally anova or point biserial correlation (in case of two class categorical variable) is calculated to find association between nominal and numerical variables.   ",
            "mc_idx": 95,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 8.1.1 Fare & Survived <a id=\"8.1.1\"></a>",
            "mc_idx": 97,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** The distribution of Fare between different categories of Survived (0 and 1) are distinct (very least overlap) that makes it comparatively strong predictor for Survived what is kind of true from the correlation value of  0.257307 and the p value (less than 0.01) that suggests we're 99% confident that this correlation is statistically significant. Also survival is positively correlated to Fare, so the more you pay for fare, the more your chances are to survive that is quite evident from the box plot.",
            "mc_idx": 99,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Looks like, on average, if you pay more for your ticket, you are more likely to survive. Let's plot histogram of survivors and victims fare together to validate our intuition:**",
            "mc_idx": 101,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**That's true. Passengers who paid more for their fair, mostly survived.**\n\n**ANOVA:** \nThe ANOVA(ANalysis Of VAriance) test lets us check whether a numeric response variable varies according to the levels (or class) of a categorical variable. When we simply refer to 'ANOVA', we usually mean the 'one way' ANOVA which is a test for exploring the impact of one single factor on three or more groups (but two groups would also do, as we explain below).\n\nThough one should use either point biserial correlation (if categorical variable is of binary type) or ANOVA method for this problem to find any association between a categorical and a numerical variable, I would perform ANOVA too to have an intuition of how ANOVA works. Though ANOVA is usually prefered if the categorical variable having more than two groups, it is also possible to perform ANOVA for a categorical variable with two groups.\n\nThe one-way ANOVA tests whether the mean of some numeric variable differs across the levels of one categorical variable. It essentially answers the question: do any of the group means differ from one another? The null hypothesis is all of the group means are equal. And the alternate hypothesis is any of the group means differ from one another.",
            "mc_idx": 103,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Interpretation of ANOVA result:**\nAs p < 0.05 we state that we have a main interaction effect. This simply means that amongst the groups at least any of the group(or groups) means statistically significantly  differ from one another (true for only more than two groups). However, this result does not identify the sample pair (or pairs) which cause this significance (again true for more than two groups of categorical variable but we have just two groups..i.e., 0 and 1).\nSo, when ANOVA reports 'interaction effect' we need to further identify the group pairs by applying pair-wise controls(required for more than two groups of categorical variable). Although these controls could be done by implementing ordinary t-test but this is not the right approach. So a post hoc-test ( usually Tukey's test) is performed to find the pair or pairs that cause the difference. Though Tukey's test is not required with a categorical variable less than three groups.\n\n***Note:*** Tukey's test is not required if ANOVA gives a p value greater than 0.05 and nominal variable has less than three groups. ",
            "mc_idx": 105,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\n### 8.1.2 Age & Survived <a id=\"8.1.2\"></a>",
            "mc_idx": 106,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Box plot shows the distribution of Age between categories of Survived (1 and 0) has significant overlap which is also kind of true from a small correlation value of -0.05939. And a p value greater than 0.05 indicates that there is no evidence that the correlation is statistically significant. As we can see that Survived is inversly correlated to Age, so if you are younger, you are just likely to survive.",
            "mc_idx": 108,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Analysing box and above bar plot, we have a feeling that younger people, on average, were just more likely to survive. Let's plot one histogram of survivors' age and another of victims' age to validate our intuition.**",
            "mc_idx": 110,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**We see infants and children had high survival rate. The oldest passengers (Age = 80) also survived. A large number of passengers aged from 16 to 30 died.**",
            "mc_idx": 112,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Note:** Choose either biserial correlation (if categorical variable has two groups) or Anova. If anova states main interaction effect(i.e.,p<0.05) and categorical variable has more than two categories ( like good, better, best), then perform tukey test to find out the pair or pairs that cause the difference(i.e., main interaction effect).\n\n**Interpretation of ANOVA result:**\nSince p>0.05, we can say that survival chance is not statistically associated with Age.\n\n## 8.2 Categorical & Categorical Variables <a id=\"8.2\"></a>\nWe will calculate and plot absolute and relative frequency of output categorical variable by predictor nominal variables. We would calculate the chi square test between target nominal and predictor nominal variables. Finally we will calculate Bonferroni-adjusted P value if the contingency table has dimension more than 2x2.",
            "mc_idx": 114,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 8.2.1 Sex & Survived <a id=\"8.2.1\"></a>",
            "mc_idx": 116,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Out of 342 survivors, 233 passergers were female while only 109 passengers were male. So female survivors were more than double the male survivors. Proportion tells a female has over 74% chance of survival while male has almost 19% chance of survival. So female has the best chance of survival.\n\n***Chi-square Test***: The Chi-square test of independence tests if there is a significant relationship between two categorical variables.The data is usually displayed in a cross-tabulation format with each row representing a category for one variable and each column representing a category for another variable. Chi-square test of independence is an omnibus test.That is it tests the data as a whole. This means that one will not be able to tell which levels (categories) of the variables are responsible for the relationship **if the Chi-square table is larger than 2\u00d72. If the test is larger than 2\u00d72, it requires post hoc testing.**\n\n**The H0 (Null Hypothesis): There is no relationship between variable 1 and variable 2.**\n\n**The H1 (Alternative Hypothesis): There is a relationship between variable 1 and variable 2.**\n\nIf the p-value is significant (less than 0.05), you can reject the null hypothesis and claim that the findings support the alternate hypothesis. While we check the results of the chi2 test, we need also to check that the expected cell frequencies are greater than or equal to 5. If a cell has an expected frequency less that 5, then the Fisher\u2019s Exact test should be use to overcome this problem.\n\nThe chi2_contingency() method conducts the Chi-square test on a contingency table (crosstab).",
            "mc_idx": 118,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "***Interpretation of chi-square test outcome***: The first value (260.717) is the Chi-square value, followed by the p-value (1.197e-58), then comes the degrees of freedom (1), and lastly it outputs the expected frequencies as an array. Since all of the expected frequencies are greater than 5, the chi2 test results can be trusted. We can reject the null hypothesis as the p-value is less than 0.05(infact p value is almost 0).  Thus, the results indicate that there is a statistically significant relationship between Sex and Survived.\n\n### 8.2.2 Pclass & Survived <a id=\"8.2.2\"></a>",
            "mc_idx": 120,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Out of 342 survivors, pclass1(136) has the most number of survivors followed by pclass3(119) and pclass2(87). But the percentage tells different story. If you're in class1, your survival chance is nearly 63% while pclass2 has just over 47% survival chance. But if you are in class3, your chance of survival is very bleak, i.e.,just over 24%.",
            "mc_idx": 122,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Interpretation of chi-square test outcome:** The overall 3x2 table has a chi-square value of 102.889, pvalue  of 4.549e-23, degrees of freedom of 2 and the rest are the expected frequencies of array. Since all of the expected frequencies are greater than 5, the chi2 test results can be trusted. We can reject the null hypothesis as the p-value is less than 0.05(infact p value is almost 0). Thus, the results indicate that there is a statistically significant relationship between Pclass and titanic's survivors. \n\n\n**Post Hoc Test**: Although our Chi-square test was signficant, since our analysis is 3x2 we don't know which levels of Pclass(1, 2 or 3) have the strongest association with variable Survived. Hence we need to perform a post hoc test to verify if and which combinations are actually significantly associated with Survived. In order to do this, we need to conduct multiple 2\u00d72 Chi-square tests using the *Bonferroni-adjusted p-value.*\n\nTo conduct multiple 2\u00d72 Chi-square tests, one needs to regroup the variables for each test to where it is one category against the rest. For us, it will be:\n\n1. 1 vs 2\n2. 1 vs 3\n3. And finally 2 vs 3\n\n**Because there are 3 comparisons, the Bonferroni-adjusted P value needed for significance is 0.05/3, or 0.017. So for our any planned pairwise comparisons to be significant, the p-value must be less than 0.017.**",
            "mc_idx": 124,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Interpretation of the outcome of  Bonferroni-adjusted p-value test:** Using the Bonferroni-adjusted p-value of 0.017, 3 out of 3 planned pairwise comparisons are significant. Though p value suggests Pclass2 has the weakest association with Survived compared to Pclass1 and Pclass3.\n\n###  8.2.3 Embarked & Survived <a id=\"8.2.3\"></a>",
            "mc_idx": 126,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Though people embarked from Southampton have the most survivors count (219) but proportion-wise it has only nearly 34% chance of survival. Because 427 passengers embarked from Southampton died. On the contrary, if you would embark from Cherbourg, you have a very decent chance of survival of over 55%.  Finally, people embarked from  Queenstown have a chance of survival more than 5% from those who embarked from Southampton.",
            "mc_idx": 128,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Interpretation of chi-square test result:** The  3x2 table has a chi-square value of 25.96, pvalue of 2.3e-06, degrees of freedom of 2 and the rest are the expected frequencies of array. Since all of the expected frequencies are greater than 5, the chi2 test results can be trusted. We can reject the null hypothesis as the p-value is less than 0.05(infact p value is less than 0.01). Thus, the results indicate that there is a statistically significant relationship between the variables Embarked and Survived.\n\n**Because there are three comparisons, the Bonferroni-adjusted P value needed for significance is 0.05/3, or 0.017. So for our any planned pairwise comparisons to be significant, the p-value must be less than 0.017.**",
            "mc_idx": 130,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Interpreting the result of pair-wise Bonferroni-adjusted pvalue:** Using the Bonferroni-adjusted p-value of 0.017, 2 of the 3 planned pairwise comparisons are significant. Bonferroni-adjusted p-value for Q and Survived is 0.989 which is way greater than 0.017. So it can be said that level Q of variable Embarked is not statistically associated with variable Survived.\n\n### 8.2.4 SibSp & Survived <a id=\"8.2.4\"></a>",
            "mc_idx": 132,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** A large number of passengers (210) who survived were without (0) any siblings or spouse, followed by 112 passengers with 1 spouse or siblings. Percentage-wise, passengers with 1 spouse or siblings had over 53.5% chance of survival, followed by passengers with 2 siblings or spouse had over 46% chance of survival. Passengers with 5 or 8 siblings or spouse had all died.",
            "mc_idx": 134,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Interpretation of Chi-square Test:**  Since all the expected frequencies aren't greater than 5, chi-square test result can't be trusted.\n\n### 8.2.5 Parch & Survived  <a id=\"8.2.5\"></a>",
            "mc_idx": 136,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Passengers with 3 children/parent had 60% survival rate, followed by passengers with 2 children/parent has a 50% survival rate. No passengers survived with 4 or 6 children/parent.",
            "mc_idx": 138,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Interpretation of Chi-square Test Outcome:**  Since all the expected frequencies aren't greater than 5, chi-square test result can't be trusted.\n\n### 8.2.6 nameProcessed & Survived <a id=\"8.2.6\"></a>",
            "mc_idx": 140,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Women had the best survival rate, i.e., Mrs(over 79%) and Miss(over 70%) that reminds us the variable Sex where we have seen female were more likely to survive in. Mr is the worst title to have when it comes to survival situation since just over 15% of passengers with title Mr survived that again indicates the importance of Sex as a deal breaker for survival.",
            "mc_idx": 142,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Interpretation of chi-square test result**: Since all the expected frequencies aren't greater than 5, chi-square test result can't be trusted.\n\n### 8.2.7 familySize & Survived <a id=\"8.2.7\"></a>",
            "mc_idx": 144,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Passengers with small and medium familiy size had good survival rate. Single passengers had survival chance of just over 30%. And passengers with large families has a survival rate below 15%.",
            "mc_idx": 146,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Interpretation of chi-square test result**:Since all of the expected frequencies are greater than 5, the chi2 test results can be trusted. We can reject the null hypothesis as the p-value is less than 0.05(infact p value is almost 0). Thus, the results indicate that there is a statistically significant relationship between variable Family_size and Survived.\n\n**Because there are 8 comparisons, the Bonferroni-adjusted P value needed for significance is 0.05/8, or 0.0063. So for our any planned pairwise comparisons to be significant, the p-value must be less than 0.0063.**",
            "mc_idx": 148,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Interpretation of Bonferroni-adjusted Post-hoc test result:** Using the Bonferroni-adjusted p-value of 0.0063, 3 of the 4 planned pairwise comparisons are significant. Bonferroni-adjusted p-value for medium and Survived is 0.03555 which is way greater than 0.0063. So it can be said that level medium of variable familySize is not statistically associated with variable Survived.\n\n### 8.2.8 cabinProcessed & Survived <a id=\"8.2.8\"></a>",
            "mc_idx": 150,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Most of the passengers survived and died were from cabin X. But percentage-wise, its category B, D, and E that had impressive chance of survival. People from cabin category X had just 30% chance of survival.",
            "mc_idx": 152,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Interpretation of chi-square test result**: Since all of the expected frequencies aren't greater than 5, the chi2 test results can't be trusted.\n\n### 8.2.9 ticketProcessed & Survived <a id=\"8.2.9\"></a>",
            "mc_idx": 154,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** 93% passengers died with ticket category A, over 64% survived from category P. Over 57% survived from F and just over 15% passengers survived from ticket category W.",
            "mc_idx": 156,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Interpretation of chi-square test result**: Since all of the expected frequencies aren't greater than 5, the chi2 test results can't be trusted.\n\n# 9.Multivariate Analysis <a id=\"9\"></a>\nIn multivariate analysis, we try to find the relationship among more than two variables. Number of predictor variable in bivariate analysis was one. On the contrary, number of predictor variables for multivariate analysis are more than one. More specifically, we will try to associate more than one predictor variable with the response variable. We will just visualize the impact of different predictor variables (3 variables) at a time on variable Survived.",
            "mc_idx": 158,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 9.1 (Pclass, Sex, cabinProcessed) vs Survived <a id=\"9.1\"></a>",
            "mc_idx": 160,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 9.2 (Pclass, Sex, Embarked) vs Survived <a id=\"9.2\"></a>",
            "mc_idx": 162,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 9.3 (Pclass, Sex, SibSp) vs Survived <a id=\"9.3\"></a>",
            "mc_idx": 164,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 9.4 (Pclass, Sex, Parch) vs Survived <a id=\"9.4\"></a>",
            "mc_idx": 166,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 9.5 (Pclass, Sex, nameProcessed) vs Survived <a id=\"9.5\"></a>",
            "mc_idx": 168,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 9.6 (Pclass, Sex, familySize) vs Survived <a id=\"9.6\"></a>",
            "mc_idx": 170,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 9.7 (Pclass, Sex, ticketProcessed) vs Survived <a id=\"9.7\"></a>",
            "mc_idx": 172,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 9.8 (Pclass, nameProcessed, cabinProcessed) vs Survived <a id=\"9.8\"></a>",
            "mc_idx": 174,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 9.9 (familySize, Sex, cabinProcessed) vs Survived <a id=\"9.9\"></a>",
            "mc_idx": 176,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 9.10 (Sex, nameProcessed, familySize) vs Survived <a id=\"9.10\"></a>",
            "mc_idx": 178,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 9.11 (Sex, nameProcessed, cabinProcessed) vs Survived <a id=\"9.11\"></a>",
            "mc_idx": 180,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 9.12 (Sex, nameProcessed, Embarked) vs Survived <a id=\"9.12\"></a>",
            "mc_idx": 182,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 9.13 (Sex, nameProcessed, ticketProcessed) vs Survived <a id=\"9.13\"></a>",
            "mc_idx": 184,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 10.Data Transformation <a id=\"10\"></a>\nIn this section, we will categorize our continuous variables. After that, redundant and useless features will be dropped. And finally categorical variables will be encoded into numerical variables to feed our machine learning models.\n\n## 10.1 Binning Continuous Variables <a id=\"10.1\"></a>\nWe saw Age is inversely correlated with survival and infants were more likely to survive. We will create some categories of age to check which categories of age  are more likely to survive. We would do the same for Fare except Fair is posivively correlated with Survived.\n\n**Note:** Binning continuous variables prevents overfitting which is a common problem for tree based models like decision trees and random forest etc.\n\n### 10.1.1 Binning Age <a id=\"10.1.1\"></a>",
            "mc_idx": 186,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 10.1.2 Binning Fare <a id=\"10.1.2\"></a>",
            "mc_idx": 188,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "##  10.2 Dropping Features <a id=\"10.2\"></a>\nNow we have both transformed and the original variables transformation have been made from. So we should safely drop the variables that we think would not be useful anymore for our survival analysis since they are very unlikely to be analyzed in their raw forms.",
            "mc_idx": 190,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 10.3 Correcting Data Types <a id=\"10.3\"></a>",
            "mc_idx": 193,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "1. PassengerId, SibSp, and Parch data types will be kept same (integer).\n2. Survived data type will be converted into integer and rest of the variables' data types will be converted into categorical data types.",
            "mc_idx": 195,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 10.4 Encoding Categorical Variables <a id=\"10.4\"></a>\nWe would like to use one hot encoding instead of label encoding because algorithm might give weights to higher values if label encoding is used to encode numeric variables.",
            "mc_idx": 198,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 11.Model Building and Evaluation <a id=\"11\"></a>\nWith all the preprocessings done and dusted, we're ready to train classifiers with the processed data. First extract train and test data from variable merged. Then feed the training data to the classifiers we're interested in for this problem.",
            "mc_idx": 200,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 11.1 Training Model <a id=\"11.1\"></a>\nWe would train 10 different classifiers for this binary classification problem.",
            "mc_idx": 205,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Looks like all the tree based models have highest train accuracy followed KNN, LR, ABC and SVC. But train accuracy of a model is not enough to tell if a model can be able to generalize the unseen data or not. Because training data is something our model has been trained with, i.e., data our model has already seen it. We all know that, the purpose of building a machine learning model is to generalize the unseen data, i.e., data our model has not yet seen. Hence we can't use training accuracy for our model evaluation rather we must know how our model will perform on the data our model is yet to see.**\n\n## 11.2 Model Evaluation <a id=\"11.2\"></a>\nSo basically, to evaluate a model's performance, we need some data (input) for which we know the ground truth(label). For this problem, we don't know the ground truth for the test set but we do know for the train set. So the idea is to train and evaluate the model performance on different data. One thing we can do is to split the train set in two groups, usually in 80:20 ratio. That means we would train our model on 80% of the training data and we reserve the rest 20% for evaluating the model since we know the ground truth for this 20% data. Then we can compare our model prediction with this ground truth (for 20% data). That's how we can tell how our model would perform on unseen data. This is the first model evaluation technique. In sklearn we have a train_test_split method for that.\n\nTrain_test split has its drawbacks. Because this approach introduces bias as we are not using all of our observations for testing and also we're  reducing the train data size. To overcome this we can use a technique called cross validation where all the data is used for training and testing periodically. Thus we may reduce the bias introduced by train_test_split. From different cross validation methods, we would use k-fold cross validation. In sklearn we have a method cross_val_score for calculating k-fold cross validation score.\n\nHowever,  as the train set gets larger, train_test_split has its advantage over k-fold cross validation. Train_test_split is k-times faster than k-fold cross validation. If the training set is very large, both train_test_split and k-fold cross validation perform identically. So for a large training data, train_test_split is prefered over k-fold cross validation to accelerate the training process.\n\n### 11.2.1 K-Fold Cross Validation <a id=\"11.2.1\"></a>\nLet's say we will use 10-fold cross validation. So k = 10 and we have total 891 observations. Each fold would have 891/10 = 89.1 observations. So basically k-fold cross validation uses fold-1 (89.1 samples) as the testing set and k-1 (9 folds) as the training sets and calculates test accuracy.This procedure is repeated k times (if k = 10, then 10 times); each time, a different group of observations is treated as a validation or test set. This process results in k estimates of the test accuracy which are then averaged out.",
            "mc_idx": 208,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**I've always found that trying out multiple algorithms on the same problem reveals very interesting differences in the patterns the algorithms pick up well. Algorithms disagree on predictions because they've different ways of viewing the data.**\n\n**Findings:** Looks like LR and SVC have the highest cross validation accuracy among the classifiers, followed by GBC, XGBC, KNN, ABC, RF, and ETC.\n\n## 11.2.2 Tuning Hyperparameters  <a id=\"11.2.2\"></a>\n**Now let's add Grid Search to all the classifiers with the hopes of optimizing their hyperparameters and thus improving their accuracy. Are the default model parameters the best bet? Let's find out.**\n\n**Note:** Hyperparameters should be tuned for all the models you try because only then you will be able to tell what is the best you can get out of that particular model.",
            "mc_idx": 210,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Note:** GridSearchCV will only consider the values for each hyperparameter that you explicitly define here. If you don't \ndefine it in the parameter dictionary object, it will not be included in the grid search.This process of finding the best \nparameters is called exhaustive grid-search because its trying every combination.",
            "mc_idx": 213,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Since accuracy increases, it can be said that the most accurate logistic regression model uses C = 2.7825594022071245 and penalty = l2 as hyperparameters.**",
            "mc_idx": 217,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 11.2.3  Model Selection <a id=\"11.2.3\"></a>\nLet's compare our models according to their accuracy score after tunning hyperparameters with cross validation scores to select the best models for further study on this classification problem.",
            "mc_idx": 218,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Among the classifiers, RF and GBC have the highest accuracy after  tunning hyperparameters. So RF and GBC are perhaps worthy of further study on this classification problem. Hence we choose RF and GBC.\n\n**Note:** Please note that if we chose our classifier based on cross validation scores, we would not get RF and GBC as our best classifiers instead we would end up choosing LR and SVC. So it is recommended to select best classifiers based on accuracy after tunning hyperparameters though it is computationally intensive.\n\n## 11.3 Retrain and Predict Using Optimized Hyperparameters <a id=\"11.3\"></a>\nSo we have our best classifiers with their best hyperparameters that produces best accuracy out of a model. That means if we retrain the classifiers using their best hyperparameters, we will be able to get the very same score that we got after tunning hyperparameters (see part 14.4). Let's retrain our classifiers and then use cross validation to calculate the accuracy of the trained model. That's how we will have the same accuracy score as after tunning hyperparameters. Let's retrain models with optimized hyperparameters.",
            "mc_idx": 220,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**See! We've successfully managed to reproduce the same score that we achived only after tunning hyperparameters. Now if we predict using these trained models, we should have the best test accuracy possible out of those model. So let's predict using those trained models:**",
            "mc_idx": 222,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 11.4 Feature Importance <a id=\"11.4\"></a>\nDo the classifiers give the same priority to every feature? Let's visualize the features importance given by our classifiers.",
            "mc_idx": 224,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** RF, DT, ETC, and ABC (in particular) give some features no importance (zero importance). On the other hand, GBC give all the features more or less importance but it doesn't give zero importance to any features. These are the tree based models that have 'feature_importances_' method by default. LR, KNN and SVC don't have this method. In this problem, SVC uses rbf kernel (only possible for linear kernel to plot feature importance), so its not possible to view feature importance given by SVC. Though its trickier, we would try to get the feature importance given by LR.",
            "mc_idx": 226,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** We can see some negative values that means that higher value of the corresponding feature pushes the classification more towards the negative class (in our case 0) that is, of course, something we're already aware of. Some features like Family_size_single, Embarked_Q, Embarked_C, and Cabin_F were given zero importance by lr.\n\n## 11.5 Learning Curves  <a id=\"11.5\"></a>\nLet's plot the learning curves for the optimized classifiers to see their bias-variance tradeoff.",
            "mc_idx": 228,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:**\n1. RF, DT, SVC and ETC are just doing okay. Among them, SVC is doing the best in terms of bias-variance tradeoff since svc's train accuracy and cross validation accuracy are almost equal. Since training and validation curves haven't yet converged for these classifiers, adding more instances (rows) might help.\n\n2. On the other hand, learning curve of GBC, ABC, KNN and LR indicates a little bit high bias or low variance (underfitting) and as the curves have already converged, adding more training data just might not help. Rather adding more features (columns) and increasing model's complexity might help.\n\n# 12.More Evaluation Metrics  <a id=\"12\"></a>\nWe've so far used accuracy score to evaluate our classifiers. But sometimes accuracy score isn't all enough to evaluate a classifier properly as accuracy score doesn't tell exactly which class (positive or negative) is being wrongly classified by our classifier in case of low accuracy score. **Again for imbalanced classification problem, accuracy score isn't the best metric to choose between different classifiers. To clarify this, in this section, we will calculate confusion matrix, precision score, recall score, specificity, f1 score, classification report for both random forest and gradient boosting classifier. And then we will compare our two best classifiers (rf and gbc) using these calculated metrics to see exactly where one classifier excels the other.**\n\n## 12.1 Confusion Matrix  <a id=\"12.1\"></a>\nThe confusion matrix shows the number of correct classifications along with misclassifications when a classifier make predictions for each class (positive or negative). The diagonal elements are correct classification while the off diagonal elements are misscalssifications. Some basic terms associated with confusion matrix:\n1. True positives (TP): These are cases in which we predicted 1(yes), and the actual is also 1(yes).\n2. True negatives (TN): We predicted 0(no), and the actual is also 0(no).\n3. False positives (FP): We predicted 1(yes), but the actual is 0(no). (Also known as a \"Type I error.\")\n4. False negatives (FN): We predicted 0(no), but the actual is 1(yes). (Also known as a \"Type II error.\")",
            "mc_idx": 231,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "The 1st row of our confusion matrix( or sometimes called error matrix) is about the negative class (because of 0 and hence non-survived) and The 2nd row of our confusion matrix( or sometimes called error matrix) is about the positive class (because of 1 and hence survived).\n\nFor rf, passengers correctly classified as survived are 243 (true positives) and passengers correctly classified as non-survived (died) are 506(true negatives). While 43 passengers (false positives) from class 0 (non-survived) were misclassified as survived and 99 (false negatives) passengers who actually survived were classified as non-survived.\n\nAnd for gbc, passengers correctly classified as survived are 248(true positives) and passengers correctly classified as non-survived (died) are 501(true negatives). While 48 (false positives) passengers from class 0 (non-survived) were misclassified as survived and 94 (false negatives) passengers who actually survived were misclassified as non-survived.\n\n**RF (749) makes exactly same correct predictions (true positives+true negatives) as gbc (749), hence rf and gbc have exactly same accuracy score that we saw when we calculated both model's accuracy score.**\n\n## 12.2 Precision Score  <a id=\"12.2\"></a>\nPrecision is the ratio of true positive to total predicted positive(true positive + false positive). So precision score tells how many true positives our model can capture out of total predicted positives.",
            "mc_idx": 233,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**RF's precision score tells when it predicts a passenger as a survivor (=class1), it is correct nearly 85% of the time. And gbc's precision score tells when gbc predicts a passenger as a survivor, it is correct nearly 84% of the time. So rf has a better precision score than gbc.**\n\n## 12.3 Recall (or Sensitivity or True Positive Rate)  <a id=\"12.3\"></a>\nRecall is the ratio of true positive to total actual positive(true positive + false negative). So recall score basically calculates true positives from total actual positives.",
            "mc_idx": 235,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**RF's recall score tells it correctly identifies over 71% of all the survivors. Or put another way, it predicts over 71.5% of the survivors as a survivor. On the other hand, gbc predicts just over 72.5% of the survivors as survivor. So gbc is more capable of capturing true positives than rf that we also observed from confusion matrix.**\n\n## 12.4 Specificity ( or True Negative Rate)  <a id=\"12.4\"></a>\nSpecificity is the ratio of true negative to total actual negative(true negative + false positive). Specificity  is exactly the opposite of recall. So specificity score basically calculates true negatives from total actual negatives.",
            "mc_idx": 237,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**RF's specificity score indicates it correctly predicts over 92% of the victims as a victim. Comparing recall score with specificity, it looks like our rf model is more accurate on predicting negative class (victims = 0) than predicting positive class (survivors = 1).**\n\n**While  gbc's specificity score indicates it correctly predicts over 91% of the victims as a victim. Comparing recall score with specificity, it looks like our gbc also is more accurate on predicting negative class (victims = 0) than predicting positive class (survivors = 1).**\n\n**Interesting! RF is better than capturing true negatives than gbc. So if we were to choose a model between rf and gbc where our priority is the negative class (0), we would choose rf. And if our priority is positive class(1), we would choose gbc.**\n\n## 12.5 F1 Score  <a id=\"12.5\"></a>\nWe can't choose classifiers solely depending on their precision or recall score. Rather we need to consider both to find out the best classifiers. Here comes the f1 score which is  the balanced harmonic mean of Recall and Precision, giving both metrics equal weight. The higher the f1 score is, the better.",
            "mc_idx": 239,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Looks like gbc is better than rf in terms of f1 score.**\n## 12.6 Classification Report  <a id=\"12.6\"></a>\nPrecision, recall, and f1 score is only associated with true positives. But what if we want to measure true negatives? We can measure them with true positives and count of each class (0 and 1) in  a classification report. It provides precision, recall, f1 score and class count altogether for both classs (0 and 1) but at the cost of less hassle.",
            "mc_idx": 241,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**We can see precision, recall, f1 score and class count for both class (0 and 1) of our two models.**\n## 12.7 Precision-Recall vs Threshold Curve  <a id=\"12.7\"></a>\nSometimes we want a high precision and sometimes a high recall depending on our classification problem. The thing is that an increasing precision results in a decreasing recall and vice versa. This is called the precision-recall tradeoff that can be illustrated using precision-recall curve as a function of the decision threshold.",
            "mc_idx": 243,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**We can see for RF, the recall falls quickly at a precision of around 84%. So therefore, we need to select the precision-recall tradeoff before 84% of precision which could be at around 82%. Now, for example, if we want a precision of 80% off RF we would need a threshold of around 0.4**\n\n**On the other hand, for GBC, the recall falls fast at a precision of around 84% and hence we would select precision-recall tradeoff at around 80% of precision. If we want a precision of around 81% off GBC, we would need a threshold of around 0.38**\n\n## 12.8 Precision-Recall Curve  <a id=\"12.8\"></a>\nWe can also plot precision against recall to get an idea of precision-recall tradeoff where y-axis represents precision and x-axis represents recall. In my plot, I plot recall on y-axis and precision on x-axis.",
            "mc_idx": 245,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**We can see recall falls rapidly at around a precision of 0.84 for both RF and 0.82 for GBC that we've observed in the previous section.**\n\n## 12.9 ROC  Curve & AUC Score  <a id=\"12.9\"></a>\nROC (Reicever Operating Characteristic Curve) is a plot of the true positive rate against the false positive rate of a classifier. It shows the tradeoff between sensitivity and specificity (any increase in sensitivity will be accompanied by a decrease in specificity). AUC (Area under the ROC Curve) score is the corresponding score to the AUC Curve. It is simply computed by measuring the area under the ROC curve, which is called AUC. We will plot ROC curve and AUC score together for our two classifiers.",
            "mc_idx": 247,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "This two plots tells few different things:\n\n1. A model that predicts at chance will have an ROC curve that looks like the diagonal red line. That is not a discriminating model.\n\n2. The further the curve is off the diagonal red line, the better the model is at discriminating between positives and negatives in general.\n\n3. There are useful statistics that can be calculated from this curve, like the Area Under the Curve (AUC). This tells you how well the model predicts and the optimal cut point for any given model (under specific circumstances).\n\n**Comparing the two ROC curves, we can see the distance between blue and red line of RF is greater than the distance between blue and red line of GBC. Hence it can safely be said that RF, in general, is better at discriminating between positives and negatives than GBC. Also RF(92.11%) auc score (which is the area under the roc curve) is greater than gbc(91.94%). It seems the higher the area, the further the classifier is off the red diagonal line and vice versa and hence more accurate. Since RF has more area under the ROC curve than GBC, RF is more accurate.**\n\n# 13.Prediction & Submission  <a id=\"13\"></a>\nFirst we will predict using both rf and gbc. Then we will create two prediction files in csv format for kaggle submission.",
            "mc_idx": 249,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Though both RF and GBC have the identical validation accuracy (in our case optimized accuracy ~0.8406), RF scored 0.79425 while GBC scored 0.78468 on kaggle leaderboard. The fact that gbc's accuracy on the holdout data is 0.78468 compared with the 0.8406 accuracy we got with cross-validation indicates that GBC underfits the training data that we obsetved from the learning curve (see part 11.7). Hence it performs poorly on kaggle hold out set compared to RF.**\n\n### Can we further improve our classifiers' accuracy? May be we can! In the next few section, we will try to improve our models' accuracy with the help of ensemble method.",
            "mc_idx": 251,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 14.Introduction to Ensemble <a id=\"14\"></a>\nCan we further boost the accuracy of our best models? That's what we will try to do using ensemble method. Ensembles combine predictions from different models to generate a final prediction, and the more models we include the better it performs. Better still, because ensembles combine baseline predictions, they perform at least as well as the best baseline model. Most of the errors from a model\u2019s learning are from three main factors: variance, noise, and bias. By using ensemble methods, we\u2019re able to increase the stability of the final model and reduce the errors caused by bias, variance, and noise. By combining many models, we\u2019re able to (mostly) reduce the variance, even when they are individually not great, as we won\u2019t suffer from random errors from a single source. **The main principle behind ensemble modelling is to group weak learners together to form one strong learner. The most basic ensemble is majority voting rule (where the prediction or vote given by the majority of the models used as final prediction).But there are many other ways to combine predictions, and more generally we can use a model to learn how to best combine predictions.**",
            "mc_idx": 252,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**To implement an ensemble we need three basic things:**\n1. A group of base learners that generate predictions.\n2. A meta learner that learns how to best combine these predictions outputed by base learners.\n3. And finally a method for splitting the training data between the base learners and the meta learner.\n\n**An ensemble works best if:**\n1. There is a less correlation in the base models' predictions.\n2. We increase the number of base learners though it might slow the process down.\n\n\n## 14.1 Different Ensemble Methods\nWe would first categorize ensemble methods into two subcategories like 1.Simple Ensemble Methods and 2.Advanced Ensemble Methods\n\n### 14.1.1 Simple Ensemble Methods\nThey're the simpliest yet so useful form of enselbles. They can be further categorised into \n1. Voting, \n2. Averaging and \n3. Weighted Average. \n\nFirst one is usually used for classification while the later two are used for regression problems.\n\n#### 14.1.1.1 Voting Ensemble  \nVoting ensemble is further classified into \n1. Hard voting and \n2. Soft voting.\n\n##### 14.1.1.1.1 Hard Voting (or Majority Voting or Max Voting) <a id=\"14.1\"></a>\nThis hard voting method is usually used for classification problems. The idea is to train multiple models to make predictions for each data point. The predictions by each model are considered as a \u2018vote\u2019. The predictions which we get from the majority of the models are used as the final prediction. Say rf and lr predict a class as 1 while knn predicts the same class as 0. Since the majority of the vots is casted in favour of class 1, the voting classifier would predict the very same class as 1. See the table below to understand how hard voting ensemble works.",
            "mc_idx": 253,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Correlation among Base Models Predictions:** How base models' predictions are correlated? If base models' predictions are weakly correlated with each other, the ensemble will likely to perform better. On the other hand, for a strong correlation of predictions among the base models, the ensemble will unlikely to perform better. To sumarize, diversity of predictions among the base models is inversely proportional to the ensemble accuracy. Let's make prediction for the test set.",
            "mc_idx": 255,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** The prediction looks quite similar for the 8 classifiers except when DT is compared to the others classifiers. Now we will create an ensemble with the base models RF, GBC, DT, KNN and LR. This ensemble can be called heterogeneous ensemble since we have three tree based, one kernel based and one linear models. We would use **EnsembleVotingClassifier method from mlxtend module** for both hard and soft voting ensembles. The advantage is it requires lesser codes to plot decision regions and I find it a bit faster than sklearn's voting classifier.",
            "mc_idx": 257,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** We can see Hard voting classifier uses RF as meta learner for this problem that beats the best base learners (rf and gbc) by some margin. So we may want to further investigate how hard voting is using its decision boundary to excel our best base learners. Let's visualize the decision regions of hard voting classifier with base classifiers.\n\n**Now we have a new challenge. In machine learning, visualizing 2 or 3 dimensional data is not that challenging. But we have 47 dimensions (47 input features). That's way too much to visualize. So we need to reduce the dimensionality- may be into 2 or 3 dimensionality. That's where PCA comes into play.**\n\n### **Introduction to Principal Component Analysis (PCA) <a id=\"14.2\"></a>\nThe main goal of a PCA analysis is to identify patterns in data. PCA aims to detect the correlation between variables. If a strong correlation between variables exists, the attempt to reduce the dimensionality only makes sense. In a nutshell, this is what PCA is all about: Finding the directions of maximum variance in high-dimensional data and project it onto a smaller dimensional subspace while retaining most of the information. PCA is very useful in the following two cases:\n1. When the training process takes too long due to large input dimension of training data.\n2. Reducing dimensions, it make data visualization a breeze.\n\nPCA is often effected if your input features have different ranges. So to make PCA work better we shoud scale the input features. We would use sklearn's StandardScaler to standarize our input features. The idea behind StandardScaler is that it will transform our data such that its distribution will have a mean value 0 and standard deviation of 1. **If the variables are correlated, PCA can achieve dimension reduction. If not, PCA just orders them according to their variances.**\n\n**Now let's perform standarization and then PCA to plot decision regions of different trained classifiers.**",
            "mc_idx": 259,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**So there we have it! We're down to 2 features only from 47 features. Now we want to calculate how much variance we're able to extract off these 2 components.**",
            "mc_idx": 261,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Not so much! But considering the number of features we have, its not either too less. Let's visualize our two components (transformed features) in a scatter plot.**",
            "mc_idx": 263,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Looking at this plot, one thing we can say that a linear decision boundary will not be a good choice to separate these two classes. Now we would train our models on this 2d transformed samples to visualize decision regions created by them.**\n\n**Note:** PCA gives you an intuition if a linear or non-linear algorithms would be suitable for a problem. For example, if we look at the scatter plot, we see a non-linear trend between the two class that is, of course better seperable by a non-linear decision boundary. So a non-linear model would be a better bet than a linear one. That's why rf(non-linear) performs better than lr(linear model) for this problem.",
            "mc_idx": 265,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** There seems to be lesser misclassifications made by hard voting decision region compared to both rf and gbc's decision regions. Let's see how and where hard voting ensemble corrects base learners prediction in a data frame together.",
            "mc_idx": 267,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Great! We can see hard voting ensemble is considering majority of the models vote(prediction) to label a particular class. Thus it can reduce prediction errors when predicted by a single base learners.**\n\n##### 14.1.1.1.2 Soft Voting <a id=\"14.3\"></a>\nOn the other hand, When an ensembles averages based on probabilities  we refer to it as soft voting. In an ensemble model, all classifiers (algorithms) are able to estimate class probabilities (i.e., they all have predict_proba() method), then we can specify Scikit-Learn to predict the class with the highest probability, averaged over all the individual classifiers. In a voting classifier setting the voting parameter to 'soft' enables the models to calculate their probability(also known as confidence score) individually and present it to the voting classifier, then the voting classifier averages them and outputs the class with the highest probability. If average probablity of class-1 is greater than class-0, it outputs predicted class is 1 otherwise 0. \n\n**Note:** This soft-voting classifier often work better than hard-voting as it gives more weight to highly confident votes. We Need to specify voting=\u201dsoft\u201d and ensure that all classifiers can estimate class probabilities. One algorithm where we need to be careful is SVC, by default SVC will not give probabilities, we have to specify 'probability' hyperparameter to True.\nSee the table below to understand how soft voting ensemble works.",
            "mc_idx": 269,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Let's implement soft voting ensemble in mlxtend.**",
            "mc_idx": 271,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Soft voting ensemble fails to beat our two best models (rf and gbc). In fact, it produces way to inferior results compared to hard voting ensemble (83.95 vs 84.18). So hard voting ensemble, for this problem, seems to be superior to soft voting ensemble method. WE can visualize soft voting ensemble decision region along with base models decision regions.",
            "mc_idx": 273,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Soft voting decision region just seems to be creating more misclassification than rf and gbc.",
            "mc_idx": 275,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### 14.1.2 Advanced Ensemble Methods\nAdvanced ensemble methods can further be classified into \n1. Bagging\n2. Boostoing\n3. Stacking\n4. Blending\n\n#### 14.1.2.1 Bagging  <a id=\"14.4\"></a>\nBagging, is shorthand for the combination of bootstrapping and aggregating. Bootstrapping is a method to help decrease the variance of the classifier and thus reduce overfitting. So the model created should be less overfitted than a single individual model. Bagging is more suitable for high variance low bias models (complex models). Random forest itself is an ensemble machine learning algorithm that follows the bagging technique. We would use rf as the base estimator for bagging instead of default dt. Let's try to implement bagging in sklearn:",
            "mc_idx": 277,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Bagging can't beat our best base learners.\n\n#### 14.1.2.2 Boosting  <a id=\"14.5\"></a>\nBoosting refers to any Ensemble method that can combine several weak learners into a strong learner. It does this through a weighted majority vote (classification) or a weighted sum (regression). Ada boost and Gradient boost, and Extreme gradient boost are popular models that uses boosting technique. Boosting is particularly suitable for low variance high bias models (less complex models). Unlike bagging, its a sequential ensemble technique. We will perform a simple voting ensemble of boosting classifiers rather performing boosting ensemble using only a single classifer with a base estimator (for ada boost). I found this method to give higher accuracy than adaboost(with a base estimator), gradient boosting, or extreme gradient boosting for this problem. Let's perform boosting ensemble(infact voting of boosting classifiers) in mlxtend.",
            "mc_idx": 279,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:** Boosting method can't beat best boosting base learner gbc. Though it could beat, if we would have optimized xgbc. If you have time and infrastructure, you can tune xgbc's hyperparameters. Then compare boosting accuracy with its base models accuracy.\n\n#### 14.1.2.3 Blending  <a id=\"14.6\"></a>\nIn blending, full training data is split into training and prediction sets. The base models (also called level 0 models) are trained on this train set and then predictions are made on this prediction set. These predictions made by base learers are then fed as an input to the meta learner (also called level 1 model). That is meta learner are trained with the output (predictions) of base learners. Blending ensemble uses only a subset of data to train base learners and another subset of data to make predictions. By only fitting every base learner once on a subset of the full training data, Blend ensemble is a fast ensemble that can handle very large datasets simply by only using portion of it at each stage. The cost of this approach is that information is thrown out at each stage, as one layer will not see the training data used by the previous layer. **We will use BlendEnsemble method from mlens.ensemble module to perform blending.**",
            "mc_idx": 281,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#### 14.1.2.4 Stacking (Or Stacked Generalization)  <a id=\"14.7\"></a>\nIn blending, we trained the base learners and the meta learner on only half the data, so a lot of information is lost. To prevent this, we need to use a cross-validation strategy. Fitting an ensemble with cross-validation is often referred to as stacking, while the ensemble itself is known as the Super Learner. So basically in stacking, the individual classification models (or base models) are trained on the complete training set; then, the meta-classifier is fitted on the outputs (predictions) of those base learners. The meta-classifier can either be trained on the predicted class labels or probabilities from the ensemble.\n\n**The basic difference between blending and stacking is therefore that stacking allows both base learners and the meta learner to train on the full data set.The outcome of stacking is improved accuracy which is typical for small and medium-sized data sets, where the effect of blending can be severe. As the data set size increases, blending and stacking performs similarly and hence for large data sets blending is preferred over stacking since stacking takes significant amount of time to train the ensemble. We will use package vecstack to perform stacking that can save you from writing a lot of codes if you implement stacking from scratch.**",
            "mc_idx": 283,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**So now we have OOF from base (or 0 level models) models and we can build level 1 model. We have 5 base models (level 0 models), so we expect to get 5 columns in sTrain and sTest. sTrain will be our input feature to train our meta learner and then prediction will be made on sTest after we train our meta learner. And this prediction on sTest is actually the prediction for our test set (xTest). Before we train our meta learner we can investigate sTrain and sTest.**",
            "mc_idx": 285,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 14.2  Evaluating Different Ensembles <a id=\"14.8\"></a>\nI've tried to demonstrate various ensemble methods. Let's make predictions with them to see how they perform on our test set on kaggle submission.",
            "mc_idx": 289,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**We've made our submissions using different ensembles. Let's now compare their submission scores with our best base models'  submission scores.**",
            "mc_idx": 291,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "**Findings:**So there you have it! Surprisingly its bagging that comes out on top with a score of *0.81339* that can take you to the top *4%* on the leaderboard! Random forest (base model) comes second with score 0.80382. Hard voting, stacking and soft voting perform identical and can't beat best base rf. Since bagging performs well for high variance model, we have a feeling that we might have overfitted the training data because cross validation score for bagging is 82.61% and it still scores over 81% on kaggle leaderboard. So its possible to overfit though your cross validation score is high since some models with higher cross validation score perform poorly on kaggle leaderboard compared to bagging ensemble.",
            "mc_idx": 294,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 15.End Note <a id=\"15\"></a>\n**If you're still with me, I congratulate you because you've learned all those things that I learned after months of study, practice and of course patience. Of course, there is always room for improvement. I'm still learning. I've tried to explain everything I could possibly know. Any suggestion is cordially welcomed. May be trying out different base learners and meta learner to improve ensemble further or may be by tunning xgbc. And if you find my kernel useful, some upvotes will be appreciated.  I have also another kernel for advanced house price regression problem that you might find useful as well.**\n\n**Finally I provide some links that I've found useful in creating this notebook.**\n\n**Recommended Readings:**\n1. Mlxtend package for voting ensemble and decision region: https://rasbt.github.io/mlxtend/user_guide/classifier/EnsembleVoteClassifier/ and\nhttps://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/\n2. Mlens package for blending ensemble: https://github.com/flennerhag/mlens/blob/master/mlens/ensemble/blend.py\n3. Vecstack package for stacking ensemble: https://github.com/vecxoz/vecstack\n4. Introduction to Python Ensembles by Dataquest: https://www.dataquest.io/blog/introduction-to-ensembles/\n5. Kaggle ensemble guide by MLWave: https://mlwave.com/kaggle-ensembling-guide/",
            "mc_idx": 295,
            "nb_idx": 4,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        }
    ],
    "sim_matrix": [
        0.8846019506454468,
        0.8393664956092834,
        0.8966423869132996,
        0.8997972011566162,
        1.0,
        0.9367772340774536,
        0.8971045017242432,
        0.8887213468551636,
        0.8724914193153381,
        0.8215800523757935,
        0.8397447466850281,
        0.8827375173568726,
        0.8794418573379517,
        0.884009599685669,
        0.871335506439209,
        0.9150328636169434,
        0.911188006401062,
        0.9367772340774536,
        0.8913484215736389,
        0.8960481882095337
    ],
    "cell_sim_matrix": [
        [
            [
                0.6683032512664795,
                0.8554257750511169,
                0.6722543835639954,
                0.7041049003601074,
                0.5904615521430969,
                0.7574281692504883,
                0.5904615521430969,
                0.8320009112358093,
                0.525836706161499,
                0.6604347229003906,
                0.6770715117454529,
                0.7986328601837158,
                0.3852367103099823,
                0.8658088445663452,
                0.5934163331985474,
                0.7327579259872437,
                0.7527671456336975,
                0.8086012601852417,
                0.7443007826805115,
                0.821153998374939,
                0.6235733032226562,
                0.7424216270446777,
                0.7343788146972656,
                0.7972183227539062,
                0.5688459277153015,
                0.760541558265686,
                0.7222640514373779,
                0.7230467200279236,
                0.6950865983963013,
                0.7427120208740234,
                0.7463544607162476,
                0.5676334500312805,
                0.7478753924369812,
                0.7295711040496826,
                0.7690396308898926,
                0.7201776504516602,
                0.8297702670097351,
                0.5356524586677551,
                0.7238844037055969,
                0.7292384505271912,
                0.7432618737220764,
                0.7291746735572815,
                0.7578447461128235,
                0.6933833956718445,
                0.7767561674118042,
                0.7563025951385498,
                0.741288959980011,
                0.8488519787788391,
                0.7655544877052307,
                0.7443681359291077,
                0.8154722452163696
            ],
            [
                0.6728448867797852,
                0.7747019529342651,
                0.6711241602897644,
                0.7965417504310608,
                0.6129395961761475,
                0.7958932518959045,
                0.6129395961761475,
                0.7485491037368774,
                0.5068018436431885,
                0.6512530446052551,
                0.6510153412818909,
                0.6771637797355652,
                0.3782103657722473,
                0.7758715152740479,
                0.6599947810173035,
                0.7644972801208496,
                0.8439528942108154,
                0.7361293435096741,
                0.7827939987182617,
                0.7052973508834839,
                0.6627172827720642,
                0.772696852684021,
                0.7638137936592102,
                0.7014391422271729,
                0.6399891972541809,
                0.8411834836006165,
                0.6842937469482422,
                0.6628509163856506,
                0.6838354468345642,
                0.6776816248893738,
                0.8498488664627075,
                0.6245947480201721,
                0.7867091298103333,
                0.8058781027793884,
                0.8640552759170532,
                0.7653135061264038,
                0.7029356956481934,
                0.59405517578125,
                0.7023311853408813,
                0.7615324258804321,
                0.761555552482605,
                0.6682872772216797,
                0.8426293134689331,
                0.695044219493866,
                0.7241567969322205,
                0.8329768180847168,
                0.7900601029396057,
                0.7222918272018433,
                0.8126248121261597,
                0.7764616012573242,
                0.6664872169494629
            ],
            [
                0.7686431407928467,
                0.83835369348526,
                0.7111344933509827,
                0.7930319905281067,
                0.6212785840034485,
                0.8114664554595947,
                0.6212785840034485,
                0.8266394138336182,
                0.5292766094207764,
                0.6756516695022583,
                0.6681864261627197,
                0.7914194464683533,
                0.3743094503879547,
                0.8486812710762024,
                0.642261803150177,
                0.7804111242294312,
                0.8135796189308167,
                0.7959824204444885,
                0.7917025685310364,
                0.7963691353797913,
                0.6449179649353027,
                0.7869979739189148,
                0.7773727774620056,
                0.8010693192481995,
                0.6118976473808289,
                0.8168067336082458,
                0.7503931522369385,
                0.7163151502609253,
                0.7184488773345947,
                0.7447500228881836,
                0.8070083260536194,
                0.6010376811027527,
                0.8110427856445312,
                0.79372239112854,
                0.844314455986023,
                0.7629002928733826,
                0.858045220375061,
                0.5919592976570129,
                0.811112105846405,
                0.7815293073654175,
                0.7954571843147278,
                0.7211931347846985,
                0.8348318934440613,
                0.7078037261962891,
                0.8365011215209961,
                0.8266668319702148,
                0.7684147357940674,
                0.8612678050994873,
                0.8125169277191162,
                0.8069918751716614,
                0.8413978219032288
            ],
            [
                0.7394281029701233,
                0.7912827134132385,
                0.8273536562919617,
                0.8319202065467834,
                0.5133638381958008,
                0.8419665694236755,
                0.5133638381958008,
                0.8179562091827393,
                0.5260912775993347,
                0.6762163043022156,
                0.688641369342804,
                0.711322546005249,
                0.3713414669036865,
                0.8150135278701782,
                0.580000638961792,
                0.8348495364189148,
                0.8585909008979797,
                0.8097326755523682,
                0.8093960285186768,
                0.7116710543632507,
                0.6304649114608765,
                0.8294220566749573,
                0.8400164246559143,
                0.7054694890975952,
                0.5612818002700806,
                0.880115807056427,
                0.6770151853561401,
                0.6741701364517212,
                0.6965938806533813,
                0.7086391448974609,
                0.834686279296875,
                0.5634123086929321,
                0.8404232263565063,
                0.8282387256622314,
                0.8728594779968262,
                0.7954325079917908,
                0.7118462324142456,
                0.5461699962615967,
                0.7253413200378418,
                0.8398752212524414,
                0.8053451180458069,
                0.6882167458534241,
                0.8732022643089294,
                0.7279552221298218,
                0.7256865501403809,
                0.8764698505401611,
                0.8146145343780518,
                0.790248453617096,
                0.8266814351081848,
                0.8502227067947388,
                0.6815404891967773
            ],
            [
                0.7367290258407593,
                0.7561005353927612,
                0.8057120442390442,
                0.8467940092086792,
                0.5610446333885193,
                0.8773860335350037,
                0.5610446333885193,
                0.8715957403182983,
                0.737879753112793,
                0.7423840165138245,
                0.7812249660491943,
                0.780901312828064,
                0.5246617794036865,
                0.805242657661438,
                0.6489825248718262,
                0.91990727186203,
                0.8350672125816345,
                0.891064465045929,
                0.8264449238777161,
                0.7690595388412476,
                0.6982839703559875,
                0.9120141863822937,
                0.9257243275642395,
                0.7130796313285828,
                0.6344422101974487,
                0.9285221695899963,
                0.6972290873527527,
                0.8076420426368713,
                0.7792086601257324,
                0.8131449818611145,
                0.8249098658561707,
                0.6527376770973206,
                0.8701825737953186,
                0.8673341870307922,
                0.8253544569015503,
                0.8749693632125854,
                0.6943069696426392,
                0.6299386024475098,
                0.7674008011817932,
                0.9295390248298645,
                0.834015965461731,
                0.8344672322273254,
                0.8368991613388062,
                0.7755404710769653,
                0.7090528607368469,
                0.8811280727386475,
                0.8867979049682617,
                0.7919719815254211,
                0.8354833722114563,
                0.9218388795852661,
                0.6637978553771973
            ],
            [
                0.7655230164527893,
                0.7866212129592896,
                0.7329625487327576,
                0.9388705492019653,
                0.6383363008499146,
                0.8969141244888306,
                0.6383363008499146,
                0.837936282157898,
                0.6102779507637024,
                0.756925642490387,
                0.7639559507369995,
                0.7687221169471741,
                0.437633752822876,
                0.8360726237297058,
                0.6474215388298035,
                0.8805380463600159,
                0.8858096599578857,
                0.8538584113121033,
                0.8527444005012512,
                0.7619537711143494,
                0.6727876663208008,
                0.8841711282730103,
                0.8808295130729675,
                0.7337507605552673,
                0.6339591145515442,
                0.9197008609771729,
                0.7274690866470337,
                0.7598357200622559,
                0.7774702906608582,
                0.7708752751350403,
                0.8881666660308838,
                0.6303908228874207,
                0.8651054501533508,
                0.8838493227958679,
                0.8904066681861877,
                0.85800701379776,
                0.7523196339607239,
                0.5949158668518066,
                0.764229416847229,
                0.8896423578262329,
                0.8642695546150208,
                0.7564361691474915,
                0.8933429718017578,
                0.7217414975166321,
                0.7566558122634888,
                0.9192583560943604,
                0.86248379945755,
                0.8012816309928894,
                0.8704015612602234,
                0.8919907808303833,
                0.6950814723968506
            ],
            [
                0.6531015634536743,
                0.8697675466537476,
                0.6843967437744141,
                0.7233330607414246,
                0.6604169011116028,
                0.775748610496521,
                0.6604169011116028,
                0.8214241862297058,
                0.5805949568748474,
                0.7049499154090881,
                0.708014726638794,
                0.8462862372398376,
                0.443593293428421,
                0.8690995573997498,
                0.6528720855712891,
                0.7329082489013672,
                0.7479826211929321,
                0.7999668121337891,
                0.7771178483963013,
                0.8448432683944702,
                0.6672685146331787,
                0.7387223243713379,
                0.7295022010803223,
                0.8468320369720459,
                0.6463454961776733,
                0.7594841718673706,
                0.7516825795173645,
                0.7545701265335083,
                0.7286142706871033,
                0.7794047594070435,
                0.7396570444107056,
                0.6488869190216064,
                0.754732608795166,
                0.7374081611633301,
                0.7488323450088501,
                0.7405111193656921,
                0.8353323936462402,
                0.6175651550292969,
                0.7509049773216248,
                0.7373725771903992,
                0.7676063776016235,
                0.7321109771728516,
                0.7478337287902832,
                0.7198134064674377,
                0.8008449077606201,
                0.7605984210968018,
                0.7406831383705139,
                0.8377373218536377,
                0.7649603486061096,
                0.7620435357093811,
                0.8405219316482544
            ],
            [
                0.6881755590438843,
                0.793458104133606,
                0.7621884942054749,
                0.837935209274292,
                0.5915464162826538,
                0.894015908241272,
                0.5915464162826538,
                0.8721292614936829,
                0.6651979684829712,
                0.7304296493530273,
                0.794512152671814,
                0.7950245141983032,
                0.47064444422721863,
                0.8675689101219177,
                0.6438846588134766,
                0.8785566091537476,
                0.8585792779922485,
                0.8793190717697144,
                0.8678224682807922,
                0.7784318923950195,
                0.6627005338668823,
                0.8898258805274963,
                0.8767644762992859,
                0.7487978935241699,
                0.6311632990837097,
                0.893354594707489,
                0.7529811859130859,
                0.8246780633926392,
                0.7743990421295166,
                0.8255922794342041,
                0.8657428622245789,
                0.6152186393737793,
                0.8557590246200562,
                0.8712432384490967,
                0.8607717752456665,
                0.8710970282554626,
                0.7519846558570862,
                0.5852846503257751,
                0.7345411777496338,
                0.8741462826728821,
                0.8582351207733154,
                0.8242626190185547,
                0.8637851476669312,
                0.7567005753517151,
                0.7610440850257874,
                0.878087043762207,
                0.9019050002098083,
                0.8351435661315918,
                0.86005699634552,
                0.8647798895835876,
                0.731175422668457
            ],
            [
                0.7214695811271667,
                0.7663130164146423,
                0.7843107581138611,
                0.844537615776062,
                0.6227905750274658,
                0.9164217114448547,
                0.6227905750274658,
                0.8919361233711243,
                0.7001335620880127,
                0.776603102684021,
                0.8139312863349915,
                0.804751992225647,
                0.4795226752758026,
                0.8460221290588379,
                0.6179390549659729,
                0.9254835844039917,
                0.857314944267273,
                0.9158927798271179,
                0.8693499565124512,
                0.793615460395813,
                0.6671263575553894,
                0.9238598942756653,
                0.9275902509689331,
                0.7257344126701355,
                0.6068298816680908,
                0.9240348935127258,
                0.7125416398048401,
                0.8402812480926514,
                0.8009111881256104,
                0.8210662007331848,
                0.8385850191116333,
                0.6456619501113892,
                0.8966065049171448,
                0.8895209431648254,
                0.8330855965614319,
                0.9010471701622009,
                0.7439465522766113,
                0.6102432012557983,
                0.7537699937820435,
                0.9348571300506592,
                0.871652364730835,
                0.8430275917053223,
                0.8632620573043823,
                0.767067551612854,
                0.7215434908866882,
                0.8965211510658264,
                0.8992289900779724,
                0.8365449905395508,
                0.8731555342674255,
                0.9253710508346558,
                0.6991984844207764
            ],
            [
                0.6731142401695251,
                0.7522876262664795,
                0.6937375068664551,
                0.8001275062561035,
                0.5898482799530029,
                0.8535507321357727,
                0.5898482799530029,
                0.8324296474456787,
                0.614423930644989,
                0.7220444083213806,
                0.7275791764259338,
                0.7565122842788696,
                0.42204374074935913,
                0.8034182190895081,
                0.6223098039627075,
                0.8454862236976624,
                0.8282504677772522,
                0.8411516547203064,
                0.8357435464859009,
                0.7567387819290161,
                0.6191891431808472,
                0.8448012471199036,
                0.836048424243927,
                0.7112791538238525,
                0.6243475079536438,
                0.8697830438613892,
                0.7421036958694458,
                0.7886527180671692,
                0.7496182322502136,
                0.763504147529602,
                0.8500649333000183,
                0.60715252161026,
                0.855887770652771,
                0.8543316721916199,
                0.8501496911048889,
                0.8417826890945435,
                0.7410971522331238,
                0.5869885683059692,
                0.7403141260147095,
                0.8454253077507019,
                0.8596428036689758,
                0.7802320718765259,
                0.8352728486061096,
                0.7105164527893066,
                0.7216333746910095,
                0.8825069069862366,
                0.8165753483772278,
                0.8123586773872375,
                0.8279504179954529,
                0.8678716421127319,
                0.6802555322647095
            ],
            [
                0.7301805019378662,
                0.846923828125,
                0.7006635069847107,
                0.8200712203979492,
                0.6318686008453369,
                0.8336874842643738,
                0.6318686008453369,
                0.8214473128318787,
                0.5382901430130005,
                0.7020622491836548,
                0.6792466640472412,
                0.7528291344642639,
                0.376094788312912,
                0.8174147605895996,
                0.6823927164077759,
                0.8002887964248657,
                0.850860059261322,
                0.7847468852996826,
                0.8289692997932434,
                0.7615121603012085,
                0.6521015167236328,
                0.8041751384735107,
                0.7887374758720398,
                0.8199384212493896,
                0.6597445607185364,
                0.853871762752533,
                0.7891718149185181,
                0.7135851979255676,
                0.7363376021385193,
                0.7913647890090942,
                0.8549127578735352,
                0.640491783618927,
                0.8434496521949768,
                0.8406240940093994,
                0.8766166567802429,
                0.7978479266166687,
                0.8210086226463318,
                0.6130096912384033,
                0.8236543536186218,
                0.7982150316238403,
                0.8235150575637817,
                0.721562385559082,
                0.8578216433525085,
                0.7070536613464355,
                0.8234653472900391,
                0.8622655868530273,
                0.7958446741104126,
                0.8398212194442749,
                0.8261494040489197,
                0.8254157304763794,
                0.7864689230918884
            ],
            [
                0.7123160362243652,
                0.7385812401771545,
                0.7721375226974487,
                0.8141315579414368,
                0.5601992011070251,
                0.8619990348815918,
                0.5601992011070251,
                0.8790791034698486,
                0.7242796421051025,
                0.7466398477554321,
                0.7807100415229797,
                0.8076328635215759,
                0.530777096748352,
                0.8204510807991028,
                0.6510347127914429,
                0.8994648456573486,
                0.804020345211029,
                0.8843857645988464,
                0.817918062210083,
                0.7767322659492493,
                0.6823778748512268,
                0.8990833759307861,
                0.8961197137832642,
                0.733639121055603,
                0.6427296996116638,
                0.8921440839767456,
                0.7468376755714417,
                0.8256646394729614,
                0.8047260046005249,
                0.8164228796958923,
                0.8234316110610962,
                0.642194926738739,
                0.8588055372238159,
                0.8567519783973694,
                0.7997568845748901,
                0.8794359564781189,
                0.7362281084060669,
                0.6147254109382629,
                0.7476643919944763,
                0.8991451263427734,
                0.8313107490539551,
                0.836662769317627,
                0.8038525581359863,
                0.7786566019058228,
                0.7309481501579285,
                0.8516709804534912,
                0.8564556837081909,
                0.8145262598991394,
                0.8176800012588501,
                0.8943262100219727,
                0.6833638548851013
            ],
            [
                0.6895650029182434,
                0.8288105130195618,
                0.7518718242645264,
                0.803830623626709,
                0.589236319065094,
                0.8734942078590393,
                0.589236319065094,
                0.8555861711502075,
                0.5529648065567017,
                0.702109694480896,
                0.7298279404640198,
                0.7678413987159729,
                0.3748464286327362,
                0.8683668971061707,
                0.6074926853179932,
                0.85016268491745,
                0.8635894656181335,
                0.8456589579582214,
                0.8625615239143372,
                0.753596842288971,
                0.6090724468231201,
                0.8527466058731079,
                0.8434456586837769,
                0.7770896553993225,
                0.5859030485153198,
                0.8760172128677368,
                0.775280237197876,
                0.7670639753341675,
                0.7308201193809509,
                0.8018480539321899,
                0.8501025438308716,
                0.5917320251464844,
                0.8727601766586304,
                0.8537225127220154,
                0.8798842430114746,
                0.8337960839271545,
                0.8055169582366943,
                0.5547498464584351,
                0.7536677718162537,
                0.845133364200592,
                0.8389082551002502,
                0.7550641894340515,
                0.8650991320610046,
                0.730246365070343,
                0.7697197198867798,
                0.8817580938339233,
                0.8505019545555115,
                0.8561062812805176,
                0.8571385741233826,
                0.8532564043998718,
                0.7625340223312378
            ],
            [
                0.747725248336792,
                0.8082720041275024,
                0.7635512351989746,
                0.8570187091827393,
                0.5808055400848389,
                0.9185259342193604,
                0.5808055400848389,
                0.8548284769058228,
                0.6266095638275146,
                0.717623770236969,
                0.738176703453064,
                0.7687029838562012,
                0.42108550667762756,
                0.8322969079017639,
                0.6465504765510559,
                0.8989313840866089,
                0.9117397665977478,
                0.8687261343002319,
                0.8966861367225647,
                0.7686404585838318,
                0.6605799794197083,
                0.899958074092865,
                0.8977792859077454,
                0.7407594323158264,
                0.6289265155792236,
                0.9378014802932739,
                0.7328238487243652,
                0.785447895526886,
                0.748430609703064,
                0.8064175844192505,
                0.8794786334037781,
                0.6357350945472717,
                0.9155066013336182,
                0.9032478332519531,
                0.9177289605140686,
                0.8720933794975281,
                0.7649232149124146,
                0.6064979434013367,
                0.7775411605834961,
                0.9047403931617737,
                0.8764601945877075,
                0.7856099009513855,
                0.9194312691688538,
                0.7364311814308167,
                0.7548999786376953,
                0.9311754107475281,
                0.8900982737541199,
                0.8293773531913757,
                0.8912135362625122,
                0.9106667041778564,
                0.7175392508506775
            ],
            [
                0.7556935548782349,
                0.7421662211418152,
                0.7558333873748779,
                0.839726984500885,
                0.597197413444519,
                0.838660478591919,
                0.597197413444519,
                0.8335126638412476,
                0.7429465055465698,
                0.7066954970359802,
                0.7469094395637512,
                0.7761521935462952,
                0.5595191121101379,
                0.7757864594459534,
                0.7420910000801086,
                0.8558081388473511,
                0.8019261360168457,
                0.8127503395080566,
                0.7966251373291016,
                0.7683033347129822,
                0.7697201371192932,
                0.8665705919265747,
                0.8625087141990662,
                0.7404067516326904,
                0.725674033164978,
                0.8644112944602966,
                0.7240641713142395,
                0.8047842979431152,
                0.7780917882919312,
                0.7998206615447998,
                0.8101427555084229,
                0.6979146599769592,
                0.800691545009613,
                0.8178505301475525,
                0.7926820516586304,
                0.8322634100914001,
                0.7027722597122192,
                0.6843470931053162,
                0.7691177129745483,
                0.8581755757331848,
                0.7985560297966003,
                0.819016695022583,
                0.8052507042884827,
                0.8022767305374146,
                0.7459268569946289,
                0.8258455991744995,
                0.8443746566772461,
                0.7806761264801025,
                0.8053489923477173,
                0.8515023589134216,
                0.7033743858337402
            ],
            [
                0.7253453731536865,
                0.7780768275260925,
                0.6849520802497864,
                0.7053598165512085,
                0.6609574556350708,
                0.7620394825935364,
                0.6609574556350708,
                0.7871026396751404,
                0.5776004791259766,
                0.719674825668335,
                0.6820194721221924,
                0.7513651847839355,
                0.46750277280807495,
                0.7662960290908813,
                0.7000058889389038,
                0.7443957328796387,
                0.7449977397918701,
                0.7507081627845764,
                0.755073606967926,
                0.7436686754226685,
                0.7028870582580566,
                0.7475351691246033,
                0.7388655543327332,
                0.7565451860427856,
                0.7030510306358337,
                0.7919527888298035,
                0.7482698559761047,
                0.7103109359741211,
                0.7403731942176819,
                0.7118238210678101,
                0.7535294890403748,
                0.6913613677024841,
                0.8184666633605957,
                0.759461522102356,
                0.8017069101333618,
                0.75617915391922,
                0.7953180074691772,
                0.6931395530700684,
                0.7736185193061829,
                0.7516112923622131,
                0.7845986485481262,
                0.696342408657074,
                0.7617034316062927,
                0.7476378679275513,
                0.7931808829307556,
                0.7901819348335266,
                0.6964924931526184,
                0.7993990182876587,
                0.7481478452682495,
                0.8013346791267395,
                0.7911472320556641
            ],
            [
                0.7069669961929321,
                0.7803689241409302,
                0.6759177446365356,
                0.7175871729850769,
                0.6326260566711426,
                0.7725259065628052,
                0.6326260566711426,
                0.7632499933242798,
                0.5105060338973999,
                0.6794968843460083,
                0.6426330208778381,
                0.733134925365448,
                0.36251339316368103,
                0.7645796537399292,
                0.6354893445968628,
                0.7397870421409607,
                0.758327066898346,
                0.7461376786231995,
                0.7613860964775085,
                0.739011287689209,
                0.626466691493988,
                0.7486696839332581,
                0.7318075299263,
                0.805740237236023,
                0.6181249618530273,
                0.767426609992981,
                0.7726989984512329,
                0.7049080729484558,
                0.6963461637496948,
                0.7480380535125732,
                0.7577465772628784,
                0.629837155342102,
                0.7977398633956909,
                0.7665627598762512,
                0.8008197546005249,
                0.7394182085990906,
                0.8707796335220337,
                0.6006619334220886,
                0.7779275178909302,
                0.7430182099342346,
                0.7516289353370667,
                0.6891115307807922,
                0.7696786522865295,
                0.6898011565208435,
                0.812944233417511,
                0.7837792634963989,
                0.7109220027923584,
                0.8231831789016724,
                0.75913405418396,
                0.7760584354400635,
                0.8434016108512878
            ],
            [
                0.7600482702255249,
                0.7396221160888672,
                0.7563236355781555,
                0.8443421125411987,
                0.6243079304695129,
                0.829897403717041,
                0.6243079304695129,
                0.8179777264595032,
                0.7187494039535522,
                0.7157092690467834,
                0.744274377822876,
                0.7640387415885925,
                0.560038685798645,
                0.7821700572967529,
                0.7855007648468018,
                0.8498717546463013,
                0.8227855563163757,
                0.8145250678062439,
                0.8093463182449341,
                0.7612146139144897,
                0.7782325744628906,
                0.8569164872169495,
                0.8484235405921936,
                0.7486057877540588,
                0.7443057298660278,
                0.8640690445899963,
                0.7536786794662476,
                0.7903252243995667,
                0.7834310531616211,
                0.7984156012535095,
                0.8167349100112915,
                0.7082095146179199,
                0.8058702349662781,
                0.8096086382865906,
                0.8005275130271912,
                0.8247859477996826,
                0.7049037218093872,
                0.6895261406898499,
                0.7714712619781494,
                0.8458746671676636,
                0.7999942302703857,
                0.8007535934448242,
                0.8088728785514832,
                0.7984618544578552,
                0.7582053542137146,
                0.8269626498222351,
                0.8319397568702698,
                0.7909557819366455,
                0.8058781027793884,
                0.8406977653503418,
                0.7075600028038025
            ],
            [
                0.6990673542022705,
                0.7580465078353882,
                0.697540283203125,
                0.7262237071990967,
                0.6589112281799316,
                0.7883031964302063,
                0.6589112281799316,
                0.7877328395843506,
                0.586887776851654,
                0.7594379186630249,
                0.7485602498054504,
                0.7486917972564697,
                0.4777272939682007,
                0.7855031490325928,
                0.7539175152778625,
                0.7713568806648254,
                0.7939061522483826,
                0.7969531416893005,
                0.8096574544906616,
                0.7345253229141235,
                0.7057203650474548,
                0.7725703120231628,
                0.755286693572998,
                0.7506946921348572,
                0.7130275964736938,
                0.8198431730270386,
                0.7620140910148621,
                0.7403868436813354,
                0.7958866357803345,
                0.7566306591033936,
                0.7917739152908325,
                0.7025168538093567,
                0.8440924882888794,
                0.7912490367889404,
                0.8049021363258362,
                0.813032329082489,
                0.7833191752433777,
                0.6902432441711426,
                0.7602766752243042,
                0.7693758010864258,
                0.8326277136802673,
                0.7236213088035583,
                0.7834198474884033,
                0.7604837417602539,
                0.7659355401992798,
                0.8029288649559021,
                0.7437697649002075,
                0.8105155825614929,
                0.7810165882110596,
                0.8036060929298401,
                0.7549446821212769
            ],
            [
                0.7369847893714905,
                0.8107864856719971,
                0.7544803023338318,
                0.7972486019134521,
                0.622893214225769,
                0.8368533849716187,
                0.622893214225769,
                0.8118383884429932,
                0.5849336981773376,
                0.7075605392456055,
                0.7161803245544434,
                0.7612221837043762,
                0.42815202474594116,
                0.8220053911209106,
                0.7245690822601318,
                0.8337402939796448,
                0.8480056524276733,
                0.8239885568618774,
                0.847281813621521,
                0.7613332271575928,
                0.6947851181030273,
                0.8383752703666687,
                0.8214066028594971,
                0.8159189224243164,
                0.6908669471740723,
                0.8679827451705933,
                0.827817976474762,
                0.7645927667617798,
                0.7404801845550537,
                0.8148825764656067,
                0.8303266167640686,
                0.6721823215484619,
                0.8559375405311584,
                0.8230946660041809,
                0.8565889000892639,
                0.8135501146316528,
                0.8080108165740967,
                0.6433343887329102,
                0.7797611951828003,
                0.8253130912780762,
                0.8075630068778992,
                0.758935809135437,
                0.8342220783233643,
                0.7630457282066345,
                0.7846683263778687,
                0.8625204563140869,
                0.8030574917793274,
                0.8433446884155273,
                0.826533317565918,
                0.8458774089813232,
                0.7910832762718201
            ],
            [
                0.7405862808227539,
                0.762828528881073,
                0.7479559779167175,
                0.7492678761482239,
                0.6357298493385315,
                0.8042247891426086,
                0.6357298493385315,
                0.8158138394355774,
                0.6200107336044312,
                0.7659593820571899,
                0.7572532296180725,
                0.7610059976577759,
                0.4914432168006897,
                0.7935807704925537,
                0.6907724142074585,
                0.8015385866165161,
                0.7744916081428528,
                0.8023411631584167,
                0.7861112356185913,
                0.7429128885269165,
                0.7378555536270142,
                0.8183625936508179,
                0.8052219152450562,
                0.727116584777832,
                0.6878675222396851,
                0.8556907176971436,
                0.7361215353012085,
                0.7400460243225098,
                0.788459062576294,
                0.7522051930427551,
                0.7879313826560974,
                0.6958263516426086,
                0.8585452437400818,
                0.814564049243927,
                0.8129482865333557,
                0.8235450387001038,
                0.7678347826004028,
                0.6823694109916687,
                0.7627034187316895,
                0.811430037021637,
                0.8181960582733154,
                0.731604278087616,
                0.78762286901474,
                0.8120453357696533,
                0.7504962682723999,
                0.8275622725486755,
                0.7646965384483337,
                0.8145111203193665,
                0.7905840873718262,
                0.8347428441047668,
                0.7305078506469727
            ],
            [
                0.7462045550346375,
                0.8328606486320496,
                0.7752744555473328,
                0.800205409526825,
                0.6209236979484558,
                0.8529165983200073,
                0.6209236979484558,
                0.8434039354324341,
                0.6058472394943237,
                0.7163999080657959,
                0.7305111885070801,
                0.7846400737762451,
                0.43869292736053467,
                0.8474699258804321,
                0.7019327878952026,
                0.841342568397522,
                0.854019820690155,
                0.8353512287139893,
                0.8431153297424316,
                0.7847571969032288,
                0.7189038395881653,
                0.8515133857727051,
                0.8386614322662354,
                0.8205973505973816,
                0.6833250522613525,
                0.8887031078338623,
                0.8218147158622742,
                0.7769990563392639,
                0.7590137720108032,
                0.8257638812065125,
                0.8469098806381226,
                0.680858850479126,
                0.8729331493377686,
                0.8505522012710571,
                0.8768395185470581,
                0.8366963863372803,
                0.8178912997245789,
                0.6463677883148193,
                0.7913830876350403,
                0.8397631049156189,
                0.8258482813835144,
                0.7969554662704468,
                0.8538363575935364,
                0.7889106273651123,
                0.7945871949195862,
                0.8745859861373901,
                0.8305144906044006,
                0.8554221987724304,
                0.8438459038734436,
                0.8559020757675171,
                0.7960967421531677
            ],
            [
                0.7167487740516663,
                0.7309516072273254,
                0.708410918712616,
                0.722052812576294,
                0.6416525840759277,
                0.7820017337799072,
                0.6416525840759277,
                0.7891299724578857,
                0.5949667692184448,
                0.7581775188446045,
                0.729667603969574,
                0.7421616315841675,
                0.4769892692565918,
                0.7621515989303589,
                0.6866053342819214,
                0.7656770348548889,
                0.7486376762390137,
                0.7731665372848511,
                0.7766558527946472,
                0.7208280563354492,
                0.6948912143707275,
                0.7767038345336914,
                0.7592669725418091,
                0.7017737627029419,
                0.6929163932800293,
                0.8171188235282898,
                0.7275066375732422,
                0.7214661836624146,
                0.7861285209655762,
                0.7258396148681641,
                0.7610673308372498,
                0.6997348070144653,
                0.8461192846298218,
                0.7910281419754028,
                0.7959913611412048,
                0.7992982864379883,
                0.7608813643455505,
                0.7013803720474243,
                0.776223361492157,
                0.7792454361915588,
                0.8272820711135864,
                0.7138162851333618,
                0.7857232093811035,
                0.7554992437362671,
                0.7400670647621155,
                0.7968008518218994,
                0.7250725030899048,
                0.7991898655891418,
                0.7666321396827698,
                0.8066921234130859,
                0.7315975427627563
            ],
            [
                0.7680066227912903,
                0.7880170345306396,
                0.7702487111091614,
                0.7881337404251099,
                0.6509213447570801,
                0.8251338601112366,
                0.6509213447570801,
                0.8202604055404663,
                0.5919877290725708,
                0.7322202920913696,
                0.7000745534896851,
                0.7704890966415405,
                0.4280815124511719,
                0.7975230813026428,
                0.6950660943984985,
                0.8196731805801392,
                0.809241771697998,
                0.8074349164962769,
                0.810908854007721,
                0.7799267172813416,
                0.6874193549156189,
                0.8324589729309082,
                0.8141891956329346,
                0.7935546040534973,
                0.6699389815330505,
                0.8462495803833008,
                0.7895740866661072,
                0.7579533457756042,
                0.7747617959976196,
                0.7990317940711975,
                0.8063264489173889,
                0.6917587518692017,
                0.85809725522995,
                0.8253052234649658,
                0.8308270573616028,
                0.8138387203216553,
                0.8326573371887207,
                0.6761124134063721,
                0.8517271280288696,
                0.8269026875495911,
                0.8196281790733337,
                0.765581488609314,
                0.8405285477638245,
                0.7632786631584167,
                0.8139299750328064,
                0.8368045687675476,
                0.7865712642669678,
                0.858315110206604,
                0.8238250017166138,
                0.8411643505096436,
                0.8016904592514038
            ],
            [
                0.7999767661094666,
                0.7447941899299622,
                0.7767762541770935,
                0.8384292721748352,
                0.6108339428901672,
                0.8746002316474915,
                0.6108339428901672,
                0.8487781286239624,
                0.6930359601974487,
                0.773457407951355,
                0.7774749994277954,
                0.7834445834159851,
                0.5098991394042969,
                0.7904515862464905,
                0.6801018118858337,
                0.9016573429107666,
                0.8185189366340637,
                0.8633614182472229,
                0.835735559463501,
                0.754666268825531,
                0.6982628703117371,
                0.8973405361175537,
                0.8976725935935974,
                0.7475693821907043,
                0.6778789758682251,
                0.9132082462310791,
                0.760719358921051,
                0.7958182096481323,
                0.813552975654602,
                0.7990887761116028,
                0.8274204730987549,
                0.6856560111045837,
                0.888262927532196,
                0.8637121915817261,
                0.8342564105987549,
                0.8773232698440552,
                0.7583518624305725,
                0.6646592617034912,
                0.7925867438316345,
                0.9110277891159058,
                0.8506664633750916,
                0.7984839677810669,
                0.8302359580993652,
                0.7785094380378723,
                0.754671573638916,
                0.8786627054214478,
                0.834550678730011,
                0.8251246213912964,
                0.8274264335632324,
                0.9175087213516235,
                0.7274646162986755
            ],
            [
                0.7657924294471741,
                0.7932555079460144,
                0.7220247983932495,
                0.7654561400413513,
                0.6625998020172119,
                0.8096405863761902,
                0.6625998020172119,
                0.8273154497146606,
                0.6424177885055542,
                0.7683555483818054,
                0.7523035407066345,
                0.8266047835350037,
                0.5174336433410645,
                0.8295436501502991,
                0.7068292498588562,
                0.8223534822463989,
                0.7779471278190613,
                0.8332813382148743,
                0.7978934049606323,
                0.8033963441848755,
                0.7060945630073547,
                0.8281084895133972,
                0.8143838047981262,
                0.8079186081886292,
                0.7093738913536072,
                0.8633363246917725,
                0.8212190866470337,
                0.7757478356361389,
                0.8045451641082764,
                0.8066076636314392,
                0.8081030249595642,
                0.704025149345398,
                0.8539960980415344,
                0.8164616823196411,
                0.8226072192192078,
                0.8210999965667725,
                0.8204392194747925,
                0.6880151629447937,
                0.8165392875671387,
                0.8284697532653809,
                0.818105936050415,
                0.7665494084358215,
                0.7908936738967896,
                0.7725737690925598,
                0.8006795644760132,
                0.8411118984222412,
                0.7688456773757935,
                0.8648869395256042,
                0.7950928211212158,
                0.8572415113449097,
                0.7969522476196289
            ],
            [
                0.7442832589149475,
                0.7691733837127686,
                0.7205163240432739,
                0.7702376842498779,
                0.6742641925811768,
                0.8136544823646545,
                0.6742641925811768,
                0.8400986790657043,
                0.682504415512085,
                0.7698848247528076,
                0.7534216046333313,
                0.8159202933311462,
                0.5400801301002502,
                0.8139744997024536,
                0.6953192949295044,
                0.836035430431366,
                0.7669125199317932,
                0.8516510725021362,
                0.788582444190979,
                0.8069096803665161,
                0.7299410104751587,
                0.8372960090637207,
                0.8332639932632446,
                0.7586491703987122,
                0.700248122215271,
                0.859766960144043,
                0.768373429775238,
                0.7994399070739746,
                0.8028146624565125,
                0.7859528064727783,
                0.7757186889648438,
                0.7121012210845947,
                0.840881884098053,
                0.8052701354026794,
                0.7871039509773254,
                0.8158804774284363,
                0.7789645195007324,
                0.7003293633460999,
                0.7924513220787048,
                0.8488544225692749,
                0.8105810284614563,
                0.7957871556282043,
                0.777673065662384,
                0.7704140543937683,
                0.7698240280151367,
                0.8349094390869141,
                0.7695621252059937,
                0.8397040367126465,
                0.789807915687561,
                0.8652541637420654,
                0.7537617087364197
            ],
            [
                0.761200487613678,
                0.8567911982536316,
                0.7550023198127747,
                0.8177510499954224,
                0.6468016505241394,
                0.8597166538238525,
                0.6468016505241394,
                0.8784337043762207,
                0.6499090790748596,
                0.7313087582588196,
                0.7391379475593567,
                0.8279221653938293,
                0.4773104190826416,
                0.8751373291015625,
                0.7168366312980652,
                0.8537851572036743,
                0.837775707244873,
                0.8717519044876099,
                0.8417380452156067,
                0.8294248580932617,
                0.7177070379257202,
                0.8563266396522522,
                0.8486385345458984,
                0.8318242430686951,
                0.7033569812774658,
                0.8888674378395081,
                0.830212414264679,
                0.8122222423553467,
                0.7890757322311401,
                0.8277693390846252,
                0.8412426114082336,
                0.690311849117279,
                0.8662599325180054,
                0.8443949222564697,
                0.8514326214790344,
                0.8405628204345703,
                0.8292564749717712,
                0.6628366112709045,
                0.8057501912117004,
                0.8539088368415833,
                0.8369029760360718,
                0.8142809867858887,
                0.8357876539230347,
                0.7788457870483398,
                0.82499760389328,
                0.8648547530174255,
                0.8298367261886597,
                0.8774827122688293,
                0.831500232219696,
                0.86898273229599,
                0.814838171005249
            ],
            [
                0.745472252368927,
                0.7247362732887268,
                0.7225288152694702,
                0.8210311532020569,
                0.6229415535926819,
                0.8404066562652588,
                0.6229415535926819,
                0.8358044028282166,
                0.7420517206192017,
                0.7797735929489136,
                0.7957014441490173,
                0.8020894527435303,
                0.562232494354248,
                0.788094699382782,
                0.6924793124198914,
                0.8815466165542603,
                0.7911157608032227,
                0.8661098480224609,
                0.805779755115509,
                0.7683587074279785,
                0.6985452175140381,
                0.8747914433479309,
                0.8732724785804749,
                0.7366977334022522,
                0.6971949338912964,
                0.8914178013801575,
                0.7825121879577637,
                0.8255028128623962,
                0.8100082278251648,
                0.796403706073761,
                0.8222278356552124,
                0.6835529208183289,
                0.8524351119995117,
                0.844688892364502,
                0.8105311393737793,
                0.8623190522193909,
                0.7390367388725281,
                0.6543108820915222,
                0.7753671407699585,
                0.8825162649154663,
                0.8343377113342285,
                0.8233208656311035,
                0.7950740456581116,
                0.7630125880241394,
                0.7174386382102966,
                0.8533130288124084,
                0.8223026394844055,
                0.8072158098220825,
                0.7984369993209839,
                0.8928563594818115,
                0.6795744299888611
            ],
            [
                0.7226617336273193,
                0.7417384386062622,
                0.7311567664146423,
                0.7960793375968933,
                0.6431971788406372,
                0.843150794506073,
                0.6431971788406372,
                0.8624094128608704,
                0.758935809135437,
                0.7904316782951355,
                0.8178169131278992,
                0.8424720168113708,
                0.5734458565711975,
                0.8140468001365662,
                0.6881904006004333,
                0.8829473853111267,
                0.7834908962249756,
                0.8941407203674316,
                0.8096731901168823,
                0.827507734298706,
                0.7166126370429993,
                0.8808665871620178,
                0.881140410900116,
                0.7573010325431824,
                0.6916686296463013,
                0.8845299482345581,
                0.7639617323875427,
                0.8600873351097107,
                0.8267382383346558,
                0.8386445641517639,
                0.8049235343933105,
                0.6917958855628967,
                0.842356264591217,
                0.8349976539611816,
                0.7833202481269836,
                0.8681331276893616,
                0.7561985850334167,
                0.6661706566810608,
                0.7802789807319641,
                0.886980414390564,
                0.8288958072662354,
                0.8688496351242065,
                0.7811663746833801,
                0.7742262482643127,
                0.7394068241119385,
                0.8400041460990906,
                0.8382527232170105,
                0.8367889523506165,
                0.8060469627380371,
                0.8912152647972107,
                0.7203999161720276
            ],
            [
                0.8052908182144165,
                0.8701897263526917,
                0.7824175357818604,
                0.8225793242454529,
                0.6465355157852173,
                0.8485173583030701,
                0.6465355157852173,
                0.8930755257606506,
                0.6930770874023438,
                0.7475062608718872,
                0.7513610124588013,
                0.849281370639801,
                0.5228927135467529,
                0.8654147386550903,
                0.7478411793708801,
                0.8552876710891724,
                0.8212518095970154,
                0.8673632740974426,
                0.8214903473854065,
                0.8620436191558838,
                0.7669972777366638,
                0.8600844144821167,
                0.8554216027259827,
                0.8443389534950256,
                0.7295896410942078,
                0.883303165435791,
                0.7929885983467102,
                0.814202070236206,
                0.8007897734642029,
                0.8521644473075867,
                0.8204469680786133,
                0.7343801856040955,
                0.8549470901489258,
                0.8301740288734436,
                0.8256468772888184,
                0.8402776718139648,
                0.8222100734710693,
                0.7081753611564636,
                0.8342750072479248,
                0.8597641587257385,
                0.827610194683075,
                0.8235146999359131,
                0.8251581192016602,
                0.8145062923431396,
                0.8440501689910889,
                0.8535985946655273,
                0.8287237286567688,
                0.8720131516456604,
                0.828088641166687,
                0.872780978679657,
                0.8201493620872498
            ],
            [
                0.7474043965339661,
                0.7380468845367432,
                0.728977382183075,
                0.8161471486091614,
                0.6624945402145386,
                0.8484334945678711,
                0.6624945402145386,
                0.8265647292137146,
                0.7179259061813354,
                0.8158687949180603,
                0.7981128692626953,
                0.7943058013916016,
                0.5400207042694092,
                0.7863616943359375,
                0.6969351768493652,
                0.8807082176208496,
                0.8000070452690125,
                0.8613199591636658,
                0.8128427267074585,
                0.7786473631858826,
                0.7128464579582214,
                0.8770195245742798,
                0.871475100517273,
                0.7502071261405945,
                0.6968147158622742,
                0.898375391960144,
                0.7788753509521484,
                0.8168883323669434,
                0.814149796962738,
                0.8064427971839905,
                0.8158596754074097,
                0.7207258343696594,
                0.8826318383216858,
                0.8643680214881897,
                0.8256707787513733,
                0.8647972941398621,
                0.7746158838272095,
                0.6773377060890198,
                0.7981533408164978,
                0.8878276944160461,
                0.8328490853309631,
                0.798625111579895,
                0.8046369552612305,
                0.7652439475059509,
                0.7386977672576904,
                0.8686672449111938,
                0.8203750848770142,
                0.8168302774429321,
                0.8100898861885071,
                0.9002663493156433,
                0.7046958804130554
            ],
            [
                0.7588682174682617,
                0.7220110893249512,
                0.7085121870040894,
                0.7593259215354919,
                0.6659870147705078,
                0.7819387316703796,
                0.6659870147705078,
                0.8017896413803101,
                0.6851678490638733,
                0.7989633083343506,
                0.757506251335144,
                0.7801553606987,
                0.5580616593360901,
                0.7616539001464844,
                0.7111564874649048,
                0.8231697678565979,
                0.7357972860336304,
                0.8169187903404236,
                0.7469512820243835,
                0.7743718028068542,
                0.7373760938644409,
                0.8224731087684631,
                0.8172773122787476,
                0.739687979221344,
                0.7116063833236694,
                0.8532910943031311,
                0.7397449612617493,
                0.7599664330482483,
                0.8234785795211792,
                0.7627203464508057,
                0.7626786231994629,
                0.7458909153938293,
                0.8466845154762268,
                0.8072181940078735,
                0.7737045884132385,
                0.8218652606010437,
                0.7697084546089172,
                0.7078655362129211,
                0.8009865880012512,
                0.8364790678024292,
                0.7956961989402771,
                0.760132908821106,
                0.7457526326179504,
                0.7664872407913208,
                0.7454278469085693,
                0.8117574453353882,
                0.7493680715560913,
                0.8030058145523071,
                0.7579385042190552,
                0.8640595078468323,
                0.7133132219314575
            ],
            [
                0.8000407814979553,
                0.8663308620452881,
                0.788128674030304,
                0.831696093082428,
                0.6476454138755798,
                0.8605708479881287,
                0.6476454138755798,
                0.9070456027984619,
                0.7060655951499939,
                0.7535257339477539,
                0.7690379023551941,
                0.8530293107032776,
                0.5355400443077087,
                0.8816885948181152,
                0.7474268674850464,
                0.8714815378189087,
                0.8308848738670349,
                0.8805530071258545,
                0.8283458352088928,
                0.8531679511070251,
                0.7733673453330994,
                0.8776718378067017,
                0.8712825775146484,
                0.8542365431785583,
                0.7280733585357666,
                0.8959258794784546,
                0.8102641105651855,
                0.8260244727134705,
                0.8039519786834717,
                0.8661770820617676,
                0.8346724510192871,
                0.7300835251808167,
                0.8651915788650513,
                0.8488866090774536,
                0.8397945165634155,
                0.8541619777679443,
                0.830238401889801,
                0.6955875754356384,
                0.8298860788345337,
                0.872352123260498,
                0.8280317783355713,
                0.8324295878410339,
                0.8301482200622559,
                0.8349184989929199,
                0.8360234498977661,
                0.8636318445205688,
                0.8487445116043091,
                0.8813165426254272,
                0.8395261168479919,
                0.8793487548828125,
                0.8203844428062439
            ],
            [
                0.7086129784584045,
                0.7838835716247559,
                0.7510709166526794,
                0.7387064099311829,
                0.6315179467201233,
                0.8054581880569458,
                0.6315179467201233,
                0.8273184895515442,
                0.5928062796592712,
                0.7632913589477539,
                0.7825993895530701,
                0.7744566202163696,
                0.46364861726760864,
                0.8279067277908325,
                0.6760242581367493,
                0.7925698757171631,
                0.7779626250267029,
                0.8213194012641907,
                0.8037974238395691,
                0.7600926160812378,
                0.69718337059021,
                0.8031789064407349,
                0.7903847098350525,
                0.7505254149436951,
                0.6639708280563354,
                0.8323854207992554,
                0.7519126534461975,
                0.7661247253417969,
                0.7641997933387756,
                0.7767326831817627,
                0.7898444533348083,
                0.6735609769821167,
                0.8499346375465393,
                0.8070114850997925,
                0.8212054967880249,
                0.8198890089988708,
                0.7864481210708618,
                0.6527759432792664,
                0.7507798075675964,
                0.7968193292617798,
                0.8228952884674072,
                0.7409650087356567,
                0.7871819734573364,
                0.8144943714141846,
                0.7662951946258545,
                0.8319639563560486,
                0.7815051674842834,
                0.8393344283103943,
                0.8067785501480103,
                0.8182215094566345,
                0.758711040019989
            ],
            [
                0.7755729556083679,
                0.817985475063324,
                0.7449710369110107,
                0.7915696501731873,
                0.6676262021064758,
                0.8357299566268921,
                0.6676262021064758,
                0.8291608095169067,
                0.6092034578323364,
                0.7295224070549011,
                0.709965705871582,
                0.7928954362869263,
                0.4561116099357605,
                0.8318601250648499,
                0.7213139533996582,
                0.8168022632598877,
                0.8257191181182861,
                0.8094822764396667,
                0.8255296945571899,
                0.7852923274040222,
                0.7006956934928894,
                0.8311168551445007,
                0.8078252077102661,
                0.8308219313621521,
                0.694135844707489,
                0.8578488230705261,
                0.8320911526679993,
                0.7783629894256592,
                0.757125735282898,
                0.8087718486785889,
                0.8229336142539978,
                0.687423825263977,
                0.8619503974914551,
                0.8341644406318665,
                0.8622205853462219,
                0.8049325942993164,
                0.8621808886528015,
                0.6670902967453003,
                0.8336466550827026,
                0.8181173205375671,
                0.8205876350402832,
                0.7607938051223755,
                0.8350933790206909,
                0.7747156620025635,
                0.8651730418205261,
                0.859058678150177,
                0.797000527381897,
                0.8866925239562988,
                0.826447069644928,
                0.8399017453193665,
                0.8510817885398865
            ],
            [
                0.7110911011695862,
                0.7408517599105835,
                0.7165350317955017,
                0.7138506770133972,
                0.6399576663970947,
                0.7752782702445984,
                0.6399576663970947,
                0.7883139848709106,
                0.6018523573875427,
                0.7564212679862976,
                0.7398618459701538,
                0.7373674511909485,
                0.4934300482273102,
                0.7722529172897339,
                0.6933680772781372,
                0.7741941809654236,
                0.7524252533912659,
                0.7748323082923889,
                0.7756742835044861,
                0.7148923873901367,
                0.7081862688064575,
                0.7843886613845825,
                0.7688605189323425,
                0.7070540189743042,
                0.6944519281387329,
                0.8212371468544006,
                0.7345884442329407,
                0.7303213477134705,
                0.7742525935173035,
                0.7352154850959778,
                0.7662997245788574,
                0.6944565773010254,
                0.8420289158821106,
                0.7906458377838135,
                0.7913320660591125,
                0.7985056042671204,
                0.7448652982711792,
                0.6915779709815979,
                0.7557129859924316,
                0.7818791270256042,
                0.8098238706588745,
                0.7171019911766052,
                0.7685182690620422,
                0.8020510077476501,
                0.7462522387504578,
                0.8099899291992188,
                0.7392939925193787,
                0.8071824312210083,
                0.781241238117218,
                0.8130137920379639,
                0.7211838960647583
            ],
            [
                0.7187162041664124,
                0.858120322227478,
                0.7273088693618774,
                0.7916238903999329,
                0.6363653540611267,
                0.8452005386352539,
                0.6363653540611267,
                0.838783323764801,
                0.5522980690002441,
                0.7048652172088623,
                0.7045482397079468,
                0.796834409236908,
                0.39648666977882385,
                0.8839104175567627,
                0.6721603274345398,
                0.8098874092102051,
                0.8556366562843323,
                0.8376708626747131,
                0.8449828028678894,
                0.8040005564689636,
                0.6598620414733887,
                0.8238140940666199,
                0.8010478615760803,
                0.8188785314559937,
                0.6471595168113708,
                0.8617677688598633,
                0.8285271525382996,
                0.7707808613777161,
                0.716191291809082,
                0.8042867183685303,
                0.8382724523544312,
                0.6340520977973938,
                0.8644285798072815,
                0.830932080745697,
                0.8890902996063232,
                0.794346272945404,
                0.8571203351020813,
                0.6021534204483032,
                0.7836578488349915,
                0.8062376379966736,
                0.8159236907958984,
                0.7381857633590698,
                0.8549315929412842,
                0.7417792081832886,
                0.8429281115531921,
                0.8763036131858826,
                0.8039868474006653,
                0.8938177227973938,
                0.8449645638465881,
                0.8263299465179443,
                0.823287844657898
            ],
            [
                0.7289204597473145,
                0.7964802980422974,
                0.7511411905288696,
                0.8656035661697388,
                0.5616345405578613,
                0.9113165140151978,
                0.5616345405578613,
                0.8296274542808533,
                0.6025949716567993,
                0.6945472955703735,
                0.7185333967208862,
                0.7470255494117737,
                0.4035834074020386,
                0.8235095739364624,
                0.639702558517456,
                0.8990293145179749,
                0.9206441640853882,
                0.845815896987915,
                0.891815185546875,
                0.7486231327056885,
                0.6419574618339539,
                0.9003171920776367,
                0.894923746585846,
                0.7262287735939026,
                0.612001895904541,
                0.9384404420852661,
                0.7315894365310669,
                0.7653495669364929,
                0.7198433876037598,
                0.7785313129425049,
                0.8854550123214722,
                0.5971986651420593,
                0.9043593406677246,
                0.8906340599060059,
                0.9311602711677551,
                0.8521690368652344,
                0.7386753559112549,
                0.5727545022964478,
                0.7513848543167114,
                0.900036096572876,
                0.8644300699234009,
                0.7584705352783203,
                0.918293833732605,
                0.7173170447349548,
                0.7418473958969116,
                0.9523861408233643,
                0.8831543326377869,
                0.8119680285453796,
                0.8891394734382629,
                0.9094049334526062,
                0.6962839365005493
            ],
            [
                0.7708603739738464,
                0.7406792640686035,
                0.7564734220504761,
                0.8453795909881592,
                0.6446677446365356,
                0.8415764570236206,
                0.6446677446365356,
                0.8248292207717896,
                0.7071930766105652,
                0.7428282499313354,
                0.7410637736320496,
                0.7608553171157837,
                0.5524869561195374,
                0.7846357822418213,
                0.7521946430206299,
                0.8526654243469238,
                0.8127433061599731,
                0.8106293678283691,
                0.8019595146179199,
                0.7683234214782715,
                0.7750381231307983,
                0.8684330582618713,
                0.8551152348518372,
                0.7398003339767456,
                0.7317100167274475,
                0.8755090236663818,
                0.7465183138847351,
                0.7921843528747559,
                0.8056663870811462,
                0.797635018825531,
                0.8212078213691711,
                0.744493842124939,
                0.8427895307540894,
                0.8447747230529785,
                0.8189276456832886,
                0.8456573486328125,
                0.7448491454124451,
                0.6977777481079102,
                0.7977492809295654,
                0.8591328263282776,
                0.8175158500671387,
                0.803099513053894,
                0.8201647996902466,
                0.7956945896148682,
                0.7703412175178528,
                0.8378477692604065,
                0.8341577649116516,
                0.8061339855194092,
                0.8206279277801514,
                0.8524941205978394,
                0.714404284954071
            ],
            [
                0.7016786336898804,
                0.7540807127952576,
                0.7363276481628418,
                0.7484928965568542,
                0.6460334062576294,
                0.8096232414245605,
                0.6460334062576294,
                0.7997968792915344,
                0.5688181519508362,
                0.779092013835907,
                0.763221263885498,
                0.7550777792930603,
                0.4549853801727295,
                0.8014656901359558,
                0.6760488748550415,
                0.796385645866394,
                0.7906982898712158,
                0.7916604280471802,
                0.8006227612495422,
                0.7418835163116455,
                0.6940904259681702,
                0.8109725117683411,
                0.789981484413147,
                0.7230234146118164,
                0.6640212535858154,
                0.8142656683921814,
                0.7419014573097229,
                0.7299670577049255,
                0.8169759511947632,
                0.7759888172149658,
                0.798301100730896,
                0.6900905966758728,
                0.8481665849685669,
                0.7930474877357483,
                0.8066565990447998,
                0.8295773863792419,
                0.7696284055709839,
                0.6564744710922241,
                0.7742700576782227,
                0.7964192628860474,
                0.805522620677948,
                0.734771192073822,
                0.8032271862030029,
                0.7777826189994812,
                0.7516883611679077,
                0.8054037094116211,
                0.7722293138504028,
                0.811610996723175,
                0.8293860554695129,
                0.8165737986564636,
                0.7158969640731812
            ],
            [
                0.6704297661781311,
                0.807353138923645,
                0.689492404460907,
                0.727714478969574,
                0.640436589717865,
                0.8068936467170715,
                0.640436589717865,
                0.8056392669677734,
                0.496414452791214,
                0.708248496055603,
                0.7096017003059387,
                0.7642061114311218,
                0.3517916202545166,
                0.8522639274597168,
                0.6049504280090332,
                0.7802280783653259,
                0.7992742657661438,
                0.8203287124633789,
                0.8079779744148254,
                0.7715675234794617,
                0.6068292856216431,
                0.7959859371185303,
                0.7727832794189453,
                0.7943425178527832,
                0.5864785313606262,
                0.8196493983268738,
                0.7958819270133972,
                0.753970742225647,
                0.719278872013092,
                0.7874993681907654,
                0.7949661016464233,
                0.6039413809776306,
                0.8443887233734131,
                0.8093535900115967,
                0.8397042155265808,
                0.7835561037063599,
                0.868662416934967,
                0.5549517273902893,
                0.7531383037567139,
                0.7785587310791016,
                0.7917394042015076,
                0.7396893501281738,
                0.7996640801429749,
                0.7061619758605957,
                0.7847319841384888,
                0.8267810940742493,
                0.781201958656311,
                0.8613646030426025,
                0.8200585842132568,
                0.794247567653656,
                0.804790735244751
            ],
            [
                0.7228617072105408,
                0.7172064781188965,
                0.6955071687698364,
                0.7378473877906799,
                0.6473631262779236,
                0.7707425355911255,
                0.6473631262779236,
                0.7825264930725098,
                0.6075844764709473,
                0.7808933854103088,
                0.7246516346931458,
                0.7645647525787354,
                0.48479777574539185,
                0.7711837291717529,
                0.6505476236343384,
                0.7778759002685547,
                0.7359718084335327,
                0.7847545742988586,
                0.7447161674499512,
                0.7266868352890015,
                0.6702926158905029,
                0.7930032014846802,
                0.7717899680137634,
                0.7155749201774597,
                0.6555584669113159,
                0.8300676345825195,
                0.7615838050842285,
                0.7255850434303284,
                0.7853364944458008,
                0.7335799932479858,
                0.7602865695953369,
                0.6941899657249451,
                0.8608961701393127,
                0.8053228855133057,
                0.8020774126052856,
                0.7996737957000732,
                0.7928612232208252,
                0.6412070393562317,
                0.7903488874435425,
                0.7924631237983704,
                0.8012783527374268,
                0.7050633430480957,
                0.7567500472068787,
                0.7320588231086731,
                0.7362055778503418,
                0.8071839809417725,
                0.7240073680877686,
                0.8055161833763123,
                0.7555918097496033,
                0.820036768913269,
                0.7021663188934326
            ],
            [
                0.6963961720466614,
                0.821231484413147,
                0.7069369554519653,
                0.7830024361610413,
                0.5905393362045288,
                0.8419401049613953,
                0.5905393362045288,
                0.805505096912384,
                0.5132002830505371,
                0.6908831000328064,
                0.7180310487747192,
                0.7375162839889526,
                0.32919496297836304,
                0.8273292779922485,
                0.6320841908454895,
                0.7935555577278137,
                0.8498014211654663,
                0.8244625329971313,
                0.8598412871360779,
                0.7527632117271423,
                0.6190994381904602,
                0.8040193319320679,
                0.7846606373786926,
                0.7959124445915222,
                0.6197316646575928,
                0.8488151431083679,
                0.7868165373802185,
                0.7619161009788513,
                0.7020127773284912,
                0.8177931904792786,
                0.8386527895927429,
                0.6065521240234375,
                0.8578733801841736,
                0.8441252708435059,
                0.8765639662742615,
                0.8097226619720459,
                0.8101356625556946,
                0.5674952268600464,
                0.7527328133583069,
                0.7902083396911621,
                0.8266242146492004,
                0.7448898553848267,
                0.8456332683563232,
                0.7121451497077942,
                0.7598363757133484,
                0.8650263547897339,
                0.8137513995170593,
                0.8370729684829712,
                0.8427226543426514,
                0.8094398975372314,
                0.7670615911483765
            ],
            [
                0.7221328020095825,
                0.7708796858787537,
                0.7145853638648987,
                0.7490753531455994,
                0.6360834240913391,
                0.7827498912811279,
                0.6360834240913391,
                0.7994478344917297,
                0.5789652466773987,
                0.7552312016487122,
                0.7414137721061707,
                0.7663572430610657,
                0.46213844418525696,
                0.8073601126670837,
                0.6848039627075195,
                0.7754173874855042,
                0.7670022249221802,
                0.7950530648231506,
                0.777202844619751,
                0.7396596074104309,
                0.7053784728050232,
                0.7929387092590332,
                0.7698140740394592,
                0.7299691438674927,
                0.7025523781776428,
                0.8357720971107483,
                0.7822306156158447,
                0.726477861404419,
                0.7795514464378357,
                0.7405416965484619,
                0.7882598042488098,
                0.6633497476577759,
                0.8419105410575867,
                0.7825014591217041,
                0.8160682916641235,
                0.790418803691864,
                0.7651572823524475,
                0.6541544795036316,
                0.7554109692573547,
                0.7812734246253967,
                0.804273784160614,
                0.7006223797798157,
                0.7774372100830078,
                0.7687491774559021,
                0.7504227757453918,
                0.825448751449585,
                0.7325411438941956,
                0.813002347946167,
                0.7765837907791138,
                0.818858802318573,
                0.7262133955955505
            ],
            [
                0.7509402632713318,
                0.726950466632843,
                0.7198305130004883,
                0.7363868355751038,
                0.6175183653831482,
                0.751250147819519,
                0.6175183653831482,
                0.7909396290779114,
                0.644511878490448,
                0.7681363224983215,
                0.7391071319580078,
                0.7935994267463684,
                0.5339733362197876,
                0.7771097421646118,
                0.6660847067832947,
                0.7804315686225891,
                0.7143301367759705,
                0.7922731041908264,
                0.7222332954406738,
                0.7435674071311951,
                0.7149982452392578,
                0.7960283756256104,
                0.7787522077560425,
                0.7307510375976562,
                0.7015690803527832,
                0.8279550671577454,
                0.7815738320350647,
                0.7218554615974426,
                0.789409339427948,
                0.7336916923522949,
                0.7423082590103149,
                0.6744088530540466,
                0.8182742595672607,
                0.7593910098075867,
                0.767577588558197,
                0.7704029679298401,
                0.7633177042007446,
                0.6581999063491821,
                0.7628422379493713,
                0.791782021522522,
                0.7551597356796265,
                0.6991704106330872,
                0.7306021451950073,
                0.761195957660675,
                0.7271376848220825,
                0.783372163772583,
                0.7098789215087891,
                0.798992395401001,
                0.730935275554657,
                0.817627489566803,
                0.7079870104789734
            ],
            [
                0.664110004901886,
                0.7464004158973694,
                0.6385332942008972,
                0.693175733089447,
                0.6604162454605103,
                0.7583551406860352,
                0.6604162454605103,
                0.7391340732574463,
                0.520817756652832,
                0.671914279460907,
                0.6328774094581604,
                0.7229010462760925,
                0.3829609751701355,
                0.7498453259468079,
                0.6300857663154602,
                0.7281409502029419,
                0.7422435283660889,
                0.7251355648040771,
                0.7637101411819458,
                0.7275410890579224,
                0.6125073432922363,
                0.746761679649353,
                0.7193647623062134,
                0.8131499886512756,
                0.6600942015647888,
                0.769012987613678,
                0.8202911615371704,
                0.711807131767273,
                0.7279688119888306,
                0.7627272605895996,
                0.7772643566131592,
                0.6179834604263306,
                0.7871858477592468,
                0.7703467607498169,
                0.7871869206428528,
                0.7377845048904419,
                0.8430390357971191,
                0.5903588533401489,
                0.7667480707168579,
                0.7296358942985535,
                0.7466984391212463,
                0.6986531019210815,
                0.7501389384269714,
                0.6590134501457214,
                0.7856276631355286,
                0.7724846005439758,
                0.7119539380073547,
                0.8069416880607605,
                0.7551572918891907,
                0.7585846185684204,
                0.8062514066696167
            ],
            [
                0.7222505807876587,
                0.8548114895820618,
                0.7108056545257568,
                0.7910757660865784,
                0.6147684454917908,
                0.8293752074241638,
                0.6147684454917908,
                0.8291736841201782,
                0.5407328605651855,
                0.7047406435012817,
                0.7196545600891113,
                0.7894390821456909,
                0.3743518590927124,
                0.8637722730636597,
                0.6650328636169434,
                0.7997533679008484,
                0.8313702344894409,
                0.8498905301094055,
                0.8370240926742554,
                0.812132716178894,
                0.6632961630821228,
                0.81197589635849,
                0.7924918532371521,
                0.8204120397567749,
                0.6573805212974548,
                0.8498222827911377,
                0.822919487953186,
                0.7762072682380676,
                0.7322778701782227,
                0.8249187469482422,
                0.8283222317695618,
                0.6348409652709961,
                0.8427601456642151,
                0.8221929669380188,
                0.8468965888023376,
                0.8017413020133972,
                0.8411117196083069,
                0.6026967167854309,
                0.769964337348938,
                0.7967137098312378,
                0.8046406507492065,
                0.7626519203186035,
                0.8272268772125244,
                0.7418122291564941,
                0.7991414666175842,
                0.8539170026779175,
                0.7992748022079468,
                0.8642853498458862,
                0.8327616453170776,
                0.8165497779846191,
                0.8001264333724976
            ],
            [
                0.7565982341766357,
                0.7177983522415161,
                0.741874635219574,
                0.7907133102416992,
                0.6652999520301819,
                0.8154303431510925,
                0.6652999520301819,
                0.8322737216949463,
                0.7181904911994934,
                0.8026379942893982,
                0.7894213199615479,
                0.7991169691085815,
                0.581278920173645,
                0.781896710395813,
                0.7083017826080322,
                0.845644474029541,
                0.757756769657135,
                0.8445478677749634,
                0.7726576924324036,
                0.7788757085800171,
                0.7558977007865906,
                0.8527343273162842,
                0.8433554768562317,
                0.7290523052215576,
                0.7132015228271484,
                0.8627740144729614,
                0.7424420714378357,
                0.792940080165863,
                0.8426379561424255,
                0.7752242684364319,
                0.784368634223938,
                0.7274670004844666,
                0.840652346611023,
                0.8256200551986694,
                0.7744865417480469,
                0.8438737988471985,
                0.761385440826416,
                0.7080051898956299,
                0.7883071899414062,
                0.8567804098129272,
                0.8233519792556763,
                0.7971246242523193,
                0.7726561427116394,
                0.7967645525932312,
                0.7620254158973694,
                0.8242880702018738,
                0.7835966348648071,
                0.8304059505462646,
                0.7812390327453613,
                0.8700915575027466,
                0.7306980490684509
            ],
            [
                0.7792055010795593,
                0.8757650256156921,
                0.7838870286941528,
                0.8315622806549072,
                0.6349305510520935,
                0.8735391497612,
                0.6349305510520935,
                0.8970823884010315,
                0.638042151927948,
                0.7230076789855957,
                0.7321970462799072,
                0.8403468132019043,
                0.47801458835601807,
                0.9063250422477722,
                0.6814215779304504,
                0.8643103837966919,
                0.851111888885498,
                0.8748955130577087,
                0.8383118510246277,
                0.8433780074119568,
                0.7084869146347046,
                0.8723770976066589,
                0.8662147521972656,
                0.8301785588264465,
                0.6583797335624695,
                0.896467387676239,
                0.7896344661712646,
                0.7994943261146545,
                0.7852685451507568,
                0.8317863941192627,
                0.8558430671691895,
                0.6656968593597412,
                0.8713400363922119,
                0.8590071797370911,
                0.8682613372802734,
                0.8460598587989807,
                0.8497070670127869,
                0.6417732834815979,
                0.8224704265594482,
                0.8676367402076721,
                0.8415113091468811,
                0.8007633090019226,
                0.8618873357772827,
                0.7872483730316162,
                0.8470757007598877,
                0.8845206499099731,
                0.8466826677322388,
                0.9011794328689575,
                0.8621196150779724,
                0.8810511231422424,
                0.825721800327301
            ],
            [
                0.7644507884979248,
                0.7342721819877625,
                0.6799915432929993,
                0.7528340220451355,
                0.7022380828857422,
                0.7606385350227356,
                0.7022380828857422,
                0.7937291860580444,
                0.6655580401420593,
                0.7793808579444885,
                0.7452327013015747,
                0.8062908053398132,
                0.5744496583938599,
                0.7822563648223877,
                0.720721960067749,
                0.7959001064300537,
                0.7266420722007751,
                0.808497428894043,
                0.7387593984603882,
                0.7886382937431335,
                0.7439098358154297,
                0.7959042191505432,
                0.7902469635009766,
                0.7571165561676025,
                0.7262020111083984,
                0.8273658156394958,
                0.7552242875099182,
                0.7556281089782715,
                0.8047372102737427,
                0.7661699056625366,
                0.7474871873855591,
                0.7322797775268555,
                0.8022975325584412,
                0.7594184279441833,
                0.7616081833839417,
                0.7732287645339966,
                0.7644363641738892,
                0.728035032749176,
                0.8067841529846191,
                0.8076059818267822,
                0.7757626175880432,
                0.7423157691955566,
                0.7397571206092834,
                0.7571665048599243,
                0.7736182808876038,
                0.7997286319732666,
                0.7172380089759827,
                0.8159400224685669,
                0.7475303411483765,
                0.8366732597351074,
                0.7444926500320435
            ]
        ],
        [
            [
                0.7508879899978638,
                0.7352239489555359,
                0.7196117639541626,
                0.7478471994400024,
                0.7299535870552063,
                0.7340620160102844,
                0.6959294080734253,
                0.8678292632102966,
                0.7714014053344727,
                0.7140970826148987,
                0.7281641364097595,
                0.7326721549034119,
                0.6796936988830566,
                0.8415043950080872,
                0.7074406743049622,
                0.7386645674705505,
                0.8568761348724365,
                0.7075372934341431,
                0.8182641267776489,
                0.7020058035850525,
                0.8390392661094666,
                0.7423115372657776,
                0.8382540345191956,
                0.7099241614341736,
                0.7429448962211609,
                0.8183718919754028,
                0.8008164167404175,
                0.6776951551437378,
                0.8423011302947998,
                0.7433265447616577,
                0.7309865951538086,
                0.8738874793052673,
                0.7120187282562256,
                0.7313340902328491,
                0.7986851334571838,
                0.8032118678092957,
                0.6789485216140747,
                0.8033973574638367,
                0.7129563689231873,
                0.7161429524421692,
                0.7307809591293335,
                0.8539642095565796,
                0.7008047699928284,
                0.6808552145957947,
                0.7147769927978516,
                0.7134493589401245,
                0.7307809591293335,
                0.7846916317939758,
                0.7156169414520264,
                0.7986321449279785,
                0.7219399809837341
            ],
            [
                0.800688624382019,
                0.7337627410888672,
                0.8159456849098206,
                0.8624261021614075,
                0.7325246930122375,
                0.8162386417388916,
                0.6907597184181213,
                0.7801323533058167,
                0.7922418713569641,
                0.797599732875824,
                0.7837029695510864,
                0.8013241291046143,
                0.7271134853363037,
                0.8144587278366089,
                0.7878863215446472,
                0.7812654972076416,
                0.7351779937744141,
                0.8519638180732727,
                0.7428249716758728,
                0.8302108645439148,
                0.6544978618621826,
                0.8028101921081543,
                0.7553144097328186,
                0.7508519887924194,
                0.6669747233390808,
                0.8609387874603271,
                0.7676348686218262,
                0.6911540031433105,
                0.7320833802223206,
                0.8552679419517517,
                0.7675811052322388,
                0.7171007990837097,
                0.7662575840950012,
                0.7843503355979919,
                0.7055993676185608,
                0.8082537055015564,
                0.7311988472938538,
                0.7232793569564819,
                0.7892645597457886,
                0.5923101902008057,
                0.7854887843132019,
                0.7449076175689697,
                0.7602827548980713,
                0.7116143703460693,
                0.7702592015266418,
                0.8184850811958313,
                0.7854887843132019,
                0.6481266617774963,
                0.7403750419616699,
                0.8619341850280762,
                0.8159633874893188
            ],
            [
                0.8141892552375793,
                0.8295844793319702,
                0.7942848205566406,
                0.8441687226295471,
                0.7709701657295227,
                0.8083500862121582,
                0.7181512117385864,
                0.8995895981788635,
                0.82935631275177,
                0.7770010828971863,
                0.7962487936019897,
                0.7945765852928162,
                0.7390469312667847,
                0.9017724990844727,
                0.7537571787834167,
                0.8034934401512146,
                0.8643094301223755,
                0.7902726531028748,
                0.8631736636161804,
                0.7798922657966614,
                0.7929456233978271,
                0.8125877976417542,
                0.8693655729293823,
                0.7378308176994324,
                0.7705200910568237,
                0.8690101504325867,
                0.8875604271888733,
                0.6934952735900879,
                0.8207641839981079,
                0.7993241548538208,
                0.786273717880249,
                0.8317740559577942,
                0.7692959308624268,
                0.7943463325500488,
                0.7994359135627747,
                0.8331187963485718,
                0.7272288799285889,
                0.7986879944801331,
                0.782197892665863,
                0.7401860356330872,
                0.798437774181366,
                0.8223026990890503,
                0.7627183794975281,
                0.7403928637504578,
                0.7678384780883789,
                0.7889828681945801,
                0.798437774181366,
                0.7810550332069397,
                0.7631349563598633,
                0.8365721702575684,
                0.7708280682563782
            ],
            [
                0.9721155166625977,
                0.8211170434951782,
                0.8103944659233093,
                0.8769863843917847,
                0.8225061893463135,
                0.8723146915435791,
                0.7461755275726318,
                0.8392467498779297,
                0.8373498320579529,
                0.8207600712776184,
                0.8558798432350159,
                0.8073477745056152,
                0.7618789076805115,
                0.8576663136482239,
                0.7804528474807739,
                0.8591018915176392,
                0.7721993327140808,
                0.8288885354995728,
                0.7976101636886597,
                0.8437803387641907,
                0.7155902981758118,
                0.8719210028648376,
                0.7699178457260132,
                0.7882248759269714,
                0.7401982545852661,
                0.8961251974105835,
                0.8165937066078186,
                0.763654351234436,
                0.7885341644287109,
                0.8646661639213562,
                0.8527501821517944,
                0.7770799994468689,
                0.798100471496582,
                0.8594633936882019,
                0.747653067111969,
                0.8499521017074585,
                0.7505563497543335,
                0.7647809982299805,
                0.8270509839057922,
                0.6769246459007263,
                0.8562779426574707,
                0.8055371046066284,
                0.7726880311965942,
                0.7305020093917847,
                0.8118180632591248,
                0.812533974647522,
                0.8562779426574707,
                0.700710654258728,
                0.7697637677192688,
                0.8754101395606995,
                0.8363393545150757
            ],
            [
                0.8659780025482178,
                0.8296563029289246,
                0.79875648021698,
                0.8432766199111938,
                0.9258597493171692,
                0.9217802882194519,
                0.8482245802879333,
                0.8217546343803406,
                0.9014289975166321,
                0.9027574062347412,
                0.9232584834098816,
                0.7949979901313782,
                0.8521318435668945,
                0.8328695297241211,
                0.7222423553466797,
                0.9226933121681213,
                0.7377150058746338,
                0.8342241644859314,
                0.7852461338043213,
                0.8769658803939819,
                0.6871472597122192,
                0.9180903434753418,
                0.758441150188446,
                0.9068246483802795,
                0.7809247374534607,
                0.8860654830932617,
                0.7606543898582458,
                0.907170832157135,
                0.806113064289093,
                0.9089392423629761,
                0.925108790397644,
                0.7760137319564819,
                0.8419949412345886,
                0.9272404909133911,
                0.7457011342048645,
                0.9119898676872253,
                0.8576098084449768,
                0.8052677512168884,
                0.8969101905822754,
                0.6754452586174011,
                0.9166203141212463,
                0.8268036246299744,
                0.8267682194709778,
                0.6805300712585449,
                0.9167733192443848,
                0.8309226632118225,
                0.9166203141212463,
                0.7128047347068787,
                0.8306634426116943,
                0.8903475403785706,
                0.9231331944465637
            ],
            [
                0.8616636991500854,
                0.8342586755752563,
                0.8259479403495789,
                0.8819229602813721,
                0.8602966666221619,
                0.9371956586837769,
                0.7981938123703003,
                0.8349995613098145,
                0.8639609217643738,
                0.8868793249130249,
                0.8975250720977783,
                0.7989319562911987,
                0.8204827308654785,
                0.8538148403167725,
                0.7570971250534058,
                0.8995041251182556,
                0.7684187889099121,
                0.871064305305481,
                0.8004642128944397,
                0.8933310508728027,
                0.6819548606872559,
                0.9004659056663513,
                0.7750825881958008,
                0.8573527336120605,
                0.7482324242591858,
                0.9042119979858398,
                0.8040106296539307,
                0.817559540271759,
                0.7936221957206726,
                0.920081615447998,
                0.8889923691749573,
                0.7591431736946106,
                0.8340821862220764,
                0.8969335556030273,
                0.7226390838623047,
                0.8804565072059631,
                0.8305286765098572,
                0.7759380340576172,
                0.8806338310241699,
                0.6784998774528503,
                0.892961859703064,
                0.7956448793411255,
                0.8214910626411438,
                0.7137468457221985,
                0.8760614395141602,
                0.8479800820350647,
                0.892961859703064,
                0.6953490972518921,
                0.8124651312828064,
                0.8996982574462891,
                0.9134870171546936
            ],
            [
                0.7434629201889038,
                0.7269275784492493,
                0.6825125217437744,
                0.7300531268119812,
                0.717064619064331,
                0.7367726564407349,
                0.7080129384994507,
                0.8698303699493408,
                0.7937189340591431,
                0.7114609479904175,
                0.7302466034889221,
                0.7333996891975403,
                0.6948820352554321,
                0.8165197372436523,
                0.6616886258125305,
                0.748123049736023,
                0.8431547284126282,
                0.7024455070495605,
                0.8464874625205994,
                0.6923964023590088,
                0.8375513553619385,
                0.7381116151809692,
                0.8362569212913513,
                0.7036049365997314,
                0.8200309872627258,
                0.8049246072769165,
                0.800137996673584,
                0.6695080399513245,
                0.8225786685943604,
                0.720797598361969,
                0.7270309329032898,
                0.8329572081565857,
                0.6813135743141174,
                0.7271695137023926,
                0.781487226486206,
                0.7914637327194214,
                0.6768227815628052,
                0.814456582069397,
                0.7092725038528442,
                0.7601194977760315,
                0.7315241694450378,
                0.8464236259460449,
                0.6953313946723938,
                0.6191670894622803,
                0.7155790328979492,
                0.6962912082672119,
                0.7315241694450378,
                0.8213692307472229,
                0.7075899243354797,
                0.7706071138381958,
                0.6943025588989258
            ],
            [
                0.8354557156562805,
                0.7844926118850708,
                0.7911031246185303,
                0.854656457901001,
                0.8983609676361084,
                0.8730897903442383,
                0.8090810775756836,
                0.8423157930374146,
                0.8661930561065674,
                0.871749758720398,
                0.8765974044799805,
                0.7972743511199951,
                0.8239589929580688,
                0.8432372212409973,
                0.7327837347984314,
                0.8798394799232483,
                0.7876548767089844,
                0.8209331035614014,
                0.8009728193283081,
                0.869640588760376,
                0.7424025535583496,
                0.8780028820037842,
                0.7887465953826904,
                0.8622864484786987,
                0.7555830478668213,
                0.905242383480072,
                0.7570613026618958,
                0.8591909408569336,
                0.8146658539772034,
                0.8892561197280884,
                0.8791323900222778,
                0.8067510724067688,
                0.8128633499145508,
                0.8764302134513855,
                0.7777770161628723,
                0.8896559476852417,
                0.8415796756744385,
                0.8126866221427917,
                0.8796412944793701,
                0.730999767780304,
                0.8717122673988342,
                0.836144745349884,
                0.832895040512085,
                0.6715153455734253,
                0.8563541769981384,
                0.8261640667915344,
                0.8717122673988342,
                0.7068362236022949,
                0.7801845073699951,
                0.9036908149719238,
                0.8924885392189026
            ],
            [
                0.8588120937347412,
                0.8247578740119934,
                0.7661138772964478,
                0.8216777443885803,
                0.8981373310089111,
                0.9013583660125732,
                0.866733193397522,
                0.8540170192718506,
                0.8864902853965759,
                0.900891900062561,
                0.9148046970367432,
                0.7960968017578125,
                0.8424097299575806,
                0.851790726184845,
                0.7051020860671997,
                0.9232258796691895,
                0.808900773525238,
                0.813614010810852,
                0.8543878197669983,
                0.861438512802124,
                0.7446273565292358,
                0.9153174161911011,
                0.8131130933761597,
                0.9048064947128296,
                0.8113269805908203,
                0.8722500205039978,
                0.7866020202636719,
                0.8799201846122742,
                0.8498154282569885,
                0.8881210088729858,
                0.9238967895507812,
                0.8327687978744507,
                0.8265532851219177,
                0.9191374182701111,
                0.7822252511978149,
                0.8923797607421875,
                0.8556252121925354,
                0.8397042751312256,
                0.8797672986984253,
                0.7420902252197266,
                0.9043447971343994,
                0.8606885075569153,
                0.8242970705032349,
                0.6674669981002808,
                0.8938761949539185,
                0.803746223449707,
                0.9043447971343994,
                0.7481387853622437,
                0.8317376971244812,
                0.8596669435501099,
                0.9029028415679932
            ],
            [
                0.7992978692054749,
                0.7704800367355347,
                0.8011752367019653,
                0.8378834128379822,
                0.8340787887573242,
                0.8421093225479126,
                0.7780591249465942,
                0.81158447265625,
                0.8319703340530396,
                0.8668637275695801,
                0.8614821434020996,
                0.7771190404891968,
                0.8184477686882019,
                0.8173578381538391,
                0.7446373105049133,
                0.8622811436653137,
                0.7709999084472656,
                0.8258288502693176,
                0.8108564615249634,
                0.8497243523597717,
                0.7105089426040649,
                0.8646432161331177,
                0.7805389165878296,
                0.8343937397003174,
                0.7736688852310181,
                0.8606716394424438,
                0.7690098881721497,
                0.7709543108940125,
                0.775087833404541,
                0.8686826229095459,
                0.8478769063949585,
                0.7464326024055481,
                0.8282300233840942,
                0.8520097732543945,
                0.7405275702476501,
                0.854339599609375,
                0.8522015810012817,
                0.8379958868026733,
                0.8737035393714905,
                0.6982062458992004,
                0.868310809135437,
                0.7894461154937744,
                0.8527066111564636,
                0.731023907661438,
                0.8656474351882935,
                0.82027667760849,
                0.868310809135437,
                0.7034142017364502,
                0.833066463470459,
                0.8492802381515503,
                0.8735941648483276
            ],
            [
                0.8311976790428162,
                0.8030498027801514,
                0.8173397779464722,
                0.8822773694992065,
                0.7705749273300171,
                0.8416489958763123,
                0.7298940420150757,
                0.870775580406189,
                0.8491522669792175,
                0.8075207471847534,
                0.8147628307342529,
                0.8361607789993286,
                0.7646458148956299,
                0.8959943056106567,
                0.7872219085693359,
                0.8232952952384949,
                0.8260641694068909,
                0.8360779285430908,
                0.8347833752632141,
                0.8303962349891663,
                0.7228786945343018,
                0.8367568254470825,
                0.8251433372497559,
                0.7633176445960999,
                0.7629411220550537,
                0.8963903188705444,
                0.8916378021240234,
                0.7005792260169983,
                0.8102796077728271,
                0.8686069250106812,
                0.8106401562690735,
                0.778346598148346,
                0.7881225943565369,
                0.8231841921806335,
                0.786547839641571,
                0.8399902582168579,
                0.7626780867576599,
                0.8063275814056396,
                0.8179479241371155,
                0.6987310647964478,
                0.8240101933479309,
                0.8074357509613037,
                0.80332350730896,
                0.7280334234237671,
                0.8011946678161621,
                0.8161957263946533,
                0.8240101933479309,
                0.7363827228546143,
                0.7748231887817383,
                0.8647288084030151,
                0.8092191219329834
            ],
            [
                0.8122079968452454,
                0.802329421043396,
                0.75672447681427,
                0.8063492774963379,
                0.9044007062911987,
                0.8560197353363037,
                0.8266826272010803,
                0.8150752782821655,
                0.8746558427810669,
                0.877456545829773,
                0.8895076513290405,
                0.7572130560874939,
                0.8304915428161621,
                0.8194810152053833,
                0.6708678603172302,
                0.8912546634674072,
                0.7473720908164978,
                0.7840310335159302,
                0.7896501421928406,
                0.8366273641586304,
                0.7165461182594299,
                0.8799395561218262,
                0.7593021988868713,
                0.8801443576812744,
                0.786841869354248,
                0.8593089580535889,
                0.7250348925590515,
                0.8602117896080017,
                0.8057379722595215,
                0.8664560317993164,
                0.8851933479309082,
                0.7711604833602905,
                0.8102537393569946,
                0.8839832544326782,
                0.752536416053772,
                0.8985791206359863,
                0.8603771924972534,
                0.8352040648460388,
                0.8870460987091064,
                0.750345766544342,
                0.8884581923484802,
                0.8139599561691284,
                0.8367690443992615,
                0.646906852722168,
                0.8982663750648499,
                0.7888936996459961,
                0.8884581923484802,
                0.7034159898757935,
                0.8013869524002075,
                0.8640878200531006,
                0.8926437497138977
            ],
            [
                0.8773120641708374,
                0.7896985411643982,
                0.7907835245132446,
                0.8606554865837097,
                0.82242351770401,
                0.8502072095870972,
                0.7926896810531616,
                0.8821900486946106,
                0.8339644074440002,
                0.8257929086685181,
                0.8435735702514648,
                0.8200674653053284,
                0.7846665382385254,
                0.8825297355651855,
                0.7769968509674072,
                0.8562769293785095,
                0.8693116903305054,
                0.8148195743560791,
                0.8632731437683105,
                0.8403690457344055,
                0.7911392450332642,
                0.8634383082389832,
                0.845788300037384,
                0.8117111921310425,
                0.7750673890113831,
                0.8995141983032227,
                0.8285799622535706,
                0.7634150981903076,
                0.840705156326294,
                0.8585304617881775,
                0.8565393090248108,
                0.8347459435462952,
                0.807847261428833,
                0.855191171169281,
                0.8138368129730225,
                0.8523543477058411,
                0.7881618738174438,
                0.8287270069122314,
                0.8348874449729919,
                0.7748231887817383,
                0.8455901741981506,
                0.8539880514144897,
                0.8044936656951904,
                0.7279713153839111,
                0.8138461709022522,
                0.8083088397979736,
                0.8455901741981506,
                0.7458354830741882,
                0.7803003787994385,
                0.8662493228912354,
                0.8311981558799744
            ],
            [
                0.9024717211723328,
                0.8406506776809692,
                0.8577739000320435,
                0.905074954032898,
                0.8847262263298035,
                0.9344165325164795,
                0.8562149405479431,
                0.873181939125061,
                0.889721691608429,
                0.8865293264389038,
                0.9181966781616211,
                0.8640217185020447,
                0.8394045829772949,
                0.8796432614326477,
                0.803565263748169,
                0.9259088039398193,
                0.817044198513031,
                0.8847484588623047,
                0.8502603769302368,
                0.8990395665168762,
                0.7402490973472595,
                0.9371142387390137,
                0.8206868171691895,
                0.886526882648468,
                0.783550500869751,
                0.9227427244186401,
                0.8222560286521912,
                0.8482393622398376,
                0.8161619901657104,
                0.9146649837493896,
                0.9298995733261108,
                0.8036137223243713,
                0.8552025556564331,
                0.9349890351295471,
                0.7704182863235474,
                0.8887417316436768,
                0.8326648473739624,
                0.7990203499794006,
                0.8886842131614685,
                0.7110607624053955,
                0.917001485824585,
                0.83144211769104,
                0.8577728271484375,
                0.7432914972305298,
                0.8897525668144226,
                0.8758816719055176,
                0.917001485824585,
                0.7439722418785095,
                0.8339083194732666,
                0.9088643789291382,
                0.8967477083206177
            ],
            [
                0.7642810344696045,
                0.8252776265144348,
                0.7799594402313232,
                0.8311111330986023,
                0.8996486067771912,
                0.8565294742584229,
                0.77869713306427,
                0.7779326438903809,
                0.8790465593338013,
                0.8368942737579346,
                0.8620409965515137,
                0.7678079605102539,
                0.8082759976387024,
                0.8171468377113342,
                0.6791471242904663,
                0.8648871779441833,
                0.6892131567001343,
                0.796248733997345,
                0.7270541191101074,
                0.8198872804641724,
                0.6369276642799377,
                0.8560535311698914,
                0.7232972383499146,
                0.8456510305404663,
                0.7260925769805908,
                0.8671814203262329,
                0.7262670993804932,
                0.8649442195892334,
                0.757339596748352,
                0.8472479581832886,
                0.8553096652030945,
                0.7217257618904114,
                0.7702575922012329,
                0.8592754602432251,
                0.7471525073051453,
                0.8941142559051514,
                0.8069367408752441,
                0.7631531357765198,
                0.8596547245979309,
                0.6690798401832581,
                0.8610273003578186,
                0.7570292949676514,
                0.8243849873542786,
                0.6165613532066345,
                0.8576648831367493,
                0.8010479211807251,
                0.8610273003578186,
                0.6869103312492371,
                0.7535122036933899,
                0.8998071551322937,
                0.8736740350723267
            ],
            [
                0.7509918808937073,
                0.7843578457832336,
                0.7361804842948914,
                0.7756549119949341,
                0.7369263172149658,
                0.7457304000854492,
                0.7299350500106812,
                0.8441405892372131,
                0.7904312014579773,
                0.7447299957275391,
                0.7684131264686584,
                0.7474702000617981,
                0.7235155701637268,
                0.8317670822143555,
                0.6698609590530396,
                0.7846217155456543,
                0.8033192753791809,
                0.7307862639427185,
                0.8248980641365051,
                0.724790096282959,
                0.7886430621147156,
                0.7815394997596741,
                0.8173962235450745,
                0.7310316562652588,
                0.7971214056015015,
                0.8093207478523254,
                0.8278350830078125,
                0.6472811102867126,
                0.7776859998703003,
                0.7505171895027161,
                0.759456217288971,
                0.767916738986969,
                0.7415267825126648,
                0.763698935508728,
                0.7580966949462891,
                0.791111946105957,
                0.7320241928100586,
                0.8026243448257446,
                0.776060938835144,
                0.7639283537864685,
                0.7781177759170532,
                0.777460515499115,
                0.7738555073738098,
                0.7205879092216492,
                0.7658939361572266,
                0.7346909046173096,
                0.7781177759170532,
                0.796940803527832,
                0.7808367609977722,
                0.7759301662445068,
                0.756022036075592
            ],
            [
                0.7571361064910889,
                0.7673070430755615,
                0.729958713054657,
                0.7691422700881958,
                0.6912738084793091,
                0.7486952543258667,
                0.7082324624061584,
                0.8638115525245667,
                0.7693426609039307,
                0.7113319635391235,
                0.7420435547828674,
                0.7695920467376709,
                0.6958268880844116,
                0.8477461338043213,
                0.711368203163147,
                0.7646800875663757,
                0.8488028645515442,
                0.7363818287849426,
                0.8468049168586731,
                0.717179536819458,
                0.7757670283317566,
                0.7665324807167053,
                0.8581506013870239,
                0.7066933512687683,
                0.755204975605011,
                0.8080801963806152,
                0.8419069051742554,
                0.63584303855896,
                0.8110536932945251,
                0.7386606931686401,
                0.7461743950843811,
                0.8036301732063293,
                0.717746913433075,
                0.7506244778633118,
                0.7928056716918945,
                0.7627426385879517,
                0.6826297640800476,
                0.7846210598945618,
                0.7370854616165161,
                0.7787411212921143,
                0.7493445873260498,
                0.7947385907173157,
                0.736391544342041,
                0.6837201714515686,
                0.7196676135063171,
                0.7322596311569214,
                0.7493445873260498,
                0.7944626212120056,
                0.7231583595275879,
                0.7619622945785522,
                0.7124326229095459
            ],
            [
                0.7617397308349609,
                0.8187954425811768,
                0.779948353767395,
                0.8412663340568542,
                0.8889238238334656,
                0.8533377647399902,
                0.7773651480674744,
                0.7776376008987427,
                0.8751017451286316,
                0.8339370489120483,
                0.8472899794578552,
                0.7694628238677979,
                0.8103954792022705,
                0.8305238485336304,
                0.688605546951294,
                0.849906861782074,
                0.694814920425415,
                0.7908517718315125,
                0.7253773808479309,
                0.8223556876182556,
                0.6327160596847534,
                0.8444074392318726,
                0.719315767288208,
                0.8369503021240234,
                0.7303608059883118,
                0.8768421411514282,
                0.7276688814163208,
                0.842724621295929,
                0.752749502658844,
                0.8414485454559326,
                0.8437610864639282,
                0.719237208366394,
                0.7642773985862732,
                0.849209189414978,
                0.7337727546691895,
                0.8979677557945251,
                0.8080405592918396,
                0.7620041966438293,
                0.8605167865753174,
                0.6743777394294739,
                0.8509560823440552,
                0.7608038187026978,
                0.8266290426254272,
                0.6216530203819275,
                0.8534229397773743,
                0.7881683111190796,
                0.8509560823440552,
                0.6830049157142639,
                0.7507021427154541,
                0.9030746817588806,
                0.8665096163749695
            ],
            [
                0.7478969097137451,
                0.7561769485473633,
                0.73882657289505,
                0.7690021395683289,
                0.765356183052063,
                0.760760486125946,
                0.7610544562339783,
                0.8128457069396973,
                0.7911238670349121,
                0.791969895362854,
                0.7842994928359985,
                0.7629343867301941,
                0.7749544382095337,
                0.8133368492126465,
                0.6705138683319092,
                0.7920078039169312,
                0.8076693415641785,
                0.7331356406211853,
                0.8145889043807983,
                0.7648441195487976,
                0.7901169061660767,
                0.7851595282554626,
                0.8015566468238831,
                0.7678464651107788,
                0.7902965545654297,
                0.8166358470916748,
                0.7827538251876831,
                0.6845445036888123,
                0.770673394203186,
                0.7806095480918884,
                0.768092691898346,
                0.7750301361083984,
                0.7697100639343262,
                0.7766036987304688,
                0.7614549398422241,
                0.7950748205184937,
                0.7834028005599976,
                0.7949402928352356,
                0.8036308884620667,
                0.7656768560409546,
                0.7937063574790955,
                0.8011770248413086,
                0.8005141019821167,
                0.7019784450531006,
                0.787765383720398,
                0.725318431854248,
                0.7937063574790955,
                0.758823037147522,
                0.7889782190322876,
                0.7853342890739441,
                0.7914727330207825
            ],
            [
                0.8294307589530945,
                0.8142021894454956,
                0.8055151104927063,
                0.8591944575309753,
                0.8113211393356323,
                0.8309000730514526,
                0.7890017628669739,
                0.8668012619018555,
                0.8450491428375244,
                0.8034676313400269,
                0.8289934992790222,
                0.8174450993537903,
                0.7833647727966309,
                0.8802111148834229,
                0.7656229734420776,
                0.8447377681732178,
                0.8429627418518066,
                0.7955282330513,
                0.8503774404525757,
                0.8123851418495178,
                0.7573087215423584,
                0.8462318181991577,
                0.8406734466552734,
                0.8053645491600037,
                0.7862709760665894,
                0.8906484842300415,
                0.8181968331336975,
                0.7431512475013733,
                0.815345287322998,
                0.8171154260635376,
                0.8376699686050415,
                0.8023586273193359,
                0.7902936339378357,
                0.8407968878746033,
                0.7994177937507629,
                0.8579143285751343,
                0.7766187787055969,
                0.8184122443199158,
                0.8393826484680176,
                0.7717665433883667,
                0.8384758234024048,
                0.8323396444320679,
                0.8122174739837646,
                0.703825831413269,
                0.8185821771621704,
                0.7871531844139099,
                0.8384758234024048,
                0.7680525183677673,
                0.7716014385223389,
                0.8736581206321716,
                0.8154786825180054
            ],
            [
                0.7964802980422974,
                0.8095572590827942,
                0.774998664855957,
                0.7885012030601501,
                0.8219922780990601,
                0.796466588973999,
                0.8074438571929932,
                0.8274845480918884,
                0.8198593854904175,
                0.804427444934845,
                0.8253421187400818,
                0.7680574655532837,
                0.7706906795501709,
                0.8212089538574219,
                0.6715292930603027,
                0.8360742330551147,
                0.8030820488929749,
                0.7392094731330872,
                0.8147298693656921,
                0.7740449905395508,
                0.7832736372947693,
                0.826013445854187,
                0.7977727651596069,
                0.8113313913345337,
                0.7877387404441833,
                0.8383357524871826,
                0.7915322184562683,
                0.7411367297172546,
                0.794639527797699,
                0.7969779968261719,
                0.8155311346054077,
                0.7959303855895996,
                0.8010184168815613,
                0.8207769989967346,
                0.778105616569519,
                0.8229814767837524,
                0.7842826843261719,
                0.7934131622314453,
                0.819656491279602,
                0.7563943862915039,
                0.8269873261451721,
                0.801525354385376,
                0.7973278760910034,
                0.7088540196418762,
                0.8054779767990112,
                0.7331568002700806,
                0.8269873261451721,
                0.7465931177139282,
                0.7928388118743896,
                0.8118342161178589,
                0.8213138580322266
            ],
            [
                0.8556532859802246,
                0.8235170245170593,
                0.8358328938484192,
                0.8712162971496582,
                0.8350955843925476,
                0.8478292226791382,
                0.8011148571968079,
                0.8885529041290283,
                0.8663835525512695,
                0.8300952315330505,
                0.8553561568260193,
                0.8293653130531311,
                0.798882782459259,
                0.8958250880241394,
                0.7841882705688477,
                0.8636996150016785,
                0.846648097038269,
                0.8145991563796997,
                0.8583188056945801,
                0.8357039093971252,
                0.7756266593933105,
                0.8664532899856567,
                0.8618179559707642,
                0.8264327645301819,
                0.799676775932312,
                0.9142966866493225,
                0.837628185749054,
                0.7735944986343384,
                0.8392252922058105,
                0.8478838205337524,
                0.8514404892921448,
                0.8313658833503723,
                0.8226844668388367,
                0.8589363694190979,
                0.82416832447052,
                0.8814980983734131,
                0.7974088191986084,
                0.8395232558250427,
                0.8550227880477905,
                0.7679147124290466,
                0.8608910441398621,
                0.8590714335441589,
                0.8257479667663574,
                0.7148090600967407,
                0.8305013179779053,
                0.8064559102058411,
                0.8608910441398621,
                0.7750723958015442,
                0.790044903755188,
                0.8971335887908936,
                0.8373083472251892
            ],
            [
                0.7564772963523865,
                0.7793938517570496,
                0.7435606718063354,
                0.7655614614486694,
                0.7785460352897644,
                0.7676063179969788,
                0.7736177444458008,
                0.8086560368537903,
                0.804088294506073,
                0.7827790975570679,
                0.786199688911438,
                0.7500180006027222,
                0.7605863809585571,
                0.8036101460456848,
                0.6563612818717957,
                0.7994558811187744,
                0.7951043844223022,
                0.718055248260498,
                0.8141078352928162,
                0.7475874423980713,
                0.7673654556274414,
                0.790295422077179,
                0.7874673008918762,
                0.770184338092804,
                0.785401463508606,
                0.8045175671577454,
                0.7868077158927917,
                0.6932044625282288,
                0.7671224474906921,
                0.7658543586730957,
                0.7758389115333557,
                0.7614027857780457,
                0.7680165767669678,
                0.780791699886322,
                0.757173478603363,
                0.7854565978050232,
                0.7665427327156067,
                0.7694780230522156,
                0.7950659990310669,
                0.7465739846229553,
                0.7899783849716187,
                0.7710132598876953,
                0.7826873064041138,
                0.6900029182434082,
                0.7813361287117004,
                0.7162860631942749,
                0.7899783849716187,
                0.7446432709693909,
                0.7878661155700684,
                0.7718173861503601,
                0.7831388711929321
            ],
            [
                0.8168846368789673,
                0.8367354273796082,
                0.7951073050498962,
                0.842726469039917,
                0.7980086207389832,
                0.8248186111450195,
                0.7762507200241089,
                0.8761377930641174,
                0.8629902601242065,
                0.8043699860572815,
                0.8130108714103699,
                0.8071768879890442,
                0.7922544479370117,
                0.8879944086074829,
                0.7543462514877319,
                0.8290701508522034,
                0.8438276052474976,
                0.790390133857727,
                0.8616657853126526,
                0.8009098172187805,
                0.7457005977630615,
                0.831174373626709,
                0.8434243202209473,
                0.7901268601417542,
                0.7914001941680908,
                0.8694884181022644,
                0.857324481010437,
                0.7372410893440247,
                0.8399420380592346,
                0.8098693490028381,
                0.8182438611984253,
                0.8093395233154297,
                0.7964119911193848,
                0.8237484097480774,
                0.8045933842658997,
                0.8398635387420654,
                0.7666999101638794,
                0.8013609051704407,
                0.8210079669952393,
                0.760046124458313,
                0.8157444596290588,
                0.8143694996833801,
                0.7986289262771606,
                0.7019125819206238,
                0.8072059154510498,
                0.786344051361084,
                0.8157444596290588,
                0.7781152129173279,
                0.793498158454895,
                0.8362313508987427,
                0.7996248006820679
            ],
            [
                0.8421509861946106,
                0.8689355850219727,
                0.7981764078140259,
                0.8405091166496277,
                0.8968678116798401,
                0.8899001479148865,
                0.8586243391036987,
                0.8622221946716309,
                0.9063456058502197,
                0.8784082531929016,
                0.9014236927032471,
                0.7930154800415039,
                0.8329246640205383,
                0.8846352696418762,
                0.6984423995018005,
                0.9217032194137573,
                0.8062394261360168,
                0.8040887117385864,
                0.8531007766723633,
                0.8521159291267395,
                0.718666672706604,
                0.9074333906173706,
                0.8034055829048157,
                0.882607102394104,
                0.8119626045227051,
                0.8778083920478821,
                0.7983323335647583,
                0.8319770693778992,
                0.8258582353591919,
                0.862432599067688,
                0.906845211982727,
                0.7866675853729248,
                0.8180609345436096,
                0.9060953855514526,
                0.7716085314750671,
                0.8912530541419983,
                0.840614914894104,
                0.8170472979545593,
                0.9006030559539795,
                0.7562016844749451,
                0.9044674038887024,
                0.8183715343475342,
                0.8376402854919434,
                0.6821284294128418,
                0.9060491323471069,
                0.7876867055892944,
                0.9044674038887024,
                0.7453790307044983,
                0.8267173171043396,
                0.8670406937599182,
                0.8899688720703125
            ],
            [
                0.7908755540847778,
                0.8321212530136108,
                0.7802767157554626,
                0.8290624022483826,
                0.823333740234375,
                0.8086223006248474,
                0.8104930520057678,
                0.8874460458755493,
                0.8721928000450134,
                0.8220693469047546,
                0.8227485418319702,
                0.7819873690605164,
                0.787975549697876,
                0.8883692026138306,
                0.6996537446975708,
                0.8430962562561035,
                0.8473625779151917,
                0.7766197919845581,
                0.882483720779419,
                0.7997099757194519,
                0.7838447093963623,
                0.8361675143241882,
                0.8479092717170715,
                0.8106421828269958,
                0.8309388756752014,
                0.8612905740737915,
                0.8395859599113464,
                0.722710907459259,
                0.8252150416374207,
                0.814213216304779,
                0.8198728561401367,
                0.8196949362754822,
                0.7918224334716797,
                0.8234646916389465,
                0.7877633571624756,
                0.8585910201072693,
                0.7938314080238342,
                0.8591555953025818,
                0.8396863341331482,
                0.785477340221405,
                0.827617347240448,
                0.8388178944587708,
                0.8013865947723389,
                0.7081938982009888,
                0.8367564082145691,
                0.7672728896141052,
                0.827617347240448,
                0.7936710119247437,
                0.8099268078804016,
                0.8326249122619629,
                0.8186590075492859
            ],
            [
                0.7733287215232849,
                0.8232450485229492,
                0.7606200575828552,
                0.7961665987968445,
                0.8394543528556824,
                0.8265795707702637,
                0.828545093536377,
                0.8581709861755371,
                0.8869683146476746,
                0.8304309844970703,
                0.8402295708656311,
                0.7637331485748291,
                0.7807698845863342,
                0.8591759204864502,
                0.6664813756942749,
                0.8583146333694458,
                0.8315820097923279,
                0.7608137726783752,
                0.8712478280067444,
                0.7866793274879456,
                0.7609588503837585,
                0.8461141586303711,
                0.8378958702087402,
                0.8403291702270508,
                0.8598852157592773,
                0.8360773921012878,
                0.7984929084777832,
                0.7584477663040161,
                0.8275290727615356,
                0.8047341108322144,
                0.8348293304443359,
                0.8012476563453674,
                0.7848740816116333,
                0.8366621732711792,
                0.7596513628959656,
                0.8643086552619934,
                0.7879400849342346,
                0.834514856338501,
                0.8213238716125488,
                0.7499114871025085,
                0.8360481858253479,
                0.8160123229026794,
                0.7766116857528687,
                0.6716095209121704,
                0.8444064855575562,
                0.7338148355484009,
                0.8360481858253479,
                0.7639873027801514,
                0.8100839853286743,
                0.8303746581077576,
                0.8290787935256958
            ],
            [
                0.8420889377593994,
                0.8417772054672241,
                0.8074073791503906,
                0.8630021810531616,
                0.8637802004814148,
                0.8569050431251526,
                0.806615948677063,
                0.9301773309707642,
                0.9167250990867615,
                0.8473854064941406,
                0.8555989265441895,
                0.8272463083267212,
                0.8079448938369751,
                0.9406633377075195,
                0.7479181885719299,
                0.8760582804679871,
                0.8860305547714233,
                0.8120482563972473,
                0.8929098844528198,
                0.8398549556732178,
                0.7925431132316589,
                0.8731244802474976,
                0.8736356496810913,
                0.8340467810630798,
                0.8524675369262695,
                0.9253594875335693,
                0.8541619777679443,
                0.7815229892730713,
                0.8749051094055176,
                0.8521298170089722,
                0.8632853627204895,
                0.859940767288208,
                0.8034241199493408,
                0.8626399636268616,
                0.8368052840232849,
                0.9181845188140869,
                0.8127896785736084,
                0.8708466291427612,
                0.8665732145309448,
                0.7715471982955933,
                0.8597606420516968,
                0.8860381245613098,
                0.8284299373626709,
                0.7083947658538818,
                0.8539212346076965,
                0.7912610769271851,
                0.8597606420516968,
                0.8041085004806519,
                0.799487829208374,
                0.9053346514701843,
                0.8511672019958496
            ],
            [
                0.7840867042541504,
                0.8113901615142822,
                0.7632772922515869,
                0.8081395626068115,
                0.8748586177825928,
                0.849321186542511,
                0.807869017124176,
                0.7972761988639832,
                0.8506500720977783,
                0.8674694299697876,
                0.8633179664611816,
                0.7441590428352356,
                0.8108002543449402,
                0.8258913159370422,
                0.6778552532196045,
                0.8664563894271851,
                0.7335260510444641,
                0.775288462638855,
                0.7788821458816528,
                0.8240242004394531,
                0.6697967648506165,
                0.8572668433189392,
                0.7488588094711304,
                0.8557921051979065,
                0.7697690725326538,
                0.843687891960144,
                0.7527320981025696,
                0.8182878494262695,
                0.7848015427589417,
                0.8658023476600647,
                0.8634721636772156,
                0.7410475611686707,
                0.7902530431747437,
                0.8638277053833008,
                0.7309552431106567,
                0.8865759372711182,
                0.8597993850708008,
                0.8456549048423767,
                0.9010255336761475,
                0.7191545367240906,
                0.870265007019043,
                0.7931578159332275,
                0.840015172958374,
                0.6683306694030762,
                0.8987074494361877,
                0.7881176471710205,
                0.870265007019043,
                0.714030385017395,
                0.8126273155212402,
                0.8484675288200378,
                0.9010236859321594
            ],
            [
                0.7589020729064941,
                0.7987716197967529,
                0.7506835460662842,
                0.7864678502082825,
                0.8829472064971924,
                0.8465059995651245,
                0.8326687812805176,
                0.8243640065193176,
                0.8734798431396484,
                0.8692265152931213,
                0.8671023845672607,
                0.7490348219871521,
                0.8232858180999756,
                0.8291648626327515,
                0.6663299798965454,
                0.871532142162323,
                0.7716279029846191,
                0.7665297389030457,
                0.8199178576469421,
                0.8134688138961792,
                0.7274115681648254,
                0.8563873171806335,
                0.7903040647506714,
                0.8786014914512634,
                0.8266507387161255,
                0.8374152183532715,
                0.7518824934959412,
                0.840156614780426,
                0.822469174861908,
                0.8548800945281982,
                0.8657737970352173,
                0.7967619299888611,
                0.8076322078704834,
                0.8655674457550049,
                0.7624423503875732,
                0.8975395560264587,
                0.8593143224716187,
                0.8652237057685852,
                0.8760144710540771,
                0.7264137268066406,
                0.8675671219825745,
                0.8417565822601318,
                0.8185714483261108,
                0.6627561450004578,
                0.8940854072570801,
                0.7660554647445679,
                0.8675671219825745,
                0.743025541305542,
                0.8296974897384644,
                0.8444443941116333,
                0.8942595720291138
            ],
            [
                0.8218867182731628,
                0.875093936920166,
                0.8105101585388184,
                0.8630408048629761,
                0.8739796876907349,
                0.8605438470840454,
                0.8017306923866272,
                0.9109241962432861,
                0.922408401966095,
                0.835672914981842,
                0.8593720197677612,
                0.8272266983985901,
                0.8115395307540894,
                0.922147810459137,
                0.7330038547515869,
                0.8726931214332581,
                0.834721565246582,
                0.8036571145057678,
                0.857368528842926,
                0.8194761276245117,
                0.800010085105896,
                0.8684290051460266,
                0.844142735004425,
                0.8347133994102478,
                0.8474726676940918,
                0.9226682782173157,
                0.8458317518234253,
                0.7993760108947754,
                0.8674590587615967,
                0.8511506915092468,
                0.8638937473297119,
                0.844482421875,
                0.8052610158920288,
                0.8679780960083008,
                0.8236729502677917,
                0.9332418441772461,
                0.8038666844367981,
                0.8578917384147644,
                0.856948971748352,
                0.7489340901374817,
                0.8605265617370605,
                0.8732250332832336,
                0.813378632068634,
                0.6910365223884583,
                0.8563321232795715,
                0.7948933839797974,
                0.8605265617370605,
                0.8071492910385132,
                0.803141713142395,
                0.9073712825775146,
                0.8450682759284973
            ],
            [
                0.7941606044769287,
                0.8178304433822632,
                0.76139235496521,
                0.8105173110961914,
                0.8445239067077637,
                0.8603602647781372,
                0.8287733793258667,
                0.8189360499382019,
                0.8534591197967529,
                0.8616195321083069,
                0.8610615134239197,
                0.7738807201385498,
                0.8035709261894226,
                0.8345158696174622,
                0.6761565208435059,
                0.8667780160903931,
                0.7630759477615356,
                0.7889249324798584,
                0.8131470680236816,
                0.8213635087013245,
                0.7015003561973572,
                0.8609975576400757,
                0.784744381904602,
                0.8560695648193359,
                0.7916799187660217,
                0.8495514392852783,
                0.791650116443634,
                0.8085218667984009,
                0.8175880908966064,
                0.8705164194107056,
                0.8700698018074036,
                0.7607752680778503,
                0.7884050607681274,
                0.8755776286125183,
                0.7221888303756714,
                0.8652239441871643,
                0.8287100791931152,
                0.836452066898346,
                0.8760076761245728,
                0.730638325214386,
                0.8608591556549072,
                0.8021180629730225,
                0.8165889978408813,
                0.6711059212684631,
                0.8791401982307434,
                0.7912161350250244,
                0.8608591556549072,
                0.7383115291595459,
                0.8151715993881226,
                0.8295280933380127,
                0.8774634003639221
            ],
            [
                0.7432344555854797,
                0.8201627135276794,
                0.7304294109344482,
                0.7748111486434937,
                0.809924840927124,
                0.8057078123092651,
                0.7871695160865784,
                0.8146812915802002,
                0.8393139243125916,
                0.8149900436401367,
                0.8171716332435608,
                0.736212968826294,
                0.7563378810882568,
                0.825657308101654,
                0.6330556869506836,
                0.826674222946167,
                0.7484596371650696,
                0.7309852838516235,
                0.801102876663208,
                0.7609655857086182,
                0.7047916650772095,
                0.8145922422409058,
                0.7744067907333374,
                0.8090807199478149,
                0.8135485053062439,
                0.8186609745025635,
                0.7999926805496216,
                0.7386845350265503,
                0.8217820525169373,
                0.813427746295929,
                0.8164317607879639,
                0.7578080296516418,
                0.7638261914253235,
                0.8251383304595947,
                0.7161696553230286,
                0.8445267677307129,
                0.7822132110595703,
                0.8206960558891296,
                0.8222259283065796,
                0.7089194059371948,
                0.8197023272514343,
                0.7930838465690613,
                0.7677759528160095,
                0.668958306312561,
                0.8399472832679749,
                0.7230219841003418,
                0.8197023272514343,
                0.745186448097229,
                0.8092002272605896,
                0.7971768379211426,
                0.8291736841201782
            ],
            [
                0.8349547982215881,
                0.8732264637947083,
                0.8183939456939697,
                0.8672090172767639,
                0.8916531205177307,
                0.8659337162971497,
                0.8167073130607605,
                0.9051671624183655,
                0.9137756824493408,
                0.8436804413795471,
                0.8699018955230713,
                0.8273596167564392,
                0.8098192811012268,
                0.9166020154953003,
                0.7442389726638794,
                0.8809084892272949,
                0.8397813439369202,
                0.8074101805686951,
                0.846622109413147,
                0.8293190002441406,
                0.7939566373825073,
                0.8763837814331055,
                0.8439211845397949,
                0.8504917025566101,
                0.8251413702964783,
                0.9320934414863586,
                0.8459854125976562,
                0.8210196495056152,
                0.8808618783950806,
                0.8663705587387085,
                0.8750136494636536,
                0.8552878499031067,
                0.808645486831665,
                0.8793913125991821,
                0.8342496156692505,
                0.9392173290252686,
                0.8102884292602539,
                0.862695038318634,
                0.8701812028884888,
                0.7638427019119263,
                0.8701515197753906,
                0.8791166543960571,
                0.8219979405403137,
                0.6885194182395935,
                0.8612844944000244,
                0.8040106296539307,
                0.8701515197753906,
                0.7953120470046997,
                0.7950605154037476,
                0.920211911201477,
                0.8610471487045288
            ],
            [
                0.7927500605583191,
                0.7825219035148621,
                0.7578227519989014,
                0.781230628490448,
                0.7993005514144897,
                0.7811327576637268,
                0.8092718124389648,
                0.8393806219100952,
                0.7966294288635254,
                0.7900868058204651,
                0.8110372424125671,
                0.7818455696105957,
                0.7620276808738708,
                0.8194012641906738,
                0.6795991063117981,
                0.8217886090278625,
                0.8347383737564087,
                0.7441737055778503,
                0.8387352228164673,
                0.7719019055366516,
                0.8250593543052673,
                0.809927225112915,
                0.8285967111587524,
                0.8028643131256104,
                0.7881097197532654,
                0.8417437672615051,
                0.7868971228599548,
                0.7234579920768738,
                0.8066266179084778,
                0.7970368266105652,
                0.7998025417327881,
                0.8241041898727417,
                0.7893897891044617,
                0.8046266436576843,
                0.7877229452133179,
                0.8098157644271851,
                0.7670696973800659,
                0.8110859394073486,
                0.8001644611358643,
                0.7808612585067749,
                0.8109601140022278,
                0.8311538696289062,
                0.7764091491699219,
                0.6925970315933228,
                0.7774896025657654,
                0.7424615621566772,
                0.8109601140022278,
                0.7580868601799011,
                0.7687456011772156,
                0.8018505573272705,
                0.79949951171875
            ],
            [
                0.8067999482154846,
                0.8416209816932678,
                0.819665789604187,
                0.8652397990226746,
                0.8081021308898926,
                0.8277720212936401,
                0.7857691645622253,
                0.8916935324668884,
                0.8567478656768799,
                0.8035486340522766,
                0.822407603263855,
                0.8160598874092102,
                0.7755951881408691,
                0.9064582586288452,
                0.7567897439002991,
                0.8385525345802307,
                0.8476842045783997,
                0.7972765564918518,
                0.8641269207000732,
                0.8057642579078674,
                0.7669696807861328,
                0.8403429985046387,
                0.8595316410064697,
                0.7951114177703857,
                0.7879724502563477,
                0.8934722542762756,
                0.8681771159172058,
                0.7322263717651367,
                0.8359318971633911,
                0.8238877654075623,
                0.8245126008987427,
                0.8229897022247314,
                0.7940893173217773,
                0.8313345909118652,
                0.815995454788208,
                0.8617627024650574,
                0.7765293121337891,
                0.826703667640686,
                0.8345651626586914,
                0.7861436009407043,
                0.8306366801261902,
                0.8296953439712524,
                0.815092146396637,
                0.7203678488731384,
                0.8094555139541626,
                0.7962002754211426,
                0.8306366801261902,
                0.7847261428833008,
                0.7833784222602844,
                0.8620105385780334,
                0.8071028590202332
            ],
            [
                0.7616130113601685,
                0.7829539775848389,
                0.7572745084762573,
                0.7716818451881409,
                0.79169100522995,
                0.7670749425888062,
                0.7970774173736572,
                0.8046349883079529,
                0.7939435243606567,
                0.7799497246742249,
                0.7895703315734863,
                0.770258367061615,
                0.7625672817230225,
                0.8013758659362793,
                0.6612934470176697,
                0.8066444396972656,
                0.7921825647354126,
                0.7244799137115479,
                0.8042908906936646,
                0.7530491948127747,
                0.7845855355262756,
                0.7998815774917603,
                0.7838199138641357,
                0.7898060083389282,
                0.7804788947105408,
                0.816723108291626,
                0.7716615200042725,
                0.7033909559249878,
                0.7645169496536255,
                0.7715123891830444,
                0.7848031520843506,
                0.7771291732788086,
                0.7750416994094849,
                0.7886558175086975,
                0.7721879482269287,
                0.7986704707145691,
                0.774900496006012,
                0.7867841720581055,
                0.8040140867233276,
                0.7486681938171387,
                0.7959690690040588,
                0.7842510342597961,
                0.792148232460022,
                0.7087957262992859,
                0.7858130931854248,
                0.7199636697769165,
                0.7959690690040588,
                0.7385731339454651,
                0.7845906615257263,
                0.7840073704719543,
                0.7910245060920715
            ],
            [
                0.841704785823822,
                0.8041428923606873,
                0.8069445490837097,
                0.8702322244644165,
                0.793692409992218,
                0.8291587233543396,
                0.7769936919212341,
                0.9051129817962646,
                0.8372662663459778,
                0.7959128022193909,
                0.8140444755554199,
                0.8229424953460693,
                0.7620790600776672,
                0.8992418646812439,
                0.7749056816101074,
                0.8314129710197449,
                0.8725389838218689,
                0.8085832595825195,
                0.8791211843490601,
                0.810509443283081,
                0.805246114730835,
                0.8403269052505493,
                0.8672704100608826,
                0.7856563329696655,
                0.7800569534301758,
                0.9044323563575745,
                0.8525423407554626,
                0.7150813937187195,
                0.8344122767448425,
                0.8288452625274658,
                0.8266982436180115,
                0.8368022441864014,
                0.7970123887062073,
                0.828704297542572,
                0.8039172291755676,
                0.8587340116500854,
                0.7640283703804016,
                0.8355013132095337,
                0.8190303444862366,
                0.7893935441970825,
                0.8212571144104004,
                0.8470884561538696,
                0.8056766390800476,
                0.7417907118797302,
                0.7935278415679932,
                0.8022269010543823,
                0.8212571144104004,
                0.7847616076469421,
                0.7752983570098877,
                0.8658415079116821,
                0.8007039427757263
            ],
            [
                0.8992872834205627,
                0.8260713815689087,
                0.8620397448539734,
                0.9179834723472595,
                0.8812019228935242,
                0.9313633441925049,
                0.8289168477058411,
                0.8547977209091187,
                0.8774579167366028,
                0.8855105042457581,
                0.9158878326416016,
                0.8440341949462891,
                0.8329668641090393,
                0.8688946962356567,
                0.8049753308296204,
                0.9219022989273071,
                0.7854711413383484,
                0.8918524384498596,
                0.8216260075569153,
                0.9054122567176819,
                0.6998980641365051,
                0.9344677925109863,
                0.790565550327301,
                0.8736469149589539,
                0.7575276494026184,
                0.9264814853668213,
                0.8021426200866699,
                0.8390535116195679,
                0.7908607125282288,
                0.9200061559677124,
                0.9295806288719177,
                0.7712032198905945,
                0.856297492980957,
                0.9328389167785645,
                0.738113522529602,
                0.8910096287727356,
                0.8338783979415894,
                0.794008195400238,
                0.8937146067619324,
                0.6746145486831665,
                0.9182716012001038,
                0.8108638525009155,
                0.8592846393585205,
                0.7601333856582642,
                0.8889744877815247,
                0.8835082650184631,
                0.9182716012001038,
                0.7092755436897278,
                0.8303806781768799,
                0.9219531416893005,
                0.8997151255607605
            ],
            [
                0.7749188542366028,
                0.8365497589111328,
                0.7905333042144775,
                0.8561816811561584,
                0.8885725736618042,
                0.8658265471458435,
                0.7918696403503418,
                0.7975004315376282,
                0.8859162330627441,
                0.8394767045974731,
                0.8496526479721069,
                0.7851270437240601,
                0.8143783211708069,
                0.8403869271278381,
                0.6927093267440796,
                0.8544554114341736,
                0.7131699323654175,
                0.7975306510925293,
                0.7435181140899658,
                0.8261925578117371,
                0.6466552019119263,
                0.8510838747024536,
                0.7342207431793213,
                0.8413221836090088,
                0.7405194044113159,
                0.8876388072967529,
                0.7600005865097046,
                0.8363129496574402,
                0.78752201795578,
                0.8543056845664978,
                0.8518095016479492,
                0.7429966926574707,
                0.7780723571777344,
                0.8605394959449768,
                0.7452071309089661,
                0.8941264748573303,
                0.8081270456314087,
                0.7610455751419067,
                0.8590570092201233,
                0.6827777624130249,
                0.8488761782646179,
                0.7622480988502502,
                0.8231077194213867,
                0.6321192383766174,
                0.8471279740333557,
                0.7933602929115295,
                0.8488761782646179,
                0.6937304735183716,
                0.7664535045623779,
                0.8972747325897217,
                0.8670830726623535
            ],
            [
                0.7823473215103149,
                0.7689039707183838,
                0.7172081470489502,
                0.770292341709137,
                0.7564904689788818,
                0.7662614583969116,
                0.7732409238815308,
                0.8078204393386841,
                0.7804792523384094,
                0.778714656829834,
                0.781313419342041,
                0.7536488771438599,
                0.7813848853111267,
                0.797850489616394,
                0.7015144228935242,
                0.7908138036727905,
                0.793522834777832,
                0.7254064679145813,
                0.8069446086883545,
                0.750282347202301,
                0.7817815542221069,
                0.7744427919387817,
                0.7883480191230774,
                0.7672120332717896,
                0.7791516184806824,
                0.8178823590278625,
                0.7850621938705444,
                0.705215573310852,
                0.7941698431968689,
                0.7836678624153137,
                0.7687801718711853,
                0.7863206267356873,
                0.7575026750564575,
                0.7742328643798828,
                0.7726836204528809,
                0.7919779419898987,
                0.7591801881790161,
                0.7965136766433716,
                0.787247359752655,
                0.7583198547363281,
                0.7837517261505127,
                0.8067174553871155,
                0.7660656571388245,
                0.6643665432929993,
                0.7634242177009583,
                0.7374153733253479,
                0.7837517261505127,
                0.7531487941741943,
                0.7622181177139282,
                0.7663335204124451,
                0.7858196496963501
            ],
            [
                0.7820635437965393,
                0.7577943801879883,
                0.7429445385932922,
                0.7981213927268982,
                0.7378560900688171,
                0.7727970480918884,
                0.7695631980895996,
                0.8815743923187256,
                0.784652590751648,
                0.7685964703559875,
                0.7730277180671692,
                0.784657895565033,
                0.7404385209083557,
                0.8628103137016296,
                0.7258003950119019,
                0.787556529045105,
                0.9065868854522705,
                0.7534612417221069,
                0.8794411420822144,
                0.7668411135673523,
                0.8135197162628174,
                0.7912663221359253,
                0.885716438293457,
                0.7659744024276733,
                0.7809804677963257,
                0.8479238748550415,
                0.8326612710952759,
                0.6820824146270752,
                0.857917308807373,
                0.7878548502922058,
                0.7800444960594177,
                0.8652054071426392,
                0.7644577622413635,
                0.7844494581222534,
                0.8218833208084106,
                0.7994414567947388,
                0.7362480163574219,
                0.8211339116096497,
                0.7679335474967957,
                0.7766736745834351,
                0.7733709216117859,
                0.8604030609130859,
                0.7580947875976562,
                0.7101371884346008,
                0.7467966675758362,
                0.7473626136779785,
                0.7733709216117859,
                0.7655692100524902,
                0.7531276345252991,
                0.7978919148445129,
                0.7639941573143005
            ],
            [
                0.7533130645751953,
                0.7913365364074707,
                0.7317216992378235,
                0.7772507071495056,
                0.7727996706962585,
                0.7689894437789917,
                0.7500739097595215,
                0.796737790107727,
                0.7950201034545898,
                0.7809533476829529,
                0.7757551670074463,
                0.7263563275337219,
                0.7302299737930298,
                0.8043244481086731,
                0.6421786546707153,
                0.7847692966461182,
                0.7502027750015259,
                0.7086064219474792,
                0.7866971492767334,
                0.7389035224914551,
                0.721234917640686,
                0.775524377822876,
                0.760920524597168,
                0.756855845451355,
                0.7565461993217468,
                0.8071755766868591,
                0.7871428728103638,
                0.6930574178695679,
                0.7935669422149658,
                0.785366952419281,
                0.7710089087486267,
                0.748953104019165,
                0.7533648014068604,
                0.7802362442016602,
                0.7333372235298157,
                0.8005537390708923,
                0.757117748260498,
                0.7897336483001709,
                0.7916539311408997,
                0.7403040528297424,
                0.7816632986068726,
                0.7714328169822693,
                0.7623463869094849,
                0.6716668605804443,
                0.7827674150466919,
                0.7171260118484497,
                0.7816632986068726,
                0.7314187288284302,
                0.7628436088562012,
                0.7712737321853638,
                0.784442663192749
            ],
            [
                0.8233353495597839,
                0.7825263142585754,
                0.8037075400352478,
                0.8416978716850281,
                0.7683926820755005,
                0.8252004384994507,
                0.7906070351600647,
                0.8726134300231934,
                0.8145525455474854,
                0.8023220896720886,
                0.8159287571907043,
                0.8561631441116333,
                0.771896481513977,
                0.8588234186172485,
                0.768037736415863,
                0.8254426717758179,
                0.8713255524635315,
                0.8227500319480896,
                0.8643065690994263,
                0.8259118795394897,
                0.7616177201271057,
                0.8363975286483765,
                0.8640270829200745,
                0.8051843643188477,
                0.7831346392631531,
                0.8861214518547058,
                0.8172492384910583,
                0.7209394574165344,
                0.807063639163971,
                0.8418282270431519,
                0.8185960054397583,
                0.8141428828239441,
                0.7916594743728638,
                0.8283371925354004,
                0.7899055480957031,
                0.8180475234985352,
                0.76349276304245,
                0.8041269779205322,
                0.8045346140861511,
                0.7215198278427124,
                0.8169719576835632,
                0.8509393930435181,
                0.8033818006515503,
                0.707206130027771,
                0.7842860221862793,
                0.8094980716705322,
                0.8169719576835632,
                0.7357679009437561,
                0.7601461410522461,
                0.8438942432403564,
                0.7898927927017212
            ],
            [
                0.7783661484718323,
                0.7947885990142822,
                0.7564600706100464,
                0.7918711304664612,
                0.800382137298584,
                0.7738954424858093,
                0.7736334204673767,
                0.8280240893363953,
                0.809231698513031,
                0.7918345928192139,
                0.7997947931289673,
                0.7427904605865479,
                0.7604220509529114,
                0.8213605284690857,
                0.6627435684204102,
                0.8151092529296875,
                0.8021835684776306,
                0.7317015528678894,
                0.820237934589386,
                0.7635641098022461,
                0.7807181477546692,
                0.7989732027053833,
                0.7908713817596436,
                0.7793594002723694,
                0.7955999970436096,
                0.8389430642127991,
                0.7791330218315125,
                0.6968328952789307,
                0.770746648311615,
                0.7766246199607849,
                0.7855611443519592,
                0.7590005993843079,
                0.7761684060096741,
                0.7869681119918823,
                0.7629361152648926,
                0.8277098536491394,
                0.7770963907241821,
                0.8075015544891357,
                0.8187649846076965,
                0.7679785490036011,
                0.8061131238937378,
                0.7921667695045471,
                0.7964425683021545,
                0.709450364112854,
                0.7955243587493896,
                0.7277075052261353,
                0.8061131238937378,
                0.7463896870613098,
                0.7756888270378113,
                0.8108556270599365,
                0.8049356937408447
            ],
            [
                0.7621922492980957,
                0.8095906972885132,
                0.7157397866249084,
                0.7628427743911743,
                0.7974463105201721,
                0.7583754658699036,
                0.7582060694694519,
                0.7989933490753174,
                0.803036093711853,
                0.7609454393386841,
                0.7706850171089172,
                0.7098360061645508,
                0.7211343050003052,
                0.8087401986122131,
                0.6203640103340149,
                0.7880235910415649,
                0.7575669884681702,
                0.6877957582473755,
                0.7871627807617188,
                0.7149297595024109,
                0.7381333112716675,
                0.7730569243431091,
                0.7468215227127075,
                0.7601679563522339,
                0.755717396736145,
                0.8012496829032898,
                0.7606097459793091,
                0.7054762840270996,
                0.7799471616744995,
                0.7570377588272095,
                0.7748759388923645,
                0.7398497462272644,
                0.7414148449897766,
                0.7739819288253784,
                0.7317712903022766,
                0.827265202999115,
                0.7492464184761047,
                0.8004328608512878,
                0.8058903813362122,
                0.7790676355361938,
                0.7796327471733093,
                0.7688425779342651,
                0.7584037780761719,
                0.6609735488891602,
                0.7959970235824585,
                0.6994108557701111,
                0.7796327471733093,
                0.746408224105835,
                0.7494827508926392,
                0.7835386395454407,
                0.7871801853179932
            ],
            [
                0.7142243385314941,
                0.7372481822967529,
                0.703913688659668,
                0.7753143906593323,
                0.6835267543792725,
                0.7357476949691772,
                0.7185131907463074,
                0.8354809284210205,
                0.7493654489517212,
                0.7121519446372986,
                0.7182478904724121,
                0.7554076313972473,
                0.700762927532196,
                0.815834105014801,
                0.6887167096138,
                0.7429394721984863,
                0.8266134858131409,
                0.7370280623435974,
                0.8259338140487671,
                0.7151290774345398,
                0.7301877737045288,
                0.7428507804870605,
                0.8329952359199524,
                0.7134758830070496,
                0.7433315515518188,
                0.7842101454734802,
                0.8210206031799316,
                0.6231511235237122,
                0.7810509204864502,
                0.7398207783699036,
                0.7256807088851929,
                0.7768464684486389,
                0.71051424741745,
                0.7309120297431946,
                0.7775862812995911,
                0.7445085048675537,
                0.7035548686981201,
                0.7872768640518188,
                0.7457541227340698,
                0.7609854936599731,
                0.7309314608573914,
                0.7727903127670288,
                0.7440979480743408,
                0.6667944192886353,
                0.7281938195228577,
                0.7313179969787598,
                0.7309314608573914,
                0.7706883549690247,
                0.7249873876571655,
                0.7449148297309875,
                0.7144407629966736
            ],
            [
                0.8056464791297913,
                0.8025221228599548,
                0.7849329113960266,
                0.827725350856781,
                0.7848661541938782,
                0.8231732845306396,
                0.7946817874908447,
                0.9102796912193298,
                0.8398023843765259,
                0.7924888134002686,
                0.8097575306892395,
                0.8400388360023499,
                0.770758330821991,
                0.8855814933776855,
                0.7417047023773193,
                0.8272427320480347,
                0.9060865640640259,
                0.8030440807342529,
                0.8853648900985718,
                0.8072299957275391,
                0.8015667200088501,
                0.8309842348098755,
                0.8853177428245544,
                0.8087590932846069,
                0.8259671926498413,
                0.8943054676055908,
                0.8207655549049377,
                0.7202052474021912,
                0.8468670845031738,
                0.8226762413978577,
                0.8155999183654785,
                0.8497574925422668,
                0.7823019027709961,
                0.8212746977806091,
                0.8033212423324585,
                0.852423369884491,
                0.7603601217269897,
                0.8372788429260254,
                0.8089379072189331,
                0.7495512962341309,
                0.8117215037345886,
                0.8762488961219788,
                0.7922481298446655,
                0.7070810794830322,
                0.7937716841697693,
                0.7825495004653931,
                0.8117215037345886,
                0.7873969078063965,
                0.7596461772918701,
                0.8540542125701904,
                0.7984744310379028
            ],
            [
                0.7599821090698242,
                0.821047306060791,
                0.7446635961532593,
                0.7884443402290344,
                0.8617158532142639,
                0.8306851387023926,
                0.8088826537132263,
                0.815025806427002,
                0.8591508865356445,
                0.8472813963890076,
                0.8484788537025452,
                0.741040825843811,
                0.7987721562385559,
                0.8287674188613892,
                0.6456122994422913,
                0.8554413318634033,
                0.7636310458183289,
                0.7487569451332092,
                0.7970560193061829,
                0.7960911989212036,
                0.7090181112289429,
                0.841296911239624,
                0.7673700451850891,
                0.845244824886322,
                0.7985730171203613,
                0.8282597661018372,
                0.7790369987487793,
                0.7915953397750854,
                0.8146133422851562,
                0.8311366438865662,
                0.8385471105575562,
                0.7706035375595093,
                0.7919662594795227,
                0.8433883786201477,
                0.7578356862068176,
                0.8636367321014404,
                0.8242958784103394,
                0.8111026287078857,
                0.8544151782989502,
                0.7302350401878357,
                0.8470681309700012,
                0.7965375781059265,
                0.7968008518218994,
                0.6606453657150269,
                0.8608505725860596,
                0.7417038083076477,
                0.8470681309700012,
                0.7394119501113892,
                0.8103055953979492,
                0.8264344930648804,
                0.8651488423347473
            ],
            [
                0.8672831654548645,
                0.8697494864463806,
                0.8215650320053101,
                0.8985931873321533,
                0.877413272857666,
                0.8729552626609802,
                0.8030626773834229,
                0.9331961870193481,
                0.9104313850402832,
                0.8492301106452942,
                0.8710545301437378,
                0.8371546268463135,
                0.80926513671875,
                0.934292733669281,
                0.7662096619606018,
                0.8843581080436707,
                0.8707029819488525,
                0.8387243747711182,
                0.8893783688545227,
                0.84916090965271,
                0.8135871887207031,
                0.8892096281051636,
                0.8628830313682556,
                0.834877610206604,
                0.8279857635498047,
                0.9366470575332642,
                0.8812819719314575,
                0.7941229939460754,
                0.8898469805717468,
                0.875397801399231,
                0.8751413822174072,
                0.8707014322280884,
                0.826471209526062,
                0.8787713646888733,
                0.8315128087997437,
                0.920071005821228,
                0.8061248064041138,
                0.8671277165412903,
                0.8634465336799622,
                0.7763279676437378,
                0.8714105486869812,
                0.8822635412216187,
                0.8226240873336792,
                0.7344712615013123,
                0.8525745272636414,
                0.8321019411087036,
                0.8714105486869812,
                0.8012049794197083,
                0.8123167157173157,
                0.9123212099075317,
                0.8596908450126648
            ],
            [
                0.7244873642921448,
                0.8148205876350403,
                0.7322426438331604,
                0.7775687575340271,
                0.791359007358551,
                0.7860246300697327,
                0.7779221534729004,
                0.8180700540542603,
                0.8465132117271423,
                0.7977224588394165,
                0.7949273586273193,
                0.7230424880981445,
                0.7458035945892334,
                0.8414931893348694,
                0.6416627168655396,
                0.8119086623191833,
                0.7753771543502808,
                0.7295490503311157,
                0.8301917314529419,
                0.7527669668197632,
                0.7274869680404663,
                0.8008758425712585,
                0.7987360954284668,
                0.7899409532546997,
                0.8119248151779175,
                0.7989977598190308,
                0.8043909668922424,
                0.7029720544815063,
                0.7858637571334839,
                0.7729543447494507,
                0.7848533391952515,
                0.7616199254989624,
                0.7462005019187927,
                0.788963794708252,
                0.7258462309837341,
                0.8350105285644531,
                0.7523332834243774,
                0.817665159702301,
                0.7899669408798218,
                0.7303204536437988,
                0.7933440208435059,
                0.7756050825119019,
                0.746368408203125,
                0.6698908805847168,
                0.8150290846824646,
                0.7098737359046936,
                0.7933440208435059,
                0.746944010257721,
                0.7947771549224854,
                0.7922186255455017,
                0.7984818816184998
            ]
        ],
        [
            [
                0.7107818722724915,
                0.9129841923713684,
                0.6311988830566406,
                0.7413532733917236,
                0.5850833058357239,
                0.8579185605049133,
                0.7414914965629578,
                0.6684408187866211,
                0.6333591341972351,
                0.62689608335495,
                0.7483205795288086,
                0.6152425408363342,
                0.7517169713973999,
                0.8041689395904541,
                0.7202127575874329,
                0.7005757093429565,
                0.47941887378692627,
                0.7159597873687744,
                0.5038101077079773,
                0.7197811007499695,
                0.4344518482685089,
                0.6940160989761353,
                0.4808899462223053,
                0.6957316398620605,
                0.473835289478302,
                0.7054576277732849,
                0.7080833911895752,
                0.4927268922328949,
                0.711407482624054,
                0.7424236536026001,
                0.4124091565608978,
                0.7337602376937866,
                0.5709331631660461,
                0.6620628833770752,
                0.8522977828979492,
                0.8553259968757629,
                0.6788341999053955,
                0.6544928550720215,
                0.6764453053474426,
                0.8158414959907532,
                0.7107807993888855,
                0.7503724098205566,
                0.7068803906440735,
                0.7428560853004456,
                0.7223755717277527,
                0.8664842844009399,
                0.7083926796913147,
                0.8707213997840881,
                0.732714056968689,
                0.7889180779457092,
                0.7439187169075012
            ],
            [
                0.6515220403671265,
                0.7458082437515259,
                0.5660595297813416,
                0.7824110984802246,
                0.5636465549468994,
                0.7368888854980469,
                0.8179093599319458,
                0.6423661112785339,
                0.6702300310134888,
                0.6160439252853394,
                0.7785705327987671,
                0.5230441093444824,
                0.7657510042190552,
                0.6482663750648499,
                0.7895746827125549,
                0.7651817202568054,
                0.4242226183414459,
                0.6799603700637817,
                0.4775174558162689,
                0.696729302406311,
                0.3699624240398407,
                0.6717371344566345,
                0.43095096945762634,
                0.6812001466751099,
                0.4262344241142273,
                0.696088433265686,
                0.7480832934379578,
                0.4222780466079712,
                0.6846128106117249,
                0.7839788198471069,
                0.3378278315067291,
                0.7789337038993835,
                0.5804799795150757,
                0.658062219619751,
                0.7410194277763367,
                0.7393214106559753,
                0.7000881433486938,
                0.6819311380386353,
                0.7135040163993835,
                0.6939309239387512,
                0.7695143818855286,
                0.6087865233421326,
                0.7191874384880066,
                0.7255134582519531,
                0.8349329233169556,
                0.7156698703765869,
                0.7725918292999268,
                0.7073687314987183,
                0.8370572924613953,
                0.6384477615356445,
                0.79631507396698
            ],
            [
                0.7070493698120117,
                0.8700187802314758,
                0.615393877029419,
                0.796322762966156,
                0.5998266339302063,
                0.8342190980911255,
                0.8109274506568909,
                0.6776384115219116,
                0.6476353406906128,
                0.619705080986023,
                0.8469564914703369,
                0.622763991355896,
                0.8015170097351074,
                0.7627496123313904,
                0.7709584832191467,
                0.7482366561889648,
                0.4899187684059143,
                0.7358969449996948,
                0.5429535508155823,
                0.748371958732605,
                0.4591972529888153,
                0.7391401529312134,
                0.5140108466148376,
                0.745132565498352,
                0.503889262676239,
                0.7501659393310547,
                0.7697845697402954,
                0.5084085464477539,
                0.7429434657096863,
                0.8004095554351807,
                0.44580793380737305,
                0.8043214082717896,
                0.5917883515357971,
                0.6613039970397949,
                0.8702594041824341,
                0.8448459506034851,
                0.7181268334388733,
                0.7003615498542786,
                0.733160138130188,
                0.8130555152893066,
                0.7838960886001587,
                0.7750715017318726,
                0.7379232048988342,
                0.801199197769165,
                0.7950813174247742,
                0.8510125875473022,
                0.7602208852767944,
                0.8215543627738953,
                0.7965071201324463,
                0.7551178932189941,
                0.7991383075714111
            ],
            [
                0.7272409200668335,
                0.7927191257476807,
                0.6573580503463745,
                0.9493355751037598,
                0.651265561580658,
                0.7752557992935181,
                0.8685958981513977,
                0.6754786968231201,
                0.6166051030158997,
                0.6566123366355896,
                0.8360480666160583,
                0.6067599058151245,
                0.8360483050346375,
                0.6845830082893372,
                0.8457911014556885,
                0.8102128505706787,
                0.5002834796905518,
                0.7145164608955383,
                0.543565571308136,
                0.7358211278915405,
                0.41774195432662964,
                0.6859951019287109,
                0.4530388116836548,
                0.6890795230865479,
                0.4493328332901001,
                0.7277985215187073,
                0.7731907367706299,
                0.514136791229248,
                0.7187451124191284,
                0.8440881371498108,
                0.40638771653175354,
                0.8346584439277649,
                0.6297041177749634,
                0.7011438608169556,
                0.7691152691841125,
                0.7886254191398621,
                0.735588550567627,
                0.7192795276641846,
                0.7911353707313538,
                0.7567632794380188,
                0.8141030073165894,
                0.6141491532325745,
                0.7863186001777649,
                0.7224068641662598,
                0.8445349335670471,
                0.767882764339447,
                0.8134909868240356,
                0.7503073215484619,
                0.8344253897666931,
                0.6466250419616699,
                0.8590282201766968
            ],
            [
                0.8249459862709045,
                0.7457992434501648,
                0.7452755570411682,
                0.8416287899017334,
                0.7573277354240417,
                0.7646783590316772,
                0.8795431852340698,
                0.7596279978752136,
                0.7024310827255249,
                0.7660559415817261,
                0.7716034650802612,
                0.6003006100654602,
                0.9003164768218994,
                0.6520395278930664,
                0.9189794063568115,
                0.8952394723892212,
                0.5501415133476257,
                0.7474847435951233,
                0.573065996170044,
                0.777346134185791,
                0.4989064037799835,
                0.7278697490692139,
                0.5102686882019043,
                0.7151961326599121,
                0.5021898150444031,
                0.8059220910072327,
                0.8054824471473694,
                0.5685904026031494,
                0.765485942363739,
                0.8836138844490051,
                0.48347318172454834,
                0.8669530153274536,
                0.7968496680259705,
                0.7953585386276245,
                0.7143176198005676,
                0.8042382001876831,
                0.7826032042503357,
                0.807028591632843,
                0.8804535269737244,
                0.8098084330558777,
                0.8645268678665161,
                0.5864279270172119,
                0.8563441038131714,
                0.6914901733398438,
                0.8515049815177917,
                0.7521772384643555,
                0.9014568328857422,
                0.7437912821769714,
                0.8186941742897034,
                0.6368662714958191,
                0.9176710844039917
            ],
            [
                0.7725366950035095,
                0.7775142788887024,
                0.6679045557975769,
                0.8419771194458008,
                0.6847971677780151,
                0.8013970255851746,
                0.9441472887992859,
                0.7138116359710693,
                0.7098692059516907,
                0.7441025972366333,
                0.8264620304107666,
                0.6032843589782715,
                0.8762999176979065,
                0.6714383363723755,
                0.8823478817939758,
                0.8552323579788208,
                0.46465015411376953,
                0.7317463755607605,
                0.525091290473938,
                0.758667528629303,
                0.4439067542552948,
                0.7472923398017883,
                0.4754776060581207,
                0.7355972528457642,
                0.47124263644218445,
                0.7937877178192139,
                0.8102312088012695,
                0.48729199171066284,
                0.7498247623443604,
                0.8637848496437073,
                0.40617841482162476,
                0.8560010194778442,
                0.6851372122764587,
                0.7740947008132935,
                0.751663327217102,
                0.8052617907524109,
                0.8058270812034607,
                0.8164278268814087,
                0.8557575941085815,
                0.7844098806381226,
                0.8725196123123169,
                0.6571505069732666,
                0.8419559001922607,
                0.7571645379066467,
                0.8963543176651001,
                0.7645390629768372,
                0.8665863871574402,
                0.7494837045669556,
                0.861121416091919,
                0.6805403232574463,
                0.8972222208976746
            ],
            [
                0.7069091200828552,
                0.8638498187065125,
                0.7050068378448486,
                0.7238856554031372,
                0.682703971862793,
                0.8900367021560669,
                0.7628709077835083,
                0.7503383755683899,
                0.6714338064193726,
                0.6339645981788635,
                0.7903673648834229,
                0.659500777721405,
                0.742034375667572,
                0.7780340909957886,
                0.7144863605499268,
                0.7136589288711548,
                0.5592703819274902,
                0.7597941756248474,
                0.5882931351661682,
                0.7660242915153503,
                0.5506929159164429,
                0.7592796683311462,
                0.5825590491294861,
                0.7629162073135376,
                0.5653517246246338,
                0.760491669178009,
                0.741741955280304,
                0.5758314728736877,
                0.7690279483795166,
                0.7399497032165527,
                0.5265770554542542,
                0.743883490562439,
                0.6601743102073669,
                0.657956600189209,
                0.8313391208648682,
                0.8200919032096863,
                0.7024684548377991,
                0.692171573638916,
                0.7146510481834412,
                0.8213989734649658,
                0.7325822710990906,
                0.7638511061668396,
                0.7305066585540771,
                0.7855042815208435,
                0.7083340287208557,
                0.8451927304267883,
                0.7012873291969299,
                0.7979902625083923,
                0.7008476853370667,
                0.784515917301178,
                0.7252418994903564
            ],
            [
                0.7898527979850769,
                0.7974507212638855,
                0.6867246627807617,
                0.8133343458175659,
                0.7007927894592285,
                0.8412318229675293,
                0.8780140280723572,
                0.7161726951599121,
                0.72248375415802,
                0.7789806127548218,
                0.7878360152244568,
                0.6961694955825806,
                0.8746551871299744,
                0.7574432492256165,
                0.9024927020072937,
                0.8976492881774902,
                0.47587132453918457,
                0.7735326290130615,
                0.5300666093826294,
                0.8008437752723694,
                0.45383110642433167,
                0.774189293384552,
                0.4965601861476898,
                0.7667350769042969,
                0.48435676097869873,
                0.8298265933990479,
                0.8370670676231384,
                0.4890882968902588,
                0.775726318359375,
                0.869560956954956,
                0.4160660207271576,
                0.8563273549079895,
                0.7064599990844727,
                0.8080241680145264,
                0.7724707126617432,
                0.8616893291473389,
                0.7837912440299988,
                0.8110060691833496,
                0.8510730266571045,
                0.8495743870735168,
                0.8658610582351685,
                0.6927196383476257,
                0.8285427093505859,
                0.7394395470619202,
                0.8692669868469238,
                0.8197376728057861,
                0.8768086433410645,
                0.8140807151794434,
                0.8429508209228516,
                0.7737566828727722,
                0.8921071290969849
            ],
            [
                0.8341663479804993,
                0.8006959557533264,
                0.7131426930427551,
                0.8137983679771423,
                0.7395374178886414,
                0.8512973785400391,
                0.8953943848609924,
                0.7202149629592896,
                0.7458032965660095,
                0.7764826416969299,
                0.7926543354988098,
                0.6893913745880127,
                0.9116231799125671,
                0.7340525388717651,
                0.9287201166152954,
                0.9118349552154541,
                0.561517596244812,
                0.8108129501342773,
                0.6008305549621582,
                0.8402044177055359,
                0.5432700514793396,
                0.8092076778411865,
                0.5348609089851379,
                0.7824210524559021,
                0.5288249254226685,
                0.8479942679405212,
                0.8443087339401245,
                0.5727601051330566,
                0.8280158638954163,
                0.9007157683372498,
                0.5090788006782532,
                0.890538215637207,
                0.7441523671150208,
                0.8180561065673828,
                0.7814784049987793,
                0.8641963005065918,
                0.8113980889320374,
                0.8469375967979431,
                0.8959780335426331,
                0.865577220916748,
                0.8808315992355347,
                0.6745076179504395,
                0.8680680990219116,
                0.7439137697219849,
                0.8532226085662842,
                0.8080551624298096,
                0.9068789482116699,
                0.7963109612464905,
                0.8093316555023193,
                0.6967318654060364,
                0.9210759401321411
            ],
            [
                0.7457256317138672,
                0.7522707581520081,
                0.6408075094223022,
                0.7728893160820007,
                0.6686524748802185,
                0.7889797687530518,
                0.8376925587654114,
                0.6995449662208557,
                0.7113715410232544,
                0.7172528505325317,
                0.7918967008590698,
                0.675899863243103,
                0.8683897852897644,
                0.7022632360458374,
                0.8520538210868835,
                0.8349157571792603,
                0.47956496477127075,
                0.7779605984687805,
                0.5051120519638062,
                0.7805562615394592,
                0.4301242530345917,
                0.7801974415779114,
                0.47497129440307617,
                0.7799428701400757,
                0.46750298142433167,
                0.8074905276298523,
                0.8308575749397278,
                0.44659072160720825,
                0.7709068059921265,
                0.8467124104499817,
                0.39024817943573,
                0.8523266315460205,
                0.6747299432754517,
                0.753247857093811,
                0.7431640625,
                0.8197739720344543,
                0.7724642157554626,
                0.7850271463394165,
                0.8246709704399109,
                0.7836918234825134,
                0.8334892988204956,
                0.6662830114364624,
                0.7927608489990234,
                0.735489010810852,
                0.8503628373146057,
                0.7778106331825256,
                0.851111650466919,
                0.7700686454772949,
                0.8355157375335693,
                0.698837399482727,
                0.8789092302322388
            ],
            [
                0.6900206208229065,
                0.8034476637840271,
                0.6891030073165894,
                0.8130157589912415,
                0.6938475966453552,
                0.7994486689567566,
                0.8419126272201538,
                0.7597817778587341,
                0.6587964296340942,
                0.6281313896179199,
                0.9448291659355164,
                0.6029585599899292,
                0.8115408420562744,
                0.7117041945457458,
                0.790952205657959,
                0.7745522856712341,
                0.4588201642036438,
                0.7392193078994751,
                0.5257672667503357,
                0.7455801963806152,
                0.44561633467674255,
                0.7564218640327454,
                0.5017613768577576,
                0.760660707950592,
                0.49281346797943115,
                0.7726149559020996,
                0.8229962587356567,
                0.46789348125457764,
                0.7400199770927429,
                0.8199586868286133,
                0.4054117202758789,
                0.8374288082122803,
                0.6927816271781921,
                0.6724041700363159,
                0.8163301944732666,
                0.8232704997062683,
                0.7476114630699158,
                0.7495301961898804,
                0.7719385027885437,
                0.7701866626739502,
                0.808148980140686,
                0.7165755033493042,
                0.7516602277755737,
                0.8070470094680786,
                0.8515647649765015,
                0.8140515089035034,
                0.7847163081169128,
                0.7612557411193848,
                0.8387985825538635,
                0.7060869336128235,
                0.8231461644172668
            ],
            [
                0.8369241952896118,
                0.7481708526611328,
                0.7237548232078552,
                0.7835811376571655,
                0.7394599318504333,
                0.7869492173194885,
                0.8375715613365173,
                0.7441551685333252,
                0.7272331714630127,
                0.8004385232925415,
                0.7463394403457642,
                0.6692286133766174,
                0.8961172699928284,
                0.7027785778045654,
                0.8970709443092346,
                0.8824900388717651,
                0.5229079127311707,
                0.7753766775131226,
                0.5633589625358582,
                0.8049934506416321,
                0.49280834197998047,
                0.7733433246612549,
                0.5151249170303345,
                0.7628393173217773,
                0.5090044736862183,
                0.8411365747451782,
                0.828495442867279,
                0.5379038453102112,
                0.7899081110954285,
                0.8673382997512817,
                0.46281227469444275,
                0.8531320691108704,
                0.7613561749458313,
                0.8167060613632202,
                0.7273083329200745,
                0.8240615129470825,
                0.8093872666358948,
                0.828032374382019,
                0.8756974339485168,
                0.8220939636230469,
                0.8726038932800293,
                0.6501660943031311,
                0.8696863055229187,
                0.6870090365409851,
                0.8205528259277344,
                0.7889463305473328,
                0.8815481662750244,
                0.7836910486221313,
                0.790710985660553,
                0.703615128993988,
                0.8977708220481873
            ],
            [
                0.7340280413627625,
                0.8536202907562256,
                0.651811957359314,
                0.8407968282699585,
                0.6583430171012878,
                0.8626540303230286,
                0.8637678623199463,
                0.6915448904037476,
                0.6860498785972595,
                0.6906638741493225,
                0.8659869432449341,
                0.7564961910247803,
                0.8587440252304077,
                0.8296710252761841,
                0.8642051815986633,
                0.8506386280059814,
                0.5059691071510315,
                0.8064222931861877,
                0.5583013296127319,
                0.8152052164077759,
                0.477071076631546,
                0.8081120848655701,
                0.5124359130859375,
                0.8025232553482056,
                0.5146961212158203,
                0.8230021595954895,
                0.8491225838661194,
                0.4937386214733124,
                0.7927699685096741,
                0.8655640482902527,
                0.4257110059261322,
                0.8722537755966187,
                0.6371081471443176,
                0.7366978526115417,
                0.8485179543495178,
                0.89610755443573,
                0.7780258655548096,
                0.7757929563522339,
                0.804194986820221,
                0.8389926552772522,
                0.8276751041412354,
                0.7482856512069702,
                0.7888352870941162,
                0.7875450849533081,
                0.855783224105835,
                0.8663005828857422,
                0.8341638445854187,
                0.8421478271484375,
                0.8364320993423462,
                0.8002638816833496,
                0.8652414083480835
            ],
            [
                0.762368381023407,
                0.7964197397232056,
                0.6403898000717163,
                0.8726519346237183,
                0.6562246680259705,
                0.8108355402946472,
                0.9117289781570435,
                0.6984789967536926,
                0.6833937764167786,
                0.6939448714256287,
                0.8398792147636414,
                0.669813871383667,
                0.9008796811103821,
                0.7259631156921387,
                0.91785728931427,
                0.8995885848999023,
                0.5254400968551636,
                0.78758704662323,
                0.5404601097106934,
                0.7856667637825012,
                0.48068803548812866,
                0.7799449563026428,
                0.5134464502334595,
                0.772142767906189,
                0.49319496750831604,
                0.8244977593421936,
                0.8529131412506104,
                0.5206847786903381,
                0.7849382162094116,
                0.9084347486495972,
                0.4363575875759125,
                0.9111048579216003,
                0.6896253824234009,
                0.7394880056381226,
                0.8043326735496521,
                0.85637366771698,
                0.7840498685836792,
                0.8072196245193481,
                0.8579729795455933,
                0.8167611360549927,
                0.8624137043952942,
                0.655093252658844,
                0.8208359479904175,
                0.7657994627952576,
                0.8997606039047241,
                0.8121310472488403,
                0.8932672142982483,
                0.7852202653884888,
                0.8728639483451843,
                0.6965802907943726,
                0.9217130541801453
            ],
            [
                0.7772377133369446,
                0.6867366433143616,
                0.7251240611076355,
                0.7608937621116638,
                0.7267646789550781,
                0.7208159565925598,
                0.8226320743560791,
                0.7669070363044739,
                0.7300628423690796,
                0.7610186338424683,
                0.739610493183136,
                0.5569584369659424,
                0.8313999176025391,
                0.6185426115989685,
                0.8398769497871399,
                0.8292048573493958,
                0.5120841860771179,
                0.7188591957092285,
                0.5628886222839355,
                0.7578011751174927,
                0.4686867892742157,
                0.7026438117027283,
                0.5342532396316528,
                0.7126601338386536,
                0.4978599548339844,
                0.7790773510932922,
                0.7781792283058167,
                0.5391650795936584,
                0.7395703792572021,
                0.8430521488189697,
                0.4561629891395569,
                0.8169840574264526,
                0.7842381000518799,
                0.7776556611061096,
                0.6946185827255249,
                0.74990314245224,
                0.773068904876709,
                0.806730329990387,
                0.8228298425674438,
                0.7662219405174255,
                0.8592773079872131,
                0.5959087014198303,
                0.8352433443069458,
                0.6859317421913147,
                0.8036494851112366,
                0.7047365307807922,
                0.850184977054596,
                0.7343325018882751,
                0.7733942866325378,
                0.6458790302276611,
                0.8558384776115417
            ],
            [
                0.702678382396698,
                0.7741844058036804,
                0.6343177556991577,
                0.7322190403938293,
                0.630035936832428,
                0.7754964232444763,
                0.7278398871421814,
                0.7026028633117676,
                0.7107408046722412,
                0.6469216346740723,
                0.7946996688842773,
                0.6543606519699097,
                0.784241795539856,
                0.7145137786865234,
                0.7264028191566467,
                0.7059570550918579,
                0.6099859476089478,
                0.7877888679504395,
                0.6095668077468872,
                0.7732937335968018,
                0.5611790418624878,
                0.7783311605453491,
                0.616177499294281,
                0.7937101125717163,
                0.5824987888336182,
                0.7561655044555664,
                0.7647358775138855,
                0.586417019367218,
                0.7858995795249939,
                0.7849956750869751,
                0.551760733127594,
                0.8018621802330017,
                0.6302164793014526,
                0.6742740273475647,
                0.7952588796615601,
                0.7731706500053406,
                0.7539682388305664,
                0.7268417477607727,
                0.7426700592041016,
                0.7514352798461914,
                0.7459219098091125,
                0.7153208255767822,
                0.7520490884780884,
                0.7388985753059387,
                0.7243569493293762,
                0.7817286849021912,
                0.7283681631088257,
                0.7473208904266357,
                0.7261391878128052,
                0.7113914489746094,
                0.7738819718360901
            ],
            [
                0.6770837306976318,
                0.8047271370887756,
                0.5842044949531555,
                0.7342084646224976,
                0.5815786123275757,
                0.7985310554504395,
                0.7479493618011475,
                0.6450518369674683,
                0.6604183912277222,
                0.5900884866714478,
                0.8230811357498169,
                0.6545305252075195,
                0.7693486213684082,
                0.7938951253890991,
                0.7188175320625305,
                0.7011047005653381,
                0.5411494374275208,
                0.7672574520111084,
                0.5976956486701965,
                0.7673344016075134,
                0.545131504535675,
                0.7854655385017395,
                0.5808499455451965,
                0.7892820835113525,
                0.5436855554580688,
                0.7546259164810181,
                0.7872524857521057,
                0.5441920161247253,
                0.7682011723518372,
                0.7821306586265564,
                0.5073617696762085,
                0.7984201312065125,
                0.5767530798912048,
                0.6376744508743286,
                0.8776587247848511,
                0.8302264213562012,
                0.7404507398605347,
                0.7162600159645081,
                0.7122283577919006,
                0.7820841073989868,
                0.7512183785438538,
                0.7675856947898865,
                0.7168144583702087,
                0.780976414680481,
                0.743987500667572,
                0.8193032741546631,
                0.708975613117218,
                0.8042452335357666,
                0.7253185510635376,
                0.7291743755340576,
                0.7535998821258545
            ],
            [
                0.7602972984313965,
                0.6892533302307129,
                0.721177875995636,
                0.7699686288833618,
                0.7249041199684143,
                0.7250123620033264,
                0.8245471119880676,
                0.7759741544723511,
                0.7394981384277344,
                0.7606641054153442,
                0.7496196031570435,
                0.5706565380096436,
                0.8187928199768066,
                0.6262979507446289,
                0.8275107741355896,
                0.8153067827224731,
                0.5080843567848206,
                0.7123540639877319,
                0.5536493062973022,
                0.7420596480369568,
                0.4679085612297058,
                0.7014791369438171,
                0.5392614006996155,
                0.7134126424789429,
                0.5385705232620239,
                0.7872987985610962,
                0.7991973757743835,
                0.5296476483345032,
                0.7251923084259033,
                0.8365791440010071,
                0.4446200132369995,
                0.8220909833908081,
                0.7695378065109253,
                0.7718707323074341,
                0.7039765119552612,
                0.7500225901603699,
                0.7842861413955688,
                0.8126917481422424,
                0.8148604035377502,
                0.7594746947288513,
                0.8589367866516113,
                0.6204334497451782,
                0.8304521441459656,
                0.7048835754394531,
                0.8109001517295837,
                0.708177924156189,
                0.8457231521606445,
                0.7267822027206421,
                0.7818714380264282,
                0.6666218638420105,
                0.8451200723648071
            ],
            [
                0.7398452162742615,
                0.7719281911849976,
                0.6476924419403076,
                0.7403003573417664,
                0.6539900302886963,
                0.7997045516967773,
                0.7536725401878357,
                0.7219250202178955,
                0.7408011555671692,
                0.7173049449920654,
                0.7779150009155273,
                0.71377032995224,
                0.8138481378555298,
                0.7597765922546387,
                0.760649561882019,
                0.744583785533905,
                0.6027191281318665,
                0.8109957575798035,
                0.5995607972145081,
                0.7899803519248962,
                0.5684974193572998,
                0.807807207107544,
                0.6086348295211792,
                0.8098870515823364,
                0.642108142375946,
                0.8023921251296997,
                0.8223880529403687,
                0.5719360113143921,
                0.799187183380127,
                0.7886660695075989,
                0.5231838226318359,
                0.8151617646217346,
                0.637374758720398,
                0.7326218485832214,
                0.7870155572891235,
                0.8147205114364624,
                0.8014835119247437,
                0.7787728309631348,
                0.7807983160018921,
                0.7592479586601257,
                0.7732729911804199,
                0.7269703149795532,
                0.7777519822120667,
                0.7243338823318481,
                0.7529692649841309,
                0.7929477095603943,
                0.7711011171340942,
                0.7622400522232056,
                0.7481966018676758,
                0.7672132253646851,
                0.7876547574996948
            ],
            [
                0.7290191054344177,
                0.8043290972709656,
                0.6440557241439819,
                0.8148877620697021,
                0.6534533500671387,
                0.8242095112800598,
                0.8297836184501648,
                0.7221205234527588,
                0.7298787236213684,
                0.6790722012519836,
                0.8427350521087646,
                0.7064359784126282,
                0.8377951383590698,
                0.8040440678596497,
                0.8299689888954163,
                0.8120747804641724,
                0.5520418286323547,
                0.8032246828079224,
                0.6041861176490784,
                0.8088732957839966,
                0.5132334232330322,
                0.7933245897293091,
                0.5858811736106873,
                0.8158121705055237,
                0.5850913524627686,
                0.8235529065132141,
                0.8731416463851929,
                0.5492308139801025,
                0.7951841354370117,
                0.8636072874069214,
                0.48152488470077515,
                0.8694690465927124,
                0.6582000255584717,
                0.7238346934318542,
                0.8609004020690918,
                0.8467128276824951,
                0.7930980920791626,
                0.7773889899253845,
                0.7965590953826904,
                0.8094764947891235,
                0.8281968832015991,
                0.7212156057357788,
                0.7974088788032532,
                0.7655206918716431,
                0.8316718935966492,
                0.8276399970054626,
                0.8187888264656067,
                0.8299798965454102,
                0.8130965828895569,
                0.7680293321609497,
                0.8428816795349121
            ],
            [
                0.7762830257415771,
                0.770623505115509,
                0.659643292427063,
                0.7794782519340515,
                0.6725291609764099,
                0.7959755659103394,
                0.773150622844696,
                0.7121628522872925,
                0.7572198510169983,
                0.7420275211334229,
                0.7736316919326782,
                0.7107218503952026,
                0.8565176129341125,
                0.7451601624488831,
                0.7927855849266052,
                0.7680476307868958,
                0.5959047675132751,
                0.7990914583206177,
                0.6494045257568359,
                0.8155583739280701,
                0.5497236251831055,
                0.7897027730941772,
                0.5792728662490845,
                0.7858176231384277,
                0.5483402013778687,
                0.7730934023857117,
                0.7822287678718567,
                0.6186850666999817,
                0.8205961585044861,
                0.8310457468032837,
                0.5196208357810974,
                0.8294546008110046,
                0.6617642045021057,
                0.7673446536064148,
                0.7869280576705933,
                0.8090583086013794,
                0.8320061564445496,
                0.7978380918502808,
                0.7930023074150085,
                0.7785035967826843,
                0.7922438979148865,
                0.7029227018356323,
                0.8267266154289246,
                0.7093281149864197,
                0.7591877579689026,
                0.7819691896438599,
                0.7796683311462402,
                0.7782813906669617,
                0.7360830307006836,
                0.7237600684165955,
                0.8141590356826782
            ],
            [
                0.7476359009742737,
                0.8212531805038452,
                0.6610530614852905,
                0.8317831158638,
                0.6600480079650879,
                0.8421409130096436,
                0.8405608534812927,
                0.7274417281150818,
                0.729503870010376,
                0.6938961148262024,
                0.8481059670448303,
                0.6867124438285828,
                0.8582441806793213,
                0.8015501499176025,
                0.8518364429473877,
                0.8330589532852173,
                0.5338338613510132,
                0.8000563979148865,
                0.6030040979385376,
                0.8174009919166565,
                0.5003953576087952,
                0.7893457412719727,
                0.5502435564994812,
                0.7976483106613159,
                0.5281342267990112,
                0.8082091212272644,
                0.8503755331039429,
                0.5646370649337769,
                0.8076170086860657,
                0.8678722977638245,
                0.466973215341568,
                0.8625898361206055,
                0.676993727684021,
                0.7345216870307922,
                0.8570139408111572,
                0.8607414364814758,
                0.7947567701339722,
                0.7768001556396484,
                0.8046074509620667,
                0.8258486390113831,
                0.8350486159324646,
                0.7132555842399597,
                0.810490608215332,
                0.7789080142974854,
                0.847556471824646,
                0.8400280475616455,
                0.826420247554779,
                0.8483089804649353,
                0.8209525942802429,
                0.7544455528259277,
                0.8573493957519531
            ],
            [
                0.7422020435333252,
                0.7403180599212646,
                0.6291190981864929,
                0.7424181699752808,
                0.6514832377433777,
                0.7786761522293091,
                0.7495540380477905,
                0.6957091689109802,
                0.7347399592399597,
                0.7148876786231995,
                0.7760480046272278,
                0.6955991983413696,
                0.8160576820373535,
                0.7143122553825378,
                0.7629730701446533,
                0.7448770999908447,
                0.5950015187263489,
                0.8021164536476135,
                0.6064181327819824,
                0.7884969115257263,
                0.5687801241874695,
                0.8030945658683777,
                0.5899385213851929,
                0.7948006391525269,
                0.5591146349906921,
                0.7727108597755432,
                0.7790302038192749,
                0.5715217590332031,
                0.7998071908950806,
                0.7948428392410278,
                0.5475600957870483,
                0.8184986710548401,
                0.6338913440704346,
                0.7321897745132446,
                0.7655982971191406,
                0.7993267774581909,
                0.8065115213394165,
                0.7880181670188904,
                0.808684229850769,
                0.7534615397453308,
                0.7766278386116028,
                0.7038317918777466,
                0.7884324193000793,
                0.7184193134307861,
                0.7417937517166138,
                0.7721768617630005,
                0.7585811614990234,
                0.7370419502258301,
                0.7277187705039978,
                0.71366947889328,
                0.7862668633460999
            ],
            [
                0.7307571768760681,
                0.8026206493377686,
                0.6649142503738403,
                0.7996146082878113,
                0.6700814366340637,
                0.805948793888092,
                0.8108931183815002,
                0.7256277203559875,
                0.7159837484359741,
                0.6747052073478699,
                0.868504524230957,
                0.6580129861831665,
                0.8346400856971741,
                0.7537558078765869,
                0.8021697998046875,
                0.7835794687271118,
                0.5613880157470703,
                0.7996704578399658,
                0.6262027621269226,
                0.8084607124328613,
                0.549565315246582,
                0.8067675828933716,
                0.5718492269515991,
                0.7984691262245178,
                0.5471069812774658,
                0.8000316023826599,
                0.8342363238334656,
                0.562781572341919,
                0.8007798790931702,
                0.8465158939361572,
                0.5321224331855774,
                0.8630726933479309,
                0.6694465279579163,
                0.7114942073822021,
                0.8490976691246033,
                0.8555001020431519,
                0.8075799942016602,
                0.789892315864563,
                0.8166619539260864,
                0.8069875836372375,
                0.8356788754463196,
                0.7409018874168396,
                0.8011870384216309,
                0.8049049973487854,
                0.8207465410232544,
                0.8195169568061829,
                0.7999321222305298,
                0.8158313035964966,
                0.7918359041213989,
                0.7078100442886353,
                0.8208439350128174
            ],
            [
                0.8288861513137817,
                0.7572717070579529,
                0.6947563886642456,
                0.8080191016197205,
                0.720374584197998,
                0.7903674840927124,
                0.8574244976043701,
                0.7376645803451538,
                0.7529486417770386,
                0.7807860374450684,
                0.805892288684845,
                0.6537047028541565,
                0.9098055958747864,
                0.6955891847610474,
                0.8908675312995911,
                0.8659092783927917,
                0.5754815936088562,
                0.7962640523910522,
                0.6258808970451355,
                0.8164904117584229,
                0.5578022003173828,
                0.796748161315918,
                0.5822792053222656,
                0.7897558212280273,
                0.5516136884689331,
                0.8400545120239258,
                0.8381091952323914,
                0.5875089168548584,
                0.8084831237792969,
                0.8906421661376953,
                0.5323323011398315,
                0.8901935815811157,
                0.7397070527076721,
                0.8043505549430847,
                0.7939529418945312,
                0.8277673125267029,
                0.8509738445281982,
                0.8588281869888306,
                0.8983626365661621,
                0.8431236147880554,
                0.9147125482559204,
                0.6825242638587952,
                0.9000449180603027,
                0.7494333982467651,
                0.842548668384552,
                0.8005043864250183,
                0.8726770281791687,
                0.7618921995162964,
                0.7938528060913086,
                0.6932816505432129,
                0.9049204587936401
            ],
            [
                0.7787195444107056,
                0.8285600543022156,
                0.6726862192153931,
                0.769302248954773,
                0.6860994696617126,
                0.8373966813087463,
                0.7919656038284302,
                0.7502214908599854,
                0.7692564129829407,
                0.7339684367179871,
                0.8139163255691528,
                0.6687528491020203,
                0.8541749715805054,
                0.755741536617279,
                0.8058464527130127,
                0.783466637134552,
                0.5898039937019348,
                0.8091786503791809,
                0.628760576248169,
                0.8085803985595703,
                0.5763655304908752,
                0.8142405152320862,
                0.6188884377479553,
                0.8171136379241943,
                0.5782433152198792,
                0.8111242651939392,
                0.8237786889076233,
                0.5906222462654114,
                0.8114510178565979,
                0.8328189253807068,
                0.5467135310173035,
                0.8448943495750427,
                0.6898012757301331,
                0.7600829005241394,
                0.8485563397407532,
                0.8417752981185913,
                0.8212680816650391,
                0.789831280708313,
                0.815155565738678,
                0.8481891751289368,
                0.8389039039611816,
                0.7872921824455261,
                0.8312926888465881,
                0.792170524597168,
                0.807482898235321,
                0.8384615778923035,
                0.794194221496582,
                0.8063894510269165,
                0.7839162349700928,
                0.7714180946350098,
                0.8313069343566895
            ],
            [
                0.8190471529960632,
                0.7821656465530396,
                0.6965326070785522,
                0.7484889030456543,
                0.7130899429321289,
                0.8165616393089294,
                0.7872015237808228,
                0.7576048970222473,
                0.7687704563140869,
                0.7307766675949097,
                0.7782819271087646,
                0.629436731338501,
                0.8432547450065613,
                0.6997199654579163,
                0.8081119060516357,
                0.7847929000854492,
                0.5904749631881714,
                0.7823986411094666,
                0.6114162802696228,
                0.7852189540863037,
                0.5666511654853821,
                0.7804757952690125,
                0.5847914218902588,
                0.7711372375488281,
                0.5521464943885803,
                0.782995879650116,
                0.780074417591095,
                0.603702187538147,
                0.7987501621246338,
                0.8294214010238647,
                0.5555562973022461,
                0.8324905037879944,
                0.724297285079956,
                0.752751350402832,
                0.7955120801925659,
                0.8033219575881958,
                0.8000518083572388,
                0.787010133266449,
                0.8146271705627441,
                0.8414346575737,
                0.8347240686416626,
                0.7391371726989746,
                0.8368090391159058,
                0.7909345030784607,
                0.7778595089912415,
                0.7927743792533875,
                0.8014910221099854,
                0.7548959851264954,
                0.747385561466217,
                0.7193698883056641,
                0.8305256366729736
            ],
            [
                0.7923574447631836,
                0.8576228022575378,
                0.7140955924987793,
                0.8092001080513,
                0.7167658805847168,
                0.8770532011985779,
                0.8481173515319824,
                0.7695504426956177,
                0.7436274290084839,
                0.7224203944206238,
                0.8536847829818726,
                0.6757767796516418,
                0.8595782518386841,
                0.7908380031585693,
                0.8497111797332764,
                0.8337984085083008,
                0.5371272563934326,
                0.7956436276435852,
                0.579723060131073,
                0.8045257925987244,
                0.5121709704399109,
                0.7883641123771667,
                0.5718821287155151,
                0.7974149584770203,
                0.5501574277877808,
                0.8239076137542725,
                0.8379127383232117,
                0.547925591468811,
                0.7983097434043884,
                0.8716713786125183,
                0.4890713393688202,
                0.869520902633667,
                0.7209113836288452,
                0.7469006776809692,
                0.8969254493713379,
                0.8713690042495728,
                0.7936615943908691,
                0.7943686246871948,
                0.822192370891571,
                0.8886435627937317,
                0.881543755531311,
                0.7752377986907959,
                0.8398861289024353,
                0.8268663287162781,
                0.8451000452041626,
                0.880314826965332,
                0.8359273076057434,
                0.8502839207649231,
                0.819114625453949,
                0.7900693416595459,
                0.872044563293457
            ],
            [
                0.8209571242332458,
                0.7350541949272156,
                0.7022454738616943,
                0.764911413192749,
                0.7264492511749268,
                0.763968825340271,
                0.8355304002761841,
                0.7502577304840088,
                0.7776651382446289,
                0.8135969042778015,
                0.7517337203025818,
                0.6377006769180298,
                0.8704390525817871,
                0.6646304130554199,
                0.8785607218742371,
                0.8615953922271729,
                0.5304781198501587,
                0.7670367360115051,
                0.5556180477142334,
                0.7845063805580139,
                0.5123643279075623,
                0.7795384526252747,
                0.5524424314498901,
                0.7745999693870544,
                0.5226322412490845,
                0.8454238176345825,
                0.8236950039863586,
                0.5220029950141907,
                0.7735334038734436,
                0.8468847274780273,
                0.4669436514377594,
                0.8464979529380798,
                0.761512815952301,
                0.8350359201431274,
                0.7301298975944519,
                0.808539628982544,
                0.8466817140579224,
                0.8592303991317749,
                0.8909071087837219,
                0.7983242869377136,
                0.8647689819335938,
                0.6465646028518677,
                0.8836328983306885,
                0.6836380958557129,
                0.821969211101532,
                0.7758712768554688,
                0.8712177276611328,
                0.75998854637146,
                0.8103905916213989,
                0.6913816332817078,
                0.898838460445404
            ],
            [
                0.843789279460907,
                0.7642868161201477,
                0.7370679378509521,
                0.7419619560241699,
                0.755998969078064,
                0.8095024824142456,
                0.8166961073875427,
                0.771293580532074,
                0.7896115779876709,
                0.8036131858825684,
                0.7432976961135864,
                0.6349340677261353,
                0.8738123774528503,
                0.6906031370162964,
                0.8663443922996521,
                0.8504696488380432,
                0.5663348436355591,
                0.7756817936897278,
                0.5833258032798767,
                0.7953846454620361,
                0.5456781983375549,
                0.7778066396713257,
                0.5715934038162231,
                0.7663421630859375,
                0.5458926558494568,
                0.8279714584350586,
                0.8040300011634827,
                0.5750740766525269,
                0.7933841943740845,
                0.846404492855072,
                0.5142657160758972,
                0.838514506816864,
                0.7798491716384888,
                0.8311236500740051,
                0.7440871000289917,
                0.8356999754905701,
                0.8216363787651062,
                0.830280601978302,
                0.8641473054885864,
                0.8615949153900146,
                0.8507097363471985,
                0.6917327046394348,
                0.8668732047080994,
                0.7183742523193359,
                0.8023676872253418,
                0.7947872281074524,
                0.8725062608718872,
                0.7747204899787903,
                0.7803181409835815,
                0.7386468648910522,
                0.8827730417251587
            ],
            [
                0.7916871309280396,
                0.8391290903091431,
                0.7605865001678467,
                0.8065276145935059,
                0.7512661814689636,
                0.8446338772773743,
                0.8348084688186646,
                0.824207067489624,
                0.7396804690361023,
                0.7328673005104065,
                0.8477240800857544,
                0.6223593950271606,
                0.8611689805984497,
                0.7335442304611206,
                0.8367887139320374,
                0.8196091651916504,
                0.576709508895874,
                0.7830914258956909,
                0.6113578677177429,
                0.8014639019966125,
                0.5439751744270325,
                0.7684118151664734,
                0.5810893177986145,
                0.7703366279602051,
                0.5586313605308533,
                0.8047051429748535,
                0.8087863326072693,
                0.5943876504898071,
                0.7946010828018188,
                0.8603328466415405,
                0.5273278951644897,
                0.8509632349014282,
                0.7749941349029541,
                0.7535316944122314,
                0.8372092843055725,
                0.8407948017120361,
                0.7919334173202515,
                0.7943764925003052,
                0.8176847100257874,
                0.8613026738166809,
                0.85845547914505,
                0.7179124355316162,
                0.8392879962921143,
                0.7909629940986633,
                0.818493664264679,
                0.8489945530891418,
                0.8334978222846985,
                0.8102580308914185,
                0.7968111634254456,
                0.7414730787277222,
                0.8597663640975952
            ],
            [
                0.8035998344421387,
                0.747672438621521,
                0.6957693696022034,
                0.7776110172271729,
                0.7179614305496216,
                0.780687153339386,
                0.8402994275093079,
                0.7505970001220703,
                0.7685858011245728,
                0.7822673320770264,
                0.7878609299659729,
                0.6454364061355591,
                0.8689557313919067,
                0.6729064583778381,
                0.8655849695205688,
                0.8465775847434998,
                0.5729687213897705,
                0.7802549600601196,
                0.5976523756980896,
                0.7911306023597717,
                0.5778430104255676,
                0.8057774901390076,
                0.5797937512397766,
                0.7839807868003845,
                0.5492124557495117,
                0.8428317308425903,
                0.8275790810585022,
                0.5730897188186646,
                0.7933213710784912,
                0.8498375415802002,
                0.5131367444992065,
                0.8600355982780457,
                0.7513536214828491,
                0.8112669587135315,
                0.7472766637802124,
                0.8233531713485718,
                0.8593544960021973,
                0.8729763627052307,
                0.8834702372550964,
                0.8042982816696167,
                0.8481804132461548,
                0.6725388765335083,
                0.8738763332366943,
                0.7121598720550537,
                0.8220210075378418,
                0.781520426273346,
                0.8505673408508301,
                0.7466678023338318,
                0.7909432053565979,
                0.6829466819763184,
                0.8800466656684875
            ],
            [
                0.8058776259422302,
                0.7399358153343201,
                0.6937577128410339,
                0.734167754650116,
                0.7048163414001465,
                0.7581005096435547,
                0.773048996925354,
                0.755135178565979,
                0.7518219947814941,
                0.7536265850067139,
                0.7703174352645874,
                0.5797417759895325,
                0.8357319235801697,
                0.6356942653656006,
                0.7859001755714417,
                0.7568244934082031,
                0.6035827398300171,
                0.7624614238739014,
                0.6300176382064819,
                0.7731735110282898,
                0.615196943283081,
                0.7807546854019165,
                0.5922948122024536,
                0.7558403015136719,
                0.5682839751243591,
                0.778790295124054,
                0.7709084153175354,
                0.613694429397583,
                0.7843461036682129,
                0.802239179611206,
                0.5569757223129272,
                0.812667191028595,
                0.7241019010543823,
                0.7599532008171082,
                0.7216565608978271,
                0.7786176800727844,
                0.839766800403595,
                0.8218408823013306,
                0.8190152049064636,
                0.7642695307731628,
                0.7930929064750671,
                0.6548661589622498,
                0.8356750011444092,
                0.7041969299316406,
                0.7529566884040833,
                0.7507126331329346,
                0.7876054644584656,
                0.7082189321517944,
                0.7352761626243591,
                0.651081919670105,
                0.8185349702835083
            ],
            [
                0.8056228160858154,
                0.852242112159729,
                0.7645379900932312,
                0.8211931586265564,
                0.7577681541442871,
                0.8533127307891846,
                0.8495331406593323,
                0.8237732648849487,
                0.761725902557373,
                0.7587180733680725,
                0.8488225340843201,
                0.6499600410461426,
                0.8732349276542664,
                0.7763064503669739,
                0.8580285310745239,
                0.8411318063735962,
                0.5713896751403809,
                0.7910436987876892,
                0.6314364075660706,
                0.8224058151245117,
                0.5422263741493225,
                0.7782712578773499,
                0.5800353288650513,
                0.7798404097557068,
                0.5584005117416382,
                0.8236037492752075,
                0.825221836566925,
                0.5934633016586304,
                0.8030994534492493,
                0.8711413741111755,
                0.5120633244514465,
                0.860456109046936,
                0.7806066870689392,
                0.7815937399864197,
                0.8540449738502502,
                0.8628693222999573,
                0.8177014589309692,
                0.8162964582443237,
                0.8319429755210876,
                0.8618535995483398,
                0.8649441003799438,
                0.7220820188522339,
                0.860444188117981,
                0.7716040015220642,
                0.8274879455566406,
                0.8614712357521057,
                0.8441615104675293,
                0.8461530804634094,
                0.8036622405052185,
                0.7656767964363098,
                0.8735182285308838
            ],
            [
                0.7688194513320923,
                0.807564914226532,
                0.6561509370803833,
                0.778097927570343,
                0.6647937297821045,
                0.840460479259491,
                0.7738985419273376,
                0.7199257612228394,
                0.7534698843955994,
                0.7494165301322937,
                0.7836816906929016,
                0.768834114074707,
                0.8454158306121826,
                0.8146227598190308,
                0.7956843376159668,
                0.7721298336982727,
                0.5848544836044312,
                0.8134796023368835,
                0.6701592803001404,
                0.8402040004730225,
                0.5441464185714722,
                0.8026738166809082,
                0.5615606307983398,
                0.7964913249015808,
                0.5481017231941223,
                0.7770039439201355,
                0.7949779629707336,
                0.574565589427948,
                0.8126586079597473,
                0.8180992603302002,
                0.5014455914497375,
                0.8207533359527588,
                0.6404045820236206,
                0.7802230715751648,
                0.8187251687049866,
                0.8444867730140686,
                0.8178331851959229,
                0.7922680974006653,
                0.7873847484588623,
                0.8017386198043823,
                0.7794685959815979,
                0.7365701198577881,
                0.8045466542243958,
                0.7379900813102722,
                0.7654043436050415,
                0.8058614730834961,
                0.7707361578941345,
                0.8107671141624451,
                0.7328030467033386,
                0.7842876315116882,
                0.8019385933876038
            ],
            [
                0.737001359462738,
                0.8101004362106323,
                0.654792308807373,
                0.7989026308059692,
                0.6610350012779236,
                0.8210535049438477,
                0.8200495839118958,
                0.7332856059074402,
                0.7377068400382996,
                0.6811097264289856,
                0.8661806583404541,
                0.6790069341659546,
                0.8444738388061523,
                0.793278157711029,
                0.8094998598098755,
                0.7909272313117981,
                0.5489495992660522,
                0.7882829904556274,
                0.6226128935813904,
                0.8003861904144287,
                0.5383739471435547,
                0.7980064153671265,
                0.5903764963150024,
                0.8041552305221558,
                0.562247633934021,
                0.8054699897766113,
                0.8372398614883423,
                0.5526610016822815,
                0.7872737646102905,
                0.8456873297691345,
                0.5043773055076599,
                0.8535077571868896,
                0.6711730360984802,
                0.7204693555831909,
                0.8716921806335449,
                0.850755512714386,
                0.7987618446350098,
                0.7882949709892273,
                0.7917129397392273,
                0.8242496848106384,
                0.8294002413749695,
                0.7667232155799866,
                0.7960234880447388,
                0.7924463748931885,
                0.817755937576294,
                0.8408623337745667,
                0.7892392873764038,
                0.8238518834114075,
                0.7946698665618896,
                0.7460637092590332,
                0.8274385929107666
            ],
            [
                0.7341861128807068,
                0.7524810433387756,
                0.6271756887435913,
                0.7490310668945312,
                0.6410872936248779,
                0.7779579758644104,
                0.7417408227920532,
                0.6968277096748352,
                0.7445002198219299,
                0.7225769758224487,
                0.7562931180000305,
                0.7242814898490906,
                0.8342382311820984,
                0.7513476014137268,
                0.7562797665596008,
                0.7321980595588684,
                0.6411822438240051,
                0.821061909198761,
                0.6216061115264893,
                0.789524257183075,
                0.5489139556884766,
                0.7799462676048279,
                0.5860481262207031,
                0.7856975197792053,
                0.5578402280807495,
                0.7596393823623657,
                0.7768906354904175,
                0.572073221206665,
                0.7899785041809082,
                0.8054723739624023,
                0.5182530283927917,
                0.818212628364563,
                0.6306033730506897,
                0.7466696500778198,
                0.7731893062591553,
                0.7965942025184631,
                0.8010814189910889,
                0.7808608412742615,
                0.7771990299224854,
                0.7515555024147034,
                0.7691089510917664,
                0.7004525661468506,
                0.7885384559631348,
                0.702073872089386,
                0.7407093644142151,
                0.7676089406013489,
                0.7565186023712158,
                0.7503640651702881,
                0.7207618951797485,
                0.7264888882637024,
                0.7910367250442505
            ],
            [
                0.702828586101532,
                0.8683341145515442,
                0.6194986701011658,
                0.8305719494819641,
                0.6183568835258484,
                0.8584232926368713,
                0.839887797832489,
                0.6944295167922974,
                0.706056535243988,
                0.6557050943374634,
                0.8577841520309448,
                0.7270523905754089,
                0.8337327837944031,
                0.8288881778717041,
                0.81342613697052,
                0.7962095141410828,
                0.51630699634552,
                0.7874189019203186,
                0.5569980144500732,
                0.7828448414802551,
                0.48034030199050903,
                0.7916232943534851,
                0.5401314496994019,
                0.7989181876182556,
                0.5232561230659485,
                0.7986345291137695,
                0.8376416563987732,
                0.5019298791885376,
                0.7729357481002808,
                0.8511091470718384,
                0.43509039282798767,
                0.8581907749176025,
                0.6146519184112549,
                0.7054917812347412,
                0.8859524726867676,
                0.8748548030853271,
                0.7703210711479187,
                0.7565475106239319,
                0.76544189453125,
                0.8284465670585632,
                0.8076898455619812,
                0.7851028442382812,
                0.7665326595306396,
                0.8099167346954346,
                0.8370397686958313,
                0.8722541928291321,
                0.7935362458229065,
                0.8529871702194214,
                0.8227974772453308,
                0.7930903434753418,
                0.8335806131362915
            ],
            [
                0.7269145846366882,
                0.7719396948814392,
                0.6173071265220642,
                0.8763365745544434,
                0.6355879306793213,
                0.7864323258399963,
                0.9163349866867065,
                0.6845242977142334,
                0.667500913143158,
                0.6776627898216248,
                0.8307538032531738,
                0.6398616433143616,
                0.8928058743476868,
                0.6989657878875732,
                0.9143440127372742,
                0.8903700113296509,
                0.47767212986946106,
                0.7577288746833801,
                0.49423807859420776,
                0.7576901316642761,
                0.41522568464279175,
                0.7463451027870178,
                0.46909454464912415,
                0.7504722476005554,
                0.46076440811157227,
                0.8120630383491516,
                0.8461153507232666,
                0.4682658016681671,
                0.7515803575515747,
                0.9121310710906982,
                0.37454235553741455,
                0.9092611074447632,
                0.6703008413314819,
                0.728166937828064,
                0.7776986360549927,
                0.8249608874320984,
                0.7569952011108398,
                0.7830005884170532,
                0.8381949067115784,
                0.7897652983665466,
                0.8558599352836609,
                0.6269198656082153,
                0.8018471598625183,
                0.7442314028739929,
                0.913973867893219,
                0.7927669882774353,
                0.8926107883453369,
                0.7683754563331604,
                0.8923481702804565,
                0.6819466352462769,
                0.9288498163223267
            ],
            [
                0.777163028717041,
                0.7084332704544067,
                0.7011702060699463,
                0.7753414511680603,
                0.7087193727493286,
                0.7410736680030823,
                0.8356925845146179,
                0.7576523423194885,
                0.7296921610832214,
                0.7581980228424072,
                0.7778909206390381,
                0.5718297958374023,
                0.8368538618087769,
                0.6356511116027832,
                0.8311477899551392,
                0.8155347108840942,
                0.5244712233543396,
                0.7282086610794067,
                0.5777190327644348,
                0.7535557150840759,
                0.527222216129303,
                0.7406890988349915,
                0.5442895293235779,
                0.7226688861846924,
                0.5178238749504089,
                0.7826550602912903,
                0.7868568301200867,
                0.544916033744812,
                0.7427417635917664,
                0.8444276452064514,
                0.46784910559654236,
                0.8383309841156006,
                0.7526609301567078,
                0.7670565247535706,
                0.7158626317977905,
                0.782390296459198,
                0.8203328847885132,
                0.8513380289077759,
                0.8222152590751648,
                0.7685902714729309,
                0.8585481643676758,
                0.6362184882164001,
                0.8359555602073669,
                0.7300663590431213,
                0.8144580125808716,
                0.7187837958335876,
                0.8349424600601196,
                0.7361754775047302,
                0.779586911201477,
                0.6536436676979065,
                0.8475219011306763
            ],
            [
                0.7177092432975769,
                0.7805213332176208,
                0.6379042267799377,
                0.7706077694892883,
                0.6444797515869141,
                0.8218466639518738,
                0.7801201343536377,
                0.6864060163497925,
                0.7318110466003418,
                0.723520040512085,
                0.7903963327407837,
                0.7326310276985168,
                0.8014931678771973,
                0.7511035799980164,
                0.7715847492218018,
                0.7506975531578064,
                0.5955734848976135,
                0.8506177663803101,
                0.6280226707458496,
                0.8469837307929993,
                0.5640960335731506,
                0.8514923453330994,
                0.5655218958854675,
                0.833433985710144,
                0.5614377856254578,
                0.8061234354972839,
                0.8202981352806091,
                0.5711069107055664,
                0.8470622301101685,
                0.8208685517311096,
                0.5146075487136841,
                0.8430523872375488,
                0.6190767884254456,
                0.7631012201309204,
                0.7633872032165527,
                0.8305993676185608,
                0.8410810232162476,
                0.7892787456512451,
                0.7990567684173584,
                0.7740655541419983,
                0.7928251624107361,
                0.7247068881988525,
                0.8014969825744629,
                0.744486391544342,
                0.7872084379196167,
                0.7913070917129517,
                0.800176203250885,
                0.767210841178894,
                0.7713415026664734,
                0.7509341835975647,
                0.804168701171875
            ],
            [
                0.7040610909461975,
                0.8770835399627686,
                0.5850005149841309,
                0.7607696652412415,
                0.5804955959320068,
                0.8745630383491516,
                0.7847030758857727,
                0.6324288845062256,
                0.6907228231430054,
                0.6339688301086426,
                0.8183488845825195,
                0.7390811443328857,
                0.8040717840194702,
                0.8743931651115417,
                0.7670923471450806,
                0.7466678619384766,
                0.5155986547470093,
                0.7915952205657959,
                0.5665942430496216,
                0.7867024540901184,
                0.5109739303588867,
                0.8018954396247864,
                0.5322657823562622,
                0.7850934863090515,
                0.519405722618103,
                0.7669621706008911,
                0.8021633625030518,
                0.5023199915885925,
                0.775787889957428,
                0.8104394674301147,
                0.4386858344078064,
                0.8223584890365601,
                0.5507436990737915,
                0.699311375617981,
                0.8834661245346069,
                0.9087044596672058,
                0.7625569105148315,
                0.7439668774604797,
                0.7255686521530151,
                0.8301447033882141,
                0.757398247718811,
                0.7976027131080627,
                0.7342621684074402,
                0.7945479154586792,
                0.7845062613487244,
                0.8796691298484802,
                0.7522186040878296,
                0.868389368057251,
                0.7641714215278625,
                0.8226150870323181,
                0.7889603972434998
            ],
            [
                0.750882089138031,
                0.7449168562889099,
                0.6227648258209229,
                0.7563542127609253,
                0.6418859958648682,
                0.768663763999939,
                0.7619449496269226,
                0.6861321330070496,
                0.7201730608940125,
                0.719535231590271,
                0.7763481736183167,
                0.6426686644554138,
                0.8181463479995728,
                0.6833294034004211,
                0.7599499225616455,
                0.7366902828216553,
                0.5533318519592285,
                0.756645917892456,
                0.5974834561347961,
                0.7620092630386353,
                0.5759647488594055,
                0.8009853363037109,
                0.5500601530075073,
                0.7658167481422424,
                0.5200626254081726,
                0.7622843384742737,
                0.770639955997467,
                0.5394521951675415,
                0.7639907002449036,
                0.7838869094848633,
                0.48604628443717957,
                0.8063980340957642,
                0.6433336734771729,
                0.745895266532898,
                0.7400282621383667,
                0.7941994667053223,
                0.8412166833877563,
                0.8282742500305176,
                0.7848925590515137,
                0.7348461747169495,
                0.7601532340049744,
                0.6888530254364014,
                0.7874061465263367,
                0.6900610327720642,
                0.7443026900291443,
                0.7577002644538879,
                0.7499780654907227,
                0.7319647669792175,
                0.7277388572692871,
                0.6715269088745117,
                0.7848384380340576
            ],
            [
                0.6747557520866394,
                0.8223001956939697,
                0.597511351108551,
                0.8125030994415283,
                0.603051483631134,
                0.8334749341011047,
                0.8226078152656555,
                0.6693892478942871,
                0.6670739054679871,
                0.6309565305709839,
                0.8502758741378784,
                0.7202688455581665,
                0.8227715492248535,
                0.8296376466751099,
                0.8029938340187073,
                0.7892618775367737,
                0.4795294404029846,
                0.7692347764968872,
                0.5317767262458801,
                0.7641604542732239,
                0.4439292252063751,
                0.7635282278060913,
                0.4895220398902893,
                0.7644046545028687,
                0.4763137698173523,
                0.7630776166915894,
                0.8376436829566956,
                0.4600084125995636,
                0.7466737031936646,
                0.8311450481414795,
                0.38708120584487915,
                0.8420443534851074,
                0.6082682013511658,
                0.6973379850387573,
                0.8479600548744202,
                0.8817459344863892,
                0.741399884223938,
                0.7512776851654053,
                0.7554502487182617,
                0.7882752418518066,
                0.7878972291946411,
                0.7052127122879028,
                0.7300122380256653,
                0.7805086970329285,
                0.8415762186050415,
                0.8272038698196411,
                0.7869352102279663,
                0.8189626932144165,
                0.7972159385681152,
                0.7607588768005371,
                0.8223453164100647
            ],
            [
                0.7227182984352112,
                0.7788074612617493,
                0.630275309085846,
                0.7774860858917236,
                0.6424537301063538,
                0.7990989685058594,
                0.7675696611404419,
                0.7030851244926453,
                0.7531106472015381,
                0.7214382290840149,
                0.770392656326294,
                0.7250021696090698,
                0.8266812562942505,
                0.7436034679412842,
                0.7647884488105774,
                0.7408312559127808,
                0.5685827732086182,
                0.7946482300758362,
                0.5817520022392273,
                0.7905375361442566,
                0.5023850798606873,
                0.7845220565795898,
                0.5790703892707825,
                0.8048632740974426,
                0.5393688678741455,
                0.7691310048103333,
                0.7866640686988831,
                0.5428988337516785,
                0.7913313508033752,
                0.8236244916915894,
                0.4763631820678711,
                0.8273849487304688,
                0.6280003190040588,
                0.757656455039978,
                0.7858192324638367,
                0.7871814370155334,
                0.8103361129760742,
                0.7686347961425781,
                0.7742134928703308,
                0.7645341157913208,
                0.7841348648071289,
                0.714865505695343,
                0.7969070672988892,
                0.7191226482391357,
                0.7608258724212646,
                0.8027430176734924,
                0.76826411485672,
                0.7667969465255737,
                0.7453137040138245,
                0.7589791417121887,
                0.8116768598556519
            ],
            [
                0.7651165127754211,
                0.7547112703323364,
                0.6702562570571899,
                0.7737972140312195,
                0.6840746998786926,
                0.7662873268127441,
                0.7492778897285461,
                0.715360164642334,
                0.7622755765914917,
                0.755048394203186,
                0.7370109558105469,
                0.6624426245689392,
                0.8190026879310608,
                0.6861252188682556,
                0.7629081010818481,
                0.7379895448684692,
                0.5800847411155701,
                0.7607145309448242,
                0.6182252168655396,
                0.7831087708473206,
                0.5505692958831787,
                0.774352490901947,
                0.6111764907836914,
                0.785049557685852,
                0.5454630255699158,
                0.7742651104927063,
                0.7662304639816284,
                0.5844975709915161,
                0.7814961671829224,
                0.8049586415290833,
                0.520753026008606,
                0.8021544814109802,
                0.6730193495750427,
                0.7797077298164368,
                0.7621451020240784,
                0.7565288543701172,
                0.8423600196838379,
                0.7942862510681152,
                0.7865938544273376,
                0.754656970500946,
                0.774961531162262,
                0.6934111714363098,
                0.8291609883308411,
                0.6597821116447449,
                0.723443865776062,
                0.7863421440124512,
                0.7538406848907471,
                0.7471945285797119,
                0.7133354544639587,
                0.700128972530365,
                0.7982380390167236
            ],
            [
                0.6762358546257019,
                0.7727250456809998,
                0.5935091972351074,
                0.6951309442520142,
                0.5992441773414612,
                0.7781746983528137,
                0.730894923210144,
                0.6481155753135681,
                0.6857160925865173,
                0.5845183730125427,
                0.8131791949272156,
                0.6373570561408997,
                0.7645715475082397,
                0.7652567028999329,
                0.7063078880310059,
                0.6973475813865662,
                0.5139293074607849,
                0.7662932872772217,
                0.5637985467910767,
                0.7531898617744446,
                0.5278764963150024,
                0.7883412837982178,
                0.6143625378608704,
                0.8072229027748108,
                0.5293910503387451,
                0.7565467357635498,
                0.7901490330696106,
                0.5128541588783264,
                0.7625442147254944,
                0.7651584148406982,
                0.4754343032836914,
                0.7783706188201904,
                0.5902109742164612,
                0.6327470541000366,
                0.8403862714767456,
                0.8175001740455627,
                0.7400769591331482,
                0.7116629481315613,
                0.6907511949539185,
                0.7709990739822388,
                0.7413687109947205,
                0.7813931703567505,
                0.7027641534805298,
                0.7933170795440674,
                0.7377138733863831,
                0.7986681461334229,
                0.7027757167816162,
                0.7866331934928894,
                0.7307432293891907,
                0.7278186082839966,
                0.7433120608329773
            ],
            [
                0.7015370726585388,
                0.8639145493507385,
                0.6285932064056396,
                0.7932994365692139,
                0.6242743730545044,
                0.8668721914291382,
                0.8188715577125549,
                0.7017986178398132,
                0.6974470019340515,
                0.6650825142860413,
                0.8275839686393738,
                0.7201244235038757,
                0.8215838670730591,
                0.8468044996261597,
                0.7905964255332947,
                0.771958589553833,
                0.49988797307014465,
                0.7780640125274658,
                0.5381304025650024,
                0.7731989026069641,
                0.45082274079322815,
                0.7624064087867737,
                0.5106722116470337,
                0.773572564125061,
                0.49045854806900024,
                0.7640094757080078,
                0.8271957635879517,
                0.4800172746181488,
                0.7617571353912354,
                0.8422929048538208,
                0.4111885130405426,
                0.8425416946411133,
                0.6205618381500244,
                0.7159245014190674,
                0.8858802318572998,
                0.8813861608505249,
                0.7669758200645447,
                0.7561508417129517,
                0.7652081251144409,
                0.8172276616096497,
                0.8061189651489258,
                0.7451985478401184,
                0.764901876449585,
                0.8085923194885254,
                0.8289268016815186,
                0.8595081567764282,
                0.7879560589790344,
                0.8469295501708984,
                0.7923611998558044,
                0.7935253381729126,
                0.8241707682609558
            ],
            [
                0.8348460793495178,
                0.7415143847465515,
                0.7235360145568848,
                0.7471165657043457,
                0.7404447197914124,
                0.7700904607772827,
                0.7971142530441284,
                0.7614855170249939,
                0.7909237742424011,
                0.8067525029182434,
                0.7627816200256348,
                0.6127274632453918,
                0.8616408705711365,
                0.6686315536499023,
                0.824648380279541,
                0.7968086004257202,
                0.5976195931434631,
                0.7715528607368469,
                0.6341041922569275,
                0.7938328385353088,
                0.5857077240943909,
                0.77699875831604,
                0.5888512134552002,
                0.7610524296760559,
                0.572387158870697,
                0.7982975840568542,
                0.7848827838897705,
                0.6189119815826416,
                0.7974663376808167,
                0.8345076441764832,
                0.5620709657669067,
                0.830132782459259,
                0.7453773021697998,
                0.8125548958778381,
                0.7378268837928772,
                0.7920584678649902,
                0.8444635272026062,
                0.8405797481536865,
                0.8524979948997498,
                0.7961156964302063,
                0.8452234864234924,
                0.6917614936828613,
                0.8696274161338806,
                0.7094904780387878,
                0.7791194915771484,
                0.7612095475196838,
                0.8193622827529907,
                0.7523906230926514,
                0.7480767369270325,
                0.6873094439506531,
                0.8494235277175903
            ],
            [
                0.780704140663147,
                0.8830459713935852,
                0.7204315066337585,
                0.8435602188110352,
                0.7169438004493713,
                0.873538613319397,
                0.8657635450363159,
                0.7732060551643372,
                0.725188136100769,
                0.7165590524673462,
                0.8789818286895752,
                0.6630016565322876,
                0.8797533512115479,
                0.7848023176193237,
                0.8519981503486633,
                0.8320967555046082,
                0.5531438589096069,
                0.807961106300354,
                0.5888960957527161,
                0.8206396698951721,
                0.5170616507530212,
                0.7990676760673523,
                0.5507737398147583,
                0.7955344319343567,
                0.5307716727256775,
                0.8178671002388,
                0.8297340869903564,
                0.5610834956169128,
                0.8140761852264404,
                0.8767148852348328,
                0.48592671751976013,
                0.8732245564460754,
                0.7167163491249084,
                0.7423407435417175,
                0.8566845059394836,
                0.8749036192893982,
                0.8002387881278992,
                0.7836029529571533,
                0.8155698180198669,
                0.8677301406860352,
                0.862440824508667,
                0.7647351026535034,
                0.8319190740585327,
                0.8093425631523132,
                0.8544061779975891,
                0.8780142068862915,
                0.8461775779724121,
                0.8516154885292053,
                0.8401077389717102,
                0.7685908079147339,
                0.8785260915756226
            ],
            [
                0.7671521902084351,
                0.7592735886573792,
                0.6949830055236816,
                0.7145076990127563,
                0.6999051570892334,
                0.770104706287384,
                0.7537453770637512,
                0.7680326104164124,
                0.777866780757904,
                0.7288269996643066,
                0.7605274319648743,
                0.5813181400299072,
                0.8009249567985535,
                0.6518344879150391,
                0.7500734329223633,
                0.7238513827323914,
                0.6127996444702148,
                0.7560506463050842,
                0.6173163056373596,
                0.752422571182251,
                0.5901103019714355,
                0.7524057626724243,
                0.6115598678588867,
                0.7508278489112854,
                0.5832867622375488,
                0.7519349455833435,
                0.7499880790710449,
                0.6185492277145386,
                0.7672349810600281,
                0.7803114056587219,
                0.5812440514564514,
                0.7881534695625305,
                0.706020712852478,
                0.7455450892448425,
                0.7517495155334473,
                0.7588095664978027,
                0.7933229207992554,
                0.7653255462646484,
                0.784934937953949,
                0.7909770607948303,
                0.7999180555343628,
                0.7365622520446777,
                0.8170033097267151,
                0.7582029700279236,
                0.7515590190887451,
                0.755850613117218,
                0.7560474872589111,
                0.7121747136116028,
                0.7307276129722595,
                0.6981256008148193,
                0.7881565093994141
            ]
        ],
        [
            [
                0.7927546501159668,
                0.7856319546699524,
                0.8619062900543213,
                0.7546356916427612,
                0.7402332425117493,
                0.7141273617744446,
                0.6043496131896973,
                0.7408726215362549,
                0.5990200638771057,
                0.705714225769043,
                0.7041050791740417,
                0.7122175693511963,
                0.6008291244506836,
                0.6720082759857178,
                0.7626298069953918,
                0.7564759254455566,
                0.8465697169303894,
                0.7918611168861389,
                0.7567055821418762,
                0.8011438846588135,
                0.7586509585380554,
                0.7632348537445068,
                0.7632444500923157,
                0.7621469497680664,
                0.8038598895072937,
                0.7600222826004028,
                0.6962270736694336,
                0.8077987432479858,
                0.7152042388916016,
                0.7493953704833984,
                0.76680588722229,
                0.8078644275665283,
                0.7873144149780273,
                0.7429273128509521,
                0.7554498314857483,
                0.7348077893257141,
                0.6950204968452454,
                0.7582350373268127,
                0.6747092604637146,
                0.7262297868728638,
                0.740236759185791,
                0.7624645233154297,
                0.7520050406455994,
                0.5380393266677856,
                0.7512414455413818,
                0.7906174063682556,
                0.5617671608924866,
                0.7371618747711182,
                0.8468283414840698,
                0.7355000376701355,
                0.78695148229599
            ],
            [
                0.7086775898933411,
                0.7171878218650818,
                0.7682921290397644,
                0.7136206030845642,
                0.7258039116859436,
                0.7957020998001099,
                0.5782619714736938,
                0.7053338885307312,
                0.6041855216026306,
                0.7322676181793213,
                0.685104489326477,
                0.6923998594284058,
                0.5172251462936401,
                0.6537922620773315,
                0.6633849143981934,
                0.8536466360092163,
                0.7177518010139465,
                0.6525260210037231,
                0.7781476974487305,
                0.6700524687767029,
                0.6426402926445007,
                0.8537389039993286,
                0.6160143613815308,
                0.8787134289741516,
                0.6572055220603943,
                0.6555326581001282,
                0.6942898035049438,
                0.7063857316970825,
                0.737738311290741,
                0.6862741112709045,
                0.8204836845397949,
                0.712466299533844,
                0.8652902841567993,
                0.6654345393180847,
                0.8518707752227783,
                0.698390781879425,
                0.6345450282096863,
                0.8506190776824951,
                0.6030685305595398,
                0.6598504781723022,
                0.7207438349723816,
                0.6713411808013916,
                0.8056037425994873,
                0.501472532749176,
                0.7763638496398926,
                0.7125712633132935,
                0.540995717048645,
                0.7524123787879944,
                0.7429299354553223,
                0.7654789686203003,
                0.617103636264801
            ],
            [
                0.7763049602508545,
                0.7954100966453552,
                0.8502341508865356,
                0.7689894437789917,
                0.7606467008590698,
                0.7897184491157532,
                0.6713364124298096,
                0.7745896577835083,
                0.6279313564300537,
                0.8057441115379333,
                0.7240563631057739,
                0.7251893877983093,
                0.6251834630966187,
                0.711499810218811,
                0.7523541450500488,
                0.8486155867576599,
                0.8619725108146667,
                0.7486850023269653,
                0.7901041507720947,
                0.765150249004364,
                0.7509607672691345,
                0.8417491912841797,
                0.7343254089355469,
                0.8418571949005127,
                0.7688882350921631,
                0.7769762277603149,
                0.7400909066200256,
                0.8087179064750671,
                0.7646404504776001,
                0.7891324758529663,
                0.8328185081481934,
                0.8465682864189148,
                0.8675622940063477,
                0.808937132358551,
                0.8550371527671814,
                0.7836093902587891,
                0.7531254291534424,
                0.8552067875862122,
                0.6840949654579163,
                0.7376148700714111,
                0.7679493427276611,
                0.754135251045227,
                0.7961797118186951,
                0.5915622711181641,
                0.8236825466156006,
                0.851762056350708,
                0.612982451915741,
                0.7907348871231079,
                0.8608328104019165,
                0.7927417755126953,
                0.7291434407234192
            ],
            [
                0.7592602372169495,
                0.7925810813903809,
                0.8136197924613953,
                0.8328607678413391,
                0.8714364767074585,
                0.8212539553642273,
                0.6063687205314636,
                0.7954320907592773,
                0.5671497583389282,
                0.7454524636268616,
                0.7766425013542175,
                0.7765733599662781,
                0.595218300819397,
                0.7479820251464844,
                0.68916255235672,
                0.8476033806800842,
                0.7782983183860779,
                0.7372574210166931,
                0.8503476977348328,
                0.7136218547821045,
                0.7058942317962646,
                0.8739787340164185,
                0.6733782291412354,
                0.8869863748550415,
                0.7237458825111389,
                0.6776409149169922,
                0.7336847186088562,
                0.7710968852043152,
                0.7493727207183838,
                0.7663354873657227,
                0.8969440460205078,
                0.7925448417663574,
                0.8996008634567261,
                0.6915932893753052,
                0.8631482720375061,
                0.7380495667457581,
                0.6665817499160767,
                0.8602273464202881,
                0.6152573227882385,
                0.7447073459625244,
                0.8028256893157959,
                0.7586774826049805,
                0.8494217395782471,
                0.602215588092804,
                0.8405067920684814,
                0.7312660813331604,
                0.6407209634780884,
                0.8366649150848389,
                0.7637491226196289,
                0.8410900831222534,
                0.6531467437744141
            ],
            [
                0.8643336892127991,
                0.7805957198143005,
                0.7388715147972107,
                0.815678060054779,
                0.8897449970245361,
                0.8364258408546448,
                0.6746921539306641,
                0.8680148124694824,
                0.6325823664665222,
                0.7202475666999817,
                0.9105556607246399,
                0.9067720174789429,
                0.6549222469329834,
                0.8850978016853333,
                0.7134625315666199,
                0.8392284512519836,
                0.7247509360313416,
                0.7642872929573059,
                0.9126830101013184,
                0.7461659908294678,
                0.7007523775100708,
                0.873784065246582,
                0.681525707244873,
                0.8646636605262756,
                0.6957747340202332,
                0.6759936809539795,
                0.8059636950492859,
                0.8025113344192505,
                0.8061949014663696,
                0.7345412373542786,
                0.927539587020874,
                0.7609498500823975,
                0.8862642049789429,
                0.6807693243026733,
                0.8493745923042297,
                0.7123157382011414,
                0.6519060134887695,
                0.8484470248222351,
                0.6238357424736023,
                0.7768233418464661,
                0.8813834190368652,
                0.7817953824996948,
                0.9070267081260681,
                0.6484650373458862,
                0.8851902484893799,
                0.6766677498817444,
                0.6729768514633179,
                0.9067318439483643,
                0.7332279682159424,
                0.9216057658195496,
                0.704086184501648
            ],
            [
                0.8229992389678955,
                0.7988872528076172,
                0.7834596633911133,
                0.7768494486808777,
                0.81791090965271,
                0.928322434425354,
                0.6906289458274841,
                0.8225796818733215,
                0.6958572268486023,
                0.7596866488456726,
                0.8449237942695618,
                0.8454487919807434,
                0.5830681324005127,
                0.8232651352882385,
                0.7203207612037659,
                0.9004905223846436,
                0.744225025177002,
                0.7285541892051697,
                0.87872314453125,
                0.7312273383140564,
                0.6923798322677612,
                0.9058879017829895,
                0.672372043132782,
                0.91963130235672,
                0.7100110650062561,
                0.7057617902755737,
                0.7882662415504456,
                0.7798632979393005,
                0.820340096950531,
                0.749051034450531,
                0.909131646156311,
                0.7730377912521362,
                0.9093858003616333,
                0.7090820670127869,
                0.8979829549789429,
                0.7290233373641968,
                0.683078408241272,
                0.8996883034706116,
                0.6452404260635376,
                0.748084306716919,
                0.8440144062042236,
                0.7562513947486877,
                0.8837825059890747,
                0.5911321043968201,
                0.8767687082290649,
                0.7385822534561157,
                0.6208727359771729,
                0.8826882243156433,
                0.7879841923713684,
                0.8781560063362122,
                0.6777223348617554
            ],
            [
                0.7434967756271362,
                0.7723421454429626,
                0.8277687430381775,
                0.7544517517089844,
                0.7311002016067505,
                0.7234681248664856,
                0.7121375799179077,
                0.7375482320785522,
                0.6720737814903259,
                0.7390695810317993,
                0.7274622321128845,
                0.7250894904136658,
                0.6448541879653931,
                0.7276153564453125,
                0.8180853724479675,
                0.7828971147537231,
                0.8696410059928894,
                0.8174217939376831,
                0.7737268209457397,
                0.8752116560935974,
                0.8046289682388306,
                0.7674271464347839,
                0.7408084869384766,
                0.7567359209060669,
                0.8290697932243347,
                0.7658108472824097,
                0.7368512749671936,
                0.831855058670044,
                0.7477594614028931,
                0.8006845116615295,
                0.7624553442001343,
                0.8517823815345764,
                0.7673245668411255,
                0.8241471648216248,
                0.7755998969078064,
                0.8241087794303894,
                0.7825681567192078,
                0.7704519629478455,
                0.7305434942245483,
                0.8012824058532715,
                0.7664110064506531,
                0.8092778921127319,
                0.7425113320350647,
                0.6925885677337646,
                0.752643346786499,
                0.7792308926582336,
                0.7010383605957031,
                0.7343519330024719,
                0.842999279499054,
                0.7279050946235657,
                0.7474409937858582
            ],
            [
                0.8157367706298828,
                0.7604268789291382,
                0.786130964756012,
                0.8250853419303894,
                0.8252928256988525,
                0.8362021446228027,
                0.6673269271850586,
                0.8770748972892761,
                0.6333038210868835,
                0.730338454246521,
                0.8424679040908813,
                0.858778715133667,
                0.6087263822555542,
                0.8097880482673645,
                0.7346728444099426,
                0.8551485538482666,
                0.7775726318359375,
                0.8138688802719116,
                0.8663524389266968,
                0.778796911239624,
                0.732683539390564,
                0.8593180179595947,
                0.7327467203140259,
                0.8683322668075562,
                0.7133396863937378,
                0.6866070628166199,
                0.7934738397598267,
                0.8439477682113647,
                0.8382983207702637,
                0.8012082576751709,
                0.8971403241157532,
                0.7840955853462219,
                0.8866480588912964,
                0.726060152053833,
                0.8504278063774109,
                0.7368965744972229,
                0.6550763845443726,
                0.8543306589126587,
                0.6114850044250488,
                0.8009815812110901,
                0.8551232218742371,
                0.760736346244812,
                0.8914435505867004,
                0.5549910068511963,
                0.8685088157653809,
                0.7248638868331909,
                0.5803785920143127,
                0.8845091462135315,
                0.8106130957603455,
                0.8713947534561157,
                0.7909682989120483
            ],
            [
                0.8476446270942688,
                0.7770287990570068,
                0.7542970180511475,
                0.8663394451141357,
                0.871703565120697,
                0.8277414441108704,
                0.7231865525245667,
                0.8851180076599121,
                0.6736153364181519,
                0.7411829829216003,
                0.8964986205101013,
                0.8981044888496399,
                0.670184850692749,
                0.8793994188308716,
                0.7152504920959473,
                0.8762029409408569,
                0.7589082717895508,
                0.7966639399528503,
                0.9265493154525757,
                0.7702627182006836,
                0.7114954590797424,
                0.8935844302177429,
                0.7318134307861328,
                0.8628441691398621,
                0.7089422941207886,
                0.6684551239013672,
                0.8245545625686646,
                0.8440981507301331,
                0.8472309112548828,
                0.7925373911857605,
                0.9242062568664551,
                0.8016892075538635,
                0.8859685659408569,
                0.7062655687332153,
                0.8805772662162781,
                0.7802304625511169,
                0.6538545489311218,
                0.8773130178451538,
                0.6019659638404846,
                0.8095391392707825,
                0.9098369479179382,
                0.7966877818107605,
                0.917161762714386,
                0.6387444734573364,
                0.9001352190971375,
                0.7434499859809875,
                0.6612480878829956,
                0.91428542137146,
                0.8180009722709656,
                0.908389151096344,
                0.7469249367713928
            ],
            [
                0.7923014760017395,
                0.7195467948913574,
                0.7517064213752747,
                0.7755730748176575,
                0.7662273049354553,
                0.7851783633232117,
                0.6634983420372009,
                0.8119121789932251,
                0.6406251192092896,
                0.7320849895477295,
                0.7858058214187622,
                0.7886344194412231,
                0.6119856834411621,
                0.7912168502807617,
                0.6914599537849426,
                0.8657948970794678,
                0.7444798350334167,
                0.7202228903770447,
                0.834452748298645,
                0.7175977230072021,
                0.6584400534629822,
                0.8607445955276489,
                0.6985918283462524,
                0.8498274087905884,
                0.653560996055603,
                0.6967289447784424,
                0.7860278487205505,
                0.8067286610603333,
                0.8119351267814636,
                0.787360668182373,
                0.8647905588150024,
                0.7982751131057739,
                0.8725124597549438,
                0.7111546993255615,
                0.8633981943130493,
                0.7486765384674072,
                0.6582843661308289,
                0.8639339208602905,
                0.6100316047668457,
                0.7705332040786743,
                0.8134790658950806,
                0.7377550601959229,
                0.8437775373458862,
                0.5753812789916992,
                0.8688411712646484,
                0.7384669184684753,
                0.5922600030899048,
                0.8512355089187622,
                0.797210156917572,
                0.8502147793769836,
                0.6903545260429382
            ],
            [
                0.7524667382240295,
                0.8066694736480713,
                0.8627182841300964,
                0.7298777103424072,
                0.7475644946098328,
                0.814815104007721,
                0.6802026629447937,
                0.745983898639679,
                0.6552201509475708,
                0.8333801627159119,
                0.7415032982826233,
                0.7458639144897461,
                0.611690878868103,
                0.746957540512085,
                0.7489079833030701,
                0.8826782703399658,
                0.8326007723808289,
                0.742890477180481,
                0.804546594619751,
                0.778582751750946,
                0.7440991401672363,
                0.8653071522712708,
                0.6621514558792114,
                0.8759684562683105,
                0.7454036474227905,
                0.762789249420166,
                0.7636501789093018,
                0.8201875686645508,
                0.7955999374389648,
                0.8307951092720032,
                0.8560779094696045,
                0.8503761291503906,
                0.8922983407974243,
                0.8206353783607483,
                0.888740599155426,
                0.8189647793769836,
                0.7698405981063843,
                0.8810997605323792,
                0.7020703554153442,
                0.7772494554519653,
                0.7623929381370544,
                0.7833982110023499,
                0.8237919807434082,
                0.6870005130767822,
                0.8476133942604065,
                0.8277419805526733,
                0.6960211396217346,
                0.8105034232139587,
                0.8363837599754333,
                0.8158283233642578,
                0.6562594771385193
            ],
            [
                0.8444891571998596,
                0.7475115060806274,
                0.7287759780883789,
                0.8088945150375366,
                0.8538445234298706,
                0.8041037321090698,
                0.6802290678024292,
                0.8760275840759277,
                0.6368511319160461,
                0.7000410556793213,
                0.8770129084587097,
                0.8803711533546448,
                0.6503012180328369,
                0.8573707938194275,
                0.7201601266860962,
                0.8197875618934631,
                0.7467660903930664,
                0.7796491384506226,
                0.8796319961547852,
                0.7564115524291992,
                0.6986883282661438,
                0.8375067114830017,
                0.7234998941421509,
                0.8286312818527222,
                0.7028314471244812,
                0.6804744601249695,
                0.8198409676551819,
                0.8267567753791809,
                0.8268541097640991,
                0.7616682648658752,
                0.8893851637840271,
                0.7916063070297241,
                0.8499664664268494,
                0.71212238073349,
                0.8237447738647461,
                0.7301161885261536,
                0.6397913694381714,
                0.8201875686645508,
                0.6012055277824402,
                0.8094323873519897,
                0.8669408559799194,
                0.7721617221832275,
                0.8803557753562927,
                0.6123132109642029,
                0.8667430281639099,
                0.6948468685150146,
                0.638126790523529,
                0.8900138139724731,
                0.7755966782569885,
                0.8891701102256775,
                0.7579028606414795
            ],
            [
                0.7720752954483032,
                0.7733165621757507,
                0.8473183512687683,
                0.8681679964065552,
                0.808319628238678,
                0.7945075035095215,
                0.6524921655654907,
                0.8363994359970093,
                0.6165878772735596,
                0.765764594078064,
                0.77219158411026,
                0.7897453904151917,
                0.618148922920227,
                0.7584818601608276,
                0.7351616621017456,
                0.8724995851516724,
                0.8515150547027588,
                0.8122402429580688,
                0.8546850681304932,
                0.7724658250808716,
                0.7387884259223938,
                0.8700202703475952,
                0.7673360705375671,
                0.86513352394104,
                0.7250261306762695,
                0.716211199760437,
                0.7721417546272278,
                0.8604920506477356,
                0.8185489773750305,
                0.8842974305152893,
                0.8972828984260559,
                0.8647707104682922,
                0.9037759900093079,
                0.7587756514549255,
                0.8745624423027039,
                0.8195042610168457,
                0.687512218952179,
                0.8722189664840698,
                0.6380001306533813,
                0.8189935088157654,
                0.8227812647819519,
                0.768171489238739,
                0.8615118861198425,
                0.6049504280090332,
                0.8787689208984375,
                0.8150594830513,
                0.6257484555244446,
                0.857548713684082,
                0.8881202936172485,
                0.8414477109909058,
                0.7693012952804565
            ],
            [
                0.8328182697296143,
                0.8012301921844482,
                0.7988162636756897,
                0.822790801525116,
                0.8438257575035095,
                0.8371224999427795,
                0.6857143044471741,
                0.8410404324531555,
                0.6254720687866211,
                0.7880555987358093,
                0.8435652256011963,
                0.8327980041503906,
                0.6494776010513306,
                0.8263484835624695,
                0.7005090117454529,
                0.9056452512741089,
                0.7911351323127747,
                0.7466294765472412,
                0.901190996170044,
                0.7338071465492249,
                0.6854533553123474,
                0.9216511249542236,
                0.702517569065094,
                0.9243255853652954,
                0.6990159153938293,
                0.7004822492599487,
                0.7953174114227295,
                0.8118867874145508,
                0.8285597562789917,
                0.807247519493103,
                0.9419994950294495,
                0.8142353892326355,
                0.9435886144638062,
                0.7115170955657959,
                0.9122428894042969,
                0.779005765914917,
                0.6668365001678467,
                0.9115471839904785,
                0.6241320967674255,
                0.7466408610343933,
                0.8527812957763672,
                0.7633998394012451,
                0.9185091257095337,
                0.6075994968414307,
                0.9158371686935425,
                0.772629976272583,
                0.6337285041809082,
                0.904297947883606,
                0.8174853324890137,
                0.9149603247642517,
                0.7100684642791748
            ],
            [
                0.8345208764076233,
                0.7787163853645325,
                0.7128437757492065,
                0.7281421422958374,
                0.8112136721611023,
                0.8447381258010864,
                0.6895782947540283,
                0.8542196154594421,
                0.6348376274108887,
                0.7266265749931335,
                0.8397359848022461,
                0.8424748182296753,
                0.596260130405426,
                0.7965460419654846,
                0.7202648520469666,
                0.8191573619842529,
                0.6929306387901306,
                0.7138290405273438,
                0.8304885029792786,
                0.7462688088417053,
                0.701826810836792,
                0.8275227546691895,
                0.6527687907218933,
                0.8314701914787292,
                0.6930839419364929,
                0.6900373101234436,
                0.7837271690368652,
                0.7623748183250427,
                0.8079783320426941,
                0.6907668113708496,
                0.8564500212669373,
                0.7331545352935791,
                0.831562340259552,
                0.7025859355926514,
                0.8122576475143433,
                0.7138946056365967,
                0.6806096434593201,
                0.8118103742599487,
                0.6474114060401917,
                0.7440422177314758,
                0.8194614052772522,
                0.7696511745452881,
                0.8504027128219604,
                0.6044464111328125,
                0.8150708675384521,
                0.6564079523086548,
                0.6294297575950623,
                0.8464531302452087,
                0.6967907547950745,
                0.8549302816390991,
                0.684650719165802
            ],
            [
                0.7238662838935852,
                0.7543179392814636,
                0.7415986657142639,
                0.7546562552452087,
                0.7235631942749023,
                0.700090765953064,
                0.7504497766494751,
                0.7373156547546387,
                0.6710154414176941,
                0.7834903597831726,
                0.6960145235061646,
                0.678950309753418,
                0.6830253601074219,
                0.7163559794425964,
                0.7160360217094421,
                0.8364612460136414,
                0.81069016456604,
                0.691361665725708,
                0.7850023508071899,
                0.7285224795341492,
                0.6956286430358887,
                0.8229768872261047,
                0.7157688140869141,
                0.7701215147972107,
                0.6967411041259766,
                0.7129042148590088,
                0.7700860500335693,
                0.7842853665351868,
                0.7728198766708374,
                0.7807114720344543,
                0.8010801076889038,
                0.8386335372924805,
                0.8091790676116943,
                0.7905840277671814,
                0.8361860513687134,
                0.8172253370285034,
                0.7388277053833008,
                0.8278796672821045,
                0.6557841897010803,
                0.7556803226470947,
                0.7775757312774658,
                0.7598990797996521,
                0.7647362947463989,
                0.6794593930244446,
                0.8014628291130066,
                0.8076281547546387,
                0.6901785135269165,
                0.7663331031799316,
                0.7999622821807861,
                0.7674634456634521,
                0.6682406067848206
            ],
            [
                0.6901395916938782,
                0.74749755859375,
                0.7695096731185913,
                0.7380504012107849,
                0.7155203819274902,
                0.7118630409240723,
                0.7041809558868408,
                0.7105278968811035,
                0.627657413482666,
                0.7758259177207947,
                0.6741052865982056,
                0.6704601049423218,
                0.63764488697052,
                0.6844462156295776,
                0.7019081711769104,
                0.8255736827850342,
                0.8571142554283142,
                0.6957578659057617,
                0.7606194615364075,
                0.7232411503791809,
                0.6940100193023682,
                0.7966761589050293,
                0.7070487141609192,
                0.7786663174629211,
                0.7111016511917114,
                0.710750937461853,
                0.7203859090805054,
                0.7667055130004883,
                0.7662957906723022,
                0.8329454064369202,
                0.7965642809867859,
                0.8640441298484802,
                0.8126615285873413,
                0.7845870852470398,
                0.823603630065918,
                0.8825087547302246,
                0.7151286602020264,
                0.8132548928260803,
                0.6489854454994202,
                0.7237768173217773,
                0.737498939037323,
                0.7188038229942322,
                0.7631046772003174,
                0.6319817900657654,
                0.7945353984832764,
                0.8795232176780701,
                0.6472288370132446,
                0.7523109316825867,
                0.8683412671089172,
                0.748589277267456,
                0.6692351698875427
            ],
            [
                0.8364772796630859,
                0.7860842347145081,
                0.7187803387641907,
                0.7137625217437744,
                0.7988713979721069,
                0.8481128811836243,
                0.687055766582489,
                0.8466964364051819,
                0.6584686636924744,
                0.7381380796432495,
                0.8221551179885864,
                0.8248106837272644,
                0.5855762958526611,
                0.7845791578292847,
                0.7373878359794617,
                0.8274962902069092,
                0.7121968865394592,
                0.7187947034835815,
                0.8217211365699768,
                0.7448810338973999,
                0.7197324633598328,
                0.8308245539665222,
                0.6544153690338135,
                0.8300601243972778,
                0.7004361152648926,
                0.7056177854537964,
                0.7894978523254395,
                0.7678055763244629,
                0.8144722580909729,
                0.7044824361801147,
                0.8525041341781616,
                0.7401675581932068,
                0.8303970098495483,
                0.7294502258300781,
                0.8200033903121948,
                0.7206368446350098,
                0.6989111304283142,
                0.818230390548706,
                0.6612950563430786,
                0.7530456781387329,
                0.8111407160758972,
                0.7662230730056763,
                0.8410876989364624,
                0.6168932318687439,
                0.8179625272750854,
                0.6716692447662354,
                0.6398271322250366,
                0.8454878330230713,
                0.708297073841095,
                0.8464546203613281,
                0.6809363961219788
            ],
            [
                0.7575079202651978,
                0.7619166374206543,
                0.7477500438690186,
                0.7625221014022827,
                0.7411767244338989,
                0.7246390581130981,
                0.7273231148719788,
                0.7797838449478149,
                0.6982353925704956,
                0.7662730813026428,
                0.7254753112792969,
                0.7118966579437256,
                0.6901568174362183,
                0.7424383163452148,
                0.7253990769386292,
                0.8345533609390259,
                0.8228447437286377,
                0.7503315806388855,
                0.8118107318878174,
                0.7390925288200378,
                0.7246204614639282,
                0.8279269337654114,
                0.7654677629470825,
                0.7742794752120972,
                0.6859254240989685,
                0.7083360552787781,
                0.8113337755203247,
                0.8118610382080078,
                0.8164362907409668,
                0.816156268119812,
                0.8194507360458374,
                0.8353506326675415,
                0.8073461651802063,
                0.7675454616546631,
                0.832648515701294,
                0.78151935338974,
                0.7166405320167542,
                0.8297621607780457,
                0.6465029716491699,
                0.7882301807403564,
                0.8148560523986816,
                0.7627885937690735,
                0.8012909293174744,
                0.6721805334091187,
                0.824698269367218,
                0.7940917611122131,
                0.6796393990516663,
                0.7934545278549194,
                0.8179506063461304,
                0.7830333709716797,
                0.7128384113311768
            ],
            [
                0.7740573883056641,
                0.7960328459739685,
                0.794736921787262,
                0.7994678616523743,
                0.794175386428833,
                0.7899200916290283,
                0.6858546733856201,
                0.8231341242790222,
                0.6319485902786255,
                0.790278971195221,
                0.7512674927711487,
                0.7530971169471741,
                0.6530614495277405,
                0.7441207766532898,
                0.7344225645065308,
                0.8741635680198669,
                0.8695580363273621,
                0.7532498240470886,
                0.8437438607215881,
                0.7484802007675171,
                0.7343463897705078,
                0.8613542318344116,
                0.7315194010734558,
                0.8429739475250244,
                0.7244306802749634,
                0.7221246957778931,
                0.778832197189331,
                0.818954348564148,
                0.8318479061126709,
                0.8750928044319153,
                0.8810343146324158,
                0.8814530372619629,
                0.8809193968772888,
                0.778339147567749,
                0.8717215657234192,
                0.8824966549873352,
                0.7024189829826355,
                0.8623387217521667,
                0.6548486351966858,
                0.7900984883308411,
                0.810596764087677,
                0.7497913837432861,
                0.8489299416542053,
                0.6415966749191284,
                0.857200026512146,
                0.8279500007629395,
                0.6656519174575806,
                0.8296542167663574,
                0.8599927425384521,
                0.8306857347488403,
                0.7039476633071899
            ],
            [
                0.7726905941963196,
                0.7914944887161255,
                0.7456767559051514,
                0.7977944016456604,
                0.794413685798645,
                0.7469666004180908,
                0.7056647539138794,
                0.8226391077041626,
                0.6877509951591492,
                0.7491039633750916,
                0.7792038917541504,
                0.7610326409339905,
                0.6821942925453186,
                0.7540364861488342,
                0.7139701247215271,
                0.836280107498169,
                0.7651602029800415,
                0.738964855670929,
                0.8478726744651794,
                0.7379216551780701,
                0.7382166385650635,
                0.8525643348693848,
                0.7527898550033569,
                0.7973639369010925,
                0.7114185690879822,
                0.6921882629394531,
                0.7902398109436035,
                0.8120765089988708,
                0.8128836154937744,
                0.7947866916656494,
                0.8542494177818298,
                0.8072587847709656,
                0.8248698115348816,
                0.7432450652122498,
                0.8457604646682739,
                0.7674416303634644,
                0.7148423790931702,
                0.8394902944564819,
                0.6283880472183228,
                0.7942322492599487,
                0.8602752089500427,
                0.7870490550994873,
                0.840011477470398,
                0.653525710105896,
                0.8368992805480957,
                0.7823953628540039,
                0.6980276703834534,
                0.8361519575119019,
                0.8110978007316589,
                0.8284484148025513,
                0.7111579179763794
            ],
            [
                0.7910709381103516,
                0.8075613379478455,
                0.8085614442825317,
                0.8141925930976868,
                0.8173076510429382,
                0.7940908670425415,
                0.6701244115829468,
                0.8318859934806824,
                0.6339035630226135,
                0.791128396987915,
                0.7931500673294067,
                0.7881515026092529,
                0.6648244857788086,
                0.7638140916824341,
                0.7396240234375,
                0.8791712522506714,
                0.8501304388046265,
                0.7704976201057434,
                0.8565539121627808,
                0.7630280256271362,
                0.754267156124115,
                0.8838600516319275,
                0.7328348755836487,
                0.8745291233062744,
                0.7493852972984314,
                0.7199174761772156,
                0.7888948321342468,
                0.8402106761932373,
                0.834144115447998,
                0.8606789112091064,
                0.895743727684021,
                0.8670885562896729,
                0.8951674699783325,
                0.7684804797172546,
                0.8842189908027649,
                0.8625320196151733,
                0.70345538854599,
                0.8742954134941101,
                0.6508948802947998,
                0.7945059537887573,
                0.8284662365913391,
                0.7680656909942627,
                0.8693474531173706,
                0.626067042350769,
                0.8638973236083984,
                0.8347855806350708,
                0.6663743257522583,
                0.843632161617279,
                0.8672560453414917,
                0.852627158164978,
                0.7248454093933105
            ],
            [
                0.7378518581390381,
                0.7544664144515991,
                0.7061924338340759,
                0.7684168815612793,
                0.75174480676651,
                0.7164719104766846,
                0.7273618578910828,
                0.7797164916992188,
                0.6959407329559326,
                0.7637608051300049,
                0.7354828715324402,
                0.7194342613220215,
                0.6839648485183716,
                0.7707257866859436,
                0.683098316192627,
                0.8242293000221252,
                0.7576944828033447,
                0.7048527598381042,
                0.816803514957428,
                0.7150940895080566,
                0.6795549988746643,
                0.8252205848693848,
                0.7274390459060669,
                0.75823974609375,
                0.660197913646698,
                0.6709209680557251,
                0.7937808036804199,
                0.791877806186676,
                0.8097952604293823,
                0.7761459350585938,
                0.8259897828102112,
                0.8100292682647705,
                0.8029119968414307,
                0.7523985505104065,
                0.8331581354141235,
                0.7493714690208435,
                0.7257947325706482,
                0.837317705154419,
                0.6135039925575256,
                0.7627396583557129,
                0.8290026187896729,
                0.7501113414764404,
                0.8019822835922241,
                0.6712074875831604,
                0.8340247869491577,
                0.7883949279785156,
                0.6729728579521179,
                0.7962349653244019,
                0.7983851432800293,
                0.7872098088264465,
                0.6711023449897766
            ],
            [
                0.7726311683654785,
                0.8098537921905518,
                0.7787258625030518,
                0.780098557472229,
                0.7976816892623901,
                0.785452127456665,
                0.7151263356208801,
                0.8012521862983704,
                0.6657648682594299,
                0.8090883493423462,
                0.7668472528457642,
                0.7654930353164673,
                0.6668310165405273,
                0.7920954823493958,
                0.7269467711448669,
                0.8600427508354187,
                0.831634521484375,
                0.7280012369155884,
                0.8414040207862854,
                0.7586475014686584,
                0.7225667238235474,
                0.8563376665115356,
                0.70584636926651,
                0.824472963809967,
                0.7369392514228821,
                0.7197116613388062,
                0.7885981798171997,
                0.8100499510765076,
                0.8333407044410706,
                0.8190228939056396,
                0.8714905381202698,
                0.8539495468139648,
                0.864387571811676,
                0.7982062101364136,
                0.8735236525535583,
                0.8401720523834229,
                0.7553904056549072,
                0.8720912337303162,
                0.6669646501541138,
                0.7655359506607056,
                0.8196020722389221,
                0.7686406373977661,
                0.8413639664649963,
                0.686668872833252,
                0.8703333139419556,
                0.8682595491409302,
                0.6938888430595398,
                0.8255228996276855,
                0.8573547601699829,
                0.8262655735015869,
                0.6776752471923828
            ],
            [
                0.8417589664459229,
                0.8219350576400757,
                0.7245636582374573,
                0.8236823678016663,
                0.8566420078277588,
                0.8205276131629944,
                0.7463796138763428,
                0.8688687682151794,
                0.6756831407546997,
                0.7871348857879639,
                0.8592464327812195,
                0.855960488319397,
                0.6915037631988525,
                0.8613978624343872,
                0.7063149213790894,
                0.8680222630500793,
                0.7616167068481445,
                0.745140790939331,
                0.9144971966743469,
                0.7350524663925171,
                0.6835495233535767,
                0.8789263963699341,
                0.6970240473747253,
                0.8394738435745239,
                0.7001306414604187,
                0.6776063442230225,
                0.8316460847854614,
                0.8085991144180298,
                0.8478049635887146,
                0.791461169719696,
                0.9181413054466248,
                0.8176678419113159,
                0.8792006969451904,
                0.7528240084648132,
                0.8790501356124878,
                0.7912957668304443,
                0.6829939484596252,
                0.8695801496505737,
                0.6127867102622986,
                0.7905906438827515,
                0.898830771446228,
                0.7842594981193542,
                0.9043472409248352,
                0.6712199449539185,
                0.8967087268829346,
                0.7594059109687805,
                0.6861266493797302,
                0.8997220993041992,
                0.7925851345062256,
                0.9036072492599487,
                0.6859285831451416
            ],
            [
                0.8268502354621887,
                0.8224563598632812,
                0.7708247900009155,
                0.7795699238777161,
                0.7893355488777161,
                0.7566244602203369,
                0.7283127307891846,
                0.8211381435394287,
                0.6986328959465027,
                0.7981278896331787,
                0.7769724726676941,
                0.7683719396591187,
                0.7031469345092773,
                0.7897160649299622,
                0.7771185636520386,
                0.8539098501205444,
                0.8181337118148804,
                0.7638826966285706,
                0.8505664467811584,
                0.7608955502510071,
                0.7398848533630371,
                0.8545365333557129,
                0.7292574048042297,
                0.8078312277793884,
                0.7549123764038086,
                0.7467828989028931,
                0.8100563287734985,
                0.82107013463974,
                0.8270201683044434,
                0.8102597594261169,
                0.8644816279411316,
                0.8584063649177551,
                0.8564573526382446,
                0.8245365619659424,
                0.8628827333450317,
                0.8192347288131714,
                0.7328882217407227,
                0.8550044298171997,
                0.6579235792160034,
                0.7983365058898926,
                0.8382393717765808,
                0.7755112051963806,
                0.8372445702552795,
                0.6844198703765869,
                0.856777012348175,
                0.820702075958252,
                0.6966834664344788,
                0.825231671333313,
                0.8528505563735962,
                0.8312410116195679,
                0.7396283149719238
            ],
            [
                0.8482168912887573,
                0.7939466834068298,
                0.7361621856689453,
                0.7698797583580017,
                0.8043417930603027,
                0.7623698711395264,
                0.7350399494171143,
                0.830674946308136,
                0.7147085070610046,
                0.7639038562774658,
                0.8047819137573242,
                0.7858819365501404,
                0.6735769510269165,
                0.8104923963546753,
                0.7573762536048889,
                0.8389629125595093,
                0.7618333697319031,
                0.7359080910682678,
                0.8538473844528198,
                0.7566021084785461,
                0.7158692479133606,
                0.8474929928779602,
                0.7020423412322998,
                0.7838812470436096,
                0.7397099733352661,
                0.7210267782211304,
                0.8022246956825256,
                0.8102670907974243,
                0.8052231669425964,
                0.7647095918655396,
                0.8551052808761597,
                0.8220617771148682,
                0.8324856758117676,
                0.7776738405227661,
                0.8433398008346558,
                0.7784387469291687,
                0.7220484018325806,
                0.8367201089859009,
                0.6407184600830078,
                0.7832478284835815,
                0.840324342250824,
                0.7983799576759338,
                0.8280373811721802,
                0.6806662082672119,
                0.8405750393867493,
                0.7622897624969482,
                0.7034271955490112,
                0.8303865790367126,
                0.8260379433631897,
                0.8432086706161499,
                0.7009912133216858
            ],
            [
                0.8284128904342651,
                0.8210161924362183,
                0.8259068727493286,
                0.8249935507774353,
                0.8240048885345459,
                0.8083705902099609,
                0.7100342512130737,
                0.8471006751060486,
                0.6637837886810303,
                0.8142164945602417,
                0.8001687526702881,
                0.800988495349884,
                0.6638318300247192,
                0.7871447801589966,
                0.7818564772605896,
                0.8751682639122009,
                0.8544808626174927,
                0.7996100187301636,
                0.8560424447059631,
                0.8062998652458191,
                0.7662977576255798,
                0.8696509599685669,
                0.7397049069404602,
                0.8508548736572266,
                0.7730027437210083,
                0.7558677792549133,
                0.8137718439102173,
                0.8736554384231567,
                0.8389084339141846,
                0.8533485531806946,
                0.8948826193809509,
                0.8732084631919861,
                0.8830894827842712,
                0.8282536268234253,
                0.8757457733154297,
                0.8615783452987671,
                0.752455472946167,
                0.8686134815216064,
                0.6927688717842102,
                0.8298736810684204,
                0.8342181444168091,
                0.7986794710159302,
                0.8589819073677063,
                0.659809947013855,
                0.8721126914024353,
                0.8324868083000183,
                0.6745060682296753,
                0.8635998964309692,
                0.8748643398284912,
                0.8620097041130066,
                0.7509873509407043
            ],
            [
                0.8497567772865295,
                0.7662282586097717,
                0.7119952440261841,
                0.7716081142425537,
                0.8161555528640747,
                0.8026607036590576,
                0.7074856162071228,
                0.8403392434120178,
                0.6927703619003296,
                0.7271455526351929,
                0.8453595042228699,
                0.8468052744865417,
                0.6480808258056641,
                0.8457812070846558,
                0.716928243637085,
                0.8443613052368164,
                0.7139376401901245,
                0.7351016998291016,
                0.8662258386611938,
                0.7205590009689331,
                0.6703913807868958,
                0.853326678276062,
                0.6901687383651733,
                0.8252697587013245,
                0.6673840880393982,
                0.7056035995483398,
                0.8240411281585693,
                0.8036562204360962,
                0.8295556306838989,
                0.7486152052879333,
                0.8793400526046753,
                0.7823790907859802,
                0.849880576133728,
                0.7250804305076599,
                0.8432750701904297,
                0.7353990077972412,
                0.6543668508529663,
                0.8401604294776917,
                0.6156139373779297,
                0.7862757444381714,
                0.8559765219688416,
                0.7438099980354309,
                0.8591694831848145,
                0.626118540763855,
                0.8608681559562683,
                0.7078562378883362,
                0.6385682821273804,
                0.8705417513847351,
                0.753998339176178,
                0.8625237345695496,
                0.7125069499015808
            ],
            [
                0.8852422833442688,
                0.7738644480705261,
                0.7260459065437317,
                0.7675437331199646,
                0.8282113075256348,
                0.7896283268928528,
                0.7181726694107056,
                0.8579487800598145,
                0.7081894874572754,
                0.7232623100280762,
                0.8643530607223511,
                0.8591461181640625,
                0.6652781367301941,
                0.852032482624054,
                0.7825697064399719,
                0.8292472958564758,
                0.7416951060295105,
                0.7883185744285583,
                0.8779866099357605,
                0.7808828949928284,
                0.7381768226623535,
                0.8463504314422607,
                0.7174046635627747,
                0.8006200194358826,
                0.7045698165893555,
                0.7370094656944275,
                0.8349818587303162,
                0.8332840204238892,
                0.8340100646018982,
                0.7481668591499329,
                0.8678401708602905,
                0.7893414497375488,
                0.8364914655685425,
                0.7546325922012329,
                0.8283475637435913,
                0.7399891018867493,
                0.6907480955123901,
                0.8276887536048889,
                0.648280918598175,
                0.7993463277816772,
                0.8738015294075012,
                0.7893048524856567,
                0.8570728898048401,
                0.6447764039039612,
                0.8544232249259949,
                0.713310718536377,
                0.6647992730140686,
                0.8652364015579224,
                0.7887491583824158,
                0.8673406839370728,
                0.7689110040664673
            ],
            [
                0.8624508380889893,
                0.854903519153595,
                0.8373158574104309,
                0.8079229593276978,
                0.8378019332885742,
                0.8221708536148071,
                0.7258844971656799,
                0.8530902862548828,
                0.672012984752655,
                0.809410810470581,
                0.8258554935455322,
                0.8248832821846008,
                0.6905127763748169,
                0.807498574256897,
                0.8082244396209717,
                0.8510604500770569,
                0.8434795141220093,
                0.8005791306495667,
                0.864760160446167,
                0.837058424949646,
                0.7830935716629028,
                0.8594164252281189,
                0.7396305799484253,
                0.8425672650337219,
                0.8080871105194092,
                0.7754577398300171,
                0.8200567960739136,
                0.8606318235397339,
                0.8195330500602722,
                0.7978245615959167,
                0.886777937412262,
                0.8513591289520264,
                0.8705945611000061,
                0.8226765990257263,
                0.8580816388130188,
                0.8234776854515076,
                0.7773550152778625,
                0.8499863743782043,
                0.7294261455535889,
                0.8236904740333557,
                0.8470263481140137,
                0.8264937400817871,
                0.8634225726127625,
                0.709025502204895,
                0.862716019153595,
                0.790769100189209,
                0.7272526025772095,
                0.8602789640426636,
                0.8330335021018982,
                0.87064129114151,
                0.7421338558197021
            ],
            [
                0.8422198295593262,
                0.7741643190383911,
                0.720065176486969,
                0.7771046161651611,
                0.8116878271102905,
                0.7979936599731445,
                0.745211660861969,
                0.8157944083213806,
                0.7304384708404541,
                0.7616950869560242,
                0.855782151222229,
                0.84649658203125,
                0.6790333986282349,
                0.8647664189338684,
                0.7121887803077698,
                0.866378664970398,
                0.7391812205314636,
                0.7401454448699951,
                0.877585232257843,
                0.7306050062179565,
                0.6707903146743774,
                0.8723050355911255,
                0.6900819540023804,
                0.8326521515846252,
                0.6775254011154175,
                0.7038180232048035,
                0.8214515447616577,
                0.8055626749992371,
                0.8284247517585754,
                0.7669863104820251,
                0.8898829817771912,
                0.800238311290741,
                0.8588111996650696,
                0.7355570793151855,
                0.8688429594039917,
                0.7681692838668823,
                0.676716685295105,
                0.8610891103744507,
                0.6191515922546387,
                0.779468297958374,
                0.8618454337120056,
                0.7583057880401611,
                0.8700532913208008,
                0.6783859729766846,
                0.8747438192367554,
                0.7552686929702759,
                0.6985698342323303,
                0.8781719207763672,
                0.7885687947273254,
                0.870173454284668,
                0.6972692012786865
            ],
            [
                0.8349463939666748,
                0.7889553904533386,
                0.7049808502197266,
                0.7474435567855835,
                0.7948232889175415,
                0.748600423336029,
                0.7361751794815063,
                0.7913845181465149,
                0.7383230924606323,
                0.7648415565490723,
                0.8018789291381836,
                0.7878726720809937,
                0.6954988837242126,
                0.8164699673652649,
                0.7244608998298645,
                0.8224039673805237,
                0.7273489236831665,
                0.7078937888145447,
                0.8481590747833252,
                0.7195956707000732,
                0.6805413365364075,
                0.8365668654441833,
                0.670474112033844,
                0.7663532495498657,
                0.6942272186279297,
                0.7012231349945068,
                0.8125700354576111,
                0.774773895740509,
                0.7956554293632507,
                0.7218371033668518,
                0.8425164818763733,
                0.7831453084945679,
                0.811059832572937,
                0.7363471388816833,
                0.8317062258720398,
                0.7354735136032104,
                0.7014535665512085,
                0.8228450417518616,
                0.6195129156112671,
                0.7525306344032288,
                0.8404895663261414,
                0.7670883536338806,
                0.8179721832275391,
                0.7171950340270996,
                0.8330095410346985,
                0.7406286597251892,
                0.7371063232421875,
                0.828457236289978,
                0.7680714130401611,
                0.8294221758842468,
                0.6599175930023193
            ],
            [
                0.8636962175369263,
                0.859469473361969,
                0.843023419380188,
                0.8289560675621033,
                0.8491950035095215,
                0.831220269203186,
                0.710528552532196,
                0.8739410042762756,
                0.6734186410903931,
                0.7984827160835266,
                0.8387987017631531,
                0.849582314491272,
                0.6798741221427917,
                0.8111156225204468,
                0.8139419555664062,
                0.8584027886390686,
                0.8519350290298462,
                0.8228703737258911,
                0.8739702105522156,
                0.8357073068618774,
                0.8034365177154541,
                0.8656785488128662,
                0.759537398815155,
                0.855614960193634,
                0.8109061121940613,
                0.7814788818359375,
                0.8157691359519958,
                0.8725048303604126,
                0.8286417126655579,
                0.8234015703201294,
                0.8957362174987793,
                0.8602121472358704,
                0.8813333511352539,
                0.8104164004325867,
                0.8621571660041809,
                0.8330303430557251,
                0.7615073919296265,
                0.8536739945411682,
                0.716174304485321,
                0.8404132127761841,
                0.860511302947998,
                0.831834077835083,
                0.8775322437286377,
                0.6949840784072876,
                0.8629769086837769,
                0.7971580624580383,
                0.7207026481628418,
                0.8697918653488159,
                0.8471416234970093,
                0.8774688839912415,
                0.7737855911254883
            ],
            [
                0.764202356338501,
                0.7786293029785156,
                0.7825270295143127,
                0.8280929327011108,
                0.7863889932632446,
                0.7390938997268677,
                0.6893327236175537,
                0.8268342018127441,
                0.6766220927238464,
                0.7419012188911438,
                0.75142502784729,
                0.7706893086433411,
                0.6932055950164795,
                0.7403591871261597,
                0.7383443713188171,
                0.8346170783042908,
                0.8064729571342468,
                0.800067663192749,
                0.8412045240402222,
                0.7654955387115479,
                0.756855309009552,
                0.836972713470459,
                0.8033668398857117,
                0.7874834537506104,
                0.7074112296104431,
                0.7015928030014038,
                0.7732285261154175,
                0.8377078771591187,
                0.8041080236434937,
                0.85417640209198,
                0.8426958322525024,
                0.8344026207923889,
                0.8242343664169312,
                0.748715341091156,
                0.8409544229507446,
                0.7912191152572632,
                0.7048815488815308,
                0.8327683806419373,
                0.6362794637680054,
                0.8264549970626831,
                0.8554326295852661,
                0.7970881462097168,
                0.8387293219566345,
                0.6307523250579834,
                0.8236988186836243,
                0.7943758964538574,
                0.6619794368743896,
                0.8158210515975952,
                0.855231523513794,
                0.8003729581832886,
                0.767464280128479
            ],
            [
                0.7881133556365967,
                0.8294825553894043,
                0.8117246627807617,
                0.7803599834442139,
                0.7782502174377441,
                0.7887151837348938,
                0.714471161365509,
                0.8118714094161987,
                0.675961434841156,
                0.8304789066314697,
                0.754020094871521,
                0.7589098811149597,
                0.6721644997596741,
                0.7541244626045227,
                0.749238908290863,
                0.8794189691543579,
                0.8483524322509766,
                0.7506362199783325,
                0.8316881656646729,
                0.7792575359344482,
                0.7436429262161255,
                0.8627493977546692,
                0.7304909229278564,
                0.8430647253990173,
                0.7498283982276917,
                0.7495927214622498,
                0.779110848903656,
                0.8188357949256897,
                0.8256565928459167,
                0.8455148339271545,
                0.8713305592536926,
                0.8702271580696106,
                0.8759368658065796,
                0.8325197100639343,
                0.885930061340332,
                0.8610610961914062,
                0.7558729648590088,
                0.8727900385856628,
                0.6809741854667664,
                0.786176860332489,
                0.8149706721305847,
                0.7711299061775208,
                0.8461232781410217,
                0.6596666574478149,
                0.8560758829116821,
                0.8620551824569702,
                0.6742267608642578,
                0.8301864862442017,
                0.8682466149330139,
                0.8310242891311646,
                0.7112505435943604
            ],
            [
                0.7547599077224731,
                0.7633510828018188,
                0.7277343273162842,
                0.7850766777992249,
                0.7491359114646912,
                0.712376594543457,
                0.7056872844696045,
                0.8006608486175537,
                0.6883765459060669,
                0.7469052076339722,
                0.7366169095039368,
                0.7276439070701599,
                0.6884798407554626,
                0.7434976696968079,
                0.6952846646308899,
                0.814371645450592,
                0.7581428289413452,
                0.7366162538528442,
                0.8148494958877563,
                0.7176228761672974,
                0.69676673412323,
                0.8181195855140686,
                0.7546478509902954,
                0.7613282203674316,
                0.6768431067466736,
                0.6816138625144958,
                0.7843190431594849,
                0.7976101636886597,
                0.7996506690979004,
                0.7943122386932373,
                0.8276082873344421,
                0.8049871325492859,
                0.8041296601295471,
                0.7274723052978516,
                0.8212535977363586,
                0.7541949152946472,
                0.7094337940216064,
                0.8203723430633545,
                0.6211854219436646,
                0.7729297876358032,
                0.833236038684845,
                0.7600127458572388,
                0.8123811483383179,
                0.6440099477767944,
                0.8235884308815002,
                0.7797678709030151,
                0.6614984273910522,
                0.8063775897026062,
                0.8002841472625732,
                0.798408031463623,
                0.7115752696990967
            ],
            [
                0.7724307775497437,
                0.799595057964325,
                0.859144926071167,
                0.8084114789962769,
                0.7678666114807129,
                0.784636914730072,
                0.6696787476539612,
                0.8003463745117188,
                0.6391986012458801,
                0.7940552830696106,
                0.7332130074501038,
                0.7371170520782471,
                0.6305580139160156,
                0.7220649719238281,
                0.7503553032875061,
                0.8827619552612305,
                0.8721596598625183,
                0.7707923650741577,
                0.8241925239562988,
                0.7716922163963318,
                0.7448962330818176,
                0.8699734807014465,
                0.7579832673072815,
                0.8651903867721558,
                0.7601943016052246,
                0.7424194812774658,
                0.75418621301651,
                0.8439283967018127,
                0.8093019723892212,
                0.862676203250885,
                0.8743936419487,
                0.8784772753715515,
                0.8921229839324951,
                0.7969309091567993,
                0.8827751278877258,
                0.8535205125808716,
                0.7125155329704285,
                0.8758516907691956,
                0.6614001393318176,
                0.7768772840499878,
                0.78807532787323,
                0.7449941039085388,
                0.8318047523498535,
                0.5928969979286194,
                0.8565939664840698,
                0.8562043905258179,
                0.6183052062988281,
                0.8288004398345947,
                0.900533139705658,
                0.8187222480773926,
                0.7530386447906494
            ],
            [
                0.8225736618041992,
                0.7757489681243896,
                0.797326922416687,
                0.8051215410232544,
                0.8214021921157837,
                0.8430764079093933,
                0.6579983830451965,
                0.8331456780433655,
                0.607994794845581,
                0.7692464590072632,
                0.823681116104126,
                0.8182542324066162,
                0.6131340265274048,
                0.8007157444953918,
                0.6828367114067078,
                0.9123861789703369,
                0.7719218730926514,
                0.7271038889884949,
                0.8850187063217163,
                0.7080210447311401,
                0.6702900528907776,
                0.9229239225387573,
                0.6737481951713562,
                0.9292966723442078,
                0.6854903697967529,
                0.6883192658424377,
                0.7825472354888916,
                0.8022511005401611,
                0.8121541142463684,
                0.787033200263977,
                0.9370712041854858,
                0.7994743585586548,
                0.9514985680580139,
                0.6952084898948669,
                0.914544403553009,
                0.7535269260406494,
                0.6416870951652527,
                0.9129308462142944,
                0.6087645292282104,
                0.7314776182174683,
                0.822760820388794,
                0.7282193899154663,
                0.8986555337905884,
                0.5606910586357117,
                0.912673830986023,
                0.7389421463012695,
                0.5898290276527405,
                0.9076205492019653,
                0.7870232462882996,
                0.9134311676025391,
                0.6805372834205627
            ],
            [
                0.8413034081459045,
                0.7979539632797241,
                0.7220409512519836,
                0.735213041305542,
                0.8086606860160828,
                0.8489252328872681,
                0.7074103951454163,
                0.8505496978759766,
                0.6836890578269958,
                0.762032151222229,
                0.8361806273460388,
                0.8375263810157776,
                0.6083250641822815,
                0.8089659214019775,
                0.717199981212616,
                0.8419076800346375,
                0.6993299722671509,
                0.7055974006652832,
                0.8342089653015137,
                0.7397661805152893,
                0.6897727847099304,
                0.8497809171676636,
                0.6576982140541077,
                0.8349179625511169,
                0.7028077840805054,
                0.6960409879684448,
                0.8008854389190674,
                0.7667840719223022,
                0.8294764757156372,
                0.7046794295310974,
                0.8723796606063843,
                0.736921489238739,
                0.843481183052063,
                0.7115063071250916,
                0.840339720249176,
                0.7189080715179443,
                0.7018962502479553,
                0.8405712842941284,
                0.6524486541748047,
                0.7389436364173889,
                0.8292334675788879,
                0.7651141881942749,
                0.862263560295105,
                0.6339895725250244,
                0.8471495509147644,
                0.7142866849899292,
                0.6610175371170044,
                0.8690540790557861,
                0.7394346594810486,
                0.86485356092453,
                0.6771602034568787
            ],
            [
                0.7389102578163147,
                0.7541201710700989,
                0.7475365996360779,
                0.794869601726532,
                0.7760542631149292,
                0.7572014927864075,
                0.7120978236198425,
                0.808059811592102,
                0.6972321271896362,
                0.7443851828575134,
                0.7632567882537842,
                0.7609240412712097,
                0.6911536455154419,
                0.777509331703186,
                0.718948245048523,
                0.8393419981002808,
                0.790573000907898,
                0.7623896598815918,
                0.8342053890228271,
                0.7297075986862183,
                0.7243902087211609,
                0.8491933345794678,
                0.777145266532898,
                0.7845233082771301,
                0.6844402551651001,
                0.6918348670005798,
                0.8449134230613708,
                0.8437824249267578,
                0.8530125617980957,
                0.7850838303565979,
                0.8390926122665405,
                0.8321324586868286,
                0.8300895690917969,
                0.7372162342071533,
                0.8467050790786743,
                0.7538895606994629,
                0.7136169672012329,
                0.8500251770019531,
                0.6265503764152527,
                0.7874358296394348,
                0.846606969833374,
                0.7456490397453308,
                0.8118464946746826,
                0.6492556929588318,
                0.8481895923614502,
                0.7863476276397705,
                0.6721273064613342,
                0.7960035800933838,
                0.834966778755188,
                0.7710620760917664,
                0.7289564609527588
            ],
            [
                0.7573453187942505,
                0.7587341666221619,
                0.8296043276786804,
                0.8022564053535461,
                0.7405813336372375,
                0.7276692390441895,
                0.64848393201828,
                0.7792981863021851,
                0.6422387361526489,
                0.7506053447723389,
                0.7085672616958618,
                0.7210990190505981,
                0.6143545508384705,
                0.6954148411750793,
                0.7292952537536621,
                0.8424116373062134,
                0.8657858371734619,
                0.7888378500938416,
                0.8022273182868958,
                0.7528197765350342,
                0.7220321297645569,
                0.8352046608924866,
                0.7653871178627014,
                0.7985947132110596,
                0.7303947806358337,
                0.7233809232711792,
                0.7543380856513977,
                0.8576231002807617,
                0.8061714172363281,
                0.8604959845542908,
                0.8343846797943115,
                0.855964720249176,
                0.8451629877090454,
                0.7487120032310486,
                0.8415961861610413,
                0.8348872661590576,
                0.6838940382003784,
                0.8394924998283386,
                0.6273375153541565,
                0.7586902976036072,
                0.7832366228103638,
                0.7244667410850525,
                0.80265212059021,
                0.5692602396011353,
                0.8315378427505493,
                0.8810679912567139,
                0.5955348610877991,
                0.7977771759033203,
                0.9356553554534912,
                0.7754861116409302,
                0.7687621116638184
            ],
            [
                0.7565543055534363,
                0.7772539258003235,
                0.7140837907791138,
                0.7485507130622864,
                0.7567479014396667,
                0.7275416851043701,
                0.701336681842804,
                0.7703284621238708,
                0.7197983264923096,
                0.7403972744941711,
                0.7522679567337036,
                0.7481241226196289,
                0.6405258178710938,
                0.7696122527122498,
                0.6708006262779236,
                0.8231716156005859,
                0.7194006443023682,
                0.6845373511314392,
                0.8116333484649658,
                0.6963775157928467,
                0.6477068662643433,
                0.8225531578063965,
                0.6905216574668884,
                0.7677661180496216,
                0.6649931073188782,
                0.6765453815460205,
                0.7848497033119202,
                0.7685659527778625,
                0.7907407879829407,
                0.751962423324585,
                0.8309986591339111,
                0.787889301776886,
                0.8070778846740723,
                0.7209272384643555,
                0.831367552280426,
                0.7303801774978638,
                0.6825860142707825,
                0.8248809576034546,
                0.5922503471374512,
                0.7414400577545166,
                0.814981997013092,
                0.7185354232788086,
                0.798484742641449,
                0.6543868184089661,
                0.8287663459777832,
                0.7737395167350769,
                0.6764158606529236,
                0.8112751245498657,
                0.7949914932250977,
                0.7957699298858643,
                0.6584722995758057
            ],
            [
                0.7467545866966248,
                0.7771600484848022,
                0.8297498822212219,
                0.7767568826675415,
                0.7471944093704224,
                0.7781733870506287,
                0.6405768990516663,
                0.7688769698143005,
                0.6078391671180725,
                0.7629271745681763,
                0.7307108640670776,
                0.746131181716919,
                0.611290454864502,
                0.7192962765693665,
                0.7127922773361206,
                0.8537978529930115,
                0.8475093841552734,
                0.7928550839424133,
                0.810644268989563,
                0.747006893157959,
                0.6978678703308105,
                0.8456863760948181,
                0.7245838046073914,
                0.8556464910507202,
                0.7127612233161926,
                0.7088168263435364,
                0.7438215017318726,
                0.8320345878601074,
                0.7888116836547852,
                0.8844051361083984,
                0.8523707389831543,
                0.8536803126335144,
                0.870245635509491,
                0.7270656228065491,
                0.8558563590049744,
                0.8394898176193237,
                0.6802235245704651,
                0.8503880500793457,
                0.6231085658073425,
                0.7589845061302185,
                0.7714724540710449,
                0.7321494817733765,
                0.8354588150978088,
                0.58103346824646,
                0.8387660980224609,
                0.8371795415878296,
                0.6077234745025635,
                0.8058297634124756,
                0.8824197053909302,
                0.8044942021369934,
                0.7340800762176514
            ],
            [
                0.7481656074523926,
                0.7721693515777588,
                0.7578444480895996,
                0.7916651368141174,
                0.7521569132804871,
                0.7463066577911377,
                0.7000865936279297,
                0.8109942674636841,
                0.6874502897262573,
                0.7407968044281006,
                0.7258598804473877,
                0.7181255221366882,
                0.6501556634902954,
                0.728970468044281,
                0.7180675864219666,
                0.8370537757873535,
                0.7854262590408325,
                0.7303358912467957,
                0.8158354759216309,
                0.7177137136459351,
                0.7135816812515259,
                0.8351850509643555,
                0.7575640082359314,
                0.7838298678398132,
                0.6869840025901794,
                0.7154975533485413,
                0.8073405623435974,
                0.8332717418670654,
                0.8170559406280518,
                0.7974277138710022,
                0.8366917967796326,
                0.8551167249679565,
                0.8263625502586365,
                0.7592335343360901,
                0.8372249007225037,
                0.7665722966194153,
                0.7192248702049255,
                0.8361263871192932,
                0.6273274421691895,
                0.7962856292724609,
                0.8198734521865845,
                0.744788646697998,
                0.788135290145874,
                0.620803713798523,
                0.8257066011428833,
                0.7622947096824646,
                0.64590984582901,
                0.8055840730667114,
                0.81532883644104,
                0.7921817898750305,
                0.7019486427307129
            ],
            [
                0.7661525011062622,
                0.8040077686309814,
                0.7160680294036865,
                0.764887809753418,
                0.7820549607276917,
                0.7286722660064697,
                0.6943280696868896,
                0.7972704172134399,
                0.6850776076316833,
                0.7259334921836853,
                0.7471233010292053,
                0.7402939200401306,
                0.6592470407485962,
                0.7468569874763489,
                0.7151771187782288,
                0.7911545634269714,
                0.7328857779502869,
                0.6961333155632019,
                0.8216538429260254,
                0.7104020118713379,
                0.6912260055541992,
                0.7991502285003662,
                0.7240082621574402,
                0.7484766840934753,
                0.6997747421264648,
                0.7204275727272034,
                0.7837913632392883,
                0.7787659764289856,
                0.7910813689231873,
                0.7484346628189087,
                0.8260277509689331,
                0.820684552192688,
                0.7931230664253235,
                0.7607697248458862,
                0.8006919026374817,
                0.7423766255378723,
                0.7030940651893616,
                0.7894403338432312,
                0.6216180324554443,
                0.781413733959198,
                0.8206315040588379,
                0.7481632232666016,
                0.7843953371047974,
                0.6593064069747925,
                0.7941933870315552,
                0.732051432132721,
                0.6835303902626038,
                0.7921214699745178,
                0.7701454758644104,
                0.781404972076416,
                0.6831153631210327
            ],
            [
                0.7184940576553345,
                0.7481783628463745,
                0.7497760653495789,
                0.685908317565918,
                0.6852973699569702,
                0.6932893395423889,
                0.6835956573486328,
                0.7082160115242004,
                0.6517269611358643,
                0.7710198760032654,
                0.668338418006897,
                0.6587076187133789,
                0.6211065053939819,
                0.6754751801490784,
                0.725128710269928,
                0.811272144317627,
                0.8143026232719421,
                0.6896626353263855,
                0.7490167617797852,
                0.7180219292640686,
                0.6836470365524292,
                0.7891316413879395,
                0.6886744499206543,
                0.7693850994110107,
                0.6983292698860168,
                0.7411261796951294,
                0.7492188811302185,
                0.757091760635376,
                0.8047183156013489,
                0.8266875147819519,
                0.7898344993591309,
                0.8487215042114258,
                0.796055793762207,
                0.7926574945449829,
                0.8108007907867432,
                0.8675128221511841,
                0.7138805985450745,
                0.7998277544975281,
                0.6524867415428162,
                0.7242168188095093,
                0.717923104763031,
                0.7090582251548767,
                0.7479008436203003,
                0.6234574317932129,
                0.7849026918411255,
                0.8670487999916077,
                0.6405658721923828,
                0.7332857847213745,
                0.8704590797424316,
                0.7261466383934021,
                0.6832871437072754
            ],
            [
                0.775628387928009,
                0.7913830876350403,
                0.8394206166267395,
                0.7764850854873657,
                0.7612276077270508,
                0.788476288318634,
                0.6504749655723572,
                0.7875919342041016,
                0.6333503127098083,
                0.7587293982505798,
                0.7359355688095093,
                0.7425760626792908,
                0.62270587682724,
                0.7213772535324097,
                0.7562662959098816,
                0.8445441126823425,
                0.8676292896270752,
                0.7924904227256775,
                0.8144946694374084,
                0.7731091976165771,
                0.7272999286651611,
                0.8390833735466003,
                0.7447168827056885,
                0.8354355692863464,
                0.7499611973762512,
                0.7470681667327881,
                0.7667691707611084,
                0.8455301523208618,
                0.7993999123573303,
                0.874113917350769,
                0.8542505502700806,
                0.8678398728370667,
                0.8598781228065491,
                0.7656769156455994,
                0.846118688583374,
                0.856472909450531,
                0.7240135669708252,
                0.842056393623352,
                0.6623749136924744,
                0.779405415058136,
                0.781118631362915,
                0.7482115030288696,
                0.8285166025161743,
                0.5924984812736511,
                0.8343351483345032,
                0.8550078272819519,
                0.6181504130363464,
                0.8105422854423523,
                0.9138821363449097,
                0.8047929406166077,
                0.7590329647064209
            ],
            [
                0.8470153212547302,
                0.7847859859466553,
                0.7151658535003662,
                0.7638903856277466,
                0.8173012733459473,
                0.7844558954238892,
                0.7482607364654541,
                0.8449604511260986,
                0.734653115272522,
                0.7463687062263489,
                0.8380106687545776,
                0.8282612562179565,
                0.7025174498558044,
                0.83918696641922,
                0.7315167188644409,
                0.8255407810211182,
                0.7274693250656128,
                0.7262979745864868,
                0.862439751625061,
                0.7418116927146912,
                0.7135517001152039,
                0.8393441438674927,
                0.7245380282402039,
                0.7863756418228149,
                0.7099581956863403,
                0.7029048800468445,
                0.822192907333374,
                0.8007094860076904,
                0.8240594863891602,
                0.7248197197914124,
                0.8585016131401062,
                0.7902625799179077,
                0.8204279541969299,
                0.740815281867981,
                0.8290987014770508,
                0.7334756255149841,
                0.710068941116333,
                0.8271610736846924,
                0.6409835815429688,
                0.7836837768554688,
                0.8632251024246216,
                0.7856805324554443,
                0.8437435030937195,
                0.6791104078292847,
                0.8468785881996155,
                0.735478401184082,
                0.6991543769836426,
                0.8565594553947449,
                0.774264931678772,
                0.8507733345031738,
                0.7063251733779907
            ],
            [
                0.8484587073326111,
                0.8485388159751892,
                0.8646562099456787,
                0.8405441641807556,
                0.8409308791160583,
                0.8304924368858337,
                0.691902756690979,
                0.8719381093978882,
                0.6514759063720703,
                0.8190406560897827,
                0.8209147453308105,
                0.8184327483177185,
                0.653371274471283,
                0.7983173727989197,
                0.7966498136520386,
                0.8827077746391296,
                0.8542898297309875,
                0.8041172027587891,
                0.8697324991226196,
                0.8191571831703186,
                0.7938013076782227,
                0.8895366191864014,
                0.7537766695022583,
                0.8804668188095093,
                0.8094813823699951,
                0.7581083178520203,
                0.8020303845405579,
                0.8595460057258606,
                0.8288153409957886,
                0.8302719593048096,
                0.9106366038322449,
                0.8750572204589844,
                0.9129648208618164,
                0.8113695979118347,
                0.8889255523681641,
                0.8248405456542969,
                0.7551512122154236,
                0.8854581117630005,
                0.6816828846931458,
                0.8221328854560852,
                0.8494228720664978,
                0.8175434470176697,
                0.8760386109352112,
                0.6638860106468201,
                0.8840899467468262,
                0.8181042671203613,
                0.6917938590049744,
                0.8714497089385986,
                0.8789178729057312,
                0.8738779425621033,
                0.7769754528999329
            ],
            [
                0.8429722785949707,
                0.8019905686378479,
                0.7165732979774475,
                0.7162105441093445,
                0.7542669177055359,
                0.7480281591415405,
                0.7373886108398438,
                0.7851839065551758,
                0.7414810061454773,
                0.7579989433288574,
                0.7578337788581848,
                0.7403857111930847,
                0.6599419116973877,
                0.7731951475143433,
                0.7822906374931335,
                0.8142884373664856,
                0.7421349287033081,
                0.7238566875457764,
                0.8190240859985352,
                0.7442047595977783,
                0.7279945611953735,
                0.8210022449493408,
                0.6742327809333801,
                0.7552693486213684,
                0.7399098873138428,
                0.7472468018531799,
                0.7824835181236267,
                0.7663113474845886,
                0.7789806127548218,
                0.7075790166854858,
                0.810133159160614,
                0.7953245639801025,
                0.8022454977035522,
                0.7941904067993164,
                0.8180848956108093,
                0.7403626441955566,
                0.7280351519584656,
                0.8116186857223511,
                0.6617960333824158,
                0.7518882751464844,
                0.8124380707740784,
                0.7817519903182983,
                0.7820138335227966,
                0.7088661193847656,
                0.8003997206687927,
                0.7345397472381592,
                0.7214345335960388,
                0.7805582880973816,
                0.7821157574653625,
                0.7921290993690491,
                0.6879646182060242
            ]
        ],
        [
            [
                1.0000001192092896,
                0.745549201965332,
                0.8799193501472473,
                0.7769777178764343,
                0.7387228012084961,
                0.7654297351837158,
                0.8391157388687134,
                0.8218138217926025,
                0.7814123034477234,
                0.733456015586853,
                0.795674741268158,
                0.7347313165664673,
                0.8476800322532654,
                0.790745735168457,
                0.7120070457458496,
                0.7346446514129639,
                0.7830994129180908,
                0.7057644128799438,
                0.7446556091308594,
                0.7798014283180237,
                0.7458698749542236,
                0.8130492568016052,
                0.7085978984832764,
                0.7781132459640503,
                0.718978762626648,
                0.7759293913841248,
                0.7422618865966797,
                0.8303143978118896,
                0.708190381526947,
                0.7607007622718811,
                0.8234682083129883,
                0.7036552429199219,
                0.6903634667396545,
                0.8417701125144958,
                0.785443127155304,
                0.8073573112487793,
                0.7222235202789307,
                0.8579913377761841,
                0.7655655741691589,
                0.7169359922409058,
                0.7333865165710449,
                0.8735455274581909,
                0.6998342871665955,
                0.80934739112854,
                0.7286567687988281,
                0.7028541564941406,
                0.7551030516624451,
                0.8325158953666687,
                0.7227036952972412,
                0.8716015815734863,
                0.7230106592178345
            ],
            [
                0.745549201965332,
                1.0000001192092896,
                0.7915635108947754,
                0.814945638179779,
                0.766677975654602,
                0.8427343368530273,
                0.6989777684211731,
                0.8215378522872925,
                0.7656672596931458,
                0.783206045627594,
                0.8513755202293396,
                0.7337475419044495,
                0.8178081512451172,
                0.8296982049942017,
                0.8125450611114502,
                0.7209212183952332,
                0.730938196182251,
                0.8203067183494568,
                0.7304868102073669,
                0.821091890335083,
                0.7407135367393494,
                0.8441230058670044,
                0.7088356018066406,
                0.7946955561637878,
                0.7434845566749573,
                0.7480157017707825,
                0.7312925457954407,
                0.8251214027404785,
                0.7471506595611572,
                0.7311540246009827,
                0.8163830041885376,
                0.7407820224761963,
                0.7032029628753662,
                0.8321765065193176,
                0.7471251487731934,
                0.816642165184021,
                0.7168735265731812,
                0.8296316266059875,
                0.8422516584396362,
                0.8242638111114502,
                0.7235648036003113,
                0.7724983096122742,
                0.6958776116371155,
                0.8135409951210022,
                0.7322307825088501,
                0.6754620671272278,
                0.7206976413726807,
                0.8155961036682129,
                0.7227210998535156,
                0.8294903635978699,
                0.713625431060791
            ],
            [
                0.8799193501472473,
                0.7915635108947754,
                1.0000001192092896,
                0.8295521140098572,
                0.7708519697189331,
                0.8288927674293518,
                0.8325764536857605,
                0.8337953090667725,
                0.8124133944511414,
                0.789653480052948,
                0.8804036974906921,
                0.7619901895523071,
                0.8806289434432983,
                0.8388615846633911,
                0.7553275227546692,
                0.830098032951355,
                0.8759992122650146,
                0.7586115598678589,
                0.7912496328353882,
                0.8493345379829407,
                0.7890876531600952,
                0.8668421506881714,
                0.7754576802253723,
                0.871134340763092,
                0.7924861311912537,
                0.8415861129760742,
                0.7954675555229187,
                0.8858296871185303,
                0.7605605721473694,
                0.7730497121810913,
                0.862755537033081,
                0.764765739440918,
                0.7466430068016052,
                0.8656322360038757,
                0.8156403303146362,
                0.8931671380996704,
                0.7640591859817505,
                0.9104881882667542,
                0.8310220241546631,
                0.7694762945175171,
                0.7879047989845276,
                0.8799149990081787,
                0.7644758224487305,
                0.8477209806442261,
                0.7911996245384216,
                0.7533719539642334,
                0.8151125311851501,
                0.8545794486999512,
                0.773863673210144,
                0.9124324321746826,
                0.7766199111938477
            ],
            [
                0.7769777178764343,
                0.814945638179779,
                0.8295521140098572,
                0.9999999403953552,
                0.8714625835418701,
                0.8743125796318054,
                0.7507759928703308,
                0.8480139970779419,
                0.8489957451820374,
                0.826992928981781,
                0.8516892194747925,
                0.8189581632614136,
                0.8907420039176941,
                0.907861053943634,
                0.7556650042533875,
                0.7801900506019592,
                0.7538625001907349,
                0.758985161781311,
                0.7827985882759094,
                0.8301057815551758,
                0.8183217644691467,
                0.8588051795959473,
                0.7869716882705688,
                0.8178315758705139,
                0.8388092517852783,
                0.8076631426811218,
                0.7805310487747192,
                0.8464337587356567,
                0.7978557348251343,
                0.7641870379447937,
                0.8283364772796631,
                0.8010042905807495,
                0.7557445764541626,
                0.8386236429214478,
                0.8160614371299744,
                0.8114936947822571,
                0.7905194759368896,
                0.8579065203666687,
                0.9076017141342163,
                0.7690153121948242,
                0.7962393760681152,
                0.7892122268676758,
                0.7825109362602234,
                0.8392481803894043,
                0.8143317103385925,
                0.7861817479133606,
                0.7086531519889832,
                0.8199095129966736,
                0.7728083729743958,
                0.8785485029220581,
                0.7432496547698975
            ],
            [
                0.7387228012084961,
                0.766677975654602,
                0.7708519697189331,
                0.8714625835418701,
                0.9999999403953552,
                0.9095898866653442,
                0.7370571494102478,
                0.8932387232780457,
                0.9320833086967468,
                0.8707148432731628,
                0.793830156326294,
                0.9277101159095764,
                0.832614004611969,
                0.9094485640525818,
                0.8636711239814758,
                0.7526748776435852,
                0.6928186416625977,
                0.8498668074607849,
                0.7819053530693054,
                0.803043782711029,
                0.8177495002746582,
                0.8303605914115906,
                0.7880932688713074,
                0.7948123216629028,
                0.9014176726341248,
                0.834104597568512,
                0.8614925146102905,
                0.853947103023529,
                0.9070226550102234,
                0.91688072681427,
                0.8739364743232727,
                0.8932626843452454,
                0.8577809929847717,
                0.8807014226913452,
                0.7992124557495117,
                0.7914966344833374,
                0.7891299724578857,
                0.7903925180435181,
                0.9064111113548279,
                0.8522998094558716,
                0.7766398191452026,
                0.7388638854026794,
                0.7996824383735657,
                0.7722561359405518,
                0.797926664352417,
                0.8050074577331543,
                0.6778779029846191,
                0.7855749726295471,
                0.8814010620117188,
                0.8738406896591187,
                0.8220590353012085
            ],
            [
                0.7654297351837158,
                0.8427343368530273,
                0.8288927674293518,
                0.8743125796318054,
                0.9095898866653442,
                0.9999998807907104,
                0.7730332612991333,
                0.8872920870780945,
                0.9085124135017395,
                0.9016185998916626,
                0.8630573749542236,
                0.8847760558128357,
                0.8544766306877136,
                0.9070560932159424,
                0.8440355062484741,
                0.7756270170211792,
                0.7437823414802551,
                0.8461238145828247,
                0.8009296655654907,
                0.8272485136985779,
                0.8237488865852356,
                0.846175491809845,
                0.7973957657814026,
                0.8136518001556396,
                0.8779643774032593,
                0.8437584638595581,
                0.8619140386581421,
                0.8608438372612,
                0.8878827691078186,
                0.8799224495887756,
                0.8598067760467529,
                0.8895272016525269,
                0.8529249429702759,
                0.868492066860199,
                0.8157867193222046,
                0.8284801244735718,
                0.7919548153877258,
                0.8464986085891724,
                0.9183562994003296,
                0.8602520227432251,
                0.8033566474914551,
                0.7906540036201477,
                0.8306090831756592,
                0.8241985440254211,
                0.8288237452507019,
                0.8080368041992188,
                0.7367649078369141,
                0.8363285064697266,
                0.8729369044303894,
                0.8894771933555603,
                0.8412774801254272
            ],
            [
                0.8391157388687134,
                0.6989777684211731,
                0.8325764536857605,
                0.7507759928703308,
                0.7370571494102478,
                0.7730332612991333,
                0.9999998807907104,
                0.7751782536506653,
                0.7931489944458008,
                0.7293962836265564,
                0.8056775331497192,
                0.7431195974349976,
                0.8106009364128113,
                0.7667824029922485,
                0.7143675684928894,
                0.7874945402145386,
                0.799479603767395,
                0.7138692140579224,
                0.772101640701294,
                0.7996998429298401,
                0.7520185112953186,
                0.8033909797668457,
                0.7474765181541443,
                0.7977681159973145,
                0.7625172734260559,
                0.8214890360832214,
                0.7980822920799255,
                0.8492924571037292,
                0.7180203199386597,
                0.7671284079551697,
                0.8606662750244141,
                0.7542341947555542,
                0.7523753643035889,
                0.8466398119926453,
                0.7883439660072327,
                0.8117327690124512,
                0.7322293519973755,
                0.8288799524307251,
                0.7410916686058044,
                0.7197422385215759,
                0.7612900733947754,
                0.8080098032951355,
                0.732526957988739,
                0.7811925411224365,
                0.760124921798706,
                0.7328559160232544,
                0.7698110342025757,
                0.8180665969848633,
                0.7368586659431458,
                0.8583579063415527,
                0.7801539301872253
            ],
            [
                0.8218138217926025,
                0.8215378522872925,
                0.8337953090667725,
                0.8480139970779419,
                0.8932387232780457,
                0.8872920870780945,
                0.7751782536506653,
                0.9999998807907104,
                0.898479700088501,
                0.8632960319519043,
                0.8400934934616089,
                0.8960162401199341,
                0.9193159341812134,
                0.8998110294342041,
                0.8723504543304443,
                0.7452777624130249,
                0.7497615218162537,
                0.8682498931884766,
                0.7915626168251038,
                0.8598635792732239,
                0.8069427609443665,
                0.8875216841697693,
                0.7751895785331726,
                0.8245636820793152,
                0.8431932330131531,
                0.8194423913955688,
                0.8031888008117676,
                0.8929851055145264,
                0.8521001935005188,
                0.8654096722602844,
                0.8790178894996643,
                0.8236885666847229,
                0.7635137438774109,
                0.9058518409729004,
                0.8345126509666443,
                0.8537958860397339,
                0.7814128398895264,
                0.8802009224891663,
                0.9007790684700012,
                0.8695180416107178,
                0.7976274490356445,
                0.8383669853210449,
                0.7664523720741272,
                0.8464661836624146,
                0.7993737459182739,
                0.7590681314468384,
                0.7329615950584412,
                0.8474656939506531,
                0.8215854167938232,
                0.9190301895141602,
                0.7559420466423035
            ],
            [
                0.7814123034477234,
                0.7656672596931458,
                0.8124133944511414,
                0.8489957451820374,
                0.9320833086967468,
                0.9085124135017395,
                0.7931489944458008,
                0.898479700088501,
                1.0,
                0.9047386646270752,
                0.8071837425231934,
                0.9276434183120728,
                0.8793973326683044,
                0.9095086455345154,
                0.8286104798316956,
                0.8023026585578918,
                0.7652341723442078,
                0.8082134127616882,
                0.8152748942375183,
                0.8297382593154907,
                0.8534016609191895,
                0.8588125109672546,
                0.826673150062561,
                0.8285554647445679,
                0.9133911728858948,
                0.8565289974212646,
                0.8952866792678833,
                0.8804032206535339,
                0.9035554528236389,
                0.9205820560455322,
                0.869937002658844,
                0.9070101380348206,
                0.866349995136261,
                0.8842555284500122,
                0.8517675399780273,
                0.8309731483459473,
                0.8199841976165771,
                0.8365868330001831,
                0.8912432789802551,
                0.8270370364189148,
                0.821689784526825,
                0.8171442151069641,
                0.8324783444404602,
                0.8100546598434448,
                0.8231849074363708,
                0.8216390013694763,
                0.7350082397460938,
                0.8210291266441345,
                0.8935049772262573,
                0.900662899017334,
                0.8395447731018066
            ],
            [
                0.733456015586853,
                0.783206045627594,
                0.789653480052948,
                0.826992928981781,
                0.8707148432731628,
                0.9016185998916626,
                0.7293962836265564,
                0.8632960319519043,
                0.9047386646270752,
                0.9999998211860657,
                0.8343291878700256,
                0.9204333424568176,
                0.8657729029655457,
                0.8889185786247253,
                0.7757368087768555,
                0.8384371995925903,
                0.7511926889419556,
                0.7719154953956604,
                0.8570622205734253,
                0.8248382210731506,
                0.8639917373657227,
                0.8413606882095337,
                0.8596746921539307,
                0.80259770154953,
                0.8801588416099548,
                0.8673068284988403,
                0.8714362382888794,
                0.8449621200561523,
                0.9235749840736389,
                0.8962950110435486,
                0.8076642155647278,
                0.9088379740715027,
                0.8612148761749268,
                0.8238794207572937,
                0.8557729721069336,
                0.818524956703186,
                0.8572406768798828,
                0.8415283560752869,
                0.893493115901947,
                0.7826037406921387,
                0.8413703441619873,
                0.7968947887420654,
                0.8645435571670532,
                0.8170026540756226,
                0.8764570951461792,
                0.8311823010444641,
                0.740622878074646,
                0.8205557465553284,
                0.8790314197540283,
                0.8550337553024292,
                0.8375307321548462
            ],
            [
                0.795674741268158,
                0.8513755202293396,
                0.8804036974906921,
                0.8516892194747925,
                0.793830156326294,
                0.8630573749542236,
                0.8056775331497192,
                0.8400934934616089,
                0.8071837425231934,
                0.8343291878700256,
                1.0000001192092896,
                0.7806314826011658,
                0.8949816226959229,
                0.8720225691795349,
                0.7791357636451721,
                0.8072232007980347,
                0.8531201481819153,
                0.8010556697845459,
                0.8089669346809387,
                0.8871516585350037,
                0.7904739379882812,
                0.8880155682563782,
                0.788163423538208,
                0.8830200433731079,
                0.8244510293006897,
                0.8516078591346741,
                0.8086416721343994,
                0.8987842798233032,
                0.7985616326332092,
                0.7852218151092529,
                0.8745232224464417,
                0.8192894458770752,
                0.7911989688873291,
                0.8798274993896484,
                0.802436351776123,
                0.9053881764411926,
                0.7740377187728882,
                0.9088569283485413,
                0.8738659024238586,
                0.8105803728103638,
                0.7908489108085632,
                0.8524708151817322,
                0.7988355755805969,
                0.8944599032402039,
                0.8000271916389465,
                0.7621905207633972,
                0.8416001200675964,
                0.8822543621063232,
                0.7888660430908203,
                0.8986061215400696,
                0.7914522290229797
            ],
            [
                0.7347313165664673,
                0.7337475419044495,
                0.7619901895523071,
                0.8189581632614136,
                0.9277101159095764,
                0.8847760558128357,
                0.7431195974349976,
                0.8960162401199341,
                0.9276434183120728,
                0.9204333424568176,
                0.7806314826011658,
                0.9999998807907104,
                0.8389452695846558,
                0.8702401518821716,
                0.8366948366165161,
                0.778166651725769,
                0.705787181854248,
                0.823976457118988,
                0.8222606182098389,
                0.8105520606040955,
                0.849618136882782,
                0.8345699310302734,
                0.8225120306015015,
                0.7884995341300964,
                0.9079502820968628,
                0.8641135096549988,
                0.8795987963676453,
                0.8550477027893066,
                0.9385330080986023,
                0.9334542751312256,
                0.8470439314842224,
                0.9139605164527893,
                0.8737648725509644,
                0.8700732588768005,
                0.8310261964797974,
                0.8000525832176208,
                0.821711540222168,
                0.7995795607566833,
                0.8677976131439209,
                0.8260354995727539,
                0.816907525062561,
                0.7560021281242371,
                0.8435689806938171,
                0.763575553894043,
                0.8425318002700806,
                0.8473803997039795,
                0.6934429407119751,
                0.7842686772346497,
                0.9102463722229004,
                0.8606550097465515,
                0.8430325388908386
            ],
            [
                0.8476800322532654,
                0.8178081512451172,
                0.8806289434432983,
                0.8907420039176941,
                0.832614004611969,
                0.8544766306877136,
                0.8106009364128113,
                0.9193159341812134,
                0.8793973326683044,
                0.8657729029655457,
                0.8949816226959229,
                0.8389452695846558,
                1.0,
                0.9178940653800964,
                0.7608200907707214,
                0.80503249168396,
                0.8427027463912964,
                0.7711805701255798,
                0.8372856974601746,
                0.9064070582389832,
                0.8304674625396729,
                0.9101322293281555,
                0.815523624420166,
                0.8705531358718872,
                0.8404491543769836,
                0.8449137806892395,
                0.799423336982727,
                0.905004620552063,
                0.8114800453186035,
                0.8024682998657227,
                0.8545729517936707,
                0.8139066696166992,
                0.7531535029411316,
                0.8809468150138855,
                0.8791775703430176,
                0.8870021104812622,
                0.8216525316238403,
                0.9454168081283569,
                0.906818151473999,
                0.7860738635063171,
                0.8424009680747986,
                0.9275598526000977,
                0.8010131120681763,
                0.9191168546676636,
                0.8385314345359802,
                0.7759472727775574,
                0.811486542224884,
                0.9011653661727905,
                0.7799549102783203,
                0.9227626323699951,
                0.7455536723136902
            ],
            [
                0.790745735168457,
                0.8296982049942017,
                0.8388615846633911,
                0.907861053943634,
                0.9094485640525818,
                0.9070560932159424,
                0.7667824029922485,
                0.8998110294342041,
                0.9095086455345154,
                0.8889185786247253,
                0.8720225691795349,
                0.8702401518821716,
                0.9178940653800964,
                1.0000001192092896,
                0.8264426589012146,
                0.8236413598060608,
                0.7906748652458191,
                0.8236989974975586,
                0.8520991802215576,
                0.8748459815979004,
                0.8717914819717407,
                0.8919350504875183,
                0.8588083982467651,
                0.8546271920204163,
                0.9046381115913391,
                0.862945020198822,
                0.8491259217262268,
                0.8864993453025818,
                0.8638013005256653,
                0.8509429097175598,
                0.8642831444740295,
                0.8710730671882629,
                0.8137031197547913,
                0.8756923079490662,
                0.8666796088218689,
                0.863644540309906,
                0.8552688360214233,
                0.895250141620636,
                0.9694730043411255,
                0.8392345309257507,
                0.8304953575134277,
                0.8407653570175171,
                0.8212788701057434,
                0.8886725306510925,
                0.8430890440940857,
                0.8025549054145813,
                0.7676926255226135,
                0.874435544013977,
                0.8290858864784241,
                0.9029666185379028,
                0.7967609167098999
            ],
            [
                0.7120070457458496,
                0.8125450611114502,
                0.7553275227546692,
                0.7556650042533875,
                0.8636711239814758,
                0.8440355062484741,
                0.7143675684928894,
                0.8723504543304443,
                0.8286104798316956,
                0.7757368087768555,
                0.7791357636451721,
                0.8366948366165161,
                0.7608200907707214,
                0.8264426589012146,
                0.9999999403953552,
                0.7182913422584534,
                0.6961578726768494,
                0.9777937531471252,
                0.727645993232727,
                0.813897430896759,
                0.770153820514679,
                0.832836389541626,
                0.7277346849441528,
                0.8112484812736511,
                0.8273231983184814,
                0.7663412690162659,
                0.7932428121566772,
                0.8518998622894287,
                0.8249174356460571,
                0.8420712351799011,
                0.9057538509368896,
                0.7952454090118408,
                0.7722276449203491,
                0.9089064598083496,
                0.7498652338981628,
                0.8195292949676514,
                0.7379876375198364,
                0.7677766680717468,
                0.8261041045188904,
                0.9673341512680054,
                0.7248205542564392,
                0.7010442018508911,
                0.7184704542160034,
                0.753290057182312,
                0.742874026298523,
                0.7453231811523438,
                0.6851769089698792,
                0.7854005098342896,
                0.8273358941078186,
                0.8579863905906677,
                0.7674499750137329
            ],
            [
                0.7346446514129639,
                0.7209212183952332,
                0.830098032951355,
                0.7801900506019592,
                0.7526748776435852,
                0.7756270170211792,
                0.7874945402145386,
                0.7452777624130249,
                0.8023026585578918,
                0.8384371995925903,
                0.8072232007980347,
                0.778166651725769,
                0.80503249168396,
                0.8236413598060608,
                0.7182913422584534,
                1.0000003576278687,
                0.8495622873306274,
                0.7139700651168823,
                0.9150756001472473,
                0.8166411519050598,
                0.8956916332244873,
                0.8279898166656494,
                0.919337272644043,
                0.8309215903282166,
                0.8314184546470642,
                0.8691144585609436,
                0.8460906744003296,
                0.8335283994674683,
                0.8112563490867615,
                0.7851916551589966,
                0.8124339580535889,
                0.8379752039909363,
                0.8399016857147217,
                0.805793046951294,
                0.8786520957946777,
                0.8429306149482727,
                0.8934504985809326,
                0.8310537934303284,
                0.7899960279464722,
                0.730657696723938,
                0.8636736869812012,
                0.7931810617446899,
                0.84603351354599,
                0.7883792519569397,
                0.8957494497299194,
                0.8365986347198486,
                0.7853142619132996,
                0.8040152788162231,
                0.8244436383247375,
                0.8305789232254028,
                0.8311936855316162
            ],
            [
                0.7830994129180908,
                0.730938196182251,
                0.8759992122650146,
                0.7538625001907349,
                0.6928186416625977,
                0.7437823414802551,
                0.799479603767395,
                0.7497615218162537,
                0.7652341723442078,
                0.7511926889419556,
                0.8531201481819153,
                0.705787181854248,
                0.8427027463912964,
                0.7906748652458191,
                0.6961578726768494,
                0.8495622873306274,
                0.9999998807907104,
                0.6966809034347534,
                0.7884721755981445,
                0.8905246257781982,
                0.7769819498062134,
                0.874476432800293,
                0.7790517807006836,
                0.9110936522483826,
                0.7818814516067505,
                0.8305261135101318,
                0.7696499824523926,
                0.8566878437995911,
                0.7205570340156555,
                0.7101938724517822,
                0.8108050227165222,
                0.7602953910827637,
                0.7301957011222839,
                0.8245387673377991,
                0.7976341247558594,
                0.9261312484741211,
                0.7618820071220398,
                0.9066643714904785,
                0.7622935771942139,
                0.7228973507881165,
                0.7705257534980774,
                0.8765569925308228,
                0.7727771997451782,
                0.847907543182373,
                0.7687957286834717,
                0.751181423664093,
                0.9031481742858887,
                0.8510957360267639,
                0.739417552947998,
                0.8409280776977539,
                0.7356957197189331
            ],
            [
                0.7057644128799438,
                0.8203067183494568,
                0.7586115598678589,
                0.758985161781311,
                0.8498668074607849,
                0.8461238145828247,
                0.7138692140579224,
                0.8682498931884766,
                0.8082134127616882,
                0.7719154953956604,
                0.8010556697845459,
                0.823976457118988,
                0.7711805701255798,
                0.8236989974975586,
                0.9777937531471252,
                0.7139700651168823,
                0.6966809034347534,
                1.0000001192092896,
                0.7605386972427368,
                0.8423383235931396,
                0.7652008533477783,
                0.8437742590904236,
                0.730556309223175,
                0.8215090036392212,
                0.8224957585334778,
                0.7762266397476196,
                0.7888211011886597,
                0.8619985580444336,
                0.8210940957069397,
                0.8319117426872253,
                0.903411865234375,
                0.7930326461791992,
                0.7722421288490295,
                0.909010648727417,
                0.7488096952438354,
                0.8349629044532776,
                0.7426653504371643,
                0.7882391214370728,
                0.8296750783920288,
                0.9734246134757996,
                0.7316587567329407,
                0.7132563591003418,
                0.7198445796966553,
                0.7720048427581787,
                0.7499735355377197,
                0.7399448752403259,
                0.6979390382766724,
                0.8036528825759888,
                0.8216560482978821,
                0.8567457795143127,
                0.7750162482261658
            ],
            [
                0.7446556091308594,
                0.7304868102073669,
                0.7912496328353882,
                0.7827985882759094,
                0.7819053530693054,
                0.8009296655654907,
                0.772101640701294,
                0.7915626168251038,
                0.8152748942375183,
                0.8570622205734253,
                0.8089669346809387,
                0.8222606182098389,
                0.8372856974601746,
                0.8520991802215576,
                0.727645993232727,
                0.9150756001472473,
                0.7884721755981445,
                0.7605386972427368,
                1.0000001192092896,
                0.8509256839752197,
                0.931955873966217,
                0.8409774303436279,
                0.9538788199424744,
                0.8228609561920166,
                0.8561863899230957,
                0.8811231255531311,
                0.8516911864280701,
                0.8386868834495544,
                0.8368180990219116,
                0.8204450607299805,
                0.8071896433830261,
                0.8496952056884766,
                0.8519809246063232,
                0.814323365688324,
                0.9249911308288574,
                0.8377273082733154,
                0.9365063309669495,
                0.8361722826957703,
                0.8128789663314819,
                0.7584908604621887,
                0.8980280160903931,
                0.8156729936599731,
                0.8631157279014587,
                0.8223689794540405,
                0.9204839468002319,
                0.8462235927581787,
                0.7694429755210876,
                0.8268423080444336,
                0.8543470501899719,
                0.823746919631958,
                0.8371447324752808
            ],
            [
                0.7798014283180237,
                0.821091890335083,
                0.8493345379829407,
                0.8301057815551758,
                0.803043782711029,
                0.8272485136985779,
                0.7996998429298401,
                0.8598635792732239,
                0.8297382593154907,
                0.8248382210731506,
                0.8871516585350037,
                0.8105520606040955,
                0.9064070582389832,
                0.8748459815979004,
                0.813897430896759,
                0.8166411519050598,
                0.8905246257781982,
                0.8423383235931396,
                0.8509256839752197,
                1.0,
                0.8317766785621643,
                0.9623287320137024,
                0.8149033188819885,
                0.9282398223876953,
                0.8523806929588318,
                0.8683168888092041,
                0.8192843794822693,
                0.9201006889343262,
                0.8121053576469421,
                0.7960143089294434,
                0.8793169260025024,
                0.820834219455719,
                0.777653157711029,
                0.9043678641319275,
                0.8497034311294556,
                0.937415361404419,
                0.8188390731811523,
                0.9314725399017334,
                0.8681516647338867,
                0.8334785103797913,
                0.8188737034797668,
                0.8820961713790894,
                0.7915136814117432,
                0.9095922708511353,
                0.8285225629806519,
                0.7897941470146179,
                0.8604249954223633,
                0.914318323135376,
                0.8017874956130981,
                0.8918513655662537,
                0.7774296402931213
            ],
            [
                0.7458698749542236,
                0.7407135367393494,
                0.7890876531600952,
                0.8183217644691467,
                0.8177495002746582,
                0.8237488865852356,
                0.7520185112953186,
                0.8069427609443665,
                0.8534016609191895,
                0.8639917373657227,
                0.7904739379882812,
                0.849618136882782,
                0.8304674625396729,
                0.8717914819717407,
                0.770153820514679,
                0.8956916332244873,
                0.7769819498062134,
                0.7652008533477783,
                0.931955873966217,
                0.8317766785621643,
                1.0,
                0.8660956025123596,
                0.9573943614959717,
                0.8237082362174988,
                0.8855661749839783,
                0.8816978931427002,
                0.8697683811187744,
                0.8392760157585144,
                0.846454381942749,
                0.8372312188148499,
                0.8217429518699646,
                0.8599833250045776,
                0.8647246956825256,
                0.8392161130905151,
                0.9563723802566528,
                0.8416231870651245,
                0.9653551578521729,
                0.8264077305793762,
                0.8255006670951843,
                0.7888275384902954,
                0.8957479596138,
                0.8101562261581421,
                0.8792123794555664,
                0.816002607345581,
                0.9287596940994263,
                0.8794153332710266,
                0.7533631324768066,
                0.8263079524040222,
                0.8800961375236511,
                0.8435335159301758,
                0.833815336227417
            ],
            [
                0.8130492568016052,
                0.8441230058670044,
                0.8668421506881714,
                0.8588051795959473,
                0.8303605914115906,
                0.846175491809845,
                0.8033909797668457,
                0.8875216841697693,
                0.8588125109672546,
                0.8413606882095337,
                0.8880155682563782,
                0.8345699310302734,
                0.9101322293281555,
                0.8919350504875183,
                0.832836389541626,
                0.8279898166656494,
                0.874476432800293,
                0.8437742590904236,
                0.8409774303436279,
                0.9623287320137024,
                0.8660956025123596,
                1.0,
                0.8289456963539124,
                0.9233995079994202,
                0.8581082224845886,
                0.8707241415977478,
                0.8327130079269409,
                0.9310877323150635,
                0.8253962993621826,
                0.8161577582359314,
                0.8932174444198608,
                0.8300806283950806,
                0.7907354831695557,
                0.9237512946128845,
                0.8742169737815857,
                0.9381036758422852,
                0.8329789042472839,
                0.9298461675643921,
                0.8817323446273804,
                0.8486279845237732,
                0.8335995674133301,
                0.8897584676742554,
                0.8023619651794434,
                0.9148197174072266,
                0.8363664746284485,
                0.7912153601646423,
                0.842766523361206,
                0.9161181449890137,
                0.821808397769928,
                0.913598358631134,
                0.7845165729522705
            ],
            [
                0.7085978984832764,
                0.7088356018066406,
                0.7754576802253723,
                0.7869716882705688,
                0.7880932688713074,
                0.7973957657814026,
                0.7474765181541443,
                0.7751895785331726,
                0.826673150062561,
                0.8596746921539307,
                0.788163423538208,
                0.8225120306015015,
                0.815523624420166,
                0.8588083982467651,
                0.7277346849441528,
                0.919337272644043,
                0.7790517807006836,
                0.730556309223175,
                0.9538788199424744,
                0.8149033188819885,
                0.9573943614959717,
                0.8289456963539124,
                0.9999998807907104,
                0.8381658792495728,
                0.8778814077377319,
                0.8843741416931152,
                0.8692885041236877,
                0.8243117332458496,
                0.8371097445487976,
                0.8151800632476807,
                0.7995904684066772,
                0.858847975730896,
                0.8628278970718384,
                0.8009328246116638,
                0.9290363192558289,
                0.8316181302070618,
                0.9594994187355042,
                0.8143619894981384,
                0.8077599406242371,
                0.7600763440132141,
                0.9050127267837524,
                0.7913379669189453,
                0.8877755403518677,
                0.7998232841491699,
                0.9316357374191284,
                0.8708899021148682,
                0.7548211812973022,
                0.8079540729522705,
                0.8681991696357727,
                0.8153663873672485,
                0.8404738306999207
            ],
            [
                0.7781132459640503,
                0.7946955561637878,
                0.871134340763092,
                0.8178315758705139,
                0.7948123216629028,
                0.8136518001556396,
                0.7977681159973145,
                0.8245636820793152,
                0.8285554647445679,
                0.80259770154953,
                0.8830200433731079,
                0.7884995341300964,
                0.8705531358718872,
                0.8546271920204163,
                0.8112484812736511,
                0.8309215903282166,
                0.9110936522483826,
                0.8215090036392212,
                0.8228609561920166,
                0.9282398223876953,
                0.8237082362174988,
                0.9233995079994202,
                0.8381658792495728,
                1.0,
                0.8591093420982361,
                0.8721843361854553,
                0.8259442448616028,
                0.9036279320716858,
                0.7934167385101318,
                0.7838954925537109,
                0.8879059553146362,
                0.814865231513977,
                0.7905744314193726,
                0.8918323516845703,
                0.8334898352622986,
                0.9476875066757202,
                0.8122808337211609,
                0.9097473621368408,
                0.8328224420547485,
                0.8493649363517761,
                0.8217999935150146,
                0.8696874380111694,
                0.8117287755012512,
                0.8741145730018616,
                0.8107660412788391,
                0.790867269039154,
                0.8673944473266602,
                0.884038507938385,
                0.8156195282936096,
                0.8960593938827515,
                0.7960077524185181
            ],
            [
                0.718978762626648,
                0.7434845566749573,
                0.7924861311912537,
                0.8388092517852783,
                0.9014176726341248,
                0.8779643774032593,
                0.7625172734260559,
                0.8431932330131531,
                0.9133911728858948,
                0.8801588416099548,
                0.8244510293006897,
                0.9079502820968628,
                0.8404491543769836,
                0.9046381115913391,
                0.8273231983184814,
                0.8314184546470642,
                0.7818814516067505,
                0.8224957585334778,
                0.8561863899230957,
                0.8523806929588318,
                0.8855661749839783,
                0.8581082224845886,
                0.8778814077377319,
                0.8591093420982361,
                1.0,
                0.9341030716896057,
                0.92239910364151,
                0.9057408571243286,
                0.918698787689209,
                0.903741180896759,
                0.8804789781570435,
                0.9205992817878723,
                0.8987071514129639,
                0.8844606280326843,
                0.8569585084915161,
                0.8610922694206238,
                0.8666175007820129,
                0.8224189281463623,
                0.8739832043647766,
                0.8362783789634705,
                0.8209710717201233,
                0.780441403388977,
                0.856757402420044,
                0.8088290691375732,
                0.8539968132972717,
                0.862655520439148,
                0.7654291391372681,
                0.8195318579673767,
                0.9120448231697083,
                0.8775568008422852,
                0.8906264305114746
            ],
            [
                0.7759293913841248,
                0.7480157017707825,
                0.8415861129760742,
                0.8076631426811218,
                0.834104597568512,
                0.8437584638595581,
                0.8214890360832214,
                0.8194423913955688,
                0.8565289974212646,
                0.8673068284988403,
                0.8516078591346741,
                0.8641135096549988,
                0.8449137806892395,
                0.862945020198822,
                0.7663412690162659,
                0.8691144585609436,
                0.8305261135101318,
                0.7762266397476196,
                0.8811231255531311,
                0.8683168888092041,
                0.8816978931427002,
                0.8707241415977478,
                0.8843741416931152,
                0.8721843361854553,
                0.9341030716896057,
                0.9999998211860657,
                0.9288981556892395,
                0.9153223037719727,
                0.8990269899368286,
                0.887895941734314,
                0.8760529160499573,
                0.9080654382705688,
                0.9009037613868713,
                0.8784628510475159,
                0.8713410496711731,
                0.8907797932624817,
                0.8715682625770569,
                0.8672940135002136,
                0.8347780108451843,
                0.7904444336891174,
                0.8403067588806152,
                0.8323003053665161,
                0.8801760077476501,
                0.8265492916107178,
                0.8766734600067139,
                0.877899169921875,
                0.8285415172576904,
                0.8521500825881958,
                0.8918730616569519,
                0.8916156888008118,
                0.9270108938217163
            ],
            [
                0.7422618865966797,
                0.7312925457954407,
                0.7954675555229187,
                0.7805310487747192,
                0.8614925146102905,
                0.8619140386581421,
                0.7980822920799255,
                0.8031888008117676,
                0.8952866792678833,
                0.8714362382888794,
                0.8086416721343994,
                0.8795987963676453,
                0.799423336982727,
                0.8491259217262268,
                0.7932428121566772,
                0.8460906744003296,
                0.7696499824523926,
                0.7888211011886597,
                0.8516911864280701,
                0.8192843794822693,
                0.8697683811187744,
                0.8327130079269409,
                0.8692885041236877,
                0.8259442448616028,
                0.92239910364151,
                0.9288981556892395,
                1.0,
                0.8895915746688843,
                0.8870569467544556,
                0.9275015592575073,
                0.8757904171943665,
                0.9065210819244385,
                0.9293832778930664,
                0.8657867908477783,
                0.8491930365562439,
                0.8392125368118286,
                0.8507762551307678,
                0.8064161539077759,
                0.825604259967804,
                0.8040833473205566,
                0.8156164288520813,
                0.7842699885368347,
                0.8523399233818054,
                0.7812719941139221,
                0.858738899230957,
                0.8515391945838928,
                0.7761228680610657,
                0.8226080536842346,
                0.9275893568992615,
                0.8746117949485779,
                0.9601459503173828
            ],
            [
                0.8303143978118896,
                0.8251214027404785,
                0.8858296871185303,
                0.8464337587356567,
                0.853947103023529,
                0.8608438372612,
                0.8492924571037292,
                0.8929851055145264,
                0.8804032206535339,
                0.8449621200561523,
                0.8987842798233032,
                0.8550477027893066,
                0.905004620552063,
                0.8864993453025818,
                0.8518998622894287,
                0.8335283994674683,
                0.8566878437995911,
                0.8619985580444336,
                0.8386868834495544,
                0.9201006889343262,
                0.8392760157585144,
                0.9310877323150635,
                0.8243117332458496,
                0.9036279320716858,
                0.9057408571243286,
                0.9153223037719727,
                0.8895915746688843,
                1.0,
                0.8568708300590515,
                0.866061270236969,
                0.9468305110931396,
                0.8510240912437439,
                0.8260084986686707,
                0.9557573199272156,
                0.8471883535385132,
                0.9223989844322205,
                0.8243947625160217,
                0.9122757911682129,
                0.8754240274429321,
                0.8632059693336487,
                0.8112589716911316,
                0.8734403252601624,
                0.7974370121955872,
                0.8812180757522583,
                0.8384751677513123,
                0.8039525747299194,
                0.8325696587562561,
                0.9109834432601929,
                0.8519244194030762,
                0.9429506063461304,
                0.846892237663269
            ],
            [
                0.708190381526947,
                0.7471506595611572,
                0.7605605721473694,
                0.7978557348251343,
                0.9070226550102234,
                0.8878827691078186,
                0.7180203199386597,
                0.8521001935005188,
                0.9035554528236389,
                0.9235749840736389,
                0.7985616326332092,
                0.9385330080986023,
                0.8114800453186035,
                0.8638013005256653,
                0.8249174356460571,
                0.8112563490867615,
                0.7205570340156555,
                0.8210940957069397,
                0.8368180990219116,
                0.8121053576469421,
                0.846454381942749,
                0.8253962993621826,
                0.8371097445487976,
                0.7934167385101318,
                0.918698787689209,
                0.8990269899368286,
                0.8870569467544556,
                0.8568708300590515,
                1.0,
                0.943849503993988,
                0.8384860754013062,
                0.9662572741508484,
                0.9160321950912476,
                0.8594834804534912,
                0.8206749558448792,
                0.8107470273971558,
                0.8302587270736694,
                0.7939449548721313,
                0.8639997243881226,
                0.8254907727241516,
                0.810344398021698,
                0.747637152671814,
                0.8775091171264648,
                0.7629592418670654,
                0.8513172268867493,
                0.8737971782684326,
                0.7189524173736572,
                0.7796887159347534,
                0.9216979742050171,
                0.8418780565261841,
                0.8790168762207031
            ],
            [
                0.7607007622718811,
                0.7311540246009827,
                0.7730497121810913,
                0.7641870379447937,
                0.91688072681427,
                0.8799224495887756,
                0.7671284079551697,
                0.8654096722602844,
                0.9205820560455322,
                0.8962950110435486,
                0.7852218151092529,
                0.9334542751312256,
                0.8024682998657227,
                0.8509429097175598,
                0.8420712351799011,
                0.7851916551589966,
                0.7101938724517822,
                0.8319117426872253,
                0.8204450607299805,
                0.7960143089294434,
                0.8372312188148499,
                0.8161577582359314,
                0.8151800632476807,
                0.7838954925537109,
                0.903741180896759,
                0.887895941734314,
                0.9275015592575073,
                0.866061270236969,
                0.943849503993988,
                0.9999999403953552,
                0.8754903674125671,
                0.924094021320343,
                0.920017659664154,
                0.8824212551116943,
                0.821927547454834,
                0.8048803210258484,
                0.8121194839477539,
                0.7844035625457764,
                0.8405523896217346,
                0.8307260870933533,
                0.8005333542823792,
                0.7710898518562317,
                0.8322503566741943,
                0.76200270652771,
                0.8276470303535461,
                0.8377193212509155,
                0.7265644073486328,
                0.7990532517433167,
                0.935992956161499,
                0.865487813949585,
                0.9120705723762512
            ],
            [
                0.8234682083129883,
                0.8163830041885376,
                0.862755537033081,
                0.8283364772796631,
                0.8739364743232727,
                0.8598067760467529,
                0.8606662750244141,
                0.8790178894996643,
                0.869937002658844,
                0.8076642155647278,
                0.8745232224464417,
                0.8470439314842224,
                0.8545729517936707,
                0.8642831444740295,
                0.9057538509368896,
                0.8124339580535889,
                0.8108050227165222,
                0.903411865234375,
                0.8071896433830261,
                0.8793169260025024,
                0.8217429518699646,
                0.8932174444198608,
                0.7995904684066772,
                0.8879059553146362,
                0.8804789781570435,
                0.8760529160499573,
                0.8757904171943665,
                0.9468305110931396,
                0.8384860754013062,
                0.8754903674125671,
                0.9999998807907104,
                0.8387875556945801,
                0.8450141549110413,
                0.9737253189086914,
                0.825160562992096,
                0.8965027332305908,
                0.7984995245933533,
                0.8691496849060059,
                0.8545857667922974,
                0.9096711874008179,
                0.7992320656776428,
                0.8210470080375671,
                0.7869926691055298,
                0.8369279503822327,
                0.8146988749504089,
                0.7994696497917175,
                0.78459632396698,
                0.8786166906356812,
                0.8612622618675232,
                0.9426924586296082,
                0.8523727655410767
            ],
            [
                0.7036552429199219,
                0.7407820224761963,
                0.764765739440918,
                0.8010042905807495,
                0.8932626843452454,
                0.8895272016525269,
                0.7542341947555542,
                0.8236885666847229,
                0.9070101380348206,
                0.9088379740715027,
                0.8192894458770752,
                0.9139605164527893,
                0.8139066696166992,
                0.8710730671882629,
                0.7952454090118408,
                0.8379752039909363,
                0.7602953910827637,
                0.7930326461791992,
                0.8496952056884766,
                0.820834219455719,
                0.8599833250045776,
                0.8300806283950806,
                0.858847975730896,
                0.814865231513977,
                0.9205992817878723,
                0.9080654382705688,
                0.9065210819244385,
                0.8510240912437439,
                0.9662572741508484,
                0.924094021320343,
                0.8387875556945801,
                1.0000003576278687,
                0.9516121745109558,
                0.8561820387840271,
                0.8351725339889526,
                0.8254635334014893,
                0.8422484993934631,
                0.8072351217269897,
                0.8650186061859131,
                0.8188551664352417,
                0.8322482705116272,
                0.7732598781585693,
                0.9060143828392029,
                0.7849317789077759,
                0.8558706641197205,
                0.8788999319076538,
                0.7489951252937317,
                0.7974324822425842,
                0.919266939163208,
                0.8435444235801697,
                0.8966994285583496
            ],
            [
                0.6903634667396545,
                0.7032029628753662,
                0.7466430068016052,
                0.7557445764541626,
                0.8577809929847717,
                0.8529249429702759,
                0.7523753643035889,
                0.7635137438774109,
                0.866349995136261,
                0.8612148761749268,
                0.7911989688873291,
                0.8737648725509644,
                0.7531535029411316,
                0.8137031197547913,
                0.7722276449203491,
                0.8399016857147217,
                0.7301957011222839,
                0.7722421288490295,
                0.8519809246063232,
                0.777653157711029,
                0.8647246956825256,
                0.7907354831695557,
                0.8628278970718384,
                0.7905744314193726,
                0.8987071514129639,
                0.9009037613868713,
                0.9293832778930664,
                0.8260084986686707,
                0.9160321950912476,
                0.920017659664154,
                0.8450141549110413,
                0.9516121745109558,
                1.000000238418579,
                0.8464249968528748,
                0.8278875350952148,
                0.7998542785644531,
                0.8422321081161499,
                0.7558771967887878,
                0.797920286655426,
                0.8032326698303223,
                0.8255259394645691,
                0.7426205277442932,
                0.9069552421569824,
                0.7388588190078735,
                0.8560211658477783,
                0.8795708417892456,
                0.7300626039505005,
                0.769629716873169,
                0.939556896686554,
                0.8317779898643494,
                0.9454613924026489
            ],
            [
                0.8417701125144958,
                0.8321765065193176,
                0.8656322360038757,
                0.8386236429214478,
                0.8807014226913452,
                0.868492066860199,
                0.8466398119926453,
                0.9058518409729004,
                0.8842555284500122,
                0.8238794207572937,
                0.8798274993896484,
                0.8700732588768005,
                0.8809468150138855,
                0.8756923079490662,
                0.9089064598083496,
                0.805793046951294,
                0.8245387673377991,
                0.909010648727417,
                0.814323365688324,
                0.9043678641319275,
                0.8392161130905151,
                0.9237512946128845,
                0.8009328246116638,
                0.8918323516845703,
                0.8844606280326843,
                0.8784628510475159,
                0.8657867908477783,
                0.9557573199272156,
                0.8594834804534912,
                0.8824212551116943,
                0.9737253189086914,
                0.8561820387840271,
                0.8464249968528748,
                0.9999997615814209,
                0.848204493522644,
                0.9113578200340271,
                0.8122663497924805,
                0.8861600756645203,
                0.8660966157913208,
                0.9136236906051636,
                0.8137918710708618,
                0.8500345945358276,
                0.8025971055030823,
                0.862194836139679,
                0.8249161243438721,
                0.8152685761451721,
                0.7946910262107849,
                0.8921191096305847,
                0.8663385510444641,
                0.9498433470726013,
                0.8390253782272339
            ],
            [
                0.785443127155304,
                0.7471251487731934,
                0.8156403303146362,
                0.8160614371299744,
                0.7992124557495117,
                0.8157867193222046,
                0.7883439660072327,
                0.8345126509666443,
                0.8517675399780273,
                0.8557729721069336,
                0.802436351776123,
                0.8310261964797974,
                0.8791775703430176,
                0.8666796088218689,
                0.7498652338981628,
                0.8786520957946777,
                0.7976341247558594,
                0.7488096952438354,
                0.9249911308288574,
                0.8497034311294556,
                0.9563723802566528,
                0.8742169737815857,
                0.9290363192558289,
                0.8334898352622986,
                0.8569585084915161,
                0.8713410496711731,
                0.8491930365562439,
                0.8471883535385132,
                0.8206749558448792,
                0.821927547454834,
                0.825160562992096,
                0.8351725339889526,
                0.8278875350952148,
                0.848204493522644,
                0.9999998807907104,
                0.8549844026565552,
                0.9430342316627502,
                0.8619434237480164,
                0.8266434669494629,
                0.7704529762268066,
                0.9004426598548889,
                0.8637778759002686,
                0.8536130785942078,
                0.8644444346427917,
                0.9120930433273315,
                0.8423155546188354,
                0.767301082611084,
                0.8679660558700562,
                0.8456494212150574,
                0.8569396138191223,
                0.8055316209793091
            ],
            [
                0.8073573112487793,
                0.816642165184021,
                0.8931671380996704,
                0.8114936947822571,
                0.7914966344833374,
                0.8284801244735718,
                0.8117327690124512,
                0.8537958860397339,
                0.8309731483459473,
                0.818524956703186,
                0.9053881764411926,
                0.8000525832176208,
                0.8870021104812622,
                0.863644540309906,
                0.8195292949676514,
                0.8429306149482727,
                0.9261312484741211,
                0.8349629044532776,
                0.8377273082733154,
                0.937415361404419,
                0.8416231870651245,
                0.9381036758422852,
                0.8316181302070618,
                0.9476875066757202,
                0.8610922694206238,
                0.8907797932624817,
                0.8392125368118286,
                0.9223989844322205,
                0.8107470273971558,
                0.8048803210258484,
                0.8965027332305908,
                0.8254635334014893,
                0.7998542785644531,
                0.9113578200340271,
                0.8549844026565552,
                1.0000001192092896,
                0.8263451457023621,
                0.9491920471191406,
                0.8521525859832764,
                0.8494510054588318,
                0.8147081136703491,
                0.8945797085762024,
                0.8210445642471313,
                0.8900333642959595,
                0.8266032338142395,
                0.8043503165245056,
                0.8954050540924072,
                0.8968967199325562,
                0.8264747262001038,
                0.9167285561561584,
                0.8121064901351929
            ],
            [
                0.7222235202789307,
                0.7168735265731812,
                0.7640591859817505,
                0.7905194759368896,
                0.7891299724578857,
                0.7919548153877258,
                0.7322293519973755,
                0.7814128398895264,
                0.8199841976165771,
                0.8572406768798828,
                0.7740377187728882,
                0.821711540222168,
                0.8216525316238403,
                0.8552688360214233,
                0.7379876375198364,
                0.8934504985809326,
                0.7618820071220398,
                0.7426653504371643,
                0.9365063309669495,
                0.8188390731811523,
                0.9653551578521729,
                0.8329789042472839,
                0.9594994187355042,
                0.8122808337211609,
                0.8666175007820129,
                0.8715682625770569,
                0.8507762551307678,
                0.8243947625160217,
                0.8302587270736694,
                0.8121194839477539,
                0.7984995245933533,
                0.8422484993934631,
                0.8422321081161499,
                0.8122663497924805,
                0.9430342316627502,
                0.8263451457023621,
                1.0,
                0.8198361396789551,
                0.8111903667449951,
                0.7661636471748352,
                0.8957132697105408,
                0.8028527498245239,
                0.8657103180885315,
                0.8198989033699036,
                0.9292040467262268,
                0.8563216328620911,
                0.7450383305549622,
                0.830188512802124,
                0.8527804017066956,
                0.8207822442054749,
                0.8222303986549377
            ],
            [
                0.8579913377761841,
                0.8296316266059875,
                0.9104881882667542,
                0.8579065203666687,
                0.7903925180435181,
                0.8464986085891724,
                0.8288799524307251,
                0.8802009224891663,
                0.8365868330001831,
                0.8415283560752869,
                0.9088569283485413,
                0.7995795607566833,
                0.9454168081283569,
                0.895250141620636,
                0.7677766680717468,
                0.8310537934303284,
                0.9066643714904785,
                0.7882391214370728,
                0.8361722826957703,
                0.9314725399017334,
                0.8264077305793762,
                0.9298461675643921,
                0.8143619894981384,
                0.9097473621368408,
                0.8224189281463623,
                0.8672940135002136,
                0.8064161539077759,
                0.9122757911682129,
                0.7939449548721313,
                0.7844035625457764,
                0.8691496849060059,
                0.8072351217269897,
                0.7558771967887878,
                0.8861600756645203,
                0.8619434237480164,
                0.9491920471191406,
                0.8198361396789551,
                1.0000001192092896,
                0.8946322202682495,
                0.8011847734451294,
                0.8359687924385071,
                0.9364060163497925,
                0.8095523715019226,
                0.9268633723258972,
                0.845738410949707,
                0.7877027988433838,
                0.8733583688735962,
                0.927987813949585,
                0.7819386124610901,
                0.9285379648208618,
                0.7682615518569946
            ],
            [
                0.7655655741691589,
                0.8422516584396362,
                0.8310220241546631,
                0.9076017141342163,
                0.9064111113548279,
                0.9183562994003296,
                0.7410916686058044,
                0.9007790684700012,
                0.8912432789802551,
                0.893493115901947,
                0.8738659024238586,
                0.8677976131439209,
                0.906818151473999,
                0.9694730043411255,
                0.8261041045188904,
                0.7899960279464722,
                0.7622935771942139,
                0.8296750783920288,
                0.8128789663314819,
                0.8681516647338867,
                0.8255006670951843,
                0.8817323446273804,
                0.8077599406242371,
                0.8328224420547485,
                0.8739832043647766,
                0.8347780108451843,
                0.825604259967804,
                0.8754240274429321,
                0.8639997243881226,
                0.8405523896217346,
                0.8545857667922974,
                0.8650186061859131,
                0.797920286655426,
                0.8660966157913208,
                0.8266434669494629,
                0.8521525859832764,
                0.8111903667449951,
                0.8946322202682495,
                1.0,
                0.8342767953872681,
                0.8147754073143005,
                0.8262149095535278,
                0.8008953928947449,
                0.8723886013031006,
                0.8424863219261169,
                0.7852499485015869,
                0.7435815930366516,
                0.8600776195526123,
                0.8194009065628052,
                0.8964810371398926,
                0.7778515815734863
            ],
            [
                0.7169359922409058,
                0.8242638111114502,
                0.7694762945175171,
                0.7690153121948242,
                0.8522998094558716,
                0.8602520227432251,
                0.7197422385215759,
                0.8695180416107178,
                0.8270370364189148,
                0.7826037406921387,
                0.8105803728103638,
                0.8260354995727539,
                0.7860738635063171,
                0.8392345309257507,
                0.9673341512680054,
                0.730657696723938,
                0.7228973507881165,
                0.9734246134757996,
                0.7584908604621887,
                0.8334785103797913,
                0.7888275384902954,
                0.8486279845237732,
                0.7600763440132141,
                0.8493649363517761,
                0.8362783789634705,
                0.7904444336891174,
                0.8040833473205566,
                0.8632059693336487,
                0.8254907727241516,
                0.8307260870933533,
                0.9096711874008179,
                0.8188551664352417,
                0.8032326698303223,
                0.9136236906051636,
                0.7704529762268066,
                0.8494510054588318,
                0.7661636471748352,
                0.8011847734451294,
                0.8342767953872681,
                0.9999999403953552,
                0.7621999979019165,
                0.7459745407104492,
                0.7767490744590759,
                0.7841591835021973,
                0.7622767090797424,
                0.7636089324951172,
                0.7196250557899475,
                0.8116760849952698,
                0.8396916389465332,
                0.8733757138252258,
                0.7840137481689453
            ],
            [
                0.7333865165710449,
                0.7235648036003113,
                0.7879047989845276,
                0.7962393760681152,
                0.7766398191452026,
                0.8033566474914551,
                0.7612900733947754,
                0.7976274490356445,
                0.821689784526825,
                0.8413703441619873,
                0.7908489108085632,
                0.816907525062561,
                0.8424009680747986,
                0.8304953575134277,
                0.7248205542564392,
                0.8636736869812012,
                0.7705257534980774,
                0.7316587567329407,
                0.8980280160903931,
                0.8188737034797668,
                0.8957479596138,
                0.8335995674133301,
                0.9050127267837524,
                0.8217999935150146,
                0.8209710717201233,
                0.8403067588806152,
                0.8156164288520813,
                0.8112589716911316,
                0.810344398021698,
                0.8005333542823792,
                0.7992320656776428,
                0.8322482705116272,
                0.8255259394645691,
                0.8137918710708618,
                0.9004426598548889,
                0.8147081136703491,
                0.8957132697105408,
                0.8359687924385071,
                0.8147754073143005,
                0.7621999979019165,
                1.0000001192092896,
                0.84120774269104,
                0.8717689514160156,
                0.8194047212600708,
                0.939601480960846,
                0.8478014469146729,
                0.7469323873519897,
                0.8265093564987183,
                0.8338069319725037,
                0.8303109407424927,
                0.7941464781761169
            ],
            [
                0.8735455274581909,
                0.7724983096122742,
                0.8799149990081787,
                0.7892122268676758,
                0.7388638854026794,
                0.7906540036201477,
                0.8080098032951355,
                0.8383669853210449,
                0.8171442151069641,
                0.7968947887420654,
                0.8524708151817322,
                0.7560021281242371,
                0.9275598526000977,
                0.8407653570175171,
                0.7010442018508911,
                0.7931810617446899,
                0.8765569925308228,
                0.7132563591003418,
                0.8156729936599731,
                0.8820961713790894,
                0.8101562261581421,
                0.8897584676742554,
                0.7913379669189453,
                0.8696874380111694,
                0.780441403388977,
                0.8323003053665161,
                0.7842699885368347,
                0.8734403252601624,
                0.747637152671814,
                0.7710898518562317,
                0.8210470080375671,
                0.7732598781585693,
                0.7426205277442932,
                0.8500345945358276,
                0.8637778759002686,
                0.8945797085762024,
                0.8028527498245239,
                0.9364060163497925,
                0.8262149095535278,
                0.7459745407104492,
                0.84120774269104,
                1.0000001192092896,
                0.7909613251686096,
                0.9197405576705933,
                0.8207077383995056,
                0.7505744695663452,
                0.8693962693214417,
                0.9210308194160461,
                0.7582041025161743,
                0.8864484429359436,
                0.7433645725250244
            ],
            [
                0.6998342871665955,
                0.6958776116371155,
                0.7644758224487305,
                0.7825109362602234,
                0.7996824383735657,
                0.8306090831756592,
                0.732526957988739,
                0.7664523720741272,
                0.8324783444404602,
                0.8645435571670532,
                0.7988355755805969,
                0.8435689806938171,
                0.8010131120681763,
                0.8212788701057434,
                0.7184704542160034,
                0.84603351354599,
                0.7727771997451782,
                0.7198445796966553,
                0.8631157279014587,
                0.7915136814117432,
                0.8792123794555664,
                0.8023619651794434,
                0.8877755403518677,
                0.8117287755012512,
                0.856757402420044,
                0.8801760077476501,
                0.8523399233818054,
                0.7974370121955872,
                0.8775091171264648,
                0.8322503566741943,
                0.7869926691055298,
                0.9060143828392029,
                0.9069552421569824,
                0.8025971055030823,
                0.8536130785942078,
                0.8210445642471313,
                0.8657103180885315,
                0.8095523715019226,
                0.8008953928947449,
                0.7767490744590759,
                0.8717689514160156,
                0.7909613251686096,
                0.9999999403953552,
                0.7735544443130493,
                0.8918278217315674,
                0.9390988349914551,
                0.7542747259140015,
                0.777824342250824,
                0.8740993142127991,
                0.820265531539917,
                0.849231481552124
            ],
            [
                0.80934739112854,
                0.8135409951210022,
                0.8477209806442261,
                0.8392481803894043,
                0.7722561359405518,
                0.8241985440254211,
                0.7811925411224365,
                0.8464661836624146,
                0.8100546598434448,
                0.8170026540756226,
                0.8944599032402039,
                0.763575553894043,
                0.9191168546676636,
                0.8886725306510925,
                0.753290057182312,
                0.7883792519569397,
                0.847907543182373,
                0.7720048427581787,
                0.8223689794540405,
                0.9095922708511353,
                0.816002607345581,
                0.9148197174072266,
                0.7998232841491699,
                0.8741145730018616,
                0.8088290691375732,
                0.8265492916107178,
                0.7812719941139221,
                0.8812180757522583,
                0.7629592418670654,
                0.76200270652771,
                0.8369279503822327,
                0.7849317789077759,
                0.7388588190078735,
                0.862194836139679,
                0.8644444346427917,
                0.8900333642959595,
                0.8198989033699036,
                0.9268633723258972,
                0.8723886013031006,
                0.7841591835021973,
                0.8194047212600708,
                0.9197405576705933,
                0.7735544443130493,
                1.0,
                0.8187295794487,
                0.7415784597396851,
                0.8495801687240601,
                0.9631747603416443,
                0.7492198348045349,
                0.8760466575622559,
                0.7340735197067261
            ],
            [
                0.7286567687988281,
                0.7322307825088501,
                0.7911996245384216,
                0.8143317103385925,
                0.797926664352417,
                0.8288237452507019,
                0.760124921798706,
                0.7993737459182739,
                0.8231849074363708,
                0.8764570951461792,
                0.8000271916389465,
                0.8425318002700806,
                0.8385314345359802,
                0.8430890440940857,
                0.742874026298523,
                0.8957494497299194,
                0.7687957286834717,
                0.7499735355377197,
                0.9204839468002319,
                0.8285225629806519,
                0.9287596940994263,
                0.8363664746284485,
                0.9316357374191284,
                0.8107660412788391,
                0.8539968132972717,
                0.8766734600067139,
                0.858738899230957,
                0.8384751677513123,
                0.8513172268867493,
                0.8276470303535461,
                0.8146988749504089,
                0.8558706641197205,
                0.8560211658477783,
                0.8249161243438721,
                0.9120930433273315,
                0.8266032338142395,
                0.9292040467262268,
                0.845738410949707,
                0.8424863219261169,
                0.7622767090797424,
                0.939601480960846,
                0.8207077383995056,
                0.8918278217315674,
                0.8187295794487,
                1.0,
                0.9117429256439209,
                0.7620838284492493,
                0.8397193551063538,
                0.8650654554367065,
                0.838286280632019,
                0.8402613401412964
            ],
            [
                0.7028541564941406,
                0.6754620671272278,
                0.7533719539642334,
                0.7861817479133606,
                0.8050074577331543,
                0.8080368041992188,
                0.7328559160232544,
                0.7590681314468384,
                0.8216390013694763,
                0.8311823010444641,
                0.7621905207633972,
                0.8473803997039795,
                0.7759472727775574,
                0.8025549054145813,
                0.7453231811523438,
                0.8365986347198486,
                0.751181423664093,
                0.7399448752403259,
                0.8462235927581787,
                0.7897941470146179,
                0.8794153332710266,
                0.7912153601646423,
                0.8708899021148682,
                0.790867269039154,
                0.862655520439148,
                0.877899169921875,
                0.8515391945838928,
                0.8039525747299194,
                0.8737971782684326,
                0.8377193212509155,
                0.7994696497917175,
                0.8788999319076538,
                0.8795708417892456,
                0.8152685761451721,
                0.8423155546188354,
                0.8043503165245056,
                0.8563216328620911,
                0.7877027988433838,
                0.7852499485015869,
                0.7636089324951172,
                0.8478014469146729,
                0.7505744695663452,
                0.9390988349914551,
                0.7415784597396851,
                0.9117429256439209,
                0.9999999403953552,
                0.749363124370575,
                0.7702300548553467,
                0.8804543614387512,
                0.8140304088592529,
                0.8487947583198547
            ],
            [
                0.7551030516624451,
                0.7206976413726807,
                0.8151125311851501,
                0.7086531519889832,
                0.6778779029846191,
                0.7367649078369141,
                0.7698110342025757,
                0.7329615950584412,
                0.7350082397460938,
                0.740622878074646,
                0.8416001200675964,
                0.6934429407119751,
                0.811486542224884,
                0.7676926255226135,
                0.6851769089698792,
                0.7853142619132996,
                0.9031481742858887,
                0.6979390382766724,
                0.7694429755210876,
                0.8604249954223633,
                0.7533631324768066,
                0.842766523361206,
                0.7548211812973022,
                0.8673944473266602,
                0.7654291391372681,
                0.8285415172576904,
                0.7761228680610657,
                0.8325696587562561,
                0.7189524173736572,
                0.7265644073486328,
                0.78459632396698,
                0.7489951252937317,
                0.7300626039505005,
                0.7946910262107849,
                0.767301082611084,
                0.8954050540924072,
                0.7450383305549622,
                0.8733583688735962,
                0.7435815930366516,
                0.7196250557899475,
                0.7469323873519897,
                0.8693962693214417,
                0.7542747259140015,
                0.8495801687240601,
                0.7620838284492493,
                0.749363124370575,
                1.0000001192092896,
                0.8581891059875488,
                0.7366880774497986,
                0.817894697189331,
                0.7520177960395813
            ],
            [
                0.8325158953666687,
                0.8155961036682129,
                0.8545794486999512,
                0.8199095129966736,
                0.7855749726295471,
                0.8363285064697266,
                0.8180665969848633,
                0.8474656939506531,
                0.8210291266441345,
                0.8205557465553284,
                0.8822543621063232,
                0.7842686772346497,
                0.9011653661727905,
                0.874435544013977,
                0.7854005098342896,
                0.8040152788162231,
                0.8510957360267639,
                0.8036528825759888,
                0.8268423080444336,
                0.914318323135376,
                0.8263079524040222,
                0.9161181449890137,
                0.8079540729522705,
                0.884038507938385,
                0.8195318579673767,
                0.8521500825881958,
                0.8226080536842346,
                0.9109834432601929,
                0.7796887159347534,
                0.7990532517433167,
                0.8786166906356812,
                0.7974324822425842,
                0.769629716873169,
                0.8921191096305847,
                0.8679660558700562,
                0.8968967199325562,
                0.830188512802124,
                0.927987813949585,
                0.8600776195526123,
                0.8116760849952698,
                0.8265093564987183,
                0.9210308194160461,
                0.777824342250824,
                0.9631747603416443,
                0.8397193551063538,
                0.7702300548553467,
                0.8581891059875488,
                0.9999998211860657,
                0.7840585708618164,
                0.8981381058692932,
                0.7758169174194336
            ],
            [
                0.7227036952972412,
                0.7227210998535156,
                0.773863673210144,
                0.7728083729743958,
                0.8814010620117188,
                0.8729369044303894,
                0.7368586659431458,
                0.8215854167938232,
                0.8935049772262573,
                0.8790314197540283,
                0.7888660430908203,
                0.9102463722229004,
                0.7799549102783203,
                0.8290858864784241,
                0.8273358941078186,
                0.8244436383247375,
                0.739417552947998,
                0.8216560482978821,
                0.8543470501899719,
                0.8017874956130981,
                0.8800961375236511,
                0.821808397769928,
                0.8681991696357727,
                0.8156195282936096,
                0.9120448231697083,
                0.8918730616569519,
                0.9275893568992615,
                0.8519244194030762,
                0.9216979742050171,
                0.935992956161499,
                0.8612622618675232,
                0.919266939163208,
                0.939556896686554,
                0.8663385510444641,
                0.8456494212150574,
                0.8264747262001038,
                0.8527804017066956,
                0.7819386124610901,
                0.8194009065628052,
                0.8396916389465332,
                0.8338069319725037,
                0.7582041025161743,
                0.8740993142127991,
                0.7492198348045349,
                0.8650654554367065,
                0.8804543614387512,
                0.7366880774497986,
                0.7840585708618164,
                0.9999998807907104,
                0.8568636178970337,
                0.9191166162490845
            ],
            [
                0.8716015815734863,
                0.8294903635978699,
                0.9124324321746826,
                0.8785485029220581,
                0.8738406896591187,
                0.8894771933555603,
                0.8583579063415527,
                0.9190301895141602,
                0.900662899017334,
                0.8550337553024292,
                0.8986061215400696,
                0.8606550097465515,
                0.9227626323699951,
                0.9029666185379028,
                0.8579863905906677,
                0.8305789232254028,
                0.8409280776977539,
                0.8567457795143127,
                0.823746919631958,
                0.8918513655662537,
                0.8435335159301758,
                0.913598358631134,
                0.8153663873672485,
                0.8960593938827515,
                0.8775568008422852,
                0.8916156888008118,
                0.8746117949485779,
                0.9429506063461304,
                0.8418780565261841,
                0.865487813949585,
                0.9426924586296082,
                0.8435444235801697,
                0.8317779898643494,
                0.9498433470726013,
                0.8569396138191223,
                0.9167285561561584,
                0.8207822442054749,
                0.9285379648208618,
                0.8964810371398926,
                0.8733757138252258,
                0.8303109407424927,
                0.8864484429359436,
                0.820265531539917,
                0.8760466575622559,
                0.838286280632019,
                0.8140304088592529,
                0.817894697189331,
                0.8981381058692932,
                0.8568636178970337,
                1.0000001192092896,
                0.842388391494751
            ],
            [
                0.7230106592178345,
                0.713625431060791,
                0.7766199111938477,
                0.7432496547698975,
                0.8220590353012085,
                0.8412774801254272,
                0.7801539301872253,
                0.7559420466423035,
                0.8395447731018066,
                0.8375307321548462,
                0.7914522290229797,
                0.8430325388908386,
                0.7455536723136902,
                0.7967609167098999,
                0.7674499750137329,
                0.8311936855316162,
                0.7356957197189331,
                0.7750162482261658,
                0.8371447324752808,
                0.7774296402931213,
                0.833815336227417,
                0.7845165729522705,
                0.8404738306999207,
                0.7960077524185181,
                0.8906264305114746,
                0.9270108938217163,
                0.9601459503173828,
                0.846892237663269,
                0.8790168762207031,
                0.9120705723762512,
                0.8523727655410767,
                0.8966994285583496,
                0.9454613924026489,
                0.8390253782272339,
                0.8055316209793091,
                0.8121064901351929,
                0.8222303986549377,
                0.7682615518569946,
                0.7778515815734863,
                0.7840137481689453,
                0.7941464781761169,
                0.7433645725250244,
                0.849231481552124,
                0.7340735197067261,
                0.8402613401412964,
                0.8487947583198547,
                0.7520177960395813,
                0.7758169174194336,
                0.9191166162490845,
                0.842388391494751,
                1.0000001192092896
            ]
        ],
        [
            [
                0.9308034777641296,
                0.9059052467346191,
                0.9140627384185791,
                0.8848468065261841,
                0.8819449543952942,
                0.7807672023773193,
                0.8637728095054626,
                0.7698729038238525,
                0.8877795934677124,
                0.785991907119751,
                0.893507182598114,
                0.7378313541412354,
                0.7226777076721191,
                0.760694146156311,
                0.7804288864135742,
                0.7986292839050293,
                0.7322777509689331,
                0.8212085366249084,
                0.7394008040428162,
                0.8623577356338501,
                0.7113128304481506,
                0.8753701448440552,
                0.7410171627998352,
                0.6974177360534668,
                0.7608264088630676,
                0.7663335204124451,
                0.7617219090461731,
                0.7387685179710388,
                0.7786359786987305,
                0.7589219212532043,
                0.7462058663368225,
                0.747505784034729,
                0.7600528597831726,
                0.9200359582901001,
                0.7729553580284119,
                0.7747638821601868,
                0.9219765663146973,
                0.7943288087844849,
                0.7445340156555176,
                0.7592079639434814,
                0.7743372321128845,
                0.9199628829956055,
                0.8605442047119141,
                0.7328569293022156,
                0.8184564113616943,
                0.7236204147338867,
                0.7295972108840942,
                0.7891536355018616,
                0.8202693462371826,
                0.7816314101219177,
                0.8046880960464478
            ],
            [
                0.825385332107544,
                0.792770504951477,
                0.8057881593704224,
                0.7785572409629822,
                0.7957871556282043,
                0.8333234190940857,
                0.7639492750167847,
                0.8112059831619263,
                0.8445192575454712,
                0.8206495642662048,
                0.8113114833831787,
                0.7916605472564697,
                0.812222421169281,
                0.8506379127502441,
                0.8546695709228516,
                0.8518157005310059,
                0.8392752408981323,
                0.7309349775314331,
                0.8298459649085999,
                0.8412754535675049,
                0.8159551620483398,
                0.7458882927894592,
                0.8264147043228149,
                0.7837841510772705,
                0.8634889125823975,
                0.8459665179252625,
                0.8459166884422302,
                0.8241583108901978,
                0.7910617589950562,
                0.7838612794876099,
                0.759096622467041,
                0.7775002121925354,
                0.8365848064422607,
                0.8068187832832336,
                0.8319597840309143,
                0.8107176423072815,
                0.8010827898979187,
                0.8481330871582031,
                0.822492778301239,
                0.8420422077178955,
                0.8360497951507568,
                0.8082317113876343,
                0.8461953997612,
                0.8486833572387695,
                0.8465015292167664,
                0.849226713180542,
                0.7659707069396973,
                0.7323560118675232,
                0.7345284819602966,
                0.8421235680580139,
                0.8709680438041687
            ],
            [
                0.913064181804657,
                0.9149102568626404,
                0.9131066799163818,
                0.9823563694953918,
                0.8729550838470459,
                0.8231744170188904,
                0.8358631134033203,
                0.8178950548171997,
                0.9015792012214661,
                0.850325345993042,
                0.9179625511169434,
                0.7802804112434387,
                0.793876051902771,
                0.8427126407623291,
                0.8466321229934692,
                0.8492122888565063,
                0.818239688873291,
                0.839017927646637,
                0.7928423285484314,
                0.8914385437965393,
                0.7925338745117188,
                0.8761716485023499,
                0.8158009052276611,
                0.7630068063735962,
                0.8424935340881348,
                0.8464956879615784,
                0.8477325439453125,
                0.8235031962394714,
                0.8455781936645508,
                0.8239260315895081,
                0.8158281445503235,
                0.7876834273338318,
                0.8258078098297119,
                0.9016371369361877,
                0.8254860639572144,
                0.8318527936935425,
                0.9164480566978455,
                0.8591119050979614,
                0.82852703332901,
                0.8437025547027588,
                0.8341168165206909,
                0.9068280458450317,
                0.8857492208480835,
                0.8102942109107971,
                0.8539204001426697,
                0.8082724213600159,
                0.7848488688468933,
                0.8086525201797485,
                0.8171360492706299,
                0.8442518711090088,
                0.8608034253120422
            ],
            [
                0.8453698754310608,
                0.8523273468017578,
                0.8443576693534851,
                0.8171733021736145,
                0.8411064147949219,
                0.9206774234771729,
                0.8690797686576843,
                0.972366213798523,
                0.879386842250824,
                0.8937710523605347,
                0.8594147562980652,
                0.8399741053581238,
                0.8338609933853149,
                0.9027571678161621,
                0.9133961200714111,
                0.8993729948997498,
                0.8910746574401855,
                0.7329338788986206,
                0.8577374219894409,
                0.8900194764137268,
                0.8549005389213562,
                0.8316584825515747,
                0.8847693204879761,
                0.8401716947555542,
                0.8823673129081726,
                0.9003050327301025,
                0.887530505657196,
                0.8783931136131287,
                0.8709874153137207,
                0.8582274913787842,
                0.8447586297988892,
                0.8519573211669922,
                0.9008145332336426,
                0.8160069584846497,
                0.9356187582015991,
                0.8827987313270569,
                0.831506609916687,
                0.9072300791740417,
                0.8838933706283569,
                0.8994057178497314,
                0.9192831516265869,
                0.8529309034347534,
                0.8910638093948364,
                0.898442268371582,
                0.8888153433799744,
                0.8920890092849731,
                0.8666914701461792,
                0.7803894877433777,
                0.8160068988800049,
                0.912680983543396,
                0.8935606479644775
            ],
            [
                0.7932599782943726,
                0.8042063117027283,
                0.8054171800613403,
                0.7538120746612549,
                0.8752570748329163,
                0.8944887518882751,
                0.8547616004943848,
                0.877861738204956,
                0.8508551716804504,
                0.884669303894043,
                0.8192089200019836,
                0.9232666492462158,
                0.7617791891098022,
                0.8915584683418274,
                0.8946390151977539,
                0.8332099914550781,
                0.8424472808837891,
                0.727729856967926,
                0.9027227163314819,
                0.8338853120803833,
                0.8197861909866333,
                0.8195277452468872,
                0.883720338344574,
                0.7510916590690613,
                0.8178895115852356,
                0.8243083357810974,
                0.8119256496429443,
                0.8627174496650696,
                0.8760040998458862,
                0.9127882719039917,
                0.8914496898651123,
                0.9131103157997131,
                0.8807768821716309,
                0.7631657123565674,
                0.8321987390518188,
                0.8603849411010742,
                0.7799195647239685,
                0.8808457255363464,
                0.846264123916626,
                0.8790909051895142,
                0.9175479412078857,
                0.8078838586807251,
                0.8464967012405396,
                0.8859753012657166,
                0.8588789105415344,
                0.8697972893714905,
                0.876251220703125,
                0.8493492007255554,
                0.8308491706848145,
                0.8346319198608398,
                0.8466573357582092
            ],
            [
                0.8325656652450562,
                0.8309349417686462,
                0.8304061889648438,
                0.8034387230873108,
                0.8512707352638245,
                0.9078309535980225,
                0.8268515467643738,
                0.8575766682624817,
                0.8890732526779175,
                0.9259482026100159,
                0.8464192152023315,
                0.9245544672012329,
                0.8557578325271606,
                0.9247269034385681,
                0.9063035845756531,
                0.8940115571022034,
                0.8749699592590332,
                0.7621895670890808,
                0.9366366863250732,
                0.8913238048553467,
                0.877990186214447,
                0.8293128609657288,
                0.9023808836936951,
                0.8183004260063171,
                0.8651387095451355,
                0.8698002696037292,
                0.8620001673698425,
                0.8901659846305847,
                0.8768723607063293,
                0.8891130089759827,
                0.8651562929153442,
                0.8701786398887634,
                0.8911120891571045,
                0.8016735315322876,
                0.8725164532661438,
                0.8802408576011658,
                0.8222229480743408,
                0.9093391299247742,
                0.8810515403747559,
                0.8855501413345337,
                0.9160640239715576,
                0.8455206751823425,
                0.8910675048828125,
                0.9317027926445007,
                0.8950018286705017,
                0.9166662693023682,
                0.8697925806045532,
                0.8445656895637512,
                0.7952694296836853,
                0.8949246406555176,
                0.8858196139335632
            ],
            [
                0.8378227949142456,
                0.8402424454689026,
                0.8243170380592346,
                0.8399671316146851,
                0.8080492615699768,
                0.7234352827072144,
                0.8145806193351746,
                0.7392851114273071,
                0.846696138381958,
                0.7776939272880554,
                0.8585291504859924,
                0.7516887187957764,
                0.6616461873054504,
                0.7651917934417725,
                0.7560374140739441,
                0.7498570680618286,
                0.7404140830039978,
                0.8301156163215637,
                0.742233395576477,
                0.826515793800354,
                0.7126991152763367,
                0.8444928526878357,
                0.7236273288726807,
                0.65069580078125,
                0.7294386625289917,
                0.7611750364303589,
                0.7679629325866699,
                0.730341374874115,
                0.7479428052902222,
                0.7672857046127319,
                0.7602819800376892,
                0.7326635122299194,
                0.7380465269088745,
                0.8123337626457214,
                0.7251790761947632,
                0.7442637085914612,
                0.8575949668884277,
                0.7853649854660034,
                0.7270435094833374,
                0.773804247379303,
                0.7547065019607544,
                0.858495831489563,
                0.8015390634536743,
                0.7432275414466858,
                0.7773664593696594,
                0.750244677066803,
                0.7018207311630249,
                0.792656660079956,
                0.8010655641555786,
                0.743283748626709,
                0.7697564959526062
            ],
            [
                0.840384840965271,
                0.8443537950515747,
                0.8632292747497559,
                0.8054736256599426,
                0.9217472076416016,
                0.8795680999755859,
                0.8792063593864441,
                0.8527756929397583,
                0.9061984419822693,
                0.8738023638725281,
                0.8805861473083496,
                0.902678370475769,
                0.7993643283843994,
                0.8840318918228149,
                0.8914877772331238,
                0.8759913444519043,
                0.8532891273498535,
                0.776817798614502,
                0.8923320770263672,
                0.8675812482833862,
                0.8313989043235779,
                0.9044570922851562,
                0.878109335899353,
                0.7618908882141113,
                0.8544763326644897,
                0.8516074419021606,
                0.8491246104240417,
                0.8512222766876221,
                0.8564324378967285,
                0.8823883533477783,
                0.8671978712081909,
                0.8928616046905518,
                0.8832890391349792,
                0.8411459922790527,
                0.859281599521637,
                0.8520071506500244,
                0.8462367057800293,
                0.886597752571106,
                0.8396850228309631,
                0.855956494808197,
                0.8862313628196716,
                0.8528609275817871,
                0.8784972429275513,
                0.8769856095314026,
                0.8807587027549744,
                0.8442127704620361,
                0.8457735180854797,
                0.9086113572120667,
                0.8526045680046082,
                0.8626697659492493,
                0.8534691333770752
            ],
            [
                0.8258071541786194,
                0.8421192169189453,
                0.8452506065368652,
                0.7885172963142395,
                0.8995110988616943,
                0.8540921211242676,
                0.8629405498504639,
                0.8584834933280945,
                0.885918378829956,
                0.8948076963424683,
                0.8657104969024658,
                0.9261906743049622,
                0.7430087327957153,
                0.9108526706695557,
                0.8965566158294678,
                0.8279455900192261,
                0.8481737971305847,
                0.7803292870521545,
                0.9042908549308777,
                0.8505293130874634,
                0.8311905264854431,
                0.8685497045516968,
                0.8696375489234924,
                0.7107709646224976,
                0.8242707848548889,
                0.8420355319976807,
                0.8322211503982544,
                0.8534063100814819,
                0.8688668608665466,
                0.9266541004180908,
                0.9021431803703308,
                0.9202693104743958,
                0.8846109509468079,
                0.8034069538116455,
                0.83519446849823,
                0.8391978740692139,
                0.8237285017967224,
                0.8797496557235718,
                0.838914692401886,
                0.880597710609436,
                0.9073637127876282,
                0.8590397834777832,
                0.8479750752449036,
                0.8831390738487244,
                0.8500765562057495,
                0.8639140725135803,
                0.8637108206748962,
                0.8706351518630981,
                0.8848544359207153,
                0.8288612365722656,
                0.8463760018348694
            ],
            [
                0.8001240491867065,
                0.8105500936508179,
                0.8226065039634705,
                0.7741892337799072,
                0.8103126883506775,
                0.8133633732795715,
                0.7820587158203125,
                0.8020448684692383,
                0.857300877571106,
                0.8280290961265564,
                0.8376092910766602,
                0.8580441474914551,
                0.7543981075286865,
                0.8789427876472473,
                0.8582184314727783,
                0.8108673095703125,
                0.8406461477279663,
                0.7386693954467773,
                0.8669092059135437,
                0.8107978701591492,
                0.7991653084754944,
                0.8318318128585815,
                0.8354059457778931,
                0.7092325687408447,
                0.8195233345031738,
                0.8316071033477783,
                0.8264887928962708,
                0.8705337047576904,
                0.8154610395431519,
                0.865119218826294,
                0.8464685082435608,
                0.8502343893051147,
                0.8446700572967529,
                0.7794568538665771,
                0.8186802864074707,
                0.7997928261756897,
                0.7896319627761841,
                0.845239520072937,
                0.8260496258735657,
                0.8569537997245789,
                0.8586530089378357,
                0.7962619662284851,
                0.8039720058441162,
                0.8485645651817322,
                0.8074039816856384,
                0.8430163860321045,
                0.789152204990387,
                0.795133650302887,
                0.8133028745651245,
                0.8199817538261414,
                0.8134444952011108
            ],
            [
                0.8736429214477539,
                0.87259441614151,
                0.8706093430519104,
                0.8851063847541809,
                0.8242301940917969,
                0.8320343494415283,
                0.8148693442344666,
                0.8258183002471924,
                0.9103520512580872,
                0.8534807562828064,
                0.8956389427185059,
                0.8108653426170349,
                0.8151165843009949,
                0.8805953860282898,
                0.8685146570205688,
                0.8616458177566528,
                0.8521634340286255,
                0.7812352180480957,
                0.8368850350379944,
                0.8722280263900757,
                0.8108408451080322,
                0.8255370259284973,
                0.8372840285301208,
                0.7894023060798645,
                0.8678702712059021,
                0.8774756789207458,
                0.8781331181526184,
                0.8703022003173828,
                0.8435453772544861,
                0.8489934802055359,
                0.8314045667648315,
                0.8171722292900085,
                0.8547618985176086,
                0.8416902422904968,
                0.8583120107650757,
                0.8364307880401611,
                0.8725268840789795,
                0.8848387598991394,
                0.8572551608085632,
                0.881657600402832,
                0.8649770021438599,
                0.8483276963233948,
                0.8714708685874939,
                0.8544076085090637,
                0.8469711542129517,
                0.8620824813842773,
                0.7925103902816772,
                0.7815348505973816,
                0.8003435134887695,
                0.870100200176239,
                0.8795190453529358
            ],
            [
                0.7814852595329285,
                0.7909103035926819,
                0.7961181402206421,
                0.7446896433830261,
                0.8547512292861938,
                0.8382336497306824,
                0.8400817513465881,
                0.8232776522636414,
                0.8528813719749451,
                0.8449556827545166,
                0.8103000521659851,
                0.8844982981681824,
                0.7446987628936768,
                0.8569239974021912,
                0.8634659647941589,
                0.8093891739845276,
                0.8154420256614685,
                0.7336307168006897,
                0.8603938221931458,
                0.805967390537262,
                0.777190089225769,
                0.8484965562820435,
                0.855506181716919,
                0.7033414840698242,
                0.7863427996635437,
                0.7952704429626465,
                0.7910144925117493,
                0.8311716914176941,
                0.845660924911499,
                0.8969603180885315,
                0.8767266273498535,
                0.8858559131622314,
                0.8407716751098633,
                0.7542933225631714,
                0.799769401550293,
                0.810884416103363,
                0.7738790512084961,
                0.8382003903388977,
                0.8124290108680725,
                0.8343225717544556,
                0.8658369779586792,
                0.7923225164413452,
                0.8206183314323425,
                0.8367862701416016,
                0.8251545429229736,
                0.8157982230186462,
                0.8291044235229492,
                0.8427127599716187,
                0.8311960697174072,
                0.8068617582321167,
                0.8066209554672241
            ],
            [
                0.8814516067504883,
                0.9156802892684937,
                0.9126945734024048,
                0.8741989731788635,
                0.8937554955482483,
                0.8565517663955688,
                0.8876572847366333,
                0.8860663175582886,
                0.9441725015640259,
                0.8730429410934448,
                0.9244725108146667,
                0.8503445982933044,
                0.7889880537986755,
                0.8960089087486267,
                0.8932120203971863,
                0.8810672760009766,
                0.8788191080093384,
                0.7975404262542725,
                0.8580420613288879,
                0.8922435641288757,
                0.8335751891136169,
                0.9158822298049927,
                0.8594818711280823,
                0.7658205628395081,
                0.8766041398048401,
                0.8995290994644165,
                0.8945415019989014,
                0.8713840246200562,
                0.857742190361023,
                0.8742273449897766,
                0.868468701839447,
                0.8787701725959778,
                0.9011595249176025,
                0.8898489475250244,
                0.9008408188819885,
                0.8570913672447205,
                0.9004091024398804,
                0.9028175473213196,
                0.8576302528381348,
                0.8895155191421509,
                0.8948377370834351,
                0.9059313535690308,
                0.8915555477142334,
                0.8725937604904175,
                0.8723775744438171,
                0.8594212532043457,
                0.8320081830024719,
                0.8281459212303162,
                0.8832177519798279,
                0.8828392624855042,
                0.8724367618560791
            ],
            [
                0.8518664836883545,
                0.8748906850814819,
                0.8663947582244873,
                0.824196457862854,
                0.8634756803512573,
                0.8921940922737122,
                0.8360320329666138,
                0.9051643013954163,
                0.9112316370010376,
                0.9115946292877197,
                0.8920701742172241,
                0.903120219707489,
                0.8116744160652161,
                0.9379145503044128,
                0.9285963177680969,
                0.8833921551704407,
                0.9053868055343628,
                0.7898154854774475,
                0.9098174571990967,
                0.8813108205795288,
                0.8895634412765503,
                0.8608115911483765,
                0.9115407466888428,
                0.799640953540802,
                0.9084129929542542,
                0.9248767495155334,
                0.9169905185699463,
                0.9228196740150452,
                0.8962579965591431,
                0.9245946407318115,
                0.9050599932670593,
                0.929949164390564,
                0.9445483088493347,
                0.8250858187675476,
                0.8946595788002014,
                0.8949463367462158,
                0.8629732728004456,
                0.936877429485321,
                0.897165060043335,
                0.9319058656692505,
                0.952982485294342,
                0.8682044148445129,
                0.8851932287216187,
                0.9316516518592834,
                0.8795081377029419,
                0.9277873039245605,
                0.8815698623657227,
                0.8170463442802429,
                0.8733488917350769,
                0.8889829516410828,
                0.9121924042701721
            ],
            [
                0.7615906000137329,
                0.749507486820221,
                0.7512485980987549,
                0.7217066287994385,
                0.8444212675094604,
                0.8359586596488953,
                0.7865915894508362,
                0.7858499884605408,
                0.7971634268760681,
                0.8422507643699646,
                0.7654002904891968,
                0.8427731990814209,
                0.7882665395736694,
                0.8152011632919312,
                0.856616199016571,
                0.8139462471008301,
                0.7652830481529236,
                0.7444954514503479,
                0.8232486844062805,
                0.8074914216995239,
                0.7855613231658936,
                0.7769315242767334,
                0.8519481420516968,
                0.7699458599090576,
                0.8038954734802246,
                0.7769766449928284,
                0.7742465734481812,
                0.78451007604599,
                0.8586447834968567,
                0.8540657162666321,
                0.8395407795906067,
                0.8432947397232056,
                0.8181619644165039,
                0.7186623215675354,
                0.7548500895500183,
                0.844217836856842,
                0.7437013387680054,
                0.8467742204666138,
                0.8049731254577637,
                0.7954071760177612,
                0.8368141055107117,
                0.7520771026611328,
                0.8307708501815796,
                0.816045343875885,
                0.8564686179161072,
                0.7947770953178406,
                0.8452674746513367,
                0.8736053109169006,
                0.7681537866592407,
                0.8042433261871338,
                0.8363149166107178
            ],
            [
                0.7982162237167358,
                0.8111358880996704,
                0.8088140487670898,
                0.8357140421867371,
                0.7545485496520996,
                0.7136927247047424,
                0.7398308515548706,
                0.7483792304992676,
                0.8100844621658325,
                0.7582696676254272,
                0.8221724033355713,
                0.7161713242530823,
                0.6880000829696655,
                0.7823442816734314,
                0.77527916431427,
                0.7466884255409241,
                0.7500187158584595,
                0.7670664191246033,
                0.7215653657913208,
                0.7722440361976624,
                0.6951603889465332,
                0.8063626885414124,
                0.7438765168190002,
                0.6675975322723389,
                0.7472662329673767,
                0.7878071069717407,
                0.7807443737983704,
                0.7678478360176086,
                0.783301830291748,
                0.8044850826263428,
                0.7932719588279724,
                0.7566736936569214,
                0.7615852952003479,
                0.761224627494812,
                0.7567312121391296,
                0.7527409791946411,
                0.7897436618804932,
                0.7913379669189453,
                0.7509928941726685,
                0.8002946376800537,
                0.784803569316864,
                0.7773508429527283,
                0.7654337286949158,
                0.7355269193649292,
                0.7605741024017334,
                0.75043785572052,
                0.711580753326416,
                0.733112096786499,
                0.7875933647155762,
                0.7583929300308228,
                0.7902029752731323
            ],
            [
                0.821277916431427,
                0.8595321178436279,
                0.8337107300758362,
                0.8820538520812988,
                0.7747113704681396,
                0.70654296875,
                0.7544358372688293,
                0.7455165386199951,
                0.8419358134269714,
                0.7706313133239746,
                0.8612237572669983,
                0.717647910118103,
                0.6926628947257996,
                0.7885230779647827,
                0.7769151329994202,
                0.7562386393547058,
                0.7572516798973083,
                0.7999149560928345,
                0.7259483337402344,
                0.8014493584632874,
                0.7208914756774902,
                0.8058854341506958,
                0.7408875823020935,
                0.6669532060623169,
                0.7733467221260071,
                0.8006022572517395,
                0.801762580871582,
                0.7633243799209595,
                0.7863454222679138,
                0.8046667575836182,
                0.7936440706253052,
                0.7592718601226807,
                0.7794142365455627,
                0.8041142821311951,
                0.7573955059051514,
                0.7559599876403809,
                0.8528560400009155,
                0.8032419085502625,
                0.7603943347930908,
                0.8074707984924316,
                0.7726863622665405,
                0.8247157335281372,
                0.7902188897132874,
                0.7412662506103516,
                0.7623072266578674,
                0.7509663105010986,
                0.7163545489311218,
                0.7105252146720886,
                0.8085054755210876,
                0.7671792507171631,
                0.7986934185028076
            ],
            [
                0.764527440071106,
                0.7531033754348755,
                0.7539207339286804,
                0.7250023484230042,
                0.8350141048431396,
                0.8346458673477173,
                0.7801865339279175,
                0.7839438319206238,
                0.808927595615387,
                0.8423393368721008,
                0.7653917670249939,
                0.8248746991157532,
                0.7968696355819702,
                0.8109145164489746,
                0.8535420298576355,
                0.8208458423614502,
                0.7710908055305481,
                0.7489839196205139,
                0.811290979385376,
                0.8141769170761108,
                0.7840422987937927,
                0.7806089520454407,
                0.8475097417831421,
                0.7875135540962219,
                0.8081268072128296,
                0.7854430079460144,
                0.7887388467788696,
                0.7995719313621521,
                0.8642478585243225,
                0.8392815589904785,
                0.840268611907959,
                0.8325530886650085,
                0.8195555806159973,
                0.727755606174469,
                0.7510783672332764,
                0.8489713668823242,
                0.749956488609314,
                0.8437045812606812,
                0.8129435181617737,
                0.7964512705802917,
                0.8359973430633545,
                0.7530131936073303,
                0.8360241651535034,
                0.8146069049835205,
                0.8604333996772766,
                0.7921064496040344,
                0.8434085249900818,
                0.864979088306427,
                0.7620590329170227,
                0.807256817817688,
                0.838512659072876
            ],
            [
                0.7907973527908325,
                0.8187299370765686,
                0.8158095479011536,
                0.7862067222595215,
                0.7664197087287903,
                0.7260041236877441,
                0.7583154439926147,
                0.7520246505737305,
                0.8346415162086487,
                0.7668272256851196,
                0.8156497478485107,
                0.7420089244842529,
                0.6915906667709351,
                0.7883058786392212,
                0.7871281504631042,
                0.766082763671875,
                0.7627741098403931,
                0.7652119994163513,
                0.7432584762573242,
                0.7809664607048035,
                0.7031816840171814,
                0.8298693299293518,
                0.7614030241966248,
                0.6723898649215698,
                0.747382640838623,
                0.7910693883895874,
                0.798058271408081,
                0.7882006764411926,
                0.7929331064224243,
                0.8051501512527466,
                0.8124454617500305,
                0.7732691764831543,
                0.7769904732704163,
                0.7712134718894958,
                0.7555961012840271,
                0.7690927982330322,
                0.8007630109786987,
                0.7941786646842957,
                0.7639944553375244,
                0.7979349493980408,
                0.8021963834762573,
                0.7925596237182617,
                0.7797524929046631,
                0.752729594707489,
                0.7754157781600952,
                0.7566028833389282,
                0.7223342657089233,
                0.7542158961296082,
                0.8069397807121277,
                0.7619970440864563,
                0.7880069017410278
            ],
            [
                0.8479178547859192,
                0.8715251684188843,
                0.8593411445617676,
                0.8409401178359985,
                0.8410284519195557,
                0.8131673336029053,
                0.811198353767395,
                0.8327074646949768,
                0.8976832032203674,
                0.8516242504119873,
                0.8822987079620361,
                0.8077648282051086,
                0.7692363262176514,
                0.8491706252098083,
                0.8642240762710571,
                0.8374036550521851,
                0.8381300568580627,
                0.8086503148078918,
                0.8124823570251465,
                0.8612252473831177,
                0.8089637160301208,
                0.8648648858070374,
                0.8437638282775879,
                0.7593740224838257,
                0.8512739539146423,
                0.8762239217758179,
                0.8817356824874878,
                0.8516573309898376,
                0.8631519079208374,
                0.8533183336257935,
                0.8784483075141907,
                0.852581799030304,
                0.8756464719772339,
                0.8349906206130981,
                0.8300488591194153,
                0.8536274433135986,
                0.8633442521095276,
                0.8811653256416321,
                0.8465421199798584,
                0.8759036064147949,
                0.8671296834945679,
                0.8550974130630493,
                0.8610495924949646,
                0.8369152545928955,
                0.8523635864257812,
                0.835922122001648,
                0.8218585848808289,
                0.8117468953132629,
                0.8592544794082642,
                0.8459815979003906,
                0.8688920736312866
            ],
            [
                0.7957112193107605,
                0.8055062890052795,
                0.8072125315666199,
                0.7748461365699768,
                0.7988847494125366,
                0.7693142890930176,
                0.7907710075378418,
                0.7984753847122192,
                0.8257836699485779,
                0.7923232913017273,
                0.8189009428024292,
                0.7675337791442871,
                0.7166680693626404,
                0.7998578548431396,
                0.8159379959106445,
                0.7888261079788208,
                0.7647693157196045,
                0.7661558985710144,
                0.7648658752441406,
                0.795069694519043,
                0.7214899659156799,
                0.8319052457809448,
                0.7882877588272095,
                0.7011690735816956,
                0.7705391645431519,
                0.8057077527046204,
                0.7953627109527588,
                0.7872579097747803,
                0.8268173336982727,
                0.8360240459442139,
                0.8310304284095764,
                0.8054037094116211,
                0.812224268913269,
                0.7712424993515015,
                0.7976205945014954,
                0.8056930899620056,
                0.7942034006118774,
                0.8121411800384521,
                0.76729416847229,
                0.8008021712303162,
                0.832574188709259,
                0.7953431010246277,
                0.8018189072608948,
                0.7698092460632324,
                0.810390830039978,
                0.7726498246192932,
                0.7644952535629272,
                0.7951143383979797,
                0.8232488036155701,
                0.798122227191925,
                0.8103513717651367
            ],
            [
                0.8719688653945923,
                0.8801054954528809,
                0.8790592551231384,
                0.8588470220565796,
                0.880818247795105,
                0.8396711945533752,
                0.8434116840362549,
                0.8593893647193909,
                0.9077401161193848,
                0.8620915412902832,
                0.9023386836051941,
                0.8260616064071655,
                0.7766396999359131,
                0.8691807389259338,
                0.8849607110023499,
                0.8490626811981201,
                0.8496328592300415,
                0.8144341707229614,
                0.8308013677597046,
                0.8727460503578186,
                0.8137732148170471,
                0.8797118067741394,
                0.8544963002204895,
                0.7696356177330017,
                0.8653293251991272,
                0.8921514749526978,
                0.8836660385131836,
                0.8633584976196289,
                0.8686317801475525,
                0.8673137426376343,
                0.875983476638794,
                0.8669543862342834,
                0.8859717845916748,
                0.8567882776260376,
                0.857670247554779,
                0.8532145023345947,
                0.8750299215316772,
                0.8838794231414795,
                0.8429380059242249,
                0.8815518021583557,
                0.8834052681922913,
                0.8697671294212341,
                0.8729966282844543,
                0.8511451482772827,
                0.8707452416419983,
                0.8475610613822937,
                0.8246647119522095,
                0.8373059034347534,
                0.8728004693984985,
                0.8612355589866638,
                0.8747379183769226
            ],
            [
                0.7612970471382141,
                0.7759911417961121,
                0.783989667892456,
                0.7645530104637146,
                0.7517910599708557,
                0.7257797718048096,
                0.7412579655647278,
                0.7561330199241638,
                0.8019867539405823,
                0.7640439867973328,
                0.8046776056289673,
                0.7419368624687195,
                0.6795518398284912,
                0.7982568740844727,
                0.7846546769142151,
                0.7532009482383728,
                0.7571240067481995,
                0.7406983375549316,
                0.7419404983520508,
                0.7570083141326904,
                0.7002997994422913,
                0.8056182265281677,
                0.755928635597229,
                0.6621675491333008,
                0.7398324608802795,
                0.7770905494689941,
                0.7765042185783386,
                0.7618222236633301,
                0.7953554391860962,
                0.8196814656257629,
                0.8047084808349609,
                0.7700710296630859,
                0.7749378681182861,
                0.7360469698905945,
                0.7584600448608398,
                0.7676934599876404,
                0.7646294832229614,
                0.7880932092666626,
                0.7512654662132263,
                0.790653645992279,
                0.8053593039512634,
                0.755562424659729,
                0.7595149278640747,
                0.7468684911727905,
                0.7660133242607117,
                0.7561354637145996,
                0.7280483841896057,
                0.750421404838562,
                0.7828001379966736,
                0.7604712247848511,
                0.777898371219635
            ],
            [
                0.8391709327697754,
                0.8459451198577881,
                0.8487028479576111,
                0.8622861504554749,
                0.8386083841323853,
                0.7941584587097168,
                0.8069030046463013,
                0.8135714530944824,
                0.8720121383666992,
                0.8431184887886047,
                0.878130316734314,
                0.8002175092697144,
                0.757232129573822,
                0.8565122485160828,
                0.8568124175071716,
                0.8185132741928101,
                0.8214395046234131,
                0.8101733922958374,
                0.8013418912887573,
                0.8431960344314575,
                0.7807359099388123,
                0.84376060962677,
                0.8228092193603516,
                0.7424026131629944,
                0.8306463956832886,
                0.8441638946533203,
                0.8460057377815247,
                0.8177709579467773,
                0.8641964197158813,
                0.8591219186782837,
                0.8524020910263062,
                0.8268012404441833,
                0.8428863883018494,
                0.8178523778915405,
                0.8002094030380249,
                0.8376092314720154,
                0.8468495607376099,
                0.8595947027206421,
                0.834540843963623,
                0.8627094030380249,
                0.8460788130760193,
                0.8321914672851562,
                0.8471963405609131,
                0.8128154873847961,
                0.8364197611808777,
                0.8182497024536133,
                0.801742672920227,
                0.8081029653549194,
                0.8287227153778076,
                0.8281216621398926,
                0.8552522659301758
            ],
            [
                0.7963409423828125,
                0.8089026212692261,
                0.8031463623046875,
                0.780056893825531,
                0.821178138256073,
                0.8234544992446899,
                0.8093244433403015,
                0.8437827229499817,
                0.859567403793335,
                0.8690991997718811,
                0.8331691026687622,
                0.8735332489013672,
                0.756275475025177,
                0.8821069598197937,
                0.8719261884689331,
                0.8195225596427917,
                0.823924720287323,
                0.7526222467422485,
                0.8571659922599792,
                0.8224250078201294,
                0.8009707927703857,
                0.825050413608551,
                0.8682571053504944,
                0.7321216464042664,
                0.8120294213294983,
                0.8308959007263184,
                0.8234291076660156,
                0.8364908695220947,
                0.8992099761962891,
                0.9257519841194153,
                0.9129672050476074,
                0.8904412984848022,
                0.8727004528045654,
                0.7508050203323364,
                0.8325192332267761,
                0.8591082692146301,
                0.7897579669952393,
                0.874122142791748,
                0.8445491790771484,
                0.8735780715942383,
                0.8957004547119141,
                0.8055928349494934,
                0.8417208790779114,
                0.8502072095870972,
                0.8489497900009155,
                0.847478985786438,
                0.8705905675888062,
                0.824522852897644,
                0.8423231244087219,
                0.8366222977638245,
                0.8454789519309998
            ],
            [
                0.845258355140686,
                0.8346039652824402,
                0.842214822769165,
                0.8370826244354248,
                0.8160580992698669,
                0.7769291996955872,
                0.8042854070663452,
                0.7891371846199036,
                0.8733546733856201,
                0.8203722834587097,
                0.8796417713165283,
                0.8062340617179871,
                0.7290964126586914,
                0.8402729034423828,
                0.826474666595459,
                0.793611466884613,
                0.7989805936813354,
                0.81413733959198,
                0.8036668300628662,
                0.8295495510101318,
                0.74054354429245,
                0.8565587401390076,
                0.8048779368400574,
                0.7066473960876465,
                0.7882974147796631,
                0.8169178366661072,
                0.8113294839859009,
                0.8163672685623169,
                0.8507723808288574,
                0.8636520504951477,
                0.859439492225647,
                0.820854663848877,
                0.8187751770019531,
                0.8082134127616882,
                0.7927118539810181,
                0.822698712348938,
                0.8441028594970703,
                0.8379042148590088,
                0.8028504252433777,
                0.8477338552474976,
                0.84211665391922,
                0.830214262008667,
                0.8404453992843628,
                0.7949225902557373,
                0.828453779220581,
                0.8040618300437927,
                0.7871771454811096,
                0.8002848029136658,
                0.8310810923576355,
                0.8108606338500977,
                0.8206955790519714
            ],
            [
                0.8077986836433411,
                0.796916127204895,
                0.8038913607597351,
                0.7844144105911255,
                0.806215226650238,
                0.7673981785774231,
                0.7756637334823608,
                0.7728428244590759,
                0.8413587212562561,
                0.8100638389587402,
                0.8415035605430603,
                0.8136654496192932,
                0.6951489448547363,
                0.8283871412277222,
                0.8102807998657227,
                0.7613604068756104,
                0.7656724452972412,
                0.7795699238777161,
                0.8036824464797974,
                0.793027937412262,
                0.7291164994239807,
                0.8298580646514893,
                0.7864845395088196,
                0.6841740608215332,
                0.7438784837722778,
                0.7738420367240906,
                0.7639161944389343,
                0.790831446647644,
                0.8277836441993713,
                0.8614901900291443,
                0.8427812457084656,
                0.8143190145492554,
                0.7925982475280762,
                0.7546790242195129,
                0.7518660426139832,
                0.7911694049835205,
                0.7950310111045837,
                0.813640296459198,
                0.7713897228240967,
                0.8182370662689209,
                0.8305637836456299,
                0.8005656003952026,
                0.8112888932228088,
                0.7831258177757263,
                0.806849479675293,
                0.7878029942512512,
                0.7822081446647644,
                0.815342903137207,
                0.8146207332611084,
                0.7713621854782104,
                0.7959429025650024
            ],
            [
                0.8804225325584412,
                0.8786140084266663,
                0.8859075307846069,
                0.8742342591285706,
                0.8953395485877991,
                0.8401207327842712,
                0.8639355301856995,
                0.8469650149345398,
                0.9219478964805603,
                0.8712983727455139,
                0.9144223928451538,
                0.8378982543945312,
                0.7764049768447876,
                0.8703727722167969,
                0.8765919208526611,
                0.8438518047332764,
                0.8368815183639526,
                0.8253926038742065,
                0.8355917930603027,
                0.8785223364830017,
                0.8075926303863525,
                0.885802149772644,
                0.8461674451828003,
                0.7584665417671204,
                0.8369259238243103,
                0.8550595641136169,
                0.8482006192207336,
                0.8422505855560303,
                0.8765398859977722,
                0.8831989169120789,
                0.8824554681777954,
                0.859622061252594,
                0.8643964529037476,
                0.8616700172424316,
                0.8405807614326477,
                0.851356029510498,
                0.8816166520118713,
                0.8879491686820984,
                0.8343679308891296,
                0.8699977993965149,
                0.8804585337638855,
                0.8787968754768372,
                0.8936176300048828,
                0.8411502242088318,
                0.8828712701797485,
                0.8372271656990051,
                0.8487826585769653,
                0.8642489314079285,
                0.8682155013084412,
                0.8511497974395752,
                0.8739267587661743
            ],
            [
                0.7841504812240601,
                0.7789301872253418,
                0.7861684560775757,
                0.7435532808303833,
                0.8138626217842102,
                0.8184037804603577,
                0.7949281930923462,
                0.7915952801704407,
                0.83940190076828,
                0.8364455103874207,
                0.8005791306495667,
                0.8721016645431519,
                0.7490086555480957,
                0.8626982569694519,
                0.8486237525939941,
                0.7920324802398682,
                0.8009384870529175,
                0.739806056022644,
                0.8605074286460876,
                0.7972642183303833,
                0.7707340121269226,
                0.8099657297134399,
                0.841410756111145,
                0.7120910882949829,
                0.7753521203994751,
                0.7881727814674377,
                0.7723938226699829,
                0.8199031949043274,
                0.8549655079841614,
                0.8915950059890747,
                0.8722068667411804,
                0.858557403087616,
                0.8229461908340454,
                0.7435062527656555,
                0.7945948243141174,
                0.8199649453163147,
                0.7586733102798462,
                0.8378778696060181,
                0.8147896528244019,
                0.8344391584396362,
                0.8595523238182068,
                0.7738046050071716,
                0.814895749092102,
                0.8276196718215942,
                0.822847843170166,
                0.8128111958503723,
                0.8348750472068787,
                0.8108412027359009,
                0.8025170564651489,
                0.8091280460357666,
                0.8069866299629211
            ],
            [
                0.8038728833198547,
                0.7976301312446594,
                0.8095400333404541,
                0.7548179626464844,
                0.8478960990905762,
                0.7933220863342285,
                0.8063247203826904,
                0.768335223197937,
                0.8568894267082214,
                0.8258892297744751,
                0.8189438581466675,
                0.8742231726646423,
                0.711449921131134,
                0.8359251022338867,
                0.829603374004364,
                0.7733556628227234,
                0.7712867259979248,
                0.7850902080535889,
                0.8495123386383057,
                0.7987900376319885,
                0.7429842948913574,
                0.831207275390625,
                0.8158934116363525,
                0.6815767884254456,
                0.7530693411827087,
                0.7658208608627319,
                0.7553055286407471,
                0.7961186170578003,
                0.8434062600135803,
                0.8841726183891296,
                0.8690909743309021,
                0.8559394478797913,
                0.8046695590019226,
                0.7677631974220276,
                0.7511690855026245,
                0.8028777241706848,
                0.7915844321250916,
                0.819631040096283,
                0.7846155166625977,
                0.8137632012367249,
                0.8450379967689514,
                0.8020179271697998,
                0.815883457660675,
                0.80192631483078,
                0.8164740204811096,
                0.7876942157745361,
                0.8071771860122681,
                0.8526573181152344,
                0.8199033737182617,
                0.7716261148452759,
                0.7893909811973572
            ],
            [
                0.8828772306442261,
                0.8694164156913757,
                0.87428879737854,
                0.8506961464881897,
                0.8958297371864319,
                0.8480691909790039,
                0.8636306524276733,
                0.8359029293060303,
                0.9009073376655579,
                0.8852275609970093,
                0.8815962672233582,
                0.8394259214401245,
                0.788292646408081,
                0.8497610092163086,
                0.880217432975769,
                0.8446335196495056,
                0.8079153299331665,
                0.8386492729187012,
                0.8249189257621765,
                0.8792001008987427,
                0.7993303537368774,
                0.8743259906768799,
                0.8550353646278381,
                0.7807282209396362,
                0.8285749554634094,
                0.83526211977005,
                0.8286413550376892,
                0.8265644907951355,
                0.8880327939987183,
                0.8753312230110168,
                0.8758788704872131,
                0.8478814959526062,
                0.8443530201911926,
                0.8355509042739868,
                0.8093478083610535,
                0.8673338890075684,
                0.8730417490005493,
                0.8949251770973206,
                0.8368555903434753,
                0.8600901365280151,
                0.8680821657180786,
                0.8695379495620728,
                0.8985177278518677,
                0.8306637406349182,
                0.8950819969177246,
                0.8263341188430786,
                0.8563671112060547,
                0.8885981440544128,
                0.8529502749443054,
                0.8414310812950134,
                0.8828486800193787
            ],
            [
                0.782158374786377,
                0.7902239561080933,
                0.7855563163757324,
                0.7544205188751221,
                0.7938900589942932,
                0.8005645275115967,
                0.7775012254714966,
                0.792715311050415,
                0.8383848667144775,
                0.8386135697364807,
                0.8059207797050476,
                0.8680510520935059,
                0.7292959094047546,
                0.8736255764961243,
                0.8445461988449097,
                0.7794793248176575,
                0.8058421611785889,
                0.759014368057251,
                0.8591310977935791,
                0.7947778701782227,
                0.7762647867202759,
                0.8005105257034302,
                0.836288332939148,
                0.6999943256378174,
                0.7791897058486938,
                0.8033509254455566,
                0.7860602736473083,
                0.8274301290512085,
                0.8442280292510986,
                0.9002642035484314,
                0.8702473640441895,
                0.8596329092979431,
                0.8263776898384094,
                0.7334027886390686,
                0.7892599701881409,
                0.8123890161514282,
                0.7732099294662476,
                0.8466829657554626,
                0.8180951476097107,
                0.852125346660614,
                0.8609288930892944,
                0.7789676785469055,
                0.8015836477279663,
                0.8322405219078064,
                0.8013030290603638,
                0.8279638886451721,
                0.8162166476249695,
                0.785164475440979,
                0.8223402500152588,
                0.8038700222969055,
                0.8102511763572693
            ],
            [
                0.7826274633407593,
                0.7750957012176514,
                0.7748363614082336,
                0.741268515586853,
                0.7647993564605713,
                0.7497795820236206,
                0.7414512038230896,
                0.7429567575454712,
                0.8125779032707214,
                0.8000149726867676,
                0.7857563495635986,
                0.8001487851142883,
                0.6875459551811218,
                0.8152928948402405,
                0.7946298122406006,
                0.7379165291786194,
                0.747029185295105,
                0.7554168105125427,
                0.7922109365463257,
                0.7631124258041382,
                0.7034862041473389,
                0.7782610058784485,
                0.7781754732131958,
                0.6657403707504272,
                0.7238684296607971,
                0.7541795969009399,
                0.7353145480155945,
                0.7721390724182129,
                0.8226811289787292,
                0.8509498834609985,
                0.8300184011459351,
                0.7861372232437134,
                0.760470449924469,
                0.7168387770652771,
                0.7348417639732361,
                0.7799553275108337,
                0.7548179626464844,
                0.7982478141784668,
                0.7632730603218079,
                0.8008983731269836,
                0.813450038433075,
                0.758357048034668,
                0.7780076265335083,
                0.759092390537262,
                0.7749286890029907,
                0.766286313533783,
                0.7569110989570618,
                0.776261568069458,
                0.7776716947555542,
                0.762013852596283,
                0.775224506855011
            ],
            [
                0.8924728035926819,
                0.882222592830658,
                0.8864462375640869,
                0.8515914678573608,
                0.9118105173110962,
                0.8683965802192688,
                0.8885011076927185,
                0.8498402237892151,
                0.9186180830001831,
                0.8918022513389587,
                0.892298698425293,
                0.85589599609375,
                0.8045610189437866,
                0.8584232330322266,
                0.8911944627761841,
                0.8678761720657349,
                0.8227241039276123,
                0.8460977673530579,
                0.8432952165603638,
                0.8953743577003479,
                0.8079518675804138,
                0.8903809189796448,
                0.8705264329910278,
                0.786827802658081,
                0.8401076793670654,
                0.8454234600067139,
                0.8384455442428589,
                0.8327856659889221,
                0.8978729844093323,
                0.885342001914978,
                0.8843753337860107,
                0.8683499097824097,
                0.8649150729179382,
                0.8566329479217529,
                0.8316627740859985,
                0.8756894469261169,
                0.8821459412574768,
                0.8995775580406189,
                0.8427285552024841,
                0.8605075478553772,
                0.8822324275970459,
                0.8834021091461182,
                0.9119822382926941,
                0.8432899713516235,
                0.9113283157348633,
                0.8337231874465942,
                0.8691955208778381,
                0.8970962762832642,
                0.8726544976234436,
                0.8633617162704468,
                0.8912703990936279
            ],
            [
                0.819893479347229,
                0.8365693688392639,
                0.8398612141609192,
                0.8014078140258789,
                0.8248950242996216,
                0.769568920135498,
                0.8206560611724854,
                0.8018116354942322,
                0.8570381999015808,
                0.7957294583320618,
                0.846139669418335,
                0.7809937000274658,
                0.7214471697807312,
                0.8006932735443115,
                0.8165492415428162,
                0.8011599779129028,
                0.7645848393440247,
                0.7996616363525391,
                0.775488555431366,
                0.8218927383422852,
                0.72577303647995,
                0.871955394744873,
                0.790675163269043,
                0.7003679871559143,
                0.77414870262146,
                0.8037227392196655,
                0.8013394474983215,
                0.7819989323616028,
                0.8069088459014893,
                0.8231431841850281,
                0.8211512565612793,
                0.8101493120193481,
                0.8191765546798706,
                0.8043866753578186,
                0.8106716871261597,
                0.8005717992782593,
                0.8269330263137817,
                0.8216449618339539,
                0.7666676044464111,
                0.8012824654579163,
                0.8234466910362244,
                0.8304404616355896,
                0.8143343925476074,
                0.7777417898178101,
                0.8174378871917725,
                0.7751421928405762,
                0.7518268823623657,
                0.8144501447677612,
                0.8612666130065918,
                0.8065029382705688,
                0.8054924607276917
            ],
            [
                0.8715364933013916,
                0.876513659954071,
                0.8786633610725403,
                0.8832356929779053,
                0.852270245552063,
                0.8089442253112793,
                0.8167672753334045,
                0.8102149963378906,
                0.898135781288147,
                0.8476710915565491,
                0.9024010896682739,
                0.8016863465309143,
                0.786443293094635,
                0.8536683917045593,
                0.8639951348304749,
                0.8437703251838684,
                0.8156375885009766,
                0.8353822827339172,
                0.8076828122138977,
                0.8660724759101868,
                0.7920795679092407,
                0.8713114261627197,
                0.8348355293273926,
                0.7716160416603088,
                0.8469530940055847,
                0.8547582626342773,
                0.8558825254440308,
                0.8379491567611694,
                0.8674717545509338,
                0.8628889918327332,
                0.8595296144485474,
                0.8328354358673096,
                0.8568119406700134,
                0.8496295809745789,
                0.8178531527519226,
                0.8500102162361145,
                0.8801329731941223,
                0.8720163702964783,
                0.8304369449615479,
                0.8569123148918152,
                0.850125789642334,
                0.8593207001686096,
                0.8718879818916321,
                0.8153044581413269,
                0.8550697565078735,
                0.8125274777412415,
                0.8129388093948364,
                0.8205903768539429,
                0.8461484313011169,
                0.8417296409606934,
                0.8666605353355408
            ],
            [
                0.7662255764007568,
                0.7802691459655762,
                0.7881304621696472,
                0.7489498853683472,
                0.7640933394432068,
                0.7414761781692505,
                0.762454092502594,
                0.7714531421661377,
                0.7997706532478333,
                0.76023930311203,
                0.7990613579750061,
                0.7335228323936462,
                0.6969035267829895,
                0.7756707668304443,
                0.7922438383102417,
                0.7667417526245117,
                0.7469373345375061,
                0.7443686723709106,
                0.7333945631980896,
                0.7707551717758179,
                0.7009305953979492,
                0.8119527697563171,
                0.7615185379981995,
                0.6810598969459534,
                0.7445169687271118,
                0.7760909199714661,
                0.7725544571876526,
                0.7693305611610413,
                0.7970299124717712,
                0.8116168975830078,
                0.8059293627738953,
                0.7791157960891724,
                0.7904200553894043,
                0.7527485489845276,
                0.7692475318908691,
                0.7828155755996704,
                0.7719607353210449,
                0.7888635396957397,
                0.7480899691581726,
                0.7790341377258301,
                0.804664134979248,
                0.7633270025253296,
                0.7753978967666626,
                0.7428730726242065,
                0.7862915992736816,
                0.7465951442718506,
                0.7393237352371216,
                0.7540236711502075,
                0.8103080987930298,
                0.7731008529663086,
                0.7928177714347839
            ],
            [
                0.9006308317184448,
                0.9097557067871094,
                0.9114492535591125,
                0.9045628309249878,
                0.8765764832496643,
                0.8363630175590515,
                0.8578317761421204,
                0.8464342951774597,
                0.9327893853187561,
                0.8586519360542297,
                0.9330790042877197,
                0.8099893927574158,
                0.7933968305587769,
                0.8708196878433228,
                0.8737142086029053,
                0.8668571710586548,
                0.8495801687240601,
                0.840872585773468,
                0.8249892592430115,
                0.8948573470115662,
                0.8218061923980713,
                0.9118279814720154,
                0.837485671043396,
                0.7846810221672058,
                0.8718760013580322,
                0.8895388841629028,
                0.8892419934272766,
                0.8676681518554688,
                0.8483090400695801,
                0.8492354154586792,
                0.8546966314315796,
                0.8423610329627991,
                0.8836108446121216,
                0.9001521468162537,
                0.8529412150382996,
                0.8554098010063171,
                0.9225108623504639,
                0.8953274488449097,
                0.8444604873657227,
                0.8773592710494995,
                0.8709041476249695,
                0.9007395505905151,
                0.8903432488441467,
                0.8470327258110046,
                0.8651388883590698,
                0.8416310548782349,
                0.8076571226119995,
                0.8092200756072998,
                0.8699280619621277,
                0.8582388162612915,
                0.88273024559021
            ],
            [
                0.8400698304176331,
                0.8558511137962341,
                0.8574610352516174,
                0.8118643164634705,
                0.8498295545578003,
                0.9111452102661133,
                0.8228317499160767,
                0.9067077040672302,
                0.8984009623527527,
                0.9084898233413696,
                0.8725443482398987,
                0.9047428965568542,
                0.8320399522781372,
                0.9414913654327393,
                0.9341099262237549,
                0.8890233635902405,
                0.9156718850135803,
                0.7573950290679932,
                0.9196417927742004,
                0.8829668760299683,
                0.9076776504516602,
                0.8460877537727356,
                0.9229189157485962,
                0.8284100890159607,
                0.9288986325263977,
                0.9322965145111084,
                0.9255204796791077,
                0.9489205479621887,
                0.890364408493042,
                0.913867175579071,
                0.9069852828979492,
                0.9294293522834778,
                0.9547319412231445,
                0.817797064781189,
                0.8953574299812317,
                0.9002567529678345,
                0.8420345783233643,
                0.9380210041999817,
                0.9074141383171082,
                0.9276419878005981,
                0.954170823097229,
                0.8499331474304199,
                0.8847874999046326,
                0.9429188370704651,
                0.8810936212539673,
                0.9306207895278931,
                0.8879690170288086,
                0.8083330988883972,
                0.8459005951881409,
                0.8949439525604248,
                0.9111273884773254
            ],
            [
                0.7758474946022034,
                0.7663131952285767,
                0.7684506177902222,
                0.7358759641647339,
                0.8402959704399109,
                0.835135281085968,
                0.7802495360374451,
                0.7890369892120361,
                0.8155674934387207,
                0.8518661856651306,
                0.7827146649360657,
                0.8366673588752747,
                0.792663037776947,
                0.8359951972961426,
                0.8662663102149963,
                0.8228017687797546,
                0.7823270559310913,
                0.7661693692207336,
                0.8259363174438477,
                0.8158159255981445,
                0.7915684580802917,
                0.7911675572395325,
                0.8463799357414246,
                0.7828862071037292,
                0.8130470514297485,
                0.7958873510360718,
                0.7875181436538696,
                0.8003137707710266,
                0.8668279647827148,
                0.8573845028877258,
                0.8371949195861816,
                0.8348612785339355,
                0.8250712156295776,
                0.7367037534713745,
                0.7652838230133057,
                0.851284384727478,
                0.7639421820640564,
                0.8527888059616089,
                0.8102962970733643,
                0.804650068283081,
                0.8423362970352173,
                0.7624333500862122,
                0.8388639688491821,
                0.8206213712692261,
                0.8610019683837891,
                0.802582859992981,
                0.838261604309082,
                0.8649387359619141,
                0.7680243253707886,
                0.8163549900054932,
                0.8470944166183472
            ],
            [
                0.7747008204460144,
                0.7950034141540527,
                0.7979549169540405,
                0.766899585723877,
                0.7751093506813049,
                0.7540774345397949,
                0.7882218360900879,
                0.7822760343551636,
                0.8258726596832275,
                0.7896135449409485,
                0.7994622588157654,
                0.7667185068130493,
                0.7216954827308655,
                0.8126810193061829,
                0.8124892115592957,
                0.7848749756813049,
                0.8015310168266296,
                0.7792335748672485,
                0.7614849805831909,
                0.793315589427948,
                0.7104721069335938,
                0.8288447260856628,
                0.7918859720230103,
                0.6996745467185974,
                0.7767804265022278,
                0.8238939046859741,
                0.8213545083999634,
                0.7673240303993225,
                0.802269458770752,
                0.8253241777420044,
                0.8287786245346069,
                0.7953274250030518,
                0.7980561852455139,
                0.7656816244125366,
                0.7729684710502625,
                0.798579216003418,
                0.7869221568107605,
                0.8107436299324036,
                0.7916340827941895,
                0.8136409521102905,
                0.8183574080467224,
                0.7801180481910706,
                0.7866615056991577,
                0.7704468965530396,
                0.7822079062461853,
                0.7753815650939941,
                0.7270497679710388,
                0.7624877095222473,
                0.8054036498069763,
                0.7877610921859741,
                0.7892429828643799
            ],
            [
                0.8763496279716492,
                0.9038593173027039,
                0.9008911848068237,
                0.876234769821167,
                0.8666098117828369,
                0.7642113566398621,
                0.840012788772583,
                0.787057638168335,
                0.9083357453346252,
                0.8017923831939697,
                0.9053018689155579,
                0.7656700611114502,
                0.7248842120170593,
                0.8161174058914185,
                0.819488525390625,
                0.808934211730957,
                0.7896313071250916,
                0.8224624991416931,
                0.7728142142295837,
                0.8596993088722229,
                0.747278094291687,
                0.8776397705078125,
                0.7745331525802612,
                0.7104644775390625,
                0.8083773255348206,
                0.8317850828170776,
                0.8257396817207336,
                0.7983282208442688,
                0.801620602607727,
                0.8101101517677307,
                0.8096067309379578,
                0.8002822399139404,
                0.8269684314727783,
                0.9017733335494995,
                0.802794873714447,
                0.7995173931121826,
                0.909191370010376,
                0.8333081603050232,
                0.779107928276062,
                0.8157932758331299,
                0.8163518309593201,
                0.8998497128486633,
                0.851879358291626,
                0.7758559584617615,
                0.8178196549415588,
                0.7716224789619446,
                0.7433114051818848,
                0.7746196389198303,
                0.8657299876213074,
                0.8002046942710876,
                0.8186733722686768
            ],
            [
                0.773596465587616,
                0.7768118977546692,
                0.7785016298294067,
                0.7568767070770264,
                0.76031494140625,
                0.7571448087692261,
                0.7516254186630249,
                0.7515121698379517,
                0.8112630844116211,
                0.7839007377624512,
                0.8003098964691162,
                0.773556113243103,
                0.7115546464920044,
                0.816493034362793,
                0.7998782396316528,
                0.7656952142715454,
                0.7611782550811768,
                0.739494800567627,
                0.7775869369506836,
                0.7744291424751282,
                0.6991689801216125,
                0.7999598979949951,
                0.7681017518043518,
                0.6888214945793152,
                0.7409522533416748,
                0.7740442752838135,
                0.7605183124542236,
                0.7784258723258972,
                0.7981051802635193,
                0.8306347131729126,
                0.7993152141571045,
                0.7646387815475464,
                0.7663090825080872,
                0.7309118509292603,
                0.754549503326416,
                0.7821203470230103,
                0.7706021666526794,
                0.7973066568374634,
                0.7566303610801697,
                0.7871217131614685,
                0.8041797280311584,
                0.7618403434753418,
                0.7776970267295837,
                0.7559261322021484,
                0.7724958658218384,
                0.7571983933448792,
                0.7352249026298523,
                0.7541947960853577,
                0.7672010064125061,
                0.7725067734718323,
                0.77256840467453
            ],
            [
                0.848353385925293,
                0.8786364197731018,
                0.8696590662002563,
                0.8412162661552429,
                0.8328050374984741,
                0.8051837086677551,
                0.8103587627410889,
                0.8296144008636475,
                0.9004615545272827,
                0.8317530751228333,
                0.8966084122657776,
                0.7997770309448242,
                0.7707770466804504,
                0.849772572517395,
                0.857852041721344,
                0.8393541574478149,
                0.8223928213119507,
                0.7938575744628906,
                0.8104851245880127,
                0.8669567108154297,
                0.8033349514007568,
                0.8434941172599792,
                0.8255877494812012,
                0.7528523206710815,
                0.8507819771766663,
                0.8695117831230164,
                0.8694360256195068,
                0.8531283736228943,
                0.815896213054657,
                0.8297183513641357,
                0.8264985680580139,
                0.8358237743377686,
                0.8811960220336914,
                0.8455784320831299,
                0.8454753756523132,
                0.8261380791664124,
                0.8900856971740723,
                0.8799102902412415,
                0.8266641497612,
                0.8601131439208984,
                0.8607885241508484,
                0.867462694644928,
                0.8563661575317383,
                0.8413081169128418,
                0.8389624357223511,
                0.8385925889015198,
                0.7829858064651489,
                0.7734382748603821,
                0.8741496205329895,
                0.8422819972038269,
                0.8654956817626953
            ],
            [
                0.7893145084381104,
                0.7966734766960144,
                0.8055024147033691,
                0.779087483882904,
                0.773264467716217,
                0.7720151543617249,
                0.7845667004585266,
                0.783753514289856,
                0.8285951614379883,
                0.7841778993606567,
                0.812182605266571,
                0.7488886117935181,
                0.7341859936714172,
                0.7976693511009216,
                0.8025525808334351,
                0.7909201979637146,
                0.7728055715560913,
                0.7495041489601135,
                0.7552021145820618,
                0.7948675155639648,
                0.7148774266242981,
                0.835725724697113,
                0.7848711013793945,
                0.7206711769104004,
                0.7673566341400146,
                0.8026836514472961,
                0.8003360629081726,
                0.7936119437217712,
                0.8099842071533203,
                0.8236474394798279,
                0.837544322013855,
                0.7818302512168884,
                0.8008623123168945,
                0.7698500752449036,
                0.7847052812576294,
                0.8000174164772034,
                0.789957582950592,
                0.815182089805603,
                0.7740004062652588,
                0.8034284114837646,
                0.8215019106864929,
                0.7793777585029602,
                0.7989997863769531,
                0.7652592658996582,
                0.8006942868232727,
                0.7663971185684204,
                0.7466983795166016,
                0.7727987766265869,
                0.7951744794845581,
                0.7928560376167297,
                0.7983759045600891
            ],
            [
                0.7781014442443848,
                0.769791841506958,
                0.7678603529930115,
                0.7453591823577881,
                0.7644942402839661,
                0.767703115940094,
                0.7764192819595337,
                0.7635313868522644,
                0.8028273582458496,
                0.7870698571205139,
                0.7837885022163391,
                0.760663628578186,
                0.7212759852409363,
                0.781208336353302,
                0.7884925603866577,
                0.761675238609314,
                0.7409791350364685,
                0.742766261100769,
                0.7555870413780212,
                0.776601254940033,
                0.6883490085601807,
                0.8055360913276672,
                0.7743933200836182,
                0.6919494271278381,
                0.7328227758407593,
                0.7592158317565918,
                0.7488322257995605,
                0.7570172548294067,
                0.8182287812232971,
                0.8308318257331848,
                0.8248600363731384,
                0.7699851989746094,
                0.7692449688911438,
                0.7249341011047363,
                0.74898362159729,
                0.7912053465843201,
                0.7637262344360352,
                0.7988163828849792,
                0.7567867040634155,
                0.7794532775878906,
                0.8048707842826843,
                0.7633731961250305,
                0.7853584289550781,
                0.7395136952400208,
                0.7842879891395569,
                0.739611029624939,
                0.7628049254417419,
                0.7718978524208069,
                0.7734992504119873,
                0.7727054357528687,
                0.7787907123565674
            ],
            [
                0.793674886226654,
                0.8087650537490845,
                0.7973421812057495,
                0.8200831413269043,
                0.7392488718032837,
                0.6764847040176392,
                0.7199617028236389,
                0.6966869831085205,
                0.8241388201713562,
                0.7308850884437561,
                0.8426039814949036,
                0.7082531452178955,
                0.6708366274833679,
                0.7690587639808655,
                0.7564784288406372,
                0.7258872389793396,
                0.7361546754837036,
                0.7734644412994385,
                0.7182039618492126,
                0.7662927508354187,
                0.6924890875816345,
                0.7745806574821472,
                0.7161570191383362,
                0.6427993178367615,
                0.7587418556213379,
                0.7794340252876282,
                0.776426374912262,
                0.7558059692382812,
                0.7589917778968811,
                0.7848086953163147,
                0.7759960889816284,
                0.7368305325508118,
                0.7596171498298645,
                0.7851842045783997,
                0.7230877876281738,
                0.7326411008834839,
                0.823567807674408,
                0.7747048735618591,
                0.7441281676292419,
                0.7898321747779846,
                0.7425529956817627,
                0.7833976149559021,
                0.7688506841659546,
                0.7214308977127075,
                0.7337484359741211,
                0.7332972884178162,
                0.6887790560722351,
                0.6953276991844177,
                0.7690542936325073,
                0.7359687089920044,
                0.771050214767456
            ],
            [
                0.8614192605018616,
                0.8789445757865906,
                0.8725733757019043,
                0.8483558297157288,
                0.8567749261856079,
                0.8051337003707886,
                0.832473635673523,
                0.8135941028594971,
                0.9129951000213623,
                0.8381524682044983,
                0.8963185548782349,
                0.7923684120178223,
                0.7701928615570068,
                0.834261417388916,
                0.847838819026947,
                0.8297288417816162,
                0.8090307116508484,
                0.8186488747596741,
                0.8007725477218628,
                0.8738601207733154,
                0.7807261347770691,
                0.8646497130393982,
                0.8187319040298462,
                0.7540740966796875,
                0.8284677863121033,
                0.8491024374961853,
                0.8488324284553528,
                0.8273777365684509,
                0.8292294144630432,
                0.834073007106781,
                0.8358813524246216,
                0.8252278566360474,
                0.8566026091575623,
                0.8585219383239746,
                0.8150719404220581,
                0.8342621922492981,
                0.899272620677948,
                0.879059910774231,
                0.8161892890930176,
                0.845524787902832,
                0.8505237102508545,
                0.8802332878112793,
                0.8731819987297058,
                0.8203088641166687,
                0.8532203435897827,
                0.8203670382499695,
                0.7873393893241882,
                0.8021151423454285,
                0.8790723085403442,
                0.8318480253219604,
                0.8639426231384277
            ],
            [
                0.7880107164382935,
                0.7769300937652588,
                0.7914095520973206,
                0.7519382834434509,
                0.8159815073013306,
                0.7881330847740173,
                0.7780850529670715,
                0.7639629244804382,
                0.8233920335769653,
                0.8126857280731201,
                0.7983241081237793,
                0.8275960087776184,
                0.7141560912132263,
                0.8229138255119324,
                0.8140974044799805,
                0.7683249711990356,
                0.750725269317627,
                0.7567417621612549,
                0.811302125453949,
                0.7796292901039124,
                0.727683424949646,
                0.8098757266998291,
                0.7952218055725098,
                0.6869993805885315,
                0.7398506999015808,
                0.7542861700057983,
                0.7417258024215698,
                0.7798380851745605,
                0.8417801260948181,
                0.8645428419113159,
                0.8475552797317505,
                0.8169702887535095,
                0.7835658192634583,
                0.7417864799499512,
                0.7500032186508179,
                0.7904364466667175,
                0.7622495889663696,
                0.8022958040237427,
                0.7726045250892639,
                0.8000043034553528,
                0.8279852867126465,
                0.7692261934280396,
                0.7993565797805786,
                0.7778001427650452,
                0.807276725769043,
                0.7695306539535522,
                0.7902825474739075,
                0.8220654129981995,
                0.7860212922096252,
                0.7720217704772949,
                0.7874352931976318
            ],
            [
                0.9182323813438416,
                0.9096294641494751,
                0.9195301532745361,
                0.8949310183525085,
                0.9252601265907288,
                0.8890366554260254,
                0.8994491100311279,
                0.877140998840332,
                0.9392377138137817,
                0.9066582918167114,
                0.9427798986434937,
                0.865644633769989,
                0.8222217559814453,
                0.8957105278968811,
                0.9120163917541504,
                0.8915113806724548,
                0.8669437170028687,
                0.8499978184700012,
                0.8645369410514832,
                0.9187012910842896,
                0.8298280239105225,
                0.9356212615966797,
                0.8779897689819336,
                0.8068844676017761,
                0.8745328783988953,
                0.883025586605072,
                0.8777163028717041,
                0.8736236095428467,
                0.9022244215011597,
                0.8942179679870605,
                0.8862535953521729,
                0.8720355033874512,
                0.8849818706512451,
                0.8880175948143005,
                0.8618742227554321,
                0.8919467926025391,
                0.9146882891654968,
                0.9142777323722839,
                0.8719638586044312,
                0.8949043154716492,
                0.9002847671508789,
                0.9113203883171082,
                0.9289728403091431,
                0.8681422472000122,
                0.9184524416923523,
                0.8606822490692139,
                0.8628165125846863,
                0.8983662724494934,
                0.8792972564697266,
                0.8867504596710205,
                0.9053106307983398
            ],
            [
                0.8033100366592407,
                0.7671685218811035,
                0.7834184169769287,
                0.7685112357139587,
                0.7637952566146851,
                0.7391270995140076,
                0.7498292326927185,
                0.7278825044631958,
                0.8149323463439941,
                0.790765106678009,
                0.8052278757095337,
                0.7719661593437195,
                0.6982666254043579,
                0.7912051677703857,
                0.7739931344985962,
                0.7464379668235779,
                0.7295034527778625,
                0.7867632508277893,
                0.7665154337882996,
                0.7778416872024536,
                0.6925013661384583,
                0.7920970320701599,
                0.7559352517127991,
                0.6772355437278748,
                0.7182286381721497,
                0.7450258731842041,
                0.7337669134140015,
                0.7601771950721741,
                0.8143029808998108,
                0.8187875151634216,
                0.8083274960517883,
                0.7595095634460449,
                0.7482283711433411,
                0.7405552268028259,
                0.7191631197929382,
                0.7771829962730408,
                0.7752209305763245,
                0.7804784178733826,
                0.752225935459137,
                0.7822636961936951,
                0.7952012419700623,
                0.7694631814956665,
                0.7969074249267578,
                0.7445679306983948,
                0.7886446714401245,
                0.754122793674469,
                0.7519744038581848,
                0.7724063992500305,
                0.7655699849128723,
                0.7537267804145813,
                0.773079514503479
            ]
        ],
        [
            [
                0.7586925625801086,
                0.8658439517021179,
                0.6954047083854675,
                0.6803860068321228,
                0.699337899684906,
                0.708197295665741,
                0.7741554379463196,
                0.7780095338821411,
                0.725784420967102,
                0.7421777844429016,
                0.8211303353309631,
                0.7475011944770813,
                0.8256701231002808,
                0.730438232421875,
                0.737497091293335,
                0.7287889122962952,
                0.6736916303634644,
                0.7352270483970642,
                0.7897807359695435,
                0.7475600242614746,
                0.7380058169364929,
                0.7284504771232605,
                0.7709724307060242,
                0.7477969527244568,
                0.7416303753852844,
                0.7376208305358887,
                0.7272295951843262,
                0.7231011390686035,
                0.7190890908241272,
                0.6794490814208984,
                0.7370874285697937,
                0.7447479367256165,
                0.76657634973526,
                0.7504749894142151,
                0.6593930721282959,
                0.6699727177619934,
                0.5585767030715942,
                0.5545489192008972,
                0.7437293529510498,
                0.7163755297660828,
                0.7412664294242859,
                0.5665383338928223,
                0.7400099039077759,
                0.7223495244979858,
                0.5919265151023865,
                0.7543445825576782,
                0.7497833371162415,
                0.4944899380207062,
                0.7530381679534912,
                0.7242962718009949,
                0.5540756583213806
            ],
            [
                0.732668399810791,
                0.6857489943504333,
                0.5836415886878967,
                0.6731135249137878,
                0.6391221880912781,
                0.7974015474319458,
                0.6398126482963562,
                0.853926956653595,
                0.6478533148765564,
                0.7792609930038452,
                0.7242001891136169,
                0.8492788076400757,
                0.7094749212265015,
                0.7556436657905579,
                0.6388542652130127,
                0.7580925822257996,
                0.5592518448829651,
                0.7557869553565979,
                0.6944417357444763,
                0.8118730187416077,
                0.657600462436676,
                0.8592204451560974,
                0.6611942052841187,
                0.8502457141876221,
                0.830536961555481,
                0.7564908266067505,
                0.7437899112701416,
                0.7827421426773071,
                0.8473822474479675,
                0.6669389605522156,
                0.8529379963874817,
                0.7759881019592285,
                0.8049873113632202,
                0.7905181646347046,
                0.6471574306488037,
                0.6370155215263367,
                0.6773430109024048,
                0.49769407510757446,
                0.7784644365310669,
                0.6680507063865662,
                0.7736276984214783,
                0.5351024270057678,
                0.7518730163574219,
                0.812743067741394,
                0.5311992764472961,
                0.7891101837158203,
                0.8260215520858765,
                0.4434826970100403,
                0.7481645941734314,
                0.8110662698745728,
                0.5318025350570679
            ],
            [
                0.8062571883201599,
                0.80876225233078,
                0.6540799736976624,
                0.7116482853889465,
                0.7674378752708435,
                0.7659925818443298,
                0.7267244458198547,
                0.8475756049156189,
                0.7637381553649902,
                0.8082026243209839,
                0.7980021834373474,
                0.812953770160675,
                0.8140051364898682,
                0.7647413611412048,
                0.7348229289054871,
                0.7787322402000427,
                0.6290679574012756,
                0.7760685682296753,
                0.7669315934181213,
                0.8132451176643372,
                0.71270352602005,
                0.8001406788825989,
                0.744062066078186,
                0.8116040825843811,
                0.8145495057106018,
                0.779679000377655,
                0.7549854516983032,
                0.7582772374153137,
                0.787592351436615,
                0.7464409470558167,
                0.8106924295425415,
                0.7795301079750061,
                0.8127733469009399,
                0.8019999861717224,
                0.6756339073181152,
                0.6622805595397949,
                0.6012949347496033,
                0.5902177095413208,
                0.7943609356880188,
                0.7092663049697876,
                0.7789415717124939,
                0.5562627911567688,
                0.7684987783432007,
                0.8009777665138245,
                0.5844206809997559,
                0.7954913377761841,
                0.8189704418182373,
                0.4848940074443817,
                0.7920137047767639,
                0.801350474357605,
                0.54017573595047
            ],
            [
                0.7739811539649963,
                0.7275373339653015,
                0.6502769589424133,
                0.8400105237960815,
                0.6826044321060181,
                0.8343127965927124,
                0.7049767971038818,
                0.9046494364738464,
                0.7275255918502808,
                0.8381170034408569,
                0.7792569398880005,
                0.8518176078796387,
                0.7598371505737305,
                0.8353051543235779,
                0.6637831926345825,
                0.8363721966743469,
                0.6305862665176392,
                0.8074483871459961,
                0.748927891254425,
                0.8600910902023315,
                0.6745456457138062,
                0.8570968508720398,
                0.7138365507125854,
                0.8538224697113037,
                0.8750247955322266,
                0.8097333908081055,
                0.7895795702934265,
                0.8232559561729431,
                0.8395504951477051,
                0.7339081764221191,
                0.862485408782959,
                0.8175380229949951,
                0.8390616774559021,
                0.8294185400009155,
                0.679662823677063,
                0.7006378173828125,
                0.6125965118408203,
                0.5264659523963928,
                0.8457039594650269,
                0.7089527249336243,
                0.8847315907478333,
                0.5932835340499878,
                0.8361266851425171,
                0.8476467132568359,
                0.5949523448944092,
                0.8716020584106445,
                0.888266921043396,
                0.47188401222229004,
                0.877930760383606,
                0.8495460748672485,
                0.5326182246208191
            ],
            [
                0.7753552198410034,
                0.7081184387207031,
                0.7738425135612488,
                0.8297407627105713,
                0.7487814426422119,
                0.8428493142127991,
                0.7717132568359375,
                0.8797677755355835,
                0.7519428730010986,
                0.8937762379646301,
                0.8270522952079773,
                0.8660598397254944,
                0.807103157043457,
                0.8956767916679382,
                0.7320711016654968,
                0.8803142309188843,
                0.7266169190406799,
                0.8681702613830566,
                0.8122528195381165,
                0.8606719374656677,
                0.6875249743461609,
                0.8216310739517212,
                0.7405064105987549,
                0.8688504099845886,
                0.8557842969894409,
                0.8662023544311523,
                0.8823332190513611,
                0.8856011629104614,
                0.8040665984153748,
                0.7996209859848022,
                0.7881479263305664,
                0.8534287810325623,
                0.8561487793922424,
                0.8449289798736572,
                0.7922393679618835,
                0.8210176229476929,
                0.5798395872116089,
                0.6240331530570984,
                0.8781825304031372,
                0.8268887400627136,
                0.911034882068634,
                0.6977125406265259,
                0.8571418523788452,
                0.8684089779853821,
                0.650297224521637,
                0.8697332739830017,
                0.8728244304656982,
                0.5680292844772339,
                0.8767820000648499,
                0.8775864243507385,
                0.6624849438667297
            ],
            [
                0.809475839138031,
                0.7191959619522095,
                0.6833070516586304,
                0.7466809749603271,
                0.7287204265594482,
                0.9248705506324768,
                0.7056626677513123,
                0.8863725066184998,
                0.7210138440132141,
                0.8967424631118774,
                0.7823194265365601,
                0.8999003767967224,
                0.7766757011413574,
                0.8473873734474182,
                0.7069145441055298,
                0.8487198948860168,
                0.6494188904762268,
                0.849560558795929,
                0.7445887327194214,
                0.8921534419059753,
                0.6794091463088989,
                0.8672874569892883,
                0.7284284830093384,
                0.9009146094322205,
                0.8895159363746643,
                0.8565688133239746,
                0.8605130314826965,
                0.8650471568107605,
                0.8534401059150696,
                0.7896831035614014,
                0.8710726499557495,
                0.869289755821228,
                0.8861990571022034,
                0.8663620948791504,
                0.7907150387763977,
                0.79423588514328,
                0.6991480588912964,
                0.6111839413642883,
                0.8829874992370605,
                0.7753533124923706,
                0.8824633955955505,
                0.6105574369430542,
                0.8358365297317505,
                0.8878433704376221,
                0.6041538715362549,
                0.8917659521102905,
                0.8937274813652039,
                0.49565160274505615,
                0.8495127558708191,
                0.8889917731285095,
                0.5894190073013306
            ],
            [
                0.709097683429718,
                0.8108527660369873,
                0.6722391843795776,
                0.6958519816398621,
                0.7501861453056335,
                0.7202927470207214,
                0.7740631103515625,
                0.7695358991622925,
                0.7467529773712158,
                0.7605138421058655,
                0.7606345415115356,
                0.7130716443061829,
                0.8223150968551636,
                0.7387980222702026,
                0.7400819063186646,
                0.7439049482345581,
                0.6597992181777954,
                0.7451238036155701,
                0.7653188109397888,
                0.7436057329177856,
                0.7438216209411621,
                0.7034502625465393,
                0.8318235874176025,
                0.71662837266922,
                0.7453858256340027,
                0.7554991245269775,
                0.7338644862174988,
                0.7312000393867493,
                0.7021111845970154,
                0.7422025203704834,
                0.7102802395820618,
                0.77768874168396,
                0.765225350856781,
                0.7600015997886658,
                0.7049822807312012,
                0.6891169548034668,
                0.5684794783592224,
                0.6735060214996338,
                0.7756131887435913,
                0.7661635279655457,
                0.7384825944900513,
                0.5419026613235474,
                0.7294784188270569,
                0.7446041703224182,
                0.6315110921859741,
                0.7507351636886597,
                0.7601416707038879,
                0.5449776649475098,
                0.7597435712814331,
                0.7458683252334595,
                0.5884606242179871
            ],
            [
                0.7733821868896484,
                0.7667363286018372,
                0.7726293206214905,
                0.7777949571609497,
                0.710624635219574,
                0.8414729833602905,
                0.80133056640625,
                0.8896814584732056,
                0.7794008255004883,
                0.8689188957214355,
                0.8135976195335388,
                0.8530284762382507,
                0.8241215348243713,
                0.8754593729972839,
                0.7118636965751648,
                0.8637277483940125,
                0.7544314861297607,
                0.8573771715164185,
                0.7944754958152771,
                0.8677009344100952,
                0.7076356410980225,
                0.8464171886444092,
                0.7329888343811035,
                0.8574936985969543,
                0.8594064712524414,
                0.8617085814476013,
                0.8935938477516174,
                0.8736552596092224,
                0.845639705657959,
                0.8038749694824219,
                0.8164383769035339,
                0.8735103011131287,
                0.8775202631950378,
                0.8722178936004639,
                0.7477896213531494,
                0.7885425090789795,
                0.6130881309509277,
                0.5665050745010376,
                0.8608110547065735,
                0.7928885817527771,
                0.8944489359855652,
                0.6244000196456909,
                0.8463849425315857,
                0.8646219372749329,
                0.6781099438667297,
                0.8712356686592102,
                0.8751068115234375,
                0.5202344655990601,
                0.8839244842529297,
                0.870261013507843,
                0.5952744483947754
            ],
            [
                0.7781514525413513,
                0.7498443722724915,
                0.7588425874710083,
                0.8101846575737,
                0.7831364870071411,
                0.8252629041671753,
                0.7979457974433899,
                0.8787417411804199,
                0.8074251413345337,
                0.9195153713226318,
                0.8412408232688904,
                0.8518610000610352,
                0.8313742280006409,
                0.8874039649963379,
                0.7538867592811584,
                0.891682505607605,
                0.7477599382400513,
                0.8826087713241577,
                0.825534999370575,
                0.8718934059143066,
                0.7156042456626892,
                0.8117533326148987,
                0.7658635377883911,
                0.8534807562828064,
                0.8608770370483398,
                0.892768144607544,
                0.8943723440170288,
                0.8773778080940247,
                0.7981501221656799,
                0.8206523656845093,
                0.7860407829284668,
                0.8832223415374756,
                0.885792076587677,
                0.8719135522842407,
                0.7968060374259949,
                0.8177675604820251,
                0.5692278146743774,
                0.6643103361129761,
                0.9074292778968811,
                0.8578059077262878,
                0.9184422492980957,
                0.6437340974807739,
                0.8760923743247986,
                0.8837870359420776,
                0.6813936829566956,
                0.890384316444397,
                0.892155647277832,
                0.546837568283081,
                0.9041357636451721,
                0.8883088827133179,
                0.6409913897514343
            ],
            [
                0.7227790355682373,
                0.7117725610733032,
                0.6697273254394531,
                0.7069880962371826,
                0.7313061952590942,
                0.7907304763793945,
                0.7002871036529541,
                0.8733714818954468,
                0.7703651785850525,
                0.8558589816093445,
                0.8226070404052734,
                0.8655188679695129,
                0.7939375042915344,
                0.8016602396965027,
                0.7360784411430359,
                0.8101701140403748,
                0.6819639801979065,
                0.821723222732544,
                0.7907544374465942,
                0.821128785610199,
                0.7174501419067383,
                0.812744140625,
                0.708441436290741,
                0.8670047521591187,
                0.8309972882270813,
                0.8258722424507141,
                0.8129016757011414,
                0.822921633720398,
                0.7997744083404541,
                0.7599982023239136,
                0.8019896149635315,
                0.8268510699272156,
                0.8397641777992249,
                0.8368794918060303,
                0.716693103313446,
                0.7160139083862305,
                0.5872858762741089,
                0.5575832724571228,
                0.8151381611824036,
                0.7682338356971741,
                0.8169922828674316,
                0.564348042011261,
                0.7792101502418518,
                0.8330056071281433,
                0.6170032024383545,
                0.81154865026474,
                0.8388727307319641,
                0.4990227520465851,
                0.8081504106521606,
                0.8330910801887512,
                0.5641964673995972
            ],
            [
                0.7596410512924194,
                0.7587551474571228,
                0.6204053163528442,
                0.6976414918899536,
                0.6944738626480103,
                0.8125094175338745,
                0.6802899837493896,
                0.8768431544303894,
                0.7539001107215881,
                0.8334959745407104,
                0.7662901282310486,
                0.849084734916687,
                0.7774966359138489,
                0.8021568059921265,
                0.7177289724349976,
                0.8150250315666199,
                0.603909432888031,
                0.8018795251846313,
                0.7391117811203003,
                0.8385648727416992,
                0.7017374634742737,
                0.8517253398895264,
                0.7150256037712097,
                0.847945511341095,
                0.8601710200309753,
                0.8049960136413574,
                0.7847979068756104,
                0.7845826148986816,
                0.840407133102417,
                0.7881501317024231,
                0.8579814434051514,
                0.8187758922576904,
                0.8370868563652039,
                0.8312699198722839,
                0.6960012316703796,
                0.6762499213218689,
                0.6673349738121033,
                0.5704213976860046,
                0.8092924356460571,
                0.7110623121261597,
                0.7874181866645813,
                0.5587359666824341,
                0.7903692126274109,
                0.8327797055244446,
                0.5543019771575928,
                0.8011155724525452,
                0.844270646572113,
                0.4792884886264801,
                0.7943712472915649,
                0.8285390138626099,
                0.5504469275474548
            ],
            [
                0.7711948752403259,
                0.7295137643814087,
                0.7824358344078064,
                0.7947821021080017,
                0.767397940158844,
                0.8067985773086548,
                0.7758779525756836,
                0.8511117100715637,
                0.7832800149917603,
                0.8710014820098877,
                0.8210004568099976,
                0.8279263973236084,
                0.822591245174408,
                0.8601403832435608,
                0.7358659505844116,
                0.8488047122955322,
                0.7418091297149658,
                0.8548582792282104,
                0.816685140132904,
                0.8258310556411743,
                0.7407703995704651,
                0.7805100083351135,
                0.754425585269928,
                0.8291261792182922,
                0.8156313896179199,
                0.8535569906234741,
                0.8659379482269287,
                0.8620213270187378,
                0.7682827115058899,
                0.8041316270828247,
                0.7518030405044556,
                0.831320583820343,
                0.8363044261932373,
                0.8315589427947998,
                0.7822748422622681,
                0.8130712509155273,
                0.5753500461578369,
                0.6127179861068726,
                0.8420473337173462,
                0.8421205282211304,
                0.866605818271637,
                0.6753935813903809,
                0.8331782817840576,
                0.8385974764823914,
                0.6739714741706848,
                0.8432703614234924,
                0.8386530876159668,
                0.560731053352356,
                0.8637809753417969,
                0.846233606338501,
                0.6480420827865601
            ],
            [
                0.7561174631118774,
                0.8076451420783997,
                0.6664536595344543,
                0.762531578540802,
                0.7055709362030029,
                0.8084481358528137,
                0.7759295105934143,
                0.9075161814689636,
                0.8217325806617737,
                0.8627511858940125,
                0.812096118927002,
                0.8461766839027405,
                0.8179271221160889,
                0.8320210576057434,
                0.7238909006118774,
                0.8493592143058777,
                0.7110568284988403,
                0.8316919803619385,
                0.7919707298278809,
                0.8525313138961792,
                0.7215039730072021,
                0.8493032455444336,
                0.7234162092208862,
                0.8495000600814819,
                0.8697903752326965,
                0.8479260206222534,
                0.8412939310073853,
                0.8236921429634094,
                0.8453715443611145,
                0.783263087272644,
                0.8377084136009216,
                0.8551836013793945,
                0.865906298160553,
                0.8618264198303223,
                0.6940577626228333,
                0.7090178728103638,
                0.5885302424430847,
                0.5492944717407227,
                0.8508216142654419,
                0.7619313597679138,
                0.8652990460395813,
                0.5497955083847046,
                0.8387435674667358,
                0.8581793904304504,
                0.682573676109314,
                0.8554477691650391,
                0.8888974189758301,
                0.4869333803653717,
                0.8810667991638184,
                0.8558933734893799,
                0.5385120511054993
            ],
            [
                0.7802445888519287,
                0.7520769238471985,
                0.6745677590370178,
                0.7763968706130981,
                0.7214697003364563,
                0.8536819219589233,
                0.7429909706115723,
                0.9443884491920471,
                0.7895678281784058,
                0.9296832084655762,
                0.8297861218452454,
                0.9034436345100403,
                0.8139309287071228,
                0.8973760008811951,
                0.7288362383842468,
                0.9017190933227539,
                0.6962200403213501,
                0.8877969980239868,
                0.7887381911277771,
                0.9148163795471191,
                0.7021493911743164,
                0.8885401487350464,
                0.7287307381629944,
                0.9075693488121033,
                0.9297181963920593,
                0.8995184302330017,
                0.8707524538040161,
                0.8750660419464111,
                0.8797073364257812,
                0.8044983148574829,
                0.8799698948860168,
                0.9097551107406616,
                0.9093922972679138,
                0.9067841172218323,
                0.7437184453010559,
                0.7514401078224182,
                0.6060134172439575,
                0.5731046199798584,
                0.9078202247619629,
                0.7717549204826355,
                0.8978597521781921,
                0.634611189365387,
                0.893957793712616,
                0.9253401160240173,
                0.6394586563110352,
                0.9060941934585571,
                0.9401848316192627,
                0.513547956943512,
                0.9043326377868652,
                0.9242924451828003,
                0.6177073121070862
            ],
            [
                0.8088451623916626,
                0.7009732127189636,
                0.7817769646644592,
                0.7651215195655823,
                0.7331200838088989,
                0.8334634900093079,
                0.7426076531410217,
                0.814501941204071,
                0.7160323262214661,
                0.8366791009902954,
                0.7750606536865234,
                0.8057329654693604,
                0.784213662147522,
                0.8563823699951172,
                0.7103999257087708,
                0.8250566720962524,
                0.67974853515625,
                0.8307684063911438,
                0.7549062967300415,
                0.8350546360015869,
                0.7136396169662476,
                0.7889705896377563,
                0.7403830289840698,
                0.8093091249465942,
                0.808680534362793,
                0.814113199710846,
                0.8406429290771484,
                0.8587014675140381,
                0.7858545780181885,
                0.7850446105003357,
                0.7557430863380432,
                0.8283785581588745,
                0.821226179599762,
                0.8149346709251404,
                0.7843208312988281,
                0.8003804683685303,
                0.6137463450431824,
                0.6363838315010071,
                0.8298696875572205,
                0.7924044132232666,
                0.8362930417060852,
                0.7209228277206421,
                0.8080482482910156,
                0.839995801448822,
                0.6411598920822144,
                0.8380049467086792,
                0.8252726197242737,
                0.5985999703407288,
                0.8202846050262451,
                0.8508660793304443,
                0.6721551418304443
            ],
            [
                0.7326122522354126,
                0.7616716623306274,
                0.6346707940101624,
                0.6869242787361145,
                0.771985650062561,
                0.6929185390472412,
                0.7049154043197632,
                0.8066446781158447,
                0.7881214022636414,
                0.7827064990997314,
                0.7634487748146057,
                0.7567863464355469,
                0.7770677804946899,
                0.723718523979187,
                0.751784086227417,
                0.7526295185089111,
                0.6142959594726562,
                0.7475755214691162,
                0.7436016201972961,
                0.7471950054168701,
                0.7410051226615906,
                0.7069348692893982,
                0.7573673725128174,
                0.7554630637168884,
                0.7594620585441589,
                0.7563177347183228,
                0.7071981430053711,
                0.7226998805999756,
                0.6909341216087341,
                0.7256210446357727,
                0.7196572422981262,
                0.746995210647583,
                0.7529910802841187,
                0.7563716769218445,
                0.6999291181564331,
                0.6722273826599121,
                0.5879074931144714,
                0.6520434617996216,
                0.740469753742218,
                0.7285557389259338,
                0.7265434265136719,
                0.5800865292549133,
                0.7135223150253296,
                0.7623773217201233,
                0.6359385848045349,
                0.7385993599891663,
                0.773864209651947,
                0.5803524255752563,
                0.7500684857368469,
                0.7607694268226624,
                0.6158730387687683
            ],
            [
                0.722161054611206,
                0.7686550617218018,
                0.5685794353485107,
                0.667991042137146,
                0.7252640724182129,
                0.7051544189453125,
                0.6818125247955322,
                0.8121052980422974,
                0.7810811996459961,
                0.7860850691795349,
                0.7473017573356628,
                0.7387607097625732,
                0.773661732673645,
                0.7333236336708069,
                0.7222124338150024,
                0.7626998424530029,
                0.5784596800804138,
                0.7474038600921631,
                0.7300038933753967,
                0.7574002146720886,
                0.6847844123840332,
                0.7354052662849426,
                0.7081680297851562,
                0.7365244030952454,
                0.768878161907196,
                0.7570358514785767,
                0.7084313035011292,
                0.707026481628418,
                0.7244449853897095,
                0.7476918697357178,
                0.746505856513977,
                0.7566021084785461,
                0.7637264728546143,
                0.7584900856018066,
                0.6621995568275452,
                0.632777214050293,
                0.5710780024528503,
                0.5985724925994873,
                0.7597700357437134,
                0.6934790015220642,
                0.7224538326263428,
                0.5353305339813232,
                0.7482226490974426,
                0.7747116684913635,
                0.5915815234184265,
                0.7392079830169678,
                0.783799946308136,
                0.4957314133644104,
                0.7640318274497986,
                0.7663872241973877,
                0.5578604340553284
            ],
            [
                0.8098119497299194,
                0.6996762156486511,
                0.7661586403846741,
                0.7586556673049927,
                0.7169367074966431,
                0.8461039066314697,
                0.7311334013938904,
                0.8135330080986023,
                0.7176344394683838,
                0.8315017223358154,
                0.7657654285430908,
                0.8103927373886108,
                0.7793015241622925,
                0.84840989112854,
                0.714237630367279,
                0.8197477459907532,
                0.6786651015281677,
                0.8259426355361938,
                0.7591265439987183,
                0.8462161421775818,
                0.7112379670143127,
                0.7948969602584839,
                0.7333686947822571,
                0.8134469389915466,
                0.8200632929801941,
                0.8092796802520752,
                0.8387290835380554,
                0.8495656251907349,
                0.7929179668426514,
                0.8134632110595703,
                0.7762954831123352,
                0.8329957127571106,
                0.821251630783081,
                0.8241134881973267,
                0.7879387140274048,
                0.796309232711792,
                0.6337616443634033,
                0.6346850395202637,
                0.81929612159729,
                0.7824990749359131,
                0.8288094401359558,
                0.7175387144088745,
                0.7983872294425964,
                0.8291527032852173,
                0.6428860425949097,
                0.8288594484329224,
                0.8185045123100281,
                0.5954703092575073,
                0.8082671761512756,
                0.8362773060798645,
                0.6620287895202637
            ],
            [
                0.7363101243972778,
                0.7745994329452515,
                0.6599322557449341,
                0.6966086626052856,
                0.7414587140083313,
                0.7340356707572937,
                0.7327510118484497,
                0.8117250204086304,
                0.8047489523887634,
                0.8009354472160339,
                0.7603064179420471,
                0.7737399339675903,
                0.782112717628479,
                0.7524310946464539,
                0.7710431814193726,
                0.7796688675880432,
                0.6758847236633301,
                0.788421630859375,
                0.7834265232086182,
                0.7831995487213135,
                0.7209600806236267,
                0.7261391282081604,
                0.7576295733451843,
                0.7754107117652893,
                0.7930017113685608,
                0.8030469417572021,
                0.7750117778778076,
                0.7643868327140808,
                0.7150430083274841,
                0.7740127444267273,
                0.7396629452705383,
                0.7896167635917664,
                0.7823521494865417,
                0.8068515062332153,
                0.7278376817703247,
                0.7212539911270142,
                0.6291310787200928,
                0.6418750286102295,
                0.751136064529419,
                0.7543364763259888,
                0.7557337880134583,
                0.6217195987701416,
                0.731386125087738,
                0.7703796029090881,
                0.6916185617446899,
                0.7609065175056458,
                0.7867262959480286,
                0.5896518230438232,
                0.7653540372848511,
                0.768450915813446,
                0.6217289566993713
            ],
            [
                0.7775335311889648,
                0.7831993103027344,
                0.643751859664917,
                0.7519486546516418,
                0.725861668586731,
                0.8141269087791443,
                0.7303897738456726,
                0.888841450214386,
                0.800962507724762,
                0.8442932963371277,
                0.788346529006958,
                0.8171007633209229,
                0.8137436509132385,
                0.8260113000869751,
                0.7290269136428833,
                0.8290318250656128,
                0.6444613337516785,
                0.8211832046508789,
                0.7860603928565979,
                0.8406708836555481,
                0.7284945249557495,
                0.8131345510482788,
                0.7383588552474976,
                0.8227971792221069,
                0.852513313293457,
                0.8213139176368713,
                0.7993919849395752,
                0.8094853758811951,
                0.8113874197006226,
                0.8249413371086121,
                0.8211658596992493,
                0.8440770506858826,
                0.8271892666816711,
                0.8409308791160583,
                0.7130897045135498,
                0.6984111070632935,
                0.6192098259925842,
                0.5946112871170044,
                0.8340398073196411,
                0.766674280166626,
                0.822641909122467,
                0.6097635626792908,
                0.8198482990264893,
                0.850526750087738,
                0.6596908569335938,
                0.8264967203140259,
                0.8622356653213501,
                0.5414849519729614,
                0.8420144319534302,
                0.8460355997085571,
                0.5962605476379395
            ],
            [
                0.7789395451545715,
                0.7770973443984985,
                0.6886416077613831,
                0.750114381313324,
                0.7706316709518433,
                0.7434413433074951,
                0.7616462111473083,
                0.8367971181869507,
                0.823550283908844,
                0.83461594581604,
                0.7661646604537964,
                0.7836892604827881,
                0.782423198223114,
                0.7945101261138916,
                0.7627546191215515,
                0.8165557980537415,
                0.6845967173576355,
                0.8085494637489319,
                0.759925127029419,
                0.7816060781478882,
                0.7293137907981873,
                0.7342361211776733,
                0.7718425393104553,
                0.7851457595825195,
                0.7881767153739929,
                0.8211359977722168,
                0.7854258418083191,
                0.8016247153282166,
                0.715918242931366,
                0.74278724193573,
                0.7226197123527527,
                0.7861472368240356,
                0.7873315811157227,
                0.7896685600280762,
                0.7560651302337646,
                0.7515995502471924,
                0.6161926984786987,
                0.6516894102096558,
                0.7760714888572693,
                0.7632979154586792,
                0.7853235006332397,
                0.6476424336433411,
                0.7701921463012695,
                0.7969138026237488,
                0.6948705911636353,
                0.8159236311912537,
                0.8116657733917236,
                0.5821966528892517,
                0.8193603754043579,
                0.8018385171890259,
                0.6767462491989136
            ],
            [
                0.7868400812149048,
                0.8088319301605225,
                0.6786952018737793,
                0.7771445512771606,
                0.7495738863945007,
                0.8063326478004456,
                0.7643868923187256,
                0.9131819605827332,
                0.8162820935249329,
                0.8631352782249451,
                0.807456910610199,
                0.8406916856765747,
                0.8249931335449219,
                0.854385495185852,
                0.7437664866447449,
                0.8581920862197876,
                0.6777123808860779,
                0.8410511612892151,
                0.7872376441955566,
                0.8519260883331299,
                0.7380220890045166,
                0.8359798192977905,
                0.7643930315971375,
                0.8439419269561768,
                0.860532283782959,
                0.8413541316986084,
                0.8192908763885498,
                0.8386536836624146,
                0.8280254602432251,
                0.8020580410957336,
                0.8267387747764587,
                0.8419126272201538,
                0.8426461219787598,
                0.8459140062332153,
                0.7234864830970764,
                0.722722053527832,
                0.6215861439704895,
                0.5977703332901001,
                0.8374781608581543,
                0.7734661102294922,
                0.8383364081382751,
                0.6257767677307129,
                0.8284653425216675,
                0.8585290312767029,
                0.6479408740997314,
                0.8460296392440796,
                0.869444727897644,
                0.5290660858154297,
                0.8524816632270813,
                0.85521399974823,
                0.6139523386955261
            ],
            [
                0.7366357445716858,
                0.7392427325248718,
                0.6539396643638611,
                0.7081310749053955,
                0.7641011476516724,
                0.7119259834289551,
                0.7113946080207825,
                0.808220386505127,
                0.8101093173027039,
                0.8104752898216248,
                0.7419511675834656,
                0.7597346901893616,
                0.7639818787574768,
                0.7508834600448608,
                0.7493536472320557,
                0.788063645362854,
                0.6630011796951294,
                0.7867098450660706,
                0.7446810603141785,
                0.771404504776001,
                0.7002285718917847,
                0.7016869783401489,
                0.7435619235038757,
                0.7583339214324951,
                0.7766432166099548,
                0.8012839555740356,
                0.7555339932441711,
                0.7476463317871094,
                0.6841561198234558,
                0.7454771399497986,
                0.7020233869552612,
                0.7680893540382385,
                0.7670825719833374,
                0.7856555581092834,
                0.7402629852294922,
                0.7275004386901855,
                0.5900574922561646,
                0.6469775438308716,
                0.7458151578903198,
                0.7405804991722107,
                0.752959132194519,
                0.6066674590110779,
                0.7295041084289551,
                0.7740756273269653,
                0.6808649897575378,
                0.7662574648857117,
                0.788238525390625,
                0.5754228234291077,
                0.7705879211425781,
                0.7747204899787903,
                0.639236569404602
            ],
            [
                0.7913840413093567,
                0.7760518789291382,
                0.6549188494682312,
                0.7650591731071472,
                0.7708550095558167,
                0.7802664637565613,
                0.7042009830474854,
                0.8569297790527344,
                0.8153320550918579,
                0.8433083891868591,
                0.7801883816719055,
                0.8049848675727844,
                0.8114333152770996,
                0.8130418062210083,
                0.7408838272094727,
                0.8402135968208313,
                0.6391976475715637,
                0.8180954456329346,
                0.7710956931114197,
                0.832964301109314,
                0.7076255083084106,
                0.7927252650260925,
                0.7479738593101501,
                0.802172064781189,
                0.832128643989563,
                0.8235059976577759,
                0.7835967540740967,
                0.7828558683395386,
                0.7788223028182983,
                0.8056159019470215,
                0.7835025191307068,
                0.8082853555679321,
                0.8186278939247131,
                0.8243258595466614,
                0.7347882390022278,
                0.7170187830924988,
                0.6018433570861816,
                0.6347206830978394,
                0.8077393174171448,
                0.7442806363105774,
                0.7993900179862976,
                0.6091587543487549,
                0.7973586320877075,
                0.8266176581382751,
                0.6246692538261414,
                0.8017032146453857,
                0.8364125490188599,
                0.5467019081115723,
                0.8133723139762878,
                0.8229491710662842,
                0.6248675584793091
            ],
            [
                0.8177560567855835,
                0.7293383479118347,
                0.7188143134117126,
                0.7855532765388489,
                0.7779124975204468,
                0.8245959877967834,
                0.7473553419113159,
                0.8775336742401123,
                0.8162301182746887,
                0.9104422926902771,
                0.7976199388504028,
                0.8314626216888428,
                0.805241584777832,
                0.872215211391449,
                0.742100715637207,
                0.8730539679527283,
                0.6752240657806396,
                0.8712269067764282,
                0.7853467464447021,
                0.8511720299720764,
                0.711776852607727,
                0.7846505045890808,
                0.761806070804596,
                0.8327337503433228,
                0.8500568866729736,
                0.8678585886955261,
                0.8536443710327148,
                0.8525377511978149,
                0.7673044800758362,
                0.8538374304771423,
                0.7756883502006531,
                0.857171356678009,
                0.8564256429672241,
                0.8469341993331909,
                0.8181856870651245,
                0.8242650032043457,
                0.5982819199562073,
                0.6618942022323608,
                0.8666470646858215,
                0.8351332545280457,
                0.8804548978805542,
                0.7006828784942627,
                0.8615326881408691,
                0.8783389329910278,
                0.6821509003639221,
                0.8700785636901855,
                0.8827563524246216,
                0.5995596051216125,
                0.8860567212104797,
                0.8853939175605774,
                0.684049665927887
            ],
            [
                0.7920972108840942,
                0.799091100692749,
                0.6916223168373108,
                0.7245282530784607,
                0.7906116247177124,
                0.7573645114898682,
                0.7512718439102173,
                0.855046808719635,
                0.8391861915588379,
                0.8420572876930237,
                0.8049079179763794,
                0.8019994497299194,
                0.8426282405853271,
                0.8029111623764038,
                0.7701196670532227,
                0.8142119646072388,
                0.6685107946395874,
                0.813628077507019,
                0.7913689613342285,
                0.7902474999427795,
                0.7551639080047607,
                0.7532473206520081,
                0.7895101308822632,
                0.8028247356414795,
                0.8026424646377563,
                0.812305212020874,
                0.7858651876449585,
                0.7802196741104126,
                0.7377130389213562,
                0.8121089339256287,
                0.7524657845497131,
                0.7928606271743774,
                0.8025459051132202,
                0.7987714409828186,
                0.7619826793670654,
                0.7461996078491211,
                0.5918377637863159,
                0.6683664321899414,
                0.7857887744903564,
                0.8111960887908936,
                0.7996394038200378,
                0.6420614123344421,
                0.7725138068199158,
                0.8034823536872864,
                0.6717815399169922,
                0.7963640093803406,
                0.8147603869438171,
                0.6015076041221619,
                0.8061052560806274,
                0.8066273927688599,
                0.6665248870849609
            ],
            [
                0.7707669734954834,
                0.7500565648078918,
                0.7121855020523071,
                0.7322597503662109,
                0.8012993931770325,
                0.754272997379303,
                0.7622863054275513,
                0.8218185305595398,
                0.7875564694404602,
                0.8509318232536316,
                0.8224460482597351,
                0.7965168356895447,
                0.8226112723350525,
                0.7941099405288696,
                0.7726690769195557,
                0.7997648119926453,
                0.6677234768867493,
                0.8091363906860352,
                0.8095267415046692,
                0.7856858372688293,
                0.7636210918426514,
                0.7232572436332703,
                0.7899772524833679,
                0.7948849201202393,
                0.7780264616012573,
                0.806290328502655,
                0.7849750518798828,
                0.7823663949966431,
                0.7047516107559204,
                0.7913747429847717,
                0.7147325873374939,
                0.7941284775733948,
                0.798739492893219,
                0.7832326889038086,
                0.7907528877258301,
                0.7714504599571228,
                0.5614248514175415,
                0.7125810384750366,
                0.8030804395675659,
                0.8503861427307129,
                0.8034449219703674,
                0.6484984755516052,
                0.768439531326294,
                0.8057612180709839,
                0.658247709274292,
                0.7896655201911926,
                0.8023549318313599,
                0.5982046723365784,
                0.7921884059906006,
                0.8097012639045715,
                0.6863020062446594
            ],
            [
                0.8047671318054199,
                0.8180216550827026,
                0.7298434972763062,
                0.7659713625907898,
                0.7837416529655457,
                0.8110470175743103,
                0.7889710664749146,
                0.8869779109954834,
                0.8147355318069458,
                0.8748561143875122,
                0.8462020754814148,
                0.843108057975769,
                0.8687732219696045,
                0.8448501825332642,
                0.767888605594635,
                0.8387206792831421,
                0.6845756769180298,
                0.8462527990341187,
                0.8284991979598999,
                0.8435136079788208,
                0.7732305526733398,
                0.8146288394927979,
                0.7912464141845703,
                0.8451964855194092,
                0.8439323902130127,
                0.8364757895469666,
                0.8347123265266418,
                0.8354188799858093,
                0.805394172668457,
                0.8415579795837402,
                0.8114802837371826,
                0.8469212651252747,
                0.8558989763259888,
                0.8413610458374023,
                0.7614980936050415,
                0.7621817588806152,
                0.621377170085907,
                0.6376605033874512,
                0.8552334308624268,
                0.8224749565124512,
                0.850155234336853,
                0.6406780481338501,
                0.8397631049156189,
                0.8549309372901917,
                0.666968584060669,
                0.8450430035591125,
                0.8657261729240417,
                0.5713477730751038,
                0.862453281879425,
                0.8579713106155396,
                0.6296395063400269
            ],
            [
                0.7846173644065857,
                0.7077703475952148,
                0.7598837614059448,
                0.7439213991165161,
                0.7568831443786621,
                0.8059738278388977,
                0.7452800869941711,
                0.8483864068984985,
                0.7955251932144165,
                0.8726845979690552,
                0.8365429043769836,
                0.8337727785110474,
                0.8151792287826538,
                0.8316609263420105,
                0.7627018094062805,
                0.8291231989860535,
                0.7123696208000183,
                0.8398681879043579,
                0.8065075278282166,
                0.8133780360221863,
                0.7468394041061401,
                0.7718825340270996,
                0.7527831792831421,
                0.8361696004867554,
                0.8121501207351685,
                0.8373343348503113,
                0.852857768535614,
                0.8348287343978882,
                0.7584037780761719,
                0.8141555786132812,
                0.7627373933792114,
                0.8209503889083862,
                0.820365309715271,
                0.8171691298484802,
                0.8116030693054199,
                0.817605197429657,
                0.6018454432487488,
                0.6388310194015503,
                0.8269496560096741,
                0.8527966737747192,
                0.851762056350708,
                0.6833223700523376,
                0.8018524050712585,
                0.8241652846336365,
                0.6795550584793091,
                0.8276617527008057,
                0.8266615271568298,
                0.6013423204421997,
                0.8262373805046082,
                0.8310340642929077,
                0.6659746766090393
            ],
            [
                0.7746328711509705,
                0.7299543023109436,
                0.786978542804718,
                0.7512682676315308,
                0.7900872230529785,
                0.7851656675338745,
                0.7900243401527405,
                0.8212382197380066,
                0.7845937013626099,
                0.8630098700523376,
                0.8593268990516663,
                0.8211871385574341,
                0.8535768985748291,
                0.8431223034858704,
                0.7912393808364868,
                0.8287814259529114,
                0.7334628105163574,
                0.8393923044204712,
                0.83979332447052,
                0.8028914928436279,
                0.7489371299743652,
                0.7508189678192139,
                0.7841665744781494,
                0.8236141800880432,
                0.7933846116065979,
                0.8353500366210938,
                0.8547979593276978,
                0.8314211368560791,
                0.7394688725471497,
                0.8132015466690063,
                0.7255266904830933,
                0.8218761682510376,
                0.8199777603149414,
                0.8110843896865845,
                0.8183032274246216,
                0.8200224041938782,
                0.572162389755249,
                0.6793618202209473,
                0.8229578137397766,
                0.8777248859405518,
                0.841399073600769,
                0.6858198642730713,
                0.7865735292434692,
                0.8164211511611938,
                0.6775555610656738,
                0.8046581745147705,
                0.8088400363922119,
                0.6165103316307068,
                0.8098544478416443,
                0.8243277072906494,
                0.6896070837974548
            ],
            [
                0.8361095786094666,
                0.813569962978363,
                0.7642361521720886,
                0.7928649187088013,
                0.8087525963783264,
                0.8131440281867981,
                0.7956640124320984,
                0.8600683808326721,
                0.7849929332733154,
                0.8560446500778198,
                0.8365464806556702,
                0.8254551887512207,
                0.8576107621192932,
                0.8494469523429871,
                0.7745223045349121,
                0.8440611362457275,
                0.6854684948921204,
                0.8308727741241455,
                0.8279208540916443,
                0.8395341634750366,
                0.76664799451828,
                0.7964155673980713,
                0.8228929042816162,
                0.8258538842201233,
                0.8264392614364624,
                0.8243281841278076,
                0.8272464871406555,
                0.8362677693367004,
                0.7821672558784485,
                0.824770450592041,
                0.7806268334388733,
                0.8300021886825562,
                0.8402823209762573,
                0.8234138488769531,
                0.7772197723388672,
                0.7805882692337036,
                0.6097783446311951,
                0.6863452792167664,
                0.8460289835929871,
                0.8364374041557312,
                0.849317729473114,
                0.6834211349487305,
                0.8193854689598083,
                0.8380227088928223,
                0.661761999130249,
                0.8277173638343811,
                0.8445801734924316,
                0.619624674320221,
                0.8462197184562683,
                0.8469853401184082,
                0.6687586307525635
            ],
            [
                0.7681142687797546,
                0.7082960605621338,
                0.7257495522499084,
                0.7484222650527954,
                0.7730621099472046,
                0.7963235974311829,
                0.7405112385749817,
                0.8520459532737732,
                0.8070831894874573,
                0.8856381177902222,
                0.8132765889167786,
                0.826901376247406,
                0.8143067955970764,
                0.8348146080970764,
                0.7731446623802185,
                0.8552007675170898,
                0.6997060179710388,
                0.8425885438919067,
                0.7915904521942139,
                0.8184503316879272,
                0.7330299019813538,
                0.777080237865448,
                0.7633034586906433,
                0.8243709802627563,
                0.8216701149940491,
                0.8561511635780334,
                0.8527849912643433,
                0.8230529427528381,
                0.7575978636741638,
                0.8267675638198853,
                0.764024019241333,
                0.828692615032196,
                0.8317404389381409,
                0.8185201287269592,
                0.8211709856987,
                0.8141164779663086,
                0.6126384735107422,
                0.6836837530136108,
                0.8384119272232056,
                0.8559328317642212,
                0.8421225547790527,
                0.6750540733337402,
                0.8129959106445312,
                0.8390203714370728,
                0.6746872067451477,
                0.819398820400238,
                0.8376267552375793,
                0.6169939637184143,
                0.8288183212280273,
                0.8403733968734741,
                0.6827796101570129
            ],
            [
                0.7702069282531738,
                0.7159311771392822,
                0.7034773230552673,
                0.724006175994873,
                0.7826926708221436,
                0.7391561269760132,
                0.7148037552833557,
                0.7905436754226685,
                0.7894726395606995,
                0.827809751033783,
                0.7833060622215271,
                0.7813901901245117,
                0.7897638082504272,
                0.7765336632728577,
                0.7782765626907349,
                0.8026697635650635,
                0.6478793621063232,
                0.7875658273696899,
                0.7757718563079834,
                0.7533565163612366,
                0.7173929214477539,
                0.7045700550079346,
                0.7842441201210022,
                0.777047872543335,
                0.7592829465866089,
                0.8008034229278564,
                0.7887741923332214,
                0.7672523260116577,
                0.6776878833770752,
                0.7890603542327881,
                0.6939882040023804,
                0.7570117712020874,
                0.7697024941444397,
                0.7508358955383301,
                0.801425576210022,
                0.7871304750442505,
                0.585314929485321,
                0.7271285057067871,
                0.7677597999572754,
                0.8330298662185669,
                0.7766660451889038,
                0.671640932559967,
                0.7409139275550842,
                0.7749356031417847,
                0.6332147717475891,
                0.7540284991264343,
                0.7703047394752502,
                0.6277733445167542,
                0.757158100605011,
                0.778626024723053,
                0.6930719017982483
            ],
            [
                0.8494771122932434,
                0.8299930095672607,
                0.7787672877311707,
                0.79859459400177,
                0.7953598499298096,
                0.8284929394721985,
                0.8163654804229736,
                0.8804393410682678,
                0.8165503144264221,
                0.8723618388175964,
                0.8450374007225037,
                0.8337488174438477,
                0.867430567741394,
                0.8650084137916565,
                0.7862200736999512,
                0.859184741973877,
                0.7155402898788452,
                0.8496984839439392,
                0.8366179466247559,
                0.8498228788375854,
                0.7805370688438416,
                0.8131885528564453,
                0.8208400011062622,
                0.835578978061676,
                0.8419102430343628,
                0.8465467095375061,
                0.8555286526679993,
                0.8642131686210632,
                0.8010567426681519,
                0.8245652318000793,
                0.7955204844474792,
                0.8440532088279724,
                0.8528704047203064,
                0.8369908332824707,
                0.7918850183486938,
                0.8013535737991333,
                0.6232377290725708,
                0.678390622138977,
                0.8601153492927551,
                0.843386173248291,
                0.8635194897651672,
                0.7029717564582825,
                0.8442602753639221,
                0.8528026938438416,
                0.6919286251068115,
                0.8536292910575867,
                0.8597016334533691,
                0.6227378845214844,
                0.8670492172241211,
                0.85878586769104,
                0.685086727142334
            ],
            [
                0.7636322379112244,
                0.8046122193336487,
                0.6889530420303345,
                0.752943754196167,
                0.7661944627761841,
                0.7423237562179565,
                0.8167092800140381,
                0.8494006991386414,
                0.8345679044723511,
                0.8233814239501953,
                0.7643741369247437,
                0.7636906504631042,
                0.7991654276847839,
                0.777209460735321,
                0.7703122496604919,
                0.8086928129196167,
                0.7248605489730835,
                0.7891800403594971,
                0.7713897824287415,
                0.7754175662994385,
                0.7268049120903015,
                0.74506676197052,
                0.7728731632232666,
                0.7688524723052979,
                0.7837187647819519,
                0.8162563443183899,
                0.8042160868644714,
                0.8022156953811646,
                0.73590087890625,
                0.735232949256897,
                0.725212037563324,
                0.7977138757705688,
                0.7918418645858765,
                0.7946459650993347,
                0.7341246604919434,
                0.742603063583374,
                0.6164230704307556,
                0.6329907178878784,
                0.773152232170105,
                0.7726054191589355,
                0.7912729978561401,
                0.6169726848602295,
                0.7571015357971191,
                0.7885745763778687,
                0.7272946834564209,
                0.8132021427154541,
                0.811359167098999,
                0.575946569442749,
                0.8227120637893677,
                0.7900874018669128,
                0.6474921703338623
            ],
            [
                0.8110767006874084,
                0.7918480038642883,
                0.65868079662323,
                0.7376639246940613,
                0.7539312243461609,
                0.7849941849708557,
                0.738165020942688,
                0.879891574382782,
                0.832916259765625,
                0.8565208911895752,
                0.7823922634124756,
                0.8133891224861145,
                0.8112258315086365,
                0.8187165856361389,
                0.7454013228416443,
                0.8335622549057007,
                0.6534278392791748,
                0.8153876662254333,
                0.7739178538322449,
                0.829537034034729,
                0.7300404906272888,
                0.8081372976303101,
                0.7500861883163452,
                0.8137412667274475,
                0.8333627581596375,
                0.8153514862060547,
                0.7946746349334717,
                0.8035843372344971,
                0.7957039475440979,
                0.8266050815582275,
                0.8044673204421997,
                0.8222739100456238,
                0.8266975283622742,
                0.8256714344024658,
                0.7373411059379578,
                0.7135794162750244,
                0.6026859283447266,
                0.6425862312316895,
                0.8123295903205872,
                0.7592035531997681,
                0.8039416074752808,
                0.6288607120513916,
                0.8062984347343445,
                0.8341158032417297,
                0.6514914631843567,
                0.8170230984687805,
                0.8437726497650146,
                0.5541584491729736,
                0.8191218376159668,
                0.8288814425468445,
                0.628105640411377
            ],
            [
                0.7464852333068848,
                0.7499339580535889,
                0.6633862853050232,
                0.7124856114387512,
                0.7437466382980347,
                0.714471161365509,
                0.7429821491241455,
                0.8193777203559875,
                0.8229031562805176,
                0.8173550367355347,
                0.743718147277832,
                0.7633318305015564,
                0.7634604573249817,
                0.7501404881477356,
                0.7468401789665222,
                0.7811893224716187,
                0.6869847774505615,
                0.7882208824157715,
                0.7493757605552673,
                0.762266218662262,
                0.7178186774253845,
                0.7143263816833496,
                0.7381829023361206,
                0.7621999382972717,
                0.7680256366729736,
                0.7959975600242615,
                0.7663803696632385,
                0.776506245136261,
                0.6927639245986938,
                0.7263205051422119,
                0.7041024565696716,
                0.7705382704734802,
                0.7685718536376953,
                0.7772641777992249,
                0.7430915236473083,
                0.7336743474006653,
                0.6005060076713562,
                0.6451380848884583,
                0.7529111504554749,
                0.7466425895690918,
                0.7580486536026001,
                0.6346983909606934,
                0.7414597272872925,
                0.7678138017654419,
                0.7045782804489136,
                0.781990647315979,
                0.7874705791473389,
                0.605022132396698,
                0.786827802658081,
                0.7685353755950928,
                0.6594249606132507
            ],
            [
                0.7721893787384033,
                0.8210784196853638,
                0.643539309501648,
                0.7268469929695129,
                0.728517472743988,
                0.7947903871536255,
                0.7453612685203552,
                0.8978577256202698,
                0.8180984258651733,
                0.8463046550750732,
                0.8156354427337646,
                0.8354610204696655,
                0.8327434659004211,
                0.8068827986717224,
                0.7397211790084839,
                0.8230217695236206,
                0.6744601726531982,
                0.8077883124351501,
                0.7872135639190674,
                0.837119460105896,
                0.7395570278167725,
                0.8330369591712952,
                0.7422333359718323,
                0.8389445543289185,
                0.8528903126716614,
                0.8186916708946228,
                0.7915416359901428,
                0.7998843193054199,
                0.827751874923706,
                0.7875593304634094,
                0.8412335515022278,
                0.833672285079956,
                0.8425836563110352,
                0.8386349678039551,
                0.6895028352737427,
                0.6741511821746826,
                0.6142202019691467,
                0.5791714191436768,
                0.8242751955986023,
                0.7441644072532654,
                0.8154523372650146,
                0.5628492832183838,
                0.8160073161125183,
                0.8327540159225464,
                0.6625811457633972,
                0.8303354978561401,
                0.8594741821289062,
                0.5062050223350525,
                0.8370653390884399,
                0.8247284889221191,
                0.5591323375701904
            ],
            [
                0.7707990407943726,
                0.7242602705955505,
                0.6511756777763367,
                0.7648895382881165,
                0.6886854767799377,
                0.8570715188980103,
                0.7110652923583984,
                0.9382790923118591,
                0.7505449056625366,
                0.9127973914146423,
                0.8112354874610901,
                0.9185267090797424,
                0.789889931678772,
                0.8768078088760376,
                0.690630316734314,
                0.8736371994018555,
                0.6596565842628479,
                0.865892767906189,
                0.7652714848518372,
                0.9097891449928284,
                0.6903934478759766,
                0.9012828469276428,
                0.6906555891036987,
                0.9229065775871277,
                0.9243651628494263,
                0.8704273700714111,
                0.8571281433105469,
                0.8707563281059265,
                0.8929939866065979,
                0.797385573387146,
                0.8972735404968262,
                0.9009177684783936,
                0.9069520831108093,
                0.9011155962944031,
                0.7221224904060364,
                0.723035991191864,
                0.610596776008606,
                0.5381293296813965,
                0.9018415212631226,
                0.7536383271217346,
                0.8963254690170288,
                0.610249400138855,
                0.8844663500785828,
                0.9129215478897095,
                0.6150228977203369,
                0.8908863067626953,
                0.9280030131340027,
                0.48657846450805664,
                0.8877465128898621,
                0.9083696603775024,
                0.5730189085006714
            ],
            [
                0.8124582767486572,
                0.7147992849349976,
                0.7556341886520386,
                0.7619115114212036,
                0.724618136882782,
                0.8376087546348572,
                0.7355438470840454,
                0.8257269263267517,
                0.7627047300338745,
                0.8593923449516296,
                0.7648555040359497,
                0.8188567161560059,
                0.7847221493721008,
                0.8480584621429443,
                0.7373613715171814,
                0.8540279269218445,
                0.6768932342529297,
                0.8377681970596313,
                0.7486354112625122,
                0.8447452187538147,
                0.7076480984687805,
                0.7982797622680664,
                0.7448117733001709,
                0.8158103227615356,
                0.8232612609863281,
                0.8409371376037598,
                0.8499102592468262,
                0.8437168598175049,
                0.7872766852378845,
                0.8076199293136597,
                0.7671852707862854,
                0.8255413770675659,
                0.832984447479248,
                0.8192516565322876,
                0.8032667636871338,
                0.8123195767402649,
                0.6372440457344055,
                0.6650758981704712,
                0.8223980069160461,
                0.7818109393119812,
                0.8295443654060364,
                0.7039064168930054,
                0.8076121211051941,
                0.8378763198852539,
                0.6391286253929138,
                0.8401548862457275,
                0.8277102708816528,
                0.5918883085250854,
                0.8146423697471619,
                0.8436081409454346,
                0.6737769246101379
            ],
            [
                0.7365538477897644,
                0.765805184841156,
                0.6704287528991699,
                0.7400637269020081,
                0.7729583978652954,
                0.7490537762641907,
                0.7357839345932007,
                0.8043844103813171,
                0.8285681009292603,
                0.7881650924682617,
                0.760090172290802,
                0.7699958086013794,
                0.7906253933906555,
                0.7561116814613342,
                0.7719495892524719,
                0.7963239550590515,
                0.7038138508796692,
                0.8079817891120911,
                0.7701176404953003,
                0.7852235436439514,
                0.7049590945243835,
                0.7390847206115723,
                0.7455451488494873,
                0.7677972912788391,
                0.7966780066490173,
                0.8333309292793274,
                0.7677242755889893,
                0.7497773766517639,
                0.7335396409034729,
                0.7434172034263611,
                0.740327000617981,
                0.7828277349472046,
                0.8083803057670593,
                0.8149967789649963,
                0.7329722046852112,
                0.724668562412262,
                0.6294773817062378,
                0.6400335431098938,
                0.7526256442070007,
                0.75380939245224,
                0.7761536240577698,
                0.5925903916358948,
                0.7282764315605164,
                0.7838922142982483,
                0.6876357793807983,
                0.7722932696342468,
                0.7946749925613403,
                0.5649375319480896,
                0.7757135629653931,
                0.7803034782409668,
                0.599689781665802
            ],
            [
                0.740797758102417,
                0.8438020944595337,
                0.6226022839546204,
                0.6916031241416931,
                0.7097399234771729,
                0.7267942428588867,
                0.7549101710319519,
                0.8361943960189819,
                0.8240561485290527,
                0.8096930980682373,
                0.7956337928771973,
                0.7819400429725647,
                0.8166390657424927,
                0.7629774212837219,
                0.7530463337898254,
                0.7995995879173279,
                0.684300422668457,
                0.7837243676185608,
                0.7858189344406128,
                0.7810128927230835,
                0.7222881317138672,
                0.7802459001541138,
                0.7207608222961426,
                0.7816279530525208,
                0.7949482202529907,
                0.8061671257019043,
                0.7835217714309692,
                0.7520939707756042,
                0.7723705172538757,
                0.7521577477455139,
                0.7677070498466492,
                0.7903736233711243,
                0.8102787733078003,
                0.7972900867462158,
                0.6733377575874329,
                0.6599879860877991,
                0.5702661275863647,
                0.56472247838974,
                0.771548330783844,
                0.7408536672592163,
                0.7718359231948853,
                0.523521900177002,
                0.7687032222747803,
                0.7798649072647095,
                0.6398389935493469,
                0.7821732759475708,
                0.8033784627914429,
                0.48062536120414734,
                0.7937160730361938,
                0.7732141613960266,
                0.5426009297370911
            ],
            [
                0.7465261816978455,
                0.7359168529510498,
                0.6566808223724365,
                0.7054367661476135,
                0.7333883047103882,
                0.7199349999427795,
                0.6909453272819519,
                0.7954998016357422,
                0.8302061557769775,
                0.8116831183433533,
                0.7550871968269348,
                0.7591661810874939,
                0.7662075757980347,
                0.7536852955818176,
                0.7625983953475952,
                0.8068161606788635,
                0.6498451232910156,
                0.7658665776252747,
                0.7469191551208496,
                0.7416812777519226,
                0.7120152711868286,
                0.7033506035804749,
                0.7363283038139343,
                0.7524932026863098,
                0.754995584487915,
                0.7956480383872986,
                0.768787682056427,
                0.7351573705673218,
                0.6783936619758606,
                0.7462624907493591,
                0.695543110370636,
                0.7382886409759521,
                0.7529038786888123,
                0.7466346621513367,
                0.7555976510047913,
                0.7343726754188538,
                0.5728092193603516,
                0.6653470396995544,
                0.7307479977607727,
                0.7636333703994751,
                0.7577322721481323,
                0.5895874500274658,
                0.7226276397705078,
                0.7469989657402039,
                0.6420152187347412,
                0.765571117401123,
                0.7614609599113464,
                0.5396612286567688,
                0.7507078647613525,
                0.7466240525245667,
                0.6116864085197449
            ],
            [
                0.7389594316482544,
                0.7924667000770569,
                0.5968857407569885,
                0.704502284526825,
                0.674910843372345,
                0.7892098426818848,
                0.7244744896888733,
                0.889987587928772,
                0.7896156311035156,
                0.844078004360199,
                0.7753424048423767,
                0.8121668696403503,
                0.7946553230285645,
                0.8093773722648621,
                0.7281386256217957,
                0.8280924558639526,
                0.6895197629928589,
                0.8167060017585754,
                0.7638238668441772,
                0.83091801404953,
                0.6861112713813782,
                0.8417514562606812,
                0.7046148777008057,
                0.8174833059310913,
                0.8545821905136108,
                0.832751452922821,
                0.8205957412719727,
                0.8063067197799683,
                0.8437630534172058,
                0.7675884366035461,
                0.8299233317375183,
                0.8492193222045898,
                0.8454117774963379,
                0.8449456095695496,
                0.66852205991745,
                0.6609823703765869,
                0.6319512724876404,
                0.5186781287193298,
                0.8163391351699829,
                0.7251014113426208,
                0.797965407371521,
                0.539745569229126,
                0.8052598237991333,
                0.8354586362838745,
                0.6216235160827637,
                0.8240643739700317,
                0.857531726360321,
                0.46091195940971375,
                0.8266249299049377,
                0.8269881010055542,
                0.5394420027732849
            ],
            [
                0.7641009092330933,
                0.7694910168647766,
                0.6593153476715088,
                0.7185072302818298,
                0.767076313495636,
                0.7441144585609436,
                0.724502444267273,
                0.8223400712013245,
                0.8122797012329102,
                0.7991770505905151,
                0.7689010500907898,
                0.7783821225166321,
                0.7891069650650024,
                0.7593926787376404,
                0.7459765076637268,
                0.7709676027297974,
                0.6673280596733093,
                0.782981812953949,
                0.76231849193573,
                0.7643444538116455,
                0.7364181876182556,
                0.725468635559082,
                0.7451286911964417,
                0.7801014184951782,
                0.7766886949539185,
                0.7820136547088623,
                0.756399929523468,
                0.7678125500679016,
                0.7123960852622986,
                0.7425566911697388,
                0.728172779083252,
                0.76551753282547,
                0.7719588279724121,
                0.777276337146759,
                0.7324614524841309,
                0.7107977271080017,
                0.6166578531265259,
                0.6255905032157898,
                0.7483914494514465,
                0.7557191848754883,
                0.7679899334907532,
                0.5898475050926208,
                0.7339997887611389,
                0.7700420618057251,
                0.7022601962089539,
                0.7800853848457336,
                0.7904900908470154,
                0.5641809105873108,
                0.7786551713943481,
                0.7692145109176636,
                0.6127078533172607
            ],
            [
                0.7848387360572815,
                0.7427060008049011,
                0.7035679221153259,
                0.7314326167106628,
                0.7767220735549927,
                0.7273357510566711,
                0.7189642190933228,
                0.7884575128555298,
                0.805417537689209,
                0.7882238626480103,
                0.7748008370399475,
                0.7357614040374756,
                0.7891038656234741,
                0.7702652215957642,
                0.7492318749427795,
                0.775100588798523,
                0.6486077308654785,
                0.7680003643035889,
                0.7565892338752747,
                0.7270504832267761,
                0.7525084614753723,
                0.6808964610099792,
                0.7709342241287231,
                0.7370035648345947,
                0.739720344543457,
                0.7628877758979797,
                0.741873562335968,
                0.7438104152679443,
                0.6643102765083313,
                0.7597046494483948,
                0.6864956021308899,
                0.7291598916053772,
                0.7292559146881104,
                0.7274967432022095,
                0.7622489333152771,
                0.7456127405166626,
                0.5624238848686218,
                0.6653653979301453,
                0.7355818748474121,
                0.779628336429596,
                0.7656228542327881,
                0.6392854452133179,
                0.7436736822128296,
                0.7442132234573364,
                0.6995540261268616,
                0.7746213674545288,
                0.7623045444488525,
                0.5932816863059998,
                0.7710751295089722,
                0.7470434308052063,
                0.6539135575294495
            ],
            [
                0.704188883304596,
                0.73771733045578,
                0.5662843585014343,
                0.6308392882347107,
                0.6829111576080322,
                0.6886245012283325,
                0.6585491895675659,
                0.7969274520874023,
                0.7884942889213562,
                0.7786957621574402,
                0.7211374044418335,
                0.7405002117156982,
                0.7649229764938354,
                0.7486332654953003,
                0.7114218473434448,
                0.7627882957458496,
                0.5666171312332153,
                0.7683534622192383,
                0.7133166193962097,
                0.7391555309295654,
                0.6889726519584656,
                0.7450229525566101,
                0.6921184659004211,
                0.7399890422821045,
                0.7625828981399536,
                0.752461850643158,
                0.7091270685195923,
                0.7013498544692993,
                0.7404876351356506,
                0.785834014415741,
                0.7365764379501343,
                0.7473465800285339,
                0.7481879591941833,
                0.7469608187675476,
                0.6651653051376343,
                0.6192236542701721,
                0.5432843565940857,
                0.585832953453064,
                0.7264711856842041,
                0.6998044848442078,
                0.6998435258865356,
                0.5153561234474182,
                0.7248969078063965,
                0.7506079077720642,
                0.5815101265907288,
                0.7129185199737549,
                0.7577305436134338,
                0.49100160598754883,
                0.7294923663139343,
                0.7431151866912842,
                0.5593823790550232
            ],
            [
                0.7679988741874695,
                0.822169840335846,
                0.6360451579093933,
                0.7120225429534912,
                0.7356993556022644,
                0.7944613099098206,
                0.7566328644752502,
                0.8667073249816895,
                0.7764778137207031,
                0.8328914642333984,
                0.8042259812355042,
                0.8065828680992126,
                0.8311653733253479,
                0.7993753552436829,
                0.7544623613357544,
                0.8068608045578003,
                0.6931155323982239,
                0.8135753273963928,
                0.7859572172164917,
                0.817389726638794,
                0.7264447808265686,
                0.8125561475753784,
                0.7438366413116455,
                0.809238851070404,
                0.8306901454925537,
                0.815540075302124,
                0.7999104857444763,
                0.7934577465057373,
                0.8088027238845825,
                0.7717908620834351,
                0.8081884384155273,
                0.8296066522598267,
                0.8296526670455933,
                0.8229411840438843,
                0.6967113614082336,
                0.6897811889648438,
                0.6418710350990295,
                0.5572709441184998,
                0.8088976144790649,
                0.7538802027702332,
                0.7919522523880005,
                0.5591878294944763,
                0.7876167893409729,
                0.824203610420227,
                0.6321908831596375,
                0.8159347176551819,
                0.8423553109169006,
                0.49692872166633606,
                0.8151848316192627,
                0.819429337978363,
                0.5767948031425476
            ],
            [
                0.7901620864868164,
                0.7397173643112183,
                0.7634359002113342,
                0.7561323642730713,
                0.8045122623443604,
                0.7731373906135559,
                0.7484148740768433,
                0.8038719892501831,
                0.7796787619590759,
                0.840354859828949,
                0.7976825833320618,
                0.7984288334846497,
                0.8077391982078552,
                0.8068282604217529,
                0.7795599102973938,
                0.816474437713623,
                0.6840118169784546,
                0.8127319812774658,
                0.7958537936210632,
                0.785727858543396,
                0.7360649108886719,
                0.7272353768348694,
                0.7788127064704895,
                0.7954797744750977,
                0.7715281248092651,
                0.8150627017021179,
                0.8203684091567993,
                0.8078378438949585,
                0.7052206993103027,
                0.8024667501449585,
                0.710091769695282,
                0.7825406789779663,
                0.794069230556488,
                0.781244158744812,
                0.826360821723938,
                0.8257628083229065,
                0.5997343063354492,
                0.7131471037864685,
                0.7914683222770691,
                0.8332460522651672,
                0.8121511340141296,
                0.7047877907752991,
                0.7666581273078918,
                0.7934547066688538,
                0.6643070578575134,
                0.7959985733032227,
                0.7895845174789429,
                0.6251907348632812,
                0.7916861772537231,
                0.8009132146835327,
                0.7056344747543335
            ],
            [
                0.8333848714828491,
                0.8283578157424927,
                0.7420875430107117,
                0.7956395745277405,
                0.7792630195617676,
                0.8258566856384277,
                0.7968630790710449,
                0.9030361175537109,
                0.8281374573707581,
                0.8758173584938049,
                0.8530731201171875,
                0.8651845455169678,
                0.867721438407898,
                0.8508638143539429,
                0.7732280492782593,
                0.8584446310997009,
                0.703077495098114,
                0.8496782183647156,
                0.8151835799217224,
                0.8589404225349426,
                0.7668505907058716,
                0.8414466381072998,
                0.8018996119499207,
                0.865646243095398,
                0.8646824955940247,
                0.8519082069396973,
                0.833717942237854,
                0.8454639315605164,
                0.8260021805763245,
                0.816273033618927,
                0.8276759386062622,
                0.839884340763092,
                0.8672100305557251,
                0.8503139019012451,
                0.7476462125778198,
                0.7572391033172607,
                0.6023061275482178,
                0.6487353444099426,
                0.8601906299591064,
                0.8066856265068054,
                0.8627174496650696,
                0.631194531917572,
                0.8380326628684998,
                0.85783451795578,
                0.6618735790252686,
                0.8622363805770874,
                0.8759419918060303,
                0.5565515756607056,
                0.867118239402771,
                0.8618063926696777,
                0.6117634177207947
            ],
            [
                0.7809657454490662,
                0.7231264710426331,
                0.6940809488296509,
                0.6837334632873535,
                0.7932578921318054,
                0.7333332300186157,
                0.7074937224388123,
                0.776318371295929,
                0.7632153034210205,
                0.7953927516937256,
                0.7843196392059326,
                0.7694332599639893,
                0.7910043597221375,
                0.7509767413139343,
                0.7546321749687195,
                0.7569296956062317,
                0.642801821231842,
                0.7604374289512634,
                0.7825978994369507,
                0.7493118643760681,
                0.7434607744216919,
                0.6896958351135254,
                0.7776181101799011,
                0.7661031484603882,
                0.742807149887085,
                0.7540645003318787,
                0.7461574673652649,
                0.7390612363815308,
                0.6680886745452881,
                0.7677444219589233,
                0.691673994064331,
                0.7427246570587158,
                0.7569766044616699,
                0.7409864068031311,
                0.7849181890487671,
                0.755679726600647,
                0.5723344087600708,
                0.7300819158554077,
                0.7488098740577698,
                0.8167541027069092,
                0.7598835229873657,
                0.6558127403259277,
                0.7132598757743835,
                0.7590116858482361,
                0.6432457566261292,
                0.7386306524276733,
                0.7577593326568604,
                0.638266921043396,
                0.7337127923965454,
                0.7644602656364441,
                0.6889778971672058
            ]
        ],
        [
            [
                0.7027179598808289,
                0.8866347670555115,
                0.8463453054428101,
                0.8977283835411072,
                0.7400856018066406,
                0.6903068423271179,
                0.9388555884361267,
                0.7358633279800415,
                0.908610463142395,
                0.5990200638771057,
                0.7051252126693726,
                0.37886929512023926,
                0.6890064477920532,
                0.37886929512023926,
                0.5990200638771057,
                0.574349582195282,
                0.7563839554786682,
                0.4877818822860718,
                0.6512254476547241,
                0.5452587008476257,
                0.7828307151794434,
                0.8148682713508606,
                0.7849171161651611,
                0.874417781829834,
                0.8835901021957397,
                0.7224861979484558,
                0.8791034817695618,
                0.743272602558136,
                0.8907731771469116,
                0.8017096519470215,
                0.8489105105400085,
                0.7323959469795227,
                0.8223942518234253,
                0.7376119494438171,
                0.6149182319641113,
                0.6612019538879395,
                0.6782760620117188,
                0.6501026153564453,
                0.8456388115882874,
                0.5376529693603516,
                0.7420357465744019,
                0.6640072464942932,
                0.6640072464942932,
                0.8689637184143066,
                0.6311156749725342,
                0.8125038743019104,
                0.7523230314254761,
                0.8127082586288452,
                0.6900100111961365,
                0.5704787373542786,
                0.7483689785003662
            ],
            [
                0.6983017325401306,
                0.8045613765716553,
                0.8176796436309814,
                0.7635763883590698,
                0.7551326751708984,
                0.7076228260993958,
                0.7189912796020508,
                0.7930038571357727,
                0.784089207649231,
                0.6041855216026306,
                0.747485339641571,
                0.37411752343177795,
                0.6786013245582581,
                0.37411752343177795,
                0.6041855216026306,
                0.5426549911499023,
                0.7374846339225769,
                0.45535436272621155,
                0.6550881266593933,
                0.4918816089630127,
                0.7200950384140015,
                0.696286141872406,
                0.8263384103775024,
                0.8261047601699829,
                0.8124032616615295,
                0.8013512492179871,
                0.7821030020713806,
                0.7381056547164917,
                0.6876260042190552,
                0.8294116258621216,
                0.7709673643112183,
                0.7267810106277466,
                0.8197556138038635,
                0.7075985670089722,
                0.5795509815216064,
                0.6226686835289001,
                0.63965904712677,
                0.6187359094619751,
                0.7205601334571838,
                0.5651556253433228,
                0.8150039911270142,
                0.6314141750335693,
                0.6314141750335693,
                0.754629909992218,
                0.6288217902183533,
                0.7112058997154236,
                0.8701903820037842,
                0.724280595779419,
                0.6615333557128906,
                0.5871043801307678,
                0.825960099697113
            ],
            [
                0.7899602651596069,
                0.9006907939910889,
                0.8927565217018127,
                0.8662992119789124,
                0.7643376588821411,
                0.7341498136520386,
                0.8616135716438293,
                0.8028964400291443,
                0.8872123956680298,
                0.6279313564300537,
                0.7539107799530029,
                0.3760254681110382,
                0.7203257083892822,
                0.3760254681110382,
                0.6279313564300537,
                0.5933603048324585,
                0.791851282119751,
                0.5168343782424927,
                0.6798403263092041,
                0.5321582555770874,
                0.7916382551193237,
                0.8070791959762573,
                0.831438422203064,
                0.9130963683128357,
                0.8814358115196228,
                0.8157615661621094,
                0.9027249217033386,
                0.7974975109100342,
                0.8245460987091064,
                0.8470321893692017,
                0.8292176127433777,
                0.7723593711853027,
                0.8374348282814026,
                0.7565622925758362,
                0.6506442427635193,
                0.6777696013450623,
                0.6980672478675842,
                0.6671989560127258,
                0.8196330070495605,
                0.5874969959259033,
                0.7989946007728577,
                0.7181059122085571,
                0.7181059122085571,
                0.8298690915107727,
                0.6807053089141846,
                0.8464081287384033,
                0.8319181799888611,
                0.8290512561798096,
                0.7088897824287415,
                0.6211783289909363,
                0.8171014785766602
            ],
            [
                0.7625471353530884,
                0.8693349361419678,
                0.8761084675788879,
                0.8276006579399109,
                0.887017011642456,
                0.772311806678772,
                0.7620306015014648,
                0.8425163626670837,
                0.818571925163269,
                0.5671497583389282,
                0.7735264897346497,
                0.36616015434265137,
                0.7735263109207153,
                0.36616015434265137,
                0.5671497583389282,
                0.595277726650238,
                0.7861777544021606,
                0.44151052832603455,
                0.6308732032775879,
                0.5141262412071228,
                0.767300009727478,
                0.7201147675514221,
                0.8343210220336914,
                0.8836184740066528,
                0.8606040477752686,
                0.8622499704360962,
                0.8435115814208984,
                0.8071707487106323,
                0.7274704575538635,
                0.8806958198547363,
                0.8091652989387512,
                0.8149237632751465,
                0.8719031810760498,
                0.7414723038673401,
                0.5985967516899109,
                0.7068353295326233,
                0.7148579955101013,
                0.6514797210693359,
                0.797553300857544,
                0.6031227111816406,
                0.8773815631866455,
                0.7111542224884033,
                0.7111542224884033,
                0.7702355980873108,
                0.6613591313362122,
                0.8106651306152344,
                0.9110706448554993,
                0.7876256704330444,
                0.7651052474975586,
                0.6208981275558472,
                0.8512201309204102
            ],
            [
                0.7931764721870422,
                0.8154579401016235,
                0.8400382399559021,
                0.8367649912834167,
                0.9406383037567139,
                0.8976326584815979,
                0.7334262132644653,
                0.8939894437789917,
                0.7515308260917664,
                0.6325823664665222,
                0.875469446182251,
                0.4443631172180176,
                0.9062266945838928,
                0.4443631172180176,
                0.6325823664665222,
                0.6439037919044495,
                0.8777872323989868,
                0.5735072493553162,
                0.6777648329734802,
                0.6710231304168701,
                0.8089519143104553,
                0.7080407738685608,
                0.8690603971481323,
                0.8462041616439819,
                0.8618186712265015,
                0.8738720417022705,
                0.8133174180984497,
                0.8695880770683289,
                0.7008170485496521,
                0.910881519317627,
                0.8371250629425049,
                0.9134631752967834,
                0.9291728734970093,
                0.8433162569999695,
                0.6967945694923401,
                0.8058137893676758,
                0.8172003626823425,
                0.7550198435783386,
                0.8353775143623352,
                0.7148810029029846,
                0.9180682897567749,
                0.7948357462882996,
                0.7948357462882996,
                0.819172739982605,
                0.7146081328392029,
                0.7846482396125793,
                0.8783807158470154,
                0.8329975605010986,
                0.9070096015930176,
                0.712530791759491,
                0.850071370601654
            ],
            [
                0.827039361000061,
                0.8577015399932861,
                0.8802059888839722,
                0.8155519366264343,
                0.86353600025177,
                0.8449321985244751,
                0.7475957274436951,
                0.9502137303352356,
                0.8212485313415527,
                0.6958572268486023,
                0.8768551349639893,
                0.4096367061138153,
                0.840991735458374,
                0.4096367061138153,
                0.6958572268486023,
                0.6663182973861694,
                0.8546890020370483,
                0.5546325445175171,
                0.7176987528800964,
                0.6118748188018799,
                0.8211312890052795,
                0.7868767976760864,
                0.9443120956420898,
                0.8852808475494385,
                0.8825060725212097,
                0.8710165023803711,
                0.8389247059822083,
                0.842402458190918,
                0.7288472652435303,
                0.9372803568840027,
                0.8192359805107117,
                0.8521971702575684,
                0.9128867983818054,
                0.8258111476898193,
                0.7044699788093567,
                0.7546818852424622,
                0.7644909620285034,
                0.7332740426063538,
                0.8182840943336487,
                0.6307352781295776,
                0.9078048467636108,
                0.7725717425346375,
                0.7725717425346375,
                0.8121106624603271,
                0.7266254425048828,
                0.795104444026947,
                0.9079883098602295,
                0.8249114155769348,
                0.8235865831375122,
                0.646065354347229,
                0.9374803900718689
            ],
            [
                0.6768930554389954,
                0.810258150100708,
                0.8063681125640869,
                0.823798418045044,
                0.7152641415596008,
                0.7060965895652771,
                0.8275033831596375,
                0.7377972602844238,
                0.8492398858070374,
                0.6720737814903259,
                0.7226076722145081,
                0.45775747299194336,
                0.6875301003456116,
                0.45775747299194336,
                0.6720737814903259,
                0.6623642444610596,
                0.775489866733551,
                0.5943154692649841,
                0.7479578256607056,
                0.6569132804870605,
                0.8023975491523743,
                0.831446647644043,
                0.792711079120636,
                0.8805089592933655,
                0.8626775741577148,
                0.7060627937316895,
                0.8447551131248474,
                0.7752876281738281,
                0.7973146438598633,
                0.8047359585762024,
                0.8091835379600525,
                0.7719168066978455,
                0.7836707234382629,
                0.7772315740585327,
                0.7021253705024719,
                0.7951284050941467,
                0.7550762295722961,
                0.7492688298225403,
                0.8868409991264343,
                0.6463650465011597,
                0.7382112145423889,
                0.7370049953460693,
                0.7370049953460693,
                0.8361874222755432,
                0.7055850028991699,
                0.8529850244522095,
                0.7361903190612793,
                0.8253275156021118,
                0.7175660729408264,
                0.6761506795883179,
                0.7812949419021606
            ],
            [
                0.7747370600700378,
                0.8615871071815491,
                0.8793079853057861,
                0.8632358312606812,
                0.8693079948425293,
                0.8968889713287354,
                0.8278521299362183,
                0.8764089941978455,
                0.836663007736206,
                0.6333038210868835,
                0.8566606044769287,
                0.4193369746208191,
                0.8448224067687988,
                0.4193369746208191,
                0.6333038210868835,
                0.6063762307167053,
                0.8910261392593384,
                0.522193968296051,
                0.6996591091156006,
                0.6263513565063477,
                0.8479138612747192,
                0.8076627254486084,
                0.8841482400894165,
                0.891024649143219,
                0.9147311449050903,
                0.8708457946777344,
                0.8419785499572754,
                0.8554204106330872,
                0.8133267164230347,
                0.8891364336013794,
                0.8992275595664978,
                0.8791337013244629,
                0.9202162027359009,
                0.8170397281646729,
                0.6618106961250305,
                0.7603131532669067,
                0.7760044932365417,
                0.7307899594306946,
                0.8623878955841064,
                0.6076030135154724,
                0.903104305267334,
                0.7672410607337952,
                0.7672410607337952,
                0.8816125988960266,
                0.660629153251648,
                0.8105104565620422,
                0.8647124767303467,
                0.8634107112884521,
                0.846811830997467,
                0.6241497993469238,
                0.8376901149749756
            ],
            [
                0.7813245058059692,
                0.8212154507637024,
                0.8514172434806824,
                0.8309599161148071,
                0.8960282802581787,
                0.8667389750480652,
                0.7979156374931335,
                0.8800642490386963,
                0.8102338910102844,
                0.6736153364181519,
                0.883188009262085,
                0.43665286898612976,
                0.8820775747299194,
                0.43665286898612976,
                0.6736153364181519,
                0.6743525862693787,
                0.8652235269546509,
                0.5783793330192566,
                0.7251269221305847,
                0.6693657636642456,
                0.8466911911964417,
                0.7818136811256409,
                0.9056538343429565,
                0.8835679888725281,
                0.8853568434715271,
                0.8344712853431702,
                0.8394247889518738,
                0.8427881598472595,
                0.7733529210090637,
                0.9263583421707153,
                0.8713145852088928,
                0.9004330635070801,
                0.941293478012085,
                0.882599949836731,
                0.7457064390182495,
                0.8157752156257629,
                0.8462183475494385,
                0.7920855283737183,
                0.8867337703704834,
                0.6547328233718872,
                0.9266438484191895,
                0.8480823040008545,
                0.8480823040008545,
                0.8628315329551697,
                0.748206615447998,
                0.8435799479484558,
                0.8566280603408813,
                0.884260892868042,
                0.9191485643386841,
                0.6611108183860779,
                0.8851318955421448
            ],
            [
                0.7408903241157532,
                0.7976139187812805,
                0.815903902053833,
                0.7628602981567383,
                0.7917641997337341,
                0.7901811003684998,
                0.7322131395339966,
                0.8298727869987488,
                0.7984400987625122,
                0.6406251192092896,
                0.8173150420188904,
                0.36814770102500916,
                0.8110436201095581,
                0.36814770102500916,
                0.6406251192092896,
                0.5816006660461426,
                0.8143484592437744,
                0.5063710808753967,
                0.6898801326751709,
                0.5498071908950806,
                0.7981860041618347,
                0.7420842051506042,
                0.9016822576522827,
                0.850972056388855,
                0.842561662197113,
                0.8026332259178162,
                0.8175823092460632,
                0.7964097857475281,
                0.7217046618461609,
                0.8690585494041443,
                0.8498974442481995,
                0.8199671506881714,
                0.8804362416267395,
                0.7836928367614746,
                0.6738547086715698,
                0.7296435236930847,
                0.728875994682312,
                0.7060642242431641,
                0.8039016127586365,
                0.6119629740715027,
                0.8872149586677551,
                0.7684275507926941,
                0.7684275507926941,
                0.8020197153091431,
                0.6793972253799438,
                0.7903385758399963,
                0.8347903490066528,
                0.811117947101593,
                0.818167507648468,
                0.6113622188568115,
                0.8581284880638123
            ],
            [
                0.7605119943618774,
                0.8712648153305054,
                0.8802298307418823,
                0.8303080201148987,
                0.7746601104736328,
                0.7621627449989319,
                0.7515588998794556,
                0.8187493085861206,
                0.841140627861023,
                0.6552201509475708,
                0.7858264446258545,
                0.3760038912296295,
                0.7241137623786926,
                0.3760038912296295,
                0.6552201509475708,
                0.6012203693389893,
                0.8162717223167419,
                0.5234620571136475,
                0.7088465094566345,
                0.5249468684196472,
                0.774490475654602,
                0.7588353157043457,
                0.8557080030441284,
                0.9223688840866089,
                0.8767410516738892,
                0.8340793251991272,
                0.8854695558547974,
                0.8262498378753662,
                0.7247745394706726,
                0.8830883502960205,
                0.828762948513031,
                0.8244652152061462,
                0.8536394834518433,
                0.778460681438446,
                0.6679708957672119,
                0.7616231441497803,
                0.6984695196151733,
                0.6719675064086914,
                0.8219223022460938,
                0.6797553896903992,
                0.8395214676856995,
                0.7403472065925598,
                0.7403472065925598,
                0.8107452392578125,
                0.6890112161636353,
                0.8662964701652527,
                0.8688592314720154,
                0.8163977861404419,
                0.7301633358001709,
                0.7018658518791199,
                0.8526750802993774
            ],
            [
                0.7785460948944092,
                0.8044372797012329,
                0.8261882662773132,
                0.819603443145752,
                0.8771965503692627,
                0.8812201619148254,
                0.748154878616333,
                0.8691831231117249,
                0.766376793384552,
                0.6368511319160461,
                0.8735973834991455,
                0.4105450212955475,
                0.883724570274353,
                0.4105450212955475,
                0.6368511319160461,
                0.659356951713562,
                0.8785312175750732,
                0.5661353468894958,
                0.6932376623153687,
                0.6524783968925476,
                0.8384159207344055,
                0.7460619211196899,
                0.8505762219429016,
                0.844346284866333,
                0.8594099879264832,
                0.8272700309753418,
                0.821912407875061,
                0.8426563143730164,
                0.7514177560806274,
                0.8700836896896362,
                0.8760483860969543,
                0.8826000690460205,
                0.8945817351341248,
                0.821793258190155,
                0.7033179402351379,
                0.7900996208190918,
                0.7973055839538574,
                0.7594121694564819,
                0.8394368290901184,
                0.6686053276062012,
                0.8871853947639465,
                0.813288688659668,
                0.813288688659668,
                0.834908127784729,
                0.7132785320281982,
                0.7989120483398438,
                0.8159074187278748,
                0.8344383835792542,
                0.886534571647644,
                0.6659336686134338,
                0.8244612216949463
            ],
            [
                0.745642364025116,
                0.8778588175773621,
                0.8926756381988525,
                0.8394196629524231,
                0.8124503493309021,
                0.785456657409668,
                0.8505537509918213,
                0.8131547570228577,
                0.8997143507003784,
                0.6165878772735596,
                0.7958436012268066,
                0.3856417238712311,
                0.7643447518348694,
                0.3856417238712311,
                0.6165878772735596,
                0.588164210319519,
                0.8145310282707214,
                0.4789412021636963,
                0.7191587686538696,
                0.539607048034668,
                0.8361011743545532,
                0.8211973905563354,
                0.8772149085998535,
                0.9459983110427856,
                0.909808874130249,
                0.8366139531135559,
                0.901546835899353,
                0.8017943501472473,
                0.8328783512115479,
                0.8818323612213135,
                0.9027763605117798,
                0.8265240788459778,
                0.906214714050293,
                0.7936125993728638,
                0.6523692607879639,
                0.7384467720985413,
                0.746898889541626,
                0.7026330828666687,
                0.8656182885169983,
                0.5780000686645508,
                0.8905815482139587,
                0.7702821493148804,
                0.7702821493148804,
                0.8707883954048157,
                0.652499794960022,
                0.8900550007820129,
                0.863613486289978,
                0.8652509450912476,
                0.7782410979270935,
                0.6008637547492981,
                0.8332222104072571
            ],
            [
                0.7960310578346252,
                0.8667115569114685,
                0.879783034324646,
                0.8218715786933899,
                0.8808824419975281,
                0.820134162902832,
                0.7636215090751648,
                0.8676027655601501,
                0.8382402062416077,
                0.6254720687866211,
                0.8430585861206055,
                0.4100293517112732,
                0.8540124297142029,
                0.4100293517112732,
                0.6254720687866211,
                0.618202805519104,
                0.831499457359314,
                0.5132890343666077,
                0.7106202840805054,
                0.5795831084251404,
                0.8108956217765808,
                0.749329149723053,
                0.9068454504013062,
                0.898937463760376,
                0.877400815486908,
                0.8934283256530762,
                0.8688139915466309,
                0.8347085118293762,
                0.7342534065246582,
                0.9329091310501099,
                0.8536261916160583,
                0.8523910045623779,
                0.949989914894104,
                0.8392424583435059,
                0.6860120296478271,
                0.7349293231964111,
                0.8005173802375793,
                0.7354991436004639,
                0.822921097278595,
                0.6426061391830444,
                0.9616792798042297,
                0.8078295588493347,
                0.8078295588493347,
                0.8395587801933289,
                0.6839980483055115,
                0.8348578214645386,
                0.9297729134559631,
                0.8617632985115051,
                0.849789023399353,
                0.6456323862075806,
                0.8780268430709839
            ],
            [
                0.832912802696228,
                0.8060963749885559,
                0.8397610783576965,
                0.832563579082489,
                0.8608275651931763,
                0.9209102392196655,
                0.6942765116691589,
                0.8823895454406738,
                0.6873830556869507,
                0.6348376274108887,
                0.8458607196807861,
                0.46596023440361023,
                0.8649532198905945,
                0.46596023440361023,
                0.6348376274108887,
                0.6425315141677856,
                0.9207385778427124,
                0.6013468503952026,
                0.6952228546142578,
                0.6884590983390808,
                0.8072816729545593,
                0.7076820731163025,
                0.7928370237350464,
                0.7795665264129639,
                0.8287441730499268,
                0.8690217137336731,
                0.7722037434577942,
                0.896185576915741,
                0.6876876950263977,
                0.8453949093818665,
                0.7807711958885193,
                0.8938151001930237,
                0.8422898650169373,
                0.7989905476570129,
                0.6719092130661011,
                0.766004741191864,
                0.7865437865257263,
                0.7299820184707642,
                0.7711479663848877,
                0.7208990454673767,
                0.8374727964401245,
                0.7367042303085327,
                0.7367042303085327,
                0.790241003036499,
                0.6788628101348877,
                0.7083982229232788,
                0.8252017498016357,
                0.7862582206726074,
                0.8241855502128601,
                0.733853816986084,
                0.800173282623291
            ],
            [
                0.73069167137146,
                0.7746193408966064,
                0.8085585236549377,
                0.74068284034729,
                0.7086517810821533,
                0.6780180931091309,
                0.7207071781158447,
                0.7227196097373962,
                0.7691637277603149,
                0.6710154414176941,
                0.7281599044799805,
                0.45968735218048096,
                0.6931596994400024,
                0.45968735218048096,
                0.6710154414176941,
                0.6547315716743469,
                0.7537100911140442,
                0.5795774459838867,
                0.751937210559845,
                0.5795513987541199,
                0.7667503952980042,
                0.7234487533569336,
                0.7824439406394958,
                0.8244549632072449,
                0.7900443077087402,
                0.7231269478797913,
                0.8027240037918091,
                0.7836366891860962,
                0.7120283246040344,
                0.7858420610427856,
                0.7686712145805359,
                0.7496389150619507,
                0.775359034538269,
                0.7482262849807739,
                0.6993765234947205,
                0.6996548175811768,
                0.7339822053909302,
                0.7218089699745178,
                0.7676389813423157,
                0.6713201999664307,
                0.7787678837776184,
                0.7604901790618896,
                0.7604901790618896,
                0.7392001152038574,
                0.7513400912284851,
                0.8024876117706299,
                0.7448165416717529,
                0.7785257697105408,
                0.7193962335586548,
                0.6842486262321472,
                0.7865011096000671
            ],
            [
                0.7143738865852356,
                0.7929900884628296,
                0.8182278871536255,
                0.7548947334289551,
                0.6932660341262817,
                0.6503356695175171,
                0.7669607996940613,
                0.7133405208587646,
                0.8159160614013672,
                0.627657413482666,
                0.7201943397521973,
                0.3958284556865692,
                0.667880654335022,
                0.3958284556865692,
                0.627657413482666,
                0.6201896071434021,
                0.7142758369445801,
                0.5209998488426208,
                0.7575145363807678,
                0.5065648555755615,
                0.7571443319320679,
                0.7515526413917542,
                0.7721428275108337,
                0.8603839874267578,
                0.7940083742141724,
                0.7310696244239807,
                0.8606393933296204,
                0.7338667511940002,
                0.7463251948356628,
                0.7950156927108765,
                0.7892757058143616,
                0.7234857678413391,
                0.7807998657226562,
                0.7552782893180847,
                0.6846866607666016,
                0.6676830053329468,
                0.7175755500793457,
                0.6879121661186218,
                0.7814732789993286,
                0.5878912806510925,
                0.7555685043334961,
                0.7371128797531128,
                0.7371128797531128,
                0.7911372780799866,
                0.6906687021255493,
                0.8664613366127014,
                0.7520608305931091,
                0.8077571988105774,
                0.6816216707229614,
                0.610293984413147,
                0.7707681059837341
            ],
            [
                0.838390588760376,
                0.8070223927497864,
                0.8439321517944336,
                0.8241568803787231,
                0.8440114259719849,
                0.9095644950866699,
                0.6844558119773865,
                0.879734456539154,
                0.6994828581809998,
                0.6584686636924744,
                0.8559272885322571,
                0.4789642095565796,
                0.8509924411773682,
                0.4789642095565796,
                0.6584686636924744,
                0.6553646326065063,
                0.9155385494232178,
                0.608506977558136,
                0.7098190188407898,
                0.6759404540061951,
                0.8107932806015015,
                0.720206618309021,
                0.798623263835907,
                0.7868409156799316,
                0.8316205143928528,
                0.8633317351341248,
                0.7864899039268494,
                0.8931633234024048,
                0.6864358186721802,
                0.8460625410079956,
                0.7840803861618042,
                0.8815287947654724,
                0.8308184742927551,
                0.7865681052207947,
                0.6722865700721741,
                0.7562370896339417,
                0.770587146282196,
                0.7255703210830688,
                0.7632887363433838,
                0.7233589887619019,
                0.8271426558494568,
                0.731218159198761,
                0.731218159198761,
                0.7871676683425903,
                0.6849383115768433,
                0.7241262197494507,
                0.8281662464141846,
                0.7814038991928101,
                0.8031814098358154,
                0.7394865155220032,
                0.7991393804550171
            ],
            [
                0.7303353548049927,
                0.7745751738548279,
                0.8140219449996948,
                0.735719621181488,
                0.7307106256484985,
                0.7137974500656128,
                0.718850314617157,
                0.7511285543441772,
                0.8046213984489441,
                0.6982353925704956,
                0.7794076800346375,
                0.4960506856441498,
                0.7274453043937683,
                0.4960506856441498,
                0.6982353925704956,
                0.6715996861457825,
                0.7751339673995972,
                0.58309406042099,
                0.7677271962165833,
                0.6024218201637268,
                0.8038074374198914,
                0.7489522099494934,
                0.8130146861076355,
                0.8374441266059875,
                0.8135476112365723,
                0.7240596413612366,
                0.8146705031394958,
                0.7889688611030579,
                0.7372440099716187,
                0.8019663095474243,
                0.8058342337608337,
                0.7678667306900024,
                0.7981585264205933,
                0.7593247890472412,
                0.6954477429389954,
                0.7161039113998413,
                0.7437295913696289,
                0.7423316240310669,
                0.7834096550941467,
                0.6597352027893066,
                0.7966353297233582,
                0.7820746898651123,
                0.7820746898651123,
                0.7716878652572632,
                0.7611873149871826,
                0.8259831070899963,
                0.7546794414520264,
                0.8044940829277039,
                0.7563790678977966,
                0.6673204898834229,
                0.7921558022499084
            ],
            [
                0.7757443785667419,
                0.8451676368713379,
                0.8772954344749451,
                0.8089534044265747,
                0.797795832157135,
                0.7790680527687073,
                0.7732921838760376,
                0.8041661381721497,
                0.83646559715271,
                0.6319485902786255,
                0.8078105449676514,
                0.4206668734550476,
                0.760866641998291,
                0.4206668734550476,
                0.6319485902786255,
                0.6283493638038635,
                0.8200292587280273,
                0.5296914577484131,
                0.7802009582519531,
                0.5642920732498169,
                0.8311440348625183,
                0.7669699192047119,
                0.8382759690284729,
                0.8968998789787292,
                0.8702877759933472,
                0.83344566822052,
                0.8896713256835938,
                0.8279542326927185,
                0.7657750844955444,
                0.8528599739074707,
                0.8499999046325684,
                0.8136144280433655,
                0.8540248870849609,
                0.7892168164253235,
                0.6762577891349792,
                0.7295681834220886,
                0.7828794121742249,
                0.740108847618103,
                0.8146997690200806,
                0.6523641347885132,
                0.8492529988288879,
                0.7661067843437195,
                0.7661067843437195,
                0.8323941230773926,
                0.6874526143074036,
                0.8639895915985107,
                0.8354712128639221,
                0.8353053331375122,
                0.7533714771270752,
                0.6646841764450073,
                0.8155961036682129
            ],
            [
                0.7819360494613647,
                0.7993428707122803,
                0.8316389322280884,
                0.7636557221412659,
                0.7835928797721863,
                0.7514235973358154,
                0.7367106676101685,
                0.785598635673523,
                0.7736862301826477,
                0.6877509951591492,
                0.7884311079978943,
                0.4991306662559509,
                0.7749574184417725,
                0.4991306662559509,
                0.6877509951591492,
                0.6789765954017639,
                0.8067855834960938,
                0.5819088220596313,
                0.7672748565673828,
                0.6277163028717041,
                0.8289803266525269,
                0.752973735332489,
                0.8208792805671692,
                0.8270434737205505,
                0.8207259774208069,
                0.7592969536781311,
                0.8133835792541504,
                0.8162074089050293,
                0.7409661412239075,
                0.8200604915618896,
                0.8011818528175354,
                0.8005111217498779,
                0.8211396336555481,
                0.7826509475708008,
                0.7057464718818665,
                0.7276400327682495,
                0.7900136113166809,
                0.756598711013794,
                0.795511782169342,
                0.6605195999145508,
                0.82512366771698,
                0.7896548509597778,
                0.7896548509597778,
                0.7887917757034302,
                0.7686305642127991,
                0.8217694759368896,
                0.7786213159561157,
                0.8237354755401611,
                0.7797217965126038,
                0.6689736843109131,
                0.8081112504005432
            ],
            [
                0.7794265747070312,
                0.8645311594009399,
                0.8855928182601929,
                0.8422186970710754,
                0.8267268538475037,
                0.8000567555427551,
                0.8062697649002075,
                0.8177298307418823,
                0.8493746519088745,
                0.6339035630226135,
                0.8073644042015076,
                0.4155164361000061,
                0.7775353193283081,
                0.4155164361000061,
                0.6339035630226135,
                0.6292453408241272,
                0.8423845767974854,
                0.5363479852676392,
                0.7624927163124084,
                0.5796838998794556,
                0.8408160209655762,
                0.7740660905838013,
                0.8503844738006592,
                0.9108889102935791,
                0.8909003734588623,
                0.8468199968338013,
                0.8894509077072144,
                0.8471519351005554,
                0.7909952998161316,
                0.8708959817886353,
                0.8737083673477173,
                0.8373322486877441,
                0.881449282169342,
                0.8077666759490967,
                0.6769110560417175,
                0.7446064949035645,
                0.792576253414154,
                0.7370951175689697,
                0.8424180150032043,
                0.6613807678222656,
                0.8741275668144226,
                0.7713848948478699,
                0.7713848948478699,
                0.8554232120513916,
                0.7003906965255737,
                0.8728690147399902,
                0.8613731265068054,
                0.8646721243858337,
                0.7805020213127136,
                0.6717817187309265,
                0.8291674852371216
            ],
            [
                0.7511349320411682,
                0.7625260949134827,
                0.7997921705245972,
                0.721930980682373,
                0.7430880069732666,
                0.7207347750663757,
                0.6940117478370667,
                0.7507153749465942,
                0.7546641230583191,
                0.6959407329559326,
                0.7617810964584351,
                0.48279666900634766,
                0.7407655119895935,
                0.48279666900634766,
                0.6959407329559326,
                0.6737491488456726,
                0.7736214995384216,
                0.5854082107543945,
                0.75388103723526,
                0.6001105904579163,
                0.7894393801689148,
                0.7228302359580994,
                0.8010377287864685,
                0.8083634376525879,
                0.7938926815986633,
                0.7322602272033691,
                0.7882201075553894,
                0.7914906144142151,
                0.691857099533081,
                0.7937628626823425,
                0.7786615490913391,
                0.7739096879959106,
                0.7922118306159973,
                0.7697703838348389,
                0.7139009237289429,
                0.6967019438743591,
                0.7546921968460083,
                0.7371833920478821,
                0.7655912041664124,
                0.6614972949028015,
                0.7994481921195984,
                0.8110631108283997,
                0.8110631108283997,
                0.7491603493690491,
                0.7796339988708496,
                0.8120520114898682,
                0.7486410737037659,
                0.8047913312911987,
                0.778313398361206,
                0.6637527942657471,
                0.7869033217430115
            ],
            [
                0.8053833842277527,
                0.8447244167327881,
                0.8701859712600708,
                0.8261402249336243,
                0.790988028049469,
                0.7796671390533447,
                0.7711794376373291,
                0.7985031008720398,
                0.8086395263671875,
                0.6657648682594299,
                0.7965661287307739,
                0.4414418935775757,
                0.7621586918830872,
                0.4414418935775757,
                0.6657648682594299,
                0.6647517681121826,
                0.8245575428009033,
                0.5683804154396057,
                0.7654896974563599,
                0.5653606057167053,
                0.8054403066635132,
                0.7531221508979797,
                0.8179983496665955,
                0.8793667554855347,
                0.8538230061531067,
                0.8262572884559631,
                0.8704439401626587,
                0.8379256725311279,
                0.7493562698364258,
                0.849210798740387,
                0.8224250674247742,
                0.8305121660232544,
                0.8420193195343018,
                0.8098527193069458,
                0.7109856009483337,
                0.7238036394119263,
                0.7681059241294861,
                0.7125178575515747,
                0.8152981996536255,
                0.6779577136039734,
                0.8258435726165771,
                0.8047260046005249,
                0.8047260046005249,
                0.8182321190834045,
                0.7471139430999756,
                0.8790308237075806,
                0.8215738534927368,
                0.8587508797645569,
                0.7770025134086609,
                0.6964498162269592,
                0.8176197409629822
            ],
            [
                0.8406596183776855,
                0.8151101469993591,
                0.8581916689872742,
                0.788901686668396,
                0.8685187101364136,
                0.8411099910736084,
                0.7057629823684692,
                0.8657135367393494,
                0.7518001794815063,
                0.6756831407546997,
                0.8952804803848267,
                0.4625181555747986,
                0.8767076134681702,
                0.4625181555747986,
                0.6756831407546997,
                0.6934827566146851,
                0.8568329811096191,
                0.5996306538581848,
                0.7609002590179443,
                0.6589260101318359,
                0.8409314155578613,
                0.7366998195648193,
                0.8583105802536011,
                0.8488405346870422,
                0.8441094756126404,
                0.8423213958740234,
                0.8467226028442383,
                0.8524689674377441,
                0.7038556933403015,
                0.8936047554016113,
                0.8199646472930908,
                0.876274049282074,
                0.8877769708633423,
                0.8581436276435852,
                0.7580101490020752,
                0.7793542742729187,
                0.8583482503890991,
                0.8092033863067627,
                0.8146235346794128,
                0.7020101547241211,
                0.8880277276039124,
                0.8542762994766235,
                0.8542762994766235,
                0.8069263696670532,
                0.7711362838745117,
                0.8301905393600464,
                0.8365432620048523,
                0.8459426760673523,
                0.8817756772041321,
                0.7179989814758301,
                0.8770058155059814
            ],
            [
                0.8052504658699036,
                0.8382253646850586,
                0.8570029735565186,
                0.8123394846916199,
                0.7869516611099243,
                0.7638576030731201,
                0.76046222448349,
                0.7921943664550781,
                0.8108745217323303,
                0.6986328959465027,
                0.8178128004074097,
                0.4797411561012268,
                0.7792044878005981,
                0.4797411561012268,
                0.6986328959465027,
                0.6724518537521362,
                0.8226444721221924,
                0.6128718256950378,
                0.7953557968139648,
                0.6494481563568115,
                0.8479456305503845,
                0.788119375705719,
                0.8504980802536011,
                0.8727316856384277,
                0.8601852059364319,
                0.7863960266113281,
                0.8814890384674072,
                0.8349265456199646,
                0.760944128036499,
                0.8512240648269653,
                0.8227851390838623,
                0.8061990141868591,
                0.8501968383789062,
                0.8158057928085327,
                0.7453092336654663,
                0.7413023114204407,
                0.7974743247032166,
                0.7868867516517639,
                0.8344120383262634,
                0.6992019414901733,
                0.8287922739982605,
                0.8080130815505981,
                0.8080130815505981,
                0.8287349939346313,
                0.7610253095626831,
                0.85909503698349,
                0.7970473170280457,
                0.8586808443069458,
                0.7847949266433716,
                0.7202892899513245,
                0.8392695188522339
            ],
            [
                0.7878460884094238,
                0.8075858950614929,
                0.8298060894012451,
                0.787131130695343,
                0.8168760538101196,
                0.787746012210846,
                0.7265394330024719,
                0.8113287687301636,
                0.7693572044372559,
                0.7147085070610046,
                0.8271737098693848,
                0.48603078722953796,
                0.8067697882652283,
                0.48603078722953796,
                0.7147085070610046,
                0.6923900246620178,
                0.844834566116333,
                0.635371208190918,
                0.7653841972351074,
                0.6833438277244568,
                0.8342509865760803,
                0.7630120515823364,
                0.8515713214874268,
                0.8375259637832642,
                0.850210428237915,
                0.7693811655044556,
                0.8481454849243164,
                0.8516829013824463,
                0.7141537666320801,
                0.8584974408149719,
                0.8034169673919678,
                0.8321881890296936,
                0.8428005576133728,
                0.8405457735061646,
                0.7632389068603516,
                0.7673120498657227,
                0.8135579824447632,
                0.796972930431366,
                0.8311117887496948,
                0.7223449349403381,
                0.8250643014907837,
                0.8092935681343079,
                0.8092935681343079,
                0.8129919767379761,
                0.7683485746383667,
                0.8206762075424194,
                0.7756209969520569,
                0.8380841016769409,
                0.829102098941803,
                0.7408475279808044,
                0.8544921875
            ],
            [
                0.8147389888763428,
                0.8771970272064209,
                0.8991886377334595,
                0.8724665641784668,
                0.8373910784721375,
                0.838904082775116,
                0.8257171511650085,
                0.8431330919265747,
                0.8515982031822205,
                0.6637837886810303,
                0.8401468992233276,
                0.4286465346813202,
                0.8080071210861206,
                0.4286465346813202,
                0.6637837886810303,
                0.6514197587966919,
                0.8749786615371704,
                0.5779802799224854,
                0.7597169280052185,
                0.6287912726402283,
                0.8540822267532349,
                0.8240317702293396,
                0.861443042755127,
                0.9251958727836609,
                0.9120838046073914,
                0.8412027955055237,
                0.9103726148605347,
                0.8752202987670898,
                0.8063830733299255,
                0.8951234817504883,
                0.8986309170722961,
                0.871303915977478,
                0.8840429782867432,
                0.8271311521530151,
                0.714562177658081,
                0.7872259616851807,
                0.8019504547119141,
                0.7708559632301331,
                0.8846887350082397,
                0.6913632154464722,
                0.8611785173416138,
                0.7929450273513794,
                0.7929450273513794,
                0.8791130781173706,
                0.7232751250267029,
                0.8729981184005737,
                0.8456905484199524,
                0.869181215763092,
                0.8135502338409424,
                0.7241376638412476,
                0.8556461334228516
            ],
            [
                0.801738977432251,
                0.7886707782745361,
                0.8223757147789001,
                0.7878307104110718,
                0.8435580134391785,
                0.8494083881378174,
                0.6997190713882446,
                0.8595203757286072,
                0.7319070100784302,
                0.6927703619003296,
                0.8888941407203674,
                0.4341326653957367,
                0.8727327585220337,
                0.4341326653957367,
                0.6927703619003296,
                0.653517484664917,
                0.8513925075531006,
                0.6118351221084595,
                0.7320272326469421,
                0.6707817912101746,
                0.831982433795929,
                0.7347986698150635,
                0.8681618571281433,
                0.8168357610702515,
                0.8282954692840576,
                0.8057303428649902,
                0.8102607131004333,
                0.8367729783058167,
                0.7032435536384583,
                0.8718010187149048,
                0.8277008533477783,
                0.8558741211891174,
                0.884869396686554,
                0.8348088264465332,
                0.7554481029510498,
                0.7758628129959106,
                0.7978222966194153,
                0.7978810667991638,
                0.797614336013794,
                0.6964600682258606,
                0.8771800994873047,
                0.8301699757575989,
                0.8301699757575989,
                0.7940388321876526,
                0.7296344041824341,
                0.7652863264083862,
                0.8132506608963013,
                0.8105562329292297,
                0.868485152721405,
                0.6876857876777649,
                0.8455640077590942
            ],
            [
                0.7860260009765625,
                0.7984517216682434,
                0.8229460120201111,
                0.8198391199111938,
                0.8534867167472839,
                0.8552162647247314,
                0.7482103109359741,
                0.851093053817749,
                0.7617722749710083,
                0.7081894874572754,
                0.886934220790863,
                0.4862612187862396,
                0.8748900294303894,
                0.4862612187862396,
                0.7081894874572754,
                0.6655874848365784,
                0.8819013833999634,
                0.642171323299408,
                0.7313842177391052,
                0.7210781574249268,
                0.8518960475921631,
                0.7718783020973206,
                0.871487021446228,
                0.830927848815918,
                0.8602665662765503,
                0.7911056280136108,
                0.8330376744270325,
                0.8501251935958862,
                0.7419719696044922,
                0.8741190433502197,
                0.842134952545166,
                0.8722741007804871,
                0.8962978720664978,
                0.8567712306976318,
                0.7553229331970215,
                0.8048460483551025,
                0.8251619935035706,
                0.8085119724273682,
                0.8542482852935791,
                0.7102595567703247,
                0.860170841217041,
                0.8109100461006165,
                0.8109100461006165,
                0.8612785339355469,
                0.7426987290382385,
                0.7880681753158569,
                0.7933719158172607,
                0.8533430099487305,
                0.8866504430770874,
                0.709389865398407,
                0.8380317091941833
            ],
            [
                0.8457028269767761,
                0.8981320858001709,
                0.9100297689437866,
                0.9052324295043945,
                0.858478844165802,
                0.870509147644043,
                0.8088526725769043,
                0.8582163453102112,
                0.8177950382232666,
                0.672012984752655,
                0.8322914838790894,
                0.47024405002593994,
                0.82393479347229,
                0.47024405002593994,
                0.672012984752655,
                0.6832728981971741,
                0.9207868576049805,
                0.6281838417053223,
                0.7539811134338379,
                0.6823703050613403,
                0.8560706973075867,
                0.8037249445915222,
                0.8361164331436157,
                0.9016212821006775,
                0.9085323214530945,
                0.8637264370918274,
                0.8918675184249878,
                0.9190782308578491,
                0.7856363654136658,
                0.8923559784889221,
                0.8543943166732788,
                0.9063934087753296,
                0.8753719329833984,
                0.8370298743247986,
                0.7135535478591919,
                0.8114746809005737,
                0.8147191405296326,
                0.7582526206970215,
                0.8771328926086426,
                0.7616328001022339,
                0.8480222225189209,
                0.7838693857192993,
                0.7838693857192993,
                0.8604353070259094,
                0.7468506693840027,
                0.8474787473678589,
                0.8427718281745911,
                0.8665499091148376,
                0.8226127028465271,
                0.7892438769340515,
                0.8372292518615723
            ],
            [
                0.7858279943466187,
                0.7833667993545532,
                0.8198390007019043,
                0.7741378545761108,
                0.8330153226852417,
                0.8097773790359497,
                0.6944761872291565,
                0.8447065353393555,
                0.7417929768562317,
                0.7304384708404541,
                0.8773559331893921,
                0.4607964754104614,
                0.8482935428619385,
                0.4607964754104614,
                0.7304384708404541,
                0.6991116404533386,
                0.8273524045944214,
                0.6460893750190735,
                0.7747536897659302,
                0.6756550073623657,
                0.8235164880752563,
                0.7316840291023254,
                0.8778997659683228,
                0.8305765390396118,
                0.8219373822212219,
                0.7954714894294739,
                0.8189586400985718,
                0.8260269165039062,
                0.6845687627792358,
                0.8900168538093567,
                0.8124690651893616,
                0.847190260887146,
                0.8846952319145203,
                0.8694177865982056,
                0.8014352917671204,
                0.7793135643005371,
                0.8217076659202576,
                0.8121121525764465,
                0.8033437132835388,
                0.7147696614265442,
                0.8783511519432068,
                0.8599609732627869,
                0.8599609732627869,
                0.7912849187850952,
                0.7758466601371765,
                0.815667986869812,
                0.819493293762207,
                0.8371831774711609,
                0.8667920827865601,
                0.70460045337677,
                0.8662081360816956
            ],
            [
                0.7856417894363403,
                0.7784295678138733,
                0.8097630143165588,
                0.7623211145401001,
                0.8006604909896851,
                0.769081175327301,
                0.6657670140266418,
                0.7965748310089111,
                0.7171605229377747,
                0.7383230924606323,
                0.8303677439689636,
                0.4921509623527527,
                0.7967343330383301,
                0.4921509623527527,
                0.7383230924606323,
                0.7155694961547852,
                0.8198091983795166,
                0.6775040626525879,
                0.7667015194892883,
                0.6866757273674011,
                0.8118584752082825,
                0.7193925380706787,
                0.8300961256027222,
                0.8068877458572388,
                0.8014433979988098,
                0.7524387240409851,
                0.806458055973053,
                0.8388394117355347,
                0.6612632274627686,
                0.850632905960083,
                0.7570830583572388,
                0.817320704460144,
                0.8156960010528564,
                0.825546145439148,
                0.7805847525596619,
                0.7489516735076904,
                0.7942202091217041,
                0.7842313051223755,
                0.7801405191421509,
                0.7440519332885742,
                0.7991256713867188,
                0.8142819404602051,
                0.8142819404602051,
                0.7574100494384766,
                0.7975701093673706,
                0.7954486012458801,
                0.7657551169395447,
                0.8133013248443604,
                0.820076048374176,
                0.7402365803718567,
                0.8291580080986023
            ],
            [
                0.8469750881195068,
                0.8989210724830627,
                0.9229949116706848,
                0.9141982197761536,
                0.8700852394104004,
                0.8855106234550476,
                0.8339264392852783,
                0.8675892949104309,
                0.8265182971954346,
                0.6734186410903931,
                0.849484920501709,
                0.4664873778820038,
                0.83595871925354,
                0.4664873778820038,
                0.6734186410903931,
                0.6838589906692505,
                0.9252173900604248,
                0.6250362992286682,
                0.7638214826583862,
                0.6857825517654419,
                0.8761849403381348,
                0.8216241002082825,
                0.8541533946990967,
                0.9156298637390137,
                0.9266477823257446,
                0.867117166519165,
                0.9008259773254395,
                0.9171850681304932,
                0.8175329566001892,
                0.8995947241783142,
                0.8877637982368469,
                0.9107627272605896,
                0.891915500164032,
                0.8472819328308105,
                0.7238048315048218,
                0.8180120587348938,
                0.8301734328269958,
                0.7789793014526367,
                0.8887946605682373,
                0.7523539066314697,
                0.8647173643112183,
                0.7945390939712524,
                0.7945390939712524,
                0.8874529600143433,
                0.7393830418586731,
                0.8623287677764893,
                0.8474924564361572,
                0.8737884163856506,
                0.8286617398262024,
                0.7708566188812256,
                0.8408775925636292
            ],
            [
                0.7505384087562561,
                0.8193970322608948,
                0.8467319011688232,
                0.7752208709716797,
                0.7687621116638184,
                0.7439664602279663,
                0.7882910966873169,
                0.7707149982452393,
                0.824059247970581,
                0.6766220927238464,
                0.7709134221076965,
                0.4965161681175232,
                0.7371740937232971,
                0.4965161681175232,
                0.6766220927238464,
                0.6594927906990051,
                0.8060789704322815,
                0.5612350106239319,
                0.7683139443397522,
                0.6238745450973511,
                0.8561590313911438,
                0.7985996603965759,
                0.8341963291168213,
                0.8605966567993164,
                0.8554022312164307,
                0.7434869408607483,
                0.8408615589141846,
                0.8041852116584778,
                0.8022985458374023,
                0.8132904171943665,
                0.8345997929573059,
                0.7930305004119873,
                0.8309482336044312,
                0.7828093767166138,
                0.6849035024642944,
                0.7369066476821899,
                0.7831189632415771,
                0.7535740733146667,
                0.8311325311660767,
                0.6303496360778809,
                0.8210549354553223,
                0.7658568620681763,
                0.7658568620681763,
                0.8333213925361633,
                0.7364532947540283,
                0.8509474396705627,
                0.7675430774688721,
                0.8455086350440979,
                0.7620589733123779,
                0.6435779333114624,
                0.8095638751983643
            ],
            [
                0.8147526979446411,
                0.8707107305526733,
                0.8958210945129395,
                0.8302996754646301,
                0.7835150957107544,
                0.785113513469696,
                0.7900306582450867,
                0.805639922618866,
                0.83442223072052,
                0.675961434841156,
                0.8088307976722717,
                0.45262011885643005,
                0.7621083855628967,
                0.45262011885643005,
                0.675961434841156,
                0.6558270454406738,
                0.837317943572998,
                0.5874218344688416,
                0.7849379181861877,
                0.5893962383270264,
                0.8261807560920715,
                0.7869088649749756,
                0.8410192131996155,
                0.9006778001785278,
                0.8740404844284058,
                0.8270443677902222,
                0.8999155163764954,
                0.8409507870674133,
                0.7827095985412598,
                0.8588844537734985,
                0.8414536118507385,
                0.8258692622184753,
                0.8467686176300049,
                0.8177018165588379,
                0.7221564054489136,
                0.7266982197761536,
                0.7808679938316345,
                0.742366373538971,
                0.8278894424438477,
                0.6730166673660278,
                0.8301148414611816,
                0.7809305191040039,
                0.7809305191040039,
                0.8423819541931152,
                0.7256847620010376,
                0.8821016550064087,
                0.8298414349555969,
                0.8624401092529297,
                0.7554205656051636,
                0.6926146745681763,
                0.8261966705322266
            ],
            [
                0.7571013569831848,
                0.7711155414581299,
                0.8079462051391602,
                0.7321547865867615,
                0.7444937229156494,
                0.7177839875221252,
                0.7060146331787109,
                0.7470393180847168,
                0.7589511871337891,
                0.6883765459060669,
                0.7634352445602417,
                0.5010281205177307,
                0.7485706210136414,
                0.5010281205177307,
                0.6883765459060669,
                0.6640287637710571,
                0.7764763832092285,
                0.5867050290107727,
                0.7592988610267639,
                0.608208954334259,
                0.8021918535232544,
                0.7336563467979431,
                0.8001583814620972,
                0.8013131022453308,
                0.8001043200492859,
                0.7304409146308899,
                0.7952268123626709,
                0.790732204914093,
                0.7206710577011108,
                0.7861356735229492,
                0.7886232733726501,
                0.7659083008766174,
                0.7888467311859131,
                0.7628093361854553,
                0.7007984519004822,
                0.6930855512619019,
                0.7566772103309631,
                0.732429563999176,
                0.7698923349380493,
                0.6490232944488525,
                0.796142578125,
                0.7832826375961304,
                0.7832826375961304,
                0.7693347334861755,
                0.7640008926391602,
                0.7968006134033203,
                0.7455903887748718,
                0.7981453537940979,
                0.7576728463172913,
                0.6583139896392822,
                0.7809445858001709
            ],
            [
                0.7636055946350098,
                0.8922679424285889,
                0.8999024033546448,
                0.843234121799469,
                0.7759959101676941,
                0.752066433429718,
                0.8525495529174805,
                0.8004472851753235,
                0.9090576171875,
                0.6391986012458801,
                0.7753570675849915,
                0.40713486075401306,
                0.7417905926704407,
                0.40713486075401306,
                0.6391986012458801,
                0.6084192991256714,
                0.8015605211257935,
                0.5187088251113892,
                0.7611047029495239,
                0.5477884411811829,
                0.8375151753425598,
                0.8341907858848572,
                0.8720059394836426,
                0.9356929063796997,
                0.905392050743103,
                0.8192575573921204,
                0.9211024641990662,
                0.8060052394866943,
                0.8299933671951294,
                0.8738124966621399,
                0.8801298141479492,
                0.7873558402061462,
                0.8766438364982605,
                0.7857133746147156,
                0.6693362593650818,
                0.6982789039611816,
                0.7430232167243958,
                0.7110971808433533,
                0.8485381603240967,
                0.5941108465194702,
                0.8569885492324829,
                0.7465429306030273,
                0.7465429306030273,
                0.8633619546890259,
                0.6716763377189636,
                0.8924984931945801,
                0.8531162738800049,
                0.8669411540031433,
                0.7305781841278076,
                0.6190705895423889,
                0.8299932479858398
            ],
            [
                0.7883051037788391,
                0.8662387132644653,
                0.8753355741500854,
                0.8095536231994629,
                0.8701279163360596,
                0.8246128559112549,
                0.7454538345336914,
                0.8737708926200867,
                0.8259516954421997,
                0.607994794845581,
                0.8367440700531006,
                0.3775710165500641,
                0.840991199016571,
                0.3775710165500641,
                0.607994794845581,
                0.5809352397918701,
                0.8263335824012756,
                0.48784899711608887,
                0.6759079098701477,
                0.5523740649223328,
                0.7912042140960693,
                0.7363874912261963,
                0.9074339270591736,
                0.889494776725769,
                0.8712026476860046,
                0.9030116200447083,
                0.8527997732162476,
                0.8264489769935608,
                0.725617527961731,
                0.9283172488212585,
                0.843734085559845,
                0.840596079826355,
                0.9331245422363281,
                0.8042105436325073,
                0.6552301049232483,
                0.7138128280639648,
                0.7584812045097351,
                0.7050997614860535,
                0.8003585934638977,
                0.614836573600769,
                0.9517514109611511,
                0.7689511775970459,
                0.7689511775970459,
                0.8145114183425903,
                0.6473110318183899,
                0.7997448444366455,
                0.9469038248062134,
                0.8291561603546143,
                0.819303572177887,
                0.6174028515815735,
                0.8787083029747009
            ],
            [
                0.8495544791221619,
                0.8197028636932373,
                0.8562066555023193,
                0.8296798467636108,
                0.8465436697006226,
                0.90333491563797,
                0.6983568072319031,
                0.8787739872932434,
                0.7077333331108093,
                0.6836890578269958,
                0.8518937230110168,
                0.4845147430896759,
                0.8519513010978699,
                0.4845147430896759,
                0.6836890578269958,
                0.6903443336486816,
                0.910036563873291,
                0.6371180415153503,
                0.736237645149231,
                0.6736097931861877,
                0.8100256323814392,
                0.7313294410705566,
                0.8181251883506775,
                0.7985807657241821,
                0.8328248858451843,
                0.869564414024353,
                0.7886350154876709,
                0.8992348909378052,
                0.6890899538993835,
                0.8640314340591431,
                0.7842611074447632,
                0.8873928785324097,
                0.8378404378890991,
                0.8209838271141052,
                0.7143381237983704,
                0.7383208274841309,
                0.784023642539978,
                0.7269874215126038,
                0.7682223916053772,
                0.7216482162475586,
                0.8358783721923828,
                0.7733905911445618,
                0.7733905911445618,
                0.786613404750824,
                0.7212266325950623,
                0.7549492120742798,
                0.8352124094963074,
                0.8223521709442139,
                0.8205525875091553,
                0.7390640377998352,
                0.8181396722793579
            ],
            [
                0.7266014814376831,
                0.7812598347663879,
                0.8153349161148071,
                0.7509286403656006,
                0.7517396807670593,
                0.7239802479743958,
                0.7341538667678833,
                0.7583341002464294,
                0.7957006692886353,
                0.6972321271896362,
                0.7663558721542358,
                0.4698145091533661,
                0.7228475213050842,
                0.4698145091533661,
                0.6972321271896362,
                0.6807664036750793,
                0.7803804278373718,
                0.5880204439163208,
                0.7428423762321472,
                0.6045801043510437,
                0.8084625601768494,
                0.7765446305274963,
                0.82024747133255,
                0.8364314436912537,
                0.8325555324554443,
                0.764193594455719,
                0.8009406924247742,
                0.787093460559845,
                0.7497941255569458,
                0.806707501411438,
                0.8073477149009705,
                0.7694851160049438,
                0.8101215958595276,
                0.76065993309021,
                0.686565637588501,
                0.7082564830780029,
                0.7360416650772095,
                0.7130910158157349,
                0.7972983717918396,
                0.6305245161056519,
                0.8046013116836548,
                0.7986161112785339,
                0.7986161112785339,
                0.7746220231056213,
                0.7693502306938171,
                0.8296598792076111,
                0.7651767730712891,
                0.8108912706375122,
                0.7453958988189697,
                0.6390568017959595,
                0.794944167137146
            ],
            [
                0.7221340537071228,
                0.8486226201057434,
                0.8577842712402344,
                0.8136799931526184,
                0.7273578643798828,
                0.6922865509986877,
                0.8716127276420593,
                0.7405515313148499,
                0.901983380317688,
                0.6422387361526489,
                0.7467840909957886,
                0.4004422128200531,
                0.6950015425682068,
                0.4004422128200531,
                0.6422387361526489,
                0.5897881984710693,
                0.7486382722854614,
                0.5066211819648743,
                0.7321507334709167,
                0.522006094455719,
                0.8141916990280151,
                0.8386016488075256,
                0.8435834646224976,
                0.9090820550918579,
                0.8778683543205261,
                0.7441198825836182,
                0.8968861103057861,
                0.7466769814491272,
                0.8589948415756226,
                0.8271374702453613,
                0.8704816699028015,
                0.740450382232666,
                0.8460213541984558,
                0.779536247253418,
                0.6624538898468018,
                0.66346675157547,
                0.7155117988586426,
                0.6827113032341003,
                0.8466735482215881,
                0.5257385969161987,
                0.8005103468894958,
                0.7376977801322937,
                0.7376977801322937,
                0.8782809972763062,
                0.6629958152770996,
                0.887971818447113,
                0.7845932245254517,
                0.8732622861862183,
                0.7040531635284424,
                0.55329430103302,
                0.7868690490722656
            ],
            [
                0.7598453760147095,
                0.7743074893951416,
                0.8119848370552063,
                0.7424958944320679,
                0.7509108781814575,
                0.7335615158081055,
                0.6913717985153198,
                0.7691012620925903,
                0.7464872598648071,
                0.7197983264923096,
                0.7731323838233948,
                0.44559144973754883,
                0.7604540586471558,
                0.44559144973754883,
                0.7197983264923096,
                0.6855785846710205,
                0.7744543552398682,
                0.6226571798324585,
                0.7592863440513611,
                0.5991833806037903,
                0.8032004237174988,
                0.7488234639167786,
                0.8249025344848633,
                0.8124021887779236,
                0.793847918510437,
                0.73324054479599,
                0.7970969080924988,
                0.8069417476654053,
                0.6860144138336182,
                0.8147757053375244,
                0.7589907646179199,
                0.7770459651947021,
                0.7989465594291687,
                0.7940754890441895,
                0.7563788294792175,
                0.6902256608009338,
                0.735270082950592,
                0.7279305458068848,
                0.758186399936676,
                0.650920569896698,
                0.792326807975769,
                0.7991032004356384,
                0.7991032004356384,
                0.736932635307312,
                0.7670111656188965,
                0.8167369961738586,
                0.7570441365242004,
                0.8185673952102661,
                0.7705164551734924,
                0.6497622132301331,
                0.8043025135993958
            ],
            [
                0.7330104112625122,
                0.8415306210517883,
                0.8604947328567505,
                0.7914835810661316,
                0.759711742401123,
                0.7267715930938721,
                0.7836490869522095,
                0.7887371182441711,
                0.8685095906257629,
                0.6078391671180725,
                0.7554548978805542,
                0.3607136011123657,
                0.7284577488899231,
                0.3607136011123657,
                0.6078391671180725,
                0.565125048160553,
                0.7732079029083252,
                0.45962661504745483,
                0.705473005771637,
                0.5005283355712891,
                0.8058053851127625,
                0.7827076315879822,
                0.8484891057014465,
                0.9027363657951355,
                0.8715705275535583,
                0.7901182174682617,
                0.8850452303886414,
                0.7774837613105774,
                0.7822636961936951,
                0.8552337884902954,
                0.8661477565765381,
                0.7831077575683594,
                0.8705575466156006,
                0.7739642262458801,
                0.631851851940155,
                0.7119606137275696,
                0.7319859266281128,
                0.6836299300193787,
                0.8354610204696655,
                0.5747669339179993,
                0.8569789528846741,
                0.7239832878112793,
                0.7239832878112793,
                0.8728490471839905,
                0.6444990634918213,
                0.8763464689254761,
                0.8339741230010986,
                0.8657503128051758,
                0.7315095663070679,
                0.5900961756706238,
                0.8223752975463867
            ],
            [
                0.7650182843208313,
                0.7931519746780396,
                0.8309987783432007,
                0.7478339672088623,
                0.7488772869110107,
                0.7366783618927002,
                0.7277870774269104,
                0.7816116809844971,
                0.7890354990959167,
                0.6874502897262573,
                0.7752540111541748,
                0.4576115310192108,
                0.7553511261940002,
                0.4576115310192108,
                0.6874502897262573,
                0.6427605748176575,
                0.793744683265686,
                0.5688581466674805,
                0.7523943781852722,
                0.6008880138397217,
                0.8319838047027588,
                0.7788259387016296,
                0.82607102394104,
                0.8325052857398987,
                0.8309652209281921,
                0.7503045797348022,
                0.8186516165733337,
                0.8081812858581543,
                0.7440865635871887,
                0.804301917552948,
                0.8010780215263367,
                0.7698707580566406,
                0.8021020889282227,
                0.7461061477661133,
                0.6818162202835083,
                0.705178439617157,
                0.7388300895690918,
                0.7299829721450806,
                0.786937415599823,
                0.6311731934547424,
                0.8042786121368408,
                0.7537887692451477,
                0.7537887692451477,
                0.7618797421455383,
                0.7461109161376953,
                0.8056054711341858,
                0.7691510915756226,
                0.7918168306350708,
                0.7357392311096191,
                0.6455989480018616,
                0.8067233562469482
            ],
            [
                0.7883467674255371,
                0.7793166041374207,
                0.8159160017967224,
                0.7642612457275391,
                0.7700416445732117,
                0.756160318851471,
                0.7065130472183228,
                0.7758456468582153,
                0.7308253049850464,
                0.6850776076316833,
                0.7906467914581299,
                0.47878900170326233,
                0.7902762293815613,
                0.47878900170326233,
                0.6850776076316833,
                0.680474579334259,
                0.7951017022132874,
                0.609832227230072,
                0.755700945854187,
                0.6504319906234741,
                0.8285092711448669,
                0.7490129470825195,
                0.7882987856864929,
                0.7940257787704468,
                0.8010836839675903,
                0.7374309301376343,
                0.8023500442504883,
                0.8232709169387817,
                0.7084923982620239,
                0.7932180762290955,
                0.7468476891517639,
                0.776435136795044,
                0.7935365438461304,
                0.76811283826828,
                0.7266086935997009,
                0.7148617506027222,
                0.7648196220397949,
                0.7653562426567078,
                0.7555644512176514,
                0.6740501523017883,
                0.7793949246406555,
                0.7776567339897156,
                0.7776567339897156,
                0.7304962277412415,
                0.7574032545089722,
                0.7859526872634888,
                0.7423726320266724,
                0.7794089913368225,
                0.7494458556175232,
                0.6797749400138855,
                0.7805737257003784
            ],
            [
                0.7069286108016968,
                0.7726330757141113,
                0.7846255302429199,
                0.7413257360458374,
                0.668786883354187,
                0.6504068374633789,
                0.7215307354927063,
                0.6891221404075623,
                0.784087061882019,
                0.6517269611358643,
                0.738366961479187,
                0.421219140291214,
                0.6857947111129761,
                0.421219140291214,
                0.6517269611358643,
                0.5914998650550842,
                0.7179088592529297,
                0.533151388168335,
                0.7671579718589783,
                0.5179416537284851,
                0.750008225440979,
                0.7406409978866577,
                0.772986114025116,
                0.8250995874404907,
                0.7749990224838257,
                0.7131363749504089,
                0.8459398746490479,
                0.719771683216095,
                0.7144308090209961,
                0.7765910029411316,
                0.7622653245925903,
                0.7092351913452148,
                0.7655395865440369,
                0.7509787678718567,
                0.6975343227386475,
                0.6649121046066284,
                0.7057564854621887,
                0.7036800384521484,
                0.7690730094909668,
                0.5869746804237366,
                0.7324806451797485,
                0.7339422702789307,
                0.7339422702789307,
                0.7938368320465088,
                0.6784414052963257,
                0.8412732481956482,
                0.7398589253425598,
                0.8058760166168213,
                0.6532648205757141,
                0.6106067299842834,
                0.7567711472511292
            ],
            [
                0.7690242528915405,
                0.8630753755569458,
                0.8721199035644531,
                0.8262224793434143,
                0.7724970579147339,
                0.7464335560798645,
                0.8210919499397278,
                0.8052781820297241,
                0.8822723627090454,
                0.6333503127098083,
                0.7760034203529358,
                0.39043694734573364,
                0.740035355091095,
                0.39043694734573364,
                0.6333503127098083,
                0.5986327528953552,
                0.807402491569519,
                0.5036587119102478,
                0.7269433736801147,
                0.5445816516876221,
                0.8439142107963562,
                0.8289027810096741,
                0.854924201965332,
                0.9108097553253174,
                0.8945888876914978,
                0.7912394404411316,
                0.9139584898948669,
                0.8111258745193481,
                0.8190320134162903,
                0.8659290075302124,
                0.880660355091095,
                0.7907111048698425,
                0.8668070435523987,
                0.7747336626052856,
                0.6448333859443665,
                0.7149212956428528,
                0.7359254360198975,
                0.6953853964805603,
                0.8578053116798401,
                0.6039772033691406,
                0.83937668800354,
                0.72365802526474,
                0.72365802526474,
                0.8919560313224792,
                0.6781284213066101,
                0.8802353739738464,
                0.8188331723213196,
                0.8638262152671814,
                0.7354795336723328,
                0.6273564696311951,
                0.8195211887359619
            ],
            [
                0.8125665187835693,
                0.8026188611984253,
                0.8310660123825073,
                0.7912824153900146,
                0.8353018760681152,
                0.8305995464324951,
                0.7125904560089111,
                0.8390181064605713,
                0.7361094951629639,
                0.734653115272522,
                0.856317400932312,
                0.5092917680740356,
                0.8386150598526001,
                0.5092917680740356,
                0.734653115272522,
                0.7197433114051819,
                0.8641414642333984,
                0.6632969975471497,
                0.7547011375427246,
                0.6996406316757202,
                0.8286439180374146,
                0.7470064163208008,
                0.847786545753479,
                0.8166970014572144,
                0.8305680751800537,
                0.7866460680961609,
                0.8115296363830566,
                0.8587262630462646,
                0.7187060713768005,
                0.8580227494239807,
                0.8013017177581787,
                0.8566699624061584,
                0.8403059840202332,
                0.8185751438140869,
                0.7661178112030029,
                0.7635963559150696,
                0.8025223612785339,
                0.7926900386810303,
                0.8005495667457581,
                0.7188937664031982,
                0.8218130469322205,
                0.8154934644699097,
                0.8154934644699097,
                0.7926381230354309,
                0.8008277416229248,
                0.7893008589744568,
                0.7748329639434814,
                0.8235869407653809,
                0.8508349657058716,
                0.7264567613601685,
                0.8432260751724243
            ],
            [
                0.8375901579856873,
                0.9353083372116089,
                0.941911518573761,
                0.91745924949646,
                0.862675666809082,
                0.8540380597114563,
                0.8641456961631775,
                0.8596381545066833,
                0.8805590867996216,
                0.6514759063720703,
                0.8282064199447632,
                0.429448664188385,
                0.8138270974159241,
                0.429448664188385,
                0.6514759063720703,
                0.6472486853599548,
                0.899928092956543,
                0.5728775262832642,
                0.7497896552085876,
                0.6285080909729004,
                0.8663216233253479,
                0.8407076597213745,
                0.8839623928070068,
                0.9474696516990662,
                0.9462249279022217,
                0.8868476152420044,
                0.9305546879768372,
                0.9048057794570923,
                0.8346241116523743,
                0.9119243025779724,
                0.8904575109481812,
                0.8856654167175293,
                0.9034861922264099,
                0.8335942625999451,
                0.6969372034072876,
                0.7720174789428711,
                0.7938597798347473,
                0.7394481301307678,
                0.8936713933944702,
                0.6949467658996582,
                0.8821398615837097,
                0.7868767976760864,
                0.7868767976760864,
                0.8842623233795166,
                0.7189123630523682,
                0.8918665647506714,
                0.8729832172393799,
                0.8933709859848022,
                0.8035351634025574,
                0.7240585088729858,
                0.8619726896286011
            ],
            [
                0.7944614291191101,
                0.7954105734825134,
                0.8162831664085388,
                0.7765746712684631,
                0.7668139934539795,
                0.7493374347686768,
                0.6936463117599487,
                0.7863476276397705,
                0.7382452487945557,
                0.7414810061454773,
                0.8063256740570068,
                0.5145248174667358,
                0.7680467963218689,
                0.5145248174667358,
                0.7414810061454773,
                0.7048903703689575,
                0.8204251527786255,
                0.6737813353538513,
                0.768351674079895,
                0.690662145614624,
                0.8122828006744385,
                0.7417408227920532,
                0.8220142722129822,
                0.8041405081748962,
                0.8222956657409668,
                0.7426738142967224,
                0.8221750259399414,
                0.8314451575279236,
                0.6943170428276062,
                0.821078896522522,
                0.7459855079650879,
                0.7880744934082031,
                0.7983608841896057,
                0.802849292755127,
                0.7586184740066528,
                0.736254096031189,
                0.7742866277694702,
                0.7752746939659119,
                0.7910704016685486,
                0.7399837374687195,
                0.7715470194816589,
                0.7765669822692871,
                0.7765669822692871,
                0.7798677682876587,
                0.7781145572662354,
                0.7842987775802612,
                0.7511304616928101,
                0.8033979535102844,
                0.7747780680656433,
                0.7638235092163086,
                0.832173764705658
            ]
        ],
        [
            [
                0.6546408534049988,
                0.7387357354164124,
                0.8790067434310913,
                0.6882541179656982,
                0.6051569581031799,
                0.7378941774368286,
                0.6964328289031982,
                0.7347424030303955,
                0.6060870885848999,
                0.6832215785980225,
                0.6686910390853882,
                0.6779841780662537,
                0.738510251045227,
                0.8009480834007263,
                0.6983092427253723,
                0.7249002456665039,
                0.7075279951095581,
                0.7358431816101074,
                0.7405369877815247,
                0.6962624788284302,
                0.6851811408996582,
                0.7100462317466736,
                0.7347424030303955,
                0.6757750511169434,
                0.25773295760154724,
                0.7396766543388367,
                0.6928890347480774,
                0.5304489731788635,
                0.5455413460731506,
                0.7347424030303955,
                0.7322827577590942,
                0.7049490213394165,
                0.6478340029716492,
                0.7047039270401001,
                0.7412445545196533,
                0.6855195760726929,
                0.5748956203460693,
                0.5786164402961731,
                0.6964328289031982,
                0.32990947365760803,
                0.6887571811676025,
                0.5222011804580688,
                0.7746489644050598
            ],
            [
                0.6219912171363831,
                0.7334561944007874,
                0.7004411220550537,
                0.7094804048538208,
                0.5417301654815674,
                0.7117096781730652,
                0.715856671333313,
                0.7268503904342651,
                0.5977843403816223,
                0.6607847809791565,
                0.6567617058753967,
                0.6729990839958191,
                0.7614033818244934,
                0.7555297017097473,
                0.6831285357475281,
                0.7121920585632324,
                0.7243606448173523,
                0.755915641784668,
                0.7576948404312134,
                0.7164521217346191,
                0.6179757118225098,
                0.7070874571800232,
                0.7268503904342651,
                0.6717453002929688,
                0.2358708530664444,
                0.7628224492073059,
                0.7127026319503784,
                0.4481535851955414,
                0.48600301146507263,
                0.7268503904342651,
                0.7292723059654236,
                0.7041964530944824,
                0.6576699614524841,
                0.6870751976966858,
                0.7608235478401184,
                0.7070512771606445,
                0.4799933433532715,
                0.5464853048324585,
                0.715856671333313,
                0.3309181332588196,
                0.7043512463569641,
                0.4653361737728119,
                0.7787468433380127
            ],
            [
                0.6605697870254517,
                0.7487752437591553,
                0.8332329392433167,
                0.7462641596794128,
                0.6022922396659851,
                0.7719260454177856,
                0.7531375885009766,
                0.7533934712409973,
                0.6088910698890686,
                0.6699334979057312,
                0.6985066533088684,
                0.7271296977996826,
                0.7805529832839966,
                0.816778838634491,
                0.7315888404846191,
                0.7311114072799683,
                0.7396923899650574,
                0.7740659713745117,
                0.7824066281318665,
                0.7607424855232239,
                0.7010212540626526,
                0.7450269460678101,
                0.7533934712409973,
                0.7178511619567871,
                0.2465030699968338,
                0.7850141525268555,
                0.7529442310333252,
                0.5342682600021362,
                0.5648224353790283,
                0.7533934712409973,
                0.7603371739387512,
                0.7403921484947205,
                0.6838713884353638,
                0.7231187224388123,
                0.7856296896934509,
                0.7499315738677979,
                0.5605736970901489,
                0.6112309098243713,
                0.7531375885009766,
                0.3183695375919342,
                0.7507875561714172,
                0.5279772877693176,
                0.820229709148407
            ],
            [
                0.751641571521759,
                0.8247955441474915,
                0.7986307740211487,
                0.781534731388092,
                0.6439248323440552,
                0.8399751782417297,
                0.7852991223335266,
                0.8116512298583984,
                0.5917291045188904,
                0.7054545879364014,
                0.6814982891082764,
                0.7014705538749695,
                0.8312487006187439,
                0.8561866283416748,
                0.7887827754020691,
                0.7916402816772461,
                0.8083555698394775,
                0.8648813962936401,
                0.8294124603271484,
                0.794583261013031,
                0.7725063562393188,
                0.7985827326774597,
                0.8116512298583984,
                0.7174131870269775,
                0.19059833884239197,
                0.8346655368804932,
                0.7851349115371704,
                0.5545006990432739,
                0.6041183471679688,
                0.8116512298583984,
                0.7964893579483032,
                0.7852943539619446,
                0.7112419009208679,
                0.7634947896003723,
                0.8315002918243408,
                0.7774605751037598,
                0.6035319566726685,
                0.6666751503944397,
                0.7852991223335266,
                0.2888326346874237,
                0.7767744660377502,
                0.5513896942138672,
                0.8545633554458618
            ],
            [
                0.8191224932670593,
                0.9133719205856323,
                0.7490279078483582,
                0.8774639964103699,
                0.7804638147354126,
                0.8665115833282471,
                0.8821195960044861,
                0.9093678593635559,
                0.6692864894866943,
                0.8230204582214355,
                0.7500072121620178,
                0.7489410638809204,
                0.8868780136108398,
                0.8990135192871094,
                0.8195775151252747,
                0.8945804834365845,
                0.884023904800415,
                0.9055771827697754,
                0.8805809020996094,
                0.8837127685546875,
                0.8247276544570923,
                0.8638229370117188,
                0.9093678593635559,
                0.7737097144126892,
                0.2682655453681946,
                0.8851732611656189,
                0.8702442646026611,
                0.6248172521591187,
                0.5875601172447205,
                0.9093678593635559,
                0.8661749362945557,
                0.8778669834136963,
                0.7964260578155518,
                0.7997446060180664,
                0.8751422762870789,
                0.8653844594955444,
                0.747657835483551,
                0.6696772575378418,
                0.8821195960044861,
                0.3863065540790558,
                0.8609958291053772,
                0.6754423379898071,
                0.7754721641540527
            ],
            [
                0.7495055198669434,
                0.8662434220314026,
                0.7649574875831604,
                0.8299752473831177,
                0.6756086945533752,
                0.8356982469558716,
                0.8744689226150513,
                0.8802700042724609,
                0.6378356218338013,
                0.780398964881897,
                0.7312134504318237,
                0.7412005662918091,
                0.8920125365257263,
                0.8475992679595947,
                0.8050858974456787,
                0.8707230091094971,
                0.8714450597763062,
                0.8635430335998535,
                0.8860511183738708,
                0.8340175151824951,
                0.7475794553756714,
                0.8527241349220276,
                0.8802700042724609,
                0.7742892503738403,
                0.26071083545684814,
                0.8849698901176453,
                0.8262360095977783,
                0.5253783464431763,
                0.5311723947525024,
                0.8802700042724609,
                0.8590823411941528,
                0.8395384550094604,
                0.7916309833526611,
                0.7769602537155151,
                0.883694052696228,
                0.8239052891731262,
                0.6191586852073669,
                0.616491973400116,
                0.8744689226150513,
                0.35964107513427734,
                0.8211103677749634,
                0.5673790574073792,
                0.8262292146682739
            ],
            [
                0.6819484829902649,
                0.703883945941925,
                0.8441708087921143,
                0.6644954085350037,
                0.6119391918182373,
                0.737389087677002,
                0.7176350951194763,
                0.7371114492416382,
                0.6578604578971863,
                0.6577669978141785,
                0.7167335748672485,
                0.7291722297668457,
                0.7463247179985046,
                0.7351123094558716,
                0.6569141745567322,
                0.7274812459945679,
                0.7023531198501587,
                0.7147698998451233,
                0.7480949759483337,
                0.6797734498977661,
                0.6844121217727661,
                0.7040022611618042,
                0.7371114492416382,
                0.6995549201965332,
                0.3272995054721832,
                0.7488729357719421,
                0.6718469858169556,
                0.558430552482605,
                0.6045675873756409,
                0.7371114492416382,
                0.718012809753418,
                0.7024700045585632,
                0.6431048512458801,
                0.6616084575653076,
                0.7480723261833191,
                0.6688829660415649,
                0.6025078892707825,
                0.6580156087875366,
                0.7176350951194763,
                0.38551270961761475,
                0.6728499531745911,
                0.5702287554740906,
                0.7189639210700989
            ],
            [
                0.8003944754600525,
                0.887177586555481,
                0.795370876789093,
                0.8527112007141113,
                0.7054166197776794,
                0.855659544467926,
                0.8194851875305176,
                0.8576337695121765,
                0.647404134273529,
                0.8127006888389587,
                0.7344763875007629,
                0.7370388507843018,
                0.8487690687179565,
                0.874085545539856,
                0.7924770712852478,
                0.849627673625946,
                0.8273221254348755,
                0.8884075284004211,
                0.8388609290122986,
                0.8513966798782349,
                0.7822299003601074,
                0.810843288898468,
                0.8576337695121765,
                0.7717670798301697,
                0.27424749732017517,
                0.8341395258903503,
                0.8390161395072937,
                0.5243250727653503,
                0.538659393787384,
                0.8576337695121765,
                0.8238415718078613,
                0.8612293004989624,
                0.7556256651878357,
                0.7599805593490601,
                0.8269773125648499,
                0.8382057547569275,
                0.6753216981887817,
                0.6429454684257507,
                0.8194851875305176,
                0.37273097038269043,
                0.8314592838287354,
                0.574370801448822,
                0.7895553112030029
            ],
            [
                0.8335596323013306,
                0.9039027690887451,
                0.8097896575927734,
                0.8490034341812134,
                0.7589012384414673,
                0.8828860521316528,
                0.8726757764816284,
                0.9051768779754639,
                0.6759321093559265,
                0.8165373802185059,
                0.7520067095756531,
                0.7577483057975769,
                0.8998509049415588,
                0.8839141130447388,
                0.7899607419967651,
                0.8993455171585083,
                0.8703926801681519,
                0.8998019695281982,
                0.8926563858985901,
                0.8509222865104675,
                0.8068789839744568,
                0.8653239607810974,
                0.9051768779754639,
                0.7901667356491089,
                0.2837720811367035,
                0.8910052180290222,
                0.840383768081665,
                0.599729597568512,
                0.5908957719802856,
                0.9051768779754639,
                0.8720605969429016,
                0.8879855275154114,
                0.7680352926254272,
                0.7898226380348206,
                0.8839600086212158,
                0.8367012739181519,
                0.7200214266777039,
                0.6779646277427673,
                0.8726757764816284,
                0.3535292148590088,
                0.8306412696838379,
                0.6493629813194275,
                0.7601632475852966
            ],
            [
                0.7299461960792542,
                0.8006934523582458,
                0.7610471248626709,
                0.8104201555252075,
                0.6199990510940552,
                0.7992881536483765,
                0.7687608599662781,
                0.8132715225219727,
                0.6465084552764893,
                0.7233002781867981,
                0.764298677444458,
                0.784936785697937,
                0.8437405824661255,
                0.8139024972915649,
                0.7060520052909851,
                0.798785388469696,
                0.7845707535743713,
                0.8074195384979248,
                0.8374695181846619,
                0.817659854888916,
                0.6935062408447266,
                0.7756585478782654,
                0.8132715225219727,
                0.7370256781578064,
                0.25428351759910583,
                0.8410941362380981,
                0.8063247799873352,
                0.4984148144721985,
                0.517108678817749,
                0.8132715225219727,
                0.7791333198547363,
                0.8013639450073242,
                0.7082903981208801,
                0.7316715121269226,
                0.8359063267707825,
                0.8082721829414368,
                0.5764207243919373,
                0.6060716509819031,
                0.7687608599662781,
                0.33647674322128296,
                0.8036184310913086,
                0.5373045802116394,
                0.7398940920829773
            ],
            [
                0.6654192805290222,
                0.7422723174095154,
                0.7699988484382629,
                0.7499160170555115,
                0.57440185546875,
                0.7510594725608826,
                0.7646521329879761,
                0.7662957310676575,
                0.6100731492042542,
                0.6516169309616089,
                0.7172868847846985,
                0.7419971823692322,
                0.8070635199546814,
                0.7924521565437317,
                0.7102165222167969,
                0.7462515234947205,
                0.7609051465988159,
                0.7814305424690247,
                0.806911826133728,
                0.762835681438446,
                0.6415937542915344,
                0.7561913728713989,
                0.7662957310676575,
                0.703504741191864,
                0.2292199581861496,
                0.8136168718338013,
                0.7550122737884521,
                0.5084877610206604,
                0.5385515689849854,
                0.7662957310676575,
                0.7631310224533081,
                0.7402656078338623,
                0.6866787075996399,
                0.7042850852012634,
                0.8125054836273193,
                0.7569817900657654,
                0.5342469215393066,
                0.6134189367294312,
                0.7646521329879761,
                0.33347517251968384,
                0.7540004849433899,
                0.5234723091125488,
                0.8194662928581238
            ],
            [
                0.8298001289367676,
                0.8841071128845215,
                0.7774307131767273,
                0.853431761264801,
                0.7534534335136414,
                0.8512102961540222,
                0.8424907326698303,
                0.8875628709793091,
                0.6531080007553101,
                0.8042644262313843,
                0.7652598023414612,
                0.7616811394691467,
                0.8602607250213623,
                0.8714684844017029,
                0.7890296578407288,
                0.8694329261779785,
                0.8451027870178223,
                0.8703237771987915,
                0.852825939655304,
                0.8590832948684692,
                0.8233450651168823,
                0.8365844488143921,
                0.8875628709793091,
                0.7737208008766174,
                0.2674872875213623,
                0.8568512797355652,
                0.8440067768096924,
                0.5872206091880798,
                0.5686336159706116,
                0.8875628709793091,
                0.8362205028533936,
                0.8778190612792969,
                0.7933095097541809,
                0.8010395765304565,
                0.8456436991691589,
                0.8396950960159302,
                0.7274266481399536,
                0.6744681596755981,
                0.8424907326698303,
                0.35610347986221313,
                0.8327432870864868,
                0.6326535940170288,
                0.7420960664749146
            ],
            [
                0.7406846880912781,
                0.8126765489578247,
                0.8472172617912292,
                0.7860392928123474,
                0.62417072057724,
                0.8363732099533081,
                0.7724609971046448,
                0.7879720330238342,
                0.6353910565376282,
                0.717460036277771,
                0.7240197062492371,
                0.7417579889297485,
                0.8202140927314758,
                0.8468642234802246,
                0.738910436630249,
                0.775410532951355,
                0.7900283336639404,
                0.8551570177078247,
                0.8152011632919312,
                0.7930484414100647,
                0.7227024435997009,
                0.7865209579467773,
                0.7879720330238342,
                0.7449880242347717,
                0.23436127603054047,
                0.813454806804657,
                0.7839481830596924,
                0.5166301131248474,
                0.566368043422699,
                0.7879720330238342,
                0.7939286231994629,
                0.8092539310455322,
                0.690710723400116,
                0.7288529276847839,
                0.8109153509140015,
                0.7831614017486572,
                0.5760935544967651,
                0.6458060145378113,
                0.7724609971046448,
                0.3305894732475281,
                0.7777010798454285,
                0.5266157388687134,
                0.8173794150352478
            ],
            [
                0.7702187299728394,
                0.8518369197845459,
                0.7997356653213501,
                0.8477526307106018,
                0.6897463798522949,
                0.8636337518692017,
                0.8430439829826355,
                0.8672011494636536,
                0.6606926321983337,
                0.7585301399230957,
                0.7575085759162903,
                0.7713793516159058,
                0.8999127745628357,
                0.8768305778503418,
                0.7912875413894653,
                0.856916606426239,
                0.8535012006759644,
                0.9129889607429504,
                0.8982662558555603,
                0.8520469665527344,
                0.752263069152832,
                0.8406312465667725,
                0.8672011494636536,
                0.7784067392349243,
                0.22662505507469177,
                0.900182843208313,
                0.8465833067893982,
                0.5846635103225708,
                0.5805623531341553,
                0.8672011494636536,
                0.8381888270378113,
                0.8469189405441284,
                0.7408573627471924,
                0.7902237772941589,
                0.8988813757896423,
                0.8449415564537048,
                0.6452420949935913,
                0.6446713209152222,
                0.8430439829826355,
                0.36456966400146484,
                0.8389264345169067,
                0.609727680683136,
                0.8370518088340759
            ],
            [
                0.7777363061904907,
                0.8567538261413574,
                0.6867070198059082,
                0.8724163174629211,
                0.7590131163597107,
                0.819668173789978,
                0.850900411605835,
                0.8691887855529785,
                0.65552818775177,
                0.816016674041748,
                0.7314305305480957,
                0.7211257219314575,
                0.8422235250473022,
                0.8666374683380127,
                0.8406006097793579,
                0.8596203327178955,
                0.844994068145752,
                0.8512543439865112,
                0.8357875943183899,
                0.8685136437416077,
                0.7921183705329895,
                0.8268865346908569,
                0.8691887855529785,
                0.7720962166786194,
                0.30355849862098694,
                0.8351907134056091,
                0.8675605654716492,
                0.5755062103271484,
                0.5495589971542358,
                0.8691887855529785,
                0.8383886218070984,
                0.8386461734771729,
                0.8079893589019775,
                0.7945955395698547,
                0.8314246535301208,
                0.8598663806915283,
                0.7115932703018188,
                0.6336444020271301,
                0.850900411605835,
                0.42112934589385986,
                0.8535988330841064,
                0.6259787082672119,
                0.7858015894889832
            ],
            [
                0.6708875298500061,
                0.6844143271446228,
                0.7771654725074768,
                0.6934341788291931,
                0.614593505859375,
                0.7594150900840759,
                0.7087643146514893,
                0.7239345908164978,
                0.7341077923774719,
                0.6537942290306091,
                0.8077977299690247,
                0.8306959867477417,
                0.7597148418426514,
                0.7391412854194641,
                0.6598547697067261,
                0.7056072950363159,
                0.7104601860046387,
                0.7062560319900513,
                0.7632014751434326,
                0.7119560837745667,
                0.6744602918624878,
                0.7213082909584045,
                0.7239345908164978,
                0.7415111660957336,
                0.3545036315917969,
                0.7707834243774414,
                0.7029703855514526,
                0.5929657220840454,
                0.6481828093528748,
                0.7239345908164978,
                0.7377290725708008,
                0.7210188508033752,
                0.670072078704834,
                0.7058104872703552,
                0.7737544178962708,
                0.7020145654678345,
                0.590445876121521,
                0.6528744101524353,
                0.7087643146514893,
                0.41148754954338074,
                0.7043498158454895,
                0.6050610542297363,
                0.7315210700035095
            ],
            [
                0.6270892024040222,
                0.6650032997131348,
                0.7814931869506836,
                0.659905731678009,
                0.55940842628479,
                0.7309534549713135,
                0.7060006260871887,
                0.6861228346824646,
                0.6251391768455505,
                0.6187883019447327,
                0.6948477625846863,
                0.7168418169021606,
                0.7290843725204468,
                0.7317620515823364,
                0.6584986448287964,
                0.6669232845306396,
                0.7001973986625671,
                0.7156756520271301,
                0.7303685545921326,
                0.6748282313346863,
                0.6335142254829407,
                0.7086259722709656,
                0.6861228346824646,
                0.7089471817016602,
                0.2831118404865265,
                0.7362799644470215,
                0.6674991250038147,
                0.5324927568435669,
                0.5912879109382629,
                0.6861228346824646,
                0.7218924760818481,
                0.7109261155128479,
                0.6362379193305969,
                0.6742234230041504,
                0.7370949387550354,
                0.665600061416626,
                0.5171396732330322,
                0.6267629861831665,
                0.7060006260871887,
                0.3547547459602356,
                0.6656646728515625,
                0.527721643447876,
                0.7351238131523132
            ],
            [
                0.7674559950828552,
                0.8384751677513123,
                0.6851667165756226,
                0.8658217191696167,
                0.7393178939819336,
                0.8120976686477661,
                0.8400698304176331,
                0.8536475896835327,
                0.6634791493415833,
                0.8018088340759277,
                0.741895318031311,
                0.7311987280845642,
                0.827962338924408,
                0.8593209385871887,
                0.8343196511268616,
                0.8427870273590088,
                0.8326952457427979,
                0.836496114730835,
                0.8235023617744446,
                0.865850567817688,
                0.7772225141525269,
                0.8141579031944275,
                0.8536475896835327,
                0.7752013206481934,
                0.31148597598075867,
                0.8241335153579712,
                0.865578830242157,
                0.5796687602996826,
                0.5657510757446289,
                0.8536475896835327,
                0.8259187340736389,
                0.8279510736465454,
                0.8093318343162537,
                0.7952562570571899,
                0.8217739462852478,
                0.8583200573921204,
                0.6949909925460815,
                0.6502684354782104,
                0.8400698304176331,
                0.434955894947052,
                0.8531280159950256,
                0.6183061003684998,
                0.7946679592132568
            ],
            [
                0.7074772715568542,
                0.7133033871650696,
                0.7756058573722839,
                0.7092284560203552,
                0.6471643447875977,
                0.7771475315093994,
                0.7324513792991638,
                0.7550700306892395,
                0.7412254810333252,
                0.6829546689987183,
                0.829224169254303,
                0.8347264528274536,
                0.7804429531097412,
                0.7467952370643616,
                0.6875207424163818,
                0.7403216361999512,
                0.737460732460022,
                0.7291847467422485,
                0.7841396331787109,
                0.7235478162765503,
                0.6980376243591309,
                0.7435961365699768,
                0.7550700306892395,
                0.7529323697090149,
                0.3587128520011902,
                0.7907837629318237,
                0.7135174870491028,
                0.6148819327354431,
                0.6364262104034424,
                0.7550700306892395,
                0.757080614566803,
                0.7684332132339478,
                0.7064812779426575,
                0.7448621988296509,
                0.7919014692306519,
                0.7129653692245483,
                0.6318584084510803,
                0.6727098226547241,
                0.7324513792991638,
                0.4341205060482025,
                0.7112183570861816,
                0.6335457563400269,
                0.7374516725540161
            ],
            [
                0.7167393565177917,
                0.7614569664001465,
                0.8014337420463562,
                0.7820220589637756,
                0.6335978507995605,
                0.8185620307922363,
                0.777225136756897,
                0.7784160375595093,
                0.6572917103767395,
                0.7093843817710876,
                0.7473612427711487,
                0.7565571665763855,
                0.8029841780662537,
                0.8291052579879761,
                0.7521477341651917,
                0.7579734325408936,
                0.7806569933891296,
                0.8173606395721436,
                0.8008286356925964,
                0.795029878616333,
                0.7168608903884888,
                0.7780475616455078,
                0.7784160375595093,
                0.7695821523666382,
                0.28138431906700134,
                0.8073223233222961,
                0.7873712778091431,
                0.5574477314949036,
                0.5982311367988586,
                0.7784160375595093,
                0.7922117710113525,
                0.8032668828964233,
                0.720389723777771,
                0.7418163418769836,
                0.8044974207878113,
                0.7837522625923157,
                0.5997969508171082,
                0.6716540455818176,
                0.777225136756897,
                0.37475746870040894,
                0.7810405492782593,
                0.5720300674438477,
                0.807762861251831
            ],
            [
                0.7536832094192505,
                0.7623913288116455,
                0.794546365737915,
                0.7613762617111206,
                0.6985998153686523,
                0.8175656199455261,
                0.7734248638153076,
                0.7982676029205322,
                0.720829963684082,
                0.7263399958610535,
                0.8045843243598938,
                0.8076685667037964,
                0.8078830242156982,
                0.8065404891967773,
                0.741127073764801,
                0.7804452180862427,
                0.793819010257721,
                0.7746033072471619,
                0.8063774108886719,
                0.769551694393158,
                0.7598192691802979,
                0.7992727160453796,
                0.7982676029205322,
                0.789715051651001,
                0.35843682289123535,
                0.8113243579864502,
                0.7603162527084351,
                0.6192619800567627,
                0.6401512622833252,
                0.7982676029205322,
                0.8160486817359924,
                0.7991947531700134,
                0.7374841570854187,
                0.7718870043754578,
                0.8112926483154297,
                0.7579297423362732,
                0.6683776378631592,
                0.6800140738487244,
                0.7734248638153076,
                0.41484519839286804,
                0.7550469040870667,
                0.6441146731376648,
                0.7685943245887756
            ],
            [
                0.7439345717430115,
                0.7905082106590271,
                0.8285520672798157,
                0.7878795862197876,
                0.6572635769844055,
                0.8256486058235168,
                0.7841879725456238,
                0.8064073920249939,
                0.6581168174743652,
                0.7322758436203003,
                0.7484369277954102,
                0.7613940238952637,
                0.8258717060089111,
                0.8513450026512146,
                0.7624021172523499,
                0.7875394821166992,
                0.793320894241333,
                0.8380396366119385,
                0.8229203224182129,
                0.8003124594688416,
                0.7337766885757446,
                0.7886061668395996,
                0.8064073920249939,
                0.768711507320404,
                0.27680036425590515,
                0.8284487724304199,
                0.7899457216262817,
                0.5673107504844666,
                0.5933016538619995,
                0.8064073920249939,
                0.8028464317321777,
                0.813610315322876,
                0.7154125571250916,
                0.7626756429672241,
                0.8259321451187134,
                0.7838559150695801,
                0.6167847514152527,
                0.6638075113296509,
                0.7841879725456238,
                0.3616608679294586,
                0.7826549410820007,
                0.5835140347480774,
                0.8166093826293945
            ],
            [
                0.726432740688324,
                0.7162067890167236,
                0.7492267489433289,
                0.7230876088142395,
                0.6556416153907776,
                0.7892464399337769,
                0.7463266849517822,
                0.7572692632675171,
                0.7336084246635437,
                0.6863375306129456,
                0.8187806606292725,
                0.8380919694900513,
                0.786253809928894,
                0.745198667049408,
                0.6869941353797913,
                0.7445397973060608,
                0.7504738569259644,
                0.7322967648506165,
                0.7877351641654968,
                0.733269453048706,
                0.7033013701438904,
                0.7562053203582764,
                0.7572692632675171,
                0.7626978158950806,
                0.35551416873931885,
                0.7931116819381714,
                0.7242615222930908,
                0.6038894653320312,
                0.6334546804428101,
                0.7572692632675171,
                0.7668914794921875,
                0.7666946649551392,
                0.7010997533798218,
                0.7305423617362976,
                0.7928345203399658,
                0.722729504108429,
                0.632127583026886,
                0.6766895651817322,
                0.7463266849517822,
                0.4179377257823944,
                0.722149670124054,
                0.6347923278808594,
                0.7316032648086548
            ],
            [
                0.7169279456138611,
                0.757021427154541,
                0.7785629034042358,
                0.7661194205284119,
                0.6512094140052795,
                0.7953546047210693,
                0.7993488907814026,
                0.7722975015640259,
                0.6597803831100464,
                0.7023152709007263,
                0.7435739636421204,
                0.7711194753646851,
                0.8000890016555786,
                0.8107305765151978,
                0.7462918162345886,
                0.7530822157859802,
                0.7878586649894714,
                0.7924233078956604,
                0.79869145154953,
                0.7788048386573792,
                0.7098520994186401,
                0.7931804656982422,
                0.7722975015640259,
                0.7650428414344788,
                0.28470268845558167,
                0.8068991303443909,
                0.7716705203056335,
                0.5879669785499573,
                0.623531699180603,
                0.7722975015640259,
                0.8026674389839172,
                0.7920845746994019,
                0.7135220766067505,
                0.7452541589736938,
                0.8045465350151062,
                0.7671828269958496,
                0.6050199270248413,
                0.6920145750045776,
                0.7993488907814026,
                0.3702188730239868,
                0.7641782760620117,
                0.6029074192047119,
                0.7991629838943481
            ],
            [
                0.7840631604194641,
                0.852668046951294,
                0.7653619050979614,
                0.8391919136047363,
                0.7588793039321899,
                0.8747325539588928,
                0.8720224499702454,
                0.8836199641227722,
                0.6873412728309631,
                0.7965438961982727,
                0.7907111644744873,
                0.7894699573516846,
                0.8731319308280945,
                0.8533506989479065,
                0.8097063899040222,
                0.863351047039032,
                0.873674750328064,
                0.8704901337623596,
                0.8689154386520386,
                0.8467508554458618,
                0.8219983577728271,
                0.8654708862304688,
                0.8836199641227722,
                0.8272637128829956,
                0.2982264757156372,
                0.8756524324417114,
                0.8381061553955078,
                0.6340422034263611,
                0.6293482780456543,
                0.8836199641227722,
                0.8708356618881226,
                0.8827847242355347,
                0.8199694752693176,
                0.8240143656730652,
                0.870958685874939,
                0.8318859934806824,
                0.7166634798049927,
                0.6798227429389954,
                0.8720224499702454,
                0.39414161443710327,
                0.8269315958023071,
                0.6722894310951233,
                0.7963365316390991
            ],
            [
                0.724794328212738,
                0.7632139921188354,
                0.8106881976127625,
                0.7746570110321045,
                0.6838624477386475,
                0.8044875860214233,
                0.781803548336029,
                0.8019587397575378,
                0.7159784436225891,
                0.7275780439376831,
                0.811029314994812,
                0.8198161125183105,
                0.8075383901596069,
                0.804480254650116,
                0.730300784111023,
                0.7763006091117859,
                0.7740607857704163,
                0.7755966782569885,
                0.8069405555725098,
                0.788996696472168,
                0.7406982183456421,
                0.7722182273864746,
                0.8019587397575378,
                0.7996522784233093,
                0.3553943336009979,
                0.8170976042747498,
                0.7780851721763611,
                0.6180375814437866,
                0.6461962461471558,
                0.8019587397575378,
                0.7912672758102417,
                0.8063888549804688,
                0.7497793436050415,
                0.7576674222946167,
                0.8139071464538574,
                0.7751909494400024,
                0.655073881149292,
                0.688660740852356,
                0.781803548336029,
                0.41656753420829773,
                0.7754321098327637,
                0.6451802849769592,
                0.7724465727806091
            ],
            [
                0.7607097625732422,
                0.7915834784507751,
                0.7804670333862305,
                0.8009745478630066,
                0.7207673788070679,
                0.8049246668815613,
                0.8167640566825867,
                0.8342607617378235,
                0.7217103242874146,
                0.7470820546150208,
                0.8056051731109619,
                0.8127464652061462,
                0.8333871960639954,
                0.8190779685974121,
                0.729557991027832,
                0.8220089077949524,
                0.7920469641685486,
                0.7760918140411377,
                0.8337521553039551,
                0.8132187128067017,
                0.7412893772125244,
                0.7893645167350769,
                0.8342607617378235,
                0.7856516242027283,
                0.3597239851951599,
                0.839346170425415,
                0.8043360710144043,
                0.6275622844696045,
                0.635682225227356,
                0.8342607617378235,
                0.8047298192977905,
                0.8077228665351868,
                0.7614842057228088,
                0.7543395161628723,
                0.8366509079933167,
                0.8038702011108398,
                0.6894598603248596,
                0.6924864649772644,
                0.8167640566825867,
                0.4085286855697632,
                0.8047935962677002,
                0.663764476776123,
                0.7341488003730774
            ],
            [
                0.7472126483917236,
                0.8216918706893921,
                0.8450371026992798,
                0.8078528642654419,
                0.6827802658081055,
                0.8471953868865967,
                0.8108375072479248,
                0.8337644934654236,
                0.6662870645523071,
                0.7624056935310364,
                0.7746326923370361,
                0.7841327786445618,
                0.8254976272583008,
                0.8536689281463623,
                0.7739846110343933,
                0.8169600367546082,
                0.8037723302841187,
                0.8467926383018494,
                0.8229440450668335,
                0.8177255988121033,
                0.7655433416366577,
                0.7968500852584839,
                0.8337644934654236,
                0.7848917841911316,
                0.29649490118026733,
                0.827505350112915,
                0.8102755546569824,
                0.5759667158126831,
                0.6030985713005066,
                0.8337644934654236,
                0.8126341700553894,
                0.8310614824295044,
                0.758996307849884,
                0.7675600051879883,
                0.8233309984207153,
                0.80613774061203,
                0.6402024626731873,
                0.6739190816879272,
                0.8108375072479248,
                0.37296563386917114,
                0.8063331246376038,
                0.5926517844200134,
                0.8102705478668213
            ],
            [
                0.7706098556518555,
                0.8451889157295227,
                0.7384288311004639,
                0.8271056413650513,
                0.7336934208869934,
                0.8453998565673828,
                0.8208637237548828,
                0.8756486177444458,
                0.688346803188324,
                0.8067989349365234,
                0.7894410490989685,
                0.783336341381073,
                0.8587988615036011,
                0.8321141004562378,
                0.7706896066665649,
                0.8543114066123962,
                0.8323917984962463,
                0.826680600643158,
                0.8536285758018494,
                0.8342563509941101,
                0.7950294017791748,
                0.819829523563385,
                0.8756486177444458,
                0.794990062713623,
                0.3160386383533478,
                0.8608337044715881,
                0.8237696290016174,
                0.5981049537658691,
                0.5705574750900269,
                0.8756486177444458,
                0.8328475952148438,
                0.8625870943069458,
                0.827074408531189,
                0.7979385256767273,
                0.8537437915802002,
                0.8185991644859314,
                0.6975470781326294,
                0.6493140459060669,
                0.8208637237548828,
                0.39251869916915894,
                0.8158045411109924,
                0.640539288520813,
                0.7479397654533386
            ],
            [
                0.797475278377533,
                0.8643302321434021,
                0.7598285675048828,
                0.8400303721427917,
                0.7697249054908752,
                0.825520932674408,
                0.8422515392303467,
                0.8898351192474365,
                0.7078524827957153,
                0.8105601072311401,
                0.796741783618927,
                0.7854863405227661,
                0.8629443645477295,
                0.8493305444717407,
                0.7599297761917114,
                0.8775126338005066,
                0.8372629880905151,
                0.8240000009536743,
                0.8588452935218811,
                0.8454247117042542,
                0.790979266166687,
                0.8269411325454712,
                0.8898351192474365,
                0.7921707630157471,
                0.3606776297092438,
                0.8636350035667419,
                0.8354809284210205,
                0.6282464861869812,
                0.5983771681785583,
                0.8898351192474365,
                0.8455596566200256,
                0.8622061014175415,
                0.8012310862541199,
                0.7905011773109436,
                0.8567601442337036,
                0.8313090801239014,
                0.7342872619628906,
                0.6603325605392456,
                0.8422515392303467,
                0.41821470856666565,
                0.8287404179573059,
                0.6772450804710388,
                0.724613606929779
            ],
            [
                0.7636139392852783,
                0.8354843854904175,
                0.8336881995201111,
                0.8301358819007874,
                0.7411715984344482,
                0.8466273546218872,
                0.8422366380691528,
                0.8556770086288452,
                0.685190737247467,
                0.7728480696678162,
                0.7755429744720459,
                0.7789584994316101,
                0.837986171245575,
                0.8749204277992249,
                0.8131089210510254,
                0.8372632265090942,
                0.8309160470962524,
                0.8380022048950195,
                0.8367534875869751,
                0.8431084156036377,
                0.7850632667541504,
                0.827101469039917,
                0.8556770086288452,
                0.777113676071167,
                0.31138309836387634,
                0.8434911966323853,
                0.8365355730056763,
                0.6454041004180908,
                0.63433438539505,
                0.8556770086288452,
                0.8402871489524841,
                0.8272769451141357,
                0.778756856918335,
                0.7946147918701172,
                0.8412957191467285,
                0.8297227621078491,
                0.7038417458534241,
                0.691337525844574,
                0.8422366380691528,
                0.39018261432647705,
                0.8287050724029541,
                0.6622024774551392,
                0.8225849866867065
            ],
            [
                0.7740122675895691,
                0.8156687021255493,
                0.7530863285064697,
                0.8020017743110657,
                0.7285010814666748,
                0.8282484412193298,
                0.8298475742340088,
                0.8670063018798828,
                0.7136538028717041,
                0.7740784883499146,
                0.7925209403038025,
                0.7896476984024048,
                0.8645205497741699,
                0.8178819417953491,
                0.7515928745269775,
                0.845702052116394,
                0.8356791734695435,
                0.8134970664978027,
                0.8633644580841064,
                0.8143636584281921,
                0.7685510516166687,
                0.830070436000824,
                0.8670063018798828,
                0.7928510308265686,
                0.3248180150985718,
                0.8717305064201355,
                0.8017052412033081,
                0.6270701289176941,
                0.6046003103256226,
                0.8670063018798828,
                0.8377854824066162,
                0.8490109443664551,
                0.8010990619659424,
                0.7811723351478577,
                0.8659513592720032,
                0.7976133227348328,
                0.6991448998451233,
                0.689030647277832,
                0.8298475742340088,
                0.4044623374938965,
                0.795048713684082,
                0.6676043272018433,
                0.7386564016342163
            ],
            [
                0.7307450175285339,
                0.7711567878723145,
                0.741486668586731,
                0.7701922059059143,
                0.7291547656059265,
                0.7774194478988647,
                0.8000181317329407,
                0.8270949125289917,
                0.7278628945350647,
                0.7302444577217102,
                0.8100335597991943,
                0.8076598644256592,
                0.8131684064865112,
                0.7968535423278809,
                0.729825496673584,
                0.8009300231933594,
                0.7992477416992188,
                0.7418240904808044,
                0.8153993487358093,
                0.7894452214241028,
                0.7418710589408875,
                0.7994548082351685,
                0.8270949125289917,
                0.7716124653816223,
                0.36499619483947754,
                0.8289321064949036,
                0.7748708724975586,
                0.6632179021835327,
                0.6362088918685913,
                0.8270949125289917,
                0.8127096891403198,
                0.8029574155807495,
                0.7869348526000977,
                0.765338659286499,
                0.8245713710784912,
                0.7700259685516357,
                0.7119357585906982,
                0.6892374753952026,
                0.8000181317329407,
                0.40924927592277527,
                0.7717394232749939,
                0.6981490850448608,
                0.7233709096908569
            ],
            [
                0.7763186693191528,
                0.8449578285217285,
                0.8459211587905884,
                0.8377460241317749,
                0.740418553352356,
                0.8611793518066406,
                0.8423900604248047,
                0.8621118068695068,
                0.690253734588623,
                0.8047930598258972,
                0.7725329995155334,
                0.767607569694519,
                0.8421535491943359,
                0.8925116658210754,
                0.8225654363632202,
                0.84119713306427,
                0.8448426127433777,
                0.8574624061584473,
                0.8387004137039185,
                0.84796142578125,
                0.8087226748466492,
                0.8407029509544373,
                0.8621118068695068,
                0.8051565885543823,
                0.3252530097961426,
                0.8445917367935181,
                0.8394260406494141,
                0.6231358051300049,
                0.6217531561851501,
                0.8621118068695068,
                0.8602431416511536,
                0.8524136543273926,
                0.8023594617843628,
                0.8024771809577942,
                0.8403465151786804,
                0.8326351642608643,
                0.7042020559310913,
                0.6948266625404358,
                0.8423900604248047,
                0.4032362401485443,
                0.8307682275772095,
                0.6436707377433777,
                0.8439306616783142
            ],
            [
                0.7466385960578918,
                0.7531396746635437,
                0.8240047097206116,
                0.7407141923904419,
                0.6860409379005432,
                0.8170773983001709,
                0.7516977787017822,
                0.7784031629562378,
                0.7315291166305542,
                0.7323082685470581,
                0.7820168733596802,
                0.7817512154579163,
                0.7926210761070251,
                0.7915032505989075,
                0.720892071723938,
                0.7590861916542053,
                0.7743673920631409,
                0.7628896236419678,
                0.78839111328125,
                0.7491719126701355,
                0.7454817295074463,
                0.7797896862030029,
                0.7784031629562378,
                0.787458598613739,
                0.3607054650783539,
                0.792055606842041,
                0.7356504201889038,
                0.5966753363609314,
                0.6297481060028076,
                0.7784031629562378,
                0.7983626127243042,
                0.7978351712226868,
                0.7165185213088989,
                0.7472261786460876,
                0.7906498312950134,
                0.734852135181427,
                0.6478085517883301,
                0.6795108914375305,
                0.7516977787017822,
                0.42478182911872864,
                0.7312058806419373,
                0.6247445344924927,
                0.7695537209510803
            ],
            [
                0.7105144262313843,
                0.7601915001869202,
                0.7955695390701294,
                0.7787452340126038,
                0.6542479991912842,
                0.8019475340843201,
                0.7815136313438416,
                0.7815356850624084,
                0.6674467921257019,
                0.7106154561042786,
                0.7527602314949036,
                0.769138753414154,
                0.8070035576820374,
                0.8222534656524658,
                0.7613003253936768,
                0.7609729766845703,
                0.7770150899887085,
                0.7964161038398743,
                0.8054826855659485,
                0.7893256545066833,
                0.7069565057754517,
                0.7843391299247742,
                0.7815356850624084,
                0.7774487733840942,
                0.31739217042922974,
                0.8105544447898865,
                0.7821764945983887,
                0.5809342265129089,
                0.6104972958564758,
                0.7815356850624084,
                0.8026906251907349,
                0.7833454608917236,
                0.7232977151870728,
                0.7553317546844482,
                0.8114349842071533,
                0.7789188623428345,
                0.610706627368927,
                0.6708928942680359,
                0.7815136313438416,
                0.3856055736541748,
                0.7778916358947754,
                0.5920631885528564,
                0.8219482898712158
            ],
            [
                0.724311351776123,
                0.728577733039856,
                0.7664729356765747,
                0.744010329246521,
                0.6587076187133789,
                0.7882252931594849,
                0.7385287284851074,
                0.7617826461791992,
                0.7288322448730469,
                0.700361967086792,
                0.8103320002555847,
                0.8144034743309021,
                0.7795038223266602,
                0.7740940451622009,
                0.7033703923225403,
                0.7419098615646362,
                0.7467821836471558,
                0.7373368740081787,
                0.7812539935112,
                0.7534774541854858,
                0.7220077514648438,
                0.7570779323577881,
                0.7617826461791992,
                0.7612303495407104,
                0.3663412928581238,
                0.7879549264907837,
                0.7440918684005737,
                0.6063050031661987,
                0.6406470537185669,
                0.7617826461791992,
                0.7733743786811829,
                0.7648525238037109,
                0.706416130065918,
                0.7437781691551208,
                0.7865644097328186,
                0.7445541620254517,
                0.642015814781189,
                0.6804679036140442,
                0.7385287284851074,
                0.43491047620773315,
                0.7429049611091614,
                0.632436990737915,
                0.7491507530212402
            ],
            [
                0.6914656162261963,
                0.7554183006286621,
                0.8618061542510986,
                0.7677390575408936,
                0.6001178622245789,
                0.8097037672996521,
                0.7472253441810608,
                0.7643834352493286,
                0.6355879902839661,
                0.6886407732963562,
                0.7270252108573914,
                0.7478154897689819,
                0.7987152338027954,
                0.8250855803489685,
                0.7242586612701416,
                0.7455777525901794,
                0.7556052803993225,
                0.8056726455688477,
                0.7960606217384338,
                0.7774924635887146,
                0.6851783990859985,
                0.7596777677536011,
                0.7643834352493286,
                0.7405911087989807,
                0.27419447898864746,
                0.7984639406204224,
                0.7688620090484619,
                0.5264405012130737,
                0.5760883092880249,
                0.7643834352493286,
                0.774163007736206,
                0.7689972519874573,
                0.6804736256599426,
                0.7209601998329163,
                0.7987877130508423,
                0.7691483497619629,
                0.5568161010742188,
                0.6462528109550476,
                0.7472253441810608,
                0.34998539090156555,
                0.7676565647125244,
                0.5277661681175232,
                0.8156202435493469
            ],
            [
                0.7376196980476379,
                0.8462693095207214,
                0.7792631983757019,
                0.8562031984329224,
                0.6533686518669128,
                0.8567836880683899,
                0.8205372095108032,
                0.8543537259101868,
                0.6219521760940552,
                0.7374653220176697,
                0.7347398996353149,
                0.7546759247779846,
                0.8822178244590759,
                0.8724760413169861,
                0.7823490500450134,
                0.8385965824127197,
                0.831311821937561,
                0.9062087535858154,
                0.8781440258026123,
                0.8611257672309875,
                0.7300024628639221,
                0.8149012327194214,
                0.8543537259101868,
                0.7489041090011597,
                0.19726625084877014,
                0.881121039390564,
                0.8535842895507812,
                0.5322518944740295,
                0.5316454768180847,
                0.8543537259101868,
                0.8137444853782654,
                0.8277941942214966,
                0.7279478311538696,
                0.7627618312835693,
                0.8780189752578735,
                0.8532195091247559,
                0.6040454506874084,
                0.6076413989067078,
                0.8205372095108032,
                0.3191970884799957,
                0.8495336771011353,
                0.5560402870178223,
                0.8276759386062622
            ],
            [
                0.7752774953842163,
                0.8398339152336121,
                0.7025758624076843,
                0.8659579157829285,
                0.7507784962654114,
                0.8156210780143738,
                0.8521571159362793,
                0.8506554961204529,
                0.6663970351219177,
                0.7970070838928223,
                0.7490970492362976,
                0.7433202266693115,
                0.836400032043457,
                0.8642594814300537,
                0.8365421891212463,
                0.8411074876785278,
                0.8466233611106873,
                0.8359345197677612,
                0.8337238430976868,
                0.8655357956886292,
                0.7682427167892456,
                0.8367413282394409,
                0.8506554961204529,
                0.781251072883606,
                0.31176865100860596,
                0.8323270082473755,
                0.8645491600036621,
                0.5910783410072327,
                0.5762689113616943,
                0.8506554961204529,
                0.8429970145225525,
                0.837462306022644,
                0.8128849864006042,
                0.7985526919364929,
                0.8319429755210876,
                0.8578366041183472,
                0.7014251351356506,
                0.6689644455909729,
                0.8521571159362793,
                0.4267127513885498,
                0.8521597981452942,
                0.6359836459159851,
                0.8002604246139526
            ],
            [
                0.7498834729194641,
                0.7458791732788086,
                0.7983954548835754,
                0.7319839000701904,
                0.657539427280426,
                0.7938798069953918,
                0.7569547295570374,
                0.7450323104858398,
                0.717313826084137,
                0.6856118440628052,
                0.7821885943412781,
                0.7879475355148315,
                0.7762779593467712,
                0.768679678440094,
                0.7048578262329102,
                0.7258217334747314,
                0.7729092836380005,
                0.7442005276679993,
                0.7748022079467773,
                0.7452075481414795,
                0.7196091413497925,
                0.7813889980316162,
                0.7450323104858398,
                0.752750813961029,
                0.32724905014038086,
                0.7833110094070435,
                0.731132984161377,
                0.5869490504264832,
                0.6287398934364319,
                0.7450323104858398,
                0.7922092080116272,
                0.7983309626579285,
                0.7035768628120422,
                0.7427389621734619,
                0.7777082324028015,
                0.7301145792007446,
                0.6381183862686157,
                0.6919506788253784,
                0.7569547295570374,
                0.3994680643081665,
                0.729218602180481,
                0.6223533749580383,
                0.7483469247817993
            ],
            [
                0.6766721606254578,
                0.7297433614730835,
                0.8481695055961609,
                0.7170668840408325,
                0.5767561793327332,
                0.7604185342788696,
                0.7124002575874329,
                0.7191208004951477,
                0.6319489479064941,
                0.6575409770011902,
                0.7103081941604614,
                0.7220918536186218,
                0.7521732449531555,
                0.7927815914154053,
                0.6730917692184448,
                0.7008792757987976,
                0.7245826721191406,
                0.7514610886573792,
                0.74976646900177,
                0.726238489151001,
                0.6574484705924988,
                0.7330638766288757,
                0.7191208004951477,
                0.7172884941101074,
                0.27024003863334656,
                0.7519622445106506,
                0.716931164264679,
                0.5051597952842712,
                0.5578356385231018,
                0.7191208004951477,
                0.7543771862983704,
                0.7521370053291321,
                0.6440653800964355,
                0.6997507810592651,
                0.7509024143218994,
                0.7175631523132324,
                0.5347267389297485,
                0.6225989460945129,
                0.7124002575874329,
                0.33730438351631165,
                0.7151578068733215,
                0.5097522735595703,
                0.7635689377784729
            ],
            [
                0.7143877744674683,
                0.7261359095573425,
                0.7546496987342834,
                0.7395898103713989,
                0.6530965566635132,
                0.7671864032745361,
                0.7450112104415894,
                0.7622592449188232,
                0.681496798992157,
                0.6728377342224121,
                0.7832882404327393,
                0.787647545337677,
                0.7812378406524658,
                0.7679755687713623,
                0.7015902996063232,
                0.739635169506073,
                0.7604194283485413,
                0.7184091806411743,
                0.7811967134475708,
                0.7520254254341125,
                0.6932073831558228,
                0.7760094404220581,
                0.7622592449188232,
                0.7496980428695679,
                0.32174643874168396,
                0.7878957390785217,
                0.7396290302276611,
                0.5723250508308411,
                0.5977824330329895,
                0.7622592449188232,
                0.7826786041259766,
                0.7628192901611328,
                0.7290153503417969,
                0.7180182933807373,
                0.7853174805641174,
                0.7382088899612427,
                0.6251771450042725,
                0.6724074482917786,
                0.7450112104415894,
                0.35859495401382446,
                0.7384456396102905,
                0.612082302570343,
                0.7384328842163086
            ],
            [
                0.6849805116653442,
                0.7256449460983276,
                0.8105876445770264,
                0.745575487613678,
                0.5638733506202698,
                0.7693376541137695,
                0.7387635707855225,
                0.7592714428901672,
                0.6146501302719116,
                0.6565515995025635,
                0.7009736895561218,
                0.7112143039703369,
                0.7987316846847534,
                0.7995504140853882,
                0.6937869191169739,
                0.7389054894447327,
                0.7535437941551208,
                0.7868600487709045,
                0.7958139777183533,
                0.7548775672912598,
                0.6577492952346802,
                0.7508365511894226,
                0.7592714428901672,
                0.7086673378944397,
                0.21183446049690247,
                0.8021714091300964,
                0.7450648546218872,
                0.49204230308532715,
                0.5355195999145508,
                0.7592714428901672,
                0.7577213644981384,
                0.7614229917526245,
                0.6559469699859619,
                0.7048669457435608,
                0.7987698912620544,
                0.7477530837059021,
                0.523003339767456,
                0.612114667892456,
                0.7387635707855225,
                0.3360096514225006,
                0.7429265379905701,
                0.5056226253509521,
                0.7944740653038025
            ],
            [
                0.7251176834106445,
                0.7355738282203674,
                0.8009111881256104,
                0.7560253739356995,
                0.6336937546730042,
                0.8040338158607483,
                0.7410885691642761,
                0.7684880495071411,
                0.7144332528114319,
                0.6846636533737183,
                0.8290995359420776,
                0.833928108215332,
                0.7827454805374146,
                0.7785714864730835,
                0.7022829651832581,
                0.7449248433113098,
                0.7584101557731628,
                0.7375317811965942,
                0.7794184684753418,
                0.7682687044143677,
                0.720757007598877,
                0.7629344463348389,
                0.7684880495071411,
                0.7647289037704468,
                0.3314744532108307,
                0.7884087562561035,
                0.7547634840011597,
                0.556100070476532,
                0.6040802597999573,
                0.7684880495071411,
                0.780463457107544,
                0.7660942077636719,
                0.7134309411048889,
                0.7234978675842285,
                0.7833658456802368,
                0.7568266987800598,
                0.6082233786582947,
                0.665456235408783,
                0.7410885691642761,
                0.3897044062614441,
                0.7585141062736511,
                0.5822054147720337,
                0.7574219107627869
            ],
            [
                0.7419164180755615,
                0.7525307536125183,
                0.7734218835830688,
                0.7461059093475342,
                0.7019255757331848,
                0.8029239773750305,
                0.7557250261306763,
                0.7854917645454407,
                0.6862211227416992,
                0.7219079732894897,
                0.7948645949363708,
                0.7841535210609436,
                0.7814475893974304,
                0.7846431732177734,
                0.7415696978569031,
                0.7598713636398315,
                0.78227299451828,
                0.7399592995643616,
                0.7789929509162903,
                0.7580859661102295,
                0.7697305679321289,
                0.7926691770553589,
                0.7854917645454407,
                0.796424925327301,
                0.37579619884490967,
                0.7881807684898376,
                0.7458053231239319,
                0.6097558736801147,
                0.6351779103279114,
                0.7854917645454407,
                0.8102323412895203,
                0.7858476638793945,
                0.7712181806564331,
                0.7388306856155396,
                0.7820854187011719,
                0.741544246673584,
                0.6752996444702148,
                0.6928762793540955,
                0.7557250261306763,
                0.39569419622421265,
                0.7420217990875244,
                0.6430572271347046,
                0.7491852641105652
            ],
            [
                0.6260273456573486,
                0.6570168137550354,
                0.7322297096252441,
                0.6768442392349243,
                0.5548571348190308,
                0.6835892200469971,
                0.691166877746582,
                0.6811909079551697,
                0.6198360323905945,
                0.6034988760948181,
                0.7235162854194641,
                0.7314099073410034,
                0.7272538542747498,
                0.7172819375991821,
                0.6393795609474182,
                0.6642255187034607,
                0.6810081601142883,
                0.6889809370040894,
                0.7273305058479309,
                0.6870080232620239,
                0.6048710346221924,
                0.6853724122047424,
                0.6811909079551697,
                0.7028120160102844,
                0.30222225189208984,
                0.7344401478767395,
                0.6818023324012756,
                0.5175170302391052,
                0.5695414543151855,
                0.6811909079551697,
                0.7063647508621216,
                0.6994138360023499,
                0.6257795691490173,
                0.6661503911018372,
                0.7349157333374023,
                0.6820975542068481,
                0.4984205663204193,
                0.6160958409309387,
                0.691166877746582,
                0.37327855825424194,
                0.6798883676528931,
                0.5124478936195374,
                0.7014231085777283
            ],
            [
                0.6963750123977661,
                0.7469338178634644,
                0.8546476364135742,
                0.7581411004066467,
                0.5955358743667603,
                0.7889187335968018,
                0.7604062557220459,
                0.7801224589347839,
                0.6324904561042786,
                0.6791003942489624,
                0.7214529514312744,
                0.7291353940963745,
                0.7991814613342285,
                0.8193802833557129,
                0.7186452150344849,
                0.7622182369232178,
                0.763289213180542,
                0.7830266952514648,
                0.7968447804450989,
                0.7687411904335022,
                0.6868034601211548,
                0.7580322027206421,
                0.7801224589347839,
                0.734421968460083,
                0.2501922845840454,
                0.8028293251991272,
                0.7603228092193604,
                0.5203045010566711,
                0.558515191078186,
                0.7801224589347839,
                0.7705625295639038,
                0.7720574736595154,
                0.6894086003303528,
                0.7195704579353333,
                0.7997572422027588,
                0.7609739899635315,
                0.5510555505752563,
                0.6322560906410217,
                0.7604062557220459,
                0.347920298576355,
                0.7585030198097229,
                0.5271415710449219,
                0.7911831140518188
            ],
            [
                0.7727802395820618,
                0.8246063590049744,
                0.7458062767982483,
                0.8102462291717529,
                0.7774078249931335,
                0.8173448443412781,
                0.8305888175964355,
                0.8415613174438477,
                0.7219759225845337,
                0.7937741875648499,
                0.8054623603820801,
                0.8033942580223083,
                0.827514111995697,
                0.8285831212997437,
                0.7724733948707581,
                0.825559139251709,
                0.8264041543006897,
                0.786881685256958,
                0.825080394744873,
                0.8195109367370605,
                0.7876339554786682,
                0.8211939930915833,
                0.8415613174438477,
                0.8044928908348083,
                0.3911544382572174,
                0.8306571245193481,
                0.8090261816978455,
                0.6628139615058899,
                0.6351029276847839,
                0.8415613174438477,
                0.8401109576225281,
                0.8454294204711914,
                0.813026487827301,
                0.8097224235534668,
                0.8269596099853516,
                0.8020553588867188,
                0.7442383766174316,
                0.6929733753204346,
                0.8305888175964355,
                0.4333009123802185,
                0.8015109300613403,
                0.7032988667488098,
                0.7345306873321533
            ],
            [
                0.7629354000091553,
                0.8463315963745117,
                0.8753102421760559,
                0.8396358489990234,
                0.6961801648139954,
                0.8542614579200745,
                0.8258166313171387,
                0.8405078649520874,
                0.6551945209503174,
                0.7663183808326721,
                0.750284731388092,
                0.7667387127876282,
                0.8478105068206787,
                0.8967483043670654,
                0.8022205829620361,
                0.8225352764129639,
                0.824176013469696,
                0.8619376420974731,
                0.8455986976623535,
                0.8495726585388184,
                0.783157229423523,
                0.8266593813896179,
                0.8405078649520874,
                0.7856956720352173,
                0.29170864820480347,
                0.8468433022499084,
                0.8413591384887695,
                0.5817864537239075,
                0.6132910847663879,
                0.8405078649520874,
                0.8431673049926758,
                0.8329564332962036,
                0.7553121447563171,
                0.7690040469169617,
                0.8456035256385803,
                0.8379237055778503,
                0.6556627154350281,
                0.6859806180000305,
                0.8258166313171387,
                0.3522569537162781,
                0.8357531428337097,
                0.5932868719100952,
                0.8561571836471558
            ],
            [
                0.7067965865135193,
                0.7487876415252686,
                0.736214816570282,
                0.7595213055610657,
                0.701863169670105,
                0.7555755376815796,
                0.7862646579742432,
                0.7981007099151611,
                0.7341679930686951,
                0.721337616443634,
                0.8089691400527954,
                0.8152249455451965,
                0.7961733937263489,
                0.7778751254081726,
                0.7171751856803894,
                0.7777852416038513,
                0.7564570307731628,
                0.7179358601570129,
                0.7990570664405823,
                0.7770445942878723,
                0.7158218622207642,
                0.7562289237976074,
                0.7981007099151611,
                0.7649709582328796,
                0.3987886607646942,
                0.8097155094146729,
                0.7690794467926025,
                0.6431312561035156,
                0.6543079614639282,
                0.7981007099151611,
                0.7817245125770569,
                0.7650918364524841,
                0.7609724998474121,
                0.7418802380561829,
                0.808242917060852,
                0.764909565448761,
                0.6782961487770081,
                0.6813496351242065,
                0.7862646579742432,
                0.43666210770606995,
                0.7687600255012512,
                0.6743003726005554,
                0.7316710948944092
            ]
        ],
        [
            [
                0.7801430225372314,
                0.6383808255195618,
                0.7123637199401855,
                0.702176034450531,
                0.8213163018226624,
                0.7225475311279297,
                0.7589827179908752,
                0.7714756727218628,
                0.733325719833374,
                0.752705991268158,
                0.8040271997451782,
                0.6983410716056824,
                0.7527472376823425,
                0.8215562105178833,
                0.7183504700660706,
                0.7329203486442566,
                0.7980931401252747,
                0.7120627164840698,
                0.6982172131538391,
                0.7421020269393921,
                0.7438026070594788,
                0.7543728351593018,
                0.7383267283439636,
                0.7954303026199341,
                0.7085986137390137,
                0.6921182870864868,
                0.759195864200592,
                0.8346174955368042,
                0.7510565519332886,
                0.7104990482330322,
                0.7116281986236572,
                0.7241640090942383,
                0.7090924382209778,
                0.7740060687065125
            ],
            [
                0.7527581453323364,
                0.6638534069061279,
                0.7238661050796509,
                0.7359722852706909,
                0.7826288938522339,
                0.764870285987854,
                0.8577714562416077,
                0.8102114796638489,
                0.764125645160675,
                0.8539202809333801,
                0.7151018381118774,
                0.6985479593276978,
                0.8450842499732971,
                0.8027740120887756,
                0.7643819451332092,
                0.8469811081886292,
                0.7870736718177795,
                0.7903069853782654,
                0.8341603875160217,
                0.7658913135528564,
                0.8783379197120667,
                0.6182805299758911,
                0.8694318532943726,
                0.789304256439209,
                0.8280903697013855,
                0.6890619993209839,
                0.8463900089263916,
                0.7642751336097717,
                0.7971752882003784,
                0.8605989217758179,
                0.6629253625869751,
                0.7281708717346191,
                0.861121654510498,
                0.817224383354187
            ],
            [
                0.8257172703742981,
                0.6694596409797668,
                0.740623414516449,
                0.7689539790153503,
                0.8376504182815552,
                0.7688295841217041,
                0.8433250188827515,
                0.8307888507843018,
                0.7956159710884094,
                0.8182576298713684,
                0.8192759156227112,
                0.7110076546669006,
                0.816137969493866,
                0.8438711762428284,
                0.7605540752410889,
                0.82448410987854,
                0.8331923484802246,
                0.7944579124450684,
                0.7871217727661133,
                0.7774547338485718,
                0.8211759924888611,
                0.7474697828292847,
                0.8155332207679749,
                0.8285970091819763,
                0.7957776784896851,
                0.7138288617134094,
                0.8148413896560669,
                0.8541967868804932,
                0.814385175704956,
                0.8139171004295349,
                0.6981979012489319,
                0.7811672687530518,
                0.8136785626411438,
                0.8214443325996399
            ],
            [
                0.8591803908348083,
                0.6958405375480652,
                0.8988065719604492,
                0.8069061040878296,
                0.830689013004303,
                0.7892068028450012,
                0.8186126947402954,
                0.9017934203147888,
                0.788667619228363,
                0.9047011137008667,
                0.7856539487838745,
                0.7555410861968994,
                0.9009935855865479,
                0.8852324485778809,
                0.7825478911399841,
                0.8726106882095337,
                0.8598964810371399,
                0.8271303176879883,
                0.8362109661102295,
                0.7854396104812622,
                0.8767911195755005,
                0.6830375790596008,
                0.8780640363693237,
                0.8377423882484436,
                0.833588719367981,
                0.7463645935058594,
                0.905063807964325,
                0.8416719436645508,
                0.8629424571990967,
                0.8376646637916565,
                0.7260600328445435,
                0.8564133644104004,
                0.8369408845901489,
                0.8239006400108337
            ],
            [
                0.8235509991645813,
                0.8239607810974121,
                0.8530245423316956,
                0.8828091621398926,
                0.8453872799873352,
                0.8384209275245667,
                0.7936508059501648,
                0.8563763499259949,
                0.8071348071098328,
                0.9050412774085999,
                0.7919051647186279,
                0.8807576894760132,
                0.9109687805175781,
                0.8900749683380127,
                0.8356705904006958,
                0.8675342202186584,
                0.8718982934951782,
                0.8201970458030701,
                0.7799340486526489,
                0.8221279382705688,
                0.8056674599647522,
                0.6469919681549072,
                0.8250054717063904,
                0.8741015195846558,
                0.8122873902320862,
                0.8558515310287476,
                0.8874744176864624,
                0.7926018238067627,
                0.9028937220573425,
                0.7947201728820801,
                0.8446427583694458,
                0.8809064626693726,
                0.7916579842567444,
                0.7600476741790771
            ],
            [
                0.8116753101348877,
                0.7577247619628906,
                0.7950637936592102,
                0.8922697305679321,
                0.8256713151931763,
                0.796965479850769,
                0.8483989834785461,
                0.8533337116241455,
                0.8043621182441711,
                0.8914353847503662,
                0.7807514071464539,
                0.8303163647651672,
                0.8907207250595093,
                0.8709256052970886,
                0.7963876724243164,
                0.8827208280563354,
                0.8410366177558899,
                0.8581129312515259,
                0.8516787886619568,
                0.8022441267967224,
                0.875210702419281,
                0.6789510846138,
                0.8842959403991699,
                0.8456460237503052,
                0.8451535701751709,
                0.8029391169548035,
                0.8878641128540039,
                0.7916882038116455,
                0.8888436555862427,
                0.8349816203117371,
                0.7440783977508545,
                0.832835853099823,
                0.8331711292266846,
                0.8350580930709839
            ],
            [
                0.7584916353225708,
                0.671733558177948,
                0.6914547085762024,
                0.7226027846336365,
                0.812184751033783,
                0.7091243863105774,
                0.7292888164520264,
                0.7831166982650757,
                0.7152427434921265,
                0.7289846539497375,
                0.8021628260612488,
                0.6805204749107361,
                0.7284500598907471,
                0.7883774042129517,
                0.6919485926628113,
                0.7265715599060059,
                0.8080139756202698,
                0.7514491081237793,
                0.6946561932563782,
                0.7142406105995178,
                0.7307690382003784,
                0.7704864740371704,
                0.7252915501594543,
                0.7873656749725342,
                0.7051597237586975,
                0.6834341287612915,
                0.7220144867897034,
                0.8150787949562073,
                0.7427695393562317,
                0.6923216581344604,
                0.7262116074562073,
                0.7359572052955627,
                0.6954951882362366,
                0.7104686498641968
            ],
            [
                0.7756921052932739,
                0.7776626348495483,
                0.8052893280982971,
                0.8309040665626526,
                0.8420270085334778,
                0.8168624043464661,
                0.7985125184059143,
                0.8257842063903809,
                0.778831958770752,
                0.8769182562828064,
                0.784284770488739,
                0.8363767266273499,
                0.8781446814537048,
                0.8657594323158264,
                0.8097640872001648,
                0.846392810344696,
                0.8505774736404419,
                0.837104320526123,
                0.813176155090332,
                0.797997772693634,
                0.8302553296089172,
                0.7683409452438354,
                0.8456372022628784,
                0.8615315556526184,
                0.8301673531532288,
                0.8180831670761108,
                0.8798934817314148,
                0.8435250520706177,
                0.8896300792694092,
                0.8184788823127747,
                0.8031393885612488,
                0.848504364490509,
                0.8161093592643738,
                0.7857697010040283
            ],
            [
                0.8033789992332458,
                0.798362135887146,
                0.8208871483802795,
                0.8794054388999939,
                0.8605232834815979,
                0.8062680959701538,
                0.7823691368103027,
                0.8405373096466064,
                0.7911231517791748,
                0.8901006579399109,
                0.8162657618522644,
                0.8727064728736877,
                0.8974313735961914,
                0.882205069065094,
                0.8105502128601074,
                0.8574336767196655,
                0.8817892074584961,
                0.8394926190376282,
                0.789457380771637,
                0.8170396089553833,
                0.8076239824295044,
                0.7306984663009644,
                0.8310149908065796,
                0.8848670721054077,
                0.8178801536560059,
                0.866928219795227,
                0.8813971281051636,
                0.8522358536720276,
                0.9185376167297363,
                0.7928179502487183,
                0.8215281367301941,
                0.8880258798599243,
                0.7898175716400146,
                0.7464408278465271
            ],
            [
                0.7475113272666931,
                0.6984720230102539,
                0.737007737159729,
                0.7944533228874207,
                0.8295338153839111,
                0.7570058107376099,
                0.8079046010971069,
                0.8211130499839783,
                0.7864077687263489,
                0.8479901552200317,
                0.7995582222938538,
                0.7923975586891174,
                0.8529232144355774,
                0.8448354005813599,
                0.7563607692718506,
                0.8347449898719788,
                0.8465964198112488,
                0.8332058787345886,
                0.8192017078399658,
                0.7684775590896606,
                0.813331663608551,
                0.6861400604248047,
                0.8303584456443787,
                0.8279067873954773,
                0.8404619693756104,
                0.7760434746742249,
                0.8320459127426147,
                0.8139240145683289,
                0.8521532416343689,
                0.8043737411499023,
                0.7211922407150269,
                0.7932299375534058,
                0.8026372790336609,
                0.7552098035812378
            ],
            [
                0.8413954973220825,
                0.7031367421150208,
                0.736728310585022,
                0.7816920876502991,
                0.8607542514801025,
                0.7629875540733337,
                0.8566007614135742,
                0.8996062278747559,
                0.7799099683761597,
                0.8605403304100037,
                0.8206749558448792,
                0.7064957022666931,
                0.856091320514679,
                0.8624417781829834,
                0.7550501227378845,
                0.869715690612793,
                0.871437132358551,
                0.8392424583435059,
                0.8449453115463257,
                0.7668669819831848,
                0.8851756453514099,
                0.6939762830734253,
                0.8582826852798462,
                0.8391882181167603,
                0.8439078330993652,
                0.7034692764282227,
                0.8478568196296692,
                0.8351466655731201,
                0.8316325545310974,
                0.8577261567115784,
                0.6913607120513916,
                0.7710878252983093,
                0.8572242259979248,
                0.8332509398460388
            ],
            [
                0.7689511775970459,
                0.7990660071372986,
                0.8017584681510925,
                0.8519604206085205,
                0.8205939531326294,
                0.8199421167373657,
                0.7539330720901489,
                0.8020356297492981,
                0.7933470606803894,
                0.8545688986778259,
                0.7899576425552368,
                0.8853334188461304,
                0.8618391156196594,
                0.8646999001502991,
                0.8046016097068787,
                0.8274388313293457,
                0.8415451049804688,
                0.8355804085731506,
                0.766828179359436,
                0.8146917819976807,
                0.7579484581947327,
                0.6921969056129456,
                0.7985907793045044,
                0.8402758240699768,
                0.7985262274742126,
                0.8641707301139832,
                0.8395227789878845,
                0.8020171523094177,
                0.8788900375366211,
                0.7659993767738342,
                0.8229327201843262,
                0.8554502725601196,
                0.7625159025192261,
                0.7286156415939331
            ],
            [
                0.8159836530685425,
                0.698995053768158,
                0.7965048551559448,
                0.7943183183670044,
                0.8715984225273132,
                0.7721037864685059,
                0.8206839561462402,
                0.873795211315155,
                0.7669392228126526,
                0.8801153898239136,
                0.82064288854599,
                0.7590900659561157,
                0.8807529807090759,
                0.876147985458374,
                0.7658073306083679,
                0.8565216064453125,
                0.8855626583099365,
                0.8478530645370483,
                0.8384251594543457,
                0.7754908204078674,
                0.8624615669250488,
                0.8102679252624512,
                0.8619750738143921,
                0.8780001997947693,
                0.8489300608634949,
                0.7634856104850769,
                0.889022171497345,
                0.9231634736061096,
                0.8686290383338928,
                0.8362281322479248,
                0.7406212687492371,
                0.8311033844947815,
                0.8356435894966125,
                0.7988545298576355
            ],
            [
                0.8594362735748291,
                0.7844231128692627,
                0.82081538438797,
                0.855232834815979,
                0.8797098398208618,
                0.8221263885498047,
                0.8737713694572449,
                0.8961388468742371,
                0.8162217140197754,
                0.9450063705444336,
                0.7974476218223572,
                0.8112969398498535,
                0.9446763396263123,
                0.9013133645057678,
                0.8290074467658997,
                0.915489673614502,
                0.9063639044761658,
                0.872107982635498,
                0.868293285369873,
                0.8205200433731079,
                0.9002351760864258,
                0.711289644241333,
                0.906853437423706,
                0.8890990614891052,
                0.8741387128829956,
                0.8093470335006714,
                0.9428233504295349,
                0.8538800477981567,
                0.9185245633125305,
                0.8853191137313843,
                0.7695476412773132,
                0.8709970712661743,
                0.8829528093338013,
                0.8265969753265381
            ],
            [
                0.7621011137962341,
                0.8686378002166748,
                0.7829276919364929,
                0.8511380553245544,
                0.7797101736068726,
                0.8509193658828735,
                0.7714582085609436,
                0.7813157439231873,
                0.8090046644210815,
                0.8345822691917419,
                0.7648833990097046,
                0.8421523571014404,
                0.8359202146530151,
                0.8423612117767334,
                0.8427959680557251,
                0.8092735409736633,
                0.8015846610069275,
                0.7950833439826965,
                0.7413883209228516,
                0.8354200720787048,
                0.7818624973297119,
                0.6314194798469543,
                0.7920417189598083,
                0.7979655861854553,
                0.7593260407447815,
                0.8198955655097961,
                0.8141339421272278,
                0.7312573194503784,
                0.8566612005233765,
                0.7740994691848755,
                0.8182562589645386,
                0.8281437158584595,
                0.7702396512031555,
                0.7794824838638306
            ],
            [
                0.7757223844528198,
                0.6809344291687012,
                0.6917128562927246,
                0.7298812866210938,
                0.8247063159942627,
                0.7259830832481384,
                0.7761811017990112,
                0.7901244759559631,
                0.7716712355613708,
                0.768875777721405,
                0.7890948057174683,
                0.6980457305908203,
                0.7704678177833557,
                0.7983798384666443,
                0.7164274454116821,
                0.7609813213348389,
                0.8369821310043335,
                0.7754014134407043,
                0.7138652205467224,
                0.7411758899688721,
                0.7525669932365417,
                0.6970726251602173,
                0.7450636625289917,
                0.7839623689651489,
                0.7348629832267761,
                0.7126497030258179,
                0.7433967590332031,
                0.8248500823974609,
                0.7651231288909912,
                0.7317588925361633,
                0.7058981657028198,
                0.7594513297080994,
                0.7330127358436584,
                0.732398271560669
            ],
            [
                0.7904433608055115,
                0.6558342576026917,
                0.6746015548706055,
                0.7180868983268738,
                0.7931192517280579,
                0.718727171421051,
                0.7695831060409546,
                0.7644610404968262,
                0.7471857070922852,
                0.7661546468734741,
                0.7861418724060059,
                0.6500052213668823,
                0.7645250558853149,
                0.7771908044815063,
                0.7167551517486572,
                0.7667236328125,
                0.802836537361145,
                0.7850947976112366,
                0.741733193397522,
                0.7367004156112671,
                0.7764490842819214,
                0.7260308265686035,
                0.7607797980308533,
                0.7747012376785278,
                0.7521289587020874,
                0.677108883857727,
                0.75935298204422,
                0.8489611148834229,
                0.7710469961166382,
                0.7560833096504211,
                0.6546171307563782,
                0.7365261912345886,
                0.7560091614723206,
                0.7281999588012695
            ],
            [
                0.7627426981925964,
                0.8554469347000122,
                0.7793991565704346,
                0.8467124700546265,
                0.7809135317802429,
                0.8377733826637268,
                0.7821424603462219,
                0.7852940559387207,
                0.7997962236404419,
                0.8343851566314697,
                0.7616774439811707,
                0.8307395577430725,
                0.8335738182067871,
                0.844346284866333,
                0.8272174596786499,
                0.8024416565895081,
                0.7997914552688599,
                0.8092141151428223,
                0.7513495683670044,
                0.8164608478546143,
                0.7896959781646729,
                0.6416985988616943,
                0.7938414216041565,
                0.7969571352005005,
                0.7705780267715454,
                0.8079017996788025,
                0.8124417066574097,
                0.7416285276412964,
                0.8395190238952637,
                0.7714303731918335,
                0.81135094165802,
                0.8137646913528442,
                0.768218994140625,
                0.7943883538246155
            ],
            [
                0.7650338411331177,
                0.722533106803894,
                0.7065098881721497,
                0.7519525289535522,
                0.8229106068611145,
                0.735722005367279,
                0.7763879895210266,
                0.7861251831054688,
                0.7669979333877563,
                0.779983639717102,
                0.7799651622772217,
                0.7354099750518799,
                0.7793546915054321,
                0.8143000602722168,
                0.7258544564247131,
                0.7569266557693481,
                0.8407657146453857,
                0.8080846667289734,
                0.730786919593811,
                0.7480419874191284,
                0.7512608766555786,
                0.7336663603782654,
                0.7535666823387146,
                0.8017449378967285,
                0.7573164105415344,
                0.7390479445457458,
                0.7630239129066467,
                0.8349778056144714,
                0.7672203779220581,
                0.7270714044570923,
                0.7469379901885986,
                0.7760905027389526,
                0.7274417877197266,
                0.7387864589691162
            ],
            [
                0.8338688015937805,
                0.7534881234169006,
                0.7709785103797913,
                0.7938016057014465,
                0.853775680065155,
                0.8071277737617493,
                0.8164714574813843,
                0.8449842929840088,
                0.7942195534706116,
                0.8616132736206055,
                0.8134147524833679,
                0.7488842606544495,
                0.8591123223304749,
                0.8608432412147522,
                0.8014730215072632,
                0.8346810340881348,
                0.8634271621704102,
                0.8759488463401794,
                0.8255754113197327,
                0.7913216948509216,
                0.859668493270874,
                0.7636337876319885,
                0.8412123918533325,
                0.8566150069236755,
                0.8270544409751892,
                0.7629687786102295,
                0.8527936935424805,
                0.9018746018409729,
                0.8339093327522278,
                0.8201684951782227,
                0.7443647384643555,
                0.8135584592819214,
                0.821711540222168,
                0.7959259748458862
            ],
            [
                0.7940479516983032,
                0.758104145526886,
                0.769463837146759,
                0.7911168932914734,
                0.8153311610221863,
                0.7959710955619812,
                0.7884416580200195,
                0.7936134338378906,
                0.833999514579773,
                0.8202735781669617,
                0.781688928604126,
                0.7869054079055786,
                0.8195475935935974,
                0.8435924649238586,
                0.7842413187026978,
                0.7804137468338013,
                0.8401561379432678,
                0.7915056347846985,
                0.714991569519043,
                0.8199344873428345,
                0.7612805962562561,
                0.7455713748931885,
                0.7745497822761536,
                0.8223317265510559,
                0.7419863343238831,
                0.7877475619316101,
                0.7954248189926147,
                0.8325009346008301,
                0.8043475151062012,
                0.7362747192382812,
                0.7786839008331299,
                0.8317974805831909,
                0.7354459762573242,
                0.7485184669494629
            ],
            [
                0.8523074984550476,
                0.751060962677002,
                0.7982566952705383,
                0.7960185408592224,
                0.8772577047348022,
                0.8433385491371155,
                0.8311355113983154,
                0.8628171682357788,
                0.826324462890625,
                0.8856255412101746,
                0.8246733546257019,
                0.7739087343215942,
                0.8826102614402771,
                0.8779305815696716,
                0.8355684876441956,
                0.8519453406333923,
                0.880099892616272,
                0.8590599298477173,
                0.8174249529838562,
                0.8253225088119507,
                0.8618389368057251,
                0.7827512621879578,
                0.8622022867202759,
                0.874944269657135,
                0.8299345374107361,
                0.778308629989624,
                0.8685194253921509,
                0.907799243927002,
                0.8533869981765747,
                0.8339340686798096,
                0.7796702980995178,
                0.8334769010543823,
                0.8349810242652893,
                0.8071359395980835
            ],
            [
                0.7669609189033508,
                0.7254953384399414,
                0.7159405946731567,
                0.7693279981613159,
                0.8075437545776367,
                0.7431038618087769,
                0.7707551121711731,
                0.7740702629089355,
                0.7829717993736267,
                0.7800191640853882,
                0.7610209584236145,
                0.7342609167098999,
                0.7796061038970947,
                0.8100512027740479,
                0.7344478964805603,
                0.7580604553222656,
                0.8311032056808472,
                0.778393030166626,
                0.7030095458030701,
                0.7611684203147888,
                0.736402690410614,
                0.7166765928268433,
                0.7403839826583862,
                0.7871099710464478,
                0.7443475127220154,
                0.7430029511451721,
                0.7582173347473145,
                0.8056409358978271,
                0.7788207530975342,
                0.7148175239562988,
                0.7388821244239807,
                0.790231466293335,
                0.7140815258026123,
                0.7202231287956238
            ],
            [
                0.84254390001297,
                0.7492351531982422,
                0.7690309882164001,
                0.8138816356658936,
                0.8365132808685303,
                0.803589940071106,
                0.8205946683883667,
                0.8298341035842896,
                0.8036985993385315,
                0.842596709728241,
                0.8046690821647644,
                0.7323095798492432,
                0.8409203886985779,
                0.8522327542304993,
                0.7977505326271057,
                0.8239320516586304,
                0.8476484417915344,
                0.8225859999656677,
                0.7802700400352478,
                0.8080986142158508,
                0.8202191591262817,
                0.7298340201377869,
                0.8096337914466858,
                0.826393187046051,
                0.8211565613746643,
                0.7477874755859375,
                0.8218765258789062,
                0.855805516242981,
                0.8374267816543579,
                0.8046246767044067,
                0.7351517677307129,
                0.8168720602989197,
                0.8045428395271301,
                0.7906404733657837
            ],
            [
                0.8464708924293518,
                0.8316890597343445,
                0.8039536476135254,
                0.8840633034706116,
                0.8339968919754028,
                0.8332054615020752,
                0.7905160188674927,
                0.8325523138046265,
                0.8253006339073181,
                0.881310224533081,
                0.8114015460014343,
                0.8540576100349426,
                0.8839773535728455,
                0.884390115737915,
                0.8230113387107849,
                0.8546814322471619,
                0.8714001178741455,
                0.862548828125,
                0.7734871506690979,
                0.8250201940536499,
                0.8018969297409058,
                0.6887108087539673,
                0.8147761225700378,
                0.8646141886711121,
                0.8035534620285034,
                0.8532592058181763,
                0.8605301976203918,
                0.8267493844032288,
                0.8985633254051208,
                0.7839050889015198,
                0.8156505823135376,
                0.8886091709136963,
                0.7815446257591248,
                0.7689765095710754
            ],
            [
                0.8226569294929504,
                0.7436110377311707,
                0.7352966070175171,
                0.7974035739898682,
                0.8469882011413574,
                0.7816301584243774,
                0.8004134893417358,
                0.8196195363998413,
                0.804530143737793,
                0.8290054202079773,
                0.8240733742713928,
                0.7757487893104553,
                0.8282939791679382,
                0.8638670444488525,
                0.7708998322486877,
                0.8171215653419495,
                0.864371120929718,
                0.818758487701416,
                0.7539995908737183,
                0.7863577604293823,
                0.7811336517333984,
                0.73649001121521,
                0.7828571200370789,
                0.8521648645401001,
                0.785359263420105,
                0.7794362306594849,
                0.7982109785079956,
                0.8537813425064087,
                0.8232811689376831,
                0.7652897238731384,
                0.7778770923614502,
                0.8109703660011292,
                0.7666730880737305,
                0.7725309133529663
            ],
            [
                0.7905051112174988,
                0.7637149095535278,
                0.7387827634811401,
                0.8267086148262024,
                0.8503623008728027,
                0.7734906077384949,
                0.781485378742218,
                0.8104988932609558,
                0.804652750492096,
                0.8143404722213745,
                0.8376810550689697,
                0.8115736842155457,
                0.8198176026344299,
                0.8616710901260376,
                0.7661346793174744,
                0.7922460436820984,
                0.872532844543457,
                0.7872241139411926,
                0.7079082131385803,
                0.7834209203720093,
                0.752143919467926,
                0.6927413940429688,
                0.7468944787979126,
                0.8512834906578064,
                0.7438645362854004,
                0.8089771270751953,
                0.7787067890167236,
                0.8107097744941711,
                0.8285804986953735,
                0.7305911183357239,
                0.7932112216949463,
                0.8034661412239075,
                0.7284932136535645,
                0.7409405708312988
            ],
            [
                0.8425654768943787,
                0.775127112865448,
                0.7844614386558533,
                0.8265959620475769,
                0.8803524971008301,
                0.8150355815887451,
                0.8290327787399292,
                0.8649933338165283,
                0.8191299438476562,
                0.8714267611503601,
                0.8607027530670166,
                0.7971290946006775,
                0.8696152567863464,
                0.8962924480438232,
                0.8060547709465027,
                0.8479325175285339,
                0.8931185007095337,
                0.8491001129150391,
                0.7921972274780273,
                0.807578980922699,
                0.8329452276229858,
                0.7545055150985718,
                0.8303876519203186,
                0.8856296539306641,
                0.8111977577209473,
                0.7937294244766235,
                0.8503488302230835,
                0.8884211778640747,
                0.8748064041137695,
                0.8088322281837463,
                0.8078151941299438,
                0.844225287437439,
                0.8079784512519836,
                0.8032742738723755
            ],
            [
                0.7628709077835083,
                0.7850639820098877,
                0.7591107487678528,
                0.8355333209037781,
                0.8101615309715271,
                0.7881572246551514,
                0.7551136612892151,
                0.7985775470733643,
                0.7788264751434326,
                0.8383766412734985,
                0.7825183868408203,
                0.861941397190094,
                0.8432710766792297,
                0.8638076782226562,
                0.7825869917869568,
                0.8315070271492004,
                0.8443058729171753,
                0.8306148052215576,
                0.7625758647918701,
                0.7857032418251038,
                0.7672457695007324,
                0.6419870853424072,
                0.7907013297080994,
                0.8351485133171082,
                0.7885149121284485,
                0.8455460071563721,
                0.8174443244934082,
                0.7885451316833496,
                0.8593105673789978,
                0.7523067593574524,
                0.8063861131668091,
                0.8331313133239746,
                0.751210629940033,
                0.7550934553146362
            ],
            [
                0.7550835013389587,
                0.8055735230445862,
                0.7556312084197998,
                0.8428521156311035,
                0.8322992324829102,
                0.8025969862937927,
                0.7621484994888306,
                0.7901709079742432,
                0.7901360988616943,
                0.8255689740180969,
                0.8126832246780396,
                0.8719432353973389,
                0.8336893320083618,
                0.8623552322387695,
                0.7941079139709473,
                0.8069790005683899,
                0.8517680168151855,
                0.7981048226356506,
                0.7197475433349609,
                0.8047530651092529,
                0.7427154183387756,
                0.6801305413246155,
                0.7601960897445679,
                0.8508964776992798,
                0.758672297000885,
                0.8493440747261047,
                0.8032469153404236,
                0.7817540764808655,
                0.8567184805870056,
                0.7309491634368896,
                0.824386715888977,
                0.8236386775970459,
                0.7278884053230286,
                0.7344317436218262
            ],
            [
                0.8619356751441956,
                0.8245358467102051,
                0.8043174147605896,
                0.8515558242797852,
                0.8895363807678223,
                0.846834659576416,
                0.8259238600730896,
                0.8716251850128174,
                0.8425033092498779,
                0.8653613328933716,
                0.8573281764984131,
                0.8007652759552002,
                0.8661345839500427,
                0.9080873131752014,
                0.834926426410675,
                0.8406616449356079,
                0.898773729801178,
                0.8233550190925598,
                0.7607965469360352,
                0.8357505202293396,
                0.8164243698120117,
                0.7218506336212158,
                0.809468150138855,
                0.8773258924484253,
                0.7897061705589294,
                0.792314350605011,
                0.8355585336685181,
                0.8478042483329773,
                0.8680738806724548,
                0.7949567437171936,
                0.8285555839538574,
                0.8480010032653809,
                0.7931903600692749,
                0.8189588785171509
            ],
            [
                0.7854124307632446,
                0.7858349084854126,
                0.7563192844390869,
                0.8392552137374878,
                0.8294167518615723,
                0.7765756249427795,
                0.7701849937438965,
                0.8120102882385254,
                0.7776990532875061,
                0.8484233021736145,
                0.7887362837791443,
                0.8401497602462769,
                0.8529548645019531,
                0.8599876761436462,
                0.7732217311859131,
                0.8438554406166077,
                0.8658541440963745,
                0.8334853053092957,
                0.7730560898780823,
                0.7853203415870667,
                0.789850652217865,
                0.6575624942779541,
                0.8023572564125061,
                0.84764564037323,
                0.7905166149139404,
                0.8343855738639832,
                0.8180254697799683,
                0.8015181422233582,
                0.8609179854393005,
                0.7615049481391907,
                0.7932850122451782,
                0.8335446119308472,
                0.7611050009727478,
                0.7466826438903809
            ],
            [
                0.7806926965713501,
                0.763106107711792,
                0.7234761118888855,
                0.8085280656814575,
                0.8229809999465942,
                0.7552579641342163,
                0.7498376369476318,
                0.7902770638465881,
                0.7785018086433411,
                0.7962663173675537,
                0.7761985063552856,
                0.7964426875114441,
                0.801386296749115,
                0.8390967845916748,
                0.7439916729927063,
                0.7812235355377197,
                0.8501268625259399,
                0.7679722309112549,
                0.6900373101234436,
                0.7645901441574097,
                0.7317450046539307,
                0.6288819909095764,
                0.7270979881286621,
                0.825360119342804,
                0.724503219127655,
                0.7842807769775391,
                0.7571945190429688,
                0.7621248960494995,
                0.8022599816322327,
                0.6980521082878113,
                0.7805513143539429,
                0.7849765419960022,
                0.6962818503379822,
                0.729079008102417
            ],
            [
                0.8677451610565186,
                0.8212001323699951,
                0.8118566274642944,
                0.8506635427474976,
                0.8907922506332397,
                0.8639631271362305,
                0.8175529837608337,
                0.872327446937561,
                0.8482149839401245,
                0.8791284561157227,
                0.8527677655220032,
                0.8282251358032227,
                0.8787440061569214,
                0.9181147813796997,
                0.8492608070373535,
                0.8506851196289062,
                0.9032257199287415,
                0.8412940502166748,
                0.7739992737770081,
                0.8515225052833557,
                0.8299460411071777,
                0.7480089068412781,
                0.8283149003982544,
                0.8956543803215027,
                0.799767017364502,
                0.8196476697921753,
                0.8544654846191406,
                0.8772739768028259,
                0.8768344521522522,
                0.8022009134292603,
                0.8477303981781006,
                0.8559163808822632,
                0.800329864025116,
                0.8308908939361572
            ],
            [
                0.7850921750068665,
                0.7320865392684937,
                0.7667553424835205,
                0.769568920135498,
                0.8316258192062378,
                0.7771143317222595,
                0.7707974314689636,
                0.8027270436286926,
                0.8087548613548279,
                0.8070947527885437,
                0.7967628240585327,
                0.7734280824661255,
                0.8060640692710876,
                0.8396981954574585,
                0.7599937319755554,
                0.7706433534622192,
                0.8607664108276367,
                0.7930396795272827,
                0.7301625609397888,
                0.798844575881958,
                0.7793910503387451,
                0.8111661672592163,
                0.7836441397666931,
                0.8501013517379761,
                0.7480416297912598,
                0.7800220847129822,
                0.7967455387115479,
                0.8751827478408813,
                0.7942920327186584,
                0.7352144122123718,
                0.7749181389808655,
                0.8272883296012878,
                0.7359240055084229,
                0.7515199184417725
            ],
            [
                0.8481591939926147,
                0.7468615770339966,
                0.7556533217430115,
                0.7941064834594727,
                0.8519493937492371,
                0.8083351254463196,
                0.8401102423667908,
                0.83429354429245,
                0.826551616191864,
                0.8505109548568726,
                0.8201164603233337,
                0.7463272213935852,
                0.8467425107955933,
                0.8632335662841797,
                0.8023853302001953,
                0.8335364460945129,
                0.8607834577560425,
                0.8336862325668335,
                0.7913831472396851,
                0.808508574962616,
                0.837161660194397,
                0.7472100257873535,
                0.8192971348762512,
                0.8521713018417358,
                0.8115457892417908,
                0.7550870180130005,
                0.8341649770736694,
                0.8831015229225159,
                0.8323758244514465,
                0.8153423070907593,
                0.7509278059005737,
                0.8095300197601318,
                0.8163142800331116,
                0.8200216293334961
            ],
            [
                0.7680079936981201,
                0.7337912917137146,
                0.7308822870254517,
                0.7630529999732971,
                0.8054258823394775,
                0.756598711013794,
                0.7713289856910706,
                0.773076057434082,
                0.8038211464881897,
                0.7924928665161133,
                0.787015974521637,
                0.7579750418663025,
                0.7918086051940918,
                0.8261500000953674,
                0.747225284576416,
                0.7568975687026978,
                0.8328490257263184,
                0.7758911848068237,
                0.7012518048286438,
                0.7818225622177124,
                0.7453259229660034,
                0.7295979261398315,
                0.7489262819290161,
                0.8142738938331604,
                0.735815167427063,
                0.7612493634223938,
                0.7688156366348267,
                0.8249516487121582,
                0.7799806594848633,
                0.7151765823364258,
                0.7635473608970642,
                0.8060162663459778,
                0.7140305042266846,
                0.7355397939682007
            ],
            [
                0.8291524052619934,
                0.6862276792526245,
                0.7627817392349243,
                0.7704389095306396,
                0.8728523254394531,
                0.7653471231460571,
                0.8432888388633728,
                0.8527936339378357,
                0.7864080667495728,
                0.8653708696365356,
                0.8157426714897156,
                0.7252770066261292,
                0.860411524772644,
                0.8729218244552612,
                0.7614963054656982,
                0.8414419889450073,
                0.8743030428886414,
                0.8375440835952759,
                0.8261731266975403,
                0.7762119770050049,
                0.8652738332748413,
                0.798935055732727,
                0.8518614172935486,
                0.8581485152244568,
                0.8339824080467224,
                0.7330981492996216,
                0.860799252986908,
                0.9131289124488831,
                0.8303025960922241,
                0.8296818137168884,
                0.7233827114105225,
                0.7941043376922607,
                0.8319019079208374,
                0.8232030272483826
            ],
            [
                0.8351732492446899,
                0.7507098317146301,
                0.8223116397857666,
                0.8396677374839783,
                0.8622981309890747,
                0.8065465688705444,
                0.8686103820800781,
                0.8975998759269714,
                0.8129246830940247,
                0.9540482759475708,
                0.7896531820297241,
                0.8076971173286438,
                0.9537456631660461,
                0.8933327794075012,
                0.8115448951721191,
                0.9194290637969971,
                0.8910088539123535,
                0.8688563108444214,
                0.8904045820236206,
                0.808104932308197,
                0.9232503771781921,
                0.6792781949043274,
                0.9168559312820435,
                0.88258957862854,
                0.8828690648078918,
                0.7955741882324219,
                0.9506774544715881,
                0.8370428085327148,
                0.9081614017486572,
                0.8980481624603271,
                0.7435005903244019,
                0.854572594165802,
                0.897878885269165,
                0.8339857459068298
            ],
            [
                0.7805522680282593,
                0.8484910130500793,
                0.7799891233444214,
                0.8593652248382568,
                0.7962185144424438,
                0.8366284370422363,
                0.7967973947525024,
                0.7915400266647339,
                0.8102302551269531,
                0.8420922756195068,
                0.7605888843536377,
                0.8235934972763062,
                0.8418298959732056,
                0.8514114618301392,
                0.8293922543525696,
                0.8142493963241577,
                0.8154841661453247,
                0.7971746325492859,
                0.7466309070587158,
                0.8287127017974854,
                0.792951226234436,
                0.6445755362510681,
                0.797039806842804,
                0.8097752928733826,
                0.7728146910667419,
                0.8056349754333496,
                0.8176600933074951,
                0.7479620575904846,
                0.8497471809387207,
                0.7728402614593506,
                0.8122113943099976,
                0.8214609026908875,
                0.770482063293457,
                0.7987643480300903
            ],
            [
                0.7594877481460571,
                0.7023031115531921,
                0.7451005578041077,
                0.78058260679245,
                0.8205270767211914,
                0.7790271639823914,
                0.7434150576591492,
                0.7949596643447876,
                0.7607611417770386,
                0.7958397269248962,
                0.7765407562255859,
                0.7434498071670532,
                0.7961745858192444,
                0.8233780860900879,
                0.7647885680198669,
                0.7748100757598877,
                0.8427723050117493,
                0.8002347350120544,
                0.7449612617492676,
                0.8035897612571716,
                0.7643404006958008,
                0.763260006904602,
                0.7740875482559204,
                0.8150190114974976,
                0.7895469665527344,
                0.7508460283279419,
                0.7788275480270386,
                0.8270197510719299,
                0.7929272055625916,
                0.7399963140487671,
                0.7492902874946594,
                0.8023742437362671,
                0.7437456846237183,
                0.742713212966919
            ],
            [
                0.7782943844795227,
                0.6478478312492371,
                0.7154202461242676,
                0.7297918796539307,
                0.8504335880279541,
                0.7226248383522034,
                0.7874141931533813,
                0.7988897562026978,
                0.741491436958313,
                0.8053791522979736,
                0.8134713172912598,
                0.7111555933952332,
                0.8042899370193481,
                0.8319056630134583,
                0.7179554104804993,
                0.7851697206497192,
                0.8444787263870239,
                0.7765253782272339,
                0.7606024146080017,
                0.755768895149231,
                0.8018325567245483,
                0.8237998485565186,
                0.7900468111038208,
                0.8499245643615723,
                0.7738358974456787,
                0.7184985280036926,
                0.8089284300804138,
                0.9109363555908203,
                0.7901127934455872,
                0.7657390832901001,
                0.7157403230667114,
                0.7631610631942749,
                0.7678864002227783,
                0.7707088589668274
            ],
            [
                0.7586920261383057,
                0.6912806034088135,
                0.7161626815795898,
                0.7669680118560791,
                0.7918305397033691,
                0.7191296815872192,
                0.745376706123352,
                0.7699677348136902,
                0.7639026045799255,
                0.7812881469726562,
                0.7499945759773254,
                0.7446395754814148,
                0.7813189625740051,
                0.8169064521789551,
                0.7081988453865051,
                0.760143518447876,
                0.8179617524147034,
                0.7571648955345154,
                0.707807183265686,
                0.7416412830352783,
                0.7301339507102966,
                0.6767902970314026,
                0.738030195236206,
                0.7852091193199158,
                0.73662930727005,
                0.7359700202941895,
                0.752082347869873,
                0.7899391055107117,
                0.7642226815223694,
                0.6977354288101196,
                0.7274169921875,
                0.7687551379203796,
                0.7002036571502686,
                0.7284290790557861
            ],
            [
                0.8156597018241882,
                0.7072773575782776,
                0.7400614023208618,
                0.7554560303688049,
                0.8498044610023499,
                0.7445099949836731,
                0.8232810497283936,
                0.8435273766517639,
                0.7670919299125671,
                0.8587071299552917,
                0.8114826679229736,
                0.7174594402313232,
                0.8523827791213989,
                0.8515689969062805,
                0.7452582716941833,
                0.8364492654800415,
                0.8728405237197876,
                0.8247833847999573,
                0.8244704604148865,
                0.7617353796958923,
                0.867664098739624,
                0.787181556224823,
                0.8599591255187988,
                0.8548979759216309,
                0.813409149646759,
                0.7241575121879578,
                0.8624157309532166,
                0.8826178908348083,
                0.8223794102668762,
                0.829622209072113,
                0.7182397842407227,
                0.7937984466552734,
                0.8292094469070435,
                0.8022037744522095
            ],
            [
                0.759809672832489,
                0.7006241679191589,
                0.7399982810020447,
                0.7722271680831909,
                0.8245772123336792,
                0.750179648399353,
                0.7729917168617249,
                0.7929760813713074,
                0.8013361096382141,
                0.8024454116821289,
                0.7906322479248047,
                0.757613480091095,
                0.8011041283607483,
                0.8411132097244263,
                0.7324930429458618,
                0.7726873159408569,
                0.8457914590835571,
                0.7942340970039368,
                0.7273461818695068,
                0.7727055549621582,
                0.760322093963623,
                0.7504544258117676,
                0.7659846544265747,
                0.8083930611610413,
                0.7535394430160522,
                0.75037682056427,
                0.7739313244819641,
                0.8353632688522339,
                0.7806384563446045,
                0.726546049118042,
                0.7443329095840454,
                0.791515588760376,
                0.7276219129562378,
                0.7553675174713135
            ],
            [
                0.7650417685508728,
                0.7351322770118713,
                0.7413164973258972,
                0.7793425917625427,
                0.7774186134338379,
                0.7462291121482849,
                0.7285467982292175,
                0.751353919506073,
                0.7791844606399536,
                0.7810279726982117,
                0.7581604719161987,
                0.7743093371391296,
                0.7800678610801697,
                0.8249310851097107,
                0.7265263795852661,
                0.7544264793395996,
                0.8014661073684692,
                0.7651945352554321,
                0.6886656880378723,
                0.7656943202018738,
                0.7127927541732788,
                0.673973023891449,
                0.7233942747116089,
                0.7802729606628418,
                0.7114160060882568,
                0.7688433527946472,
                0.7482240200042725,
                0.7921157479286194,
                0.7699212431907654,
                0.6804906129837036,
                0.7485218644142151,
                0.7951421737670898,
                0.6829017400741577,
                0.7283700704574585
            ],
            [
                0.7403957843780518,
                0.6572138071060181,
                0.6267824172973633,
                0.7007322311401367,
                0.7708666324615479,
                0.6942996382713318,
                0.7673469185829163,
                0.7382065057754517,
                0.719347357749939,
                0.7487523555755615,
                0.7733660936355591,
                0.6440094113349915,
                0.7454131841659546,
                0.7539945244789124,
                0.6857969164848328,
                0.769008219242096,
                0.7715390920639038,
                0.7704827189445496,
                0.7356951236724854,
                0.7315337657928467,
                0.7618056535720825,
                0.6993483304977417,
                0.7408427000045776,
                0.7579948902130127,
                0.749666154384613,
                0.667214035987854,
                0.7344281673431396,
                0.8003101944923401,
                0.7500601410865784,
                0.7524468898773193,
                0.6422496438026428,
                0.7015301585197449,
                0.7536295652389526,
                0.7251060009002686
            ],
            [
                0.8133811950683594,
                0.7275798320770264,
                0.7401421666145325,
                0.7833541035652161,
                0.8654322028160095,
                0.7601843476295471,
                0.8223270177841187,
                0.8254764080047607,
                0.7837910652160645,
                0.8469004034996033,
                0.828019917011261,
                0.7294895648956299,
                0.841560959815979,
                0.8667107820510864,
                0.7512856721878052,
                0.8195680379867554,
                0.8676343560218811,
                0.8247888088226318,
                0.7971036434173584,
                0.7787541151046753,
                0.8364316821098328,
                0.8024035096168518,
                0.8385432958602905,
                0.8583605885505676,
                0.7997936010360718,
                0.7312150597572327,
                0.8354951739311218,
                0.8816114664077759,
                0.8224164843559265,
                0.7996091842651367,
                0.738746166229248,
                0.797505259513855,
                0.7986059188842773,
                0.7966316938400269
            ],
            [
                0.7775052785873413,
                0.8026988506317139,
                0.7577911615371704,
                0.8411981463432312,
                0.807977020740509,
                0.7981124520301819,
                0.7511072754859924,
                0.7776389122009277,
                0.8118829727172852,
                0.8073745369911194,
                0.792381227016449,
                0.8492189049720764,
                0.8126025795936584,
                0.8465272784233093,
                0.7874323725700378,
                0.7833782434463501,
                0.8327644467353821,
                0.7826954126358032,
                0.7029698491096497,
                0.8058231472969055,
                0.7340978980064392,
                0.6530673503875732,
                0.7417378425598145,
                0.8234878182411194,
                0.7398361563682556,
                0.8344429135322571,
                0.7807323336601257,
                0.7741814851760864,
                0.8316731452941895,
                0.7146650552749634,
                0.8104022741317749,
                0.8259190917015076,
                0.711403489112854,
                0.7410284876823425
            ],
            [
                0.8645660877227783,
                0.7560625076293945,
                0.817046582698822,
                0.8420796990394592,
                0.8978034257888794,
                0.828676164150238,
                0.847160279750824,
                0.8931183815002441,
                0.8317855000495911,
                0.8923409581184387,
                0.8593595027923584,
                0.7971367835998535,
                0.8928940296173096,
                0.918414831161499,
                0.8192233443260193,
                0.8712652921676636,
                0.9033489227294922,
                0.8427425622940063,
                0.8145232796669006,
                0.8311375975608826,
                0.8500881791114807,
                0.7733389735221863,
                0.852522075176239,
                0.898751974105835,
                0.8385744690895081,
                0.7922502756118774,
                0.8680372834205627,
                0.8966876268386841,
                0.886813223361969,
                0.8370885848999023,
                0.799140453338623,
                0.8494240045547485,
                0.8373771905899048,
                0.8496960997581482
            ],
            [
                0.7700648903846741,
                0.737427294254303,
                0.6914989948272705,
                0.7956666350364685,
                0.8104163408279419,
                0.7408524751663208,
                0.7657087445259094,
                0.787346363067627,
                0.777816891670227,
                0.773786187171936,
                0.8058087825775146,
                0.7807790637016296,
                0.7778726816177368,
                0.8332222700119019,
                0.7327244281768799,
                0.761958122253418,
                0.8380178213119507,
                0.7515832781791687,
                0.6760408878326416,
                0.7539810538291931,
                0.7243601679801941,
                0.651940643787384,
                0.7105461359024048,
                0.8112296462059021,
                0.7123006582260132,
                0.7728186845779419,
                0.7373340725898743,
                0.7639346718788147,
                0.7828714847564697,
                0.6967303156852722,
                0.759066641330719,
                0.760165274143219,
                0.6948440074920654,
                0.7495998740196228
            ]
        ],
        [
            [
                0.694251298904419,
                0.87199866771698,
                0.7369616627693176,
                0.7627120018005371,
                0.8108426332473755,
                0.8179013133049011,
                0.6951764822006226,
                0.7886625528335571,
                0.7064765095710754,
                0.7424979209899902,
                0.690104067325592,
                0.8285902738571167,
                0.5569922924041748,
                0.7009893655776978,
                0.8334900736808777,
                0.8566896915435791,
                0.8304368853569031,
                0.7723343372344971,
                0.6980183720588684,
                0.7408451437950134,
                0.6820860505104065,
                0.6849136352539062,
                0.7326266169548035,
                0.5505731105804443,
                0.7192811965942383,
                0.6872618794441223,
                0.634602963924408,
                0.728895366191864,
                0.6906687617301941,
                0.7696298956871033,
                0.8040062785148621,
                0.6692751049995422,
                0.69610595703125,
                0.686982274055481,
                0.7970340847969055,
                0.7272806167602539,
                0.663136899471283,
                0.7582407593727112,
                0.7830696702003479,
                0.7818437814712524,
                0.682373046875,
                0.763873815536499,
                0.7264026999473572,
                0.7611389756202698,
                0.7478337287902832,
                0.813233494758606,
                0.6968135237693787,
                0.7556875944137573,
                0.7663968801498413,
                0.7554410696029663,
                0.85482257604599
            ],
            [
                0.7429192066192627,
                0.7980162501335144,
                0.7193431258201599,
                0.9305144548416138,
                0.741983950138092,
                0.7384098172187805,
                0.7167881727218628,
                0.7764602899551392,
                0.7371178865432739,
                0.7957634329795837,
                0.7379594445228577,
                0.8462816476821899,
                0.640138566493988,
                0.7207182049751282,
                0.8045967817306519,
                0.7330101132392883,
                0.776691198348999,
                0.82783442735672,
                0.7304835319519043,
                0.7968379855155945,
                0.7408370971679688,
                0.708476722240448,
                0.8090630173683167,
                0.5059295892715454,
                0.7547573447227478,
                0.7378286719322205,
                0.6516997218132019,
                0.7851749658584595,
                0.7333966493606567,
                0.8224003314971924,
                0.7856299877166748,
                0.6384174823760986,
                0.6907863616943359,
                0.6944711804389954,
                0.7360939979553223,
                0.76374351978302,
                0.6443647742271423,
                0.7785727381706238,
                0.6981040835380554,
                0.7970564365386963,
                0.7422217726707458,
                0.8445500731468201,
                0.7139134407043457,
                0.8598594665527344,
                0.6875916123390198,
                0.6997575163841248,
                0.741383969783783,
                0.819848358631134,
                0.7200616598129272,
                0.8521703481674194,
                0.7182688117027283
            ],
            [
                0.7890398502349854,
                0.9476435780525208,
                0.7748807668685913,
                0.8415822386741638,
                0.8083457946777344,
                0.8713921308517456,
                0.7374002933502197,
                0.812990665435791,
                0.7485162615776062,
                0.7809262275695801,
                0.7392688989639282,
                0.9233412742614746,
                0.6414638161659241,
                0.7446046471595764,
                0.8709142208099365,
                0.8521162867546082,
                0.8569544553756714,
                0.8266106843948364,
                0.7398111820220947,
                0.787714421749115,
                0.7457091212272644,
                0.7471805214881897,
                0.7862528562545776,
                0.5715962648391724,
                0.765110433101654,
                0.754729151725769,
                0.6941566467285156,
                0.7797884941101074,
                0.741645336151123,
                0.8179101347923279,
                0.8426811695098877,
                0.6724871397018433,
                0.7272727489471436,
                0.719962477684021,
                0.8746563196182251,
                0.7767000794410706,
                0.6917833089828491,
                0.8001838326454163,
                0.8197683095932007,
                0.8486475348472595,
                0.7597966194152832,
                0.8493655323982239,
                0.8209530711174011,
                0.8430201411247253,
                0.8457893133163452,
                0.8542366623878479,
                0.75649094581604,
                0.8240085244178772,
                0.8478549718856812,
                0.82828688621521,
                0.8527688980102539
            ],
            [
                0.7990267276763916,
                0.8399869799613953,
                0.7538300156593323,
                0.838335394859314,
                0.8055315613746643,
                0.8196070194244385,
                0.7625963687896729,
                0.9529518485069275,
                0.7621660828590393,
                0.864701509475708,
                0.7574539184570312,
                0.885301947593689,
                0.6226688027381897,
                0.7600923180580139,
                0.8932734131813049,
                0.7656220197677612,
                0.843159556388855,
                0.883459746837616,
                0.7507250308990479,
                0.8398754596710205,
                0.7614006996154785,
                0.7475566864013672,
                0.8357856273651123,
                0.55028235912323,
                0.8183625340461731,
                0.7568797469139099,
                0.7360585927963257,
                0.8174445033073425,
                0.7577891945838928,
                0.8514866232872009,
                0.8606269359588623,
                0.7028310894966125,
                0.7258140444755554,
                0.7296470403671265,
                0.7356177568435669,
                0.8027510046958923,
                0.6911880970001221,
                0.8646559715270996,
                0.7306668162345886,
                0.7999705076217651,
                0.7632899880409241,
                0.8929075598716736,
                0.7610042095184326,
                0.90326327085495,
                0.7268799543380737,
                0.7111100554466248,
                0.7696765661239624,
                0.8787365555763245,
                0.7090393900871277,
                0.8784283399581909,
                0.7614386677742004
            ],
            [
                0.8209840655326843,
                0.7797966599464417,
                0.7946878671646118,
                0.7767208218574524,
                0.8890348672866821,
                0.8316662907600403,
                0.890156090259552,
                0.8905330896377563,
                0.8919426798820496,
                0.8997870683670044,
                0.8790175318717957,
                0.8229069113731384,
                0.5678904056549072,
                0.8967124819755554,
                0.8613969087600708,
                0.7927541136741638,
                0.8677189946174622,
                0.8950522541999817,
                0.8956347107887268,
                0.9201512932777405,
                0.8778941631317139,
                0.8188390135765076,
                0.8657063841819763,
                0.6600732207298279,
                0.9090960621833801,
                0.8635862469673157,
                0.8729925751686096,
                0.8343532085418701,
                0.8187783360481262,
                0.8550571203231812,
                0.8666501045227051,
                0.8234459757804871,
                0.8268805742263794,
                0.8253490328788757,
                0.6828256249427795,
                0.8989114761352539,
                0.7542409896850586,
                0.9249659776687622,
                0.6940831542015076,
                0.7418811321258545,
                0.8726133704185486,
                0.8900383114814758,
                0.7186165452003479,
                0.8862307667732239,
                0.6635814905166626,
                0.661669909954071,
                0.8795034885406494,
                0.9121037721633911,
                0.6642134189605713,
                0.8700478076934814,
                0.7043365240097046
            ],
            [
                0.8353109955787659,
                0.8347222208976746,
                0.794151782989502,
                0.8566150665283203,
                0.8634699583053589,
                0.8336517214775085,
                0.8402184844017029,
                0.8444376587867737,
                0.8454424142837524,
                0.9451652765274048,
                0.835319995880127,
                0.8825123310089111,
                0.6325464844703674,
                0.837022602558136,
                0.8688007593154907,
                0.788349449634552,
                0.854885995388031,
                0.9278398752212524,
                0.8250434398651123,
                0.9281582236289978,
                0.8226464986801147,
                0.8289399147033691,
                0.8908795714378357,
                0.6361086964607239,
                0.9021761417388916,
                0.8136972188949585,
                0.780934751033783,
                0.8380553722381592,
                0.8252741694450378,
                0.8668720722198486,
                0.8623366951942444,
                0.7986009120941162,
                0.8150776028633118,
                0.8179947137832642,
                0.7594636678695679,
                0.8527623414993286,
                0.7660122513771057,
                0.8881097435951233,
                0.7595850825309753,
                0.8246602416038513,
                0.8189041614532471,
                0.9126328825950623,
                0.7758846879005432,
                0.9088674783706665,
                0.7243996858596802,
                0.7093838453292847,
                0.8245171308517456,
                0.9158254861831665,
                0.7467774152755737,
                0.8979068398475647,
                0.7381395101547241
            ],
            [
                0.658078134059906,
                0.8161634802818298,
                0.742893397808075,
                0.7210705280303955,
                0.7538995742797852,
                0.8357078433036804,
                0.6897934675216675,
                0.7506346702575684,
                0.6936790347099304,
                0.7391704320907593,
                0.6862567663192749,
                0.8318514227867126,
                0.565350353717804,
                0.7018523216247559,
                0.8436254858970642,
                0.8481403589248657,
                0.8300071954727173,
                0.7815588116645813,
                0.6935532093048096,
                0.7605675458908081,
                0.7036957144737244,
                0.7219282388687134,
                0.7455884218215942,
                0.6356880068778992,
                0.7485308051109314,
                0.714367151260376,
                0.6482728719711304,
                0.6892340183258057,
                0.7173817157745361,
                0.7317185401916504,
                0.7612985372543335,
                0.7053219079971313,
                0.7564201354980469,
                0.7394168972969055,
                0.8144824504852295,
                0.7337771058082581,
                0.7063112854957581,
                0.7452118992805481,
                0.8324230313301086,
                0.8153106570243835,
                0.7210059762001038,
                0.7722876071929932,
                0.8078946471214294,
                0.760814905166626,
                0.7973484992980957,
                0.8647361993789673,
                0.7098493576049805,
                0.7670291662216187,
                0.8055649995803833,
                0.7547290325164795,
                0.8410850763320923
            ],
            [
                0.8119889497756958,
                0.8107329607009888,
                0.8308987021446228,
                0.842314600944519,
                0.8724152445793152,
                0.855715274810791,
                0.8944621086120605,
                0.8727133274078369,
                0.8875993490219116,
                0.8753041625022888,
                0.8773309588432312,
                0.8723926544189453,
                0.5838159918785095,
                0.8824414610862732,
                0.8828769326210022,
                0.8338751792907715,
                0.8833629488945007,
                0.885364830493927,
                0.880679726600647,
                0.8873488903045654,
                0.8544602990150452,
                0.7940112948417664,
                0.8923736214637756,
                0.6128381490707397,
                0.8753347396850586,
                0.8422727584838867,
                0.7891592979431152,
                0.8290475606918335,
                0.8303326368331909,
                0.8518162965774536,
                0.8927119374275208,
                0.7913321852684021,
                0.8044887781143188,
                0.8133381605148315,
                0.7655910849571228,
                0.8999569416046143,
                0.7284461855888367,
                0.8949073553085327,
                0.762937068939209,
                0.7987512350082397,
                0.8478156924247742,
                0.8871638774871826,
                0.7697837948799133,
                0.8646294474601746,
                0.7284306883811951,
                0.7197446823120117,
                0.8498751521110535,
                0.8830443024635315,
                0.7140653729438782,
                0.861594021320343,
                0.7387018203735352
            ],
            [
                0.7915009260177612,
                0.7942104935646057,
                0.8010031580924988,
                0.7727260589599609,
                0.876493513584137,
                0.8426104187965393,
                0.8551065921783447,
                0.8729307055473328,
                0.8539025783538818,
                0.887381374835968,
                0.8341751098632812,
                0.8550598621368408,
                0.5728880167007446,
                0.8553369045257568,
                0.8889695405960083,
                0.8382786512374878,
                0.8888919949531555,
                0.9093149304389954,
                0.8490312099456787,
                0.9331278204917908,
                0.821124255657196,
                0.8413100838661194,
                0.8587032556533813,
                0.6616171002388,
                0.9266757965087891,
                0.8178940415382385,
                0.8063030242919922,
                0.8184502124786377,
                0.8316777944564819,
                0.8437783718109131,
                0.8645481467247009,
                0.8291690945625305,
                0.8557960987091064,
                0.8426942229270935,
                0.7406328320503235,
                0.8692736029624939,
                0.7732688188552856,
                0.9305481314659119,
                0.769854724407196,
                0.8058415055274963,
                0.825427770614624,
                0.9052251577377319,
                0.7774655222892761,
                0.8829898238182068,
                0.7341790795326233,
                0.7151080369949341,
                0.8294081091880798,
                0.9200989007949829,
                0.7183883190155029,
                0.8745474815368652,
                0.7488897442817688
            ],
            [
                0.7656644582748413,
                0.7749964594841003,
                0.7629179358482361,
                0.7933166027069092,
                0.8187439441680908,
                0.7859430313110352,
                0.7816357016563416,
                0.7960307002067566,
                0.7813886404037476,
                0.8226414918899536,
                0.7760198712348938,
                0.8258470892906189,
                0.5927448868751526,
                0.7870945930480957,
                0.8635826110839844,
                0.7853893637657166,
                0.8213443160057068,
                0.8555668592453003,
                0.7811293601989746,
                0.8597894310951233,
                0.7648314237594604,
                0.767372190952301,
                0.8316759467124939,
                0.5699191093444824,
                0.8318583965301514,
                0.7655553817749023,
                0.7388898730278015,
                0.8178424835205078,
                0.822205126285553,
                0.8396475315093994,
                0.8252652883529663,
                0.7230958342552185,
                0.7709957361221313,
                0.7778695225715637,
                0.7603868842124939,
                0.8087056279182434,
                0.6998192071914673,
                0.853040874004364,
                0.7548692226409912,
                0.8053141832351685,
                0.7769526839256287,
                0.8827329874038696,
                0.7807443737983704,
                0.8554403781890869,
                0.7355817556381226,
                0.7039798498153687,
                0.7629599571228027,
                0.8630875945091248,
                0.71473228931427,
                0.8479533195495605,
                0.7311971187591553
            ],
            [
                0.7836756706237793,
                0.8954402208328247,
                0.7677381634712219,
                0.8645196557044983,
                0.7977442145347595,
                0.8365580439567566,
                0.7455369234085083,
                0.80329829454422,
                0.7531678676605225,
                0.8070098161697388,
                0.7553726434707642,
                0.9148144721984863,
                0.6860913038253784,
                0.7559983134269714,
                0.9119616150856018,
                0.7990711331367493,
                0.8366972208023071,
                0.8696166276931763,
                0.7472618818283081,
                0.828704297542572,
                0.774407684803009,
                0.7749203443527222,
                0.8422654867172241,
                0.5861014723777771,
                0.8011154532432556,
                0.7789344787597656,
                0.7118315100669861,
                0.7958935499191284,
                0.7823128700256348,
                0.8400753736495972,
                0.8306246399879456,
                0.690377414226532,
                0.7539583444595337,
                0.7618231177330017,
                0.8437079191207886,
                0.791985273361206,
                0.7029631733894348,
                0.8070970177650452,
                0.8416008949279785,
                0.9012383818626404,
                0.7868865132331848,
                0.8967658281326294,
                0.8454464673995972,
                0.8873343467712402,
                0.8210721015930176,
                0.8210098147392273,
                0.7649835348129272,
                0.8612214922904968,
                0.8125912547111511,
                0.8658391833305359,
                0.813278317451477
            ],
            [
                0.7922762632369995,
                0.7596225738525391,
                0.7889564037322998,
                0.7393368482589722,
                0.8690042495727539,
                0.8203481435775757,
                0.8668893575668335,
                0.8394780158996582,
                0.8675611019134521,
                0.8580151796340942,
                0.850401759147644,
                0.8093008399009705,
                0.5408004522323608,
                0.8641358613967896,
                0.8609267473220825,
                0.8067660927772522,
                0.8472638130187988,
                0.8547484874725342,
                0.8626730442047119,
                0.8821415305137634,
                0.8363515734672546,
                0.7999396324157715,
                0.8425423502922058,
                0.626785159111023,
                0.8850935697555542,
                0.8238246440887451,
                0.8304193019866943,
                0.7955772280693054,
                0.8505386710166931,
                0.8126925230026245,
                0.8583442568778992,
                0.8143346309661865,
                0.8205454349517822,
                0.830828845500946,
                0.7198578119277954,
                0.8706197738647461,
                0.7504721283912659,
                0.9080742001533508,
                0.7296746969223022,
                0.7487360239028931,
                0.8348149657249451,
                0.867029070854187,
                0.7497150897979736,
                0.8400542140007019,
                0.6934620141983032,
                0.6797177791595459,
                0.8353798389434814,
                0.8782978057861328,
                0.6773828268051147,
                0.8313701748847961,
                0.71430504322052
            ],
            [
                0.7698533535003662,
                0.8505246639251709,
                0.7731785178184509,
                0.8398334980010986,
                0.8171626329421997,
                0.847952663898468,
                0.7714778780937195,
                0.8849074840545654,
                0.7659600973129272,
                0.822287917137146,
                0.7603824138641357,
                0.9080535769462585,
                0.615820050239563,
                0.7691591382026672,
                0.937850296497345,
                0.8430629968643188,
                0.8898887634277344,
                0.8829952478408813,
                0.7606810331344604,
                0.8507505655288696,
                0.7597067356109619,
                0.7767504453659058,
                0.8514742255210876,
                0.5785377621650696,
                0.8356353640556335,
                0.7587328553199768,
                0.7060348391532898,
                0.8251551985740662,
                0.8016527891159058,
                0.8625012636184692,
                0.8839492201805115,
                0.7176178097724915,
                0.7689322829246521,
                0.7776135802268982,
                0.8347870111465454,
                0.8190755248069763,
                0.7005013823509216,
                0.8666605353355408,
                0.8520732522010803,
                0.8765382170677185,
                0.7651904225349426,
                0.9076091051101685,
                0.8405680060386658,
                0.8836466073989868,
                0.8144604563713074,
                0.7903202772140503,
                0.7537017464637756,
                0.8711444735527039,
                0.7720209360122681,
                0.87129145860672,
                0.8096793293952942
            ],
            [
                0.8281670808792114,
                0.8372985124588013,
                0.7934994697570801,
                0.8527771830558777,
                0.8627299070358276,
                0.8572942018508911,
                0.8165760636329651,
                0.8935381174087524,
                0.8233839869499207,
                0.8827848434448242,
                0.8154356479644775,
                0.8925135135650635,
                0.6475263833999634,
                0.8245795369148254,
                0.9001176953315735,
                0.8219721913337708,
                0.8902109861373901,
                0.9394142627716064,
                0.8216939568519592,
                0.9056646823883057,
                0.8240488171577454,
                0.8318601846694946,
                0.8986794948577881,
                0.6311519742012024,
                0.8989582061767578,
                0.8202137351036072,
                0.7975003123283386,
                0.862908661365509,
                0.8201038837432861,
                0.8932885527610779,
                0.8748517036437988,
                0.7603388428688049,
                0.8020952939987183,
                0.8040168285369873,
                0.7801812291145325,
                0.8610989451408386,
                0.7351058125495911,
                0.9106449484825134,
                0.7804539799690247,
                0.8366503715515137,
                0.8254374861717224,
                0.9450418949127197,
                0.8024676442146301,
                0.9363923668861389,
                0.7595043778419495,
                0.733731210231781,
                0.8223146200180054,
                0.9249431490898132,
                0.739980161190033,
                0.9210771322250366,
                0.7738929390907288
            ],
            [
                0.8652520179748535,
                0.7869223356246948,
                0.8505861759185791,
                0.8055254220962524,
                0.8651692271232605,
                0.8128472566604614,
                0.9312232732772827,
                0.7841455936431885,
                0.9500759243965149,
                0.8689067959785461,
                0.9458082318305969,
                0.8029544353485107,
                0.5920616388320923,
                0.9387217164039612,
                0.7806838750839233,
                0.7659467458724976,
                0.8225762248039246,
                0.8391486406326294,
                0.9463452100753784,
                0.8478926420211792,
                0.9444049000740051,
                0.7959619760513306,
                0.849867582321167,
                0.64585280418396,
                0.8475205302238464,
                0.935525119304657,
                0.846912682056427,
                0.7708155512809753,
                0.8235263824462891,
                0.7848398089408875,
                0.8598281145095825,
                0.7942665815353394,
                0.8043937087059021,
                0.7977311015129089,
                0.6951732635498047,
                0.9386572241783142,
                0.7447490692138672,
                0.8533307909965515,
                0.6717357635498047,
                0.7322790026664734,
                0.9425547122955322,
                0.8325732350349426,
                0.7015185356140137,
                0.8284074068069458,
                0.6611682772636414,
                0.6781337857246399,
                0.9507639408111572,
                0.8600647449493408,
                0.681175708770752,
                0.8102161288261414,
                0.6823610663414001
            ],
            [
                0.7281075716018677,
                0.8081850409507751,
                0.7508856058120728,
                0.744725227355957,
                0.7199602127075195,
                0.8001017570495605,
                0.6908596158027649,
                0.7331225275993347,
                0.6953130960464478,
                0.715903103351593,
                0.7009769678115845,
                0.8215884566307068,
                0.5982111096382141,
                0.7139500975608826,
                0.814548909664154,
                0.7750937342643738,
                0.7874303460121155,
                0.767844021320343,
                0.7067978382110596,
                0.7530685067176819,
                0.726235032081604,
                0.7240352630615234,
                0.7125723958015442,
                0.6176901459693909,
                0.7433317303657532,
                0.7471602559089661,
                0.6568755507469177,
                0.7022736072540283,
                0.7666472792625427,
                0.7353017330169678,
                0.7828088998794556,
                0.6853484511375427,
                0.7584829330444336,
                0.7449244260787964,
                0.8371032476425171,
                0.7438807487487793,
                0.7087024450302124,
                0.7783498167991638,
                0.7847815155982971,
                0.816677987575531,
                0.7481116056442261,
                0.8111289739608765,
                0.8079861402511597,
                0.7827662229537964,
                0.8214675784111023,
                0.8158737421035767,
                0.7381018996238708,
                0.7751508951187134,
                0.8145873546600342,
                0.7693476676940918,
                0.8249214291572571
            ],
            [
                0.7057947516441345,
                0.8409631848335266,
                0.7030872702598572,
                0.7553248405456543,
                0.7112585306167603,
                0.8096970319747925,
                0.6459095478057861,
                0.7299648523330688,
                0.6674428582191467,
                0.7094719409942627,
                0.6685149669647217,
                0.844178318977356,
                0.5977144241333008,
                0.6690673232078552,
                0.8302798271179199,
                0.8094736337661743,
                0.8169631958007812,
                0.7836021184921265,
                0.6704904437065125,
                0.7526386976242065,
                0.6888652443885803,
                0.7424579858779907,
                0.7347408533096313,
                0.590291440486908,
                0.74400794506073,
                0.7094496488571167,
                0.6177101731300354,
                0.7045170664787292,
                0.7458598613739014,
                0.7426661849021912,
                0.7700756788253784,
                0.6505424976348877,
                0.746441662311554,
                0.7253691554069519,
                0.9237917065620422,
                0.7188684940338135,
                0.6909657120704651,
                0.7633953094482422,
                0.8962126970291138,
                0.8795087933540344,
                0.7164969444274902,
                0.8284057378768921,
                0.8869988918304443,
                0.7956967353820801,
                0.9154476523399353,
                0.8749361634254456,
                0.7002954483032227,
                0.7855446934700012,
                0.8747326731681824,
                0.7781673073768616,
                0.8496885895729065
            ],
            [
                0.8593734502792358,
                0.7861264944076538,
                0.8417820930480957,
                0.810790479183197,
                0.8523722887039185,
                0.808497965335846,
                0.9263665676116943,
                0.7778661847114563,
                0.9367535710334778,
                0.8659368753433228,
                0.9435420632362366,
                0.8100726008415222,
                0.5978520512580872,
                0.9287763833999634,
                0.7862762212753296,
                0.7605845332145691,
                0.8234388828277588,
                0.840901255607605,
                0.9316136240959167,
                0.8352643251419067,
                0.957294225692749,
                0.7958535552024841,
                0.8666812777519226,
                0.6539474129676819,
                0.8399079442024231,
                0.9310775399208069,
                0.8361185789108276,
                0.7733421325683594,
                0.8350836634635925,
                0.7943045496940613,
                0.8624272346496582,
                0.7910131216049194,
                0.7970050573348999,
                0.821388840675354,
                0.7092958688735962,
                0.9311437606811523,
                0.7466573715209961,
                0.8433636426925659,
                0.6839391589164734,
                0.7578600645065308,
                0.9466586709022522,
                0.8375343680381775,
                0.7176380753517151,
                0.8309943675994873,
                0.6625352501869202,
                0.6867849230766296,
                0.9345575571060181,
                0.8511199355125427,
                0.6864304542541504,
                0.8041828870773315,
                0.6880651116371155
            ],
            [
                0.7202455401420593,
                0.7747363448143005,
                0.7625745534896851,
                0.7397658228874207,
                0.739463210105896,
                0.7869269251823425,
                0.7239359021186829,
                0.7496940493583679,
                0.7168322801589966,
                0.7545461058616638,
                0.7238128781318665,
                0.8135970830917358,
                0.5999394059181213,
                0.7390246987342834,
                0.8230594396591187,
                0.7752991318702698,
                0.80975341796875,
                0.7896024584770203,
                0.7260346412658691,
                0.7768682837486267,
                0.7612770199775696,
                0.7454813718795776,
                0.7770586609840393,
                0.6291844248771667,
                0.7793266773223877,
                0.7473167181015015,
                0.6790235042572021,
                0.723492443561554,
                0.8083683848381042,
                0.7606722116470337,
                0.808823823928833,
                0.7303622364997864,
                0.7798301577568054,
                0.8143492341041565,
                0.7976468801498413,
                0.7642267942428589,
                0.7318888902664185,
                0.8051344752311707,
                0.8025431632995605,
                0.8325169086456299,
                0.7576915621757507,
                0.8245639204978943,
                0.7836400866508484,
                0.7871921062469482,
                0.7626171112060547,
                0.7739444971084595,
                0.7350273728370667,
                0.7869643568992615,
                0.7491082549095154,
                0.7709994316101074,
                0.7912712097167969
            ],
            [
                0.793419599533081,
                0.8351725339889526,
                0.7856209874153137,
                0.8335434794425964,
                0.7953142523765564,
                0.8438186049461365,
                0.7781490683555603,
                0.8171250820159912,
                0.7884534597396851,
                0.8090078830718994,
                0.795863926410675,
                0.8845533132553101,
                0.6301723718643188,
                0.7954424619674683,
                0.8883181810379028,
                0.8334478735923767,
                0.8858628869056702,
                0.8536021709442139,
                0.7918286323547363,
                0.8199793696403503,
                0.8254578113555908,
                0.7807157039642334,
                0.8458541035652161,
                0.605154812335968,
                0.8131927251815796,
                0.8127778768539429,
                0.7319585084915161,
                0.7839459180831909,
                0.8337669968605042,
                0.8245364427566528,
                0.8715758919715881,
                0.706570565700531,
                0.7786079049110413,
                0.8041689991950989,
                0.8633987307548523,
                0.8421787023544312,
                0.7102236747741699,
                0.8508883714675903,
                0.8666801452636719,
                0.8920159935951233,
                0.833118736743927,
                0.9024178981781006,
                0.8853821754455566,
                0.8682045936584473,
                0.8332372903823853,
                0.8204424381256104,
                0.8069489598274231,
                0.8529343008995056,
                0.8092749714851379,
                0.8442543745040894,
                0.8081894516944885
            ],
            [
                0.7741259336471558,
                0.7834091782569885,
                0.7983813285827637,
                0.7510000467300415,
                0.7741454243659973,
                0.7921174764633179,
                0.7667309641838074,
                0.8012418746948242,
                0.7708053588867188,
                0.7988202571868896,
                0.7782664895057678,
                0.8192514181137085,
                0.5820903182029724,
                0.7801701426506042,
                0.8282544016838074,
                0.7821437120437622,
                0.8177379369735718,
                0.8050006031990051,
                0.7765458822250366,
                0.8049750328063965,
                0.7770746350288391,
                0.7623879313468933,
                0.7603222727775574,
                0.6332563757896423,
                0.8052862286567688,
                0.7891311049461365,
                0.7149636745452881,
                0.7208296656608582,
                0.8098580837249756,
                0.7516937851905823,
                0.8417760729789734,
                0.7582898139953613,
                0.790960431098938,
                0.7869778871536255,
                0.7720423340797424,
                0.8230098485946655,
                0.7644447684288025,
                0.861900806427002,
                0.7715713381767273,
                0.8068495988845825,
                0.7839965224266052,
                0.8374390602111816,
                0.7572093605995178,
                0.7967405319213867,
                0.7330368161201477,
                0.7459045648574829,
                0.8005017042160034,
                0.8166821002960205,
                0.7417160868644714,
                0.7936137318611145,
                0.7731521725654602
            ],
            [
                0.8041642308235168,
                0.8563095927238464,
                0.8115879893302917,
                0.8564611077308655,
                0.8175402283668518,
                0.859792947769165,
                0.8033128976821899,
                0.8481534719467163,
                0.8165799975395203,
                0.8234992027282715,
                0.8189678192138672,
                0.9025803208351135,
                0.6415866613388062,
                0.8190986514091492,
                0.9009701013565063,
                0.84957355260849,
                0.8938202261924744,
                0.870273232460022,
                0.8224252462387085,
                0.8388612866401672,
                0.8294854760169983,
                0.7940937876701355,
                0.8423333168029785,
                0.6080238819122314,
                0.8274801969528198,
                0.8278287053108215,
                0.7426737546920776,
                0.8003264665603638,
                0.8238492012023926,
                0.8377115726470947,
                0.8843899965286255,
                0.7301615476608276,
                0.7894734144210815,
                0.7972925901412964,
                0.8495873808860779,
                0.8590800166130066,
                0.7253533005714417,
                0.8723471164703369,
                0.8513526916503906,
                0.887254536151886,
                0.8349396586418152,
                0.9007782936096191,
                0.8528529405593872,
                0.8752765655517578,
                0.815345048904419,
                0.8119163513183594,
                0.8342986106872559,
                0.8683138489723206,
                0.8131811022758484,
                0.8687220811843872,
                0.8296966552734375
            ],
            [
                0.7377963066101074,
                0.7614152431488037,
                0.7739140391349792,
                0.7203356623649597,
                0.7323555946350098,
                0.7792652249336243,
                0.7284044027328491,
                0.7549649477005005,
                0.7261698842048645,
                0.7546678781509399,
                0.7333194613456726,
                0.8026549816131592,
                0.5849742889404297,
                0.7402133345603943,
                0.814235508441925,
                0.7606367468833923,
                0.7926427125930786,
                0.7818776965141296,
                0.7338545322418213,
                0.7781458497047424,
                0.7454494833946228,
                0.748650848865509,
                0.7315014004707336,
                0.6416614055633545,
                0.7847628593444824,
                0.754848837852478,
                0.683013379573822,
                0.7064329981803894,
                0.8011654615402222,
                0.7357689142227173,
                0.8000444173812866,
                0.7429567575454712,
                0.7886963486671448,
                0.786349892616272,
                0.7754433155059814,
                0.7755027413368225,
                0.750503420829773,
                0.8161904811859131,
                0.7707251906394958,
                0.8021754622459412,
                0.7578630447387695,
                0.8148373365402222,
                0.7672142386436462,
                0.7739477157592773,
                0.7529307007789612,
                0.7520430088043213,
                0.7521957159042358,
                0.7877817153930664,
                0.737583577632904,
                0.7626615762710571,
                0.7652745246887207
            ],
            [
                0.8064446449279785,
                0.8640621304512024,
                0.8110669255256653,
                0.8112211227416992,
                0.7917525768280029,
                0.8412062525749207,
                0.7743006944656372,
                0.7999994158744812,
                0.7916648983955383,
                0.7929396629333496,
                0.7935007810592651,
                0.889539897441864,
                0.6271839737892151,
                0.7919180989265442,
                0.8816972970962524,
                0.8345912098884583,
                0.860342800617218,
                0.8414627313613892,
                0.793799877166748,
                0.8216056823730469,
                0.8131593465805054,
                0.8104541301727295,
                0.796835720539093,
                0.6423990726470947,
                0.8174192309379578,
                0.8175703287124634,
                0.7191928029060364,
                0.7761558294296265,
                0.8141931295394897,
                0.8090129494667053,
                0.8553838133811951,
                0.7306146621704102,
                0.8045654296875,
                0.7990556359291077,
                0.8532683849334717,
                0.8344199657440186,
                0.7530225515365601,
                0.8394126296043396,
                0.8483522534370422,
                0.8801968693733215,
                0.825141191482544,
                0.8733102083206177,
                0.8447373509407043,
                0.8444691896438599,
                0.8426514863967896,
                0.8378743529319763,
                0.8114794492721558,
                0.8476606607437134,
                0.8227154016494751,
                0.8290422558784485,
                0.824543833732605
            ],
            [
                0.8242954611778259,
                0.8100932240486145,
                0.7974758148193359,
                0.7580822110176086,
                0.8490994572639465,
                0.850991427898407,
                0.8350724577903748,
                0.8367188572883606,
                0.8406738638877869,
                0.8660420179367065,
                0.8390398025512695,
                0.8515149354934692,
                0.6036285161972046,
                0.8490622043609619,
                0.8630355000495911,
                0.8148652911186218,
                0.8749815225601196,
                0.8823474645614624,
                0.8419361710548401,
                0.8972563743591309,
                0.8478139638900757,
                0.82964026927948,
                0.8385134935379028,
                0.6849114894866943,
                0.9025468826293945,
                0.8490439653396606,
                0.8233039379119873,
                0.7872018218040466,
                0.874719500541687,
                0.8121676445007324,
                0.8756890296936035,
                0.8299509882926941,
                0.8654001355171204,
                0.8673165440559387,
                0.774259090423584,
                0.8723070621490479,
                0.7945739030838013,
                0.9231349229812622,
                0.7826311588287354,
                0.8123903274536133,
                0.8560361266136169,
                0.8994973301887512,
                0.8025662302970886,
                0.8705150485038757,
                0.7431223392486572,
                0.7239251732826233,
                0.847693920135498,
                0.9009623527526855,
                0.739589273929596,
                0.8501908183097839,
                0.7497854828834534
            ],
            [
                0.7777259945869446,
                0.8356283903121948,
                0.7948077917098999,
                0.7738419771194458,
                0.8190715909004211,
                0.8464335203170776,
                0.7701880931854248,
                0.7823067903518677,
                0.7735140919685364,
                0.7800693511962891,
                0.7797853350639343,
                0.8647903203964233,
                0.6086568832397461,
                0.7881529927253723,
                0.8691178560256958,
                0.8527113199234009,
                0.8434481024742126,
                0.8245624899864197,
                0.7752088904380798,
                0.8271923661231995,
                0.7895984053611755,
                0.7746899127960205,
                0.7781277894973755,
                0.6497893929481506,
                0.8155673146247864,
                0.8038866519927979,
                0.7465900778770447,
                0.7557676434516907,
                0.8390060067176819,
                0.7907501459121704,
                0.8524306416511536,
                0.7563878893852234,
                0.8156020641326904,
                0.8194577097892761,
                0.8449682593345642,
                0.8157821893692017,
                0.7500027418136597,
                0.8503624200820923,
                0.8199536204338074,
                0.8387901782989502,
                0.8037926554679871,
                0.8600676655769348,
                0.8304606080055237,
                0.828230619430542,
                0.7944705486297607,
                0.8096804022789001,
                0.790088415145874,
                0.8346720337867737,
                0.8042698502540588,
                0.8124057054519653,
                0.8184975981712341
            ],
            [
                0.7752257585525513,
                0.7949842810630798,
                0.7975972890853882,
                0.7412878274917603,
                0.8488255739212036,
                0.8125693798065186,
                0.7992689609527588,
                0.7683936953544617,
                0.8063991069793701,
                0.8005558252334595,
                0.7990356087684631,
                0.8216558694839478,
                0.5758342742919922,
                0.8215158581733704,
                0.8334050178527832,
                0.8257887959480286,
                0.8341465592384338,
                0.81759113073349,
                0.8080418109893799,
                0.837460994720459,
                0.8102853894233704,
                0.7735260128974915,
                0.7646878361701965,
                0.6626062393188477,
                0.830098032951355,
                0.8210009336471558,
                0.7764286994934082,
                0.734610378742218,
                0.813610315322876,
                0.7682479619979858,
                0.8182847499847412,
                0.7824644446372986,
                0.8266587853431702,
                0.8159658908843994,
                0.7757055163383484,
                0.8284621834754944,
                0.7603029012680054,
                0.8534969687461853,
                0.7763769030570984,
                0.8066838383674622,
                0.8165908455848694,
                0.8403912782669067,
                0.7993872165679932,
                0.8125370740890503,
                0.7513221502304077,
                0.7553318738937378,
                0.8155434131622314,
                0.8363358378410339,
                0.750061571598053,
                0.7953296303749084,
                0.7754145264625549
            ],
            [
                0.8129175305366516,
                0.8808580636978149,
                0.8206716775894165,
                0.8316879272460938,
                0.8531044721603394,
                0.8902254700660706,
                0.8386601209640503,
                0.8396542072296143,
                0.8475916385650635,
                0.8378741145133972,
                0.8433591723442078,
                0.9065359234809875,
                0.6382583975791931,
                0.8502950668334961,
                0.9186170697212219,
                0.8984124660491943,
                0.9110248684883118,
                0.8772188425064087,
                0.8438212871551514,
                0.851818859577179,
                0.8488993048667908,
                0.8014881610870361,
                0.8453475832939148,
                0.6477264761924744,
                0.844025731086731,
                0.8565934300422668,
                0.7941576242446899,
                0.7985501885414124,
                0.8358039259910583,
                0.8361539840698242,
                0.8851244449615479,
                0.7704707384109497,
                0.816668689250946,
                0.8226795196533203,
                0.8667116165161133,
                0.8744338750839233,
                0.7446429133415222,
                0.8705924153327942,
                0.8444655537605286,
                0.8723874688148499,
                0.8625237941741943,
                0.894489049911499,
                0.8672322034835815,
                0.8719318509101868,
                0.819934606552124,
                0.8222123384475708,
                0.8466289639472961,
                0.8774661421775818,
                0.83883136510849,
                0.8514450788497925,
                0.8482446074485779
            ],
            [
                0.7919358611106873,
                0.7703542709350586,
                0.7749456763267517,
                0.7538179755210876,
                0.850323498249054,
                0.8159873485565186,
                0.8440170288085938,
                0.7913313508033752,
                0.8398033976554871,
                0.8458693027496338,
                0.836887001991272,
                0.8026794195175171,
                0.5676374435424805,
                0.8543960452079773,
                0.8314593434333801,
                0.78960782289505,
                0.8308040499687195,
                0.8533817529678345,
                0.8468387722969055,
                0.8865326046943665,
                0.8332905173301697,
                0.7956380844116211,
                0.8254960775375366,
                0.6484023332595825,
                0.8806020617485046,
                0.8299241065979004,
                0.8208791613578796,
                0.7916259765625,
                0.8747788071632385,
                0.814571738243103,
                0.849266529083252,
                0.816613495349884,
                0.840874969959259,
                0.8529013991355896,
                0.7271807193756104,
                0.8501608967781067,
                0.7620469927787781,
                0.8839448690414429,
                0.7243883609771729,
                0.7578853964805603,
                0.8346503973007202,
                0.8620753288269043,
                0.74331134557724,
                0.84173184633255,
                0.6822054386138916,
                0.67038494348526,
                0.8236305117607117,
                0.8700432181358337,
                0.690867006778717,
                0.8216484189033508,
                0.7086227536201477
            ],
            [
                0.7768955826759338,
                0.7757842540740967,
                0.799606442451477,
                0.7339503169059753,
                0.8915956020355225,
                0.8162415027618408,
                0.8582080602645874,
                0.7803473472595215,
                0.8611739277839661,
                0.8400632739067078,
                0.8482239246368408,
                0.7967707514762878,
                0.5443165898323059,
                0.8717429637908936,
                0.8278070092201233,
                0.8387088775634766,
                0.8353915810585022,
                0.840319037437439,
                0.8658148646354675,
                0.8883529901504517,
                0.8440738916397095,
                0.7892223596572876,
                0.8142744898796082,
                0.6644463539123535,
                0.8767527341842651,
                0.839961051940918,
                0.8295360803604126,
                0.7815620303153992,
                0.8514423966407776,
                0.8062787055969238,
                0.8348352909088135,
                0.8227855563163757,
                0.8493828177452087,
                0.8513036370277405,
                0.7258120775222778,
                0.8639079332351685,
                0.754572331905365,
                0.8836899399757385,
                0.7318177223205566,
                0.7611463665962219,
                0.8440225720405579,
                0.8436338901519775,
                0.7392708659172058,
                0.8219717144966125,
                0.6750010251998901,
                0.7012467980384827,
                0.8415143489837646,
                0.8634485006332397,
                0.7011182308197021,
                0.8105936050415039,
                0.7336871027946472
            ],
            [
                0.8548632860183716,
                0.8892862796783447,
                0.873591423034668,
                0.8297823667526245,
                0.8843466639518738,
                0.8859636187553406,
                0.8749269247055054,
                0.8344504833221436,
                0.8890467286109924,
                0.8457790017127991,
                0.8866670727729797,
                0.9007412195205688,
                0.6450698971748352,
                0.8932639360427856,
                0.891493558883667,
                0.8797678351402283,
                0.8892330527305603,
                0.866481363773346,
                0.8906289339065552,
                0.851565957069397,
                0.9001362323760986,
                0.8078127503395081,
                0.8252999782562256,
                0.6637864708900452,
                0.8453960418701172,
                0.904100239276886,
                0.8250973224639893,
                0.7891432642936707,
                0.8160721063613892,
                0.8236778378486633,
                0.8922758102416992,
                0.7857472896575928,
                0.8167576789855957,
                0.8106175065040588,
                0.8132038116455078,
                0.9086841940879822,
                0.7592649459838867,
                0.8684258460998535,
                0.7946451902389526,
                0.8346270322799683,
                0.9017734527587891,
                0.8655085563659668,
                0.8148888349533081,
                0.8581854104995728,
                0.7804234027862549,
                0.8200446367263794,
                0.9000298976898193,
                0.8736587762832642,
                0.8070085644721985,
                0.8365879058837891,
                0.8299217820167542
            ],
            [
                0.77451092004776,
                0.7721792459487915,
                0.7650942802429199,
                0.7445348501205444,
                0.836355447769165,
                0.8231580853462219,
                0.8028157949447632,
                0.7865332365036011,
                0.8054315447807312,
                0.8340233564376831,
                0.8033146858215332,
                0.8176339268684387,
                0.5929644107818604,
                0.8215505480766296,
                0.8406959176063538,
                0.7941663861274719,
                0.8314173221588135,
                0.8693269491195679,
                0.81283038854599,
                0.8993124961853027,
                0.8122159838676453,
                0.8284875154495239,
                0.8231899738311768,
                0.6827855110168457,
                0.8938705921173096,
                0.8121761083602905,
                0.8003978133201599,
                0.7734189629554749,
                0.8525358438491821,
                0.8036633729934692,
                0.8217636346817017,
                0.8241034746170044,
                0.8612334728240967,
                0.860670268535614,
                0.7483551502227783,
                0.8334345817565918,
                0.7923064231872559,
                0.8810901641845703,
                0.7719544172286987,
                0.7997989654541016,
                0.8133228421211243,
                0.8787603974342346,
                0.7771209478378296,
                0.8557788729667664,
                0.7286152839660645,
                0.7039972543716431,
                0.8064752221107483,
                0.8815234303474426,
                0.7270466089248657,
                0.8374797105789185,
                0.7421714067459106
            ],
            [
                0.7642459869384766,
                0.7696009874343872,
                0.7718654870986938,
                0.7095986008644104,
                0.8176788091659546,
                0.7890151739120483,
                0.7807493209838867,
                0.7361209392547607,
                0.7826723456382751,
                0.7840054035186768,
                0.7871580123901367,
                0.8007528781890869,
                0.5840338468551636,
                0.8062056303024292,
                0.8054431676864624,
                0.7670687437057495,
                0.7923760414123535,
                0.8096514940261841,
                0.7927699089050293,
                0.8448100686073303,
                0.8039892911911011,
                0.7796446084976196,
                0.7473924160003662,
                0.6670054793357849,
                0.8336620926856995,
                0.8109356164932251,
                0.7760571837425232,
                0.716630756855011,
                0.8153697848320007,
                0.752411961555481,
                0.7992777228355408,
                0.7981574535369873,
                0.8321740627288818,
                0.8256048560142517,
                0.7294766306877136,
                0.8099223375320435,
                0.7746511101722717,
                0.8405922055244446,
                0.7526895999908447,
                0.7906805872917175,
                0.8017937541007996,
                0.8216280937194824,
                0.7414085268974304,
                0.8004471659660339,
                0.6955510377883911,
                0.7075482606887817,
                0.8020714521408081,
                0.8277966380119324,
                0.7189297080039978,
                0.7764315009117126,
                0.7499651312828064
            ],
            [
                0.8527072668075562,
                0.88426274061203,
                0.8596527576446533,
                0.8401451706886292,
                0.884939968585968,
                0.8980664610862732,
                0.8871748447418213,
                0.8546082973480225,
                0.900505542755127,
                0.8601922988891602,
                0.9005658626556396,
                0.8980442881584167,
                0.6328370571136475,
                0.9002571702003479,
                0.9090476632118225,
                0.8880650997161865,
                0.9149649739265442,
                0.8812965750694275,
                0.9016567468643188,
                0.8675641417503357,
                0.9033210277557373,
                0.8195041418075562,
                0.8459010720252991,
                0.6735994219779968,
                0.8648287653923035,
                0.9045323729515076,
                0.8296692371368408,
                0.7960963845252991,
                0.8393374085426331,
                0.8315190672874451,
                0.9186214804649353,
                0.8033762574195862,
                0.8313546180725098,
                0.8285976648330688,
                0.8222169876098633,
                0.922775387763977,
                0.7713547945022583,
                0.892006516456604,
                0.8161327838897705,
                0.844290554523468,
                0.9029232263565063,
                0.8797144889831543,
                0.8141993284225464,
                0.8657747507095337,
                0.7737570405006409,
                0.8109335899353027,
                0.9037383198738098,
                0.8831422328948975,
                0.8037832379341125,
                0.8506017327308655,
                0.830255389213562
            ],
            [
                0.7419990301132202,
                0.7957926392555237,
                0.7982834577560425,
                0.763826847076416,
                0.7693669199943542,
                0.8017396330833435,
                0.7481235265731812,
                0.8070732355117798,
                0.7513003945350647,
                0.7878794074058533,
                0.756704568862915,
                0.8340755105018616,
                0.5929993987083435,
                0.7628622055053711,
                0.8456445336341858,
                0.8110989928245544,
                0.8388043642044067,
                0.8104349970817566,
                0.7532935738563538,
                0.8066969513893127,
                0.7490159273147583,
                0.7479103207588196,
                0.7675089240074158,
                0.6208482384681702,
                0.797554075717926,
                0.7575297951698303,
                0.6798038482666016,
                0.7202295064926147,
                0.7947426438331604,
                0.7548348903656006,
                0.8514549732208252,
                0.7488441467285156,
                0.7886320352554321,
                0.7852058410644531,
                0.7967210412025452,
                0.8119041919708252,
                0.7447728514671326,
                0.8524726629257202,
                0.8100787997245789,
                0.8290496468544006,
                0.7521205544471741,
                0.831891655921936,
                0.7777608036994934,
                0.791161298751831,
                0.7631826996803284,
                0.7690960168838501,
                0.7578212022781372,
                0.803213357925415,
                0.7517821788787842,
                0.7922376394271851,
                0.792310893535614
            ],
            [
                0.8208974599838257,
                0.8843137621879578,
                0.8185744285583496,
                0.8456828594207764,
                0.8086516857147217,
                0.8621331453323364,
                0.7827116847038269,
                0.7986294031143188,
                0.8016560077667236,
                0.7960482239723206,
                0.8079891204833984,
                0.9076744318008423,
                0.6498181819915771,
                0.8006043434143066,
                0.8798606395721436,
                0.8496646881103516,
                0.8706096410751343,
                0.8465589880943298,
                0.8033918142318726,
                0.8191725015640259,
                0.821325957775116,
                0.7974668741226196,
                0.8150654435157776,
                0.6376073360443115,
                0.8100597858428955,
                0.8319342136383057,
                0.716681957244873,
                0.7701014280319214,
                0.8205118775367737,
                0.8075071573257446,
                0.8746383190155029,
                0.7232381105422974,
                0.7921615839004517,
                0.7949907183647156,
                0.8940926790237427,
                0.8470993041992188,
                0.7439113855361938,
                0.8499006628990173,
                0.8762274384498596,
                0.8942821621894836,
                0.834773600101471,
                0.8868889808654785,
                0.8689818978309631,
                0.8526646494865417,
                0.8639419078826904,
                0.8568722605705261,
                0.816024899482727,
                0.8465583920478821,
                0.8357099294662476,
                0.8341810703277588,
                0.8343631625175476
            ],
            [
                0.7448068857192993,
                0.7540879845619202,
                0.7814028263092041,
                0.7284530997276306,
                0.7399444580078125,
                0.7752867937088013,
                0.7344310879707336,
                0.7690960168838501,
                0.7328218221664429,
                0.7613255977630615,
                0.7482078075408936,
                0.7923160195350647,
                0.5869932174682617,
                0.7454949617385864,
                0.8130941987037659,
                0.7664684057235718,
                0.7964099645614624,
                0.7798323035240173,
                0.7394839525222778,
                0.7719660997390747,
                0.7513699531555176,
                0.7446722984313965,
                0.7369899153709412,
                0.6350025534629822,
                0.7766103148460388,
                0.761172354221344,
                0.6866300106048584,
                0.7099308371543884,
                0.7947566509246826,
                0.7376832962036133,
                0.8178238868713379,
                0.7396120429039001,
                0.7762938737869263,
                0.7749864459037781,
                0.7697384357452393,
                0.7943920493125916,
                0.7520043849945068,
                0.8268183469772339,
                0.7599766850471497,
                0.7941882610321045,
                0.7637631297111511,
                0.8133572936058044,
                0.7488656640052795,
                0.7712772488594055,
                0.7286497950553894,
                0.7325273156166077,
                0.7586069703102112,
                0.7803436517715454,
                0.7343026995658875,
                0.764042854309082,
                0.7537129521369934
            ],
            [
                0.7812898755073547,
                0.8779895901679993,
                0.7878854274749756,
                0.8591916561126709,
                0.805180013179779,
                0.8649798035621643,
                0.7523097395896912,
                0.8393835425376892,
                0.7613556385040283,
                0.8014451861381531,
                0.7611260414123535,
                0.9175349473953247,
                0.6341860294342041,
                0.7600484490394592,
                0.9123020172119141,
                0.8721478581428528,
                0.8804706335067749,
                0.8658325672149658,
                0.7518618106842041,
                0.8142402768135071,
                0.763630747795105,
                0.7714531421661377,
                0.8271528482437134,
                0.588725209236145,
                0.8020625114440918,
                0.7710564136505127,
                0.6825733780860901,
                0.7945482730865479,
                0.7925645709037781,
                0.8376780152320862,
                0.8639125227928162,
                0.6825914978981018,
                0.7467919588088989,
                0.7579673528671265,
                0.8989269733428955,
                0.8118538856506348,
                0.6923080086708069,
                0.8359834551811218,
                0.8737561702728271,
                0.8957110643386841,
                0.7749923467636108,
                0.8969950675964355,
                0.8823541402816772,
                0.8677206039428711,
                0.8710443377494812,
                0.8429911732673645,
                0.7565021514892578,
                0.843558669090271,
                0.8367301225662231,
                0.850884735584259,
                0.8476445078849792
            ],
            [
                0.8366092443466187,
                0.8310583233833313,
                0.7860313057899475,
                0.8671647310256958,
                0.857712984085083,
                0.838805079460144,
                0.8211461305618286,
                0.8847532868385315,
                0.8234641551971436,
                0.8794776201248169,
                0.8203640580177307,
                0.892262876033783,
                0.6416876316070557,
                0.8257740139961243,
                0.8893885612487793,
                0.7999576330184937,
                0.871380090713501,
                0.9312571883201599,
                0.8182830810546875,
                0.8992153406143188,
                0.8233080506324768,
                0.8054176568984985,
                0.9075441360473633,
                0.5839819312095642,
                0.8758335709571838,
                0.8149104118347168,
                0.7902274131774902,
                0.8691835403442383,
                0.8096925616264343,
                0.8995130658149719,
                0.866096556186676,
                0.7263098955154419,
                0.7649433016777039,
                0.7796340584754944,
                0.7582370638847351,
                0.8606381416320801,
                0.6989855170249939,
                0.9022513628005981,
                0.7545225024223328,
                0.8167826533317566,
                0.8239426612854004,
                0.9520250558853149,
                0.7934485673904419,
                0.9459714889526367,
                0.7441439032554626,
                0.6971091628074646,
                0.81634122133255,
                0.9230440258979797,
                0.7169944047927856,
                0.9286893606185913,
                0.7411743402481079
            ],
            [
                0.871787428855896,
                0.7957891821861267,
                0.8601172566413879,
                0.8187075257301331,
                0.8600031137466431,
                0.8213230967521667,
                0.9219569563865662,
                0.7861801385879517,
                0.9344086050987244,
                0.8673948049545288,
                0.9411298036575317,
                0.8301630020141602,
                0.620011568069458,
                0.9245211482048035,
                0.8059716820716858,
                0.7688503861427307,
                0.8273783922195435,
                0.8584025502204895,
                0.9300828576087952,
                0.8565409183502197,
                0.9403589367866516,
                0.8425459861755371,
                0.8483526110649109,
                0.6807724237442017,
                0.8653818368911743,
                0.9336140751838684,
                0.8310843110084534,
                0.7745607495307922,
                0.8318764567375183,
                0.7944568395614624,
                0.8657451868057251,
                0.8152036666870117,
                0.8218005895614624,
                0.8223397135734558,
                0.7203640341758728,
                0.9337661862373352,
                0.7890634536743164,
                0.8567935824394226,
                0.7136664986610413,
                0.7859649062156677,
                0.9306160807609558,
                0.8484087586402893,
                0.7192158102989197,
                0.8362064361572266,
                0.6806483864784241,
                0.699420690536499,
                0.9329116940498352,
                0.8645710349082947,
                0.7083518505096436,
                0.815540075302124,
                0.7143921852111816
            ],
            [
                0.7306340336799622,
                0.7776649594306946,
                0.786727786064148,
                0.7385815978050232,
                0.7641100287437439,
                0.7732479572296143,
                0.7357900142669678,
                0.7856453061103821,
                0.7293063402175903,
                0.7628676891326904,
                0.7346972823143005,
                0.8235016465187073,
                0.5860036611557007,
                0.7390502691268921,
                0.8407164216041565,
                0.7874298691749573,
                0.7845959663391113,
                0.8062378764152527,
                0.7312895655632019,
                0.8068820834159851,
                0.7377626895904541,
                0.7711889743804932,
                0.758607804775238,
                0.6210715174674988,
                0.8056012392044067,
                0.7385702729225159,
                0.6759885549545288,
                0.7689159512519836,
                0.826076328754425,
                0.7925096154212952,
                0.8213238716125488,
                0.7385836839675903,
                0.7990658283233643,
                0.8029277324676514,
                0.7748060822486877,
                0.7839226722717285,
                0.73789381980896,
                0.8150883316993713,
                0.7869313955307007,
                0.8245582580566406,
                0.7447288036346436,
                0.8231762647628784,
                0.779859185218811,
                0.802208423614502,
                0.7553473711013794,
                0.7446043491363525,
                0.7432222962379456,
                0.8065319657325745,
                0.7628903388977051,
                0.8016406297683716,
                0.7845138311386108
            ],
            [
                0.7187713980674744,
                0.8427527546882629,
                0.7489222288131714,
                0.7963932752609253,
                0.7823517918586731,
                0.8132307529449463,
                0.6950541734695435,
                0.7892429232597351,
                0.7046350836753845,
                0.7458886504173279,
                0.6966286301612854,
                0.8736982345581055,
                0.5949447154998779,
                0.7026709318161011,
                0.8774627447128296,
                0.8629657030105591,
                0.845275342464447,
                0.8171406984329224,
                0.6964216828346252,
                0.7919944524765015,
                0.6950953602790833,
                0.7548630833625793,
                0.772384524345398,
                0.5682566165924072,
                0.7736837863922119,
                0.7050074934959412,
                0.6266631484031677,
                0.7525864839553833,
                0.7564643621444702,
                0.7958504557609558,
                0.8302494883537292,
                0.6727675199508667,
                0.7429562211036682,
                0.7426613569259644,
                0.869762122631073,
                0.7591619491577148,
                0.6813221573829651,
                0.8064671754837036,
                0.8982383608818054,
                0.894770085811615,
                0.7008334994316101,
                0.84666907787323,
                0.8414088487625122,
                0.8120507001876831,
                0.8345286846160889,
                0.8320285677909851,
                0.6934131383895874,
                0.8035240173339844,
                0.8191612362861633,
                0.8045148849487305,
                0.85917067527771
            ],
            [
                0.7457298636436462,
                0.758960485458374,
                0.7544446587562561,
                0.7163594961166382,
                0.7595821619033813,
                0.7686857581138611,
                0.7375805974006653,
                0.7583120465278625,
                0.7337892055511475,
                0.7608824372291565,
                0.7405365705490112,
                0.8065597414970398,
                0.5620749592781067,
                0.7499172687530518,
                0.8183907270431519,
                0.7522450089454651,
                0.7734209299087524,
                0.7887185215950012,
                0.7394946813583374,
                0.807212769985199,
                0.7414827942848206,
                0.7690920233726501,
                0.7325180768966675,
                0.6234869956970215,
                0.8019363880157471,
                0.756486177444458,
                0.6904104948043823,
                0.701906681060791,
                0.7937670946121216,
                0.734963059425354,
                0.8040781021118164,
                0.7502787709236145,
                0.7830831408500671,
                0.7759509086608887,
                0.7730649709701538,
                0.7704602479934692,
                0.7672103643417358,
                0.8176162838935852,
                0.7799956798553467,
                0.8057156205177307,
                0.7442427277565002,
                0.821272075176239,
                0.7605715990066528,
                0.780842661857605,
                0.7403519153594971,
                0.7127572298049927,
                0.742668628692627,
                0.8011207580566406,
                0.7213506102561951,
                0.7607266306877136,
                0.7562622427940369
            ],
            [
                0.7527918219566345,
                0.8370072841644287,
                0.7651492953300476,
                0.8308927416801453,
                0.7815194725990295,
                0.8281933665275574,
                0.7196140289306641,
                0.8140562176704407,
                0.7294399738311768,
                0.8001000285148621,
                0.7317147254943848,
                0.877701461315155,
                0.6457976698875427,
                0.7331955432891846,
                0.8856778144836426,
                0.8485361337661743,
                0.8655132055282593,
                0.8708041310310364,
                0.7316570281982422,
                0.8122015595436096,
                0.7394016981124878,
                0.7646329998970032,
                0.8399370908737183,
                0.5581657886505127,
                0.8031667470932007,
                0.7451364994049072,
                0.6782053709030151,
                0.7751120328903198,
                0.7689207196235657,
                0.8174974322319031,
                0.8296775817871094,
                0.6703030467033386,
                0.7395817041397095,
                0.7467636466026306,
                0.8446762561798096,
                0.7912139892578125,
                0.6695272326469421,
                0.8192000985145569,
                0.8693682551383972,
                0.9010810256004333,
                0.7487514019012451,
                0.8767816424369812,
                0.845535159111023,
                0.8522836565971375,
                0.8071966171264648,
                0.786207914352417,
                0.7335014939308167,
                0.8338382244110107,
                0.8094985485076904,
                0.8466051816940308,
                0.8175208568572998
            ],
            [
                0.7588752508163452,
                0.7809164524078369,
                0.7825406789779663,
                0.7517071962356567,
                0.7548601627349854,
                0.7834522724151611,
                0.7539269328117371,
                0.7840261459350586,
                0.7484996318817139,
                0.778069257736206,
                0.760701596736908,
                0.8205000162124634,
                0.5694402456283569,
                0.7591750621795654,
                0.8349758386611938,
                0.7924186587333679,
                0.7982571125030518,
                0.7889164686203003,
                0.7473558783531189,
                0.7802250385284424,
                0.7562029957771301,
                0.7275828719139099,
                0.7508657574653625,
                0.5984577536582947,
                0.7766792178153992,
                0.771775484085083,
                0.6809736490249634,
                0.7203235626220703,
                0.8255306482315063,
                0.7527340054512024,
                0.834967851638794,
                0.7196862697601318,
                0.761154055595398,
                0.7703951001167297,
                0.7954515814781189,
                0.8029032945632935,
                0.7217369079589844,
                0.8251919150352478,
                0.7798371315002441,
                0.8056051731109619,
                0.7729038596153259,
                0.8271834850311279,
                0.7995864152908325,
                0.789643406867981,
                0.7636784315109253,
                0.736278235912323,
                0.765072226524353,
                0.7957313656806946,
                0.75528484582901,
                0.7741849422454834,
                0.7735821008682251
            ],
            [
                0.7578198909759521,
                0.763742208480835,
                0.7579118013381958,
                0.6941965222358704,
                0.7713173031806946,
                0.7735732197761536,
                0.7622390389442444,
                0.7732582092285156,
                0.765483558177948,
                0.7672484517097473,
                0.7699480056762695,
                0.7838123440742493,
                0.5386490225791931,
                0.7761836647987366,
                0.8004813194274902,
                0.7678349614143372,
                0.7868683338165283,
                0.7639176845550537,
                0.7621986269950867,
                0.7841314673423767,
                0.7656058073043823,
                0.7261167764663696,
                0.7187674045562744,
                0.6229735612869263,
                0.7805011868476868,
                0.7883449792861938,
                0.7170397043228149,
                0.6841639280319214,
                0.826300323009491,
                0.714369535446167,
                0.8248289823532104,
                0.7510623335838318,
                0.7769050002098083,
                0.7755796909332275,
                0.7554550170898438,
                0.7963330149650574,
                0.7414621710777283,
                0.826565682888031,
                0.7494067549705505,
                0.7545003294944763,
                0.7761430144309998,
                0.8008288741111755,
                0.745575487613678,
                0.7661834359169006,
                0.7238963842391968,
                0.7085149884223938,
                0.7764683365821838,
                0.7818905115127563,
                0.7057753801345825,
                0.7395855188369751,
                0.730190098285675
            ],
            [
                0.6919770240783691,
                0.7987264394760132,
                0.712576150894165,
                0.7544164061546326,
                0.7301428318023682,
                0.7683898210525513,
                0.6459565162658691,
                0.6792222857475281,
                0.6656357645988464,
                0.6835660934448242,
                0.6672130823135376,
                0.8108538389205933,
                0.592547595500946,
                0.6664125919342041,
                0.8039542436599731,
                0.7959450483322144,
                0.7728706002235413,
                0.7535947561264038,
                0.6676680445671082,
                0.7381342649459839,
                0.6869685053825378,
                0.7394408583641052,
                0.7344650030136108,
                0.582491934299469,
                0.7265486121177673,
                0.7199987769126892,
                0.6119801998138428,
                0.7007701992988586,
                0.7768796682357788,
                0.7335816621780396,
                0.7466684579849243,
                0.6358873248100281,
                0.741274356842041,
                0.7338345050811768,
                0.873711347579956,
                0.7129103541374207,
                0.6719794273376465,
                0.7460094690322876,
                0.8798392415046692,
                0.8784788846969604,
                0.7138517498970032,
                0.8123617768287659,
                0.8479934930801392,
                0.7756472826004028,
                0.863892674446106,
                0.8478631973266602,
                0.6888197064399719,
                0.7682992815971375,
                0.8439638018608093,
                0.7624605894088745,
                0.814251720905304
            ],
            [
                0.7701319456100464,
                0.8508366346359253,
                0.7944114208221436,
                0.8197554349899292,
                0.8125655651092529,
                0.8390684127807617,
                0.7507246732711792,
                0.801419198513031,
                0.7666071057319641,
                0.8098878860473633,
                0.7657484412193298,
                0.8747805953025818,
                0.6246893405914307,
                0.7678801417350769,
                0.8854674100875854,
                0.8887413144111633,
                0.8707699179649353,
                0.8631675839424133,
                0.7593690752983093,
                0.8083693981170654,
                0.7706415057182312,
                0.7638903260231018,
                0.8224848508834839,
                0.5758531093597412,
                0.8007177710533142,
                0.7780367732048035,
                0.6973402500152588,
                0.7696438431739807,
                0.7876999974250793,
                0.8144168853759766,
                0.8443678021430969,
                0.6974454522132874,
                0.7583910822868347,
                0.7634974718093872,
                0.8751128911972046,
                0.8182815909385681,
                0.6879304051399231,
                0.8209156394004822,
                0.8677736520767212,
                0.891205906867981,
                0.7798946499824524,
                0.8609114289283752,
                0.8661983013153076,
                0.8411427140235901,
                0.8231236934661865,
                0.8230052590370178,
                0.7677127122879028,
                0.8282140493392944,
                0.8454462885856628,
                0.8275731205940247,
                0.8547083139419556
            ],
            [
                0.7975037097930908,
                0.7848413586616516,
                0.8127409219741821,
                0.7374767065048218,
                0.843687891960144,
                0.8039048910140991,
                0.8421555757522583,
                0.769430935382843,
                0.8439302444458008,
                0.8302562236785889,
                0.8419146537780762,
                0.8096211552619934,
                0.5668419003486633,
                0.8572640419006348,
                0.8142384886741638,
                0.7918912768363953,
                0.8180683851242065,
                0.8261641263961792,
                0.8498849868774414,
                0.8590783476829529,
                0.8413237929344177,
                0.795413076877594,
                0.778403103351593,
                0.6803854703903198,
                0.8543350696563721,
                0.8398610949516296,
                0.7900324463844299,
                0.7370651364326477,
                0.8373628258705139,
                0.7636940479278564,
                0.8413973450660706,
                0.8292413353919983,
                0.8441683650016785,
                0.8418310284614563,
                0.737582802772522,
                0.8505854606628418,
                0.7931666970252991,
                0.8717299699783325,
                0.738617479801178,
                0.7807035446166992,
                0.842639148235321,
                0.8347412943840027,
                0.7435159683227539,
                0.8040653467178345,
                0.7134082913398743,
                0.7147902250289917,
                0.8482338190078735,
                0.8407235145568848,
                0.7166309356689453,
                0.78872150182724,
                0.7458052039146423
            ],
            [
                0.8568057417869568,
                0.9076888561248779,
                0.8658596873283386,
                0.8758402466773987,
                0.8932375907897949,
                0.9068746566772461,
                0.8617762923240662,
                0.8764705061912537,
                0.86643385887146,
                0.8529807925224304,
                0.8614556193351746,
                0.9386515617370605,
                0.6528929471969604,
                0.8684809803962708,
                0.9365316033363342,
                0.8888227343559265,
                0.913058876991272,
                0.8898349404335022,
                0.85694819688797,
                0.8655588030815125,
                0.8605989217758179,
                0.8146443963050842,
                0.8458709120750427,
                0.6329533457756042,
                0.8533302545547485,
                0.8678609132766724,
                0.7949898838996887,
                0.8278231620788574,
                0.823258101940155,
                0.8630955219268799,
                0.9201971292495728,
                0.7641736268997192,
                0.8061741590499878,
                0.7999967336654663,
                0.8417707681655884,
                0.8934081792831421,
                0.7441419959068298,
                0.8860140442848206,
                0.835606575012207,
                0.8714215755462646,
                0.8666013479232788,
                0.9031729698181152,
                0.8326252698898315,
                0.8880489468574524,
                0.8203137516975403,
                0.8314889669418335,
                0.8665114045143127,
                0.8868160247802734,
                0.8066868185997009,
                0.876756489276886,
                0.8436839580535889
            ],
            [
                0.7563642859458923,
                0.7897602915763855,
                0.7748045921325684,
                0.7264807820320129,
                0.8125937581062317,
                0.7881150841712952,
                0.763255774974823,
                0.713739812374115,
                0.7657695412635803,
                0.763994574546814,
                0.7714119553565979,
                0.8025752902030945,
                0.5661700367927551,
                0.78638756275177,
                0.7911362051963806,
                0.7960951924324036,
                0.7798506021499634,
                0.7768294811248779,
                0.7668967247009277,
                0.8036641478538513,
                0.7907195687294006,
                0.7396021485328674,
                0.7209628224372864,
                0.6608426570892334,
                0.7886353731155396,
                0.7934907674789429,
                0.7441070079803467,
                0.7065839171409607,
                0.7978687882423401,
                0.7421301603317261,
                0.7966498136520386,
                0.7631158232688904,
                0.8061681389808655,
                0.8000809550285339,
                0.7528250813484192,
                0.7890458703041077,
                0.7527027130126953,
                0.8077385425567627,
                0.7395147681236267,
                0.7752153277397156,
                0.7921800017356873,
                0.7973317503929138,
                0.7495726346969604,
                0.7801430225372314,
                0.7110563516616821,
                0.7467767596244812,
                0.7887939810752869,
                0.7970593571662903,
                0.7352926731109619,
                0.757361650466919,
                0.7538774013519287
            ]
        ],
        [
            [
                0.8278493285179138,
                0.6588984727859497,
                0.6864104270935059,
                0.6047795414924622,
                0.6948370933532715,
                0.6854921579360962,
                0.6014045476913452,
                0.6689173579216003,
                0.5503698587417603,
                0.7523598074913025,
                0.7537948489189148,
                0.7906766533851624,
                0.6973872780799866,
                0.559070348739624,
                0.7432253956794739,
                0.7380383014678955,
                0.6984573006629944,
                0.7393844723701477,
                0.7431646585464478,
                0.7314919829368591,
                0.7393704652786255,
                0.7198584079742432,
                0.6941015720367432,
                0.6809421181678772,
                0.6530805230140686,
                0.6571225523948669,
                0.7250405550003052,
                0.7040245532989502,
                0.626488983631134,
                0.6239606142044067,
                0.7192060947418213,
                0.6014045476913452,
                0.692450761795044,
                0.7207221984863281,
                0.7096014618873596,
                0.7294016480445862,
                0.7340241074562073
            ],
            [
                0.8208360075950623,
                0.6474366784095764,
                0.6757832765579224,
                0.6245830655097961,
                0.7154607772827148,
                0.6816418170928955,
                0.6242803335189819,
                0.6627429127693176,
                0.5878392457962036,
                0.7173035740852356,
                0.7436796426773071,
                0.7657114863395691,
                0.6980504393577576,
                0.5815519094467163,
                0.7476313710212708,
                0.7433181405067444,
                0.7125666737556458,
                0.7466744780540466,
                0.7477465271949768,
                0.714034914970398,
                0.8128799796104431,
                0.7191339135169983,
                0.7392294406890869,
                0.7154325842857361,
                0.6928379535675049,
                0.7046782970428467,
                0.7195256948471069,
                0.7425536513328552,
                0.6620199680328369,
                0.6375494003295898,
                0.7001903057098389,
                0.6242803335189819,
                0.7071372866630554,
                0.729518473148346,
                0.7140669226646423,
                0.7379376888275146,
                0.742614209651947
            ],
            [
                0.8380129933357239,
                0.7013927102088928,
                0.7196490168571472,
                0.6223869323730469,
                0.7746519446372986,
                0.7429474592208862,
                0.6346652507781982,
                0.7075888514518738,
                0.583965539932251,
                0.7537359595298767,
                0.795793354511261,
                0.8245381116867065,
                0.7210581302642822,
                0.6557484269142151,
                0.8167322278022766,
                0.8105077743530273,
                0.7323978543281555,
                0.8146256804466248,
                0.8186471462249756,
                0.7383845448493958,
                0.8455926179885864,
                0.7534513473510742,
                0.793458878993988,
                0.7450326085090637,
                0.737824022769928,
                0.7300950884819031,
                0.7358270883560181,
                0.7807000875473022,
                0.6680846810340881,
                0.6799165606498718,
                0.7291184067726135,
                0.6346652507781982,
                0.7368327975273132,
                0.7749990820884705,
                0.7760225534439087,
                0.7952986359596252,
                0.7938826084136963
            ],
            [
                0.8993334770202637,
                0.7875447273254395,
                0.7663602828979492,
                0.6036959290504456,
                0.7858895063400269,
                0.7702273726463318,
                0.6364997625350952,
                0.7547613382339478,
                0.567858874797821,
                0.7572262287139893,
                0.8358996510505676,
                0.8402693271636963,
                0.731631338596344,
                0.5751392245292664,
                0.8352678418159485,
                0.8255224227905273,
                0.7353473901748657,
                0.8209105730056763,
                0.817916750907898,
                0.7731828093528748,
                0.8207582831382751,
                0.7443405389785767,
                0.7710199952125549,
                0.7570429444313049,
                0.7121102213859558,
                0.7129031419754028,
                0.7634737491607666,
                0.784575879573822,
                0.6499148011207581,
                0.6805188655853271,
                0.7307980060577393,
                0.6364997625350952,
                0.7462021708488464,
                0.7622726559638977,
                0.7519943714141846,
                0.7849168181419373,
                0.7960726618766785
            ],
            [
                0.9139381647109985,
                0.7782148718833923,
                0.8655312061309814,
                0.6832401156425476,
                0.8654974102973938,
                0.851380467414856,
                0.7134379148483276,
                0.8652400970458984,
                0.6350271105766296,
                0.7903334498405457,
                0.8706952333450317,
                0.8442769050598145,
                0.8153236508369446,
                0.6374315619468689,
                0.8669106960296631,
                0.8614760637283325,
                0.7973345518112183,
                0.845476508140564,
                0.8454899787902832,
                0.8413112163543701,
                0.8074602484703064,
                0.7915141582489014,
                0.7967352867126465,
                0.8447018265724182,
                0.7898716330528259,
                0.7893832921981812,
                0.8280518054962158,
                0.8295345306396484,
                0.7130789160728455,
                0.6938933730125427,
                0.8202846050262451,
                0.7134379148483276,
                0.828750729560852,
                0.8199592232704163,
                0.7836028337478638,
                0.8303221464157104,
                0.8456339836120605
            ],
            [
                0.90567547082901,
                0.7202112674713135,
                0.8156008720397949,
                0.6830026507377625,
                0.8727403879165649,
                0.8273324370384216,
                0.7087743878364563,
                0.8131445646286011,
                0.6342529058456421,
                0.7578762173652649,
                0.8458343148231506,
                0.8352367281913757,
                0.7470484375953674,
                0.6380749344825745,
                0.8367826342582703,
                0.8366053700447083,
                0.7535368204116821,
                0.8337024450302124,
                0.8320799469947815,
                0.7765640020370483,
                0.8430440425872803,
                0.7627447247505188,
                0.783646821975708,
                0.8026451468467712,
                0.7665734887123108,
                0.769981324672699,
                0.7758058309555054,
                0.7932240962982178,
                0.6748001575469971,
                0.6806100606918335,
                0.7709149122238159,
                0.7087743878364563,
                0.827714204788208,
                0.8329284191131592,
                0.8111218810081482,
                0.846402645111084,
                0.8522394895553589
            ],
            [
                0.7615557909011841,
                0.6893206834793091,
                0.7051658630371094,
                0.6548924446105957,
                0.7138992547988892,
                0.7222257852554321,
                0.6683170795440674,
                0.6846135854721069,
                0.6147875189781189,
                0.7610485553741455,
                0.7659497261047363,
                0.7766839861869812,
                0.7495235800743103,
                0.6363018155097961,
                0.7762618064880371,
                0.7647771239280701,
                0.7526498436927795,
                0.7724096775054932,
                0.7735065817832947,
                0.7456672191619873,
                0.7349483966827393,
                0.7494727373123169,
                0.7127230167388916,
                0.7312275171279907,
                0.7269665002822876,
                0.7256854772567749,
                0.7280027866363525,
                0.7078395485877991,
                0.6940796971321106,
                0.6475106477737427,
                0.7404613494873047,
                0.6683170795440674,
                0.7178543210029602,
                0.7377848625183105,
                0.7077900767326355,
                0.731404185295105,
                0.7266431450843811
            ],
            [
                0.8994580507278442,
                0.7371538877487183,
                0.8388579487800598,
                0.6518532633781433,
                0.8079191446304321,
                0.8362585306167603,
                0.6682538986206055,
                0.8390837907791138,
                0.6033678650856018,
                0.8111092448234558,
                0.8856146931648254,
                0.8780580759048462,
                0.7843376398086548,
                0.5800372362136841,
                0.8643990159034729,
                0.8646098971366882,
                0.7767922878265381,
                0.8628778457641602,
                0.8633098006248474,
                0.8441005349159241,
                0.8267586827278137,
                0.807172417640686,
                0.7538968920707703,
                0.7813930511474609,
                0.733517050743103,
                0.7474187016487122,
                0.8512774705886841,
                0.791082501411438,
                0.6903892755508423,
                0.6813870668411255,
                0.8090006113052368,
                0.6682538986206055,
                0.8192633986473083,
                0.8448734879493713,
                0.8140214681625366,
                0.8369938731193542,
                0.8511719107627869
            ],
            [
                0.8991151452064514,
                0.7695965766906738,
                0.8667067885398865,
                0.6853693723678589,
                0.8600761890411377,
                0.8756601214408875,
                0.7279574871063232,
                0.8669619560241699,
                0.6450862884521484,
                0.8306063413619995,
                0.9028174877166748,
                0.881399929523468,
                0.820659875869751,
                0.6489296555519104,
                0.8884837031364441,
                0.8879662156105042,
                0.8132217526435852,
                0.8745863437652588,
                0.877871036529541,
                0.864591658115387,
                0.8289320468902588,
                0.8184045553207397,
                0.815802812576294,
                0.8561577796936035,
                0.8143073320388794,
                0.809698760509491,
                0.8519599437713623,
                0.8500845432281494,
                0.7057844400405884,
                0.7169036269187927,
                0.8374746441841125,
                0.7279574871063232,
                0.8489652276039124,
                0.859557032585144,
                0.8107718229293823,
                0.8583709001541138,
                0.8728630542755127
            ],
            [
                0.8244101405143738,
                0.682547926902771,
                0.7545264959335327,
                0.6655874252319336,
                0.7619947791099548,
                0.7818508148193359,
                0.6832229495048523,
                0.7648922204971313,
                0.6372432708740234,
                0.7617154717445374,
                0.8341484069824219,
                0.8463786244392395,
                0.7732071280479431,
                0.6216800212860107,
                0.8380323052406311,
                0.8428966403007507,
                0.7811871767044067,
                0.8466777801513672,
                0.853418231010437,
                0.7920268774032593,
                0.8284206390380859,
                0.7869768142700195,
                0.7643020153045654,
                0.802627682685852,
                0.7708433866500854,
                0.778794527053833,
                0.7951783537864685,
                0.7954541444778442,
                0.6867735981941223,
                0.7039081454277039,
                0.7764405012130737,
                0.6832229495048523,
                0.7961592674255371,
                0.8361325860023499,
                0.8191746473312378,
                0.8366972208023071,
                0.8425818085670471
            ],
            [
                0.8404849171638489,
                0.6750397682189941,
                0.7115424275398254,
                0.6461596488952637,
                0.7745320200920105,
                0.7418246269226074,
                0.6651233434677124,
                0.6987738609313965,
                0.6150699853897095,
                0.7358686923980713,
                0.7927757501602173,
                0.8296993970870972,
                0.7365972995758057,
                0.6292566657066345,
                0.8155525326728821,
                0.8224397897720337,
                0.736609935760498,
                0.8234288692474365,
                0.8280819058418274,
                0.7379332780838013,
                0.8446653485298157,
                0.7538732886314392,
                0.7632998824119568,
                0.7870602607727051,
                0.773187518119812,
                0.7807314991950989,
                0.7364603281021118,
                0.7596472501754761,
                0.6845555901527405,
                0.693440854549408,
                0.7356452941894531,
                0.6651233434677124,
                0.7715604901313782,
                0.8041882514953613,
                0.79839688539505,
                0.8102319240570068,
                0.8072053790092468
            ],
            [
                0.8658567667007446,
                0.753832995891571,
                0.8545446395874023,
                0.6812136769294739,
                0.8314275145530701,
                0.8607473969459534,
                0.7176417112350464,
                0.8579639792442322,
                0.6355212926864624,
                0.799309492111206,
                0.8746041655540466,
                0.850031316280365,
                0.8061904907226562,
                0.6326333284378052,
                0.871886670589447,
                0.8708723783493042,
                0.7969025373458862,
                0.8680782914161682,
                0.8667599558830261,
                0.8449816703796387,
                0.8052954077720642,
                0.8092626929283142,
                0.788756251335144,
                0.8355445265769958,
                0.7897387146949768,
                0.7997595071792603,
                0.8496544361114502,
                0.8286181092262268,
                0.7058903574943542,
                0.702022135257721,
                0.8167431354522705,
                0.7176417112350464,
                0.8304567933082581,
                0.8477400541305542,
                0.8089415431022644,
                0.8450575470924377,
                0.8590912818908691
            ],
            [
                0.874830961227417,
                0.7236810922622681,
                0.7732730507850647,
                0.6312260627746582,
                0.7665257453918457,
                0.7923096418380737,
                0.6524709463119507,
                0.7650718688964844,
                0.5982112288475037,
                0.7958764433860779,
                0.886188268661499,
                0.9136764407157898,
                0.7719326019287109,
                0.5804662704467773,
                0.8762730360031128,
                0.8824423551559448,
                0.769377589225769,
                0.8810278177261353,
                0.8820585012435913,
                0.8145042657852173,
                0.8328559994697571,
                0.8111617565155029,
                0.7549036145210266,
                0.7764910459518433,
                0.7327675223350525,
                0.7470789551734924,
                0.8184696435928345,
                0.7779104113578796,
                0.6589924097061157,
                0.7084285616874695,
                0.7703495025634766,
                0.6524709463119507,
                0.7862362861633301,
                0.8293905854225159,
                0.817541241645813,
                0.8378909230232239,
                0.843424379825592
            ],
            [
                0.9044764637947083,
                0.7342772483825684,
                0.8036093711853027,
                0.6556941270828247,
                0.8299322128295898,
                0.8210949897766113,
                0.683853030204773,
                0.8000900745391846,
                0.6107860207557678,
                0.7901232242584229,
                0.8911862969398499,
                0.9060559272766113,
                0.8010074496269226,
                0.6120333075523376,
                0.8915054202079773,
                0.8941797018051147,
                0.7912113070487976,
                0.8803919553756714,
                0.8860597610473633,
                0.8214753866195679,
                0.8706396818161011,
                0.803856372833252,
                0.7905633449554443,
                0.8263740539550781,
                0.7772601246833801,
                0.779936671257019,
                0.8035827875137329,
                0.8090668320655823,
                0.6939021944999695,
                0.7201848030090332,
                0.796319305896759,
                0.683853030204773,
                0.818994402885437,
                0.8439123630523682,
                0.8408888578414917,
                0.8681363463401794,
                0.8725166320800781
            ],
            [
                0.8542368412017822,
                0.7539108395576477,
                0.8460536003112793,
                0.6727249622344971,
                0.8435682654380798,
                0.824258029460907,
                0.6923821568489075,
                0.8455881476402283,
                0.6217331886291504,
                0.7877697348594666,
                0.8273738622665405,
                0.7880213856697083,
                0.7638264894485474,
                0.6271558403968811,
                0.8325223922729492,
                0.8133898973464966,
                0.7567536234855652,
                0.8183401823043823,
                0.8151916861534119,
                0.8075512051582336,
                0.8019230961799622,
                0.7632879614830017,
                0.776252031326294,
                0.791790246963501,
                0.7605602741241455,
                0.7640359401702881,
                0.8004292249679565,
                0.8010556101799011,
                0.752967357635498,
                0.6731194257736206,
                0.8094505667686462,
                0.6923821568489075,
                0.8063265681266785,
                0.8163208365440369,
                0.7685896754264832,
                0.7934598326683044,
                0.8066222667694092
            ],
            [
                0.730889618396759,
                0.6965376734733582,
                0.6825685501098633,
                0.6933841705322266,
                0.7137058973312378,
                0.721099317073822,
                0.7203332185745239,
                0.6708873510360718,
                0.6712184548377991,
                0.7738947868347168,
                0.7637874484062195,
                0.7808045744895935,
                0.8021783232688904,
                0.7273292541503906,
                0.8014799952507019,
                0.7920712232589722,
                0.8264821171760559,
                0.7989407181739807,
                0.8026463389396667,
                0.7711963653564453,
                0.7899445295333862,
                0.789050281047821,
                0.7766315340995789,
                0.793567419052124,
                0.7966428995132446,
                0.7896021604537964,
                0.7491892576217651,
                0.7723044157028198,
                0.7460654973983765,
                0.7169958353042603,
                0.7651804089546204,
                0.7203332185745239,
                0.7447998523712158,
                0.75507652759552,
                0.7443416714668274,
                0.7680719494819641,
                0.7638902068138123
            ],
            [
                0.7482914328575134,
                0.6704475283622742,
                0.676595151424408,
                0.6181398034095764,
                0.7146809101104736,
                0.7272962927818298,
                0.6564425826072693,
                0.6619473099708557,
                0.5900426506996155,
                0.7100242376327515,
                0.774478018283844,
                0.8023800253868103,
                0.708940327167511,
                0.6359503269195557,
                0.7991845011711121,
                0.794499397277832,
                0.7202906608581543,
                0.804092526435852,
                0.8070067763328552,
                0.7066531181335449,
                0.798643946647644,
                0.726250946521759,
                0.747627854347229,
                0.7526888847351074,
                0.7585307955741882,
                0.7507609128952026,
                0.7006524801254272,
                0.7415990233421326,
                0.6463586091995239,
                0.6718237996101379,
                0.6884562969207764,
                0.6564425826072693,
                0.7442996501922607,
                0.7684723138809204,
                0.77531898021698,
                0.7922114729881287,
                0.787930428981781
            ],
            [
                0.8432857990264893,
                0.7519869208335876,
                0.8343774676322937,
                0.6965330243110657,
                0.8338135480880737,
                0.814099133014679,
                0.7064117193222046,
                0.8276832103729248,
                0.6472119688987732,
                0.7741445302963257,
                0.8283063173294067,
                0.8011112213134766,
                0.7700254321098328,
                0.6373341679573059,
                0.8359575867652893,
                0.8280611038208008,
                0.7605742812156677,
                0.8377434611320496,
                0.8265743255615234,
                0.8016875982284546,
                0.7966980934143066,
                0.7705102562904358,
                0.7629446983337402,
                0.7863426804542542,
                0.7523342370986938,
                0.778321385383606,
                0.7993965744972229,
                0.785332202911377,
                0.7663711309432983,
                0.6932305097579956,
                0.7977973818778992,
                0.7064117193222046,
                0.8060272932052612,
                0.818082869052887,
                0.7810284495353699,
                0.7994093298912048,
                0.8093554973602295
            ],
            [
                0.7447701096534729,
                0.708279550075531,
                0.7136167883872986,
                0.7356188297271729,
                0.7266340255737305,
                0.7482258677482605,
                0.7535275816917419,
                0.6939690113067627,
                0.6913818120956421,
                0.782480776309967,
                0.8040509223937988,
                0.8201686143875122,
                0.828420877456665,
                0.7112387418746948,
                0.828113853931427,
                0.8385037183761597,
                0.8317018747329712,
                0.8426353931427002,
                0.8329967856407166,
                0.8128516674041748,
                0.7934446930885315,
                0.826287567615509,
                0.7633563876152039,
                0.8093864321708679,
                0.7973144054412842,
                0.8311775326728821,
                0.7947933077812195,
                0.7724063396453857,
                0.7682034969329834,
                0.7376430630683899,
                0.774438738822937,
                0.7535275816917419,
                0.7650877833366394,
                0.7838985323905945,
                0.7601511478424072,
                0.784888744354248,
                0.779796838760376
            ],
            [
                0.8250014185905457,
                0.734739363193512,
                0.7655274868011475,
                0.6758966445922852,
                0.7729595899581909,
                0.7793604731559753,
                0.6849793195724487,
                0.7556179165840149,
                0.6554086804389954,
                0.7795259952545166,
                0.8684971928596497,
                0.8869497776031494,
                0.7887283563613892,
                0.6339171528816223,
                0.8830294013023376,
                0.8790624141693115,
                0.7916267514228821,
                0.8992392420768738,
                0.8892354965209961,
                0.8016501665115356,
                0.836860179901123,
                0.8040167093276978,
                0.7671012878417969,
                0.7992312908172607,
                0.7755279541015625,
                0.8014438152313232,
                0.8026378154754639,
                0.7851398587226868,
                0.7207744121551514,
                0.7452113628387451,
                0.7654805779457092,
                0.6849793195724487,
                0.7912241816520691,
                0.8162212371826172,
                0.8076289892196655,
                0.8256122469902039,
                0.8277428150177002
            ],
            [
                0.7814987897872925,
                0.7645941972732544,
                0.7622878551483154,
                0.718044638633728,
                0.7664080858230591,
                0.7824985384941101,
                0.7586016058921814,
                0.7510893940925598,
                0.6786820888519287,
                0.8386372327804565,
                0.8373441100120544,
                0.8172446489334106,
                0.8213651776313782,
                0.7098277807235718,
                0.8606044054031372,
                0.8424398899078369,
                0.8208271265029907,
                0.8368059992790222,
                0.8257903456687927,
                0.838428258895874,
                0.7986232042312622,
                0.8266462683677673,
                0.8167993426322937,
                0.814012348651886,
                0.7933303117752075,
                0.7913637161254883,
                0.8171399831771851,
                0.8166804313659668,
                0.7514921426773071,
                0.7369475364685059,
                0.8116388320922852,
                0.7586016058921814,
                0.7886427640914917,
                0.7981852889060974,
                0.7647993564605713,
                0.8056670427322388,
                0.8059354424476624
            ],
            [
                0.8563809990882874,
                0.753796398639679,
                0.786399245262146,
                0.6676533818244934,
                0.7820987701416016,
                0.7948179841041565,
                0.6862161159515381,
                0.771256685256958,
                0.6375023126602173,
                0.8064457178115845,
                0.8712130784988403,
                0.8834810256958008,
                0.7951079607009888,
                0.6308029890060425,
                0.8827794194221497,
                0.8720124959945679,
                0.7994349598884583,
                0.8764081597328186,
                0.8706182837486267,
                0.8234740495681763,
                0.8499506711959839,
                0.8110508322715759,
                0.7973339557647705,
                0.81047523021698,
                0.7809856534004211,
                0.7921311259269714,
                0.8199676871299744,
                0.812747061252594,
                0.7276943325996399,
                0.7314895391464233,
                0.7867777943611145,
                0.6862161159515381,
                0.7887086868286133,
                0.8107385039329529,
                0.7949156165122986,
                0.8188450932502747,
                0.8258247375488281
            ],
            [
                0.7403163909912109,
                0.7212582230567932,
                0.7204192280769348,
                0.7180712223052979,
                0.7413541078567505,
                0.7696680426597595,
                0.7666189074516296,
                0.7095396518707275,
                0.6787292957305908,
                0.7881224155426025,
                0.7994650602340698,
                0.7906372547149658,
                0.823302686214447,
                0.7286316752433777,
                0.8292269110679626,
                0.8211816549301147,
                0.8293626308441162,
                0.8195606470108032,
                0.8128637671470642,
                0.8101850748062134,
                0.7815436124801636,
                0.8138754367828369,
                0.78179532289505,
                0.8038581609725952,
                0.8106181621551514,
                0.7991809844970703,
                0.7848832011222839,
                0.787599503993988,
                0.7464544773101807,
                0.7254031300544739,
                0.7834497690200806,
                0.7666189074516296,
                0.7768505811691284,
                0.7849288582801819,
                0.7693318128585815,
                0.7980437278747559,
                0.7927485108375549
            ],
            [
                0.8228033185005188,
                0.7547609806060791,
                0.7736899852752686,
                0.6655906438827515,
                0.8033035397529602,
                0.8098210692405701,
                0.7180468440055847,
                0.7546808123588562,
                0.6294730305671692,
                0.7617555260658264,
                0.8405242562294006,
                0.8545544147491455,
                0.7746764421463013,
                0.6771288514137268,
                0.8613942265510559,
                0.8601486086845398,
                0.7777697443962097,
                0.859466552734375,
                0.856404721736908,
                0.7797163128852844,
                0.8349642157554626,
                0.7906903028488159,
                0.8108471632003784,
                0.8181150555610657,
                0.8207999467849731,
                0.8098644614219666,
                0.7749918699264526,
                0.8131108283996582,
                0.7095730900764465,
                0.7242692708969116,
                0.7540209293365479,
                0.7180468440055847,
                0.7992944717407227,
                0.8259539008140564,
                0.8184143304824829,
                0.8434554934501648,
                0.8411150574684143
            ],
            [
                0.8521484732627869,
                0.7694628238677979,
                0.8570694923400879,
                0.7258531451225281,
                0.8673191070556641,
                0.8832366466522217,
                0.7795845866203308,
                0.8497170805931091,
                0.6730301976203918,
                0.7993552684783936,
                0.8881889581680298,
                0.8546380400657654,
                0.8226162195205688,
                0.701082170009613,
                0.9026877880096436,
                0.8899200558662415,
                0.8136003613471985,
                0.892839252948761,
                0.8846674561500549,
                0.8430342674255371,
                0.8278905153274536,
                0.8210313320159912,
                0.8218836188316345,
                0.8758902549743652,
                0.8433778882026672,
                0.8412304520606995,
                0.8331854939460754,
                0.8442368507385254,
                0.7362853288650513,
                0.738406777381897,
                0.8128063082695007,
                0.7795845866203308,
                0.8852571845054626,
                0.8485561609268188,
                0.8311128616333008,
                0.8786090612411499,
                0.884545087814331
            ],
            [
                0.8028461337089539,
                0.7207592725753784,
                0.7718237638473511,
                0.7495350241661072,
                0.7848477363586426,
                0.8017659187316895,
                0.7742235064506531,
                0.7482936978340149,
                0.6822559833526611,
                0.7890450358390808,
                0.8380206227302551,
                0.8387330174446106,
                0.8141874074935913,
                0.7307026982307434,
                0.8631090521812439,
                0.8543730974197388,
                0.8173660635948181,
                0.861360490322113,
                0.8562325835227966,
                0.8059594631195068,
                0.8144021034240723,
                0.806250810623169,
                0.7948339581489563,
                0.8377439379692078,
                0.8326733112335205,
                0.8293439745903015,
                0.7887982130050659,
                0.7994135022163391,
                0.7395836114883423,
                0.7349230647087097,
                0.7953643202781677,
                0.7742235064506531,
                0.8301726579666138,
                0.8109843730926514,
                0.8074525594711304,
                0.8428534269332886,
                0.8374179601669312
            ],
            [
                0.8131771683692932,
                0.7233219742774963,
                0.7761791944503784,
                0.7521672248840332,
                0.8105564117431641,
                0.7992848753929138,
                0.7861423492431641,
                0.7672531008720398,
                0.7071176767349243,
                0.7969518899917603,
                0.8166044354438782,
                0.8070579767227173,
                0.8318140506744385,
                0.7395044565200806,
                0.8377786874771118,
                0.8266003131866455,
                0.8320751786231995,
                0.8230037093162537,
                0.8209912180900574,
                0.8125742077827454,
                0.775529682636261,
                0.8142641186714172,
                0.8036485314369202,
                0.8358553647994995,
                0.8237143158912659,
                0.8121905326843262,
                0.7999091744422913,
                0.8124755620956421,
                0.7522674798965454,
                0.7154058218002319,
                0.8277051448822021,
                0.7861423492431641,
                0.8216858506202698,
                0.7976956963539124,
                0.7740530371665955,
                0.8153353929519653,
                0.815797746181488
            ],
            [
                0.8725938200950623,
                0.7395138740539551,
                0.8089578747749329,
                0.6919986009597778,
                0.8116726875305176,
                0.8299167156219482,
                0.7245324850082397,
                0.7900356650352478,
                0.6474015712738037,
                0.8049693703651428,
                0.8674103021621704,
                0.8758367300033569,
                0.8159768581390381,
                0.6652631759643555,
                0.8803043961524963,
                0.867676317691803,
                0.8163858652114868,
                0.8783084154129028,
                0.8736078143119812,
                0.8309186100959778,
                0.8326988816261292,
                0.8209817409515381,
                0.7884741425514221,
                0.8239948153495789,
                0.7923071980476379,
                0.8000987768173218,
                0.8305869698524475,
                0.8057593107223511,
                0.7428280115127563,
                0.7199054956436157,
                0.8029215335845947,
                0.7245324850082397,
                0.8303301334381104,
                0.8284878134727478,
                0.8146065473556519,
                0.8394175171852112,
                0.8459895849227905
            ],
            [
                0.8350498676300049,
                0.7163994312286377,
                0.8475722074508667,
                0.7543341517448425,
                0.8197143077850342,
                0.8484195470809937,
                0.7669386267662048,
                0.8346622586250305,
                0.6839014291763306,
                0.7922160029411316,
                0.863423228263855,
                0.826810359954834,
                0.8085623979568481,
                0.6932504177093506,
                0.8579679727554321,
                0.8520997762680054,
                0.807126522064209,
                0.8631714582443237,
                0.8556872606277466,
                0.831199049949646,
                0.8043050765991211,
                0.790874719619751,
                0.7729856371879578,
                0.8549838066101074,
                0.8158032894134521,
                0.8261458873748779,
                0.8200876712799072,
                0.8068332076072693,
                0.7403598427772522,
                0.7101156115531921,
                0.8240644931793213,
                0.7669386267662048,
                0.878045916557312,
                0.8456345200538635,
                0.828791618347168,
                0.8612779378890991,
                0.8716221451759338
            ],
            [
                0.8489629030227661,
                0.7322724461555481,
                0.8424520492553711,
                0.763674259185791,
                0.8290125131607056,
                0.8335709571838379,
                0.7720445394515991,
                0.8392921686172485,
                0.7014173269271851,
                0.8019289970397949,
                0.8526244163513184,
                0.8253715634346008,
                0.8262163400650024,
                0.704698920249939,
                0.8537267446517944,
                0.8466031551361084,
                0.810719907283783,
                0.8458977937698364,
                0.8419862985610962,
                0.8343603610992432,
                0.7861130237579346,
                0.8001388907432556,
                0.7907800078392029,
                0.8649125099182129,
                0.8214174509048462,
                0.8282141089439392,
                0.8245554566383362,
                0.8250061273574829,
                0.7476956844329834,
                0.7083568572998047,
                0.8415542244911194,
                0.7720445394515991,
                0.8585788607597351,
                0.8359147310256958,
                0.791334867477417,
                0.8350484371185303,
                0.8442041873931885
            ],
            [
                0.8801581263542175,
                0.7708505988121033,
                0.8238523602485657,
                0.7053971886634827,
                0.8424668312072754,
                0.8244522213935852,
                0.7329978346824646,
                0.8047374486923218,
                0.6568590402603149,
                0.812397837638855,
                0.8551819920539856,
                0.8501777648925781,
                0.8224210739135742,
                0.6825369596481323,
                0.8679693341255188,
                0.8539915680885315,
                0.8244355916976929,
                0.8553864359855652,
                0.8532646894454956,
                0.8272901773452759,
                0.8186939358711243,
                0.8107045292854309,
                0.8025767803192139,
                0.8319565653800964,
                0.7992874979972839,
                0.7999477386474609,
                0.8186466693878174,
                0.8171182870864868,
                0.778228759765625,
                0.7103520035743713,
                0.8224137425422668,
                0.7329978346824646,
                0.8169275522232056,
                0.818432092666626,
                0.7876269817352295,
                0.8201085329055786,
                0.8270041942596436
            ],
            [
                0.8252575993537903,
                0.7213267087936401,
                0.8237050771713257,
                0.7589787244796753,
                0.8294165730476379,
                0.8461223244667053,
                0.792370080947876,
                0.8116571307182312,
                0.6998549103736877,
                0.7943100333213806,
                0.860467791557312,
                0.8324208855628967,
                0.8232741951942444,
                0.7237511277198792,
                0.8590220212936401,
                0.8603407144546509,
                0.8247503042221069,
                0.8573629260063171,
                0.8518058657646179,
                0.8281012773513794,
                0.8071529865264893,
                0.8002520203590393,
                0.7857446074485779,
                0.8680287003517151,
                0.8399724960327148,
                0.8402530550956726,
                0.8053991794586182,
                0.8046581745147705,
                0.7486578822135925,
                0.720680296421051,
                0.8274793028831482,
                0.792370080947876,
                0.8812205791473389,
                0.8472324013710022,
                0.8267769813537598,
                0.8657903671264648,
                0.869966983795166
            ],
            [
                0.7866414785385132,
                0.7120885848999023,
                0.7708378434181213,
                0.7699006795883179,
                0.7990984320640564,
                0.7885531783103943,
                0.8030995726585388,
                0.7629643082618713,
                0.7219858169555664,
                0.7694661021232605,
                0.7965863943099976,
                0.7711255550384521,
                0.8258444666862488,
                0.7586076855659485,
                0.8159894347190857,
                0.8132051825523376,
                0.8292486667633057,
                0.8065458536148071,
                0.7988594174385071,
                0.7946073412895203,
                0.758227527141571,
                0.7929145097732544,
                0.7903075218200684,
                0.8539751172065735,
                0.837881326675415,
                0.8351091742515564,
                0.7732506990432739,
                0.7946199774742126,
                0.7446363568305969,
                0.7141680717468262,
                0.8005406856536865,
                0.8030995726585388,
                0.8282017707824707,
                0.7955171465873718,
                0.756288468837738,
                0.8069338798522949,
                0.8056191802024841
            ],
            [
                0.8911068439483643,
                0.7695556282997131,
                0.8456241488456726,
                0.7109367847442627,
                0.840975284576416,
                0.8386375308036804,
                0.7326650619506836,
                0.8285552859306335,
                0.6639459133148193,
                0.8388190269470215,
                0.8818270564079285,
                0.868262767791748,
                0.8300684094429016,
                0.667346715927124,
                0.8836480975151062,
                0.8679890632629395,
                0.8293287754058838,
                0.8739996552467346,
                0.867347002029419,
                0.8529313802719116,
                0.8267943263053894,
                0.8320104479789734,
                0.8031973838806152,
                0.8342077136039734,
                0.7966703772544861,
                0.803796648979187,
                0.8492127656936646,
                0.8220025300979614,
                0.772315502166748,
                0.7249183058738708,
                0.8342803716659546,
                0.7326650619506836,
                0.8394474387168884,
                0.8326283693313599,
                0.804989755153656,
                0.837632417678833,
                0.8471405506134033
            ],
            [
                0.7851046323776245,
                0.7578589916229248,
                0.7645459771156311,
                0.710204005241394,
                0.7413872480392456,
                0.7801884412765503,
                0.7355355024337769,
                0.7512569427490234,
                0.6745283603668213,
                0.8482241630554199,
                0.8559944033622742,
                0.8439915180206299,
                0.8144825100898743,
                0.6812319755554199,
                0.8546026945114136,
                0.8412401676177979,
                0.8126775026321411,
                0.8407615423202515,
                0.8305584192276001,
                0.8415966033935547,
                0.797666072845459,
                0.8439555168151855,
                0.7913276553153992,
                0.7908514738082886,
                0.7720584869384766,
                0.7744065523147583,
                0.8281489610671997,
                0.7992181777954102,
                0.7428363561630249,
                0.7346631288528442,
                0.7957339286804199,
                0.7355355024337769,
                0.7812505960464478,
                0.7905192375183105,
                0.7518094182014465,
                0.7952122688293457,
                0.7933076620101929
            ],
            [
                0.8315454721450806,
                0.7341852784156799,
                0.7658827900886536,
                0.6851216554641724,
                0.7860387563705444,
                0.7983788847923279,
                0.7162243127822876,
                0.7463250160217285,
                0.639331042766571,
                0.7848182916641235,
                0.8455149531364441,
                0.8559761047363281,
                0.7761671543121338,
                0.6737759709358215,
                0.8623483180999756,
                0.8559622168540955,
                0.7781592011451721,
                0.8682518005371094,
                0.8634895086288452,
                0.7878861427307129,
                0.8468557596206665,
                0.7952311038970947,
                0.7858861088752747,
                0.7944750189781189,
                0.789523184299469,
                0.7938255071640015,
                0.7851597666740417,
                0.79139643907547,
                0.7280537486076355,
                0.7152162194252014,
                0.7735984921455383,
                0.7162243127822876,
                0.81587815284729,
                0.8324047327041626,
                0.8357365131378174,
                0.8562571406364441,
                0.8546972274780273
            ],
            [
                0.7496837973594666,
                0.7250736355781555,
                0.7215941548347473,
                0.7191529273986816,
                0.7292892932891846,
                0.7540098428726196,
                0.7522703409194946,
                0.7176235914230347,
                0.696705162525177,
                0.8141037821769714,
                0.8092496991157532,
                0.8023891448974609,
                0.823494553565979,
                0.7126255035400391,
                0.8381334543228149,
                0.8234471082687378,
                0.8206755518913269,
                0.8268584609031677,
                0.8192791938781738,
                0.8286415338516235,
                0.7769420742988586,
                0.8420395851135254,
                0.7773429751396179,
                0.7883232831954956,
                0.7785633206367493,
                0.7778557538986206,
                0.8139491081237793,
                0.7964083552360535,
                0.7604036927223206,
                0.7588027715682983,
                0.7963493466377258,
                0.7522703409194946,
                0.7728977799415588,
                0.780391275882721,
                0.7573429942131042,
                0.7899712920188904,
                0.785423755645752
            ],
            [
                0.846102237701416,
                0.7076009511947632,
                0.7401245832443237,
                0.6552849411964417,
                0.7477514743804932,
                0.7659292221069336,
                0.6673058867454529,
                0.7157204151153564,
                0.612423837184906,
                0.7898839712142944,
                0.858171820640564,
                0.8946164846420288,
                0.7646639347076416,
                0.6103578209877014,
                0.8542914986610413,
                0.8547852635383606,
                0.7720935344696045,
                0.8661606907844543,
                0.8636380434036255,
                0.7803199291229248,
                0.8385366797447205,
                0.7825950980186462,
                0.7440491318702698,
                0.7569326162338257,
                0.7301584482192993,
                0.7424944043159485,
                0.7723425626754761,
                0.7550882697105408,
                0.68746417760849,
                0.7000513672828674,
                0.767392098903656,
                0.6673058867454529,
                0.7771206498146057,
                0.8134329319000244,
                0.8316628336906433,
                0.842781126499176,
                0.8409266471862793
            ],
            [
                0.9035993814468384,
                0.7216334342956543,
                0.7953519821166992,
                0.645660936832428,
                0.8132331371307373,
                0.7990650534629822,
                0.6558560132980347,
                0.7902007699012756,
                0.6079809069633484,
                0.7689633965492249,
                0.884776771068573,
                0.9049624800682068,
                0.7669263482093811,
                0.589716374874115,
                0.8817250728607178,
                0.8871355056762695,
                0.7640193700790405,
                0.8795373439788818,
                0.885775089263916,
                0.7948924899101257,
                0.8721998333930969,
                0.7763048410415649,
                0.7689074277877808,
                0.8006252646446228,
                0.7454842329025269,
                0.7555262446403503,
                0.7858389616012573,
                0.7913629412651062,
                0.6834654808044434,
                0.7154956459999084,
                0.7784479260444641,
                0.6558560132980347,
                0.8000813722610474,
                0.8388341069221497,
                0.8377797603607178,
                0.8567702174186707,
                0.8630788922309875
            ],
            [
                0.8483069539070129,
                0.7527365684509277,
                0.8340343236923218,
                0.6840242743492126,
                0.8475790023803711,
                0.8334260582923889,
                0.7213940024375916,
                0.829171359539032,
                0.6329704523086548,
                0.7842785716056824,
                0.8350823521614075,
                0.8028286695480347,
                0.7790130376815796,
                0.6427850723266602,
                0.8373279571533203,
                0.8348551392555237,
                0.7752461433410645,
                0.8268533945083618,
                0.8195639848709106,
                0.8082653284072876,
                0.7999677658081055,
                0.7816466093063354,
                0.7761911153793335,
                0.7928505539894104,
                0.763495683670044,
                0.7695528864860535,
                0.7990679740905762,
                0.7923468947410583,
                0.7526599168777466,
                0.6913129687309265,
                0.8121787309646606,
                0.7213940024375916,
                0.8186143636703491,
                0.8408248424530029,
                0.7985109686851501,
                0.8236463665962219,
                0.8309952020645142
            ],
            [
                0.7630573511123657,
                0.7465038299560547,
                0.7567710876464844,
                0.7114661931991577,
                0.7549500465393066,
                0.7896935343742371,
                0.7448529601097107,
                0.7451584935188293,
                0.667474627494812,
                0.7962511777877808,
                0.8391481637954712,
                0.8388280868530273,
                0.8243626356124878,
                0.6962562799453735,
                0.852163553237915,
                0.8573784828186035,
                0.8376867175102234,
                0.8481565117835999,
                0.8450663685798645,
                0.8213497400283813,
                0.8159884214401245,
                0.8241327404975891,
                0.8097925782203674,
                0.8299399614334106,
                0.81160569190979,
                0.8149994611740112,
                0.8032244443893433,
                0.8166539072990417,
                0.7339590787887573,
                0.755884051322937,
                0.7880414128303528,
                0.7448529601097107,
                0.7843882441520691,
                0.8194405436515808,
                0.786827027797699,
                0.81260085105896,
                0.8091004490852356
            ],
            [
                0.8081147074699402,
                0.6772422790527344,
                0.7139306664466858,
                0.6422072649002075,
                0.7100276350975037,
                0.7361363768577576,
                0.6482484340667725,
                0.6918249130249023,
                0.5971136093139648,
                0.7666868567466736,
                0.832821786403656,
                0.8671014308929443,
                0.7498582601547241,
                0.6019695401191711,
                0.8211333155632019,
                0.8273082375526428,
                0.7489984035491943,
                0.8253085017204285,
                0.8224159479141235,
                0.766968846321106,
                0.7989264130592346,
                0.784164547920227,
                0.733889102935791,
                0.7467937469482422,
                0.7168449759483337,
                0.7257699370384216,
                0.7660436630249023,
                0.7437220811843872,
                0.6425650119781494,
                0.6877424120903015,
                0.7419997453689575,
                0.6482484340667725,
                0.7508871555328369,
                0.7912803292274475,
                0.7769014239311218,
                0.8003734350204468,
                0.7972310781478882
            ],
            [
                0.7578318119049072,
                0.7005031704902649,
                0.7396092414855957,
                0.7110476493835449,
                0.7482776641845703,
                0.7696802616119385,
                0.7477306127548218,
                0.7161394357681274,
                0.6425213813781738,
                0.7621811032295227,
                0.7978956699371338,
                0.7764716148376465,
                0.7830491662025452,
                0.6892567276954651,
                0.8078054189682007,
                0.8120262026786804,
                0.7942243218421936,
                0.80742347240448,
                0.797459602355957,
                0.7756065130233765,
                0.758954644203186,
                0.7697845697402954,
                0.75030916929245,
                0.7901007533073425,
                0.7798236608505249,
                0.7757053375244141,
                0.7483757138252258,
                0.7512204051017761,
                0.6896478533744812,
                0.6831220984458923,
                0.7778124809265137,
                0.7477306127548218,
                0.7883924245834351,
                0.8112437725067139,
                0.7871098518371582,
                0.8220928907394409,
                0.8147414326667786
            ],
            [
                0.8180438280105591,
                0.6723650693893433,
                0.7254591584205627,
                0.6386972665786743,
                0.7358551025390625,
                0.7362205982208252,
                0.6340274214744568,
                0.7015666365623474,
                0.60004723072052,
                0.7563341856002808,
                0.8437137007713318,
                0.8764068484306335,
                0.7563823461532593,
                0.5871667265892029,
                0.8421458005905151,
                0.8383796811103821,
                0.7477424740791321,
                0.8437536954879761,
                0.8386109471321106,
                0.7777056694030762,
                0.8404919505119324,
                0.7945517301559448,
                0.7324987053871155,
                0.7660255432128906,
                0.7327903509140015,
                0.7464796304702759,
                0.7760674357414246,
                0.7458882331848145,
                0.6663808822631836,
                0.6883037090301514,
                0.7314372062683105,
                0.6340274214744568,
                0.749705970287323,
                0.7794256210327148,
                0.7777881622314453,
                0.794326663017273,
                0.7904945015907288
            ],
            [
                0.7671006917953491,
                0.7269562482833862,
                0.7316319942474365,
                0.7319960594177246,
                0.7375598549842834,
                0.7527823448181152,
                0.7460119724273682,
                0.7109194993972778,
                0.6823888421058655,
                0.8073136210441589,
                0.8205142021179199,
                0.8174415230751038,
                0.8264400959014893,
                0.708220362663269,
                0.8512220978736877,
                0.8302410840988159,
                0.8378129601478577,
                0.8486194014549255,
                0.836742103099823,
                0.813856303691864,
                0.793632984161377,
                0.8196778297424316,
                0.7730681896209717,
                0.796703040599823,
                0.7735309600830078,
                0.7777879238128662,
                0.7971773743629456,
                0.7793859243392944,
                0.7406975030899048,
                0.7273979783058167,
                0.7984253168106079,
                0.7460119724273682,
                0.781812310218811,
                0.7899988293647766,
                0.7796236276626587,
                0.8031593561172485,
                0.7978774905204773
            ],
            [
                0.7725895643234253,
                0.7307244539260864,
                0.7767578363418579,
                0.7406927943229675,
                0.7579769492149353,
                0.7876746654510498,
                0.7674011588096619,
                0.7490965127944946,
                0.6624730825424194,
                0.7874980568885803,
                0.8129702806472778,
                0.7761428356170654,
                0.7820720672607422,
                0.7092698216438293,
                0.8345311284065247,
                0.8066882491111755,
                0.785683810710907,
                0.8301296830177307,
                0.8104117512702942,
                0.7823619246482849,
                0.7525087594985962,
                0.7560904026031494,
                0.7582942247390747,
                0.795849084854126,
                0.781817615032196,
                0.777020275592804,
                0.751261293888092,
                0.7569242715835571,
                0.7108690142631531,
                0.6889277100563049,
                0.7831851243972778,
                0.7674011588096619,
                0.8167859315872192,
                0.7905253171920776,
                0.7810717821121216,
                0.8210936784744263,
                0.8176913261413574
            ],
            [
                0.7250809073448181,
                0.6308320164680481,
                0.6727631092071533,
                0.6543107032775879,
                0.698486864566803,
                0.7116563320159912,
                0.6684505343437195,
                0.6518366932868958,
                0.6198660135269165,
                0.6879087686538696,
                0.7539465427398682,
                0.7826129198074341,
                0.6941252946853638,
                0.6364993453025818,
                0.7889068126678467,
                0.7761117219924927,
                0.6883034706115723,
                0.7967367172241211,
                0.7910516262054443,
                0.6806579232215881,
                0.7963718175888062,
                0.705177366733551,
                0.72956383228302,
                0.7565949559211731,
                0.76235032081604,
                0.7640444040298462,
                0.6752740740776062,
                0.7230685949325562,
                0.6307625770568848,
                0.6680959463119507,
                0.6928430795669556,
                0.6684505343437195,
                0.7530415058135986,
                0.7759736776351929,
                0.7809111475944519,
                0.7950131297111511,
                0.7854300737380981
            ],
            [
                0.8328248858451843,
                0.6877456903457642,
                0.7394052743911743,
                0.6678247451782227,
                0.7556862235069275,
                0.7523150444030762,
                0.6683031320571899,
                0.7191128134727478,
                0.6349143385887146,
                0.7683184742927551,
                0.8450412154197693,
                0.8774378895759583,
                0.7692418694496155,
                0.6206284165382385,
                0.8509710431098938,
                0.838123619556427,
                0.7655378580093384,
                0.8485820889472961,
                0.8424591422080994,
                0.7755202054977417,
                0.8228759765625,
                0.7934420704841614,
                0.747820258140564,
                0.7769080400466919,
                0.7458950877189636,
                0.7549839615821838,
                0.7727574706077576,
                0.7585105895996094,
                0.6814691424369812,
                0.702704131603241,
                0.7461242079734802,
                0.6683031320571899,
                0.77553790807724,
                0.7867235541343689,
                0.7874141335487366,
                0.8067707419395447,
                0.8029943704605103
            ],
            [
                0.8203877210617065,
                0.7546747326850891,
                0.8191322684288025,
                0.7758470773696899,
                0.8272312879562378,
                0.8349661231040955,
                0.8171700239181519,
                0.8126158714294434,
                0.7285503149032593,
                0.8062056303024292,
                0.8277398347854614,
                0.7888045907020569,
                0.8299146890640259,
                0.7588071823120117,
                0.8370717763900757,
                0.8281213641166687,
                0.8306544423103333,
                0.8283361792564392,
                0.8176494836807251,
                0.8330734372138977,
                0.7829231023788452,
                0.8117064833641052,
                0.8147847056388855,
                0.8464959859848022,
                0.833840012550354,
                0.8283236026763916,
                0.8233752250671387,
                0.8300562500953674,
                0.7556195855140686,
                0.7160685658454895,
                0.8256837129592896,
                0.8171700239181519,
                0.8354215025901794,
                0.8165566325187683,
                0.776455819606781,
                0.8244277834892273,
                0.8316408395767212
            ],
            [
                0.9127455353736877,
                0.7640479803085327,
                0.8127213716506958,
                0.6722825765609741,
                0.827815592288971,
                0.8228869438171387,
                0.6988385319709778,
                0.7968242764472961,
                0.6255640983581543,
                0.8199074864387512,
                0.8772003650665283,
                0.8881608247756958,
                0.7947967648506165,
                0.6391695737838745,
                0.8769186735153198,
                0.8726451396942139,
                0.79518723487854,
                0.8668850660324097,
                0.8708996176719666,
                0.8181191682815552,
                0.8519957065582275,
                0.8053026795387268,
                0.8093277215957642,
                0.8138101696968079,
                0.7826484441757202,
                0.7830049395561218,
                0.8071948885917664,
                0.8212655782699585,
                0.7140868306159973,
                0.7175863981246948,
                0.8152024149894714,
                0.6988385319709778,
                0.8163182735443115,
                0.8354560136795044,
                0.8214604258537292,
                0.851100504398346,
                0.8567475080490112
            ],
            [
                0.7759504914283752,
                0.6888935565948486,
                0.7432412505149841,
                0.7869587540626526,
                0.7894531488418579,
                0.7608120441436768,
                0.802956223487854,
                0.7281336188316345,
                0.7289239764213562,
                0.7596808075904846,
                0.7681752443313599,
                0.7587394118309021,
                0.8079756498336792,
                0.7835952639579773,
                0.796551525592804,
                0.786333441734314,
                0.8152613043785095,
                0.7909263968467712,
                0.7863829731941223,
                0.771104633808136,
                0.747438907623291,
                0.7831072211265564,
                0.7843676805496216,
                0.8190315365791321,
                0.8243677020072937,
                0.8159872889518738,
                0.7568808197975159,
                0.7832267880439758,
                0.7569575309753418,
                0.7085786461830139,
                0.7930763363838196,
                0.802956223487854,
                0.8089378476142883,
                0.7651229500770569,
                0.7450733184814453,
                0.7868372201919556,
                0.7822876572608948
            ]
        ],
        [
            [
                0.8050049543380737,
                0.7558887004852295,
                0.6128618717193604,
                0.659275233745575,
                0.6692751049995422,
                0.6930074691772461,
                0.7837531566619873,
                0.7621814608573914,
                0.8048930764198303,
                0.7210656404495239,
                0.7427968382835388,
                0.8518846035003662,
                0.758133053779602,
                0.6957098245620728,
                0.6930074691772461,
                0.7452576160430908,
                0.8339239358901978,
                0.7542682886123657,
                0.7130489945411682,
                0.6669222712516785,
                0.7065682411193848,
                0.6922523379325867,
                0.7598591446876526,
                0.7307535409927368,
                0.6922523379325867,
                0.7217224836349487,
                0.7396697402000427,
                0.7432196736335754,
                0.7653855681419373,
                0.671795129776001,
                0.7811228632926941,
                0.7034049034118652,
                0.7542030811309814,
                0.7524670958518982,
                0.7736151814460754,
                0.746271550655365,
                0.7449803352355957,
                0.7175235152244568,
                0.7411162853240967,
                0.7730645537376404,
                0.7034049034118652,
                0.6564750671386719,
                0.6843090057373047,
                0.7231013178825378,
                0.7425022721290588
            ],
            [
                0.7933737635612488,
                0.8138644099235535,
                0.569188117980957,
                0.6495047807693481,
                0.6384174823760986,
                0.6726664900779724,
                0.6815996766090393,
                0.8497419953346252,
                0.6905456781387329,
                0.729092001914978,
                0.7681192755699158,
                0.7888038754463196,
                0.8321211338043213,
                0.6886466145515442,
                0.6726664900779724,
                0.70307856798172,
                0.8171228170394897,
                0.8486936092376709,
                0.70489501953125,
                0.6411914825439453,
                0.6977285146713257,
                0.6648935079574585,
                0.8012070655822754,
                0.7790464162826538,
                0.6648935079574585,
                0.6311917304992676,
                0.7598859071731567,
                0.7588815689086914,
                0.7409778833389282,
                0.6053696274757385,
                0.7989523410797119,
                0.7301856279373169,
                0.8108909726142883,
                0.6695007085800171,
                0.8063575029373169,
                0.7545208930969238,
                0.7129964828491211,
                0.6958617568016052,
                0.7333288788795471,
                0.7621647119522095,
                0.7301856279373169,
                0.6164542436599731,
                0.6741738319396973,
                0.7865065336227417,
                0.707304835319519
            ],
            [
                0.8135598301887512,
                0.8279579281806946,
                0.6301556825637817,
                0.6895915269851685,
                0.6724871397018433,
                0.7002711296081543,
                0.8578593730926514,
                0.8308273553848267,
                0.8659570813179016,
                0.7623406052589417,
                0.7872031927108765,
                0.8680960536003113,
                0.8223826289176941,
                0.7209560871124268,
                0.7002711296081543,
                0.7504034042358398,
                0.8965778946876526,
                0.8202869892120361,
                0.7343409061431885,
                0.6853649616241455,
                0.7180547118186951,
                0.6881504058837891,
                0.8299579620361328,
                0.8054730296134949,
                0.6881504058837891,
                0.689649760723114,
                0.7685720920562744,
                0.7894291877746582,
                0.7797320485115051,
                0.6695128679275513,
                0.8305534720420837,
                0.7408074736595154,
                0.8101962208747864,
                0.7358888983726501,
                0.8084599375724792,
                0.7760018706321716,
                0.7705574631690979,
                0.7362085580825806,
                0.7826843857765198,
                0.8015617728233337,
                0.7408074736595154,
                0.6848827004432678,
                0.7123623490333557,
                0.8054060339927673,
                0.7750231623649597
            ],
            [
                0.8823575377464294,
                0.8532645106315613,
                0.5952461361885071,
                0.6759060621261597,
                0.7028310894966125,
                0.7358093857765198,
                0.7232069969177246,
                0.8824584484100342,
                0.7120637893676758,
                0.8105648756027222,
                0.8694862127304077,
                0.8214253187179565,
                0.8704403638839722,
                0.7550941109657288,
                0.7358093857765198,
                0.7778192162513733,
                0.8741512298583984,
                0.8827646970748901,
                0.7761951088905334,
                0.6804877519607544,
                0.7703948020935059,
                0.7295234799385071,
                0.8442167043685913,
                0.8144082427024841,
                0.7295234799385071,
                0.6676194667816162,
                0.8037533164024353,
                0.8515929579734802,
                0.8709535598754883,
                0.6863082647323608,
                0.906796932220459,
                0.8126018643379211,
                0.8847970366477966,
                0.7938098311424255,
                0.8488654494285583,
                0.866183876991272,
                0.7988559007644653,
                0.7947579026222229,
                0.8362140655517578,
                0.8630180358886719,
                0.8126018643379211,
                0.6709814071655273,
                0.7641676664352417,
                0.8449215888977051,
                0.7903230786323547
            ],
            [
                0.9226964712142944,
                0.8553751707077026,
                0.6994096040725708,
                0.7738324403762817,
                0.8234459757804871,
                0.8455044627189636,
                0.6641486287117004,
                0.8704949617385864,
                0.6441856622695923,
                0.9089308977127075,
                0.914659857749939,
                0.8157649636268616,
                0.8702035546302795,
                0.8542409539222717,
                0.8455044627189636,
                0.8724067211151123,
                0.8464069962501526,
                0.8623092770576477,
                0.8587996363639832,
                0.7581549286842346,
                0.8573901057243347,
                0.8385467529296875,
                0.810937225818634,
                0.7852797508239746,
                0.8385467529296875,
                0.717463493347168,
                0.9032833576202393,
                0.8773589730262756,
                0.8901653289794922,
                0.7526915073394775,
                0.9075829982757568,
                0.9110043048858643,
                0.9086385369300842,
                0.8088105916976929,
                0.8470171689987183,
                0.884186863899231,
                0.8782575130462646,
                0.9007400274276733,
                0.8676511645317078,
                0.9131351709365845,
                0.9110043048858643,
                0.7641298174858093,
                0.8485147356987,
                0.8865796327590942,
                0.8970634937286377
            ],
            [
                0.8974820971488953,
                0.9350652694702148,
                0.6366808414459229,
                0.7853822112083435,
                0.7986009120941162,
                0.8205769658088684,
                0.7102348804473877,
                0.9015725255012512,
                0.7078891396522522,
                0.8728265762329102,
                0.8887909650802612,
                0.8387372493743896,
                0.8886155486106873,
                0.8448871374130249,
                0.8205769658088684,
                0.8416019678115845,
                0.8714262843132019,
                0.8786711692810059,
                0.8504205942153931,
                0.7873216271400452,
                0.8330886363983154,
                0.8172118067741394,
                0.8432021141052246,
                0.8164193630218506,
                0.8172118067741394,
                0.6721226572990417,
                0.8632171154022217,
                0.8722057342529297,
                0.8542935252189636,
                0.6879661083221436,
                0.8917962312698364,
                0.8628805875778198,
                0.8956390619277954,
                0.7489624619483948,
                0.8385722637176514,
                0.8435131311416626,
                0.8507860898971558,
                0.8373377323150635,
                0.8575398921966553,
                0.874373197555542,
                0.8628805875778198,
                0.7244156002998352,
                0.8315001726150513,
                0.909762442111969,
                0.8634530305862427
            ],
            [
                0.756169319152832,
                0.7671143412590027,
                0.6805403232574463,
                0.7190437912940979,
                0.7053219079971313,
                0.7174605131149292,
                0.8277662992477417,
                0.7737815380096436,
                0.8085315823554993,
                0.7508959770202637,
                0.7501809597015381,
                0.8282749652862549,
                0.7419994473457336,
                0.7323088049888611,
                0.7174605131149292,
                0.7822665572166443,
                0.8103315234184265,
                0.7258708477020264,
                0.7392147183418274,
                0.7051954865455627,
                0.7323248386383057,
                0.7224501967430115,
                0.7691261172294617,
                0.7209853529930115,
                0.7224501967430115,
                0.7209613919258118,
                0.7638642191886902,
                0.7790504693984985,
                0.766663134098053,
                0.7292125821113586,
                0.7825875878334045,
                0.7061074376106262,
                0.750313937664032,
                0.742957353591919,
                0.7358577847480774,
                0.7156266570091248,
                0.7561904788017273,
                0.6971859931945801,
                0.773379385471344,
                0.7875660061836243,
                0.7061074376106262,
                0.7579686045646667,
                0.7472959756851196,
                0.7491030693054199,
                0.7363686561584473
            ],
            [
                0.8928874731063843,
                0.8628743290901184,
                0.684821367263794,
                0.7377215027809143,
                0.7913321852684021,
                0.8200315833091736,
                0.7291754484176636,
                0.8843240141868591,
                0.7235054969787598,
                0.8627557158470154,
                0.8832334876060486,
                0.8665103912353516,
                0.8848682641983032,
                0.8360626697540283,
                0.8200315833091736,
                0.8789241909980774,
                0.8864361047744751,
                0.8719713687896729,
                0.8525744676589966,
                0.7329179644584656,
                0.8658459186553955,
                0.8159369230270386,
                0.8235554099082947,
                0.7948441505432129,
                0.8159369230270386,
                0.7386085391044617,
                0.8831496834754944,
                0.8688262104988098,
                0.8875625729560852,
                0.7544363737106323,
                0.8955546617507935,
                0.8818892240524292,
                0.8927817940711975,
                0.7996134757995605,
                0.8643893003463745,
                0.8723739385604858,
                0.8533573746681213,
                0.8553327322006226,
                0.8431317210197449,
                0.8952347636222839,
                0.8818892240524292,
                0.7407218217849731,
                0.8185624480247498,
                0.850485622882843,
                0.8408921360969543
            ],
            [
                0.91779625415802,
                0.8536397814750671,
                0.6939648985862732,
                0.7912720441818237,
                0.8291690945625305,
                0.8600492477416992,
                0.7156702280044556,
                0.8787572979927063,
                0.7201008796691895,
                0.9205502867698669,
                0.9138096570968628,
                0.8632089495658875,
                0.8746877312660217,
                0.8831069469451904,
                0.8600492477416992,
                0.9059181213378906,
                0.8784024119377136,
                0.8577479124069214,
                0.8898698091506958,
                0.7692164182662964,
                0.8812876343727112,
                0.8354057669639587,
                0.8139018416404724,
                0.7889844179153442,
                0.8354057669639587,
                0.7137776613235474,
                0.9191297888755798,
                0.9085937142372131,
                0.9073377847671509,
                0.7681929469108582,
                0.9103155732154846,
                0.9055181741714478,
                0.9076540470123291,
                0.8191933035850525,
                0.8637880086898804,
                0.881131649017334,
                0.9039892554283142,
                0.8780577182769775,
                0.8817707896232605,
                0.9222747087478638,
                0.9055181741714478,
                0.7834863066673279,
                0.8656388521194458,
                0.8805941939353943,
                0.891104519367218
            ],
            [
                0.8264341354370117,
                0.8059512376785278,
                0.6450377106666565,
                0.7145469188690186,
                0.7230958342552185,
                0.7583297491073608,
                0.7051241397857666,
                0.8402798771858215,
                0.6987253427505493,
                0.8216674327850342,
                0.8436218500137329,
                0.8601348400115967,
                0.8533987402915955,
                0.7701512575149536,
                0.7583297491073608,
                0.7978983521461487,
                0.8559123277664185,
                0.8384233117103577,
                0.7885534167289734,
                0.6995925903320312,
                0.7815253734588623,
                0.7352148294448853,
                0.8093523979187012,
                0.7944918274879456,
                0.7352148294448853,
                0.6745917797088623,
                0.8239815831184387,
                0.8056200742721558,
                0.8065246343612671,
                0.6898587942123413,
                0.8484184741973877,
                0.8128983974456787,
                0.8559030890464783,
                0.7392921447753906,
                0.8090522885322571,
                0.7984793782234192,
                0.8258407115936279,
                0.7951924204826355,
                0.8158209323883057,
                0.8334046006202698,
                0.8128983974456787,
                0.7009636163711548,
                0.7525149583816528,
                0.8161740899085999,
                0.8171300292015076
            ],
            [
                0.8132434487342834,
                0.8369339108467102,
                0.6245279908180237,
                0.7128225564956665,
                0.690377414226532,
                0.7173358201980591,
                0.7934513688087463,
                0.8641566038131714,
                0.8008138537406921,
                0.7803217172622681,
                0.8134304881095886,
                0.8542057275772095,
                0.8580219149589539,
                0.736289918422699,
                0.7173358201980591,
                0.7473926544189453,
                0.8881701827049255,
                0.8600994348526001,
                0.7412370443344116,
                0.7034200429916382,
                0.7157140970230103,
                0.6888151168823242,
                0.8556552529335022,
                0.8256775736808777,
                0.6888151168823242,
                0.6657732725143433,
                0.7786394357681274,
                0.8029073476791382,
                0.7889468669891357,
                0.6622189283370972,
                0.8320378065109253,
                0.7513031363487244,
                0.8388815522193909,
                0.6885743141174316,
                0.799942135810852,
                0.784195601940155,
                0.7573180198669434,
                0.7347536087036133,
                0.8020784854888916,
                0.8046630620956421,
                0.7513031363487244,
                0.6736373901367188,
                0.725560188293457,
                0.8233588933944702,
                0.7601367235183716
            ],
            [
                0.8760313987731934,
                0.8167284727096558,
                0.7042630314826965,
                0.7608864307403564,
                0.8143346309661865,
                0.8305047750473022,
                0.7052762508392334,
                0.8349648714065552,
                0.6715897917747498,
                0.8902729749679565,
                0.8889816999435425,
                0.822936475276947,
                0.8337077498435974,
                0.8346108794212341,
                0.8305047750473022,
                0.8629938960075378,
                0.8374024033546448,
                0.8190357089042664,
                0.8483051061630249,
                0.7569261193275452,
                0.849308967590332,
                0.8305416703224182,
                0.7900162935256958,
                0.7570976614952087,
                0.8305416703224182,
                0.7249354124069214,
                0.8800954222679138,
                0.8496050238609314,
                0.867792546749115,
                0.7565186023712158,
                0.8746586441993713,
                0.8864789605140686,
                0.8844358921051025,
                0.8037434220314026,
                0.828301191329956,
                0.8412941694259644,
                0.8724944591522217,
                0.8817874193191528,
                0.8372825384140015,
                0.8868968486785889,
                0.8864789605140686,
                0.7671803832054138,
                0.8251676559448242,
                0.8487239480018616,
                0.8798842430114746
            ],
            [
                0.8589054346084595,
                0.8326716423034668,
                0.6277216076850891,
                0.700488805770874,
                0.7176178097724915,
                0.7543525695800781,
                0.804993748664856,
                0.8830464482307434,
                0.8132940530776978,
                0.8214792013168335,
                0.8682125806808472,
                0.9022383093833923,
                0.881367564201355,
                0.7833127379417419,
                0.7543525695800781,
                0.8250001668930054,
                0.9106773734092712,
                0.8798317313194275,
                0.8011595010757446,
                0.6922039985656738,
                0.7990768551826477,
                0.7327935099601746,
                0.8511974215507507,
                0.8268548250198364,
                0.7327935099601746,
                0.7182068228721619,
                0.8251820206642151,
                0.8570162653923035,
                0.8707828521728516,
                0.7401593327522278,
                0.8871521353721619,
                0.8091074824333191,
                0.8842529058456421,
                0.8040591478347778,
                0.8726414442062378,
                0.8571610450744629,
                0.82227623462677,
                0.797928512096405,
                0.8464447855949402,
                0.87260901927948,
                0.8091074824333191,
                0.6951072812080383,
                0.774451732635498,
                0.8202373385429382,
                0.7857585549354553
            ],
            [
                0.898167610168457,
                0.879667341709137,
                0.6525627970695496,
                0.7453491687774658,
                0.7603388428688049,
                0.7933355569839478,
                0.7393802404403687,
                0.920458972454071,
                0.727581262588501,
                0.8778360486030579,
                0.9215902090072632,
                0.8767214417457581,
                0.919956386089325,
                0.8358139395713806,
                0.7933355569839478,
                0.8555000424385071,
                0.8946707248687744,
                0.9233564138412476,
                0.853003203868866,
                0.7275728583335876,
                0.8468751907348633,
                0.7741588354110718,
                0.8685304522514343,
                0.8526499271392822,
                0.7741588354110718,
                0.6917305588722229,
                0.889489471912384,
                0.9017132520675659,
                0.8924007415771484,
                0.7198138236999512,
                0.9284583330154419,
                0.8642022609710693,
                0.92795729637146,
                0.7867575883865356,
                0.8890470862388611,
                0.9117727279663086,
                0.8605736494064331,
                0.8594973087310791,
                0.9032412767410278,
                0.9134393334388733,
                0.8642022609710693,
                0.7123721837997437,
                0.839279294013977,
                0.8872089385986328,
                0.8484147787094116
            ],
            [
                0.8545265793800354,
                0.8469884991645813,
                0.735044538974762,
                0.7598451375961304,
                0.7942665815353394,
                0.8067498207092285,
                0.6650878190994263,
                0.8371194005012512,
                0.6364932060241699,
                0.863249659538269,
                0.8374077081680298,
                0.767510712146759,
                0.8143904805183411,
                0.8249200582504272,
                0.8067498207092285,
                0.8369678258895874,
                0.8159802556037903,
                0.8120288252830505,
                0.8260634541511536,
                0.7589083909988403,
                0.8399948477745056,
                0.8321096301078796,
                0.7728220820426941,
                0.7479382753372192,
                0.8321096301078796,
                0.7320523858070374,
                0.8738598227500916,
                0.8286081552505493,
                0.8178706169128418,
                0.7245209217071533,
                0.8385130763053894,
                0.8668508529663086,
                0.846990704536438,
                0.7663118839263916,
                0.7975195050239563,
                0.8342298865318298,
                0.8256412148475647,
                0.8489966988563538,
                0.7937299609184265,
                0.8440336585044861,
                0.8668508529663086,
                0.770687460899353,
                0.8171822428703308,
                0.8603156805038452,
                0.8468965291976929
            ],
            [
                0.7273550033569336,
                0.7239682674407959,
                0.6955018639564514,
                0.7134385108947754,
                0.6853484511375427,
                0.7054028511047363,
                0.7900267243385315,
                0.7686305642127991,
                0.7773829698562622,
                0.7426869869232178,
                0.7538881301879883,
                0.7988039255142212,
                0.7477097511291504,
                0.6883018016815186,
                0.7054028511047363,
                0.7122727632522583,
                0.8047581911087036,
                0.7402106523513794,
                0.7019855380058289,
                0.6946814656257629,
                0.685236930847168,
                0.6846325993537903,
                0.76404869556427,
                0.73930823802948,
                0.6846325993537903,
                0.7040178775787354,
                0.738675594329834,
                0.7296257019042969,
                0.7350231409072876,
                0.7094972133636475,
                0.791043758392334,
                0.691637396812439,
                0.7749274969100952,
                0.7322283983230591,
                0.7306243777275085,
                0.730327844619751,
                0.7369410991668701,
                0.6934080123901367,
                0.7563934326171875,
                0.7632596492767334,
                0.691637396812439,
                0.73646080493927,
                0.7087971568107605,
                0.7437839508056641,
                0.7329608201980591
            ],
            [
                0.7351118922233582,
                0.7464469075202942,
                0.6080099940299988,
                0.6854490637779236,
                0.6505424976348877,
                0.6810321807861328,
                0.8762027621269226,
                0.7811597585678101,
                0.8783112168312073,
                0.7362856864929199,
                0.7594344615936279,
                0.8365808725357056,
                0.7641264200210571,
                0.6998820900917053,
                0.6810321807861328,
                0.7094394564628601,
                0.8325192332267761,
                0.7593144774436951,
                0.7000089287757874,
                0.6772792935371399,
                0.6718417406082153,
                0.6481513381004333,
                0.7840722799301147,
                0.7501025199890137,
                0.6481513381004333,
                0.6383248567581177,
                0.7347127199172974,
                0.7588781714439392,
                0.7448815703392029,
                0.6740264296531677,
                0.7839410901069641,
                0.6718019843101501,
                0.7583632469177246,
                0.6846648454666138,
                0.7501005530357361,
                0.7340137362480164,
                0.7231213450431824,
                0.6804304718971252,
                0.7555205821990967,
                0.7634625434875488,
                0.6718019843101501,
                0.6665473580360413,
                0.6985669136047363,
                0.7490418553352356,
                0.7085619568824768
            ],
            [
                0.8372323513031006,
                0.8458237051963806,
                0.7258532047271729,
                0.7675728797912598,
                0.7910131216049194,
                0.7988853454589844,
                0.6805790662765503,
                0.84898841381073,
                0.6405069828033447,
                0.8493797779083252,
                0.8336066007614136,
                0.7656204700469971,
                0.8101590871810913,
                0.8145954608917236,
                0.7988853454589844,
                0.8227634429931641,
                0.8182713985443115,
                0.8182945251464844,
                0.8134443163871765,
                0.7668088674545288,
                0.822296679019928,
                0.822260856628418,
                0.7831316590309143,
                0.7554717659950256,
                0.822260856628418,
                0.7305639982223511,
                0.8526549935340881,
                0.8221887946128845,
                0.8052499294281006,
                0.7169345021247864,
                0.8317952156066895,
                0.8528673648834229,
                0.839415431022644,
                0.7589871883392334,
                0.7940666079521179,
                0.8211227059364319,
                0.8205447196960449,
                0.8341866731643677,
                0.784676194190979,
                0.8314491510391235,
                0.8528673648834229,
                0.7609085440635681,
                0.8029413819313049,
                0.84940105676651,
                0.8261293768882751
            ],
            [
                0.7409512996673584,
                0.7375127673149109,
                0.7051354646682739,
                0.7337011098861694,
                0.7303622364997864,
                0.7456563711166382,
                0.7779873013496399,
                0.798450231552124,
                0.7297712564468384,
                0.7692819237709045,
                0.7867152094841003,
                0.8018853664398193,
                0.7698202133178711,
                0.7168814539909363,
                0.7456563711166382,
                0.7549424171447754,
                0.8042829632759094,
                0.7657109498977661,
                0.7367051243782043,
                0.718357264995575,
                0.7295637130737305,
                0.7264456152915955,
                0.7568369507789612,
                0.7417370080947876,
                0.7264456152915955,
                0.7392475605010986,
                0.7479825019836426,
                0.7475157976150513,
                0.7594678401947021,
                0.7398700714111328,
                0.811744749546051,
                0.7180894017219543,
                0.7879512310028076,
                0.7607560157775879,
                0.7508139610290527,
                0.7463135719299316,
                0.7705283761024475,
                0.7237669229507446,
                0.7779548168182373,
                0.795261025428772,
                0.7180894017219543,
                0.7382842898368835,
                0.7411009669303894,
                0.7513422966003418,
                0.7500981688499451
            ],
            [
                0.8075859546661377,
                0.8205862045288086,
                0.6698296070098877,
                0.7176755666732788,
                0.706570565700531,
                0.7413000464439392,
                0.8580273389816284,
                0.8791322112083435,
                0.8069143891334534,
                0.8094337582588196,
                0.8570599555969238,
                0.8634446263313293,
                0.8317214250564575,
                0.7658733129501343,
                0.7413000464439392,
                0.7969141006469727,
                0.8687323927879333,
                0.8460698127746582,
                0.7712132334709167,
                0.7049076557159424,
                0.7716346383094788,
                0.7330687642097473,
                0.839961051940918,
                0.8067317605018616,
                0.7330687642097473,
                0.704673171043396,
                0.8060345649719238,
                0.8462726473808289,
                0.82423996925354,
                0.7458608746528625,
                0.8775731921195984,
                0.7932900190353394,
                0.8514925837516785,
                0.7693727612495422,
                0.8319702744483948,
                0.8248876333236694,
                0.800514280796051,
                0.7739547491073608,
                0.8327566981315613,
                0.8576980233192444,
                0.7932900190353394,
                0.7319690585136414,
                0.7796550989151001,
                0.8206338882446289,
                0.7884483933448792
            ],
            [
                0.783860445022583,
                0.7591750621795654,
                0.7256712913513184,
                0.7560791373252869,
                0.7582898139953613,
                0.7788819670677185,
                0.7539257407188416,
                0.7982789278030396,
                0.7144913077354431,
                0.8186320066452026,
                0.8251175880432129,
                0.7958488464355469,
                0.7739053964614868,
                0.7570998072624207,
                0.7788819670677185,
                0.7865771651268005,
                0.8127657771110535,
                0.7683385610580444,
                0.7818198800086975,
                0.7487581372261047,
                0.7753714919090271,
                0.7773145437240601,
                0.7523784041404724,
                0.7341411709785461,
                0.7773145437240601,
                0.7258419394493103,
                0.7767651081085205,
                0.7791306972503662,
                0.8003618121147156,
                0.7495763301849365,
                0.844786524772644,
                0.7682916522026062,
                0.8115969300270081,
                0.8040989637374878,
                0.7795985341072083,
                0.7942115664482117,
                0.7905579209327698,
                0.766819179058075,
                0.8067811131477356,
                0.8265119791030884,
                0.7682916522026062,
                0.7751309275627136,
                0.7833309173583984,
                0.7836792469024658,
                0.7794967889785767
            ],
            [
                0.8399643301963806,
                0.8273462057113647,
                0.6736088395118713,
                0.725683867931366,
                0.7301615476608276,
                0.7599641680717468,
                0.8349442481994629,
                0.8835269808769226,
                0.815087616443634,
                0.8267855048179626,
                0.8647139072418213,
                0.8764796853065491,
                0.8522259593009949,
                0.7789336442947388,
                0.7599641680717468,
                0.817543625831604,
                0.8797114491462708,
                0.8565737009048462,
                0.7923763990402222,
                0.7075280547142029,
                0.7901256084442139,
                0.743863046169281,
                0.8521442413330078,
                0.8174914717674255,
                0.743863046169281,
                0.7078368067741394,
                0.8286595940589905,
                0.8458690643310547,
                0.8391152024269104,
                0.7433502674102783,
                0.889136552810669,
                0.820298969745636,
                0.8752278089523315,
                0.7769345045089722,
                0.8457692861557007,
                0.8379006385803223,
                0.8070729970932007,
                0.7933968901634216,
                0.8318728804588318,
                0.8691954612731934,
                0.820298969745636,
                0.7377400398254395,
                0.781247615814209,
                0.8263530731201172,
                0.7969233989715576
            ],
            [
                0.7415786981582642,
                0.731995701789856,
                0.7213613390922546,
                0.7523162364959717,
                0.7429567575454712,
                0.7573047876358032,
                0.750704824924469,
                0.7718278765678406,
                0.7128819823265076,
                0.7792370915412903,
                0.7892653346061707,
                0.7944408655166626,
                0.7700210213661194,
                0.727461040019989,
                0.7573047876358032,
                0.7486807107925415,
                0.7995700836181641,
                0.7545716166496277,
                0.7532337307929993,
                0.7329609394073486,
                0.733437180519104,
                0.7310031652450562,
                0.7468516826629639,
                0.7370351552963257,
                0.7310031652450562,
                0.7007222175598145,
                0.7491987943649292,
                0.7447879910469055,
                0.7571156024932861,
                0.7238242626190186,
                0.8155180811882019,
                0.7250851392745972,
                0.788824200630188,
                0.753774106502533,
                0.7381999492645264,
                0.7551689743995667,
                0.7704879641532898,
                0.7267958521842957,
                0.7826969027519226,
                0.7940049767494202,
                0.7250851392745972,
                0.7501057982444763,
                0.7477304339408875,
                0.756323516368866,
                0.7455196976661682
            ],
            [
                0.8129487037658691,
                0.8130037784576416,
                0.6806936860084534,
                0.750132143497467,
                0.7306146621704102,
                0.7565237879753113,
                0.8356530070304871,
                0.8400074243545532,
                0.8250972628593445,
                0.8140684962272644,
                0.8336780667304993,
                0.8651367425918579,
                0.8341087698936462,
                0.7680078744888306,
                0.7565237879753113,
                0.7724449038505554,
                0.8888934850692749,
                0.8337728977203369,
                0.7720749378204346,
                0.7330344915390015,
                0.7440325021743774,
                0.7184986472129822,
                0.8343090415000916,
                0.8138384819030762,
                0.7184986472129822,
                0.6911960244178772,
                0.8003756999969482,
                0.8136286735534668,
                0.7987608909606934,
                0.7159278988838196,
                0.8492041826248169,
                0.7664386034011841,
                0.8348449468612671,
                0.7502843141555786,
                0.810121476650238,
                0.8109511137008667,
                0.7922177314758301,
                0.7556672096252441,
                0.7983013391494751,
                0.8275936245918274,
                0.7664386034011841,
                0.7259182929992676,
                0.7486372590065002,
                0.8197033405303955,
                0.7779263854026794
            ],
            [
                0.8580707311630249,
                0.8381313681602478,
                0.7245194911956787,
                0.8057767152786255,
                0.8299509882926941,
                0.847152829170227,
                0.7501156330108643,
                0.8632379770278931,
                0.7226252555847168,
                0.9001687169075012,
                0.912270188331604,
                0.82591313123703,
                0.8480408787727356,
                0.8550652861595154,
                0.847152829170227,
                0.8577905893325806,
                0.8523421287536621,
                0.830289900302887,
                0.8579878211021423,
                0.7965980768203735,
                0.84492427110672,
                0.8351497650146484,
                0.8440616130828857,
                0.8023480176925659,
                0.8351497650146484,
                0.7174233198165894,
                0.8655406832695007,
                0.8719444274902344,
                0.8809093832969666,
                0.7800120115280151,
                0.901790976524353,
                0.8704909682273865,
                0.888831377029419,
                0.8157374262809753,
                0.8242215514183044,
                0.8786771893501282,
                0.8744570016860962,
                0.8689306974411011,
                0.886396050453186,
                0.9036595821380615,
                0.8704909682273865,
                0.7858119606971741,
                0.8730184435844421,
                0.8854179382324219,
                0.8827703595161438
            ],
            [
                0.7934902906417847,
                0.783090353012085,
                0.7349928617477417,
                0.7660583257675171,
                0.7563878893852234,
                0.7815259695053101,
                0.8160979747772217,
                0.8202908039093018,
                0.7900659441947937,
                0.8175485134124756,
                0.8315393924713135,
                0.8594135642051697,
                0.8064650893211365,
                0.7612483501434326,
                0.7815259695053101,
                0.7863759994506836,
                0.8591050505638123,
                0.7924831509590149,
                0.7618620991706848,
                0.7579225301742554,
                0.7474728226661682,
                0.7639087438583374,
                0.8363734483718872,
                0.7851579785346985,
                0.7639087438583374,
                0.7283929586410522,
                0.7878280878067017,
                0.7912853956222534,
                0.7987703084945679,
                0.7685267329216003,
                0.8514488339424133,
                0.7756868600845337,
                0.8327157497406006,
                0.7766867876052856,
                0.7763697504997253,
                0.7869190573692322,
                0.8088629245758057,
                0.7781853079795837,
                0.8228192925453186,
                0.8388589024543762,
                0.7756868600845337,
                0.7914673089981079,
                0.7806105613708496,
                0.8081150650978088,
                0.8066863417625427
            ],
            [
                0.8191904425621033,
                0.785810649394989,
                0.7406529784202576,
                0.7904221415519714,
                0.7824644446372986,
                0.7955315709114075,
                0.7525834441184998,
                0.7912123203277588,
                0.7424956560134888,
                0.8381073474884033,
                0.8243858814239502,
                0.8289730548858643,
                0.7849235534667969,
                0.7867618799209595,
                0.7955315709114075,
                0.8017184138298035,
                0.839703381061554,
                0.7676271796226501,
                0.7840598225593567,
                0.7656105756759644,
                0.7614416480064392,
                0.7820144295692444,
                0.7988741993904114,
                0.7539455890655518,
                0.7820144295692444,
                0.714647114276886,
                0.8224711418151855,
                0.7991453409194946,
                0.7977955341339111,
                0.753628671169281,
                0.8385211229324341,
                0.79423987865448,
                0.821785569190979,
                0.7626101970672607,
                0.753655731678009,
                0.7775434851646423,
                0.8294447660446167,
                0.794334888458252,
                0.8190681338310242,
                0.8403390645980835,
                0.79423987865448,
                0.8085182905197144,
                0.7982034683227539,
                0.8205639123916626,
                0.830630898475647
            ],
            [
                0.8587622046470642,
                0.8373607397079468,
                0.7079430818557739,
                0.7629852294921875,
                0.7704707384109497,
                0.7843047380447388,
                0.8293811082839966,
                0.872652530670166,
                0.8244529962539673,
                0.8429776430130005,
                0.8642996549606323,
                0.8885490894317627,
                0.8472946882247925,
                0.8131860494613647,
                0.7843047380447388,
                0.8439838886260986,
                0.8978620171546936,
                0.8387924432754517,
                0.8157145380973816,
                0.7524376511573792,
                0.8078140616416931,
                0.784086287021637,
                0.8832933902740479,
                0.8273618817329407,
                0.784086287021637,
                0.7476143836975098,
                0.8437356948852539,
                0.8645294308662415,
                0.858489990234375,
                0.768621027469635,
                0.8828206658363342,
                0.8428519368171692,
                0.8743304014205933,
                0.8009925484657288,
                0.8334531784057617,
                0.8474472761154175,
                0.8449172973632812,
                0.8225231170654297,
                0.8528106808662415,
                0.8746111392974854,
                0.8428519368171692,
                0.7785221934318542,
                0.8090585470199585,
                0.8475431203842163,
                0.8309476375579834
            ],
            [
                0.8387572765350342,
                0.8049444556236267,
                0.724420964717865,
                0.7904706001281738,
                0.816613495349884,
                0.8430331945419312,
                0.692901611328125,
                0.8369066715240479,
                0.6601473689079285,
                0.8672730922698975,
                0.8682718276977539,
                0.8210152387619019,
                0.8278898596763611,
                0.8249136805534363,
                0.8430331945419312,
                0.835129976272583,
                0.8289603590965271,
                0.8049907088279724,
                0.8252761960029602,
                0.7910160422325134,
                0.8208420276641846,
                0.8327947854995728,
                0.7942310571670532,
                0.7594388723373413,
                0.8327947854995728,
                0.7176758050918579,
                0.8473995923995972,
                0.8229017853736877,
                0.8287864327430725,
                0.7569048404693604,
                0.8635088205337524,
                0.8674202561378479,
                0.8828366994857788,
                0.7700173258781433,
                0.7910664081573486,
                0.8179782032966614,
                0.8666934370994568,
                0.8647226691246033,
                0.8348641395568848,
                0.8615644574165344,
                0.8674202561378479,
                0.7779294848442078,
                0.8184537887573242,
                0.8330962061882019,
                0.8757736086845398
            ],
            [
                0.8641896843910217,
                0.8014868497848511,
                0.7412576079368591,
                0.7982293963432312,
                0.8227855563163757,
                0.8511852622032166,
                0.6925479769706726,
                0.8201246857643127,
                0.6731849312782288,
                0.8785815238952637,
                0.8585809469223022,
                0.8396372199058533,
                0.813912570476532,
                0.8229835629463196,
                0.8511852622032166,
                0.8516687750816345,
                0.8336173295974731,
                0.7884247899055481,
                0.8238901495933533,
                0.781531572341919,
                0.8233553767204285,
                0.8407160639762878,
                0.7711718082427979,
                0.7485164999961853,
                0.8407160639762878,
                0.7341704368591309,
                0.865839421749115,
                0.8178162574768066,
                0.823179304599762,
                0.7554574608802795,
                0.8481839895248413,
                0.8551852703094482,
                0.854902446269989,
                0.767969012260437,
                0.7875591516494751,
                0.8003331422805786,
                0.862377941608429,
                0.85481858253479,
                0.8173196911811829,
                0.8650327920913696,
                0.8551852703094482,
                0.7979544401168823,
                0.8202366232872009,
                0.8343654870986938,
                0.8868685364723206
            ],
            [
                0.8708955645561218,
                0.8448143005371094,
                0.7582941055297852,
                0.7722589373588562,
                0.7857472896575928,
                0.7979698181152344,
                0.7920119762420654,
                0.8553186655044556,
                0.7734575271606445,
                0.8555520176887512,
                0.8594546318054199,
                0.852687656879425,
                0.826517641544342,
                0.8070051074028015,
                0.7979698181152344,
                0.834356963634491,
                0.8797709345817566,
                0.821538507938385,
                0.8078356385231018,
                0.7657268047332764,
                0.7992452383041382,
                0.7991222739219666,
                0.8420323133468628,
                0.8019837141036987,
                0.7991222739219666,
                0.7809111475944519,
                0.8524854183197021,
                0.8579995632171631,
                0.8491562008857727,
                0.7832582592964172,
                0.8760817050933838,
                0.8332318067550659,
                0.8617310523986816,
                0.8099545836448669,
                0.8240483999252319,
                0.8404915928840637,
                0.8456709980964661,
                0.8361226320266724,
                0.8413498401641846,
                0.8776781558990479,
                0.8332318067550659,
                0.8095189929008484,
                0.8163715600967407,
                0.8575074672698975,
                0.8459192514419556
            ],
            [
                0.8320879340171814,
                0.8025105595588684,
                0.7233316898345947,
                0.8153443932533264,
                0.8241034746170044,
                0.8504490256309509,
                0.7198379635810852,
                0.8378281593322754,
                0.6909498572349548,
                0.8758544921875,
                0.8709071278572083,
                0.8223928213119507,
                0.8270773887634277,
                0.8305434584617615,
                0.8504490256309509,
                0.8260449171066284,
                0.8296688199043274,
                0.8085771203041077,
                0.8259057402610779,
                0.8072080612182617,
                0.8006579279899597,
                0.8152222037315369,
                0.7967095375061035,
                0.7637282609939575,
                0.8152222037315369,
                0.7221843004226685,
                0.8480433225631714,
                0.834711492061615,
                0.8323964476585388,
                0.7652546763420105,
                0.8646829128265381,
                0.8406827449798584,
                0.8673659563064575,
                0.7692114114761353,
                0.788860559463501,
                0.8109360337257385,
                0.8637141585350037,
                0.8478031754493713,
                0.8475726842880249,
                0.8675842881202698,
                0.8406827449798584,
                0.7862880825996399,
                0.8217090964317322,
                0.835551381111145,
                0.8574812412261963
            ],
            [
                0.7931690812110901,
                0.7509727478027344,
                0.7385030388832092,
                0.7989017963409424,
                0.7981574535369873,
                0.801157534122467,
                0.6977664828300476,
                0.77599036693573,
                0.6735464334487915,
                0.8308044075965881,
                0.8128868937492371,
                0.7807749509811401,
                0.7611701488494873,
                0.763227105140686,
                0.801157534122467,
                0.7672794461250305,
                0.7940985560417175,
                0.7413398027420044,
                0.7540863752365112,
                0.7972517013549805,
                0.7249302268028259,
                0.7854802012443542,
                0.7515869140625,
                0.7201693654060364,
                0.7854802012443542,
                0.7117980718612671,
                0.7879984974861145,
                0.7664932012557983,
                0.7665303349494934,
                0.7456709146499634,
                0.8178300857543945,
                0.7742499113082886,
                0.8007587194442749,
                0.732081413269043,
                0.7206593751907349,
                0.7412867546081543,
                0.8082126379013062,
                0.7792769074440002,
                0.7905916571617126,
                0.8182060718536377,
                0.7742499113082886,
                0.8018755912780762,
                0.7695281505584717,
                0.7957860231399536,
                0.8294989466667175
            ],
            [
                0.8767834901809692,
                0.8531469106674194,
                0.7583197355270386,
                0.7823009490966797,
                0.8033762574195862,
                0.8164206147193909,
                0.8006354570388794,
                0.8712731003761292,
                0.7797876000404358,
                0.8669525980949402,
                0.8793237805366516,
                0.86604905128479,
                0.8391785025596619,
                0.8309198021888733,
                0.8164206147193909,
                0.8593851923942566,
                0.8869694471359253,
                0.8395388126373291,
                0.8335003852844238,
                0.7873415946960449,
                0.8315748572349548,
                0.831476628780365,
                0.8503477573394775,
                0.807870090007782,
                0.831476628780365,
                0.7936824560165405,
                0.8653209209442139,
                0.8704174757003784,
                0.8650527596473694,
                0.8028402924537659,
                0.8903900384902954,
                0.8643139004707336,
                0.8776602745056152,
                0.8291362524032593,
                0.8492954969406128,
                0.8587941527366638,
                0.8541462421417236,
                0.8558785915374756,
                0.8531164526939392,
                0.8904401063919067,
                0.8643139004707336,
                0.8118681907653809,
                0.8286539316177368,
                0.8609213829040527,
                0.8535448312759399
            ],
            [
                0.7805643677711487,
                0.7672446370124817,
                0.722121000289917,
                0.7365401387214661,
                0.7488441467285156,
                0.7779958248138428,
                0.7874035835266113,
                0.8034577965736389,
                0.7508301734924316,
                0.8018976449966431,
                0.8303705453872681,
                0.8230113983154297,
                0.782011866569519,
                0.7540974617004395,
                0.7779958248138428,
                0.8092389702796936,
                0.829488217830658,
                0.774503767490387,
                0.776524007320404,
                0.7256932258605957,
                0.7863437533378601,
                0.7740575075149536,
                0.7542166709899902,
                0.7317270040512085,
                0.7740575075149536,
                0.7606187462806702,
                0.7716591358184814,
                0.7810072898864746,
                0.809954047203064,
                0.7782856822013855,
                0.8467158079147339,
                0.749376654624939,
                0.807557225227356,
                0.8256352543830872,
                0.7891328930854797,
                0.7872921228408813,
                0.7966755032539368,
                0.7631583213806152,
                0.8058192133903503,
                0.8385474681854248,
                0.749376654624939,
                0.7774143815040588,
                0.7813555002212524,
                0.7690186500549316,
                0.7651454210281372
            ],
            [
                0.8104807734489441,
                0.8204213380813599,
                0.7005776762962341,
                0.7463493943214417,
                0.7232381105422974,
                0.7512907981872559,
                0.8632375001907349,
                0.8546825051307678,
                0.8386041522026062,
                0.8056247234344482,
                0.8325220942497253,
                0.8668460845947266,
                0.8288449645042419,
                0.7718024253845215,
                0.7512907981872559,
                0.7834987044334412,
                0.8903275728225708,
                0.8305526971817017,
                0.7759649157524109,
                0.7392158508300781,
                0.7561751008033752,
                0.7313143014907837,
                0.8329583406448364,
                0.801619291305542,
                0.7313143014907837,
                0.7099725008010864,
                0.797176718711853,
                0.8154364228248596,
                0.8014082908630371,
                0.7398843169212341,
                0.848694920539856,
                0.7711654305458069,
                0.8372248411178589,
                0.7503088116645813,
                0.8141560554504395,
                0.8113857507705688,
                0.7897896766662598,
                0.7640603184700012,
                0.8084937930107117,
                0.8278060555458069,
                0.7711654305458069,
                0.7457626461982727,
                0.759502649307251,
                0.812701940536499,
                0.7797724008560181
            ],
            [
                0.7459375858306885,
                0.725098192691803,
                0.7276114821434021,
                0.7440530061721802,
                0.7396120429039001,
                0.7583810091018677,
                0.740033745765686,
                0.7734101414680481,
                0.6927618980407715,
                0.7807861566543579,
                0.7968125343322754,
                0.7815635204315186,
                0.7525690793991089,
                0.7279280424118042,
                0.7583810091018677,
                0.7535737156867981,
                0.7894408106803894,
                0.7526112794876099,
                0.7510741949081421,
                0.734842836856842,
                0.7404391765594482,
                0.747359037399292,
                0.7421068549156189,
                0.7247893214225769,
                0.747359037399292,
                0.7451589107513428,
                0.7516852617263794,
                0.7504488229751587,
                0.7690899968147278,
                0.7502878308296204,
                0.8120291233062744,
                0.7284874320030212,
                0.7833380103111267,
                0.7997974157333374,
                0.760837733745575,
                0.7663626074790955,
                0.7795878648757935,
                0.7419432401657104,
                0.7824437022209167,
                0.7955557703971863,
                0.7284874320030212,
                0.7529464364051819,
                0.7466215491294861,
                0.7454277873039246,
                0.735917329788208
            ],
            [
                0.8201687932014465,
                0.827928900718689,
                0.6497664451599121,
                0.7009904980659485,
                0.6825914978981018,
                0.7230187058448792,
                0.8619145750999451,
                0.8694468140602112,
                0.8421058654785156,
                0.7827474474906921,
                0.837149441242218,
                0.9044904708862305,
                0.8449730277061462,
                0.7509740591049194,
                0.7230187058448792,
                0.7879457473754883,
                0.9121575355529785,
                0.8554520010948181,
                0.7635844945907593,
                0.6932027339935303,
                0.7557960748672485,
                0.7076591849327087,
                0.8462021350860596,
                0.816929042339325,
                0.7076591849327087,
                0.7100380659103394,
                0.7927559614181519,
                0.8314047455787659,
                0.8201451301574707,
                0.7267080545425415,
                0.8626018762588501,
                0.7617149949073792,
                0.851227343082428,
                0.7669993042945862,
                0.8434629440307617,
                0.8203849792480469,
                0.7963472008705139,
                0.7643441557884216,
                0.8254165053367615,
                0.8361595869064331,
                0.7617149949073792,
                0.7106873989105225,
                0.7455574870109558,
                0.7969897985458374,
                0.7516323924064636
            ],
            [
                0.8897663950920105,
                0.8815406560897827,
                0.6240325570106506,
                0.7174723744392395,
                0.7263098955154419,
                0.765340268611908,
                0.7184735536575317,
                0.9304046630859375,
                0.6963229775428772,
                0.8644523024559021,
                0.9095332622528076,
                0.8604029417037964,
                0.9125508666038513,
                0.8127646446228027,
                0.765340268611908,
                0.8268607258796692,
                0.8867669105529785,
                0.922192394733429,
                0.8270156979560852,
                0.7002008557319641,
                0.825308084487915,
                0.7501540184020996,
                0.8658642172813416,
                0.85047847032547,
                0.7501540184020996,
                0.674652636051178,
                0.87418133020401,
                0.8953149318695068,
                0.8739621043205261,
                0.6924451589584351,
                0.9150049686431885,
                0.8647108674049377,
                0.9221678972244263,
                0.7628404498100281,
                0.8871104121208191,
                0.8979982137680054,
                0.8481032252311707,
                0.8527470231056213,
                0.8805081844329834,
                0.8930627107620239,
                0.8647108674049377,
                0.6900186538696289,
                0.8077348470687866,
                0.8735997676849365,
                0.8310778141021729
            ],
            [
                0.8429384231567383,
                0.8474297523498535,
                0.7274524569511414,
                0.794258713722229,
                0.8152036666870117,
                0.8160707950592041,
                0.6751318573951721,
                0.840652585029602,
                0.6587324738502502,
                0.8648045659065247,
                0.8396269083023071,
                0.7791215777397156,
                0.8239058256149292,
                0.8311305642127991,
                0.8160707950592041,
                0.8200544118881226,
                0.8360119462013245,
                0.8213324546813965,
                0.8312458992004395,
                0.7998490333557129,
                0.8156081438064575,
                0.8191022276878357,
                0.7892533540725708,
                0.7635686993598938,
                0.8191022276878357,
                0.728395402431488,
                0.856293797492981,
                0.8255013227462769,
                0.8122802376747131,
                0.7234197854995728,
                0.839095413684845,
                0.8468813300132751,
                0.848603367805481,
                0.7600323557853699,
                0.7968162298202515,
                0.8281699419021606,
                0.8306487798690796,
                0.8322956562042236,
                0.7965887784957886,
                0.8355423212051392,
                0.8468813300132751,
                0.7667481899261475,
                0.8042454719543457,
                0.8519400954246521,
                0.8237767219543457
            ],
            [
                0.7589603066444397,
                0.7626858949661255,
                0.6909441351890564,
                0.7431497573852539,
                0.7385836839675903,
                0.7710174918174744,
                0.7315358519554138,
                0.8089017868041992,
                0.706352710723877,
                0.803522527217865,
                0.7981553673744202,
                0.8233441114425659,
                0.7936846613883972,
                0.7242884039878845,
                0.7710174918174744,
                0.757972002029419,
                0.8326373100280762,
                0.7909495830535889,
                0.7509739398956299,
                0.7344019412994385,
                0.737368643283844,
                0.7421260476112366,
                0.7732142210006714,
                0.7712063789367676,
                0.7421260476112366,
                0.7255648374557495,
                0.7768691778182983,
                0.7472243309020996,
                0.7632513642311096,
                0.7199949622154236,
                0.8325821757316589,
                0.7235634326934814,
                0.8164346218109131,
                0.7817270159721375,
                0.7848103642463684,
                0.749679684638977,
                0.7901173830032349,
                0.7340945601463318,
                0.7655733227729797,
                0.8085166215896606,
                0.7235634326934814,
                0.7469906806945801,
                0.7297548651695251,
                0.7666155099868774,
                0.746296226978302
            ],
            [
                0.7883821129798889,
                0.7630747556686401,
                0.5951300263404846,
                0.6890536546707153,
                0.6727675199508667,
                0.7191393375396729,
                0.8312041759490967,
                0.8132075071334839,
                0.8530787229537964,
                0.7603602409362793,
                0.7915008664131165,
                0.8847909569740295,
                0.8007235527038574,
                0.723916232585907,
                0.7191393375396729,
                0.7632318735122681,
                0.8761483430862427,
                0.801397442817688,
                0.7364956140518188,
                0.6797714829444885,
                0.7189558148384094,
                0.6785722970962524,
                0.7865998148918152,
                0.7652009725570679,
                0.6785722970962524,
                0.6995799541473389,
                0.7569719552993774,
                0.7726385593414307,
                0.7842020988464355,
                0.6927824020385742,
                0.8112595677375793,
                0.7102094292640686,
                0.7959169745445251,
                0.7522364854812622,
                0.8065316081047058,
                0.7658373117446899,
                0.7668222784996033,
                0.7186010479927063,
                0.7693208456039429,
                0.7984588146209717,
                0.7102094292640686,
                0.6651573777198792,
                0.7005654573440552,
                0.7410616874694824,
                0.7227924466133118
            ],
            [
                0.7531017065048218,
                0.7365644574165344,
                0.6839704513549805,
                0.7655372023582458,
                0.7502787709236145,
                0.7687482237815857,
                0.726471483707428,
                0.7688118815422058,
                0.7018575072288513,
                0.7901008129119873,
                0.785190999507904,
                0.7826676368713379,
                0.7596639394760132,
                0.732465922832489,
                0.7687482237815857,
                0.7348012328147888,
                0.8027615547180176,
                0.7409627437591553,
                0.7409436106681824,
                0.786876916885376,
                0.7012907266616821,
                0.7365372776985168,
                0.7330108880996704,
                0.7040636539459229,
                0.7365372776985168,
                0.6702625155448914,
                0.7420774102210999,
                0.7373870611190796,
                0.742050290107727,
                0.7130493521690369,
                0.8102467060089111,
                0.7338494658470154,
                0.7982745170593262,
                0.7197845578193665,
                0.7225033044815063,
                0.7329435348510742,
                0.7759228944778442,
                0.7405765652656555,
                0.7705212235450745,
                0.786921501159668,
                0.7338494658470154,
                0.7497308850288391,
                0.7180702090263367,
                0.7426291108131409,
                0.7465013265609741
            ],
            [
                0.7944492697715759,
                0.8114716410636902,
                0.5873982310295105,
                0.678867757320404,
                0.6703030467033386,
                0.7227597832679749,
                0.8028042316436768,
                0.8509676456451416,
                0.7920413017272949,
                0.7704116106033325,
                0.8429843187332153,
                0.8705238699913025,
                0.8403711318969727,
                0.7361804246902466,
                0.7227597832679749,
                0.7922834157943726,
                0.8625128865242004,
                0.8461810350418091,
                0.7498262524604797,
                0.6571109294891357,
                0.755946159362793,
                0.6901810169219971,
                0.8220040798187256,
                0.7913318872451782,
                0.6901810169219971,
                0.6798655986785889,
                0.7874826788902283,
                0.8178879618644714,
                0.8107039928436279,
                0.6838167309761047,
                0.8449817299842834,
                0.7397171854972839,
                0.8283067941665649,
                0.7396556735038757,
                0.8318219780921936,
                0.8036909103393555,
                0.7737702131271362,
                0.7605587840080261,
                0.821496844291687,
                0.8365246653556824,
                0.7397171854972839,
                0.6568780541419983,
                0.7453746199607849,
                0.7902896404266357,
                0.7424070239067078
            ],
            [
                0.757419228553772,
                0.758431077003479,
                0.7100367546081543,
                0.7363836765289307,
                0.7196862697601318,
                0.7493330240249634,
                0.7586041688919067,
                0.7958107590675354,
                0.7146890759468079,
                0.778387188911438,
                0.7995677590370178,
                0.8103282451629639,
                0.7640405893325806,
                0.7130981683731079,
                0.7493330240249634,
                0.7497366070747375,
                0.8153066039085388,
                0.7610249519348145,
                0.7401177287101746,
                0.7317644953727722,
                0.7366349697113037,
                0.7496352791786194,
                0.7611092925071716,
                0.7355254888534546,
                0.7496352791786194,
                0.7270031571388245,
                0.7492486834526062,
                0.7505735754966736,
                0.7632852792739868,
                0.7305545210838318,
                0.825964629650116,
                0.7365363836288452,
                0.8018814921379089,
                0.7815959453582764,
                0.7573556900024414,
                0.7562970519065857,
                0.7814469337463379,
                0.7420103549957275,
                0.7802484631538391,
                0.7981088757514954,
                0.7365363836288452,
                0.7582148909568787,
                0.7383936643600464,
                0.7583256959915161,
                0.7408550977706909
            ],
            [
                0.7693626880645752,
                0.7420520782470703,
                0.7289055585861206,
                0.7544913291931152,
                0.7510623335838318,
                0.7743141651153564,
                0.7423576712608337,
                0.76568603515625,
                0.6868686079978943,
                0.7861066460609436,
                0.7951103448867798,
                0.7680620551109314,
                0.7308252453804016,
                0.7307515144348145,
                0.7743141651153564,
                0.7486989498138428,
                0.786907434463501,
                0.7221120595932007,
                0.740310549736023,
                0.782612681388855,
                0.727924108505249,
                0.7860614657402039,
                0.7316097021102905,
                0.6939926147460938,
                0.7860614657402039,
                0.7074371576309204,
                0.7424688339233398,
                0.7527099251747131,
                0.7586724758148193,
                0.7513368725776672,
                0.8194180130958557,
                0.7541177272796631,
                0.7942355275154114,
                0.7657854557037354,
                0.7281968593597412,
                0.7526256442070007,
                0.7838388681411743,
                0.7609068751335144,
                0.7744879126548767,
                0.7963874340057373,
                0.7541177272796631,
                0.7937292456626892,
                0.751982569694519,
                0.7511541843414307,
                0.7629714608192444
            ],
            [
                0.7109782695770264,
                0.7252090573310852,
                0.6024443507194519,
                0.6851455569267273,
                0.6358873248100281,
                0.6674580574035645,
                0.8374063968658447,
                0.7624977231025696,
                0.8328773379325867,
                0.7158321142196655,
                0.7241616249084473,
                0.8268982172012329,
                0.7590693235397339,
                0.6750677824020386,
                0.6674580574035645,
                0.6786435842514038,
                0.8154124617576599,
                0.7467495799064636,
                0.6792137026786804,
                0.6669542193412781,
                0.6472200751304626,
                0.6298032402992249,
                0.7600659728050232,
                0.7306874990463257,
                0.6298032402992249,
                0.6152389049530029,
                0.7121787071228027,
                0.7161492109298706,
                0.7149835228919983,
                0.6505205631256104,
                0.7340258359909058,
                0.6505124568939209,
                0.7409073114395142,
                0.6388042569160461,
                0.7307823896408081,
                0.6986954808235168,
                0.6921306252479553,
                0.6538077592849731,
                0.7193391919136047,
                0.7191754579544067,
                0.6505124568939209,
                0.6493089199066162,
                0.668722927570343,
                0.722835898399353,
                0.6902884244918823
            ],
            [
                0.8119833469390869,
                0.8152244687080383,
                0.6270704865455627,
                0.7035644054412842,
                0.6974454522132874,
                0.7364091277122498,
                0.8306958675384521,
                0.8383684158325195,
                0.8103337287902832,
                0.785105288028717,
                0.83808833360672,
                0.8824336528778076,
                0.8207774758338928,
                0.7433492541313171,
                0.7364091277122498,
                0.7961603999137878,
                0.8649317026138306,
                0.824694812297821,
                0.7483354210853577,
                0.6960259675979614,
                0.7479513883590698,
                0.7235815525054932,
                0.8236136436462402,
                0.7863931655883789,
                0.7235815525054932,
                0.704505443572998,
                0.7942872643470764,
                0.8137305974960327,
                0.8044831156730652,
                0.7005544304847717,
                0.8430761694908142,
                0.7447527647018433,
                0.8278443217277527,
                0.7623295783996582,
                0.8144611120223999,
                0.7886144518852234,
                0.7939802408218384,
                0.7616260051727295,
                0.811602771282196,
                0.8380529880523682,
                0.7447527647018433,
                0.7033876776695251,
                0.7523749470710754,
                0.7985408902168274,
                0.756394624710083
            ],
            [
                0.8278558850288391,
                0.7844555377960205,
                0.7521433234214783,
                0.811378538608551,
                0.8292413353919983,
                0.8342342376708984,
                0.7122305631637573,
                0.7911903262138367,
                0.6819871664047241,
                0.8550810217857361,
                0.8311285972595215,
                0.7948516607284546,
                0.7839298844337463,
                0.8056708574295044,
                0.8342342376708984,
                0.8036814332008362,
                0.8188612461090088,
                0.7619154453277588,
                0.8059167861938477,
                0.8046532273292542,
                0.7864141464233398,
                0.8294625282287598,
                0.7608533501625061,
                0.7285946011543274,
                0.8294625282287598,
                0.73097163438797,
                0.8213146924972534,
                0.7884451150894165,
                0.8021459579467773,
                0.755649209022522,
                0.8346558213233948,
                0.8232618570327759,
                0.8241433501243591,
                0.7612947225570679,
                0.7510011196136475,
                0.7825766801834106,
                0.8417437076568604,
                0.8163453936576843,
                0.7959271669387817,
                0.8317650556564331,
                0.8232618570327759,
                0.8037103414535522,
                0.7987156510353088,
                0.8250734806060791,
                0.8532592058181763
            ],
            [
                0.8985000252723694,
                0.8640424013137817,
                0.718207597732544,
                0.7487111687660217,
                0.7641736268997192,
                0.7807843685150146,
                0.8187379240989685,
                0.8783870935440063,
                0.8099923133850098,
                0.8523018956184387,
                0.8676227927207947,
                0.9026343822479248,
                0.8739396333694458,
                0.8078086972236633,
                0.7807843685150146,
                0.8408775329589844,
                0.9407666325569153,
                0.8739755153656006,
                0.8155690431594849,
                0.7544190287590027,
                0.8058426976203918,
                0.7859236598014832,
                0.8743026852607727,
                0.8444423079490662,
                0.7859236598014832,
                0.755099892616272,
                0.8566834330558777,
                0.8647010922431946,
                0.8605430126190186,
                0.7730947732925415,
                0.8939514756202698,
                0.8422086238861084,
                0.8885823488235474,
                0.8155633211135864,
                0.8668264746665955,
                0.8610440492630005,
                0.8403303623199463,
                0.8225681781768799,
                0.8484684228897095,
                0.8806501626968384,
                0.8422086238861084,
                0.7851166129112244,
                0.7962003946304321,
                0.8650819063186646,
                0.835760235786438
            ],
            [
                0.7730922102928162,
                0.7604547142982483,
                0.7442868947982788,
                0.7816651463508606,
                0.7631158232688904,
                0.7763601541519165,
                0.7297417521476746,
                0.763915479183197,
                0.7072227001190186,
                0.7928268313407898,
                0.7773278951644897,
                0.7936015129089355,
                0.7464532852172852,
                0.7390188574790955,
                0.7763601541519165,
                0.7462216019630432,
                0.8064199686050415,
                0.7316752672195435,
                0.7278532981872559,
                0.7712406516075134,
                0.7038918733596802,
                0.7613394856452942,
                0.7737503051757812,
                0.7336041927337646,
                0.7613394856452942,
                0.7208738327026367,
                0.7671071887016296,
                0.7408521175384521,
                0.7409198880195618,
                0.7348186373710632,
                0.7957421541213989,
                0.7452043294906616,
                0.7806121110916138,
                0.7278580069541931,
                0.7110008597373962,
                0.7217780947685242,
                0.7852262258529663,
                0.7451304793357849,
                0.7654268145561218,
                0.7901459336280823,
                0.7452043294906616,
                0.7861548066139221,
                0.7467091083526611,
                0.7858465909957886,
                0.7976828813552856
            ]
        ],
        [
            [
                0.8278493285179138,
                0.6964328289031982,
                0.5768061876296997,
                0.6598532199859619,
                0.7374811172485352,
                0.6915377378463745,
                0.7008843421936035,
                0.6879155039787292,
                0.6191835403442383,
                0.6842690110206604,
                0.679790198802948,
                0.726083517074585,
                0.730438232421875,
                0.7233979105949402,
                0.7374811172485352,
                0.8436626195907593,
                0.7033908367156982,
                0.7374811172485352,
                0.6600855588912964,
                0.6999161243438721,
                0.6970390677452087,
                0.6629831194877625,
                0.7165442705154419,
                0.5768061876296997,
                0.695787250995636,
                0.7927125096321106,
                0.6968111991882324,
                0.6754062175750732,
                0.7436316013336182,
                0.6833599209785461,
                0.7405462265014648,
                0.7369807958602905,
                0.7383777499198914,
                0.7436316013336182,
                0.718100905418396,
                0.6889169812202454,
                0.4714621901512146,
                0.6837331056594849,
                0.7093055844306946,
                0.7079135775566101,
                0.7123622298240662,
                0.6754062175750732,
                0.6807733178138733,
                0.732732355594635,
                0.6754062175750732,
                0.7088513970375061,
                0.7323765158653259,
                0.723464846611023,
                0.7043790221214294,
                0.7169063687324524,
                0.6541094183921814
            ],
            [
                0.8208360075950623,
                0.715856671333313,
                0.6101024746894836,
                0.6489284038543701,
                0.7263695001602173,
                0.7014828324317932,
                0.707251250743866,
                0.7074511051177979,
                0.6303755044937134,
                0.6908825039863586,
                0.6853232383728027,
                0.745625376701355,
                0.7556436657905579,
                0.7415943741798401,
                0.7263695001602173,
                0.737273097038269,
                0.6942130327224731,
                0.7263695001602173,
                0.6407088041305542,
                0.711098849773407,
                0.7039012908935547,
                0.6856178641319275,
                0.7225638628005981,
                0.6101024746894836,
                0.6934420466423035,
                0.7172721028327942,
                0.7225708365440369,
                0.6524798274040222,
                0.7206177711486816,
                0.6607224941253662,
                0.746327817440033,
                0.7610659003257751,
                0.7614971995353699,
                0.7206177711486816,
                0.6974872350692749,
                0.6982868313789368,
                0.4254973828792572,
                0.6500381827354431,
                0.7218822836875916,
                0.7164478898048401,
                0.7295848727226257,
                0.6524798274040222,
                0.678130030632019,
                0.733726441860199,
                0.6524798274040222,
                0.7407702803611755,
                0.6654718518257141,
                0.6906484365463257,
                0.6868596076965332,
                0.68140709400177,
                0.6053295135498047
            ],
            [
                0.8380129933357239,
                0.7531375885009766,
                0.5896204710006714,
                0.7030578851699829,
                0.7619152665138245,
                0.7432478666305542,
                0.743481457233429,
                0.7223522663116455,
                0.6161160469055176,
                0.7118791341781616,
                0.7202807664871216,
                0.770067036151886,
                0.7647413611412048,
                0.7561870217323303,
                0.7619152665138245,
                0.8257817029953003,
                0.7296707034111023,
                0.7619152665138245,
                0.6647648811340332,
                0.7260618209838867,
                0.7262275815010071,
                0.709092915058136,
                0.7592130303382874,
                0.5896204710006714,
                0.7205089330673218,
                0.7697871923446655,
                0.7532563805580139,
                0.6713137030601501,
                0.76484215259552,
                0.6817535758018494,
                0.7791376709938049,
                0.7704728841781616,
                0.7785916924476624,
                0.76484215259552,
                0.7441917061805725,
                0.7230369448661804,
                0.49099236726760864,
                0.7085054516792297,
                0.7411328554153442,
                0.7424107789993286,
                0.7622683644294739,
                0.6713137030601501,
                0.7233872413635254,
                0.7845261693000793,
                0.6713137030601501,
                0.7466974258422852,
                0.7269214391708374,
                0.7326580286026001,
                0.7118099927902222,
                0.7298323512077332,
                0.6357358694076538
            ],
            [
                0.8993334770202637,
                0.7852991223335266,
                0.571223258972168,
                0.7942628860473633,
                0.8177561163902283,
                0.7652303576469421,
                0.7862762808799744,
                0.7576385736465454,
                0.6295495629310608,
                0.764705240726471,
                0.7375631332397461,
                0.7977789044380188,
                0.8353051543235779,
                0.7890964150428772,
                0.8177561163902283,
                0.7707103490829468,
                0.7463555932044983,
                0.8177561163902283,
                0.7130419015884399,
                0.7902922630310059,
                0.8012844324111938,
                0.7393494248390198,
                0.7549641132354736,
                0.571223258972168,
                0.7576180696487427,
                0.8186320066452026,
                0.7977105975151062,
                0.708960771560669,
                0.8284660577774048,
                0.7178557515144348,
                0.8151806592941284,
                0.8417336940765381,
                0.8186436295509338,
                0.8284660577774048,
                0.783304750919342,
                0.7478407025337219,
                0.4850233197212219,
                0.7603189945220947,
                0.8041254281997681,
                0.8137598037719727,
                0.8089478611946106,
                0.708960771560669,
                0.7613834142684937,
                0.7874441742897034,
                0.708960771560669,
                0.7490313053131104,
                0.8258583545684814,
                0.79013991355896,
                0.7479788661003113,
                0.780167818069458,
                0.7401243448257446
            ],
            [
                0.9139381647109985,
                0.8821195960044861,
                0.6262695789337158,
                0.7829541563987732,
                0.8711367845535278,
                0.8526414036750793,
                0.881115198135376,
                0.8704748749732971,
                0.7062555551528931,
                0.8699129819869995,
                0.8320093750953674,
                0.8734480142593384,
                0.8956767916679382,
                0.8601893186569214,
                0.8711367845535278,
                0.7399560213088989,
                0.8325909972190857,
                0.8711367845535278,
                0.8324817419052124,
                0.8888357877731323,
                0.8974837064743042,
                0.8159742951393127,
                0.8187837600708008,
                0.6262695789337158,
                0.8655445575714111,
                0.8321059346199036,
                0.8855839371681213,
                0.8334498405456543,
                0.8927934169769287,
                0.8169844746589661,
                0.8917647004127502,
                0.8985899686813354,
                0.8752945065498352,
                0.8927934169769287,
                0.8786841034889221,
                0.8472464680671692,
                0.5840659737586975,
                0.8575991988182068,
                0.8893877863883972,
                0.8968993425369263,
                0.8701733350753784,
                0.8334498405456543,
                0.8646566867828369,
                0.851945698261261,
                0.8334498405456543,
                0.8318994641304016,
                0.8070354461669922,
                0.817380428314209,
                0.8005001544952393,
                0.8363636136054993,
                0.8050428032875061
            ],
            [
                0.90567547082901,
                0.8744689226150513,
                0.6488487124443054,
                0.7238919734954834,
                0.8184973001480103,
                0.8166607618331909,
                0.8276475071907043,
                0.8084157705307007,
                0.7174745202064514,
                0.8118889331817627,
                0.7858610153198242,
                0.8455680012702942,
                0.8473873734474182,
                0.8227711319923401,
                0.8184973001480103,
                0.7703386545181274,
                0.7896540760993958,
                0.8184973001480103,
                0.7609063386917114,
                0.8296215534210205,
                0.8322235345840454,
                0.7695026993751526,
                0.7975425124168396,
                0.6488487124443054,
                0.8016591668128967,
                0.7660170197486877,
                0.882577657699585,
                0.8014757037162781,
                0.8391838073730469,
                0.8069363236427307,
                0.8649716973304749,
                0.8586879968643188,
                0.8592671751976013,
                0.8391838073730469,
                0.8281118869781494,
                0.8262065649032593,
                0.5369717478752136,
                0.803851306438446,
                0.8499613404273987,
                0.8543910980224609,
                0.8510161638259888,
                0.8014757037162781,
                0.8320608139038086,
                0.8380284905433655,
                0.8014757037162781,
                0.8038686513900757,
                0.7600764036178589,
                0.7980772852897644,
                0.7771890163421631,
                0.8170428276062012,
                0.7212287783622742
            ],
            [
                0.7615557909011841,
                0.7176350951194763,
                0.6134354472160339,
                0.692503809928894,
                0.7459443211555481,
                0.7336756587028503,
                0.7297425270080566,
                0.7032806277275085,
                0.6425575613975525,
                0.6940757632255554,
                0.6951465606689453,
                0.7343892455101013,
                0.7387980222702026,
                0.7202799916267395,
                0.7459443211555481,
                0.8563425540924072,
                0.7387126684188843,
                0.7459443211555481,
                0.6937229633331299,
                0.6920883059501648,
                0.6920291185379028,
                0.685931921005249,
                0.7285329699516296,
                0.6134354472160339,
                0.7139348983764648,
                0.7622780203819275,
                0.7245352268218994,
                0.720368504524231,
                0.7610737085342407,
                0.7150446772575378,
                0.7606330513954163,
                0.7513535022735596,
                0.7571659088134766,
                0.7610737085342407,
                0.7644234895706177,
                0.7255033850669861,
                0.5600064396858215,
                0.7352473735809326,
                0.7214438915252686,
                0.7221946120262146,
                0.757191002368927,
                0.720368504524231,
                0.7215023636817932,
                0.7533538341522217,
                0.720368504524231,
                0.7354024052619934,
                0.7297214269638062,
                0.7209631204605103,
                0.6939383745193481,
                0.7550232410430908,
                0.6249814629554749
            ],
            [
                0.8994580507278442,
                0.8194851875305176,
                0.6248580813407898,
                0.7399832606315613,
                0.8499469757080078,
                0.8466505408287048,
                0.8523758053779602,
                0.8386973142623901,
                0.690987765789032,
                0.8524112105369568,
                0.8124982714653015,
                0.8716533780097961,
                0.8754593729972839,
                0.8548066020011902,
                0.8499469757080078,
                0.771511435508728,
                0.8337891101837158,
                0.8499469757080078,
                0.8184850215911865,
                0.8499992489814758,
                0.8522535562515259,
                0.7972092628479004,
                0.8293924331665039,
                0.6248580813407898,
                0.846215009689331,
                0.8241816163063049,
                0.8253645300865173,
                0.7937645316123962,
                0.8624359369277954,
                0.786355197429657,
                0.8821355700492859,
                0.8828983902931213,
                0.8683748841285706,
                0.8624359369277954,
                0.8545107245445251,
                0.8486387133598328,
                0.5501092076301575,
                0.8323718309402466,
                0.8560919761657715,
                0.8581775426864624,
                0.8492003679275513,
                0.7937645316123962,
                0.8315418362617493,
                0.8476959466934204,
                0.7937645316123962,
                0.8385968804359436,
                0.8120920658111572,
                0.856233537197113,
                0.8355036973953247,
                0.8439958691596985,
                0.76447993516922
            ],
            [
                0.8991151452064514,
                0.8726757764816284,
                0.6223845481872559,
                0.7710519433021545,
                0.8831337094306946,
                0.8811946511268616,
                0.9016854763031006,
                0.8797886967658997,
                0.6945294141769409,
                0.8814258575439453,
                0.8603184223175049,
                0.8865931630134583,
                0.8874039649963379,
                0.8699048161506653,
                0.8831337094306946,
                0.7800315022468567,
                0.8777236938476562,
                0.8831337094306946,
                0.8462105393409729,
                0.8823069930076599,
                0.896760880947113,
                0.8313732147216797,
                0.8543670773506165,
                0.6223845481872559,
                0.8992013931274414,
                0.8349829912185669,
                0.874177098274231,
                0.8299319744110107,
                0.9019696712493896,
                0.8081743121147156,
                0.9028385877609253,
                0.8952932357788086,
                0.8853549957275391,
                0.9019696712493896,
                0.9105154275894165,
                0.8711277842521667,
                0.6002087593078613,
                0.8865684270858765,
                0.8892784118652344,
                0.9038891792297363,
                0.8870872259140015,
                0.8299319744110107,
                0.8695515394210815,
                0.8880553841590881,
                0.8299319744110107,
                0.86411452293396,
                0.8263745903968811,
                0.8660451173782349,
                0.8349864482879639,
                0.8628067374229431,
                0.783505916595459
            ],
            [
                0.8244101405143738,
                0.7687608599662781,
                0.624858558177948,
                0.6831520199775696,
                0.8016423583030701,
                0.8339765071868896,
                0.8268136382102966,
                0.7925281524658203,
                0.6755518317222595,
                0.7907814383506775,
                0.7792434096336365,
                0.8321837782859802,
                0.8016602396965027,
                0.8190326690673828,
                0.8016423583030701,
                0.7401694059371948,
                0.8064891695976257,
                0.8016423583030701,
                0.7573408484458923,
                0.7751718759536743,
                0.7728457450866699,
                0.768048107624054,
                0.8239322900772095,
                0.624858558177948,
                0.8108169436454773,
                0.7428315281867981,
                0.768034040927887,
                0.7222840785980225,
                0.7960322499275208,
                0.7210017442703247,
                0.8244861364364624,
                0.8071411848068237,
                0.8244646787643433,
                0.7960322499275208,
                0.799748420715332,
                0.7835853695869446,
                0.5099689960479736,
                0.7705711126327515,
                0.7784302830696106,
                0.7756938934326172,
                0.792195737361908,
                0.7222840785980225,
                0.7560170292854309,
                0.8358825445175171,
                0.7222840785980225,
                0.8080955743789673,
                0.7407317757606506,
                0.7701714634895325,
                0.7624897360801697,
                0.7611380815505981,
                0.6731173396110535
            ],
            [
                0.8404849171638489,
                0.7646521329879761,
                0.6159816384315491,
                0.6815049052238464,
                0.7714598774909973,
                0.7736940979957581,
                0.7599401473999023,
                0.7349762320518494,
                0.6358811259269714,
                0.7194738388061523,
                0.7299627661705017,
                0.7857687473297119,
                0.8021568059921265,
                0.7822138667106628,
                0.7714598774909973,
                0.7851338386535645,
                0.7556509375572205,
                0.7714598774909973,
                0.6870145797729492,
                0.7421833276748657,
                0.7323870062828064,
                0.7424154281616211,
                0.7872054576873779,
                0.6159816384315491,
                0.7422774434089661,
                0.744053304195404,
                0.7610572576522827,
                0.671301543712616,
                0.7658098340034485,
                0.6858454346656799,
                0.7864165902137756,
                0.8088919520378113,
                0.8029800057411194,
                0.7658098340034485,
                0.7572605609893799,
                0.7469117641448975,
                0.503892719745636,
                0.7254481911659241,
                0.7566983699798584,
                0.7483830451965332,
                0.7820433974266052,
                0.671301543712616,
                0.7324702739715576,
                0.80685955286026,
                0.671301543712616,
                0.7679864764213562,
                0.6929240226745605,
                0.7354866862297058,
                0.7001880407333374,
                0.7205210328102112,
                0.6189610958099365
            ],
            [
                0.8658567667007446,
                0.8424907326698303,
                0.6206487417221069,
                0.7569307088851929,
                0.8540284037590027,
                0.8723205924034119,
                0.8808164596557617,
                0.8585233688354492,
                0.7190502285957336,
                0.8727660179138184,
                0.8324350118637085,
                0.8788204789161682,
                0.8601403832435608,
                0.8512227535247803,
                0.8540284037590027,
                0.7466285228729248,
                0.8252773284912109,
                0.8540284037590027,
                0.827883243560791,
                0.8611022233963013,
                0.8602358102798462,
                0.7925142645835876,
                0.8240165114402771,
                0.6206487417221069,
                0.8565067648887634,
                0.8148406744003296,
                0.8437063097953796,
                0.8181466460227966,
                0.8681008815765381,
                0.8090147972106934,
                0.8860870003700256,
                0.8646954894065857,
                0.8611447215080261,
                0.8681008815765381,
                0.8555297255516052,
                0.8504740595817566,
                0.5754059553146362,
                0.8466026782989502,
                0.859620213508606,
                0.8578014373779297,
                0.8404521942138672,
                0.8181466460227966,
                0.8421337604522705,
                0.851542055606842,
                0.8181466460227966,
                0.8214620351791382,
                0.8101352453231812,
                0.8233270645141602,
                0.8223415017127991,
                0.831538736820221,
                0.8005878925323486
            ],
            [
                0.874830961227417,
                0.7724609971046448,
                0.6034803986549377,
                0.7279655933380127,
                0.8391151428222656,
                0.822889506816864,
                0.8160221576690674,
                0.7889240384101868,
                0.6438477635383606,
                0.7942004203796387,
                0.7855490446090698,
                0.8328056931495667,
                0.8320210576057434,
                0.822288990020752,
                0.8391151428222656,
                0.8029423356056213,
                0.8189131617546082,
                0.8391151428222656,
                0.7533570528030396,
                0.7957358360290527,
                0.7908679842948914,
                0.7792582511901855,
                0.8263580203056335,
                0.6034803986549377,
                0.810623288154602,
                0.8137574195861816,
                0.7738876342773438,
                0.7127747535705566,
                0.8390750885009766,
                0.7130656242370605,
                0.8371453881263733,
                0.8431383967399597,
                0.8388863205909729,
                0.8390750885009766,
                0.8201504945755005,
                0.8017115592956543,
                0.5351539254188538,
                0.796981155872345,
                0.8075511455535889,
                0.8005610108375549,
                0.8226576447486877,
                0.7127747535705566,
                0.7674118280410767,
                0.8431148529052734,
                0.7127747535705566,
                0.805651843547821,
                0.8186691999435425,
                0.8420363664627075,
                0.8010340332984924,
                0.8116403818130493,
                0.6871885657310486
            ],
            [
                0.9044764637947083,
                0.8430439829826355,
                0.6259486675262451,
                0.7413334250450134,
                0.8737109899520874,
                0.8567354679107666,
                0.86780846118927,
                0.8325167894363403,
                0.67408686876297,
                0.8242626786231995,
                0.8210405111312866,
                0.8695811033248901,
                0.8973760008811951,
                0.8771553039550781,
                0.8737109899520874,
                0.7801833152770996,
                0.8674793243408203,
                0.8737109899520874,
                0.7977029085159302,
                0.8615147471427917,
                0.8671162724494934,
                0.8471055030822754,
                0.8569296002388,
                0.6259486675262451,
                0.8676393032073975,
                0.8248901963233948,
                0.8511262536048889,
                0.7637125849723816,
                0.8801910877227783,
                0.758440375328064,
                0.8795694708824158,
                0.9039211869239807,
                0.8965556621551514,
                0.8801910877227783,
                0.8803367614746094,
                0.84117192029953,
                0.5719228982925415,
                0.8498764634132385,
                0.8722810745239258,
                0.8770581483840942,
                0.8901945948600769,
                0.7637125849723816,
                0.8184859156608582,
                0.8782157301902771,
                0.7637125849723816,
                0.8597871661186218,
                0.7991283535957336,
                0.8567728400230408,
                0.8000614047050476,
                0.8374439477920532,
                0.725935161113739
            ],
            [
                0.8542368412017822,
                0.850900411605835,
                0.6478863954544067,
                0.7586610317230225,
                0.811174750328064,
                0.8291820883750916,
                0.848612904548645,
                0.8277233242988586,
                0.7262327075004578,
                0.8450406193733215,
                0.7933411002159119,
                0.8653540015220642,
                0.8563823699951172,
                0.8256275653839111,
                0.811174750328064,
                0.7254514098167419,
                0.7898035645484924,
                0.811174750328064,
                0.7968475222587585,
                0.8427121639251709,
                0.8422319293022156,
                0.7831119894981384,
                0.7752515077590942,
                0.6478863954544067,
                0.8094510436058044,
                0.8016188144683838,
                0.8632795810699463,
                0.8203098773956299,
                0.826362669467926,
                0.8181474804878235,
                0.8735364675521851,
                0.8566350936889648,
                0.8402965068817139,
                0.826362669467926,
                0.8303185701370239,
                0.8144212961196899,
                0.5662986040115356,
                0.8042648434638977,
                0.8472906351089478,
                0.8498265743255615,
                0.8355714678764343,
                0.8203098773956299,
                0.8501453399658203,
                0.7997190952301025,
                0.8203098773956299,
                0.824755847454071,
                0.7506741881370544,
                0.7884306311607361,
                0.7847689986228943,
                0.7956814169883728,
                0.7724427580833435
            ],
            [
                0.730889618396759,
                0.7087643146514893,
                0.6550731062889099,
                0.6994410753250122,
                0.7568929195404053,
                0.7537996172904968,
                0.7474610805511475,
                0.7242922186851501,
                0.6721060872077942,
                0.694978654384613,
                0.7209732532501221,
                0.7473425269126892,
                0.723718523979187,
                0.7418258786201477,
                0.7568929195404053,
                0.7541067600250244,
                0.7607858777046204,
                0.7568929195404053,
                0.6911929249763489,
                0.6858868598937988,
                0.6899988651275635,
                0.7430990934371948,
                0.7644023895263672,
                0.6550731062889099,
                0.7361363768577576,
                0.7174484729766846,
                0.7077281475067139,
                0.6809854507446289,
                0.7432411313056946,
                0.6881742477416992,
                0.7406575679779053,
                0.7258221507072449,
                0.7482444047927856,
                0.7432411313056946,
                0.7491349577903748,
                0.7073151469230652,
                0.5851593017578125,
                0.7322732210159302,
                0.6953543424606323,
                0.6967787742614746,
                0.7487732768058777,
                0.6809854507446289,
                0.6841675639152527,
                0.7699540257453918,
                0.6809854507446289,
                0.7418636679649353,
                0.7324097156524658,
                0.7092797160148621,
                0.7069603204727173,
                0.7287343144416809,
                0.6082258224487305
            ],
            [
                0.7482914328575134,
                0.7060006260871887,
                0.5952619314193726,
                0.673948347568512,
                0.7537034749984741,
                0.7440555095672607,
                0.7303259372711182,
                0.7095996141433716,
                0.6184151768684387,
                0.6823847889900208,
                0.7256109714508057,
                0.7488429546356201,
                0.7333236336708069,
                0.7299799919128418,
                0.7537034749984741,
                0.781975269317627,
                0.7328435778617859,
                0.7537034749984741,
                0.6468533277511597,
                0.6844832897186279,
                0.6805379390716553,
                0.7044987678527832,
                0.7436899542808533,
                0.5952619314193726,
                0.7122082114219666,
                0.7132383584976196,
                0.6989835500717163,
                0.6355917453765869,
                0.7443739771842957,
                0.6464534401893616,
                0.7458705902099609,
                0.7383170127868652,
                0.7470242977142334,
                0.7443739771842957,
                0.7279009819030762,
                0.7099300622940063,
                0.5471429228782654,
                0.7093855738639832,
                0.6970545649528503,
                0.6919152140617371,
                0.733605682849884,
                0.6355917453765869,
                0.6898530125617981,
                0.7619292140007019,
                0.6355917453765869,
                0.7443170547485352,
                0.6904067993164062,
                0.7201340794563293,
                0.6820679903030396,
                0.715257465839386,
                0.5830150842666626
            ],
            [
                0.8432857990264893,
                0.8400698304176331,
                0.6709591150283813,
                0.758155882358551,
                0.8028725385665894,
                0.8337758183479309,
                0.8330897688865662,
                0.8179746270179749,
                0.7363471388816833,
                0.8309251666069031,
                0.7863821387290955,
                0.8588419556617737,
                0.84840989112854,
                0.8189786672592163,
                0.8028725385665894,
                0.7294279932975769,
                0.7875872850418091,
                0.8028725385665894,
                0.7915287017822266,
                0.8471280932426453,
                0.8241496682167053,
                0.797936201095581,
                0.7862114906311035,
                0.6709591150283813,
                0.8006677031517029,
                0.7961671948432922,
                0.8499758243560791,
                0.8102302551269531,
                0.8129155039787292,
                0.8132734298706055,
                0.8643087148666382,
                0.8482746481895447,
                0.8346456289291382,
                0.8129155039787292,
                0.8178357481956482,
                0.8102326393127441,
                0.5716482400894165,
                0.793116569519043,
                0.8520364165306091,
                0.8319292068481445,
                0.8424234390258789,
                0.8102302551269531,
                0.8427066206932068,
                0.8040104508399963,
                0.8102302551269531,
                0.8102925419807434,
                0.7475823163986206,
                0.7741208076477051,
                0.788909912109375,
                0.7885386347770691,
                0.7581503391265869
            ],
            [
                0.7447701096534729,
                0.7324513792991638,
                0.6830801367759705,
                0.7131491899490356,
                0.7952497601509094,
                0.8011835813522339,
                0.7749179601669312,
                0.7681756019592285,
                0.7086302638053894,
                0.7384883165359497,
                0.7627342343330383,
                0.7782381176948547,
                0.7524310946464539,
                0.7881354093551636,
                0.7952497601509094,
                0.7348132133483887,
                0.8022595643997192,
                0.7952497601509094,
                0.7573104500770569,
                0.7466045022010803,
                0.7228626012802124,
                0.7964767813682556,
                0.82048100233078,
                0.6830801367759705,
                0.7849893569946289,
                0.7642226219177246,
                0.7307507991790771,
                0.7239081859588623,
                0.7780120968818665,
                0.727656364440918,
                0.7716990113258362,
                0.7556475400924683,
                0.7908744812011719,
                0.7780120968818665,
                0.7790072560310364,
                0.7747081518173218,
                0.6163614392280579,
                0.776818573474884,
                0.7540470957756042,
                0.7264246344566345,
                0.7962729930877686,
                0.7239081859588623,
                0.7199414968490601,
                0.8100408315658569,
                0.7239081859588623,
                0.7630726099014282,
                0.7791663408279419,
                0.7457659244537354,
                0.7660263180732727,
                0.7738469839096069,
                0.6426493525505066
            ],
            [
                0.8250014185905457,
                0.777225136756897,
                0.6501815915107727,
                0.7416864633560181,
                0.8412806987762451,
                0.8359558582305908,
                0.8140809535980225,
                0.7915597558021545,
                0.6756615042686462,
                0.783166229724884,
                0.777237594127655,
                0.8394787311553955,
                0.8260113000869751,
                0.8150074481964111,
                0.8412806987762451,
                0.7933146357536316,
                0.7977685332298279,
                0.8412806987762451,
                0.7414655685424805,
                0.7980067729949951,
                0.772119402885437,
                0.8046914339065552,
                0.814005970954895,
                0.6501815915107727,
                0.7896084785461426,
                0.7945026755332947,
                0.784583330154419,
                0.7241413593292236,
                0.8329458236694336,
                0.7269396185874939,
                0.8384942412376404,
                0.8330793380737305,
                0.8344165682792664,
                0.8329458236694336,
                0.7987019419670105,
                0.7839320302009583,
                0.5561078786849976,
                0.7794288396835327,
                0.8094825148582458,
                0.7814354300498962,
                0.835106372833252,
                0.7241413593292236,
                0.7663767337799072,
                0.8238581418991089,
                0.7241413593292236,
                0.8033879399299622,
                0.7712419033050537,
                0.7985094785690308,
                0.7687092423439026,
                0.7920790910720825,
                0.6725562810897827
            ],
            [
                0.7814987897872925,
                0.7734248638153076,
                0.6761166453361511,
                0.7653148770332336,
                0.8367611765861511,
                0.7968499660491943,
                0.817559540271759,
                0.7941750884056091,
                0.7355349063873291,
                0.788706362247467,
                0.7854033708572388,
                0.820698618888855,
                0.7945101261138916,
                0.8082021474838257,
                0.8367611765861511,
                0.7408206462860107,
                0.8080722093582153,
                0.8367611765861511,
                0.7624531388282776,
                0.7507543563842773,
                0.7587318420410156,
                0.7891109585762024,
                0.7888614535331726,
                0.6761166453361511,
                0.8050274848937988,
                0.8168624043464661,
                0.7740825414657593,
                0.7659239172935486,
                0.8277170062065125,
                0.7741103172302246,
                0.8168099522590637,
                0.7986048460006714,
                0.8123674392700195,
                0.8277170062065125,
                0.8069256544113159,
                0.7876383066177368,
                0.6169683337211609,
                0.8054524660110474,
                0.7597567439079285,
                0.7640062570571899,
                0.8085566163063049,
                0.7659239172935486,
                0.7594696283340454,
                0.8018880486488342,
                0.7659239172935486,
                0.765427827835083,
                0.8285682201385498,
                0.7832295894622803,
                0.7775031328201294,
                0.7989345192909241,
                0.7012084722518921
            ],
            [
                0.8563809990882874,
                0.7841879725456238,
                0.6365326046943665,
                0.7575955986976624,
                0.8522669076919556,
                0.822364866733551,
                0.826764702796936,
                0.809769868850708,
                0.6676360368728638,
                0.7993771433830261,
                0.7948776483535767,
                0.8488991856575012,
                0.854385495185852,
                0.8353960514068604,
                0.8522669076919556,
                0.8071913719177246,
                0.802808403968811,
                0.8522669076919556,
                0.754946768283844,
                0.8032286167144775,
                0.7944923639297485,
                0.7975091934204102,
                0.8159654140472412,
                0.6365326046943665,
                0.8070950508117676,
                0.8277292847633362,
                0.7890698909759521,
                0.7375909686088562,
                0.8466877937316895,
                0.7352112531661987,
                0.8491254448890686,
                0.8584383726119995,
                0.8489786386489868,
                0.8466877937316895,
                0.8087772727012634,
                0.801852822303772,
                0.5516485571861267,
                0.7909742593765259,
                0.8115615248680115,
                0.8018531203269958,
                0.8319864273071289,
                0.7375909686088562,
                0.7801124453544617,
                0.8285475969314575,
                0.7375909686088562,
                0.8122093677520752,
                0.7836549282073975,
                0.8036096096038818,
                0.7692170739173889,
                0.7934562563896179,
                0.6999213695526123
            ],
            [
                0.7403163909912109,
                0.7463266849517822,
                0.668135404586792,
                0.7245573997497559,
                0.7967533469200134,
                0.7802453637123108,
                0.7787274718284607,
                0.7690383195877075,
                0.705283522605896,
                0.7377058267593384,
                0.7676064968109131,
                0.7759785056114197,
                0.7508834600448608,
                0.7846492528915405,
                0.7967533469200134,
                0.7093491554260254,
                0.8122529983520508,
                0.7967533469200134,
                0.7478379011154175,
                0.7175452709197998,
                0.7394886612892151,
                0.7906277179718018,
                0.7994045615196228,
                0.668135404586792,
                0.7951766848564148,
                0.759547770023346,
                0.7385200262069702,
                0.7233759164810181,
                0.7798683643341064,
                0.729546844959259,
                0.767615556716919,
                0.7533323168754578,
                0.7822390198707581,
                0.7798683643341064,
                0.7921572923660278,
                0.7692884206771851,
                0.6318644881248474,
                0.7873555421829224,
                0.7231258153915405,
                0.7416799664497375,
                0.7889608144760132,
                0.7233759164810181,
                0.7272617220878601,
                0.803331732749939,
                0.7233759164810181,
                0.7543177008628845,
                0.7865188717842102,
                0.7460200786590576,
                0.746234118938446,
                0.7718377113342285,
                0.6395748853683472
            ],
            [
                0.8228033185005188,
                0.7993488907814026,
                0.6277024745941162,
                0.7605121731758118,
                0.8180605173110962,
                0.8056914806365967,
                0.8023421764373779,
                0.7942776679992676,
                0.665259063243866,
                0.7695811986923218,
                0.802898108959198,
                0.8235771656036377,
                0.8130418062210083,
                0.80620276927948,
                0.8180605173110962,
                0.7850664258003235,
                0.7978867888450623,
                0.8180605173110962,
                0.7241461873054504,
                0.7736000418663025,
                0.7848345041275024,
                0.7876100540161133,
                0.8095079660415649,
                0.6277024745941162,
                0.7911701798439026,
                0.7932769656181335,
                0.786698579788208,
                0.7073171734809875,
                0.8085477948188782,
                0.7143511772155762,
                0.8185731768608093,
                0.814882755279541,
                0.8115389943122864,
                0.8085477948188782,
                0.8010470271110535,
                0.7823629379272461,
                0.5851368308067322,
                0.7755096554756165,
                0.7748096585273743,
                0.7867214679718018,
                0.8045402765274048,
                0.7073171734809875,
                0.775775134563446,
                0.827470064163208,
                0.7073171734809875,
                0.7955159544944763,
                0.7523189783096313,
                0.7683626413345337,
                0.7385342121124268,
                0.7656780481338501,
                0.656390905380249
            ],
            [
                0.8521484732627869,
                0.8720224499702454,
                0.6540482044219971,
                0.7767497301101685,
                0.8912414908409119,
                0.8752287030220032,
                0.8808026313781738,
                0.8708086609840393,
                0.7384947538375854,
                0.8585212230682373,
                0.8447745442390442,
                0.8782455921173096,
                0.872215211391449,
                0.8598757386207581,
                0.8912414908409119,
                0.7674059271812439,
                0.8667217493057251,
                0.8912414908409119,
                0.8356922268867493,
                0.8633766174316406,
                0.8675130605697632,
                0.8330215811729431,
                0.8353128433227539,
                0.6540482044219971,
                0.8711444139480591,
                0.8172928094863892,
                0.8739180564880371,
                0.8328037858009338,
                0.9015453457832336,
                0.828970193862915,
                0.888815701007843,
                0.8776928186416626,
                0.8761731386184692,
                0.9015453457832336,
                0.8985759019851685,
                0.8558130264282227,
                0.6387171149253845,
                0.8844609260559082,
                0.8680785298347473,
                0.8714803457260132,
                0.8811453580856323,
                0.8328037858009338,
                0.8646030426025391,
                0.8702738285064697,
                0.8328037858009338,
                0.8284397125244141,
                0.83266282081604,
                0.838740348815918,
                0.8137912750244141,
                0.8634636402130127,
                0.7778334021568298
            ],
            [
                0.8028461337089539,
                0.781803548336029,
                0.6812951564788818,
                0.726432740688324,
                0.8207270503044128,
                0.8143227100372314,
                0.8076708912849426,
                0.8043705224990845,
                0.7332895398139954,
                0.7728176712989807,
                0.7862896919250488,
                0.819364607334137,
                0.8029111623764038,
                0.8092397451400757,
                0.8207270503044128,
                0.8119235634803772,
                0.8126847743988037,
                0.8207270503044128,
                0.7530249953269958,
                0.7678329944610596,
                0.7673987150192261,
                0.7781414985656738,
                0.8049939870834351,
                0.6812951564788818,
                0.7987165451049805,
                0.779059886932373,
                0.7785914540290833,
                0.7586319446563721,
                0.8132808804512024,
                0.7669943571090698,
                0.817530632019043,
                0.8070369362831116,
                0.8168854713439941,
                0.8132808804512024,
                0.8170364499092102,
                0.7903458476066589,
                0.6162554025650024,
                0.7951546907424927,
                0.7724121809005737,
                0.7698962688446045,
                0.7999417781829834,
                0.7586319446563721,
                0.7769665122032166,
                0.8234766125679016,
                0.7586319446563721,
                0.7730777263641357,
                0.77479487657547,
                0.7551299929618835,
                0.7597943544387817,
                0.7923006415367126,
                0.6859374046325684
            ],
            [
                0.8131771683692932,
                0.8167640566825867,
                0.6756594181060791,
                0.7280864715576172,
                0.8027113080024719,
                0.8063216805458069,
                0.817142128944397,
                0.8029142618179321,
                0.7286540269851685,
                0.7721360921859741,
                0.7795034646987915,
                0.8117058873176575,
                0.7941099405288696,
                0.7975358963012695,
                0.8027113080024719,
                0.7909207940101624,
                0.828612208366394,
                0.8027113080024719,
                0.7633664608001709,
                0.779548704624176,
                0.7875672578811646,
                0.7883914113044739,
                0.7924911379814148,
                0.6756594181060791,
                0.8216493725776672,
                0.7746690511703491,
                0.8127126693725586,
                0.7873106002807617,
                0.8058438301086426,
                0.7801885008811951,
                0.8174028992652893,
                0.7978729009628296,
                0.8071990013122559,
                0.8058438301086426,
                0.843397855758667,
                0.783093273639679,
                0.6059143543243408,
                0.7977999448776245,
                0.7858143448829651,
                0.7947133779525757,
                0.8120344281196594,
                0.7873106002807617,
                0.8014577627182007,
                0.8245688676834106,
                0.7873106002807617,
                0.7865647673606873,
                0.7525898814201355,
                0.7425491213798523,
                0.7589646577835083,
                0.7912925481796265,
                0.7026392221450806
            ],
            [
                0.8725938200950623,
                0.8108375072479248,
                0.6393753290176392,
                0.7447354197502136,
                0.8360392451286316,
                0.831939697265625,
                0.8290075063705444,
                0.8158999681472778,
                0.6941301226615906,
                0.8007823824882507,
                0.7961456775665283,
                0.849470853805542,
                0.8448501825332642,
                0.8337567448616028,
                0.8360392451286316,
                0.8732037544250488,
                0.8318607807159424,
                0.8360392451286316,
                0.7770018577575684,
                0.81980299949646,
                0.8117311596870422,
                0.7932360768318176,
                0.822754442691803,
                0.6393753290176392,
                0.8221176862716675,
                0.8332859873771667,
                0.8158297538757324,
                0.7726848125457764,
                0.8419598937034607,
                0.7741754055023193,
                0.8593792915344238,
                0.851006031036377,
                0.8517599105834961,
                0.8419598937034607,
                0.8513580560684204,
                0.8098087906837463,
                0.5787484645843506,
                0.8128020167350769,
                0.8309452533721924,
                0.8231704831123352,
                0.8461021780967712,
                0.7726848125457764,
                0.8201324343681335,
                0.848037600517273,
                0.7726848125457764,
                0.813020646572113,
                0.8009578585624695,
                0.8094741702079773,
                0.7866959571838379,
                0.8187679052352905,
                0.731479287147522
            ],
            [
                0.8350498676300049,
                0.8208637237548828,
                0.672573447227478,
                0.719481885433197,
                0.8253771662712097,
                0.8589603900909424,
                0.854965329170227,
                0.8458994626998901,
                0.7620241045951843,
                0.846757173538208,
                0.8111224174499512,
                0.8606570363044739,
                0.8316609263420105,
                0.8345520496368408,
                0.8253771662712097,
                0.7261995077133179,
                0.8127586841583252,
                0.8253771662712097,
                0.8168233036994934,
                0.8330891132354736,
                0.8260025978088379,
                0.775071382522583,
                0.815753698348999,
                0.672573447227478,
                0.8289575576782227,
                0.7682063579559326,
                0.8226180076599121,
                0.8280412554740906,
                0.8364667892456055,
                0.8283860683441162,
                0.8642194867134094,
                0.835033655166626,
                0.8467413187026978,
                0.8364667892456055,
                0.8357012271881104,
                0.8406018614768982,
                0.6171642541885376,
                0.8423796892166138,
                0.8351854681968689,
                0.8275492787361145,
                0.8228524327278137,
                0.8280412554740906,
                0.8182559013366699,
                0.8380082845687866,
                0.8280412554740906,
                0.8034172654151917,
                0.7840907573699951,
                0.7899364233016968,
                0.8055903911590576,
                0.8181917667388916,
                0.7546408176422119
            ],
            [
                0.8489629030227661,
                0.8422515392303467,
                0.6745778322219849,
                0.7342604398727417,
                0.835366427898407,
                0.8558158278465271,
                0.8654541373252869,
                0.8670544624328613,
                0.7566379904747009,
                0.8513135313987732,
                0.827495813369751,
                0.868050754070282,
                0.8431223034858704,
                0.8408159613609314,
                0.835366427898407,
                0.7584804892539978,
                0.8366407752037048,
                0.835366427898407,
                0.834294855594635,
                0.842953622341156,
                0.8390194177627563,
                0.7915780544281006,
                0.8292822241783142,
                0.6745778322219849,
                0.858727216720581,
                0.7973021864891052,
                0.8395835161209106,
                0.8446506261825562,
                0.8468879461288452,
                0.8276724219322205,
                0.8732007145881653,
                0.8453990817070007,
                0.8445879817008972,
                0.8468879461288452,
                0.8595762848854065,
                0.8405269980430603,
                0.6169354915618896,
                0.8399264812469482,
                0.8410091996192932,
                0.8368761539459229,
                0.8264306783676147,
                0.8446506261825562,
                0.8359231352806091,
                0.8528841733932495,
                0.8446506261825562,
                0.8227525353431702,
                0.7685476541519165,
                0.7803341746330261,
                0.7988780736923218,
                0.8128543496131897,
                0.7540342211723328
            ],
            [
                0.8801581263542175,
                0.8422366380691528,
                0.6412746906280518,
                0.7777443528175354,
                0.8354170918464661,
                0.822381317615509,
                0.8326910138130188,
                0.8204255104064941,
                0.7046205401420593,
                0.8115037083625793,
                0.7947758436203003,
                0.8479747176170349,
                0.8494469523429871,
                0.8177499175071716,
                0.8354170918464661,
                0.8589109182357788,
                0.8106542229652405,
                0.8354170918464661,
                0.7802032232284546,
                0.8282005190849304,
                0.828863799571991,
                0.7906749248504639,
                0.8103465437889099,
                0.6412746906280518,
                0.8152198195457458,
                0.8414791822433472,
                0.8449005484580994,
                0.791932225227356,
                0.8462475538253784,
                0.7926080226898193,
                0.8603134155273438,
                0.8522970676422119,
                0.8347212076187134,
                0.8462475538253784,
                0.8440477848052979,
                0.8062191605567932,
                0.5885990858078003,
                0.8139523267745972,
                0.8359678983688354,
                0.8372880220413208,
                0.8395643830299377,
                0.791932225227356,
                0.8275290727615356,
                0.8374196290969849,
                0.791932225227356,
                0.8083364963531494,
                0.7847264409065247,
                0.7886306047439575,
                0.7806282639503479,
                0.8170299530029297,
                0.7339110970497131
            ],
            [
                0.8252575993537903,
                0.8298475742340088,
                0.6797587275505066,
                0.7252444624900818,
                0.8213775753974915,
                0.8525976538658142,
                0.853480875492096,
                0.8325832486152649,
                0.7584211230278015,
                0.831969678401947,
                0.8182796835899353,
                0.8477879762649536,
                0.8348146080970764,
                0.8278082609176636,
                0.8213775753974915,
                0.7349317669868469,
                0.826229453086853,
                0.8213775753974915,
                0.8018233776092529,
                0.8189775943756104,
                0.8181086778640747,
                0.7899463176727295,
                0.8195502758026123,
                0.6797587275505066,
                0.8352199196815491,
                0.7673043608665466,
                0.8207018971443176,
                0.8136237263679504,
                0.831549882888794,
                0.8117513060569763,
                0.8519120216369629,
                0.8373711109161377,
                0.8421435356140137,
                0.831549882888794,
                0.8446728587150574,
                0.8448354005813599,
                0.6577343344688416,
                0.8537034392356873,
                0.8235616683959961,
                0.8215875625610352,
                0.8280672430992126,
                0.8136237263679504,
                0.8168836832046509,
                0.8485270738601685,
                0.8136237263679504,
                0.810259222984314,
                0.7694680094718933,
                0.7933050990104675,
                0.7971876859664917,
                0.8160755634307861,
                0.7299709320068359
            ],
            [
                0.7866414785385132,
                0.8000181317329407,
                0.6761990785598755,
                0.7167800664901733,
                0.7864710688591003,
                0.791749119758606,
                0.8004440665245056,
                0.7920079231262207,
                0.7579202651977539,
                0.7737202048301697,
                0.7783598899841309,
                0.8010823130607605,
                0.7765336632728577,
                0.7745511531829834,
                0.7864710688591003,
                0.7311016321182251,
                0.7757538557052612,
                0.7864710688591003,
                0.7501361966133118,
                0.7623323798179626,
                0.7645717263221741,
                0.7515493035316467,
                0.7787207961082458,
                0.6761990785598755,
                0.7846178412437439,
                0.7427642941474915,
                0.7887095808982849,
                0.7841101288795471,
                0.7905842661857605,
                0.7917130589485168,
                0.8033857941627502,
                0.7776410579681396,
                0.7834434509277344,
                0.7905842661857605,
                0.795096218585968,
                0.7864689826965332,
                0.6459927558898926,
                0.799498438835144,
                0.7656310796737671,
                0.7666785717010498,
                0.7767083644866943,
                0.7841101288795471,
                0.7775099277496338,
                0.8075481057167053,
                0.7841101288795471,
                0.7481172680854797,
                0.7249225974082947,
                0.7063915133476257,
                0.7358983159065247,
                0.7602964043617249,
                0.6920634508132935
            ],
            [
                0.8911068439483643,
                0.8423900604248047,
                0.6553043127059937,
                0.7745382189750671,
                0.856925368309021,
                0.8382112979888916,
                0.8476293683052063,
                0.8329404592514038,
                0.7346126437187195,
                0.8396099209785461,
                0.8068342804908752,
                0.8684622645378113,
                0.8650084137916565,
                0.8375838994979858,
                0.856925368309021,
                0.8577814698219299,
                0.8147929906845093,
                0.856925368309021,
                0.796205997467041,
                0.841858446598053,
                0.8367741703987122,
                0.7920221090316772,
                0.8144814372062683,
                0.6553043127059937,
                0.8231990933418274,
                0.8575170040130615,
                0.8474985957145691,
                0.8149083256721497,
                0.8693095445632935,
                0.8223838806152344,
                0.8812494874000549,
                0.8700530529022217,
                0.8575564622879028,
                0.8693095445632935,
                0.8493876457214355,
                0.8308397531509399,
                0.6049866676330566,
                0.8323041796684265,
                0.8518468141555786,
                0.8472471237182617,
                0.8509095311164856,
                0.8149083256721497,
                0.8428064584732056,
                0.8428409695625305,
                0.8149083256721497,
                0.8201553821563721,
                0.814963698387146,
                0.817305326461792,
                0.8030197620391846,
                0.8339412212371826,
                0.7630901336669922
            ],
            [
                0.7851046323776245,
                0.7516977787017822,
                0.6766553521156311,
                0.7597535848617554,
                0.8461340665817261,
                0.7964210510253906,
                0.8043971657752991,
                0.7919350862503052,
                0.72294682264328,
                0.8026787042617798,
                0.7829862833023071,
                0.8062200546264648,
                0.777209460735321,
                0.793025553226471,
                0.8461340665817261,
                0.7661030888557434,
                0.8154134750366211,
                0.8461340665817261,
                0.7736243009567261,
                0.7420083284378052,
                0.7436261773109436,
                0.7764449119567871,
                0.7874422669410706,
                0.6766553521156311,
                0.8008556962013245,
                0.8208321928977966,
                0.7561123371124268,
                0.762132465839386,
                0.8355339765548706,
                0.7635680437088013,
                0.8043641448020935,
                0.7842728495597839,
                0.7992837429046631,
                0.8355339765548706,
                0.8075054883956909,
                0.7946738600730896,
                0.6057571172714233,
                0.8048973679542542,
                0.7534051537513733,
                0.7514989376068115,
                0.7949270606040955,
                0.762132465839386,
                0.7411693930625916,
                0.7929334044456482,
                0.762132465839386,
                0.7704444527626038,
                0.844038188457489,
                0.7988459467887878,
                0.8004588484764099,
                0.8175874948501587,
                0.6811513304710388
            ],
            [
                0.8315454721450806,
                0.7815136313438416,
                0.6463831067085266,
                0.7383041381835938,
                0.8168461322784424,
                0.8065521717071533,
                0.7945111393928528,
                0.7847139835357666,
                0.6842260956764221,
                0.767225980758667,
                0.7766975164413452,
                0.8223940134048462,
                0.8187165856361389,
                0.8018479943275452,
                0.8168461322784424,
                0.8068156242370605,
                0.7927958965301514,
                0.8168461322784424,
                0.7271742224693298,
                0.7677979469299316,
                0.7607516050338745,
                0.7766925692558289,
                0.8017591834068298,
                0.6463831067085266,
                0.7825750708580017,
                0.7821866273880005,
                0.7775321006774902,
                0.7212013602256775,
                0.8116148114204407,
                0.730985701084137,
                0.8206604719161987,
                0.8229876756668091,
                0.8174175024032593,
                0.8116148114204407,
                0.7958995699882507,
                0.7781642079353333,
                0.5821772217750549,
                0.7741646766662598,
                0.7785124182701111,
                0.771070122718811,
                0.810230016708374,
                0.7212013602256775,
                0.771795392036438,
                0.822172999382019,
                0.7212013602256775,
                0.7901564836502075,
                0.7530224919319153,
                0.7807385325431824,
                0.754673182964325,
                0.7801253795623779,
                0.6646437048912048
            ],
            [
                0.7496837973594666,
                0.7385287284851074,
                0.6792759299278259,
                0.7285976409912109,
                0.8079216480255127,
                0.7821313142776489,
                0.7841371893882751,
                0.7744709849357605,
                0.7228188514709473,
                0.750966489315033,
                0.7657730579376221,
                0.7838707566261292,
                0.7501404881477356,
                0.7903580665588379,
                0.8079216480255127,
                0.7233858108520508,
                0.8134328126907349,
                0.8079216480255127,
                0.749701738357544,
                0.7187555432319641,
                0.7277286648750305,
                0.7881510257720947,
                0.7872549891471863,
                0.6792759299278259,
                0.7929441928863525,
                0.7914674878120422,
                0.7339345216751099,
                0.7353886961936951,
                0.7886479496955872,
                0.7456684112548828,
                0.7741498947143555,
                0.7539273500442505,
                0.7849012017250061,
                0.7886479496955872,
                0.7944263219833374,
                0.7638543844223022,
                0.6240474581718445,
                0.7814884781837463,
                0.7255693078041077,
                0.7303023338317871,
                0.7861334681510925,
                0.7353886961936951,
                0.7228118181228638,
                0.7868403196334839,
                0.7353886961936951,
                0.7558919191360474,
                0.8164641261100769,
                0.7630677223205566,
                0.7743993997573853,
                0.7769646644592285,
                0.6695472002029419
            ],
            [
                0.846102237701416,
                0.7472253441810608,
                0.6225596070289612,
                0.711660623550415,
                0.7998547554016113,
                0.7903017401695251,
                0.7769008874893188,
                0.7552449703216553,
                0.6487576961517334,
                0.7449744939804077,
                0.7537989616394043,
                0.8080035448074341,
                0.8068827986717224,
                0.7955453991889954,
                0.7998547554016113,
                0.8421342372894287,
                0.7856050729751587,
                0.7998547554016113,
                0.6996704339981079,
                0.7553520798683167,
                0.7449827194213867,
                0.7621702551841736,
                0.7982828617095947,
                0.6225596070289612,
                0.7696346044540405,
                0.7836174368858337,
                0.7509384751319885,
                0.6927881836891174,
                0.7973362803459167,
                0.7003241777420044,
                0.8113020658493042,
                0.8151112794876099,
                0.8177289366722107,
                0.7973362803459167,
                0.7834348678588867,
                0.7666579484939575,
                0.5388303399085999,
                0.7519571185112,
                0.7719081044197083,
                0.7598093748092651,
                0.8052307367324829,
                0.6927881836891174,
                0.7396331429481506,
                0.8159356117248535,
                0.6927881836891174,
                0.7802461385726929,
                0.7644919753074646,
                0.7963114976882935,
                0.7646902203559875,
                0.783805251121521,
                0.6424789428710938
            ],
            [
                0.9035993814468384,
                0.8205372095108032,
                0.61114501953125,
                0.7278094291687012,
                0.8475549221038818,
                0.849676251411438,
                0.8546162843704224,
                0.807371973991394,
                0.6482363343238831,
                0.815037727355957,
                0.7871884703636169,
                0.8625130653381348,
                0.8768078088760376,
                0.8531804084777832,
                0.8475549221038818,
                0.7751601934432983,
                0.8364226222038269,
                0.8475549221038818,
                0.7695420980453491,
                0.849601149559021,
                0.8447344303131104,
                0.8185280561447144,
                0.8408993482589722,
                0.61114501953125,
                0.8382474184036255,
                0.8005883693695068,
                0.8319481611251831,
                0.7437529563903809,
                0.855364203453064,
                0.7352056503295898,
                0.873039186000824,
                0.8835809230804443,
                0.8780646324157715,
                0.855364203453064,
                0.8524322509765625,
                0.8124309182167053,
                0.5165674686431885,
                0.811303436756134,
                0.8622010946273804,
                0.8568743467330933,
                0.8700908422470093,
                0.7437529563903809,
                0.7991577982902527,
                0.8648425340652466,
                0.7437529563903809,
                0.8387151956558228,
                0.7651491165161133,
                0.8375640511512756,
                0.7968880534172058,
                0.8126171827316284,
                0.7178871631622314
            ],
            [
                0.8483069539070129,
                0.8521571159362793,
                0.6548762321472168,
                0.7585151791572571,
                0.8025392889976501,
                0.8204566240310669,
                0.8336317539215088,
                0.8212704658508301,
                0.7393984198570251,
                0.8280705213546753,
                0.8173285722732544,
                0.859183132648468,
                0.8480584621429443,
                0.8233563899993896,
                0.8025392889976501,
                0.732980489730835,
                0.7967079877853394,
                0.8025392889976501,
                0.7832663655281067,
                0.8256514072418213,
                0.8254906535148621,
                0.7937049865722656,
                0.791240930557251,
                0.6548762321472168,
                0.8125905990600586,
                0.7924677729606628,
                0.8475821018218994,
                0.7978094816207886,
                0.8116832375526428,
                0.8098044395446777,
                0.8617103099822998,
                0.8474286198616028,
                0.8345602750778198,
                0.8116832375526428,
                0.82286536693573,
                0.8326395750045776,
                0.6199780702590942,
                0.81794673204422,
                0.8292562961578369,
                0.831993579864502,
                0.8330304026603699,
                0.7978094816207886,
                0.8524335622787476,
                0.8165058493614197,
                0.7978094816207886,
                0.8086671233177185,
                0.7478416562080383,
                0.7793248891830444,
                0.7823011875152588,
                0.7889118194580078,
                0.7450171709060669
            ],
            [
                0.7630573511123657,
                0.7569547295570374,
                0.6616560220718384,
                0.7489508390426636,
                0.8043988943099976,
                0.8097929954528809,
                0.8078324198722839,
                0.7954890727996826,
                0.7119925618171692,
                0.7810304760932922,
                0.8074013590812683,
                0.8178252577781677,
                0.7561116814613342,
                0.8110040426254272,
                0.8043988943099976,
                0.7329846620559692,
                0.808879554271698,
                0.8043988943099976,
                0.7417033314704895,
                0.7334751486778259,
                0.7360464930534363,
                0.77676922082901,
                0.8341333270072937,
                0.6616560220718384,
                0.8021883368492126,
                0.777880072593689,
                0.7444016933441162,
                0.7241057753562927,
                0.7854790091514587,
                0.732017993927002,
                0.8020843267440796,
                0.7557106614112854,
                0.8035469055175781,
                0.7854790091514587,
                0.7860693335533142,
                0.7985988855361938,
                0.6042847037315369,
                0.7753397226333618,
                0.7350199818611145,
                0.7341228723526001,
                0.7763357162475586,
                0.7241057753562927,
                0.7400927543640137,
                0.8318054676055908,
                0.7241057753562927,
                0.7846822738647461,
                0.7896103262901306,
                0.7415132522583008,
                0.7797532081604004,
                0.7713786959648132,
                0.6583575010299683
            ],
            [
                0.8081147074699402,
                0.7124002575874329,
                0.6015291810035706,
                0.6796737313270569,
                0.7790774703025818,
                0.7575089931488037,
                0.7517058253288269,
                0.7494478225708008,
                0.6303309798240662,
                0.7308351397514343,
                0.7658585906028748,
                0.7806535363197327,
                0.7629774212837219,
                0.7768121957778931,
                0.7790774703025818,
                0.815690815448761,
                0.7817493677139282,
                0.7790774703025818,
                0.690253496170044,
                0.7146502733230591,
                0.7037547826766968,
                0.7298277616500854,
                0.7874011397361755,
                0.6015291810035706,
                0.766954243183136,
                0.786491334438324,
                0.7001165747642517,
                0.6630722284317017,
                0.7671536207199097,
                0.665602445602417,
                0.7736989855766296,
                0.7687791585922241,
                0.7801240086555481,
                0.7671536207199097,
                0.7589409351348877,
                0.7582513093948364,
                0.5364204049110413,
                0.7340684533119202,
                0.7229113578796387,
                0.7100043892860413,
                0.7502464652061462,
                0.6630722284317017,
                0.7033247351646423,
                0.7945635318756104,
                0.6630722284317017,
                0.7595587968826294,
                0.7513369917869568,
                0.7711372971534729,
                0.7461891174316406,
                0.7444793581962585,
                0.6169114708900452
            ],
            [
                0.7578318119049072,
                0.7450112104415894,
                0.6437750458717346,
                0.7018789649009705,
                0.7649136185646057,
                0.7642476558685303,
                0.7634024620056152,
                0.7544723153114319,
                0.7309458255767822,
                0.7405276298522949,
                0.7681342959403992,
                0.7767115235328674,
                0.7536852955818176,
                0.7505024671554565,
                0.7649136185646057,
                0.7119895219802856,
                0.7487229704856873,
                0.7649136185646057,
                0.7084618210792542,
                0.6972448825836182,
                0.7071965336799622,
                0.7241221070289612,
                0.757248044013977,
                0.6437750458717346,
                0.749600350856781,
                0.7216971516609192,
                0.7266215682029724,
                0.7109050154685974,
                0.7571068406105042,
                0.7418253421783447,
                0.7680845856666565,
                0.7547410726547241,
                0.7572299838066101,
                0.7571068406105042,
                0.7450353503227234,
                0.7709861397743225,
                0.6255707144737244,
                0.7742747664451599,
                0.7040454745292664,
                0.7113503217697144,
                0.7425255179405212,
                0.7109050154685974,
                0.7178314328193665,
                0.7749945521354675,
                0.7109050154685974,
                0.7129855751991272,
                0.7361249923706055,
                0.7051841020584106,
                0.7239906191825867,
                0.7416931986808777,
                0.6333723664283752
            ],
            [
                0.8180438280105591,
                0.7387635707855225,
                0.6072811484336853,
                0.6806355714797974,
                0.8091017603874207,
                0.7783523797988892,
                0.7708821892738342,
                0.7625530958175659,
                0.6205294132232666,
                0.7470875382423401,
                0.7603456974029541,
                0.7954641580581665,
                0.8093773722648621,
                0.8142327070236206,
                0.8091017603874207,
                0.8054585456848145,
                0.812963604927063,
                0.8091017603874207,
                0.7314728498458862,
                0.7509604096412659,
                0.7366693019866943,
                0.7707824110984802,
                0.8030548095703125,
                0.6072811484336853,
                0.7931073904037476,
                0.7973682880401611,
                0.7443504929542542,
                0.68268883228302,
                0.7990689873695374,
                0.6780518293380737,
                0.7936851978302002,
                0.8172065615653992,
                0.8264634609222412,
                0.7990689873695374,
                0.7941939234733582,
                0.7862897515296936,
                0.5167795419692993,
                0.7671147584915161,
                0.7670989632606506,
                0.751885712146759,
                0.798170268535614,
                0.68268883228302,
                0.7196816205978394,
                0.802431583404541,
                0.68268883228302,
                0.7998601198196411,
                0.7654330730438232,
                0.8008954524993896,
                0.7575986385345459,
                0.7732558846473694,
                0.6236573457717896
            ],
            [
                0.7671006917953491,
                0.7410885691642761,
                0.6782655715942383,
                0.7282741069793701,
                0.7881842851638794,
                0.7853950262069702,
                0.7804585695266724,
                0.7679305076599121,
                0.7265357971191406,
                0.7484973073005676,
                0.7474496960639954,
                0.7997680902481079,
                0.7593926787376404,
                0.7846716046333313,
                0.7881842851638794,
                0.756902277469635,
                0.7828497886657715,
                0.7881842851638794,
                0.7232975363731384,
                0.7098838090896606,
                0.7109703421592712,
                0.761900782585144,
                0.777835488319397,
                0.6782655715942383,
                0.7671002745628357,
                0.7694934606552124,
                0.7425645589828491,
                0.735514223575592,
                0.774395227432251,
                0.74607253074646,
                0.7912284731864929,
                0.7635213732719421,
                0.7903831601142883,
                0.774395227432251,
                0.77068030834198,
                0.7547960877418518,
                0.5666593313217163,
                0.753634512424469,
                0.722254753112793,
                0.7190611958503723,
                0.780701220035553,
                0.735514223575592,
                0.718988299369812,
                0.7856017351150513,
                0.735514223575592,
                0.7425357103347778,
                0.8004715442657471,
                0.749345600605011,
                0.7734462022781372,
                0.7832174301147461,
                0.6571602821350098
            ],
            [
                0.7725895643234253,
                0.7557250261306763,
                0.6690918207168579,
                0.731823742389679,
                0.7812004685401917,
                0.7720040082931519,
                0.7747034430503845,
                0.7715433835983276,
                0.7668945789337158,
                0.7610760927200317,
                0.7459398508071899,
                0.7982965111732483,
                0.7702652215957642,
                0.7622269988059998,
                0.7812004685401917,
                0.7280809879302979,
                0.7378553748130798,
                0.7812004685401917,
                0.7096461057662964,
                0.7177847623825073,
                0.7267621159553528,
                0.7221299409866333,
                0.7335691452026367,
                0.6690918207168579,
                0.7402782440185547,
                0.7530711889266968,
                0.7561946511268616,
                0.7631756067276001,
                0.7821559906005859,
                0.7934095859527588,
                0.7974821329116821,
                0.7724618315696716,
                0.7760832905769348,
                0.7821559906005859,
                0.7572946548461914,
                0.7526111602783203,
                0.6165531873703003,
                0.7688689827919006,
                0.7270470857620239,
                0.7320321202278137,
                0.759677529335022,
                0.7631756067276001,
                0.739883303642273,
                0.7603772878646851,
                0.7631756067276001,
                0.7068780660629272,
                0.7879834771156311,
                0.734584629535675,
                0.7574272751808167,
                0.7805938124656677,
                0.6888946294784546
            ],
            [
                0.7250809073448181,
                0.691166877746582,
                0.6142213344573975,
                0.6360194087028503,
                0.7196708917617798,
                0.7315195202827454,
                0.7124749422073364,
                0.726200520992279,
                0.6207029819488525,
                0.6661064624786377,
                0.725479781627655,
                0.7511295676231384,
                0.7486332654953003,
                0.7569049000740051,
                0.7196708917617798,
                0.740204930305481,
                0.7257301807403564,
                0.7196708917617798,
                0.6344923377037048,
                0.6678504943847656,
                0.6568079590797424,
                0.6999472379684448,
                0.7416685819625854,
                0.6142213344573975,
                0.7117923498153687,
                0.6750603318214417,
                0.676395058631897,
                0.6259051561355591,
                0.7035359144210815,
                0.6318271160125732,
                0.7396108508110046,
                0.7522246241569519,
                0.7635883688926697,
                0.7035359144210815,
                0.7089316844940186,
                0.7108516693115234,
                0.5501593351364136,
                0.6843321323394775,
                0.678121030330658,
                0.6655628085136414,
                0.7147103548049927,
                0.6259051561355591,
                0.6855062246322632,
                0.7538873553276062,
                0.6259051561355591,
                0.7327771782875061,
                0.6580005884170532,
                0.7064645886421204,
                0.6616092920303345,
                0.6834327578544617,
                0.5541514158248901
            ],
            [
                0.8328248858451843,
                0.7604062557220459,
                0.625214159488678,
                0.6952679753303528,
                0.8029546737670898,
                0.7792631387710571,
                0.7758105993270874,
                0.7668466567993164,
                0.6612545847892761,
                0.7471833229064941,
                0.7522428035736084,
                0.80384761095047,
                0.7993753552436829,
                0.8108359575271606,
                0.8029546737670898,
                0.8597557544708252,
                0.8091369271278381,
                0.8029546737670898,
                0.7203111052513123,
                0.756374716758728,
                0.7449209690093994,
                0.7672867774963379,
                0.7934740781784058,
                0.625214159488678,
                0.7907437682151794,
                0.8168721795082092,
                0.7640765905380249,
                0.7054077982902527,
                0.7953842282295227,
                0.712666392326355,
                0.8027544021606445,
                0.8063957095146179,
                0.8203545212745667,
                0.7953842282295227,
                0.7984345555305481,
                0.7795111536979675,
                0.524994969367981,
                0.7547421455383301,
                0.7701570987701416,
                0.7574678659439087,
                0.7969344258308411,
                0.7054077982902527,
                0.739528238773346,
                0.8025527000427246,
                0.7054077982902527,
                0.789282500743866,
                0.7743329405784607,
                0.7833821773529053,
                0.7578988075256348,
                0.7773467898368835,
                0.6372869610786438
            ],
            [
                0.8203877210617065,
                0.8305888175964355,
                0.6918640732765198,
                0.7579188942909241,
                0.8207055926322937,
                0.8195072412490845,
                0.8317826986312866,
                0.8345556855201721,
                0.7729357481002808,
                0.8202155232429504,
                0.8132604360580444,
                0.8397895097732544,
                0.8068282604217529,
                0.8037126064300537,
                0.8207055926322937,
                0.7391588687896729,
                0.8012064695358276,
                0.8207055926322937,
                0.7931248545646667,
                0.8027724623680115,
                0.8090134859085083,
                0.7828025817871094,
                0.7916686534881592,
                0.6918640732765198,
                0.8226759433746338,
                0.784936249256134,
                0.8236250281333923,
                0.8273664712905884,
                0.8254528045654297,
                0.8257042765617371,
                0.8409209251403809,
                0.8076916337013245,
                0.8104078769683838,
                0.8254528045654297,
                0.8252500891685486,
                0.8143185973167419,
                0.6391443610191345,
                0.8192296028137207,
                0.8025198578834534,
                0.8085883855819702,
                0.8115716576576233,
                0.8273664712905884,
                0.8315464854240417,
                0.823526918888092,
                0.8273664712905884,
                0.7763745188713074,
                0.7697446942329407,
                0.7555941343307495,
                0.7881539463996887,
                0.7980248332023621,
                0.7490951418876648
            ],
            [
                0.9127455353736877,
                0.8258166313171387,
                0.6205518245697021,
                0.7687085270881653,
                0.8330143690109253,
                0.8210218548774719,
                0.8325097560882568,
                0.8074882626533508,
                0.686320960521698,
                0.7999265789985657,
                0.7945871353149414,
                0.8499681949615479,
                0.8508638143539429,
                0.8349140286445618,
                0.8330143690109253,
                0.8687125444412231,
                0.8055607080459595,
                0.8330143690109253,
                0.7472063302993774,
                0.8166465759277344,
                0.8208085894584656,
                0.7823329567909241,
                0.8195781707763672,
                0.6205518245697021,
                0.8093315958976746,
                0.8334609270095825,
                0.8272874355316162,
                0.7608547210693359,
                0.8426229953765869,
                0.7718415260314941,
                0.8616356253623962,
                0.858148455619812,
                0.8537483811378479,
                0.8426229953765869,
                0.8353642225265503,
                0.8074348568916321,
                0.5691214203834534,
                0.8019748330116272,
                0.8280164003372192,
                0.8325189352035522,
                0.8368241786956787,
                0.7608547210693359,
                0.8222396373748779,
                0.8547451496124268,
                0.7608547210693359,
                0.8085048198699951,
                0.8000158071517944,
                0.8111632466316223,
                0.7830155491828918,
                0.8106206655502319,
                0.7252846956253052
            ],
            [
                0.7759504914283752,
                0.7862646579742432,
                0.6942057013511658,
                0.6946336030960083,
                0.7589706182479858,
                0.7645889520645142,
                0.7667553424835205,
                0.7659643888473511,
                0.7485293745994568,
                0.7300781011581421,
                0.737299382686615,
                0.7721057534217834,
                0.7509767413139343,
                0.748602569103241,
                0.7589706182479858,
                0.758966863155365,
                0.7718169689178467,
                0.7589706182479858,
                0.7231786847114563,
                0.7382868528366089,
                0.7399578094482422,
                0.7387613654136658,
                0.7538825869560242,
                0.6942057013511658,
                0.7590335607528687,
                0.7288038730621338,
                0.7794613242149353,
                0.7663363218307495,
                0.7582324147224426,
                0.7715262174606323,
                0.774112343788147,
                0.7526270747184753,
                0.7579683065414429,
                0.7582324147224426,
                0.7867293953895569,
                0.7412749528884888,
                0.6110281944274902,
                0.7508761286735535,
                0.7426630854606628,
                0.74539715051651,
                0.7594572305679321,
                0.7663363218307495,
                0.7577400207519531,
                0.7785440683364868,
                0.7663363218307495,
                0.7358693480491638,
                0.713223934173584,
                0.6846861839294434,
                0.72959965467453,
                0.7447470426559448,
                0.6689726114273071
            ]
        ],
        [
            [
                0.8330353498458862,
                0.909134566783905,
                0.8711078763008118,
                0.8131029605865479,
                0.7686739563941956,
                0.8763177394866943,
                0.7908414006233215,
                0.8301582336425781,
                0.867435872554779,
                0.8137914538383484,
                0.7491162419319153,
                0.8981900811195374,
                0.9135145545005798,
                0.6383898258209229,
                0.7600321769714355,
                0.8156371712684631,
                0.8226009011268616,
                0.8831996321678162,
                0.7757577896118164,
                0.8564698696136475,
                0.8176475167274475,
                0.7961944341659546,
                0.876065731048584,
                0.8379288911819458,
                0.7069300413131714,
                0.8169999718666077,
                0.7724083662033081,
                0.8513165712356567,
                0.8084346652030945,
                0.7001624703407288,
                0.7988452911376953,
                0.787754237651825,
                0.7951205968856812,
                0.7444603443145752,
                0.6996227502822876,
                0.7130222916603088,
                0.7615216374397278,
                0.8366554975509644,
                0.8202202320098877,
                0.9049477577209473,
                0.793244481086731,
                0.7794160842895508,
                0.6888274550437927,
                0.8446760773658752,
                0.8058870434761047,
                0.802410900592804,
                0.7553851008415222,
                0.8076746463775635,
                0.8377828598022461,
                0.7330527305603027,
                0.7622261643409729
            ],
            [
                0.785449206829071,
                0.7968999147415161,
                0.7847277522087097,
                0.8027443289756775,
                0.7703583240509033,
                0.831542432308197,
                0.7172151207923889,
                0.763948917388916,
                0.7232834696769714,
                0.7007447481155396,
                0.7000954747200012,
                0.8070728182792664,
                0.7987992167472839,
                0.6719056367874146,
                0.740129292011261,
                0.7494944930076599,
                0.7858248353004456,
                0.8055895566940308,
                0.7471839785575867,
                0.7648553252220154,
                0.8270444273948669,
                0.7644140124320984,
                0.7841375470161438,
                0.8195392489433289,
                0.7143481969833374,
                0.73879075050354,
                0.8062200546264648,
                0.796027421951294,
                0.6601436138153076,
                0.7231797575950623,
                0.7672227025032043,
                0.7756196856498718,
                0.7656763195991516,
                0.6174827218055725,
                0.825092613697052,
                0.8512518405914307,
                0.6985439658164978,
                0.8280929923057556,
                0.7909727692604065,
                0.7819757461547852,
                0.7361491322517395,
                0.7033724784851074,
                0.652652382850647,
                0.741002082824707,
                0.8293822407722473,
                0.7784112691879272,
                0.750881552696228,
                0.7609527707099915,
                0.8303039073944092,
                0.7635663747787476,
                0.8028371930122375
            ],
            [
                0.8672917485237122,
                0.9041170477867126,
                0.9165399074554443,
                0.8278671503067017,
                0.8460342288017273,
                0.8894835710525513,
                0.782544732093811,
                0.8288202285766602,
                0.8658628463745117,
                0.7748469114303589,
                0.818902313709259,
                0.9134413599967957,
                0.9178401231765747,
                0.6729471683502197,
                0.8081926703453064,
                0.8455328941345215,
                0.8457353115081787,
                0.8881303071975708,
                0.8219898343086243,
                0.8718181252479553,
                0.8840190172195435,
                0.8153499364852905,
                0.9142432808876038,
                0.8662008047103882,
                0.7806963920593262,
                0.8510967493057251,
                0.8560781478881836,
                0.8682112097740173,
                0.7917121648788452,
                0.7982223629951477,
                0.846110463142395,
                0.8310754895210266,
                0.851566731929779,
                0.7515788078308105,
                0.8249328136444092,
                0.8379359245300293,
                0.8044432997703552,
                0.8912630081176758,
                0.8754037022590637,
                0.886099636554718,
                0.8337433934211731,
                0.8030456304550171,
                0.7121303081512451,
                0.8030814528465271,
                0.8800426125526428,
                0.8468766808509827,
                0.8105151653289795,
                0.8238956928253174,
                0.8747709393501282,
                0.7976962327957153,
                0.8287593722343445
            ],
            [
                0.8278648853302002,
                0.8345298171043396,
                0.8429330587387085,
                0.8934226036071777,
                0.8434504866600037,
                0.8765608668327332,
                0.7934128046035767,
                0.824724555015564,
                0.7690057754516602,
                0.7724325656890869,
                0.7158207893371582,
                0.8547505736351013,
                0.8291527032852173,
                0.6758557558059692,
                0.8205377459526062,
                0.8226942420005798,
                0.850290060043335,
                0.8279678225517273,
                0.7984101176261902,
                0.812334418296814,
                0.8602318167686462,
                0.8185642957687378,
                0.8477233648300171,
                0.8609610199928284,
                0.8099683523178101,
                0.8054342865943909,
                0.8664812445640564,
                0.8450608849525452,
                0.7199441194534302,
                0.7874141335487366,
                0.8175479173660278,
                0.8269615769386292,
                0.8158343434333801,
                0.6801124811172485,
                0.8239825367927551,
                0.8405889272689819,
                0.755621075630188,
                0.8602553009986877,
                0.8530772924423218,
                0.794427216053009,
                0.8119657039642334,
                0.7213869094848633,
                0.7456464171409607,
                0.7532137632369995,
                0.8576222658157349,
                0.8239141702651978,
                0.8109961152076721,
                0.7689447999000549,
                0.8574100732803345,
                0.8012326955795288,
                0.8413723707199097
            ],
            [
                0.758816123008728,
                0.7752638459205627,
                0.8029147982597351,
                0.9311134815216064,
                0.8970592617988586,
                0.8456206321716309,
                0.8953481316566467,
                0.9047439694404602,
                0.7875704169273376,
                0.8633031845092773,
                0.6826457381248474,
                0.7999293804168701,
                0.7961784601211548,
                0.7175064086914062,
                0.8921175599098206,
                0.8809919953346252,
                0.9204117059707642,
                0.7865146398544312,
                0.8272320628166199,
                0.8327257037162781,
                0.8298167586326599,
                0.9040505886077881,
                0.8223045468330383,
                0.8942991495132446,
                0.869662880897522,
                0.8367444276809692,
                0.8816493153572083,
                0.8701462745666504,
                0.7218217849731445,
                0.8613177537918091,
                0.8938050866127014,
                0.8979029059410095,
                0.8755917549133301,
                0.6832895278930664,
                0.8046202659606934,
                0.7859840989112854,
                0.8106024861335754,
                0.8356016874313354,
                0.9077057242393494,
                0.80320143699646,
                0.8824137449264526,
                0.7191762328147888,
                0.8604745864868164,
                0.8035552501678467,
                0.8174139261245728,
                0.8389883637428284,
                0.8885089755058289,
                0.7887414693832397,
                0.8707670569419861,
                0.876746654510498,
                0.8930706977844238
            ],
            [
                0.8214874863624573,
                0.8120244741439819,
                0.8318253755569458,
                0.8983873128890991,
                0.9115376472473145,
                0.8734064102172852,
                0.8353304862976074,
                0.8710678219795227,
                0.7801612019538879,
                0.8063541054725647,
                0.7097650766372681,
                0.8341204524040222,
                0.8311883807182312,
                0.7135312557220459,
                0.8494367599487305,
                0.8554852604866028,
                0.8784708976745605,
                0.8168328404426575,
                0.813321053981781,
                0.8210396766662598,
                0.8656819462776184,
                0.8705316781997681,
                0.8340799808502197,
                0.8906980156898499,
                0.8253059983253479,
                0.8200465440750122,
                0.8785368204116821,
                0.8469262719154358,
                0.6962267160415649,
                0.8360340595245361,
                0.8630355000495911,
                0.8647063374519348,
                0.8561699390411377,
                0.6741337776184082,
                0.8803437948226929,
                0.8722531795501709,
                0.776524543762207,
                0.8593619465827942,
                0.8832216858863831,
                0.821116030216217,
                0.8399933576583862,
                0.7358376979827881,
                0.7959574460983276,
                0.7996005415916443,
                0.8383137583732605,
                0.8173490166664124,
                0.8421459794044495,
                0.8147768974304199,
                0.877802312374115,
                0.8521888852119446,
                0.8880823254585266
            ],
            [
                0.7679823637008667,
                0.8229934573173523,
                0.8527684807777405,
                0.7704586982727051,
                0.7787509560585022,
                0.8532746434211731,
                0.7382116913795471,
                0.7806206345558167,
                0.8559576869010925,
                0.7536317110061646,
                0.7698898911476135,
                0.8564614057540894,
                0.8734957575798035,
                0.7411855459213257,
                0.7689671516418457,
                0.7938610315322876,
                0.7722742557525635,
                0.8118588328361511,
                0.7576763033866882,
                0.8199796676635742,
                0.7774530053138733,
                0.770216703414917,
                0.8370507955551147,
                0.8117232322692871,
                0.7573524713516235,
                0.8128485083580017,
                0.7479596138000488,
                0.8274490237236023,
                0.8054958581924438,
                0.7159039974212646,
                0.7817678451538086,
                0.7803874611854553,
                0.7810642719268799,
                0.7948299050331116,
                0.6910133957862854,
                0.6945512890815735,
                0.7737007141113281,
                0.7950458526611328,
                0.7994762063026428,
                0.837479829788208,
                0.8076525330543518,
                0.7422234416007996,
                0.7044910192489624,
                0.7928597927093506,
                0.782599151134491,
                0.8286141753196716,
                0.7787861227989197,
                0.806357204914093,
                0.8129572868347168,
                0.7134066820144653,
                0.7253850698471069
            ],
            [
                0.7914263010025024,
                0.840542197227478,
                0.8587578535079956,
                0.9085649847984314,
                0.8689168691635132,
                0.9142834544181824,
                0.9193472862243652,
                0.8794979453086853,
                0.8319836854934692,
                0.8903045058250427,
                0.7089893817901611,
                0.8668642044067383,
                0.837970495223999,
                0.6923540830612183,
                0.8703803420066833,
                0.8815741539001465,
                0.8912772536277771,
                0.8252030611038208,
                0.8425131440162659,
                0.8600742816925049,
                0.8546573519706726,
                0.9013581275939941,
                0.8477718234062195,
                0.9027572870254517,
                0.83230060338974,
                0.8367699980735779,
                0.8728161454200745,
                0.8632765412330627,
                0.7116219997406006,
                0.8122971653938293,
                0.8785498142242432,
                0.8831661939620972,
                0.8355920910835266,
                0.6683886051177979,
                0.7975490093231201,
                0.7999558448791504,
                0.7673700451850891,
                0.8566911220550537,
                0.8845710754394531,
                0.8386800289154053,
                0.8508340716362,
                0.7329717874526978,
                0.8056601881980896,
                0.8259688019752502,
                0.8370522260665894,
                0.8520969152450562,
                0.8681478500366211,
                0.7986770272254944,
                0.8922358155250549,
                0.8767982721328735,
                0.8867812156677246
            ],
            [
                0.769426703453064,
                0.8246973156929016,
                0.8642327189445496,
                0.9181200265884399,
                0.9107703566551208,
                0.8903710842132568,
                0.8999006152153015,
                0.9242398142814636,
                0.8409494161605835,
                0.8773494362831116,
                0.7257283926010132,
                0.8524033427238464,
                0.8405370712280273,
                0.7243786454200745,
                0.9198502898216248,
                0.9235631227493286,
                0.9101113080978394,
                0.8110101819038391,
                0.8528066873550415,
                0.8793913125991821,
                0.8488324284553528,
                0.9225362539291382,
                0.8608371019363403,
                0.9178476929664612,
                0.8817631006240845,
                0.8645883798599243,
                0.8792700171470642,
                0.8897319436073303,
                0.7276223301887512,
                0.8491436243057251,
                0.9073387980461121,
                0.9147867560386658,
                0.8769228458404541,
                0.6813063621520996,
                0.7983434200286865,
                0.7810001373291016,
                0.8132007122039795,
                0.8601021766662598,
                0.9227510690689087,
                0.8464632630348206,
                0.9176569581031799,
                0.724557638168335,
                0.8542318344116211,
                0.841041088104248,
                0.8350575566291809,
                0.8721151351928711,
                0.9059504866600037,
                0.7962110638618469,
                0.8917080760002136,
                0.8807504177093506,
                0.8814572691917419
            ],
            [
                0.7468768954277039,
                0.8094770312309265,
                0.8236758708953857,
                0.8231244683265686,
                0.8357287645339966,
                0.8637731671333313,
                0.8373302221298218,
                0.8404109477996826,
                0.7867292165756226,
                0.7894951701164246,
                0.702555775642395,
                0.8284030556678772,
                0.813265323638916,
                0.6912487149238586,
                0.8400179743766785,
                0.8499196767807007,
                0.8502554297447205,
                0.826904833316803,
                0.8248001337051392,
                0.8166112303733826,
                0.8672674298286438,
                0.8568817377090454,
                0.8305752873420715,
                0.8597792983055115,
                0.8356483578681946,
                0.8211020231246948,
                0.8468169569969177,
                0.8278577327728271,
                0.7023834586143494,
                0.8133720755577087,
                0.8497827649116516,
                0.8604655265808105,
                0.8214139938354492,
                0.6518449783325195,
                0.8523305058479309,
                0.8315547704696655,
                0.7649294137954712,
                0.8511160016059875,
                0.8733195662498474,
                0.8133047819137573,
                0.8491835594177246,
                0.6952462792396545,
                0.7571701407432556,
                0.782163679599762,
                0.8203802108764648,
                0.8186070919036865,
                0.8471530675888062,
                0.7751274108886719,
                0.8458338975906372,
                0.8304612040519714,
                0.8571919202804565
            ],
            [
                0.8412826657295227,
                0.8649150729179382,
                0.8884499073028564,
                0.8188753724098206,
                0.8237798810005188,
                0.9075289964675903,
                0.7608144283294678,
                0.8199756741523743,
                0.8125568628311157,
                0.744901180267334,
                0.8059757947921753,
                0.8888007402420044,
                0.879531979560852,
                0.7621121406555176,
                0.7992348670959473,
                0.8325228691101074,
                0.8204888701438904,
                0.874270498752594,
                0.8053745627403259,
                0.8137001991271973,
                0.8720091581344604,
                0.7952029705047607,
                0.866206169128418,
                0.8645909428596497,
                0.789660632610321,
                0.826806902885437,
                0.8467608690261841,
                0.8526723384857178,
                0.7342470288276672,
                0.7841178774833679,
                0.827614426612854,
                0.8248224258422852,
                0.8264681100845337,
                0.7342187166213989,
                0.8476229906082153,
                0.8681825399398804,
                0.7900197505950928,
                0.8884696960449219,
                0.8638447523117065,
                0.8304501175880432,
                0.8063223361968994,
                0.7431164383888245,
                0.7086651921272278,
                0.7419500350952148,
                0.8703503012657166,
                0.8444381356239319,
                0.8153676986694336,
                0.7990781664848328,
                0.8718503713607788,
                0.7943990230560303,
                0.8241546154022217
            ],
            [
                0.7369596362113953,
                0.7705748677253723,
                0.7989897727966309,
                0.8902838826179504,
                0.8879951238632202,
                0.8550890684127808,
                0.9044569134712219,
                0.8869235515594482,
                0.8002416491508484,
                0.8796190023422241,
                0.6873891353607178,
                0.7939121723175049,
                0.787821352481842,
                0.7081659436225891,
                0.8936046957969666,
                0.8881059288978577,
                0.9010097980499268,
                0.7806543111801147,
                0.8571892380714417,
                0.8437909483909607,
                0.8189396262168884,
                0.9096363186836243,
                0.8260542154312134,
                0.8861801028251648,
                0.8741858005523682,
                0.8603074550628662,
                0.8660207390785217,
                0.8615776896476746,
                0.7250151634216309,
                0.8609372973442078,
                0.8928314447402954,
                0.9026457071304321,
                0.8600335717201233,
                0.6707063913345337,
                0.7841891646385193,
                0.7645789384841919,
                0.8187705874443054,
                0.8280634880065918,
                0.8983365297317505,
                0.8163371086120605,
                0.8809357285499573,
                0.7290883660316467,
                0.8580039143562317,
                0.8157951831817627,
                0.8005602359771729,
                0.8391835689544678,
                0.8864089250564575,
                0.8175453543663025,
                0.858858585357666,
                0.8601453304290771,
                0.8697091341018677
            ],
            [
                0.8280801177024841,
                0.9077451825141907,
                0.9130706787109375,
                0.8687664866447449,
                0.8481246829032898,
                0.9604001641273499,
                0.8469938635826111,
                0.8506186008453369,
                0.8706526756286621,
                0.8356260657310486,
                0.783271074295044,
                0.92469722032547,
                0.8935823440551758,
                0.6988629698753357,
                0.8374995589256287,
                0.8799731135368347,
                0.8545044660568237,
                0.8792319893836975,
                0.8385606408119202,
                0.8586779832839966,
                0.8902029991149902,
                0.8529084920883179,
                0.8975416421890259,
                0.895136296749115,
                0.8234668374061584,
                0.8596940636634827,
                0.8609646558761597,
                0.88054358959198,
                0.7302830219268799,
                0.7696354389190674,
                0.8568336963653564,
                0.8628050088882446,
                0.8137066960334778,
                0.6948360204696655,
                0.8060680627822876,
                0.816464364528656,
                0.7614421844482422,
                0.9016917943954468,
                0.8772367835044861,
                0.8605637550354004,
                0.8475317358970642,
                0.7376748323440552,
                0.7405409812927246,
                0.783859372138977,
                0.8697136044502258,
                0.8783077001571655,
                0.8460178375244141,
                0.7971469759941101,
                0.8865060806274414,
                0.83460533618927,
                0.8493629693984985
            ],
            [
                0.8259369134902954,
                0.850652277469635,
                0.8561760187149048,
                0.8934813737869263,
                0.8827234506607056,
                0.9110541343688965,
                0.8450972437858582,
                0.8853560090065002,
                0.8290560841560364,
                0.8219561576843262,
                0.7508598566055298,
                0.8824247717857361,
                0.8619017601013184,
                0.6935015916824341,
                0.8896117210388184,
                0.8942164778709412,
                0.9019359350204468,
                0.8532602190971375,
                0.833285391330719,
                0.852109432220459,
                0.8939319849014282,
                0.8880565166473389,
                0.8824048638343811,
                0.9088577032089233,
                0.8715879917144775,
                0.8579574227333069,
                0.8954058289527893,
                0.8947696089744568,
                0.7313679456710815,
                0.8329596519470215,
                0.8859328031539917,
                0.8889039158821106,
                0.8717861175537109,
                0.6945347189903259,
                0.8692946434020996,
                0.8622894287109375,
                0.800230085849762,
                0.9027634263038635,
                0.910193145275116,
                0.8492449522018433,
                0.8877336382865906,
                0.7542728781700134,
                0.786157488822937,
                0.7867213487625122,
                0.8854063153266907,
                0.8698614835739136,
                0.8874179720878601,
                0.8045058250427246,
                0.8986369371414185,
                0.8693101406097412,
                0.8951570391654968
            ],
            [
                0.7670871615409851,
                0.7119028568267822,
                0.7424209713935852,
                0.8694111108779907,
                0.8593860864639282,
                0.77720707654953,
                0.8290796279907227,
                0.842019259929657,
                0.7299425005912781,
                0.820038378238678,
                0.6738019585609436,
                0.7345677018165588,
                0.7525548934936523,
                0.7549297213554382,
                0.8328713774681091,
                0.8247584700584412,
                0.863381028175354,
                0.7345178127288818,
                0.8176984786987305,
                0.8187094926834106,
                0.7573226690292358,
                0.8758580684661865,
                0.7729364037513733,
                0.8450064063072205,
                0.8375274538993835,
                0.8062059879302979,
                0.8415213823318481,
                0.8305985927581787,
                0.7128245830535889,
                0.8331631422042847,
                0.8441851139068604,
                0.8385155200958252,
                0.842714786529541,
                0.6572683453559875,
                0.7583339810371399,
                0.7598093152046204,
                0.8047924637794495,
                0.7923522591590881,
                0.843544602394104,
                0.7888596057891846,
                0.8223982453346252,
                0.737804651260376,
                0.8238063454627991,
                0.8177545070648193,
                0.7944180965423584,
                0.811822235584259,
                0.862903892993927,
                0.805483877658844,
                0.8529996275901794,
                0.8399724364280701,
                0.858401894569397
            ],
            [
                0.759212851524353,
                0.8042356371879578,
                0.837160587310791,
                0.7343125343322754,
                0.7750987410545349,
                0.8081034421920776,
                0.7185677289962769,
                0.7531437873840332,
                0.7849116921424866,
                0.6999905705451965,
                0.7774379253387451,
                0.8119862675666809,
                0.820130467414856,
                0.7192246317863464,
                0.7761566042900085,
                0.7968649864196777,
                0.7653186321258545,
                0.8147866725921631,
                0.776157021522522,
                0.8059174418449402,
                0.8079564571380615,
                0.7575323581695557,
                0.8254971504211426,
                0.7995443940162659,
                0.8054714798927307,
                0.8188473582267761,
                0.7831361293792725,
                0.8142670392990112,
                0.7846621870994568,
                0.7898368835449219,
                0.7787375450134277,
                0.7874978184700012,
                0.8073112964630127,
                0.7172689437866211,
                0.7848217487335205,
                0.7720022797584534,
                0.7899020314216614,
                0.8085536360740662,
                0.8197505474090576,
                0.7907708287239075,
                0.8090766668319702,
                0.7351080179214478,
                0.7059769034385681,
                0.7581062912940979,
                0.8025427460670471,
                0.8250983953475952,
                0.7905444502830505,
                0.811707615852356,
                0.8007990717887878,
                0.7209609150886536,
                0.7546799182891846
            ],
            [
                0.7856752872467041,
                0.8320412635803223,
                0.8607320189476013,
                0.7362754344940186,
                0.7808279395103455,
                0.8524817228317261,
                0.7068061232566833,
                0.7578357458114624,
                0.8451507091522217,
                0.6991806030273438,
                0.8623172044754028,
                0.8589746952056885,
                0.8651178479194641,
                0.7039610147476196,
                0.7540391683578491,
                0.8104366064071655,
                0.757280170917511,
                0.8183677196502686,
                0.7714042663574219,
                0.8092856407165527,
                0.8097710609436035,
                0.7477734684944153,
                0.852259635925293,
                0.8173683881759644,
                0.7748340964317322,
                0.8514358997344971,
                0.7859815359115601,
                0.8447688221931458,
                0.7431511282920837,
                0.7314521074295044,
                0.7880601286888123,
                0.7826946377754211,
                0.7827768921852112,
                0.6935716867446899,
                0.748600423336029,
                0.7685896754264832,
                0.7784330248832703,
                0.8510015606880188,
                0.8175273537635803,
                0.8367689251899719,
                0.7919033765792847,
                0.741283655166626,
                0.666356086730957,
                0.7312119007110596,
                0.827660083770752,
                0.8475884795188904,
                0.8034114837646484,
                0.7808960676193237,
                0.816106379032135,
                0.7285996079444885,
                0.7429943680763245
            ],
            [
                0.771747350692749,
                0.7164032459259033,
                0.7428480386734009,
                0.8564537763595581,
                0.8490399122238159,
                0.7813127636909485,
                0.8183553814888,
                0.8263184428215027,
                0.7299857139587402,
                0.811540424823761,
                0.6912591457366943,
                0.7348332405090332,
                0.7525482773780823,
                0.7599582076072693,
                0.8150924444198608,
                0.8188655376434326,
                0.8488401770591736,
                0.7508010864257812,
                0.8337349891662598,
                0.8014880418777466,
                0.759040892124176,
                0.8593513369560242,
                0.7705432772636414,
                0.8427226543426514,
                0.828470766544342,
                0.8040695190429688,
                0.8359005451202393,
                0.8234779834747314,
                0.7048003077507019,
                0.834338366985321,
                0.8397704362869263,
                0.8327036499977112,
                0.837662398815155,
                0.6781764626502991,
                0.7688634395599365,
                0.7717998623847961,
                0.7951998114585876,
                0.7909362316131592,
                0.8354815244674683,
                0.7797691822052002,
                0.8080461025238037,
                0.7475469708442688,
                0.8106658458709717,
                0.7968853116035461,
                0.790658175945282,
                0.8144558072090149,
                0.8426344394683838,
                0.8130872845649719,
                0.8636710047721863,
                0.832955539226532,
                0.8596401214599609
            ],
            [
                0.751539409160614,
                0.8106464147567749,
                0.8210784792900085,
                0.7494378685951233,
                0.7795354127883911,
                0.8299580216407776,
                0.7559367418289185,
                0.7749735116958618,
                0.7917278409004211,
                0.7519460916519165,
                0.7330098748207092,
                0.8074404001235962,
                0.8073204159736633,
                0.7162564396858215,
                0.7959367036819458,
                0.8212224245071411,
                0.7841283082962036,
                0.8330050706863403,
                0.8292843103408813,
                0.8035376667976379,
                0.810092568397522,
                0.7861446142196655,
                0.829099714756012,
                0.8116154074668884,
                0.8193251490592957,
                0.8210848569869995,
                0.7896227240562439,
                0.8137854337692261,
                0.76470547914505,
                0.7982470989227295,
                0.7956504225730896,
                0.8131819367408752,
                0.8131546378135681,
                0.7244029641151428,
                0.7903858423233032,
                0.7686588764190674,
                0.7702651023864746,
                0.8092377781867981,
                0.8203776478767395,
                0.7938922047615051,
                0.8143050670623779,
                0.748485267162323,
                0.7452937960624695,
                0.7568163871765137,
                0.7904676198959351,
                0.8300749063491821,
                0.7934679985046387,
                0.8360225558280945,
                0.82391357421875,
                0.744530200958252,
                0.7670228481292725
            ],
            [
                0.8220001459121704,
                0.8479613065719604,
                0.8598608374595642,
                0.8217864036560059,
                0.8379824757575989,
                0.9020953178405762,
                0.7847667932510376,
                0.8154776692390442,
                0.8397931456565857,
                0.7839502692222595,
                0.8102462291717529,
                0.8705559968948364,
                0.8645426034927368,
                0.7447488903999329,
                0.8092339038848877,
                0.8495661020278931,
                0.8325262069702148,
                0.8530851602554321,
                0.8567134141921997,
                0.8413598537445068,
                0.8486487865447998,
                0.8274180293083191,
                0.8771330118179321,
                0.870994508266449,
                0.8469110131263733,
                0.8793224096298218,
                0.8477108478546143,
                0.8818227052688599,
                0.7590782046318054,
                0.793975830078125,
                0.8449545502662659,
                0.8454091548919678,
                0.8360816836357117,
                0.7082337141036987,
                0.8035576343536377,
                0.8192827105522156,
                0.8051047325134277,
                0.8862434029579163,
                0.860795795917511,
                0.8444787859916687,
                0.8328945636749268,
                0.7689267992973328,
                0.7489140033721924,
                0.7715335488319397,
                0.8572719693183899,
                0.8965262770652771,
                0.8618326187133789,
                0.8251860737800598,
                0.8906538486480713,
                0.7996001839637756,
                0.8272830843925476
            ],
            [
                0.7645012140274048,
                0.7956596612930298,
                0.8194992542266846,
                0.796512246131897,
                0.8191137909889221,
                0.8244504332542419,
                0.7950572967529297,
                0.8010112643241882,
                0.7946786284446716,
                0.7861508727073669,
                0.7231383323669434,
                0.8060712814331055,
                0.805948793888092,
                0.7380936741828918,
                0.8205835819244385,
                0.8297616839408875,
                0.8107830882072449,
                0.8103240132331848,
                0.829313337802887,
                0.8251556158065796,
                0.8047018051147461,
                0.8226326107978821,
                0.827048122882843,
                0.8306397199630737,
                0.8518412709236145,
                0.8270586133003235,
                0.8164170384407043,
                0.8314363956451416,
                0.7615919709205627,
                0.8206148147583008,
                0.8170782923698425,
                0.8314238786697388,
                0.8359470367431641,
                0.7075527906417847,
                0.7871819138526917,
                0.7668248414993286,
                0.7981992363929749,
                0.8123825788497925,
                0.8410447835922241,
                0.8101587295532227,
                0.8425713777542114,
                0.7551387548446655,
                0.7880780696868896,
                0.7809332609176636,
                0.8015328645706177,
                0.8397192358970642,
                0.8294702768325806,
                0.8439486622810364,
                0.8235006332397461,
                0.7641922831535339,
                0.7906067967414856
            ],
            [
                0.8262816667556763,
                0.8669777512550354,
                0.8818132877349854,
                0.8557124733924866,
                0.8514359593391418,
                0.9157961010932922,
                0.8221338391304016,
                0.8493844270706177,
                0.8490729331970215,
                0.8197329640388489,
                0.8100458979606628,
                0.8896926045417786,
                0.8815396428108215,
                0.7392346858978271,
                0.840837836265564,
                0.8655577898025513,
                0.8616983294487,
                0.8717923760414124,
                0.8648079633712769,
                0.8637185096740723,
                0.8709207773208618,
                0.8509981632232666,
                0.8828192949295044,
                0.8948679566383362,
                0.8469629287719727,
                0.8749459385871887,
                0.8730918169021606,
                0.8886368870735168,
                0.7707033157348633,
                0.8120985627174377,
                0.864923357963562,
                0.8639709949493408,
                0.8534504175186157,
                0.7266150712966919,
                0.81638503074646,
                0.8253157734870911,
                0.8133442997932434,
                0.8942744135856628,
                0.8817600011825562,
                0.8619195222854614,
                0.8488225936889648,
                0.7731091380119324,
                0.7658182382583618,
                0.801517128944397,
                0.8839859962463379,
                0.9070335030555725,
                0.8762155175209045,
                0.8387850522994995,
                0.8927363157272339,
                0.818146288394928,
                0.8476880192756653
            ],
            [
                0.733643651008606,
                0.7756760716438293,
                0.8083499073982239,
                0.7526186108589172,
                0.7897043228149414,
                0.8020066618919373,
                0.7525733113288879,
                0.767512321472168,
                0.7757120132446289,
                0.736953616142273,
                0.7314037680625916,
                0.7908623218536377,
                0.7841712236404419,
                0.7150343060493469,
                0.8147000670433044,
                0.8170086145401001,
                0.7771670818328857,
                0.7933107018470764,
                0.8016133308410645,
                0.7936479449272156,
                0.7895865440368652,
                0.7843468189239502,
                0.8086797595024109,
                0.7957299947738647,
                0.8292555212974548,
                0.8010052442550659,
                0.7880470752716064,
                0.7962193489074707,
                0.7421289086341858,
                0.8105848431587219,
                0.788752555847168,
                0.8089491128921509,
                0.8169196844100952,
                0.6865956783294678,
                0.7781107425689697,
                0.7576397657394409,
                0.774998128414154,
                0.785917341709137,
                0.8201409578323364,
                0.7699159383773804,
                0.8268693685531616,
                0.719284176826477,
                0.7528641223907471,
                0.7326943278312683,
                0.7807949185371399,
                0.8118024468421936,
                0.7970284819602966,
                0.8121778964996338,
                0.7950834631919861,
                0.748763918876648,
                0.7615943551063538
            ],
            [
                0.8211269378662109,
                0.8360046744346619,
                0.8760020136833191,
                0.8233130574226379,
                0.8515968918800354,
                0.8655366897583008,
                0.7755625247955322,
                0.818318784236908,
                0.8414437770843506,
                0.7670324444770813,
                0.8523448705673218,
                0.860623300075531,
                0.8711413741111755,
                0.7605190873146057,
                0.8406140208244324,
                0.8609600067138672,
                0.8317672610282898,
                0.840624988079071,
                0.8415406942367554,
                0.8509937524795532,
                0.8417435884475708,
                0.823896586894989,
                0.8761907815933228,
                0.8654744029045105,
                0.8345252871513367,
                0.8652539253234863,
                0.856677234172821,
                0.8694531917572021,
                0.7747564315795898,
                0.8192397952079773,
                0.8499519228935242,
                0.8496944308280945,
                0.8548779487609863,
                0.7281612157821655,
                0.7978045344352722,
                0.8108896613121033,
                0.8266249895095825,
                0.8721954226493835,
                0.8748107552528381,
                0.8521445989608765,
                0.8533512949943542,
                0.7752284407615662,
                0.7574669718742371,
                0.7667213082313538,
                0.8684669137001038,
                0.8716146349906921,
                0.8565518856048584,
                0.8195507526397705,
                0.8799105882644653,
                0.8175106048583984,
                0.8208974599838257
            ],
            [
                0.7862421870231628,
                0.7810695767402649,
                0.8184040188789368,
                0.8681340217590332,
                0.9002525806427002,
                0.8473525643348694,
                0.8494572043418884,
                0.8714560270309448,
                0.8152694702148438,
                0.8306040167808533,
                0.7634553909301758,
                0.8116901516914368,
                0.8137112855911255,
                0.7418373823165894,
                0.89701908826828,
                0.8920300602912903,
                0.8847163915634155,
                0.7914482355117798,
                0.8590995073318481,
                0.8504250645637512,
                0.8238394260406494,
                0.8873859643936157,
                0.849236011505127,
                0.8896730542182922,
                0.9129387140274048,
                0.8842753171920776,
                0.8856204748153687,
                0.8768680691719055,
                0.7483900785446167,
                0.8937329649925232,
                0.8939614295959473,
                0.9006660580635071,
                0.9004634618759155,
                0.6818053722381592,
                0.8194410800933838,
                0.8108676671981812,
                0.8540234565734863,
                0.8494296073913574,
                0.9287673830986023,
                0.828924834728241,
                0.9178478717803955,
                0.7509396076202393,
                0.868294894695282,
                0.7715762853622437,
                0.8272204995155334,
                0.8706168532371521,
                0.8938918113708496,
                0.8264186382293701,
                0.8640002012252808,
                0.8463737368583679,
                0.8668004274368286
            ],
            [
                0.7980197072029114,
                0.8306981325149536,
                0.8553512096405029,
                0.8122811317443848,
                0.8426878452301025,
                0.8599189519882202,
                0.8058775663375854,
                0.8319116234779358,
                0.8669674396514893,
                0.8046824336051941,
                0.8158045411109924,
                0.8646309971809387,
                0.8723903298377991,
                0.7500870823860168,
                0.8441585302352905,
                0.8612475991249084,
                0.85145503282547,
                0.8462879657745361,
                0.844582736492157,
                0.8566077351570129,
                0.8446437120437622,
                0.8389377593994141,
                0.8777909874916077,
                0.8767402172088623,
                0.8495402336120605,
                0.8824409246444702,
                0.8428144454956055,
                0.8708919286727905,
                0.8037331700325012,
                0.8605304956436157,
                0.874829113483429,
                0.881582498550415,
                0.8830779790878296,
                0.7463912963867188,
                0.8199547529220581,
                0.8076475858688354,
                0.8561728596687317,
                0.863313615322113,
                0.9104154109954834,
                0.8637632727622986,
                0.8934537172317505,
                0.7923406362533569,
                0.802055299282074,
                0.7763318419456482,
                0.8388147950172424,
                0.8650603890419006,
                0.841799795627594,
                0.8561257719993591,
                0.8643689155578613,
                0.792143702507019,
                0.8150922656059265
            ],
            [
                0.748980700969696,
                0.7861722707748413,
                0.8191152811050415,
                0.8230354189872742,
                0.8606880307197571,
                0.8265271186828613,
                0.8020076155662537,
                0.8567237257957458,
                0.8232885599136353,
                0.8001359105110168,
                0.7604401111602783,
                0.8221999406814575,
                0.8324288129806519,
                0.7569782733917236,
                0.8521225452423096,
                0.8563925623893738,
                0.8476043939590454,
                0.799456000328064,
                0.8199283480644226,
                0.8318125605583191,
                0.8036999106407166,
                0.852558434009552,
                0.8290949463844299,
                0.8614630103111267,
                0.8448048830032349,
                0.8428343534469604,
                0.8221035599708557,
                0.8612650036811829,
                0.7664174437522888,
                0.855898916721344,
                0.8565056920051575,
                0.8612393140792847,
                0.8697603344917297,
                0.726880669593811,
                0.794108510017395,
                0.7689165472984314,
                0.8332881331443787,
                0.8161022067070007,
                0.9003593325614929,
                0.8397861123085022,
                0.8963775038719177,
                0.7605713605880737,
                0.8149192929267883,
                0.8090925812721252,
                0.792392373085022,
                0.8303337097167969,
                0.8385806679725647,
                0.8376108407974243,
                0.8446033596992493,
                0.7904673218727112,
                0.8136153817176819
            ],
            [
                0.8277921676635742,
                0.8690366744995117,
                0.8965578079223633,
                0.8801468014717102,
                0.8740150928497314,
                0.9187039136886597,
                0.850646436214447,
                0.8707324266433716,
                0.8894160985946655,
                0.8488193154335022,
                0.8499389290809631,
                0.8992807865142822,
                0.9048943519592285,
                0.7681982517242432,
                0.860341489315033,
                0.886498749256134,
                0.8887050151824951,
                0.8744404315948486,
                0.8630785942077637,
                0.8743857741355896,
                0.8656367063522339,
                0.8774241209030151,
                0.8932046890258789,
                0.9106765389442444,
                0.8614310026168823,
                0.8900086879730225,
                0.8654864430427551,
                0.9038439393043518,
                0.7908129692077637,
                0.8509715795516968,
                0.8956707119941711,
                0.8867840766906738,
                0.8832730650901794,
                0.7569550275802612,
                0.8148593902587891,
                0.8193072080612183,
                0.8451828360557556,
                0.8961675763130188,
                0.9272482395172119,
                0.8958342671394348,
                0.9006119966506958,
                0.7782759070396423,
                0.792323887348175,
                0.8271226286888123,
                0.86115562915802,
                0.8998440504074097,
                0.8774388432502747,
                0.858324408531189,
                0.9064416289329529,
                0.8263682126998901,
                0.8651052713394165
            ],
            [
                0.7527561783790588,
                0.7622658610343933,
                0.7856019735336304,
                0.8495598435401917,
                0.8675381541252136,
                0.825495719909668,
                0.8699232339859009,
                0.8657189011573792,
                0.7840973138809204,
                0.8416489362716675,
                0.6976497173309326,
                0.7811998128890991,
                0.7815219163894653,
                0.7115318775177002,
                0.8648027181625366,
                0.8699864149093628,
                0.8905331492424011,
                0.7892472147941589,
                0.8477197885513306,
                0.8296509385108948,
                0.8151664137840271,
                0.8871356248855591,
                0.82320237159729,
                0.874661386013031,
                0.864162266254425,
                0.8619849681854248,
                0.8560362458229065,
                0.8501696586608887,
                0.7341589331626892,
                0.8751136064529419,
                0.8945187926292419,
                0.8970579504966736,
                0.873434841632843,
                0.6556760668754578,
                0.8240288496017456,
                0.8014513850212097,
                0.8456724286079407,
                0.8219477534294128,
                0.898636519908905,
                0.809816837310791,
                0.87264084815979,
                0.7298263311386108,
                0.8642632365226746,
                0.7929009199142456,
                0.7919651865959167,
                0.8249114155769348,
                0.8634927868843079,
                0.8173854351043701,
                0.8442140221595764,
                0.8332824110984802,
                0.8631824851036072
            ],
            [
                0.7414671182632446,
                0.7825262546539307,
                0.7996357083320618,
                0.8674225211143494,
                0.8731510043144226,
                0.8408884406089783,
                0.8897523283958435,
                0.9052371978759766,
                0.825258731842041,
                0.8805060386657715,
                0.700093686580658,
                0.7986153364181519,
                0.8168638348579407,
                0.7351033687591553,
                0.8841346502304077,
                0.8908072113990784,
                0.9085198640823364,
                0.8009897470474243,
                0.853385329246521,
                0.8631376028060913,
                0.8086801171302795,
                0.9099960923194885,
                0.8337904214859009,
                0.8986005783081055,
                0.8623067736625671,
                0.8698054552078247,
                0.8518330454826355,
                0.8771181106567383,
                0.752185583114624,
                0.8610188364982605,
                0.9089022278785706,
                0.9118313789367676,
                0.8899092674255371,
                0.6993159055709839,
                0.7896844148635864,
                0.7616203427314758,
                0.8511971831321716,
                0.8293951749801636,
                0.9174644947052002,
                0.8506399393081665,
                0.9079986810684204,
                0.7642090320587158,
                0.8772696256637573,
                0.8418739438056946,
                0.7878558039665222,
                0.8366401791572571,
                0.8775134682655334,
                0.830238938331604,
                0.8635087013244629,
                0.8397855758666992,
                0.8527173399925232
            ],
            [
                0.8480578660964966,
                0.8480892777442932,
                0.87486732006073,
                0.8929372429847717,
                0.8895505666732788,
                0.8810195326805115,
                0.8379372954368591,
                0.8828566670417786,
                0.856842577457428,
                0.857707142829895,
                0.8210925459861755,
                0.8591151237487793,
                0.8871613144874573,
                0.8003372550010681,
                0.8676009178161621,
                0.8835166692733765,
                0.9023503661155701,
                0.8500364422798157,
                0.8526825904846191,
                0.8892250061035156,
                0.8421050906181335,
                0.8877500891685486,
                0.8785383701324463,
                0.8971837759017944,
                0.8625280857086182,
                0.8809568285942078,
                0.8651697635650635,
                0.9083148241043091,
                0.8217021226882935,
                0.8594383001327515,
                0.8928976058959961,
                0.8841497898101807,
                0.900776743888855,
                0.7822110056877136,
                0.7929573655128479,
                0.7940497398376465,
                0.874709963798523,
                0.8728027939796448,
                0.913737952709198,
                0.8720189332962036,
                0.8995804190635681,
                0.8082745671272278,
                0.8252478241920471,
                0.8487854599952698,
                0.8597505688667297,
                0.8869307637214661,
                0.8818490505218506,
                0.8709490895271301,
                0.9037824869155884,
                0.8291154503822327,
                0.8591136932373047
            ],
            [
                0.7495036125183105,
                0.7664840817451477,
                0.8002647757530212,
                0.8338481187820435,
                0.8759832382202148,
                0.8300053477287292,
                0.8396196365356445,
                0.8608197569847107,
                0.7922318577766418,
                0.8137654662132263,
                0.7380378246307373,
                0.78955078125,
                0.7968907952308655,
                0.7246349453926086,
                0.8707695603370667,
                0.8845525979995728,
                0.8664212822914124,
                0.7851270437240601,
                0.8240714073181152,
                0.8226491808891296,
                0.8134818077087402,
                0.8680207133293152,
                0.8320344686508179,
                0.8784474730491638,
                0.8665428757667542,
                0.8670064806938171,
                0.8493900299072266,
                0.8556973338127136,
                0.7359941005706787,
                0.8598825931549072,
                0.8870716094970703,
                0.8904915452003479,
                0.871078610420227,
                0.6659554839134216,
                0.8254303336143494,
                0.8000503778457642,
                0.8511906862258911,
                0.8314087986946106,
                0.898293673992157,
                0.8047194480895996,
                0.8783472180366516,
                0.737784206867218,
                0.8546673655509949,
                0.777717113494873,
                0.8076745867729187,
                0.8384512662887573,
                0.8649012446403503,
                0.8241187930107117,
                0.8449521660804749,
                0.8223583102226257,
                0.8403961062431335
            ],
            [
                0.7362332940101624,
                0.7558225393295288,
                0.7836575508117676,
                0.798599362373352,
                0.8396636247634888,
                0.7901001572608948,
                0.7899260520935059,
                0.8316401839256287,
                0.757197916507721,
                0.776763379573822,
                0.7313482165336609,
                0.765130877494812,
                0.791982889175415,
                0.731828510761261,
                0.8306123614311218,
                0.8486799597740173,
                0.8305612802505493,
                0.7827939987182617,
                0.80552077293396,
                0.807101309299469,
                0.7795748710632324,
                0.8209432363510132,
                0.8080657720565796,
                0.839181125164032,
                0.8374075293540955,
                0.8356099724769592,
                0.8103688955307007,
                0.834607720375061,
                0.758091926574707,
                0.851943850517273,
                0.8466370701789856,
                0.8491011261940002,
                0.8556249141693115,
                0.7019344568252563,
                0.7919629216194153,
                0.7546437382698059,
                0.8536422848701477,
                0.7933176755905151,
                0.8762854933738708,
                0.7881719470024109,
                0.8585980534553528,
                0.7547090649604797,
                0.8238481879234314,
                0.7669996619224548,
                0.7664475440979004,
                0.8094650506973267,
                0.824317991733551,
                0.825437605381012,
                0.8141354918479919,
                0.7629785537719727,
                0.7919557094573975
            ],
            [
                0.8598338961601257,
                0.8624733090400696,
                0.8841877579689026,
                0.9033097624778748,
                0.8958450555801392,
                0.9078720808029175,
                0.8722937107086182,
                0.8872607946395874,
                0.8626364469528198,
                0.8806592226028442,
                0.8123946189880371,
                0.8736303448677063,
                0.8908903002738953,
                0.8013960123062134,
                0.8720918297767639,
                0.8978210687637329,
                0.9099860787391663,
                0.8609325289726257,
                0.8735261559486389,
                0.9028134346008301,
                0.8490336537361145,
                0.9011265635490417,
                0.8919649124145508,
                0.9159001111984253,
                0.8679320812225342,
                0.8967577219009399,
                0.8812048435211182,
                0.916465163230896,
                0.8183659315109253,
                0.8539184927940369,
                0.9051715135574341,
                0.8950627446174622,
                0.8958994746208191,
                0.7604619264602661,
                0.7915155291557312,
                0.7973034977912903,
                0.8751910328865051,
                0.8832248449325562,
                0.9208084344863892,
                0.8900025486946106,
                0.8979615569114685,
                0.8130810260772705,
                0.8348667025566101,
                0.8604902625083923,
                0.866065502166748,
                0.9011297225952148,
                0.8914652466773987,
                0.8794024586677551,
                0.9146275520324707,
                0.8419895172119141,
                0.8688496351242065
            ],
            [
                0.7751536965370178,
                0.8329998850822449,
                0.857183039188385,
                0.7938351631164551,
                0.8134148120880127,
                0.8635826110839844,
                0.7947425842285156,
                0.8077511787414551,
                0.8250290155410767,
                0.8084553480148315,
                0.7239635586738586,
                0.8410571813583374,
                0.8382717370986938,
                0.7387173175811768,
                0.8114907741546631,
                0.8323959708213806,
                0.8019262552261353,
                0.8228286504745483,
                0.8279621005058289,
                0.8367225527763367,
                0.8155922889709473,
                0.8230711817741394,
                0.8464857339859009,
                0.8369898200035095,
                0.8301149010658264,
                0.8337446451187134,
                0.812389075756073,
                0.8315725326538086,
                0.762860119342804,
                0.7751956582069397,
                0.810174822807312,
                0.8230441212654114,
                0.808142364025116,
                0.7102004885673523,
                0.7624174952507019,
                0.7514017820358276,
                0.7691121697425842,
                0.8183940649032593,
                0.8312475681304932,
                0.8256844282150269,
                0.836784303188324,
                0.7677894234657288,
                0.773353099822998,
                0.8018163442611694,
                0.8173040151596069,
                0.8514550924301147,
                0.8219352960586548,
                0.8421437740325928,
                0.829852819442749,
                0.7631843686103821,
                0.7693248391151428
            ],
            [
                0.8469363451004028,
                0.86459881067276,
                0.8896403312683105,
                0.8230435848236084,
                0.846773624420166,
                0.8918769359588623,
                0.7925121188163757,
                0.8217175006866455,
                0.8680614233016968,
                0.7827059030532837,
                0.859176516532898,
                0.8871350288391113,
                0.8875025510787964,
                0.7614902257919312,
                0.8214282393455505,
                0.8631488084793091,
                0.8335828185081482,
                0.8597074747085571,
                0.8432685732841492,
                0.8544865846633911,
                0.8556414842605591,
                0.830714762210846,
                0.8891345262527466,
                0.8768175840377808,
                0.8372609615325928,
                0.8856912851333618,
                0.8575518131256104,
                0.8877987861633301,
                0.7861495018005371,
                0.8112328052520752,
                0.8554975390434265,
                0.8505842685699463,
                0.8498131036758423,
                0.734564483165741,
                0.8141391277313232,
                0.8230287432670593,
                0.8327000737190247,
                0.8905050754547119,
                0.8795106410980225,
                0.8613625168800354,
                0.8529367446899414,
                0.7931674718856812,
                0.7540062665939331,
                0.7807543277740479,
                0.8780848383903503,
                0.8968797922134399,
                0.8577494025230408,
                0.832675039768219,
                0.8823341727256775,
                0.806361198425293,
                0.8296123743057251
            ],
            [
                0.7424451112747192,
                0.7783612608909607,
                0.799241304397583,
                0.7621222138404846,
                0.7830651998519897,
                0.799897313117981,
                0.7660479545593262,
                0.7657216191291809,
                0.7797561287879944,
                0.7599105834960938,
                0.7178014516830444,
                0.788385272026062,
                0.781424343585968,
                0.7115212678909302,
                0.7943140864372253,
                0.8078067302703857,
                0.7792907953262329,
                0.8019312620162964,
                0.8099777698516846,
                0.7948029637336731,
                0.7872759103775024,
                0.7939750552177429,
                0.8134683966636658,
                0.8029083013534546,
                0.8329246044158936,
                0.8041322827339172,
                0.7890336513519287,
                0.8020482063293457,
                0.7556520700454712,
                0.8000307083129883,
                0.7897937893867493,
                0.805561363697052,
                0.8088515400886536,
                0.6867299675941467,
                0.7722971439361572,
                0.7552342414855957,
                0.7710189819335938,
                0.7916588187217712,
                0.8164107799530029,
                0.7848519086837769,
                0.8211551308631897,
                0.7433145046234131,
                0.755759596824646,
                0.7447813749313354,
                0.7906725406646729,
                0.8253489136695862,
                0.8053008317947388,
                0.8212060332298279,
                0.804964542388916,
                0.7491785287857056,
                0.7670769691467285
            ],
            [
                0.8478196859359741,
                0.9051604270935059,
                0.908988356590271,
                0.8354372382164001,
                0.837670087814331,
                0.9353404641151428,
                0.8037654161453247,
                0.8272809982299805,
                0.8931071162223816,
                0.7985581159591675,
                0.8430721163749695,
                0.9293538331985474,
                0.9191096425056458,
                0.7088286280632019,
                0.8071542382240295,
                0.8584327697753906,
                0.8394697904586792,
                0.8889581561088562,
                0.8299461603164673,
                0.8512736558914185,
                0.8869678378105164,
                0.8317737579345703,
                0.9081552624702454,
                0.8903272747993469,
                0.8061322569847107,
                0.8760355710983276,
                0.8455865979194641,
                0.8880321979522705,
                0.7694544196128845,
                0.772546648979187,
                0.8509273529052734,
                0.8517062067985535,
                0.8232782483100891,
                0.7326886653900146,
                0.8198651075363159,
                0.8289519548416138,
                0.7908197641372681,
                0.9108216762542725,
                0.8686681389808655,
                0.8804106712341309,
                0.8437075614929199,
                0.7759462594985962,
                0.714703381061554,
                0.7935622334480286,
                0.884963870048523,
                0.8842069506645203,
                0.8363263607025146,
                0.8268527388572693,
                0.8946352005004883,
                0.8027636408805847,
                0.8338111639022827
            ],
            [
                0.8188337087631226,
                0.838699221611023,
                0.8340427875518799,
                0.8870072960853577,
                0.8706883788108826,
                0.8973413109779358,
                0.8399408459663391,
                0.8629755973815918,
                0.8020998239517212,
                0.8037995100021362,
                0.7295891046524048,
                0.8622709512710571,
                0.8457109928131104,
                0.6666655540466309,
                0.8615558743476868,
                0.8721637725830078,
                0.8924098014831543,
                0.8419095277786255,
                0.824700117111206,
                0.827709436416626,
                0.8997851014137268,
                0.8799683451652527,
                0.8673444986343384,
                0.8966832160949707,
                0.8634089827537537,
                0.8453390598297119,
                0.8930345773696899,
                0.8751122951507568,
                0.707447350025177,
                0.8268171548843384,
                0.8737488389015198,
                0.8720182180404663,
                0.8502882719039917,
                0.6649564504623413,
                0.8867588639259338,
                0.8807693123817444,
                0.7745734453201294,
                0.9005687236785889,
                0.8960111141204834,
                0.8248023390769958,
                0.8632296323776245,
                0.7349646091461182,
                0.766490638256073,
                0.7711963057518005,
                0.8777250647544861,
                0.855370044708252,
                0.8770758509635925,
                0.7848811149597168,
                0.8920082449913025,
                0.8645398616790771,
                0.9057050347328186
            ],
            [
                0.7798267602920532,
                0.7336333990097046,
                0.7641503810882568,
                0.8618278503417969,
                0.8623524904251099,
                0.790627121925354,
                0.8185001611709595,
                0.8361992835998535,
                0.7428054213523865,
                0.8095227479934692,
                0.721774160861969,
                0.7525948286056519,
                0.7723023891448975,
                0.7517368197441101,
                0.8322080969810486,
                0.8416333794593811,
                0.8491214513778687,
                0.7554646134376526,
                0.8193956017494202,
                0.8079912662506104,
                0.7697902917861938,
                0.8592547178268433,
                0.7843536734580994,
                0.8493870496749878,
                0.830086886882782,
                0.8065969944000244,
                0.842005729675293,
                0.8294016122817993,
                0.7151064276695251,
                0.8389140367507935,
                0.842571496963501,
                0.8381481170654297,
                0.8446252942085266,
                0.6775436997413635,
                0.7796763777732849,
                0.7766992449760437,
                0.807887077331543,
                0.7973323464393616,
                0.8465469479560852,
                0.7911277413368225,
                0.8196844458580017,
                0.745638370513916,
                0.8123476505279541,
                0.7937947511672974,
                0.8046457171440125,
                0.8137179017066956,
                0.8479381203651428,
                0.8189206123352051,
                0.8610249757766724,
                0.8388531804084778,
                0.8616963624954224
            ],
            [
                0.7549765706062317,
                0.7895430326461792,
                0.812231183052063,
                0.7849128246307373,
                0.8057894110679626,
                0.8296382427215576,
                0.7686702013015747,
                0.7894940376281738,
                0.7816061973571777,
                0.7744841575622559,
                0.7216715812683105,
                0.7927274107933044,
                0.7925782203674316,
                0.7091008424758911,
                0.8235946893692017,
                0.8436446189880371,
                0.8041068315505981,
                0.8011634349822998,
                0.8439488410949707,
                0.834710419178009,
                0.8127262592315674,
                0.8045583963394165,
                0.8222681283950806,
                0.8333421945571899,
                0.8103846311569214,
                0.8089285492897034,
                0.8111380934715271,
                0.8027710318565369,
                0.7412411570549011,
                0.7833528518676758,
                0.8033722639083862,
                0.8302714228630066,
                0.816092312335968,
                0.6894400119781494,
                0.7709530591964722,
                0.7743549346923828,
                0.7762104868888855,
                0.8129151463508606,
                0.818588137626648,
                0.7799969911575317,
                0.8243735432624817,
                0.7360857129096985,
                0.7669531106948853,
                0.7522715926170349,
                0.8248947262763977,
                0.836906373500824,
                0.8037900924682617,
                0.8244025111198425,
                0.8407504558563232,
                0.8022114634513855,
                0.7768567800521851
            ],
            [
                0.8052963614463806,
                0.9020313620567322,
                0.8966410160064697,
                0.7980968356132507,
                0.7982079982757568,
                0.9158952236175537,
                0.7956774234771729,
                0.8227934837341309,
                0.8893429040908813,
                0.8108494877815247,
                0.8135846257209778,
                0.9104252457618713,
                0.912223219871521,
                0.6579622030258179,
                0.7808142304420471,
                0.8520517349243164,
                0.8051595091819763,
                0.8822269439697266,
                0.8165068030357361,
                0.8402533531188965,
                0.8518607020378113,
                0.8022980690002441,
                0.8882293105125427,
                0.8743239641189575,
                0.7687008380889893,
                0.8566389679908752,
                0.8092188239097595,
                0.8702781796455383,
                0.7493107318878174,
                0.7248207330703735,
                0.8288664817810059,
                0.8240324258804321,
                0.788224458694458,
                0.6890796422958374,
                0.7603713274002075,
                0.76431804895401,
                0.7464829683303833,
                0.8818894624710083,
                0.8475363254547119,
                0.8891790509223938,
                0.8226613998413086,
                0.7522403001785278,
                0.6941413283348083,
                0.7821331024169922,
                0.8439406752586365,
                0.8627728223800659,
                0.8053058385848999,
                0.7978889346122742,
                0.8582087159156799,
                0.7744123935699463,
                0.7818775177001953
            ],
            [
                0.7480980157852173,
                0.7680075764656067,
                0.8032220005989075,
                0.7664153575897217,
                0.807746946811676,
                0.801776111125946,
                0.7663246393203735,
                0.7854086756706238,
                0.7712827324867249,
                0.7511643171310425,
                0.7370997071266174,
                0.7877156734466553,
                0.7896981239318848,
                0.6972222328186035,
                0.7952881455421448,
                0.8231747150421143,
                0.7874109745025635,
                0.7741715312004089,
                0.7905512452125549,
                0.7819123864173889,
                0.782374918460846,
                0.7906568646430969,
                0.810909628868103,
                0.809928297996521,
                0.8169718980789185,
                0.8191373348236084,
                0.7974124550819397,
                0.8092033267021179,
                0.7256340980529785,
                0.8075131177902222,
                0.8038932085037231,
                0.8173978328704834,
                0.8067469000816345,
                0.6593369245529175,
                0.7834765315055847,
                0.7622460126876831,
                0.8067228198051453,
                0.7873400449752808,
                0.8329154253005981,
                0.7686920166015625,
                0.8127596974372864,
                0.7061602473258972,
                0.7781975865364075,
                0.7347099781036377,
                0.7697191834449768,
                0.795464277267456,
                0.7924832701683044,
                0.7984652519226074,
                0.7955113649368286,
                0.7478817105293274,
                0.7706317901611328
            ],
            [
                0.8108490705490112,
                0.8661348819732666,
                0.8655421733856201,
                0.798838198184967,
                0.8081149458885193,
                0.91130530834198,
                0.7822564840316772,
                0.817756175994873,
                0.842307984828949,
                0.7843992114067078,
                0.77047199010849,
                0.8958072662353516,
                0.8781124949455261,
                0.6949734091758728,
                0.800268292427063,
                0.8386120796203613,
                0.8127495050430298,
                0.8615670800209045,
                0.8127830624580383,
                0.817572832107544,
                0.857757031917572,
                0.8156836032867432,
                0.8754669427871704,
                0.8723912239074707,
                0.7954979538917542,
                0.834534764289856,
                0.8347575068473816,
                0.8611042499542236,
                0.7235769033432007,
                0.7430825233459473,
                0.8338937163352966,
                0.8338838815689087,
                0.7935456037521362,
                0.6867023706436157,
                0.8062812089920044,
                0.8167399168014526,
                0.7423850893974304,
                0.8870912194252014,
                0.8512803912162781,
                0.8592267632484436,
                0.8222919702529907,
                0.7370998859405518,
                0.7034021019935608,
                0.7458022236824036,
                0.8665920495986938,
                0.8645458221435547,
                0.8263591527938843,
                0.7978464365005493,
                0.8732016682624817,
                0.7889408469200134,
                0.8023000359535217
            ],
            [
                0.762578010559082,
                0.7952288389205933,
                0.8085430860519409,
                0.7816234827041626,
                0.8095921874046326,
                0.8238939046859741,
                0.7804172039031982,
                0.7719370722770691,
                0.796112596988678,
                0.7685170769691467,
                0.7247609496116638,
                0.8015108108520508,
                0.8035843372344971,
                0.7147611379623413,
                0.7909689545631409,
                0.8076770901679993,
                0.7970912456512451,
                0.805657684803009,
                0.8242847323417664,
                0.8058246970176697,
                0.8078933954238892,
                0.8062361478805542,
                0.8336323499679565,
                0.8251148462295532,
                0.8440717458724976,
                0.8293231725692749,
                0.8103905916213989,
                0.8258742690086365,
                0.761581301689148,
                0.8228225111961365,
                0.8108446002006531,
                0.8282945156097412,
                0.81973797082901,
                0.6850725412368774,
                0.8054590821266174,
                0.790539026260376,
                0.79213547706604,
                0.8154361248016357,
                0.8334245681762695,
                0.7891294360160828,
                0.8279023170471191,
                0.736149787902832,
                0.7666320204734802,
                0.7600006461143494,
                0.7945547699928284,
                0.8286442160606384,
                0.8016713261604309,
                0.8388977646827698,
                0.8260326385498047,
                0.7574640512466431,
                0.7890297174453735
            ],
            [
                0.7602615356445312,
                0.7531235814094543,
                0.7841150760650635,
                0.788379430770874,
                0.8152426481246948,
                0.7848972082138062,
                0.7719079852104187,
                0.7789580821990967,
                0.780014157295227,
                0.7716227173805237,
                0.7260552048683167,
                0.7688775062561035,
                0.7776898145675659,
                0.7410830855369568,
                0.7864833474159241,
                0.8034079670906067,
                0.8013273477554321,
                0.7536581754684448,
                0.8015215396881104,
                0.7994797229766846,
                0.7586812376976013,
                0.803534209728241,
                0.8188820481300354,
                0.8172316551208496,
                0.8444564342498779,
                0.8520041108131409,
                0.8020782470703125,
                0.8298499584197998,
                0.7605921626091003,
                0.8345506191253662,
                0.8190519213676453,
                0.8313437104225159,
                0.8306571841239929,
                0.6726176142692566,
                0.7606436014175415,
                0.7507430911064148,
                0.8484658598899841,
                0.7910425066947937,
                0.8340430855751038,
                0.7777954339981079,
                0.8255693912506104,
                0.7315341234207153,
                0.8194469213485718,
                0.7701653838157654,
                0.7627513408660889,
                0.8102753758430481,
                0.7973648905754089,
                0.8306145071983337,
                0.8022081851959229,
                0.7363438010215759,
                0.7675082683563232
            ],
            [
                0.7463707327842712,
                0.7957538962364197,
                0.8163508176803589,
                0.7131698727607727,
                0.7516713738441467,
                0.8219990730285645,
                0.6895362138748169,
                0.7357414960861206,
                0.8281362056732178,
                0.6881182789802551,
                0.8481014370918274,
                0.8366320133209229,
                0.83511883020401,
                0.7042555212974548,
                0.7290205359458923,
                0.7793620228767395,
                0.7357656955718994,
                0.8085544109344482,
                0.7582939863204956,
                0.7702100872993469,
                0.7883709073066711,
                0.7274313569068909,
                0.8276386857032776,
                0.8205755352973938,
                0.7626749277114868,
                0.8452004790306091,
                0.7675837278366089,
                0.8411827683448792,
                0.7290690541267395,
                0.7263381481170654,
                0.7927333116531372,
                0.780021071434021,
                0.7621406316757202,
                0.6909968852996826,
                0.7630939483642578,
                0.7663211822509766,
                0.7692292928695679,
                0.8446393013000488,
                0.7984368205070496,
                0.8191881775856018,
                0.7667074799537659,
                0.7275782227516174,
                0.6525130271911621,
                0.7037677764892578,
                0.8119171261787415,
                0.8295584917068481,
                0.779638409614563,
                0.7747029066085815,
                0.8060967922210693,
                0.7272645831108093,
                0.7356414794921875
            ],
            [
                0.8167466521263123,
                0.8645253777503967,
                0.872696578502655,
                0.8237161040306091,
                0.8330054879188538,
                0.911137580871582,
                0.7976871728897095,
                0.8369461297988892,
                0.8661274313926697,
                0.8220574855804443,
                0.8076654076576233,
                0.8910250663757324,
                0.9059934020042419,
                0.7282863855361938,
                0.8060337901115417,
                0.8486056923866272,
                0.8383126854896545,
                0.8712891340255737,
                0.838212788105011,
                0.8395288586616516,
                0.850886881351471,
                0.8394289016723633,
                0.8784705996513367,
                0.8896401524543762,
                0.8042914271354675,
                0.8551208972930908,
                0.8310514688491821,
                0.8814083337783813,
                0.7607324123382568,
                0.7747055292129517,
                0.8514254689216614,
                0.8496175408363342,
                0.824068009853363,
                0.7195775508880615,
                0.7993601560592651,
                0.806621253490448,
                0.781851589679718,
                0.8886706829071045,
                0.8673887252807617,
                0.8878803849220276,
                0.8487355709075928,
                0.7691233158111572,
                0.7258202433586121,
                0.7920982241630554,
                0.8644293546676636,
                0.872511625289917,
                0.8320940732955933,
                0.8461526036262512,
                0.8893245458602905,
                0.788577675819397,
                0.8043010830879211
            ],
            [
                0.7479538917541504,
                0.7662211656570435,
                0.7968789339065552,
                0.8404279351234436,
                0.8607994318008423,
                0.8064100742340088,
                0.8433355689048767,
                0.8573398590087891,
                0.7814587354660034,
                0.8262524604797363,
                0.7138625383377075,
                0.7740089297294617,
                0.7979034781455994,
                0.7459326386451721,
                0.8595830202102661,
                0.8656312227249146,
                0.8611088991165161,
                0.7850310802459717,
                0.8397520184516907,
                0.8355081677436829,
                0.7897036671638489,
                0.8603973984718323,
                0.8257467150688171,
                0.8563693761825562,
                0.8586851954460144,
                0.8495551347732544,
                0.8374898433685303,
                0.8427026271820068,
                0.7515172362327576,
                0.8773496150970459,
                0.8632780909538269,
                0.865944504737854,
                0.8774259090423584,
                0.6950250267982483,
                0.7913839221000671,
                0.7645249366760254,
                0.8474724888801575,
                0.8025139570236206,
                0.8902174234390259,
                0.813641369342804,
                0.8690178394317627,
                0.7643008828163147,
                0.8532218933105469,
                0.8095055222511292,
                0.7790666818618774,
                0.8232300281524658,
                0.8484403491020203,
                0.8444796204566956,
                0.8335541486740112,
                0.8053015470504761,
                0.8288612365722656
            ],
            [
                0.8742901682853699,
                0.9009332060813904,
                0.9198940992355347,
                0.9110012650489807,
                0.8987464904785156,
                0.9324796199798584,
                0.8628785014152527,
                0.8870890736579895,
                0.8835740089416504,
                0.8569446206092834,
                0.824089527130127,
                0.9276777505874634,
                0.9274987578392029,
                0.7546143531799316,
                0.8730803728103638,
                0.9031025767326355,
                0.9121439456939697,
                0.8934502601623535,
                0.868626594543457,
                0.9066091179847717,
                0.8990164399147034,
                0.8928202986717224,
                0.9190967082977295,
                0.928951621055603,
                0.8488392233848572,
                0.8864132165908813,
                0.8939095735549927,
                0.9125661253929138,
                0.8050119876861572,
                0.8486396074295044,
                0.8966042399406433,
                0.9003071188926697,
                0.8870080709457397,
                0.7601738572120667,
                0.8337298631668091,
                0.8336543440818787,
                0.8506016135215759,
                0.9126482605934143,
                0.92989581823349,
                0.9045565128326416,
                0.9010999202728271,
                0.8032371401786804,
                0.7922925353050232,
                0.8533303737640381,
                0.8977795839309692,
                0.8970867395401001,
                0.8755744099617004,
                0.8588879704475403,
                0.9255821108818054,
                0.8564107418060303,
                0.8837652802467346
            ],
            [
                0.7539504170417786,
                0.7662954330444336,
                0.789167582988739,
                0.785135805606842,
                0.8269429206848145,
                0.7822014689445496,
                0.7665010690689087,
                0.8094857335090637,
                0.785580039024353,
                0.762932538986206,
                0.7415313124656677,
                0.7846185564994812,
                0.8078564405441284,
                0.7555124163627625,
                0.8100771903991699,
                0.8176873922348022,
                0.8184816837310791,
                0.7952351570129395,
                0.7947377562522888,
                0.8183534741401672,
                0.783462643623352,
                0.8113862872123718,
                0.8171280026435852,
                0.8325859308242798,
                0.8058528304100037,
                0.8262072205543518,
                0.7958133816719055,
                0.8329670429229736,
                0.7819147706031799,
                0.845000147819519,
                0.8358865976333618,
                0.8403077125549316,
                0.857695460319519,
                0.7380239963531494,
                0.7893528342247009,
                0.7634351253509521,
                0.8393802046775818,
                0.7951071262359619,
                0.8782853484153748,
                0.8089673519134521,
                0.8706433773040771,
                0.7881544828414917,
                0.7946555018424988,
                0.7839775085449219,
                0.765668511390686,
                0.7996600270271301,
                0.792018473148346,
                0.8297626376152039,
                0.8210310935974121,
                0.7540382742881775,
                0.7840600609779358
            ]
        ],
        [
            [
                0.8825228214263916,
                0.8805793523788452,
                0.7498015761375427,
                0.8463956713676453,
                0.7319459915161133,
                0.8472158312797546,
                0.6636095643043518,
                0.8293247818946838,
                0.7079929709434509,
                0.8591553568840027,
                0.6539419293403625,
                0.8231580257415771,
                0.7410303950309753,
                0.8376957774162292,
                0.7591558694839478,
                0.7771908044815063,
                0.6778532862663269,
                0.8574628829956055,
                0.8710573315620422,
                0.7326262593269348,
                0.7252665162086487,
                0.7347431778907776,
                0.7363924980163574,
                0.8618205189704895,
                0.7312482595443726,
                0.8384716510772705,
                0.762951672077179,
                0.8110007047653198,
                0.762866735458374,
                0.8241082429885864,
                0.7533137798309326,
                0.9034255146980286,
                0.7509116530418396,
                0.8501981496810913,
                0.7289122939109802,
                0.8089603185653687,
                0.7170262336730957,
                0.7367287874221802,
                0.7639152407646179,
                0.8475300669670105,
                0.750373363494873,
                0.876638650894165,
                0.733847975730896,
                0.8608067035675049,
                0.7524243593215942,
                0.7962480783462524,
                0.7025977969169617,
                0.8029426336288452,
                0.731929361820221,
                0.7390146851539612,
                0.7329265475273132
            ],
            [
                0.8283607959747314,
                0.8330730199813843,
                0.7763220071792603,
                0.7220100164413452,
                0.8048542737960815,
                0.7825638055801392,
                0.6549816131591797,
                0.7861518859863281,
                0.6759968996047974,
                0.806532621383667,
                0.6463407278060913,
                0.7887981534004211,
                0.7548027634620667,
                0.8045209646224976,
                0.8428694009780884,
                0.7833333611488342,
                0.6617873311042786,
                0.8390980362892151,
                0.8315446972846985,
                0.7656151652336121,
                0.7585819363594055,
                0.7688747644424438,
                0.7634789943695068,
                0.8266710638999939,
                0.7486661672592163,
                0.8356265425682068,
                0.822609007358551,
                0.8257132768630981,
                0.8138898611068726,
                0.8319019079208374,
                0.8110748529434204,
                0.7894068956375122,
                0.8551681041717529,
                0.8039356470108032,
                0.763115644454956,
                0.6398538947105408,
                0.8022096157073975,
                0.6144607663154602,
                0.8245924115180969,
                0.708053469657898,
                0.8243398666381836,
                0.7522969841957092,
                0.7665265202522278,
                0.8474270701408386,
                0.818787157535553,
                0.6536933779716492,
                0.7091833353042603,
                0.7324568629264832,
                0.8514689207077026,
                0.5952388644218445,
                0.7916630506515503
            ],
            [
                0.9022987484931946,
                0.9020022749900818,
                0.7977874875068665,
                0.8094685673713684,
                0.7789221405982971,
                0.8676487803459167,
                0.6894965767860413,
                0.8737133741378784,
                0.7155252695083618,
                0.8777442574501038,
                0.685791015625,
                0.8543930649757385,
                0.7633611559867859,
                0.910284161567688,
                0.8256868124008179,
                0.8558386564254761,
                0.6974000334739685,
                0.8911036252975464,
                0.8940048217773438,
                0.786017656326294,
                0.7842148542404175,
                0.7877829074859619,
                0.7859009504318237,
                0.9025055766105652,
                0.7841165661811829,
                0.8978341817855835,
                0.8258978724479675,
                0.8817996382713318,
                0.8250293731689453,
                0.8859682083129883,
                0.8206685781478882,
                0.8973630666732788,
                0.8201344609260559,
                0.8790730834007263,
                0.7711946964263916,
                0.776216983795166,
                0.7858424782752991,
                0.7004857659339905,
                0.8192106485366821,
                0.8195006847381592,
                0.8065119981765747,
                0.8365465998649597,
                0.7781586647033691,
                0.8971667885780334,
                0.8210377097129822,
                0.7754864692687988,
                0.7165946960449219,
                0.7975805997848511,
                0.8057880401611328,
                0.7234742045402527,
                0.7902467250823975
            ],
            [
                0.864864706993103,
                0.891396164894104,
                0.9772647023200989,
                0.8032065033912659,
                0.8364201784133911,
                0.832543671131134,
                0.7232434749603271,
                0.8709051609039307,
                0.7435704469680786,
                0.8690693378448486,
                0.6843445301055908,
                0.8568167090415955,
                0.8060859441757202,
                0.8181423544883728,
                0.8284193277359009,
                0.8397278785705566,
                0.7276772260665894,
                0.8790034651756287,
                0.8836854100227356,
                0.8275275826454163,
                0.8160953521728516,
                0.8320884704589844,
                0.8293814063072205,
                0.8861158490180969,
                0.8112421631813049,
                0.8991495966911316,
                0.8770686388015747,
                0.8820327520370483,
                0.8704261183738708,
                0.8845828175544739,
                0.8613731861114502,
                0.8435817956924438,
                0.8630539178848267,
                0.8882954716682434,
                0.8294107913970947,
                0.6873113512992859,
                0.8146890997886658,
                0.6653468012809753,
                0.8593142628669739,
                0.7740181088447571,
                0.8470413684844971,
                0.8184791207313538,
                0.8230974078178406,
                0.8881062865257263,
                0.8747380971908569,
                0.7558549642562866,
                0.7388628721237183,
                0.7467264533042908,
                0.8812354803085327,
                0.6502030491828918,
                0.8349342346191406
            ],
            [
                0.7859253287315369,
                0.8437485694885254,
                0.8392682075500488,
                0.7915319204330444,
                0.8617430329322815,
                0.8497990965843201,
                0.8718168139457703,
                0.7939529418945312,
                0.8760364651679993,
                0.8410158753395081,
                0.791999340057373,
                0.8727286458015442,
                0.8849889039993286,
                0.7518510222434998,
                0.8187694549560547,
                0.8261573314666748,
                0.868137776851654,
                0.7805452942848206,
                0.8224177956581116,
                0.8996147513389587,
                0.9084193110466003,
                0.919258713722229,
                0.920453667640686,
                0.8040407299995422,
                0.8744874596595764,
                0.7969521880149841,
                0.9034419059753418,
                0.7956495881080627,
                0.8984096050262451,
                0.8140508532524109,
                0.8898416757583618,
                0.7869731187820435,
                0.8285274505615234,
                0.8873055577278137,
                0.912947952747345,
                0.7000455856323242,
                0.7948712110519409,
                0.6986998319625854,
                0.8965714573860168,
                0.7877379655838013,
                0.8667773604393005,
                0.8484059572219849,
                0.8976600766181946,
                0.8069117665290833,
                0.8950186967849731,
                0.8047695159912109,
                0.8182079195976257,
                0.7570546865463257,
                0.8759620189666748,
                0.6402344107627869,
                0.8830188512802124
            ],
            [
                0.8424258828163147,
                0.8642209768295288,
                0.8253198266029358,
                0.7914184331893921,
                0.9352577924728394,
                0.8552072644233704,
                0.8335716724395752,
                0.8311728835105896,
                0.8397156596183777,
                0.8482630252838135,
                0.7856788635253906,
                0.8716518878936768,
                0.8964500427246094,
                0.8130609393119812,
                0.8472480773925781,
                0.842954158782959,
                0.8099422454833984,
                0.8432604074478149,
                0.8548721671104431,
                0.869307279586792,
                0.8781229257583618,
                0.8849239945411682,
                0.8811456561088562,
                0.8471328616142273,
                0.8588109612464905,
                0.8507713079452515,
                0.9035108089447021,
                0.8532958030700684,
                0.893848717212677,
                0.866869330406189,
                0.888373613357544,
                0.8205981254577637,
                0.9021222591400146,
                0.8688733577728271,
                0.8763248324394226,
                0.672391414642334,
                0.8286558389663696,
                0.6605706214904785,
                0.9052772521972656,
                0.7963943481445312,
                0.9067614674568176,
                0.8193418383598328,
                0.8800063133239746,
                0.8670623302459717,
                0.8960349559783936,
                0.7432447671890259,
                0.7867758870124817,
                0.7546024918556213,
                0.8978097438812256,
                0.6421340703964233,
                0.8759013414382935
            ],
            [
                0.8180680274963379,
                0.8428013920783997,
                0.7339661717414856,
                0.7971833944320679,
                0.740068256855011,
                0.8182534575462341,
                0.7094583511352539,
                0.8125752210617065,
                0.7325426340103149,
                0.8351849317550659,
                0.7241703867912292,
                0.8627829551696777,
                0.7835604548454285,
                0.8235905766487122,
                0.7482609152793884,
                0.8183914422988892,
                0.7010507583618164,
                0.8583499789237976,
                0.8654537200927734,
                0.7430554032325745,
                0.7476584315299988,
                0.7452188730239868,
                0.744843602180481,
                0.8544982075691223,
                0.7469398975372314,
                0.8421884775161743,
                0.7507766485214233,
                0.8449076414108276,
                0.7476915121078491,
                0.825039267539978,
                0.7410798668861389,
                0.8678855895996094,
                0.7396902441978455,
                0.8614660501480103,
                0.7279787063598633,
                0.7276980876922607,
                0.6831150650978088,
                0.6991404294967651,
                0.7514374256134033,
                0.8477420210838318,
                0.756685197353363,
                0.8373640775680542,
                0.7438721656799316,
                0.8234089612960815,
                0.7430827617645264,
                0.8084003925323486,
                0.7168710231781006,
                0.802325427532196,
                0.7357536554336548,
                0.7746741771697998,
                0.7430799603462219
            ],
            [
                0.8454701900482178,
                0.8749165534973145,
                0.8255184292793274,
                0.8646825551986694,
                0.8634260296821594,
                0.8798027038574219,
                0.8080084323883057,
                0.8714040517807007,
                0.8309692740440369,
                0.8920039534568787,
                0.7554739117622375,
                0.9066441059112549,
                0.8488659858703613,
                0.823237955570221,
                0.8363282680511475,
                0.8492826819419861,
                0.8266858458518982,
                0.8483074903488159,
                0.891635537147522,
                0.8745471835136414,
                0.881415605545044,
                0.8887248039245605,
                0.8839890956878662,
                0.8608510494232178,
                0.854978621006012,
                0.8652285933494568,
                0.8813208341598511,
                0.8387205004692078,
                0.8679402470588684,
                0.8692667484283447,
                0.8722732067108154,
                0.8576017022132874,
                0.850536048412323,
                0.8893505334854126,
                0.8826137185096741,
                0.7498732805252075,
                0.813043475151062,
                0.7729195356369019,
                0.8991638422012329,
                0.8391525745391846,
                0.8706541061401367,
                0.9001150727272034,
                0.9059066772460938,
                0.875993013381958,
                0.8746156692504883,
                0.843674898147583,
                0.8376873135566711,
                0.8385037183761597,
                0.8711240887641907,
                0.7235746383666992,
                0.8654487729072571
            ],
            [
                0.8221431374549866,
                0.8746368288993835,
                0.8301035761833191,
                0.852898895740509,
                0.8591985106468201,
                0.8672603964805603,
                0.8783711791038513,
                0.8410557508468628,
                0.8817734122276306,
                0.878801167011261,
                0.8066162467002869,
                0.9166924953460693,
                0.8877338171005249,
                0.8080551624298096,
                0.8172119855880737,
                0.8839285969734192,
                0.86896812915802,
                0.8221462368965149,
                0.8628979921340942,
                0.9086010456085205,
                0.9184762835502625,
                0.929767906665802,
                0.92686927318573,
                0.8427379131317139,
                0.8936452865600586,
                0.8395609259605408,
                0.9020280838012695,
                0.8305026292800903,
                0.895106315612793,
                0.8610484004020691,
                0.8890803456306458,
                0.8470340967178345,
                0.8510652780532837,
                0.9036887288093567,
                0.9236442446708679,
                0.7272990942001343,
                0.7978814244270325,
                0.7345889210700989,
                0.9072829484939575,
                0.8599331974983215,
                0.8846144676208496,
                0.8829599618911743,
                0.9174700975418091,
                0.8355035781860352,
                0.8903548717498779,
                0.8357831835746765,
                0.8347907066345215,
                0.8209754228591919,
                0.8733765482902527,
                0.6954517960548401,
                0.8971201777458191
            ],
            [
                0.8082095980644226,
                0.8357632756233215,
                0.7842426300048828,
                0.7827013731002808,
                0.8045790791511536,
                0.829893171787262,
                0.7791725397109985,
                0.8451415300369263,
                0.778252124786377,
                0.8653006553649902,
                0.723008394241333,
                0.8608193397521973,
                0.8000648617744446,
                0.8005519509315491,
                0.7915744781494141,
                0.843876838684082,
                0.7713583707809448,
                0.8172932267189026,
                0.8391357064247131,
                0.8335752487182617,
                0.8550455570220947,
                0.8527344465255737,
                0.8563316464424133,
                0.8311065435409546,
                0.8200164437294006,
                0.8329628109931946,
                0.8529837727546692,
                0.8237558603286743,
                0.850120484828949,
                0.8593006134033203,
                0.8545205593109131,
                0.7960417866706848,
                0.8490802049636841,
                0.8491460680961609,
                0.8407706618309021,
                0.7136066555976868,
                0.8138888478279114,
                0.7037217617034912,
                0.877483606338501,
                0.7767004370689392,
                0.840108335018158,
                0.8013715147972107,
                0.8559727072715759,
                0.8264429569244385,
                0.8513683676719666,
                0.7715329527854919,
                0.7645614147186279,
                0.7814585566520691,
                0.8507775664329529,
                0.6787558197975159,
                0.8434742093086243
            ],
            [
                0.865723729133606,
                0.8869446516036987,
                0.8105056881904602,
                0.7427822947502136,
                0.8133643865585327,
                0.8429984450340271,
                0.7136496305465698,
                0.8907405734062195,
                0.7152083516120911,
                0.8861072659492493,
                0.7200218439102173,
                0.8795592784881592,
                0.8089761734008789,
                0.8973920941352844,
                0.8615425229072571,
                0.8874768614768982,
                0.7166258096694946,
                0.9119181632995605,
                0.903235673904419,
                0.8030616641044617,
                0.8113501667976379,
                0.8081094622612,
                0.8029783964157104,
                0.9065262079238892,
                0.7978049516677856,
                0.9221829771995544,
                0.8523584604263306,
                0.91653972864151,
                0.8430867195129395,
                0.9226669073104858,
                0.855198323726654,
                0.8433955311775208,
                0.8567782640457153,
                0.8938993215560913,
                0.7865930199623108,
                0.715330183506012,
                0.8047983646392822,
                0.6594804525375366,
                0.8347148895263672,
                0.7603301405906677,
                0.8367970585823059,
                0.8089777827262878,
                0.8072277307510376,
                0.8947454690933228,
                0.8557579517364502,
                0.7239779829978943,
                0.7456398010253906,
                0.7918965816497803,
                0.870606541633606,
                0.6694576740264893,
                0.8276498317718506
            ],
            [
                0.769801914691925,
                0.8214284181594849,
                0.7890031337738037,
                0.8282344341278076,
                0.8220698237419128,
                0.8727755546569824,
                0.8640182018280029,
                0.8100001811981201,
                0.8744366765022278,
                0.8526568412780762,
                0.7776893377304077,
                0.8725920915603638,
                0.8509703278541565,
                0.7625600099563599,
                0.7976011633872986,
                0.8255438804626465,
                0.859690248966217,
                0.7727164626121521,
                0.8176550269126892,
                0.8739005327224731,
                0.8928772211074829,
                0.8947261571884155,
                0.8929463028907776,
                0.8036108016967773,
                0.8602679967880249,
                0.7973310351371765,
                0.8625534772872925,
                0.7854359149932861,
                0.8606093525886536,
                0.8102893829345703,
                0.8504465222358704,
                0.7878444194793701,
                0.7904358506202698,
                0.8624629974365234,
                0.887230396270752,
                0.7268728017807007,
                0.7705456614494324,
                0.7227399349212646,
                0.8781822919845581,
                0.8135472536087036,
                0.826636791229248,
                0.8491345643997192,
                0.8947362303733826,
                0.7945119738578796,
                0.8605594635009766,
                0.8315762281417847,
                0.8164175748825073,
                0.7836441397666931,
                0.8300206661224365,
                0.7048891186714172,
                0.8591461181640625
            ],
            [
                0.8925216794013977,
                0.9094510078430176,
                0.8788973093032837,
                0.8461198806762695,
                0.8200047612190247,
                0.8696904182434082,
                0.7429879903793335,
                0.9487613439559937,
                0.7581735849380493,
                0.9330098628997803,
                0.7162260413169861,
                0.9100313782691956,
                0.8046380281448364,
                0.8998676538467407,
                0.8410937786102295,
                0.9147334694862366,
                0.748629093170166,
                0.9126607179641724,
                0.9454016089439392,
                0.8391305208206177,
                0.8442180156707764,
                0.8495327234268188,
                0.8453877568244934,
                0.9323435425758362,
                0.8354802131652832,
                0.9309645295143127,
                0.8730982542037964,
                0.9078225493431091,
                0.8644531965255737,
                0.9355940818786621,
                0.8757935762405396,
                0.8937610387802124,
                0.8620479106903076,
                0.9151708483695984,
                0.8420560359954834,
                0.7664093375205994,
                0.8215555548667908,
                0.7605184316635132,
                0.8724726438522339,
                0.8383030891418457,
                0.8565001487731934,
                0.8840571641921997,
                0.8670090436935425,
                0.9301621913909912,
                0.8727151155471802,
                0.8301711082458496,
                0.7889191508293152,
                0.8641451597213745,
                0.8814460635185242,
                0.7597314715385437,
                0.8542165160179138
            ],
            [
                0.8634016513824463,
                0.8986105918884277,
                0.8772830367088318,
                0.7882654666900635,
                0.8722981810569763,
                0.8533676266670227,
                0.8098600506782532,
                0.8990203142166138,
                0.8034189939498901,
                0.8893506526947021,
                0.7620205879211426,
                0.8900318145751953,
                0.8647931218147278,
                0.8556985259056091,
                0.8690720796585083,
                0.8988468647003174,
                0.8018442988395691,
                0.8654540777206421,
                0.89530348777771,
                0.8876150846481323,
                0.8924942016601562,
                0.8959850072860718,
                0.9013010859489441,
                0.8898520469665527,
                0.874488353729248,
                0.8948346376419067,
                0.9343328475952148,
                0.8823707103729248,
                0.9236564040184021,
                0.908511757850647,
                0.9321256279945374,
                0.8556803464889526,
                0.9098442196846008,
                0.911226212978363,
                0.8909866809844971,
                0.7117185592651367,
                0.8423231244087219,
                0.7146240472793579,
                0.9139661192893982,
                0.7835068702697754,
                0.9154905080795288,
                0.8555002212524414,
                0.883368968963623,
                0.8986818790435791,
                0.930377185344696,
                0.7894364595413208,
                0.8241794109344482,
                0.8196007609367371,
                0.9345553517341614,
                0.6782161593437195,
                0.9018548130989075
            ],
            [
                0.7481454610824585,
                0.798041045665741,
                0.7349010705947876,
                0.738532304763794,
                0.8502465486526489,
                0.8322045803070068,
                0.8119710683822632,
                0.7320006489753723,
                0.8474776744842529,
                0.7834542989730835,
                0.7685067653656006,
                0.8112919330596924,
                0.8481530547142029,
                0.738391637802124,
                0.8137903809547424,
                0.7713381052017212,
                0.8203490972518921,
                0.7440480589866638,
                0.7707703113555908,
                0.8408111929893494,
                0.8452123403549194,
                0.8552041053771973,
                0.8497548699378967,
                0.7402400970458984,
                0.8364075422286987,
                0.7612231969833374,
                0.8607760071754456,
                0.7463380694389343,
                0.848639965057373,
                0.7510986328125,
                0.8359715342521667,
                0.7393805980682373,
                0.7871744632720947,
                0.8108412623405457,
                0.8479898571968079,
                0.6858548521995544,
                0.733735978603363,
                0.6669395565986633,
                0.8464334607124329,
                0.7543243169784546,
                0.8311865329742432,
                0.796501100063324,
                0.8438095450401306,
                0.7696242928504944,
                0.8504540920257568,
                0.7475441694259644,
                0.8041672110557556,
                0.7294602394104004,
                0.8145058751106262,
                0.6222394704818726,
                0.8283681273460388
            ],
            [
                0.8151068091392517,
                0.8357893824577332,
                0.7450464963912964,
                0.7144808173179626,
                0.6997761726379395,
                0.7967503070831299,
                0.6989206075668335,
                0.83326256275177,
                0.7069960236549377,
                0.8118877410888672,
                0.7103350758552551,
                0.8072253465652466,
                0.7314740419387817,
                0.8416144251823425,
                0.7865994572639465,
                0.8286129236221313,
                0.6838693022727966,
                0.8107380270957947,
                0.8143163323402405,
                0.7450945377349854,
                0.7585130929946899,
                0.7529970407485962,
                0.7582859992980957,
                0.8221136331558228,
                0.7703722715377808,
                0.8431981801986694,
                0.7798287868499756,
                0.833719789981842,
                0.7895111441612244,
                0.8281810283660889,
                0.7728684544563293,
                0.7968116998672485,
                0.7562275528907776,
                0.8264992833137512,
                0.7311074733734131,
                0.7210758924484253,
                0.7122607231140137,
                0.6830836534500122,
                0.7639477252960205,
                0.7295347452163696,
                0.746505081653595,
                0.7343525290489197,
                0.7295228242874146,
                0.7926894426345825,
                0.7760115265846252,
                0.7339708805084229,
                0.7121469974517822,
                0.7653856873512268,
                0.757941484451294,
                0.714644193649292,
                0.7593497037887573
            ],
            [
                0.8202060461044312,
                0.8468316793441772,
                0.7425171732902527,
                0.7201669812202454,
                0.7141044735908508,
                0.7935407757759094,
                0.6654003262519836,
                0.8452630639076233,
                0.6725773811340332,
                0.8319701552391052,
                0.6861749291419983,
                0.8178170323371887,
                0.735998809337616,
                0.9290315508842468,
                0.8101016879081726,
                0.8852025270462036,
                0.6674180626869202,
                0.851972222328186,
                0.8526172637939453,
                0.7424870133399963,
                0.7473039031028748,
                0.7451612949371338,
                0.7425166368484497,
                0.8693564534187317,
                0.7749475240707397,
                0.8781309127807617,
                0.7858564853668213,
                0.8735175132751465,
                0.7817583680152893,
                0.8566722273826599,
                0.7837845087051392,
                0.8230206370353699,
                0.7594135403633118,
                0.8318765163421631,
                0.7162390351295471,
                0.7404083609580994,
                0.711933434009552,
                0.6555648446083069,
                0.7558527588844299,
                0.7645604014396667,
                0.7586843371391296,
                0.7591819167137146,
                0.7383875250816345,
                0.8334459662437439,
                0.7825778722763062,
                0.7402260303497314,
                0.7106162309646606,
                0.7976266145706177,
                0.7728517055511475,
                0.7318098545074463,
                0.7629801034927368
            ],
            [
                0.7528932690620422,
                0.7927224040031433,
                0.7342103123664856,
                0.7247408628463745,
                0.8522737622261047,
                0.8323513269424438,
                0.8027125597000122,
                0.7472375631332397,
                0.8357483148574829,
                0.7885752320289612,
                0.7745388746261597,
                0.8051419258117676,
                0.8428031802177429,
                0.7409977912902832,
                0.8154096007347107,
                0.7843034267425537,
                0.8092817068099976,
                0.752223551273346,
                0.7816945314407349,
                0.8232024908065796,
                0.840224027633667,
                0.8348418474197388,
                0.8311161398887634,
                0.7467626929283142,
                0.8255640864372253,
                0.7730456590652466,
                0.8566781878471375,
                0.7665925621986389,
                0.8498464822769165,
                0.7628880143165588,
                0.8369115591049194,
                0.7319658994674683,
                0.7942391633987427,
                0.8050967454910278,
                0.8420637249946594,
                0.683077335357666,
                0.736215353012085,
                0.6781278848648071,
                0.8475158214569092,
                0.7458521127700806,
                0.8323746919631958,
                0.801028311252594,
                0.853672444820404,
                0.7880865931510925,
                0.8603707551956177,
                0.7496936321258545,
                0.8103813529014587,
                0.7479114532470703,
                0.822603702545166,
                0.6311047077178955,
                0.8191933035850525
            ],
            [
                0.7996656894683838,
                0.8154450058937073,
                0.748146116733551,
                0.720966637134552,
                0.7354103922843933,
                0.8032618165016174,
                0.73064786195755,
                0.8516279458999634,
                0.7450421452522278,
                0.811459481716156,
                0.739894449710846,
                0.8052367568016052,
                0.7582448720932007,
                0.8145074248313904,
                0.7961751818656921,
                0.833072304725647,
                0.7353792786598206,
                0.7971328496932983,
                0.8290984630584717,
                0.7606619596481323,
                0.7942966818809509,
                0.7710033655166626,
                0.7786402106285095,
                0.8236697316169739,
                0.7826635837554932,
                0.8426937460899353,
                0.7814253568649292,
                0.8442962169647217,
                0.7922813296318054,
                0.840820848941803,
                0.7803486585617065,
                0.7825172543525696,
                0.7653114795684814,
                0.8248791694641113,
                0.7757114171981812,
                0.7358337640762329,
                0.7233917117118835,
                0.7642561793327332,
                0.7829692363739014,
                0.7428232431411743,
                0.7651907801628113,
                0.7815055847167969,
                0.784457266330719,
                0.8149926066398621,
                0.7931575179100037,
                0.781294584274292,
                0.7535977959632874,
                0.8183193206787109,
                0.7798094749450684,
                0.7636439800262451,
                0.7778234481811523
            ],
            [
                0.8501929044723511,
                0.8773778676986694,
                0.8196916580200195,
                0.7651738524436951,
                0.8084287047386169,
                0.8559110760688782,
                0.7312977313995361,
                0.8964488506317139,
                0.7555361390113831,
                0.8870806694030762,
                0.7262823581695557,
                0.8655522465705872,
                0.7966583967208862,
                0.908115565776825,
                0.8591181635856628,
                0.9313532114028931,
                0.7409316897392273,
                0.8854625821113586,
                0.9138623476028442,
                0.8098693490028381,
                0.8258394002914429,
                0.8160354495048523,
                0.8126592040061951,
                0.9014807939529419,
                0.8269639611244202,
                0.910499095916748,
                0.8628014326095581,
                0.9174399971961975,
                0.8538983464241028,
                0.8904812335968018,
                0.8558854460716248,
                0.8383125066757202,
                0.824112057685852,
                0.8861925601959229,
                0.8145016431808472,
                0.7584692239761353,
                0.7781482338905334,
                0.7087510824203491,
                0.8467157483100891,
                0.7888200879096985,
                0.8311408758163452,
                0.8335584402084351,
                0.8458303809165955,
                0.8932408094406128,
                0.874050498008728,
                0.8069950342178345,
                0.7938745617866516,
                0.8450760245323181,
                0.8689394593238831,
                0.7544522881507874,
                0.8311282396316528
            ],
            [
                0.8032768368721008,
                0.8430799245834351,
                0.7912015318870544,
                0.7470860481262207,
                0.7571459412574768,
                0.8267273902893066,
                0.7614060044288635,
                0.8366959095001221,
                0.7987099289894104,
                0.8151528239250183,
                0.7623499631881714,
                0.8041130900382996,
                0.7913548946380615,
                0.8104393482208252,
                0.8055635094642639,
                0.8251844644546509,
                0.7511797547340393,
                0.7867203950881958,
                0.8250916004180908,
                0.789665937423706,
                0.793075680732727,
                0.8028725981712341,
                0.8005143404006958,
                0.8152807950973511,
                0.813912570476532,
                0.8444293737411499,
                0.8169763684272766,
                0.8235663771629333,
                0.8178708553314209,
                0.8274438977241516,
                0.7958698868751526,
                0.7875598073005676,
                0.7627730369567871,
                0.8315258026123047,
                0.7886448502540588,
                0.7332203984260559,
                0.7164361476898193,
                0.7369559407234192,
                0.8038545250892639,
                0.7781039476394653,
                0.7749356031417847,
                0.775900661945343,
                0.7847228050231934,
                0.8080024719238281,
                0.8143419027328491,
                0.7741193175315857,
                0.7542778253555298,
                0.7951962947845459,
                0.7866244316101074,
                0.739220380783081,
                0.7983273267745972
            ],
            [
                0.8785660266876221,
                0.8974977731704712,
                0.8408453464508057,
                0.8072205185890198,
                0.816895067691803,
                0.8795638084411621,
                0.7420486807823181,
                0.9057500958442688,
                0.7782307863235474,
                0.9052944183349609,
                0.7355170845985413,
                0.8844238519668579,
                0.8108775019645691,
                0.9068683385848999,
                0.8676206469535828,
                0.9173812866210938,
                0.7666181325912476,
                0.898729681968689,
                0.9312597513198853,
                0.8385117650032043,
                0.8368827104568481,
                0.842912495136261,
                0.8361802697181702,
                0.9067091941833496,
                0.8383001685142517,
                0.9255636930465698,
                0.8759437799453735,
                0.9177169799804688,
                0.8618419170379639,
                0.8966585993766785,
                0.8592541217803955,
                0.86420738697052,
                0.8382995128631592,
                0.901928186416626,
                0.8308959007263184,
                0.778552234172821,
                0.7961212992668152,
                0.7218038439750671,
                0.867553174495697,
                0.8143540024757385,
                0.8453267216682434,
                0.8492897748947144,
                0.8467909097671509,
                0.8965492248535156,
                0.876458466053009,
                0.8076642155647278,
                0.8034392595291138,
                0.8509840965270996,
                0.8731182813644409,
                0.7400864362716675,
                0.850331723690033
            ],
            [
                0.78025221824646,
                0.8155303001403809,
                0.7536762952804565,
                0.7052674293518066,
                0.7216097712516785,
                0.796366274356842,
                0.748071014881134,
                0.8265869617462158,
                0.7662702798843384,
                0.7948447465896606,
                0.7600979804992676,
                0.8003478646278381,
                0.7642991542816162,
                0.8000987768173218,
                0.7820380330085754,
                0.8230559825897217,
                0.7385210990905762,
                0.7755151987075806,
                0.7941080927848816,
                0.7595050930976868,
                0.7768003940582275,
                0.7735191583633423,
                0.779460072517395,
                0.800300121307373,
                0.7927734851837158,
                0.8264013528823853,
                0.7831382155418396,
                0.8230640888214111,
                0.7982989549636841,
                0.8293324708938599,
                0.780240535736084,
                0.7737728357315063,
                0.7465873956680298,
                0.8109087944030762,
                0.7653632760047913,
                0.705010712146759,
                0.706648051738739,
                0.7357536554336548,
                0.7800151109695435,
                0.7438248991966248,
                0.7536287903785706,
                0.7413808107376099,
                0.7630873918533325,
                0.7803581357002258,
                0.7848274111747742,
                0.7461930513381958,
                0.7310913801193237,
                0.7712777256965637,
                0.763542652130127,
                0.723152756690979,
                0.7740330100059509
            ],
            [
                0.8462713360786438,
                0.871964156627655,
                0.8049110770225525,
                0.7617694735527039,
                0.7865716218948364,
                0.8563441634178162,
                0.7468392848968506,
                0.8610178232192993,
                0.764583945274353,
                0.8616358041763306,
                0.7547771334648132,
                0.857628345489502,
                0.8027268052101135,
                0.9051828980445862,
                0.8384068012237549,
                0.912067711353302,
                0.7629455327987671,
                0.8623544573783875,
                0.8692766427993774,
                0.8101674318313599,
                0.8145353198051453,
                0.8189602494239807,
                0.8148335218429565,
                0.8688575029373169,
                0.8331354260444641,
                0.8912140727043152,
                0.8490900993347168,
                0.8887230157852173,
                0.8533503413200378,
                0.8787603974342346,
                0.8498560190200806,
                0.8410057425498962,
                0.8029705882072449,
                0.8671687245368958,
                0.8062164783477783,
                0.7441385388374329,
                0.7710012197494507,
                0.697716474533081,
                0.8313841223716736,
                0.7964205741882324,
                0.814416766166687,
                0.8060789108276367,
                0.8175632953643799,
                0.8534771203994751,
                0.8534329533576965,
                0.7702664136886597,
                0.756571888923645,
                0.8063790798187256,
                0.8324096202850342,
                0.7042428255081177,
                0.8213279843330383
            ],
            [
                0.7968862652778625,
                0.8478732705116272,
                0.8222619295120239,
                0.7506874203681946,
                0.8315562605857849,
                0.8681409955024719,
                0.8646284937858582,
                0.8180417418479919,
                0.8732545375823975,
                0.8443363308906555,
                0.8256658911705017,
                0.8744065761566162,
                0.8749792575836182,
                0.8125568628311157,
                0.8305470943450928,
                0.8878811597824097,
                0.8554369211196899,
                0.7957965731620789,
                0.8278480768203735,
                0.876754879951477,
                0.8983665704727173,
                0.8986812233924866,
                0.8976215720176697,
                0.8241469860076904,
                0.89202880859375,
                0.8285006284713745,
                0.8902999758720398,
                0.8359944820404053,
                0.8891363739967346,
                0.8442517518997192,
                0.8742539286613464,
                0.7912973165512085,
                0.8144651651382446,
                0.8766502737998962,
                0.8818317651748657,
                0.710274875164032,
                0.7658758759498596,
                0.6888274550437927,
                0.8759481906890869,
                0.7956347465515137,
                0.848888635635376,
                0.8099063038825989,
                0.8780583143234253,
                0.8067346215248108,
                0.8892086744308472,
                0.7977110147476196,
                0.8229103088378906,
                0.7795510292053223,
                0.8602831363677979,
                0.6892396211624146,
                0.8802669048309326
            ],
            [
                0.8339395523071289,
                0.8614110350608826,
                0.7729633450508118,
                0.7577832937240601,
                0.7605661749839783,
                0.8761980533599854,
                0.7774405479431152,
                0.8493835926055908,
                0.8018574714660645,
                0.8641541600227356,
                0.7732041478157043,
                0.862798810005188,
                0.8088369965553284,
                0.8555694818496704,
                0.8175029754638672,
                0.8774198293685913,
                0.77461838722229,
                0.8342794179916382,
                0.8594298958778381,
                0.8068838715553284,
                0.8250046968460083,
                0.8188847303390503,
                0.8223395943641663,
                0.8616200685501099,
                0.8220828771591187,
                0.8593146800994873,
                0.8295695185661316,
                0.8594776391983032,
                0.8325090408325195,
                0.856371283531189,
                0.8212119340896606,
                0.8391162753105164,
                0.7838510274887085,
                0.8808180689811707,
                0.8028945922851562,
                0.7691988348960876,
                0.7549978494644165,
                0.7190943360328674,
                0.8251456022262573,
                0.8182604312896729,
                0.7928388118743896,
                0.8159927129745483,
                0.8158552646636963,
                0.8432536125183105,
                0.8332997560501099,
                0.8147600293159485,
                0.7852938771247864,
                0.8119547367095947,
                0.8231076002120972,
                0.7575454711914062,
                0.8208810091018677
            ],
            [
                0.8006033301353455,
                0.8474054336547852,
                0.7430242300033569,
                0.7416208386421204,
                0.7669645547866821,
                0.8566562533378601,
                0.8154996037483215,
                0.7988113760948181,
                0.8455899953842163,
                0.8323288559913635,
                0.8020103573799133,
                0.860460638999939,
                0.8315631151199341,
                0.7960813641548157,
                0.7878700494766235,
                0.8461742401123047,
                0.7937458753585815,
                0.7965254783630371,
                0.8162041902542114,
                0.8059713840484619,
                0.8234564065933228,
                0.8217307925224304,
                0.8266315460205078,
                0.8139455914497375,
                0.8189072012901306,
                0.8082970976829529,
                0.827565610408783,
                0.8190016150474548,
                0.8325501084327698,
                0.8180710077285767,
                0.8146791458129883,
                0.8109700083732605,
                0.7711610794067383,
                0.8681625127792358,
                0.8085700869560242,
                0.7118985056877136,
                0.7223543524742126,
                0.6926154494285583,
                0.8219003081321716,
                0.8183683156967163,
                0.7950624823570251,
                0.8056188225746155,
                0.8068000078201294,
                0.7862093448638916,
                0.824820876121521,
                0.7834231853485107,
                0.7642123699188232,
                0.7718265056610107,
                0.7880430817604065,
                0.7100235223770142,
                0.809922993183136
            ],
            [
                0.8768737316131592,
                0.8983963131904602,
                0.8235059976577759,
                0.8154513239860535,
                0.8211901187896729,
                0.9052921533584595,
                0.7889434695243835,
                0.8805464506149292,
                0.8126546740531921,
                0.9240542650222778,
                0.7756155729293823,
                0.9245455265045166,
                0.8424121141433716,
                0.8824286460876465,
                0.8654541969299316,
                0.9173513054847717,
                0.7967071533203125,
                0.8920563459396362,
                0.9153962135314941,
                0.8458022475242615,
                0.8612070083618164,
                0.8573663830757141,
                0.8571704030036926,
                0.8993797302246094,
                0.8535854816436768,
                0.903063952922821,
                0.8757571578025818,
                0.892912745475769,
                0.8673356771469116,
                0.8859235644340515,
                0.8592303991317749,
                0.8803410530090332,
                0.8391953110694885,
                0.9275700449943542,
                0.8458073735237122,
                0.7933007478713989,
                0.789147675037384,
                0.7406438589096069,
                0.8782158493995667,
                0.8606242537498474,
                0.8528251647949219,
                0.8759350776672363,
                0.8595452308654785,
                0.8833897113800049,
                0.8760513067245483,
                0.8268358707427979,
                0.8098103404045105,
                0.8378745317459106,
                0.8574514389038086,
                0.7529895305633545,
                0.852229654788971
            ],
            [
                0.7745478749275208,
                0.8154348731040955,
                0.7584372162818909,
                0.7548260688781738,
                0.8127334117889404,
                0.8588761687278748,
                0.8638079762458801,
                0.791526734828949,
                0.8660374879837036,
                0.8341426849365234,
                0.7959426045417786,
                0.8499239087104797,
                0.8515294790267944,
                0.7599823474884033,
                0.7969855666160583,
                0.8190638422966003,
                0.8395355939865112,
                0.7648181319236755,
                0.7942133545875549,
                0.8639423251152039,
                0.8909527063369751,
                0.885439395904541,
                0.8870742917060852,
                0.7842407822608948,
                0.8457200527191162,
                0.7831810712814331,
                0.8558862209320068,
                0.780885636806488,
                0.857609212398529,
                0.8121368288993835,
                0.8434765338897705,
                0.7570695877075195,
                0.7909409999847412,
                0.8459932804107666,
                0.8683981895446777,
                0.7291790246963501,
                0.7733016014099121,
                0.7098759412765503,
                0.8691707849502563,
                0.767176628112793,
                0.8225166201591492,
                0.8021241426467896,
                0.8728915452957153,
                0.7893632650375366,
                0.8546937704086304,
                0.7892261743545532,
                0.8302091360092163,
                0.7636052966117859,
                0.8382339477539062,
                0.6720004081726074,
                0.8595598340034485
            ],
            [
                0.774383544921875,
                0.821705162525177,
                0.7275698184967041,
                0.7722944021224976,
                0.8039348125457764,
                0.8648210167884827,
                0.8674505949020386,
                0.7775271534919739,
                0.8880296945571899,
                0.8356509804725647,
                0.8044996857643127,
                0.8622036576271057,
                0.8576697707176208,
                0.7554988265037537,
                0.7844488024711609,
                0.8139212131500244,
                0.8558242917060852,
                0.7593463063240051,
                0.7981981039047241,
                0.8597643971443176,
                0.8817458152770996,
                0.8793955445289612,
                0.8813655972480774,
                0.7812016010284424,
                0.848109245300293,
                0.7646420001983643,
                0.8469734191894531,
                0.7639793157577515,
                0.8469111323356628,
                0.7911368012428284,
                0.8323987126350403,
                0.7795454263687134,
                0.7733104228973389,
                0.8678668141365051,
                0.8743630051612854,
                0.7444831132888794,
                0.7517944574356079,
                0.7421190738677979,
                0.8575499653816223,
                0.8184454441070557,
                0.8165268898010254,
                0.8406152129173279,
                0.8677424788475037,
                0.7806035280227661,
                0.8413846492767334,
                0.8286041617393494,
                0.8199753165245056,
                0.7932944893836975,
                0.8120925426483154,
                0.7037850022315979,
                0.8489837646484375
            ],
            [
                0.8664292097091675,
                0.8914746046066284,
                0.8039941191673279,
                0.8077046871185303,
                0.825498104095459,
                0.9077168703079224,
                0.7997913360595703,
                0.8409682512283325,
                0.8401119709014893,
                0.8836990594863892,
                0.7821698188781738,
                0.9007439613342285,
                0.8466998934745789,
                0.8480291366577148,
                0.8679429292678833,
                0.8745939135551453,
                0.8076614737510681,
                0.8608717322349548,
                0.8811062574386597,
                0.845487117767334,
                0.854224681854248,
                0.8585565686225891,
                0.8575654029846191,
                0.8654381632804871,
                0.8503046035766602,
                0.8718811273574829,
                0.869663417339325,
                0.8591243624687195,
                0.8619978427886963,
                0.8506985306739807,
                0.8505434989929199,
                0.8642545938491821,
                0.8136090040206909,
                0.9201750159263611,
                0.8450586199760437,
                0.7671476006507874,
                0.764320433139801,
                0.7154653072357178,
                0.8589595556259155,
                0.8388788104057312,
                0.8382469415664673,
                0.8702494502067566,
                0.8396635055541992,
                0.8562744855880737,
                0.863964319229126,
                0.8164483308792114,
                0.8005948066711426,
                0.8093828558921814,
                0.8351664543151855,
                0.7204201221466064,
                0.8423691391944885
            ],
            [
                0.7748775482177734,
                0.8274526596069336,
                0.7617180943489075,
                0.7402446269989014,
                0.8087905645370483,
                0.8373647928237915,
                0.8692178726196289,
                0.801834225654602,
                0.85833340883255,
                0.8253344297409058,
                0.8214353919029236,
                0.8515578508377075,
                0.8654693961143494,
                0.7921104431152344,
                0.8089402318000793,
                0.8519015908241272,
                0.8324344158172607,
                0.7779868245124817,
                0.805360734462738,
                0.861777663230896,
                0.8827657103538513,
                0.8800753355026245,
                0.8814460635185242,
                0.8046234846115112,
                0.8546801805496216,
                0.8064972758293152,
                0.861337423324585,
                0.8098190426826477,
                0.8609583377838135,
                0.8345091342926025,
                0.8542556166648865,
                0.7695480585098267,
                0.8039838671684265,
                0.8499129414558411,
                0.8549496531486511,
                0.7016462683677673,
                0.7585949897766113,
                0.6888936161994934,
                0.8557943105697632,
                0.7656164169311523,
                0.8298056721687317,
                0.7955940961837769,
                0.8590217232704163,
                0.7949198484420776,
                0.8581311702728271,
                0.7824863791465759,
                0.8324170708656311,
                0.7787021994590759,
                0.8465715050697327,
                0.6767535209655762,
                0.8644000291824341
            ],
            [
                0.766052782535553,
                0.8115233778953552,
                0.7101767659187317,
                0.6948847770690918,
                0.7458556294441223,
                0.8266855478286743,
                0.8180996775627136,
                0.7615913152694702,
                0.8371917605400085,
                0.7950164079666138,
                0.7972300052642822,
                0.8090155720710754,
                0.8273921608924866,
                0.7617177963256836,
                0.7815499901771545,
                0.8077773451805115,
                0.791354775428772,
                0.7484059929847717,
                0.768953263759613,
                0.8005357384681702,
                0.8220558166503906,
                0.8213492631912231,
                0.8222470283508301,
                0.7730501890182495,
                0.8155693411827087,
                0.7687103748321533,
                0.8060874342918396,
                0.779342532157898,
                0.8139565587043762,
                0.7930939793586731,
                0.7941120862960815,
                0.7451473474502563,
                0.7450326085090637,
                0.8301103115081787,
                0.7968977093696594,
                0.6956200003623962,
                0.7055202722549438,
                0.6610177159309387,
                0.7978851199150085,
                0.7553738951683044,
                0.7663105726242065,
                0.7526789903640747,
                0.7899266481399536,
                0.7505332827568054,
                0.8040022253990173,
                0.7406599521636963,
                0.7551349401473999,
                0.7307208776473999,
                0.7712910175323486,
                0.6529800891876221,
                0.8043633699417114
            ],
            [
                0.8724740743637085,
                0.9001890420913696,
                0.8172402381896973,
                0.831365704536438,
                0.8417478799819946,
                0.9237374663352966,
                0.8121561408042908,
                0.8596240878105164,
                0.8564372658729553,
                0.9040638208389282,
                0.792324423789978,
                0.904710054397583,
                0.8664732575416565,
                0.8571654558181763,
                0.8732321262359619,
                0.8834190964698792,
                0.8162762522697449,
                0.8716821670532227,
                0.9032621383666992,
                0.8592796921730042,
                0.8657114505767822,
                0.8754099607467651,
                0.8678034543991089,
                0.8756354451179504,
                0.8593586683273315,
                0.8845425844192505,
                0.8811101913452148,
                0.8663020133972168,
                0.8732626438140869,
                0.8680171370506287,
                0.8623135685920715,
                0.8683123588562012,
                0.8218541145324707,
                0.9168669581413269,
                0.8576564192771912,
                0.7915781736373901,
                0.7734180092811584,
                0.7417229413986206,
                0.8714852333068848,
                0.8579919338226318,
                0.8502569198608398,
                0.8839008808135986,
                0.8615323305130005,
                0.8721246719360352,
                0.8755099773406982,
                0.8296693563461304,
                0.828424334526062,
                0.8315316438674927,
                0.8491673469543457,
                0.7366697192192078,
                0.8588705062866211
            ],
            [
                0.8294153213500977,
                0.8528371453285217,
                0.8015334606170654,
                0.7928768396377563,
                0.758781373500824,
                0.8398558497428894,
                0.7405968904495239,
                0.8642845153808594,
                0.7898041605949402,
                0.8361623287200928,
                0.749445378780365,
                0.826802670955658,
                0.7770779728889465,
                0.8336207270622253,
                0.7991375923156738,
                0.8418652415275574,
                0.7366102337837219,
                0.8264971375465393,
                0.8693726062774658,
                0.7779362797737122,
                0.7834008932113647,
                0.8021326661109924,
                0.7906075716018677,
                0.8505131602287292,
                0.8097063899040222,
                0.8697103261947632,
                0.8042774200439453,
                0.8440828323364258,
                0.8022063970565796,
                0.8519750237464905,
                0.7906844615936279,
                0.8241755962371826,
                0.7718846201896667,
                0.8401075601577759,
                0.784346878528595,
                0.7437659502029419,
                0.7167239785194397,
                0.7652549147605896,
                0.7906658053398132,
                0.8072928190231323,
                0.7770576477050781,
                0.813494086265564,
                0.7904809713363647,
                0.8416124582290649,
                0.7989775538444519,
                0.8030814528465271,
                0.760915219783783,
                0.8340811729431152,
                0.7895777225494385,
                0.7956828474998474,
                0.7893425226211548
            ],
            [
                0.8630295991897583,
                0.8979350924491882,
                0.7883922457695007,
                0.7763944268226624,
                0.7922913432121277,
                0.8794801831245422,
                0.738396406173706,
                0.8825716972351074,
                0.7622388005256653,
                0.8756265044212341,
                0.7534551620483398,
                0.8704197406768799,
                0.7978853583335876,
                0.9334944486618042,
                0.8551037907600403,
                0.916902482509613,
                0.7424206733703613,
                0.8793272972106934,
                0.8992075324058533,
                0.8040757179260254,
                0.8152459859848022,
                0.8155567049980164,
                0.8105032444000244,
                0.8952316641807556,
                0.8295267820358276,
                0.908588707447052,
                0.8524978756904602,
                0.9019023180007935,
                0.8464577794075012,
                0.8934777975082397,
                0.8442822694778442,
                0.8598101139068604,
                0.8147308826446533,
                0.8744179010391235,
                0.7929167747497559,
                0.7577373385429382,
                0.7681001424789429,
                0.7031522989273071,
                0.8375247716903687,
                0.8132510781288147,
                0.8225079774856567,
                0.8221592307090759,
                0.8209923505783081,
                0.8853030204772949,
                0.856134295463562,
                0.7833712697029114,
                0.7878246903419495,
                0.8325040936470032,
                0.8451442122459412,
                0.7440434694290161,
                0.8233726620674133
            ],
            [
                0.7781352996826172,
                0.8142530918121338,
                0.7669074535369873,
                0.7118014097213745,
                0.7246385216712952,
                0.8022613525390625,
                0.7348456382751465,
                0.8312551975250244,
                0.7685357928276062,
                0.7960343360900879,
                0.7521182894706726,
                0.7866265177726746,
                0.7584774494171143,
                0.7931494116783142,
                0.7836248278617859,
                0.814586341381073,
                0.7313984632492065,
                0.7699897289276123,
                0.8120104670524597,
                0.7527952790260315,
                0.7663423418998718,
                0.7681781649589539,
                0.7829882502555847,
                0.8020803928375244,
                0.7939330339431763,
                0.826338529586792,
                0.7922108769416809,
                0.8091168999671936,
                0.8009650707244873,
                0.8182258009910583,
                0.7835696935653687,
                0.7666680812835693,
                0.7514896392822266,
                0.8047763109207153,
                0.7650322914123535,
                0.7198824286460876,
                0.699401319026947,
                0.7490447163581848,
                0.7790361046791077,
                0.7481632232666016,
                0.7576351761817932,
                0.7612197399139404,
                0.7679219841957092,
                0.7936018109321594,
                0.7928628325462341,
                0.7587197422981262,
                0.7462994456291199,
                0.7839794158935547,
                0.7680544853210449,
                0.7524563074111938,
                0.7722785472869873
            ],
            [
                0.9058542251586914,
                0.9164858460426331,
                0.8311820030212402,
                0.8298617005348206,
                0.802829921245575,
                0.877909779548645,
                0.714216947555542,
                0.937869668006897,
                0.7325703501701355,
                0.9174740314483643,
                0.7073401212692261,
                0.892436683177948,
                0.7838461399078369,
                0.9455728530883789,
                0.851105272769928,
                0.9194801449775696,
                0.7065868973731995,
                0.9211028814315796,
                0.9431926012039185,
                0.797416090965271,
                0.8039023876190186,
                0.8023475408554077,
                0.8030858635902405,
                0.9470361471176147,
                0.8081164956092834,
                0.944439709186554,
                0.860105037689209,
                0.9211426973342896,
                0.8511545062065125,
                0.9230301380157471,
                0.8568019866943359,
                0.9098134636878967,
                0.8551191091537476,
                0.9021487236022949,
                0.7931888699531555,
                0.7682123184204102,
                0.798461377620697,
                0.7325531244277954,
                0.8529834747314453,
                0.8388459086418152,
                0.8421775102615356,
                0.8679646253585815,
                0.8259232640266418,
                0.9439501762390137,
                0.8644724488258362,
                0.814451277256012,
                0.7824419736862183,
                0.8641172051429749,
                0.8671039342880249,
                0.7751799821853638,
                0.8198460340499878
            ],
            [
                0.850496232509613,
                0.8798822164535522,
                0.8668020367622375,
                0.7827872037887573,
                0.8695904016494751,
                0.8483607172966003,
                0.783507764339447,
                0.88654625415802,
                0.7812799215316772,
                0.8869689106941223,
                0.7298346757888794,
                0.881355345249176,
                0.8398578763008118,
                0.8378985524177551,
                0.8593470454216003,
                0.886439323425293,
                0.7748176455497742,
                0.8648589849472046,
                0.8892865180969238,
                0.8756603598594666,
                0.8846864700317383,
                0.8848162889480591,
                0.8896893858909607,
                0.881881058216095,
                0.8638067245483398,
                0.8819277286529541,
                0.9394716024398804,
                0.8710075616836548,
                0.925003707408905,
                0.8901785016059875,
                0.936489999294281,
                0.834880530834198,
                0.9181809425354004,
                0.8947606086730957,
                0.8807108998298645,
                0.6915241479873657,
                0.8572971224784851,
                0.6779256463050842,
                0.9230305552482605,
                0.7695551514625549,
                0.9107990264892578,
                0.8406624794006348,
                0.883037805557251,
                0.8971940279006958,
                0.939436674118042,
                0.7655128836631775,
                0.8081749677658081,
                0.7924514412879944,
                0.9384552240371704,
                0.6512047052383423,
                0.8869584202766418
            ],
            [
                0.7695283889770508,
                0.8096648454666138,
                0.7426183223724365,
                0.7314122319221497,
                0.8540889024734497,
                0.8356683254241943,
                0.8209158182144165,
                0.7641666531562805,
                0.8462427854537964,
                0.8019997477531433,
                0.8019396066665649,
                0.8172539472579956,
                0.8590114116668701,
                0.7671273946762085,
                0.8336855173110962,
                0.8007763028144836,
                0.8257878422737122,
                0.7604696154594421,
                0.7843288779258728,
                0.8324703574180603,
                0.8388786911964417,
                0.8471342921257019,
                0.843112587928772,
                0.7578619718551636,
                0.8475501537322998,
                0.7870097756385803,
                0.867267370223999,
                0.7721932530403137,
                0.8593475818634033,
                0.7888175845146179,
                0.851288914680481,
                0.7509064674377441,
                0.8064647912979126,
                0.8088368773460388,
                0.8427890539169312,
                0.687532901763916,
                0.7430408000946045,
                0.6749109029769897,
                0.8553422689437866,
                0.7655923962593079,
                0.8436442017555237,
                0.7939859628677368,
                0.8471484184265137,
                0.7891810536384583,
                0.8633939027786255,
                0.7363753318786621,
                0.8013458251953125,
                0.7435228824615479,
                0.8236347436904907,
                0.620789647102356,
                0.830302357673645
            ],
            [
                0.790148138999939,
                0.8177334666252136,
                0.7731788754463196,
                0.7701998949050903,
                0.7620463967323303,
                0.8105818629264832,
                0.7429222464561462,
                0.8547613024711609,
                0.7702576518058777,
                0.820065438747406,
                0.7475258111953735,
                0.8092175126075745,
                0.7810989022254944,
                0.7981477975845337,
                0.8006820678710938,
                0.8248109221458435,
                0.7586542963981628,
                0.7950001358985901,
                0.8267092704772949,
                0.7986528277397156,
                0.7891994714736938,
                0.7914221882820129,
                0.7924721240997314,
                0.8224824070930481,
                0.8178999423980713,
                0.8470379114151001,
                0.8091193437576294,
                0.8222491145133972,
                0.818870484828949,
                0.8358924984931946,
                0.8103022575378418,
                0.7903849482536316,
                0.7788415551185608,
                0.8237471580505371,
                0.8089635372161865,
                0.7334648966789246,
                0.7699015736579895,
                0.771138608455658,
                0.8018737435340881,
                0.77101069688797,
                0.7856610417366028,
                0.7783174514770508,
                0.8096345067024231,
                0.813561201095581,
                0.8097807765007019,
                0.782841145992279,
                0.748370885848999,
                0.8045204877853394,
                0.7807503938674927,
                0.7410506010055542,
                0.8066388964653015
            ],
            [
                0.8629891872406006,
                0.8776056170463562,
                0.7722299098968506,
                0.8055669665336609,
                0.7461963295936584,
                0.8386842012405396,
                0.6852694749832153,
                0.9022496938705444,
                0.7167048454284668,
                0.8907948732376099,
                0.6942802667617798,
                0.8541539907455444,
                0.7505981922149658,
                0.9130588173866272,
                0.8039214611053467,
                0.8870532512664795,
                0.6933352947235107,
                0.8778865933418274,
                0.9118212461471558,
                0.7667143940925598,
                0.7674988508224487,
                0.7740650773048401,
                0.772132933139801,
                0.9069380760192871,
                0.7936305999755859,
                0.8965647220611572,
                0.8101388216018677,
                0.874345064163208,
                0.8024668097496033,
                0.8895491361618042,
                0.8106113076210022,
                0.8747175335884094,
                0.8005169034004211,
                0.8658151626586914,
                0.7657551765441895,
                0.7880634069442749,
                0.75431889295578,
                0.7626009583473206,
                0.8040247559547424,
                0.8406196236610413,
                0.7946568131446838,
                0.8602378368377686,
                0.7958467602729797,
                0.8960748314857483,
                0.8090993762016296,
                0.7991194128990173,
                0.7444863319396973,
                0.8599778413772583,
                0.8011214137077332,
                0.765906035900116,
                0.7880192995071411
            ],
            [
                0.7820793390274048,
                0.8116342425346375,
                0.7402863502502441,
                0.7280758023262024,
                0.724677562713623,
                0.8154287338256836,
                0.7703454494476318,
                0.8123596906661987,
                0.7815621495246887,
                0.8026864528656006,
                0.762750506401062,
                0.7970011234283447,
                0.7813469767570496,
                0.7954199910163879,
                0.7666714787483215,
                0.80645352602005,
                0.7354839444160461,
                0.7650710344314575,
                0.7820342183113098,
                0.7598239183425903,
                0.7753314971923828,
                0.7807626724243164,
                0.7795109748840332,
                0.7960315942764282,
                0.7917855978012085,
                0.8066191077232361,
                0.7831087112426758,
                0.7951256632804871,
                0.78996342420578,
                0.8274116516113281,
                0.7825652360916138,
                0.765251636505127,
                0.7339158654212952,
                0.8008203506469727,
                0.7627916932106018,
                0.6880092620849609,
                0.704035222530365,
                0.6838035583496094,
                0.7880668640136719,
                0.7555210590362549,
                0.7425147294998169,
                0.7428005337715149,
                0.7775478959083557,
                0.7869678139686584,
                0.7848402857780457,
                0.7366189956665039,
                0.7414062023162842,
                0.7475743889808655,
                0.7710644006729126,
                0.6664731502532959,
                0.772228479385376
            ],
            [
                0.8470257520675659,
                0.8636042475700378,
                0.8247197866439819,
                0.7591826319694519,
                0.8010638356208801,
                0.8258135318756104,
                0.6946079730987549,
                0.9059790372848511,
                0.7154937982559204,
                0.878337025642395,
                0.6931077837944031,
                0.8575433492660522,
                0.7736402750015259,
                0.8956828117370605,
                0.8428462743759155,
                0.8941716551780701,
                0.7035287618637085,
                0.897614061832428,
                0.9275257587432861,
                0.7940989136695862,
                0.7986800074577332,
                0.8046566843986511,
                0.8007252216339111,
                0.9092952013015747,
                0.7967641353607178,
                0.9210867285728455,
                0.8448553681373596,
                0.9012540578842163,
                0.8281816244125366,
                0.9051471948623657,
                0.8462133407592773,
                0.8490645289421082,
                0.8487035036087036,
                0.8701512813568115,
                0.7891395092010498,
                0.7293197512626648,
                0.7701936364173889,
                0.7379356622695923,
                0.8225170373916626,
                0.7818411588668823,
                0.8348267078399658,
                0.8495343923568726,
                0.8104571104049683,
                0.9174422025680542,
                0.8454393148422241,
                0.7820720076560974,
                0.7925652861595154,
                0.8640481233596802,
                0.8706523776054382,
                0.7283691763877869,
                0.822018563747406
            ],
            [
                0.8052223324775696,
                0.8270109295845032,
                0.7752466201782227,
                0.757068395614624,
                0.7470682263374329,
                0.8306451439857483,
                0.7371695637702942,
                0.852249801158905,
                0.7740140557289124,
                0.8270394206047058,
                0.7346773147583008,
                0.809118926525116,
                0.7663193941116333,
                0.8061795234680176,
                0.7843753695487976,
                0.8211421966552734,
                0.7125915884971619,
                0.8039515018463135,
                0.826468825340271,
                0.7601698040962219,
                0.7758682370185852,
                0.7730796933174133,
                0.7768968939781189,
                0.8366878628730774,
                0.8001019358634949,
                0.8491035103797913,
                0.8053295612335205,
                0.8279868364334106,
                0.8098520040512085,
                0.8288371562957764,
                0.7911421656608582,
                0.788472056388855,
                0.7671217918395996,
                0.8308714628219604,
                0.7695819735527039,
                0.7204636931419373,
                0.724899411201477,
                0.7402369379997253,
                0.8028824329376221,
                0.7686883807182312,
                0.7640968561172485,
                0.7714169025421143,
                0.7852065563201904,
                0.8234904408454895,
                0.8096382021903992,
                0.7862810492515564,
                0.7482355833053589,
                0.7956250905990601,
                0.7884700298309326,
                0.7659749984741211,
                0.7822762727737427
            ],
            [
                0.7783353328704834,
                0.8118958473205566,
                0.7522804141044617,
                0.752364993095398,
                0.7232474684715271,
                0.8365300893783569,
                0.7690617442131042,
                0.7820745706558228,
                0.8070377111434937,
                0.7893667817115784,
                0.7466501593589783,
                0.7862709760665894,
                0.7806982398033142,
                0.7724008560180664,
                0.7590280771255493,
                0.7860901355743408,
                0.7300944924354553,
                0.7557381391525269,
                0.7678219079971313,
                0.7574020028114319,
                0.7726428508758545,
                0.7765116095542908,
                0.7721956968307495,
                0.7898905277252197,
                0.7954210042953491,
                0.788165807723999,
                0.7863441705703735,
                0.7760397791862488,
                0.7923085689544678,
                0.777854323387146,
                0.7645685076713562,
                0.7654632329940796,
                0.705306887626648,
                0.8105511665344238,
                0.7600626945495605,
                0.7143236398696899,
                0.6868802905082703,
                0.6788629293441772,
                0.7770792245864868,
                0.7674927711486816,
                0.7260937690734863,
                0.7466071844100952,
                0.7728836536407471,
                0.7784256935119629,
                0.7888185381889343,
                0.7781630158424377,
                0.7616174817085266,
                0.7530098557472229,
                0.7723715901374817,
                0.7252155542373657,
                0.7753975987434387
            ],
            [
                0.7681686878204346,
                0.8082823753356934,
                0.6925930380821228,
                0.6654870510101318,
                0.6947466731071472,
                0.7696073055267334,
                0.657698392868042,
                0.8169382214546204,
                0.6641280055046082,
                0.7991201877593994,
                0.6864640712738037,
                0.7975518107414246,
                0.7266721725463867,
                0.9070522785186768,
                0.7793787717819214,
                0.8595811128616333,
                0.6654253005981445,
                0.8125348091125488,
                0.8279943466186523,
                0.7335274815559387,
                0.7407429218292236,
                0.7333548665046692,
                0.7340816259384155,
                0.8415071368217468,
                0.7604831457138062,
                0.8298264145851135,
                0.7644421458244324,
                0.8345438241958618,
                0.753623902797699,
                0.8246610760688782,
                0.7600739002227783,
                0.7785316109657288,
                0.7403485774993896,
                0.8126689195632935,
                0.7021369338035583,
                0.7242245078086853,
                0.7119559049606323,
                0.6418522596359253,
                0.7457304000854492,
                0.7408138513565063,
                0.74162358045578,
                0.7360684871673584,
                0.7415306568145752,
                0.8119303584098816,
                0.7651307582855225,
                0.738409161567688,
                0.722800612449646,
                0.8007996678352356,
                0.7791911363601685,
                0.728247880935669,
                0.7748340964317322
            ],
            [
                0.8580203056335449,
                0.8692501783370972,
                0.797636866569519,
                0.7854342460632324,
                0.8026770353317261,
                0.8617579936981201,
                0.7159892916679382,
                0.8845475316047668,
                0.7549993395805359,
                0.8803815245628357,
                0.7165241241455078,
                0.8613966107368469,
                0.7934313416481018,
                0.8871535658836365,
                0.8387739658355713,
                0.8876127004623413,
                0.7202841639518738,
                0.8982352614402771,
                0.922630786895752,
                0.7908351421356201,
                0.7956796884536743,
                0.7979902029037476,
                0.7984008193016052,
                0.9084597826004028,
                0.8056122064590454,
                0.9097737669944763,
                0.8471307754516602,
                0.8901408314704895,
                0.8335883021354675,
                0.8745627999305725,
                0.8356700539588928,
                0.8673397898674011,
                0.8329038619995117,
                0.8832799196243286,
                0.7898708581924438,
                0.7439531683921814,
                0.7604116797447205,
                0.7338496446609497,
                0.822242021560669,
                0.822364866733551,
                0.8302794694900513,
                0.8678165674209595,
                0.8138109445571899,
                0.917204737663269,
                0.8488895893096924,
                0.7947927713394165,
                0.7778453826904297,
                0.8583052754402161,
                0.8531927466392517,
                0.765188455581665,
                0.815697968006134
            ],
            [
                0.7765210270881653,
                0.8171920776367188,
                0.7302708625793457,
                0.7420177459716797,
                0.7854338884353638,
                0.856873631477356,
                0.8439605832099915,
                0.7770630717277527,
                0.874183714389801,
                0.8130872249603271,
                0.8174931406974792,
                0.8389801979064941,
                0.8393616676330566,
                0.7701380252838135,
                0.7942039966583252,
                0.8139380812644958,
                0.8354076147079468,
                0.7530444860458374,
                0.778292179107666,
                0.822324812412262,
                0.8432460427284241,
                0.8451920747756958,
                0.8441553711891174,
                0.7721031308174133,
                0.840114176273346,
                0.7764760255813599,
                0.8306941986083984,
                0.7748384475708008,
                0.8344355225563049,
                0.7891932725906372,
                0.8104841709136963,
                0.760346531867981,
                0.7586402893066406,
                0.8280544281005859,
                0.8297542929649353,
                0.7257304191589355,
                0.7200468182563782,
                0.7040369510650635,
                0.8282283544540405,
                0.8011743426322937,
                0.79225754737854,
                0.7872848510742188,
                0.8272992968559265,
                0.7584865689277649,
                0.8272460699081421,
                0.7732378244400024,
                0.7726032137870789,
                0.7473944425582886,
                0.7807857394218445,
                0.6822097301483154,
                0.814619243144989
            ],
            [
                0.9146759510040283,
                0.936390221118927,
                0.8495365381240845,
                0.8598124384880066,
                0.8405928611755371,
                0.9346138834953308,
                0.7808457016944885,
                0.9145345687866211,
                0.8196814060211182,
                0.9351111054420471,
                0.7577415704727173,
                0.9278770089149475,
                0.8506060242652893,
                0.9022404551506042,
                0.8672024607658386,
                0.9051717519760132,
                0.7942406535148621,
                0.9157628417015076,
                0.9410160183906555,
                0.8624553680419922,
                0.8636553287506104,
                0.8702631592750549,
                0.8711482286453247,
                0.9237067103385925,
                0.8501766920089722,
                0.920738697052002,
                0.8909968137741089,
                0.9011422395706177,
                0.8857685923576355,
                0.9097385406494141,
                0.8812361359596252,
                0.9227234721183777,
                0.8614175319671631,
                0.9417315721511841,
                0.8576556444168091,
                0.800127387046814,
                0.8205558061599731,
                0.7360040545463562,
                0.8866564631462097,
                0.8808557987213135,
                0.8673437237739563,
                0.8988898992538452,
                0.8611918091773987,
                0.915727436542511,
                0.8853248357772827,
                0.8351093530654907,
                0.7925276756286621,
                0.8383576273918152,
                0.8690976500511169,
                0.7508548498153687,
                0.8649314045906067
            ],
            [
                0.779754102230072,
                0.8145892024040222,
                0.6949679255485535,
                0.7021721005439758,
                0.7384478449821472,
                0.8357043862342834,
                0.7826372385025024,
                0.7581716179847717,
                0.8118340969085693,
                0.7856550216674805,
                0.782324492931366,
                0.8053441047668457,
                0.8018414974212646,
                0.7691792249679565,
                0.7651721239089966,
                0.7977820634841919,
                0.7538913488388062,
                0.7593268752098083,
                0.7749059200286865,
                0.7636134624481201,
                0.7845559120178223,
                0.7780556678771973,
                0.7843146920204163,
                0.7775247097015381,
                0.7803778648376465,
                0.7706120014190674,
                0.7870370149612427,
                0.7845878005027771,
                0.7981982231140137,
                0.7840157747268677,
                0.7748093605041504,
                0.7718381881713867,
                0.7386390566825867,
                0.8302730917930603,
                0.7631925940513611,
                0.7064692974090576,
                0.6966391801834106,
                0.675544798374176,
                0.7795295119285583,
                0.7707231044769287,
                0.7521671056747437,
                0.7615095973014832,
                0.763399600982666,
                0.7635688185691833,
                0.7861857414245605,
                0.7510235905647278,
                0.7454671263694763,
                0.7389827370643616,
                0.7536117434501648,
                0.6905956268310547,
                0.7712135314941406
            ]
        ],
        [
            [
                0.9064942002296448,
                0.7691014409065247,
                0.9137499928474426,
                0.7725724577903748,
                0.8609919548034668,
                0.770780622959137,
                0.7640650868415833,
                0.8761783838272095,
                0.5951792597770691,
                0.8683792352676392,
                0.7507740259170532,
                0.9150399565696716,
                0.7513433694839478,
                0.8636140823364258,
                0.9071407914161682,
                0.7868514657020569,
                0.8929955959320068,
                0.8793584108352661,
                0.7240272164344788,
                0.8634630441665649,
                0.9067490696907043,
                0.7598429918289185,
                0.8465350866317749,
                0.7417270541191101,
                0.8581679463386536,
                0.7863019108772278,
                0.8727357387542725,
                0.7218680381774902,
                0.8785561323165894,
                0.7095218300819397,
                0.9013862013816833,
                0.6899023056030273,
                0.792158842086792,
                0.7404822111129761,
                0.8324834108352661,
                0.751566469669342,
                0.8011845350265503,
                0.7411089539527893,
                0.79471355676651,
                0.7450171113014221,
                0.7453486919403076,
                0.8781979084014893,
                0.76085364818573,
                0.7211333513259888,
                0.7379838228225708,
                0.8285298943519592,
                0.7313979864120483,
                0.8348886370658875,
                0.8791891932487488,
                0.7589685320854187,
                0.8665099143981934
            ],
            [
                0.8030604720115662,
                0.7784830331802368,
                0.7187373638153076,
                0.7998567819595337,
                0.7711926102638245,
                0.8671441674232483,
                0.8194010853767395,
                0.7297151684761047,
                0.6169167160987854,
                0.7201784253120422,
                0.8106749653816223,
                0.7744914889335632,
                0.7956891059875488,
                0.7021985650062561,
                0.786578893661499,
                0.8501250147819519,
                0.7885666489601135,
                0.7633013725280762,
                0.8323992490768433,
                0.7785117626190186,
                0.8160691261291504,
                0.826438307762146,
                0.691969096660614,
                0.7943393588066101,
                0.7427558302879333,
                0.7888305187225342,
                0.7499537467956543,
                0.7861335873603821,
                0.7731152176856995,
                0.799514651298523,
                0.7185510396957397,
                0.7884559631347656,
                0.6711363196372986,
                0.766784131526947,
                0.7336198091506958,
                0.8264003992080688,
                0.6777553558349609,
                0.7489401698112488,
                0.6915669441223145,
                0.8197644948959351,
                0.6713619828224182,
                0.7570162415504456,
                0.8016150593757629,
                0.6548277139663696,
                0.7812961339950562,
                0.6882805824279785,
                0.7860962152481079,
                0.6934952139854431,
                0.8046724200248718,
                0.8138720393180847,
                0.7719118595123291
            ],
            [
                0.9029704928398132,
                0.8102990388870239,
                0.8525033593177795,
                0.8184677362442017,
                0.9042532444000244,
                0.8509576916694641,
                0.8256052136421204,
                0.8453811407089233,
                0.6195487976074219,
                0.8381971716880798,
                0.8083228468894958,
                0.8846674561500549,
                0.8084214925765991,
                0.8421981334686279,
                0.8597817420959473,
                0.8335725665092468,
                0.8542250990867615,
                0.8633124232292175,
                0.8053014278411865,
                0.8306819200515747,
                0.896091639995575,
                0.805152416229248,
                0.7826646566390991,
                0.8052984476089478,
                0.851584792137146,
                0.824393630027771,
                0.8455325961112976,
                0.7952300906181335,
                0.8573532700538635,
                0.783517599105835,
                0.8436520099639893,
                0.7555084228515625,
                0.7582716345787048,
                0.7871829867362976,
                0.8349981307983398,
                0.8192145824432373,
                0.7737667560577393,
                0.7665207386016846,
                0.8076186180114746,
                0.8099910616874695,
                0.744513750076294,
                0.8560023903846741,
                0.8043739199638367,
                0.7474931478500366,
                0.7960361838340759,
                0.8123424053192139,
                0.7912158370018005,
                0.8000847697257996,
                0.8811064958572388,
                0.804096519947052,
                0.8577221035957336
            ],
            [
                0.867755115032196,
                0.9567850232124329,
                0.7936585545539856,
                0.86179119348526,
                0.8423434495925903,
                0.9095670580863953,
                0.8661254644393921,
                0.8147033452987671,
                0.5165789723396301,
                0.8072165250778198,
                0.8648906350135803,
                0.8271898031234741,
                0.8447144031524658,
                0.7934038639068604,
                0.8601177930831909,
                0.9077765941619873,
                0.8634631037712097,
                0.829399824142456,
                0.873818576335907,
                0.8661817908287048,
                0.8832652568817139,
                0.8609136939048767,
                0.7606095671653748,
                0.9186140298843384,
                0.8441759943962097,
                0.8728320598602295,
                0.8189864158630371,
                0.8567999601364136,
                0.8770270347595215,
                0.8423228859901428,
                0.7903559803962708,
                0.7652491331100464,
                0.7767046689987183,
                0.871063768863678,
                0.8524560928344727,
                0.8929396271705627,
                0.7382651567459106,
                0.8127257227897644,
                0.7978377342224121,
                0.883870542049408,
                0.728169322013855,
                0.8224158883094788,
                0.8820503950119019,
                0.7495569586753845,
                0.869026243686676,
                0.7218402028083801,
                0.848260223865509,
                0.7761476039886475,
                0.8756499290466309,
                0.8613889217376709,
                0.8479424715042114
            ],
            [
                0.788945734500885,
                0.8991657495498657,
                0.7842471599578857,
                0.8942935466766357,
                0.7885028123855591,
                0.8730185031890869,
                0.8854435086250305,
                0.7922244668006897,
                0.5653819441795349,
                0.7648722529411316,
                0.8803640604019165,
                0.7549473643302917,
                0.8665459156036377,
                0.7617018818855286,
                0.8576405048370361,
                0.892990231513977,
                0.855792224407196,
                0.8118983507156372,
                0.8327068090438843,
                0.8270920515060425,
                0.8451381921768188,
                0.8071108460426331,
                0.771227240562439,
                0.8271980285644531,
                0.8108274340629578,
                0.9107089042663574,
                0.8217356204986572,
                0.8046644926071167,
                0.8598707318305969,
                0.8265385031700134,
                0.8239084482192993,
                0.651849627494812,
                0.8044362664222717,
                0.8941782712936401,
                0.83918696641922,
                0.8786659836769104,
                0.7756990790367126,
                0.8863226175308228,
                0.7774632573127747,
                0.8926911950111389,
                0.7680891752243042,
                0.8112819790840149,
                0.894088864326477,
                0.7447118759155273,
                0.922250509262085,
                0.6494138240814209,
                0.8075281977653503,
                0.7545797824859619,
                0.8504699468612671,
                0.8611242175102234,
                0.8301290273666382
            ],
            [
                0.8059954643249512,
                0.8572510480880737,
                0.7713215947151184,
                0.949832558631897,
                0.8121297955513,
                0.9080855250358582,
                0.8977863788604736,
                0.7813710570335388,
                0.6464501023292542,
                0.7744215130805969,
                0.8767595291137695,
                0.7960214614868164,
                0.8523353338241577,
                0.7434770464897156,
                0.825747013092041,
                0.8981562256813049,
                0.8385798931121826,
                0.8303078413009644,
                0.8785157203674316,
                0.8159752488136292,
                0.8691321611404419,
                0.8399960398674011,
                0.7381221055984497,
                0.8325964212417603,
                0.8130649328231812,
                0.9029069542884827,
                0.8285802602767944,
                0.8477783203125,
                0.8417940735816956,
                0.8675670027732849,
                0.789902925491333,
                0.7450063824653625,
                0.7677320241928101,
                0.8626325726509094,
                0.8185523152351379,
                0.8786042332649231,
                0.767824649810791,
                0.8570595979690552,
                0.7619258761405945,
                0.8813315033912659,
                0.7691283822059631,
                0.8128121495246887,
                0.9055531024932861,
                0.7370403409004211,
                0.9048663973808289,
                0.6831366419792175,
                0.8547171950340271,
                0.7699742913246155,
                0.872459888458252,
                0.8638331294059753,
                0.8239234685897827
            ],
            [
                0.8491231799125671,
                0.7470097541809082,
                0.8260602355003357,
                0.781741201877594,
                0.83086758852005,
                0.7679883241653442,
                0.7649115324020386,
                0.8581492900848389,
                0.6585146188735962,
                0.8191040754318237,
                0.7362291812896729,
                0.8873823881149292,
                0.7335931062698364,
                0.8008310794830322,
                0.8155197501182556,
                0.7782691121101379,
                0.8092434406280518,
                0.859988808631897,
                0.7322847843170166,
                0.7962821125984192,
                0.8625183701515198,
                0.7196222543716431,
                0.8067529797554016,
                0.7081130146980286,
                0.8593733310699463,
                0.7953078746795654,
                0.8634580373764038,
                0.7280397415161133,
                0.8531225919723511,
                0.7219452857971191,
                0.8339157104492188,
                0.5995824933052063,
                0.748794436454773,
                0.7362928986549377,
                0.8186963200569153,
                0.7253348231315613,
                0.7521260380744934,
                0.7291456460952759,
                0.82171231508255,
                0.7142989039421082,
                0.7621221542358398,
                0.8787105679512024,
                0.7507636547088623,
                0.8425649404525757,
                0.7414028644561768,
                0.7804014086723328,
                0.7198355197906494,
                0.8309032320976257,
                0.8378923535346985,
                0.7454856634140015,
                0.8416879773139954
            ],
            [
                0.8369644284248352,
                0.8625720143318176,
                0.866472601890564,
                0.8824535608291626,
                0.8040895462036133,
                0.8818725347518921,
                0.8803277015686035,
                0.8510514497756958,
                0.6054347157478333,
                0.8517976999282837,
                0.8731126189231873,
                0.8302063941955566,
                0.8480937480926514,
                0.7921397686004639,
                0.9019219279289246,
                0.8947056531906128,
                0.9181210994720459,
                0.8675965666770935,
                0.8409348130226135,
                0.8880120515823364,
                0.8900047540664673,
                0.8407843112945557,
                0.8406286835670471,
                0.8387573957443237,
                0.8708825707435608,
                0.9213692545890808,
                0.8800283074378967,
                0.8044830560684204,
                0.9046492576599121,
                0.8367459774017334,
                0.8471078276634216,
                0.7257934212684631,
                0.8510186672210693,
                0.878450870513916,
                0.8747679591178894,
                0.8765318393707275,
                0.8665142059326172,
                0.9039096236228943,
                0.8434770703315735,
                0.8828069567680359,
                0.8252880573272705,
                0.8908354043960571,
                0.8720752596855164,
                0.7309608459472656,
                0.8950181603431702,
                0.7090820074081421,
                0.8269739151000977,
                0.8423396348953247,
                0.8887687921524048,
                0.8734285831451416,
                0.8566727042198181
            ],
            [
                0.8262568712234497,
                0.8845573663711548,
                0.8321030735969543,
                0.9021621942520142,
                0.8100612759590149,
                0.8797829151153564,
                0.9086777567863464,
                0.8431764245033264,
                0.6200215816497803,
                0.8234588503837585,
                0.900994598865509,
                0.8167252540588379,
                0.8683000802993774,
                0.8065838813781738,
                0.8700587749481201,
                0.8936193585395813,
                0.8747745752334595,
                0.8689103722572327,
                0.8379972577095032,
                0.8601009845733643,
                0.8763740658760071,
                0.8015018105506897,
                0.7998489737510681,
                0.8270224928855896,
                0.8550732135772705,
                0.9386979341506958,
                0.8755477666854858,
                0.8056090474128723,
                0.887268602848053,
                0.8356492519378662,
                0.8589207530021667,
                0.655992865562439,
                0.8574087023735046,
                0.8969515562057495,
                0.8708518147468567,
                0.8716235160827637,
                0.8444308042526245,
                0.9142915606498718,
                0.8325045704841614,
                0.8863046765327454,
                0.8305799961090088,
                0.8634902834892273,
                0.8908484578132629,
                0.7861649990081787,
                0.9256038069725037,
                0.7073467373847961,
                0.8129771947860718,
                0.8376205563545227,
                0.8782482743263245,
                0.8781177997589111,
                0.8853426575660706
            ],
            [
                0.7931981086730957,
                0.7949419021606445,
                0.7584806084632874,
                0.8254348039627075,
                0.786082923412323,
                0.866438627243042,
                0.8528430461883545,
                0.7882043123245239,
                0.5984916090965271,
                0.7813919186592102,
                0.8487077951431274,
                0.793405294418335,
                0.8400023579597473,
                0.7487281560897827,
                0.7905080914497375,
                0.8401957750320435,
                0.8110526204109192,
                0.8103288412094116,
                0.8033361434936523,
                0.7896432280540466,
                0.8324425220489502,
                0.7882115244865417,
                0.7172510027885437,
                0.7929696440696716,
                0.793692946434021,
                0.8595430850982666,
                0.8037921786308289,
                0.7691024541854858,
                0.8161869645118713,
                0.8063656687736511,
                0.7754022479057312,
                0.6878751516342163,
                0.7946598529815674,
                0.8435801863670349,
                0.8282678723335266,
                0.8483096361160278,
                0.804533839225769,
                0.8637263178825378,
                0.8019298315048218,
                0.8478344678878784,
                0.7885479927062988,
                0.8118845820426941,
                0.8304903507232666,
                0.7302848100662231,
                0.8520461916923523,
                0.7010944485664368,
                0.7825958132743835,
                0.754866898059845,
                0.8108441233634949,
                0.814580500125885,
                0.8133851885795593
            ],
            [
                0.8573687076568604,
                0.8138229250907898,
                0.7652153372764587,
                0.8397860527038574,
                0.8612790107727051,
                0.8824021220207214,
                0.8470767736434937,
                0.780079185962677,
                0.6297483444213867,
                0.7935924530029297,
                0.8341273665428162,
                0.8537584543228149,
                0.8448050618171692,
                0.758573591709137,
                0.8261843323707581,
                0.8695799112319946,
                0.826145589351654,
                0.8101112246513367,
                0.8553858399391174,
                0.7956713438034058,
                0.8957577347755432,
                0.829749584197998,
                0.7265912294387817,
                0.8288493156433105,
                0.8010558485984802,
                0.8160450458526611,
                0.8014997839927673,
                0.8270666599273682,
                0.8392181992530823,
                0.8192636966705322,
                0.7654975056648254,
                0.7877352237701416,
                0.695324182510376,
                0.7974197268486023,
                0.82049161195755,
                0.8477014899253845,
                0.7181620597839355,
                0.7731556296348572,
                0.8064187169075012,
                0.8396949768066406,
                0.7183130383491516,
                0.8251432776451111,
                0.8269001245498657,
                0.7886332273483276,
                0.8153846263885498,
                0.7435352206230164,
                0.824729859828949,
                0.7421107888221741,
                0.8421454429626465,
                0.8353050351142883,
                0.8425211906433105
            ],
            [
                0.7713700532913208,
                0.8471964001655579,
                0.795562744140625,
                0.8629351854324341,
                0.785952091217041,
                0.8403527736663818,
                0.8594762682914734,
                0.8139190673828125,
                0.5662105083465576,
                0.7838692665100098,
                0.8568149209022522,
                0.7766404151916504,
                0.8366183042526245,
                0.7634578943252563,
                0.8337470889091492,
                0.8391783833503723,
                0.8450552821159363,
                0.8095141053199768,
                0.776127815246582,
                0.8374462723731995,
                0.8361671566963196,
                0.7729290723800659,
                0.8055617213249207,
                0.7894940376281738,
                0.8248938322067261,
                0.8985850214958191,
                0.8360989093780518,
                0.7482990622520447,
                0.8608256578445435,
                0.8044353127479553,
                0.822356104850769,
                0.6273831129074097,
                0.8369808197021484,
                0.8877391815185547,
                0.8604145050048828,
                0.8395426273345947,
                0.8295239210128784,
                0.888740062713623,
                0.8184254169464111,
                0.8499698042869568,
                0.8131756782531738,
                0.8329235315322876,
                0.8503071069717407,
                0.7443581223487854,
                0.8982595801353455,
                0.6865341663360596,
                0.763080894947052,
                0.7829355001449585,
                0.8416533470153809,
                0.8336085081100464,
                0.810142993927002
            ],
            [
                0.8929764032363892,
                0.8697947263717651,
                0.8633080720901489,
                0.8477824926376343,
                0.8497189283370972,
                0.8950349688529968,
                0.8799159526824951,
                0.8791325688362122,
                0.5876906514167786,
                0.8980767726898193,
                0.8864978551864624,
                0.9040290117263794,
                0.8683876395225525,
                0.8113808035850525,
                0.898927628993988,
                0.9030966758728027,
                0.9083736538887024,
                0.8893131017684937,
                0.8553737998008728,
                0.8903213143348694,
                0.9256893992424011,
                0.8645404577255249,
                0.8118357062339783,
                0.8655461072921753,
                0.8725780248641968,
                0.8886438608169556,
                0.8637155294418335,
                0.8241199851036072,
                0.9132068753242493,
                0.8324301242828369,
                0.8376705646514893,
                0.7543740272521973,
                0.8362410068511963,
                0.8669117093086243,
                0.8925204277038574,
                0.8863869905471802,
                0.8488865494728088,
                0.8645244240760803,
                0.8939447402954102,
                0.8840899467468262,
                0.8118695020675659,
                0.8902677893638611,
                0.8566896915435791,
                0.7751818895339966,
                0.8682578206062317,
                0.7919407486915588,
                0.8299205303192139,
                0.8636404871940613,
                0.8938995599746704,
                0.8782324194908142,
                0.9005740880966187
            ],
            [
                0.8508050441741943,
                0.8923627734184265,
                0.7937681078910828,
                0.883122980594635,
                0.8360222578048706,
                0.9195117950439453,
                0.9201094508171082,
                0.8245437741279602,
                0.5801917910575867,
                0.8229023218154907,
                0.9284437894821167,
                0.8352495431900024,
                0.9115128517150879,
                0.786628782749176,
                0.8558228611946106,
                0.9384883642196655,
                0.8599395751953125,
                0.8539311289787292,
                0.9157965183258057,
                0.840752363204956,
                0.8982950448989868,
                0.891995906829834,
                0.7441536784172058,
                0.9004005789756775,
                0.8247857689857483,
                0.9163791537284851,
                0.8360030055046082,
                0.8835768699645996,
                0.8754738569259644,
                0.8830509781837463,
                0.8108264207839966,
                0.7764334678649902,
                0.788897693157196,
                0.9007464647293091,
                0.858921229839325,
                0.9472976922988892,
                0.798974871635437,
                0.9091331958770752,
                0.8310519456863403,
                0.946474552154541,
                0.785485029220581,
                0.8401276469230652,
                0.9089761972427368,
                0.7456014156341553,
                0.9285142421722412,
                0.7307819128036499,
                0.8918160796165466,
                0.7959264516830444,
                0.8754494190216064,
                0.9280823469161987,
                0.8782933950424194
            ],
            [
                0.739046573638916,
                0.8075708746910095,
                0.7409502267837524,
                0.8588314652442932,
                0.7728251218795776,
                0.8110551834106445,
                0.8234888315200806,
                0.7292248010635376,
                0.6002873182296753,
                0.7092348337173462,
                0.8181798458099365,
                0.7017483711242676,
                0.7967966794967651,
                0.7248959541320801,
                0.7934600114822388,
                0.8242375254631042,
                0.7923812866210938,
                0.7523113489151001,
                0.7800883054733276,
                0.7878231406211853,
                0.7972561120986938,
                0.7720838785171509,
                0.7472512722015381,
                0.7677604556083679,
                0.7652486562728882,
                0.8429419994354248,
                0.7877410650253296,
                0.750787615776062,
                0.792538046836853,
                0.7835370898246765,
                0.7676219344139099,
                0.6822550892829895,
                0.7338647842407227,
                0.8206126093864441,
                0.7709585428237915,
                0.8111154437065125,
                0.7372121810913086,
                0.8326959609985352,
                0.7249190807342529,
                0.8253471851348877,
                0.7686794996261597,
                0.7681048512458801,
                0.838031530380249,
                0.7028213739395142,
                0.8535339832305908,
                0.6413444876670837,
                0.7777671813964844,
                0.7163317799568176,
                0.8236586451530457,
                0.8239915370941162,
                0.7741223573684692
            ],
            [
                0.8125087022781372,
                0.7398156523704529,
                0.7546321153640747,
                0.7332402467727661,
                0.8343095183372498,
                0.7673137187957764,
                0.7671692371368408,
                0.7820940017700195,
                0.6573684811592102,
                0.7585642337799072,
                0.785982608795166,
                0.7905629873275757,
                0.7741570472717285,
                0.801291823387146,
                0.7370561957359314,
                0.761402428150177,
                0.728412926197052,
                0.7827240824699402,
                0.7270770072937012,
                0.7400810718536377,
                0.7884427309036255,
                0.6991966366767883,
                0.6935038566589355,
                0.7327737808227539,
                0.7623598575592041,
                0.7567152380943298,
                0.7667142748832703,
                0.6956498026847839,
                0.7702563405036926,
                0.7160660028457642,
                0.7513158917427063,
                0.6522657871246338,
                0.7380837798118591,
                0.7362653613090515,
                0.8056475520133972,
                0.7565147876739502,
                0.7092297077178955,
                0.743548572063446,
                0.7998424172401428,
                0.7404114603996277,
                0.7460557222366333,
                0.7708660364151001,
                0.7454654574394226,
                0.7850069999694824,
                0.755121648311615,
                0.7646782398223877,
                0.710124671459198,
                0.7306582927703857,
                0.7799113988876343,
                0.7480186820030212,
                0.7891404032707214
            ],
            [
                0.8381302952766418,
                0.7426139116287231,
                0.7653831839561462,
                0.7509689927101135,
                0.8330748081207275,
                0.7708895206451416,
                0.7718311548233032,
                0.7976162433624268,
                0.6284623146057129,
                0.7876012921333313,
                0.7872949242591858,
                0.8401145935058594,
                0.7803149223327637,
                0.7644666433334351,
                0.7681109309196472,
                0.7714868783950806,
                0.7569320797920227,
                0.8098592162132263,
                0.7510784864425659,
                0.745258629322052,
                0.8240611553192139,
                0.7472258806228638,
                0.7070645689964294,
                0.7440904378890991,
                0.7712869048118591,
                0.7622875571250916,
                0.7717597484588623,
                0.7239758372306824,
                0.7876247763633728,
                0.7283849120140076,
                0.7664587497711182,
                0.7125503420829773,
                0.7016732096672058,
                0.7336227893829346,
                0.7818425893783569,
                0.7596554756164551,
                0.7332277297973633,
                0.7368053793907166,
                0.8009200096130371,
                0.7476023435592651,
                0.732533872127533,
                0.7890517115592957,
                0.7502833008766174,
                0.7435100078582764,
                0.7511592507362366,
                0.8093143701553345,
                0.7336887717247009,
                0.7578744888305664,
                0.7979751229286194,
                0.7798777222633362,
                0.8119606971740723
            ],
            [
                0.7266299724578857,
                0.7990422248840332,
                0.7278631329536438,
                0.8602845668792725,
                0.7746031284332275,
                0.8123739957809448,
                0.8211578726768494,
                0.7217814922332764,
                0.6282387971878052,
                0.7122572064399719,
                0.8166218400001526,
                0.7101643085479736,
                0.7977989912033081,
                0.712160587310791,
                0.7890306115150452,
                0.8209258913993835,
                0.7868393659591675,
                0.747506320476532,
                0.7818549275398254,
                0.779118537902832,
                0.7963646054267883,
                0.7728350162506104,
                0.7398701906204224,
                0.7592002749443054,
                0.7502517104148865,
                0.8243297338485718,
                0.7725399732589722,
                0.7508746385574341,
                0.7816896438598633,
                0.7869471907615662,
                0.7520920634269714,
                0.6871050596237183,
                0.7229172587394714,
                0.8073855638504028,
                0.7739608287811279,
                0.8088100552558899,
                0.7242802381515503,
                0.8210544586181641,
                0.7330430746078491,
                0.8246273398399353,
                0.758680522441864,
                0.7564991116523743,
                0.8291305303573608,
                0.7060940265655518,
                0.8420762419700623,
                0.6475127935409546,
                0.7795393466949463,
                0.7088724374771118,
                0.8203192949295044,
                0.8186807036399841,
                0.7653157711029053
            ],
            [
                0.7904579639434814,
                0.7435296177864075,
                0.7587578892707825,
                0.7597572803497314,
                0.8088021278381348,
                0.7705991268157959,
                0.7817052602767944,
                0.7916378974914551,
                0.6619656085968018,
                0.7910990715026855,
                0.8081779479980469,
                0.8010122179985046,
                0.7892587780952454,
                0.7782219052314758,
                0.7591365575790405,
                0.7705996632575989,
                0.7561131715774536,
                0.800022304058075,
                0.7387447357177734,
                0.7584453225135803,
                0.7935348749160767,
                0.7006920576095581,
                0.7256200313568115,
                0.7220538258552551,
                0.753635048866272,
                0.7695756554603577,
                0.7727617621421814,
                0.6946985125541687,
                0.7812599539756775,
                0.7204657196998596,
                0.7555084824562073,
                0.6496914625167847,
                0.75963294506073,
                0.7367914915084839,
                0.8286888599395752,
                0.7606627941131592,
                0.7414804100990295,
                0.772884726524353,
                0.82938551902771,
                0.7567748427391052,
                0.7894142866134644,
                0.7843132019042969,
                0.7600044012069702,
                0.7774121165275574,
                0.7719506621360779,
                0.7558435201644897,
                0.7258906364440918,
                0.7770942449569702,
                0.7933180928230286,
                0.7639780044555664,
                0.7882561087608337
            ],
            [
                0.8504177331924438,
                0.8262882232666016,
                0.7881066203117371,
                0.8274062275886536,
                0.8444240689277649,
                0.8448714017868042,
                0.8406894207000732,
                0.8285616636276245,
                0.6246820092201233,
                0.8259713649749756,
                0.8741204142570496,
                0.8621959090232849,
                0.8481619358062744,
                0.781269371509552,
                0.8194305300712585,
                0.8538012504577637,
                0.8203325867652893,
                0.842295229434967,
                0.8220247626304626,
                0.8102506399154663,
                0.8673648238182068,
                0.8162776231765747,
                0.7620071172714233,
                0.8190336227416992,
                0.8047024011611938,
                0.829937756061554,
                0.8055850267410278,
                0.7914408445358276,
                0.8471195101737976,
                0.8113642930984497,
                0.7943698763847351,
                0.740513801574707,
                0.7624426484107971,
                0.8179932832717896,
                0.8497098684310913,
                0.8508076071739197,
                0.7764790058135986,
                0.8346036672592163,
                0.8556644320487976,
                0.8493553996086121,
                0.7902411818504333,
                0.8298404812812805,
                0.826386570930481,
                0.7724023461341858,
                0.8441625833511353,
                0.7992686629295349,
                0.8044680953025818,
                0.7927451133728027,
                0.8518158197402954,
                0.8669989109039307,
                0.8453400135040283
            ],
            [
                0.8052894473075867,
                0.7938028573989868,
                0.7781291007995605,
                0.7893389463424683,
                0.826487123966217,
                0.7844135761260986,
                0.7978028655052185,
                0.8061002492904663,
                0.6389818787574768,
                0.8088983297348022,
                0.8513798713684082,
                0.7922408580780029,
                0.7947669625282288,
                0.804531455039978,
                0.7766458988189697,
                0.7877998352050781,
                0.7690539360046387,
                0.7984287142753601,
                0.7512333989143372,
                0.7894808053970337,
                0.8009677529335022,
                0.7255092263221741,
                0.7469820380210876,
                0.7666318416595459,
                0.7903961539268494,
                0.7961502075195312,
                0.7976828813552856,
                0.711126983165741,
                0.8106093406677246,
                0.741008460521698,
                0.7789309024810791,
                0.6812280416488647,
                0.7909648418426514,
                0.7758395075798035,
                0.8339744806289673,
                0.7831617593765259,
                0.7721382975578308,
                0.8055232167243958,
                0.8195495009422302,
                0.7805618047714233,
                0.8104861974716187,
                0.7905032634735107,
                0.7966539263725281,
                0.7921509742736816,
                0.814132571220398,
                0.7392928004264832,
                0.7493055462837219,
                0.7797878980636597,
                0.8303964734077454,
                0.798296332359314,
                0.8105320930480957
            ],
            [
                0.8867408633232117,
                0.8579337000846863,
                0.8252426981925964,
                0.8416393995285034,
                0.8627493977546692,
                0.8710836172103882,
                0.8599576354026794,
                0.8490064740180969,
                0.6281449198722839,
                0.8519643545150757,
                0.8812613487243652,
                0.8790072202682495,
                0.8569417595863342,
                0.8211996555328369,
                0.8653019666671753,
                0.877137303352356,
                0.8628854155540466,
                0.866416335105896,
                0.8353816866874695,
                0.8505662083625793,
                0.8873521089553833,
                0.8310261368751526,
                0.7991512417793274,
                0.8462426662445068,
                0.8427163362503052,
                0.8543857336044312,
                0.8385166525840759,
                0.8007310032844543,
                0.8873150944709778,
                0.8266913890838623,
                0.8281710147857666,
                0.7644191980361938,
                0.7957951426506042,
                0.8443965911865234,
                0.8815368413925171,
                0.8678421378135681,
                0.8031909465789795,
                0.8517434597015381,
                0.8720759749412537,
                0.860887885093689,
                0.8032581806182861,
                0.8647582530975342,
                0.8422027826309204,
                0.7855480909347534,
                0.8575758934020996,
                0.7957786917686462,
                0.8134953379631042,
                0.8123307228088379,
                0.8791323900222778,
                0.8722290992736816,
                0.8648617267608643
            ],
            [
                0.7779216766357422,
                0.7505896091461182,
                0.736183226108551,
                0.7583702802658081,
                0.804329514503479,
                0.763918936252594,
                0.7788251638412476,
                0.7801243662834167,
                0.6477946043014526,
                0.7728537321090698,
                0.8147743940353394,
                0.7674160599708557,
                0.7799039483070374,
                0.7776530385017395,
                0.7270801663398743,
                0.7554522156715393,
                0.7221492528915405,
                0.7765525579452515,
                0.7285041213035583,
                0.7442730069160461,
                0.770263135433197,
                0.6946856379508972,
                0.6925312280654907,
                0.72711181640625,
                0.7521095275878906,
                0.7645481824874878,
                0.7600306868553162,
                0.6903911828994751,
                0.7691210508346558,
                0.7179991006851196,
                0.7386082410812378,
                0.6453996300697327,
                0.7591127753257751,
                0.7497653961181641,
                0.8173297047615051,
                0.7588436007499695,
                0.7345378398895264,
                0.7844164967536926,
                0.8070668578147888,
                0.751115083694458,
                0.7839717268943787,
                0.7639214992523193,
                0.7626945972442627,
                0.7718063592910767,
                0.7760555148124695,
                0.7044738531112671,
                0.7228929400444031,
                0.7495258450508118,
                0.7806918025016785,
                0.7627095580101013,
                0.7698534727096558
            ],
            [
                0.857460618019104,
                0.8193763494491577,
                0.7882927060127258,
                0.8283394575119019,
                0.8740663528442383,
                0.8384732007980347,
                0.8405364751815796,
                0.8257364630699158,
                0.64622962474823,
                0.8079091906547546,
                0.8511471748352051,
                0.8407782316207886,
                0.8398089408874512,
                0.8092048764228821,
                0.8085111379623413,
                0.822394609451294,
                0.800319254398346,
                0.8329317569732666,
                0.7976937294006348,
                0.8003247976303101,
                0.856961190700531,
                0.7974973320960999,
                0.7514768838882446,
                0.7976729869842529,
                0.8203533291816711,
                0.8156155943870544,
                0.8068150877952576,
                0.7683507800102234,
                0.8372606039047241,
                0.7782886028289795,
                0.8003448247909546,
                0.7171254754066467,
                0.7463215589523315,
                0.8101449012756348,
                0.8413611650466919,
                0.827165424823761,
                0.7553733587265015,
                0.8102052211761475,
                0.8282055258750916,
                0.8218867182731628,
                0.7621217966079712,
                0.8247155547142029,
                0.8171891570091248,
                0.7784700989723206,
                0.8222088813781738,
                0.7780996561050415,
                0.7802904844284058,
                0.7773224115371704,
                0.8444393277168274,
                0.8317827582359314,
                0.8374152779579163
            ],
            [
                0.7887635231018066,
                0.8632274866104126,
                0.7509417533874512,
                0.8742920160293579,
                0.8307666778564453,
                0.8490314483642578,
                0.8702855706214905,
                0.7845675349235535,
                0.6098214387893677,
                0.7667123675346375,
                0.8954935073852539,
                0.7736810445785522,
                0.8588975667953491,
                0.7620928287506104,
                0.7944457530975342,
                0.8589250445365906,
                0.7952269911766052,
                0.8135230541229248,
                0.8242038488388062,
                0.8037660717964172,
                0.8373334407806396,
                0.7777656316757202,
                0.7510071396827698,
                0.8245337605476379,
                0.7849746346473694,
                0.8715688586235046,
                0.7914831638336182,
                0.7972733974456787,
                0.8266331553459167,
                0.8238436579704285,
                0.7844347953796387,
                0.6702175140380859,
                0.7860826849937439,
                0.8668438792228699,
                0.8331334590911865,
                0.8542600274085999,
                0.7687839865684509,
                0.873005211353302,
                0.8022624254226685,
                0.8582892417907715,
                0.802888810634613,
                0.7983677983283997,
                0.8819501399993896,
                0.7787746787071228,
                0.9110836386680603,
                0.7147697806358337,
                0.8173454999923706,
                0.7678431272506714,
                0.8526796698570251,
                0.869280219078064,
                0.8307905197143555
            ],
            [
                0.8302425742149353,
                0.7960565090179443,
                0.7937036156654358,
                0.8117187023162842,
                0.8662769198417664,
                0.8236802816390991,
                0.8187240958213806,
                0.8256471753120422,
                0.665401816368103,
                0.8044427037239075,
                0.8428318500518799,
                0.8354098200798035,
                0.8231346011161804,
                0.8056467175483704,
                0.7997408509254456,
                0.8114737272262573,
                0.7946491241455078,
                0.8331858515739441,
                0.7722797989845276,
                0.7962571978569031,
                0.8444797396659851,
                0.7483094334602356,
                0.7717199921607971,
                0.7693918347358704,
                0.799860954284668,
                0.8023632764816284,
                0.8084799647331238,
                0.7451292872428894,
                0.8260594010353088,
                0.7678807973861694,
                0.8086270093917847,
                0.6653777956962585,
                0.7772474884986877,
                0.7988616228103638,
                0.8383106589317322,
                0.8070428967475891,
                0.776889443397522,
                0.8082066774368286,
                0.8326957821846008,
                0.7984127402305603,
                0.7955392003059387,
                0.8268756866455078,
                0.8035021424293518,
                0.7939048409461975,
                0.8211783766746521,
                0.7732623219490051,
                0.7517264485359192,
                0.7671053409576416,
                0.8483737707138062,
                0.8001891374588013,
                0.8232030272483826
            ],
            [
                0.7914595603942871,
                0.7908056378364563,
                0.7657656669616699,
                0.8241430521011353,
                0.8160300254821777,
                0.7970231175422668,
                0.8216099739074707,
                0.7933472990989685,
                0.6707501411437988,
                0.7741937637329102,
                0.8328523635864258,
                0.7864646315574646,
                0.802141010761261,
                0.7897840142250061,
                0.7751680016517639,
                0.7939407229423523,
                0.7652341723442078,
                0.8187225461006165,
                0.7429851293563843,
                0.7668542861938477,
                0.8217744827270508,
                0.7135928273200989,
                0.7342664003372192,
                0.7317538261413574,
                0.7723026275634766,
                0.8138234615325928,
                0.8167093396186829,
                0.7195237278938293,
                0.7989982962608337,
                0.7526381611824036,
                0.8004252910614014,
                0.628467321395874,
                0.7891086935997009,
                0.7945284247398376,
                0.8303437829017639,
                0.783009946346283,
                0.7582810521125793,
                0.8162742257118225,
                0.7884576916694641,
                0.7898375988006592,
                0.8080141544342041,
                0.7991995811462402,
                0.7995081543922424,
                0.8025381565093994,
                0.8280521035194397,
                0.7236388921737671,
                0.727556586265564,
                0.745526134967804,
                0.8214705586433411,
                0.7833293676376343,
                0.8205405473709106
            ],
            [
                0.876407265663147,
                0.8575103878974915,
                0.8348801136016846,
                0.8660551309585571,
                0.8768081068992615,
                0.8760887980461121,
                0.8676008582115173,
                0.8509727716445923,
                0.6423084139823914,
                0.8372363448143005,
                0.8692682385444641,
                0.8796916604042053,
                0.85164475440979,
                0.8192076086997986,
                0.8782978653907776,
                0.8758569955825806,
                0.8751921057701111,
                0.8702759742736816,
                0.82719886302948,
                0.861592173576355,
                0.9092951416969299,
                0.817986249923706,
                0.821225643157959,
                0.8249520659446716,
                0.8417167067527771,
                0.865734338760376,
                0.8570418357849121,
                0.8074241876602173,
                0.891446053981781,
                0.8275890350341797,
                0.8459278345108032,
                0.7284980416297913,
                0.8094992637634277,
                0.8501805067062378,
                0.8636044859886169,
                0.8520298600196838,
                0.8088688850402832,
                0.8479493260383606,
                0.8515159487724304,
                0.8510880470275879,
                0.802653968334198,
                0.8720985651016235,
                0.85036700963974,
                0.8027706146240234,
                0.8639612197875977,
                0.7933728098869324,
                0.8143681287765503,
                0.8172152638435364,
                0.8970868587493896,
                0.8669896721839905,
                0.880537748336792
            ],
            [
                0.7525767087936401,
                0.8131167888641357,
                0.7444103360176086,
                0.8486624360084534,
                0.7901563048362732,
                0.8322731852531433,
                0.8401746153831482,
                0.7531073093414307,
                0.6310474872589111,
                0.7331171035766602,
                0.8394898772239685,
                0.739675760269165,
                0.8180515170097351,
                0.7313944101333618,
                0.790068507194519,
                0.8297510743141174,
                0.797335684299469,
                0.7810204029083252,
                0.7860003709793091,
                0.7896867990493774,
                0.816726803779602,
                0.7468539476394653,
                0.7426012754440308,
                0.765862762928009,
                0.7597227692604065,
                0.8518015146255493,
                0.7797971963882446,
                0.7484674453735352,
                0.8039882779121399,
                0.8040514588356018,
                0.7860313057899475,
                0.6353037357330322,
                0.7881293892860413,
                0.8470320701599121,
                0.821066677570343,
                0.8248926997184753,
                0.7887482047080994,
                0.8690606355667114,
                0.785743772983551,
                0.8278107047080994,
                0.8030872941017151,
                0.7841238379478455,
                0.8540416359901428,
                0.7217751145362854,
                0.8770011067390442,
                0.6787502765655518,
                0.763540506362915,
                0.7284663915634155,
                0.8169635534286499,
                0.8164088726043701,
                0.7881576418876648
            ],
            [
                0.7744905352592468,
                0.8010556697845459,
                0.783532977104187,
                0.8490445613861084,
                0.7915021777153015,
                0.8070663213729858,
                0.8351938724517822,
                0.7870482206344604,
                0.6472225785255432,
                0.7651591897010803,
                0.8341113924980164,
                0.7671003341674805,
                0.8184378743171692,
                0.7696544528007507,
                0.8175073266029358,
                0.8119504451751709,
                0.8178896903991699,
                0.8117762804031372,
                0.7554854154586792,
                0.793813943862915,
                0.8322122693061829,
                0.7252780795097351,
                0.7709800004959106,
                0.7252153158187866,
                0.7767806649208069,
                0.8501209616661072,
                0.8312985897064209,
                0.7200387120246887,
                0.8213568925857544,
                0.7616791725158691,
                0.8392202258110046,
                0.6135709285736084,
                0.811141848564148,
                0.8202414512634277,
                0.8332750201225281,
                0.8000019192695618,
                0.8213615417480469,
                0.8656902313232422,
                0.7922981381416321,
                0.8149036765098572,
                0.8249701857566833,
                0.8224697113037109,
                0.8292670249938965,
                0.758827269077301,
                0.8652569055557251,
                0.682547926902771,
                0.7350562810897827,
                0.7577441334724426,
                0.833904504776001,
                0.7971529960632324,
                0.8220108151435852
            ],
            [
                0.8653057217597961,
                0.8533098101615906,
                0.8365685939788818,
                0.8740114569664001,
                0.8849491477012634,
                0.8518472909927368,
                0.8592896461486816,
                0.8495234251022339,
                0.6418169140815735,
                0.8153327107429504,
                0.8507621884346008,
                0.8498995900154114,
                0.8355786204338074,
                0.8373180627822876,
                0.8604714870452881,
                0.8625816106796265,
                0.8518180847167969,
                0.8570106029510498,
                0.8035085201263428,
                0.850031316280365,
                0.8977154493331909,
                0.8003162145614624,
                0.8185068964958191,
                0.8081750869750977,
                0.8456955552101135,
                0.8607353568077087,
                0.866032600402832,
                0.7896912693977356,
                0.8789486289024353,
                0.7943131327629089,
                0.8526250123977661,
                0.7075523138046265,
                0.7998009324073792,
                0.840764045715332,
                0.8549719452857971,
                0.839325487613678,
                0.7797501683235168,
                0.828528642654419,
                0.8270363211631775,
                0.8391739130020142,
                0.7997965812683105,
                0.8670329451560974,
                0.8487483263015747,
                0.8169876337051392,
                0.8644880056381226,
                0.7639972567558289,
                0.7862045764923096,
                0.8005887269973755,
                0.9043731689453125,
                0.8434758186340332,
                0.863783597946167
            ],
            [
                0.7631990313529968,
                0.8107988238334656,
                0.7329815030097961,
                0.8523328900337219,
                0.7939771413803101,
                0.8331473469734192,
                0.8522276282310486,
                0.7605827450752258,
                0.6674803495407104,
                0.7384878993034363,
                0.850990891456604,
                0.754365086555481,
                0.8310574293136597,
                0.7322480082511902,
                0.7710390090942383,
                0.8345843553543091,
                0.7749309539794922,
                0.787482738494873,
                0.7993507385253906,
                0.7759259939193726,
                0.8182997703552246,
                0.7505017518997192,
                0.7185783386230469,
                0.7703203558921814,
                0.7573704719543457,
                0.8482972383499146,
                0.7774029970169067,
                0.7602910399436951,
                0.7938408851623535,
                0.8027378916740417,
                0.7806823253631592,
                0.6325113773345947,
                0.7690211534500122,
                0.8347407579421997,
                0.8201444149017334,
                0.8239860534667969,
                0.7678180932998657,
                0.8526558876037598,
                0.7932348251342773,
                0.8222325444221497,
                0.7926944494247437,
                0.7781293988227844,
                0.8485109210014343,
                0.7601346373558044,
                0.8693447113037109,
                0.6829851269721985,
                0.7667551636695862,
                0.7342596650123596,
                0.8123317956924438,
                0.8226985931396484,
                0.8054379224777222
            ],
            [
                0.7544313073158264,
                0.7671976685523987,
                0.7189813852310181,
                0.8116158843040466,
                0.7998390197753906,
                0.7714658379554749,
                0.8024504780769348,
                0.7449636459350586,
                0.6700993180274963,
                0.7102982401847839,
                0.8048269748687744,
                0.7316035032272339,
                0.7826496362686157,
                0.7429659366607666,
                0.7343652248382568,
                0.7681288719177246,
                0.7231873273849487,
                0.7684760689735413,
                0.7252064943313599,
                0.735082745552063,
                0.7756994366645813,
                0.6750001311302185,
                0.6993727684020996,
                0.7085359692573547,
                0.7231664657592773,
                0.7782158255577087,
                0.7528951168060303,
                0.698981761932373,
                0.7535408735275269,
                0.7286509275436401,
                0.7601091861724854,
                0.5925461649894714,
                0.7362499237060547,
                0.7670033574104309,
                0.7978918552398682,
                0.7559492588043213,
                0.7038983106613159,
                0.7704261541366577,
                0.7488791942596436,
                0.7565591931343079,
                0.7626547813415527,
                0.748873233795166,
                0.7877888679504395,
                0.7741502523422241,
                0.8062430024147034,
                0.6808873414993286,
                0.7002739906311035,
                0.7016043066978455,
                0.7958528995513916,
                0.7500892877578735,
                0.7632608413696289
            ],
            [
                0.8726258873939514,
                0.8665856719017029,
                0.8553320169448853,
                0.8841254115104675,
                0.8896991610527039,
                0.8623461127281189,
                0.8689166307449341,
                0.8614488840103149,
                0.6472537517547607,
                0.840066134929657,
                0.8693590760231018,
                0.867721676826477,
                0.8459051847457886,
                0.8390341997146606,
                0.8861350417137146,
                0.8756029009819031,
                0.878110408782959,
                0.8714969158172607,
                0.8188967704772949,
                0.8785915374755859,
                0.9077281355857849,
                0.8195902705192566,
                0.8485507965087891,
                0.8259955048561096,
                0.8626316785812378,
                0.8758202195167542,
                0.8747773170471191,
                0.8033668994903564,
                0.903337299823761,
                0.8187493085861206,
                0.8686526417732239,
                0.724520742893219,
                0.8179000616073608,
                0.8624926805496216,
                0.8775728344917297,
                0.850477933883667,
                0.8166611790657043,
                0.8536168336868286,
                0.8518736362457275,
                0.8515201210975647,
                0.8200549483299255,
                0.8842264413833618,
                0.8698049187660217,
                0.8192669153213501,
                0.8808174729347229,
                0.7844294309616089,
                0.8094035387039185,
                0.8251484632492065,
                0.9192582964897156,
                0.8683613538742065,
                0.8794299364089966
            ],
            [
                0.8339227437973022,
                0.7945957183837891,
                0.8195526003837585,
                0.7845482230186462,
                0.8266870379447937,
                0.7912061810493469,
                0.7911913394927979,
                0.8529021143913269,
                0.6408495903015137,
                0.8717535734176636,
                0.8494700193405151,
                0.8438770771026611,
                0.7887246608734131,
                0.8101919889450073,
                0.8033904433250427,
                0.8012581467628479,
                0.8057143092155457,
                0.8417484760284424,
                0.7523191571235657,
                0.8218997716903687,
                0.829146683216095,
                0.7313403487205505,
                0.7811298966407776,
                0.7684577107429504,
                0.8216116428375244,
                0.804192304611206,
                0.8290256857872009,
                0.7062559127807617,
                0.8358830809593201,
                0.7282508611679077,
                0.8121305108070374,
                0.6751955151557922,
                0.8257312774658203,
                0.7717905640602112,
                0.8597378134727478,
                0.7772877812385559,
                0.821738600730896,
                0.812726616859436,
                0.8650286197662354,
                0.7733975648880005,
                0.8432237505912781,
                0.8288145661354065,
                0.7886643409729004,
                0.8124492764472961,
                0.8066196441650391,
                0.7653546333312988,
                0.7399715781211853,
                0.8341944813728333,
                0.8544265031814575,
                0.7946385741233826,
                0.8458771705627441
            ],
            [
                0.8545694351196289,
                0.8085436820983887,
                0.8011041879653931,
                0.8294883966445923,
                0.8733623027801514,
                0.8458096981048584,
                0.8366328477859497,
                0.8242440819740295,
                0.6698704957962036,
                0.8211816549301147,
                0.8591836094856262,
                0.8644753098487854,
                0.83553546667099,
                0.8046552538871765,
                0.8246114253997803,
                0.8436434268951416,
                0.8181919455528259,
                0.8436878323554993,
                0.8205887079238892,
                0.8034082651138306,
                0.8681756854057312,
                0.8076099157333374,
                0.771062970161438,
                0.8073441386222839,
                0.8205015063285828,
                0.8204885125160217,
                0.8127989768981934,
                0.7867467403411865,
                0.8391517400741577,
                0.8048037886619568,
                0.801221489906311,
                0.7643907070159912,
                0.749671459197998,
                0.8082372546195984,
                0.8425753116607666,
                0.8343748450279236,
                0.7793251872062683,
                0.8136855363845825,
                0.8429645299911499,
                0.8285785913467407,
                0.7877313494682312,
                0.8361407518386841,
                0.8188552260398865,
                0.779430627822876,
                0.8272057175636292,
                0.7979916334152222,
                0.7987319231033325,
                0.7906203866004944,
                0.8643733263015747,
                0.845552384853363,
                0.8398829698562622
            ],
            [
                0.7749494314193726,
                0.7534688115119934,
                0.7552761435508728,
                0.7524845600128174,
                0.8027182221412659,
                0.7647549510002136,
                0.775077223777771,
                0.7920005917549133,
                0.6426666975021362,
                0.794201135635376,
                0.833263099193573,
                0.7782411575317383,
                0.7845216989517212,
                0.7806879281997681,
                0.742479681968689,
                0.7678670287132263,
                0.7400927543640137,
                0.775022029876709,
                0.7343695163726807,
                0.7698466777801514,
                0.7751650810241699,
                0.7132562398910522,
                0.7244419455528259,
                0.7366064786911011,
                0.7560182809829712,
                0.7640547752380371,
                0.7610926032066345,
                0.6952504515647888,
                0.7783885598182678,
                0.7238085865974426,
                0.744968056678772,
                0.6599215865135193,
                0.7668713331222534,
                0.7564018368721008,
                0.8091794848442078,
                0.7639355659484863,
                0.7544244527816772,
                0.7846269607543945,
                0.8094121813774109,
                0.7595217823982239,
                0.7909161448478699,
                0.7626982927322388,
                0.7705182433128357,
                0.7699017524719238,
                0.7789943218231201,
                0.7161625623703003,
                0.7326115369796753,
                0.7690185308456421,
                0.7979254722595215,
                0.7726147770881653,
                0.7892115116119385
            ],
            [
                0.8895313739776611,
                0.8251721858978271,
                0.849947452545166,
                0.8339516520500183,
                0.8682916760444641,
                0.873367190361023,
                0.8537026047706604,
                0.8719517588615417,
                0.6381639838218689,
                0.8824070692062378,
                0.8720448017120361,
                0.9185363054275513,
                0.8423932790756226,
                0.8227441906929016,
                0.8674276471138,
                0.8692237734794617,
                0.8693503141403198,
                0.8842085003852844,
                0.840685248374939,
                0.8546422123908997,
                0.9139033555984497,
                0.8528763651847839,
                0.7931649088859558,
                0.8354015946388245,
                0.8563342690467834,
                0.8477525115013123,
                0.858870267868042,
                0.8121092319488525,
                0.88082355260849,
                0.8156108856201172,
                0.8353523015975952,
                0.7695896029472351,
                0.8016372323036194,
                0.827159583568573,
                0.8644188046455383,
                0.8671702742576599,
                0.8250973224639893,
                0.8381555676460266,
                0.872706949710846,
                0.856978178024292,
                0.7956993579864502,
                0.8734579086303711,
                0.8257066607475281,
                0.7623533010482788,
                0.8325793743133545,
                0.8114690184593201,
                0.8140857815742493,
                0.828301727771759,
                0.8903511166572571,
                0.8644315004348755,
                0.8732845783233643
            ],
            [
                0.8284400701522827,
                0.8848752975463867,
                0.7728655934333801,
                0.879286527633667,
                0.8159312009811401,
                0.933928370475769,
                0.9190643429756165,
                0.7936944961547852,
                0.5637198090553284,
                0.8007263541221619,
                0.9271320104598999,
                0.8208255171775818,
                0.9102581143379211,
                0.7541692852973938,
                0.8374086618423462,
                0.9458423256874084,
                0.8537817001342773,
                0.8271348476409912,
                0.919194221496582,
                0.8263713717460632,
                0.8869200944900513,
                0.8985128998756409,
                0.7278738021850586,
                0.9062116146087646,
                0.8050915002822876,
                0.9093309640884399,
                0.8077869415283203,
                0.887868344783783,
                0.8530309200286865,
                0.8921328783035278,
                0.7843130230903625,
                0.7847136855125427,
                0.7686046361923218,
                0.8946002721786499,
                0.8378962874412537,
                0.9576793313026428,
                0.7772397994995117,
                0.8944288492202759,
                0.8068477511405945,
                0.9601156711578369,
                0.7533634305000305,
                0.8145528435707092,
                0.8993373513221741,
                0.7122746109962463,
                0.9232437610626221,
                0.7023628354072571,
                0.8846288323402405,
                0.7639217972755432,
                0.8597488403320312,
                0.925614595413208,
                0.8495426177978516
            ],
            [
                0.7425537705421448,
                0.8057271242141724,
                0.7407873272895813,
                0.874786376953125,
                0.7885220050811768,
                0.8225932121276855,
                0.8419747948646545,
                0.736798882484436,
                0.648497998714447,
                0.7220281958580017,
                0.8315525650978088,
                0.7172138690948486,
                0.8100229501724243,
                0.7267246246337891,
                0.7886836528778076,
                0.8264356255531311,
                0.7838563919067383,
                0.7604663968086243,
                0.7911010980606079,
                0.7862266898155212,
                0.8013851642608643,
                0.7827267050743103,
                0.7330024838447571,
                0.7693500518798828,
                0.7598366141319275,
                0.831532895565033,
                0.7780693769454956,
                0.7599479556083679,
                0.7898316979408264,
                0.8002745509147644,
                0.7585599422454834,
                0.7038606405258179,
                0.7349802255630493,
                0.823803722858429,
                0.7863188982009888,
                0.8191766142845154,
                0.7313302755355835,
                0.8250246644020081,
                0.7374700903892517,
                0.8276941776275635,
                0.7633264064788818,
                0.7623871564865112,
                0.8384637236595154,
                0.7114284038543701,
                0.8468968868255615,
                0.654466986656189,
                0.785227358341217,
                0.7198838591575623,
                0.8266302347183228,
                0.8270959258079529,
                0.7701095938682556
            ],
            [
                0.7998645901679993,
                0.7754210233688354,
                0.7750028967857361,
                0.796110212802887,
                0.8193159699440002,
                0.7985227108001709,
                0.8202642202377319,
                0.8292102217674255,
                0.6512033939361572,
                0.8245595693588257,
                0.8249135613441467,
                0.7982499599456787,
                0.8186324834823608,
                0.7890303730964661,
                0.7592220306396484,
                0.778717041015625,
                0.766547679901123,
                0.7998139262199402,
                0.7423108220100403,
                0.7965322732925415,
                0.7874292135238647,
                0.7390907406806946,
                0.7518094182014465,
                0.7418414950370789,
                0.8006318807601929,
                0.7965234518051147,
                0.7876845002174377,
                0.6994210481643677,
                0.8106780052185059,
                0.7281982898712158,
                0.776854395866394,
                0.6497284173965454,
                0.8024005889892578,
                0.7907446622848511,
                0.8478615880012512,
                0.7861435413360596,
                0.7819470167160034,
                0.7984257936477661,
                0.8527302742004395,
                0.7779922485351562,
                0.7958892583847046,
                0.8115962147712708,
                0.7912926077842712,
                0.7775108218193054,
                0.7931411862373352,
                0.7160558104515076,
                0.7217035889625549,
                0.8000555038452148,
                0.8135971426963806,
                0.7628427743911743,
                0.7798970341682434
            ],
            [
                0.8861066102981567,
                0.7758212089538574,
                0.8516400456428528,
                0.7865712642669678,
                0.8392338752746582,
                0.8145673871040344,
                0.8118162751197815,
                0.8621305823326111,
                0.6380999088287354,
                0.8947231769561768,
                0.833588719367981,
                0.9127353429794312,
                0.8088110685348511,
                0.8062872290611267,
                0.8657891750335693,
                0.8188391327857971,
                0.862637460231781,
                0.8838791847229004,
                0.7763845324516296,
                0.8392823934555054,
                0.8839467167854309,
                0.7868544459342957,
                0.7977737188339233,
                0.7700256109237671,
                0.8318037390708923,
                0.8018021583557129,
                0.8355775475502014,
                0.7384183406829834,
                0.8613101243972778,
                0.7433423399925232,
                0.8363005518913269,
                0.7168274521827698,
                0.7994198203086853,
                0.7655239701271057,
                0.8495008945465088,
                0.7956929206848145,
                0.8268908858299255,
                0.797679603099823,
                0.8666989803314209,
                0.7923078536987305,
                0.7860741019248962,
                0.8659128546714783,
                0.7745869159698486,
                0.7415329813957214,
                0.7783796191215515,
                0.8191561102867126,
                0.7506245374679565,
                0.845845639705658,
                0.8663892149925232,
                0.8064422607421875,
                0.8779217004776001
            ],
            [
                0.7602109909057617,
                0.7580194473266602,
                0.7334789633750916,
                0.786354124546051,
                0.798668384552002,
                0.7726200222969055,
                0.7818015217781067,
                0.7571426033973694,
                0.6572822332382202,
                0.7480795383453369,
                0.7985995411872864,
                0.7481983304023743,
                0.7600979804992676,
                0.7397170662879944,
                0.7402071356773376,
                0.7535900473594666,
                0.7325295805931091,
                0.7770931720733643,
                0.7219365239143372,
                0.7452212572097778,
                0.7755171656608582,
                0.696082592010498,
                0.6892492771148682,
                0.7212228775024414,
                0.7497759461402893,
                0.768945038318634,
                0.7545238733291626,
                0.6863259077072144,
                0.7682856321334839,
                0.7281268835067749,
                0.751035749912262,
                0.6292503476142883,
                0.7489243149757385,
                0.7735363245010376,
                0.8056891560554504,
                0.7563186883926392,
                0.733140230178833,
                0.7724431753158569,
                0.7815963625907898,
                0.7486074566841125,
                0.7626400589942932,
                0.7563236951828003,
                0.7735306024551392,
                0.7423467636108398,
                0.779900848865509,
                0.69685298204422,
                0.7022022604942322,
                0.7122694849967957,
                0.7908684015274048,
                0.7472485899925232,
                0.7473854422569275
            ],
            [
                0.866618275642395,
                0.8100680112838745,
                0.7974817752838135,
                0.8138449192047119,
                0.8385864496231079,
                0.8516165614128113,
                0.8325614929199219,
                0.836782693862915,
                0.5913686752319336,
                0.8635365962982178,
                0.8692992925643921,
                0.8790629506111145,
                0.8310295939445496,
                0.7716256976127625,
                0.8347097635269165,
                0.8593183159828186,
                0.8428937196731567,
                0.8604377508163452,
                0.841376781463623,
                0.8224884867668152,
                0.8847836256027222,
                0.8262279629707336,
                0.7622399926185608,
                0.8216542601585388,
                0.8066697716712952,
                0.8198812007904053,
                0.8125714063644409,
                0.7919701337814331,
                0.8572140336036682,
                0.7837332487106323,
                0.795760452747345,
                0.7655720710754395,
                0.7519813776016235,
                0.7876260876655579,
                0.8361606001853943,
                0.8427279591560364,
                0.8028629422187805,
                0.8312906622886658,
                0.8673409223556519,
                0.8427637219429016,
                0.7775448560714722,
                0.8445574045181274,
                0.8100466132164001,
                0.7486394047737122,
                0.8206104636192322,
                0.768988847732544,
                0.8119949102401733,
                0.8209977746009827,
                0.856955349445343,
                0.8599817156791687,
                0.8776873350143433
            ],
            [
                0.7998032569885254,
                0.7670950293540955,
                0.7642430663108826,
                0.7820038199424744,
                0.8179510235786438,
                0.7892497777938843,
                0.7855116724967957,
                0.80506831407547,
                0.6419918537139893,
                0.8115239143371582,
                0.8320592045783997,
                0.7973993420600891,
                0.7819250822067261,
                0.7896173000335693,
                0.7535325288772583,
                0.7746327519416809,
                0.7583960294723511,
                0.8001973032951355,
                0.7383670210838318,
                0.7840040326118469,
                0.7944498062133789,
                0.7191528081893921,
                0.7327359318733215,
                0.7481461763381958,
                0.7777986526489258,
                0.7816533446311951,
                0.7851297855377197,
                0.7022305130958557,
                0.7934502959251404,
                0.7279850840568542,
                0.7601044178009033,
                0.6535428762435913,
                0.7950525283813477,
                0.768374502658844,
                0.8331059217453003,
                0.7767411470413208,
                0.769038200378418,
                0.7963038682937622,
                0.8342641592025757,
                0.771044909954071,
                0.7990941405296326,
                0.7892143130302429,
                0.7786661386489868,
                0.7807838916778564,
                0.7921914458274841,
                0.723946750164032,
                0.7257605791091919,
                0.7688344120979309,
                0.8191611170768738,
                0.7763329148292542,
                0.7806177735328674
            ],
            [
                0.7648457288742065,
                0.7714530229568481,
                0.7433821558952332,
                0.7825891375541687,
                0.8077124357223511,
                0.7547016739845276,
                0.7597507238388062,
                0.7668184041976929,
                0.6251521706581116,
                0.7546228766441345,
                0.8004587888717651,
                0.7519830465316772,
                0.7519739866256714,
                0.7624236345291138,
                0.7418155074119568,
                0.7482913136482239,
                0.7293481826782227,
                0.778425931930542,
                0.7046164274215698,
                0.7542347311973572,
                0.7776462435722351,
                0.6871321797370911,
                0.7165536880493164,
                0.7198015451431274,
                0.7565023303031921,
                0.7647137641906738,
                0.7665332555770874,
                0.6765196919441223,
                0.7775465250015259,
                0.7083584070205688,
                0.765419065952301,
                0.6136186122894287,
                0.7748990654945374,
                0.7719740867614746,
                0.7948336005210876,
                0.7476365566253662,
                0.7475861310958862,
                0.7792309522628784,
                0.7730568051338196,
                0.7413259148597717,
                0.7920102477073669,
                0.7607383131980896,
                0.7746302485466003,
                0.7783413529396057,
                0.7897258996963501,
                0.7240639328956604,
                0.6893017292022705,
                0.7153429985046387,
                0.8080345392227173,
                0.7618722319602966,
                0.7505936622619629
            ],
            [
                0.7957331538200378,
                0.6967047452926636,
                0.720664918422699,
                0.7339415550231934,
                0.7967616319656372,
                0.7592260837554932,
                0.7513106465339661,
                0.7544794678688049,
                0.6540581583976746,
                0.7567241787910461,
                0.7683735489845276,
                0.8057889938354492,
                0.7696113586425781,
                0.7365087270736694,
                0.7390194535255432,
                0.7536650896072388,
                0.7247818112373352,
                0.774402916431427,
                0.7386640906333923,
                0.7001890540122986,
                0.8074347376823425,
                0.7374075651168823,
                0.6789153218269348,
                0.6998931765556335,
                0.7291154861450195,
                0.7211936116218567,
                0.7354528903961182,
                0.6937557458877563,
                0.7490193843841553,
                0.7073467373847961,
                0.7255611419677734,
                0.6871488690376282,
                0.667923092842102,
                0.7071011066436768,
                0.7476633191108704,
                0.7428047060966492,
                0.71201491355896,
                0.7240509986877441,
                0.7797784209251404,
                0.7328815460205078,
                0.7268304824829102,
                0.7645706534385681,
                0.720244824886322,
                0.7350748181343079,
                0.7259035706520081,
                0.7665339112281799,
                0.7064532041549683,
                0.7179173231124878,
                0.7595956325531006,
                0.7576327323913574,
                0.7942057251930237
            ],
            [
                0.8762795925140381,
                0.8015095591545105,
                0.821013867855072,
                0.8342618346214294,
                0.8563664555549622,
                0.8442709445953369,
                0.8284531831741333,
                0.8710583448410034,
                0.6159835457801819,
                0.8849245309829712,
                0.8652138710021973,
                0.9064356088638306,
                0.823667049407959,
                0.7973392009735107,
                0.8432294130325317,
                0.8396177291870117,
                0.847878098487854,
                0.8725895881652832,
                0.8072852492332458,
                0.8317863941192627,
                0.888661801815033,
                0.8040881752967834,
                0.7855134606361389,
                0.7823399305343628,
                0.8154228925704956,
                0.8198407888412476,
                0.8379226922988892,
                0.7684557437896729,
                0.8720529079437256,
                0.7678502798080444,
                0.8306252956390381,
                0.7348965406417847,
                0.7877770662307739,
                0.7864851355552673,
                0.8366854786872864,
                0.8256626129150391,
                0.8218291401863098,
                0.8303975462913513,
                0.860191285610199,
                0.8259965181350708,
                0.7910147309303284,
                0.85560142993927,
                0.8095458745956421,
                0.7651506662368774,
                0.819288432598114,
                0.790052056312561,
                0.7829321622848511,
                0.8210015296936035,
                0.8814622759819031,
                0.8390751481056213,
                0.8779734373092651
            ],
            [
                0.7639877200126648,
                0.7912150621414185,
                0.761718213558197,
                0.8435521125793457,
                0.8003517389297485,
                0.7887667417526245,
                0.8175404667854309,
                0.7634581327438354,
                0.6731866598129272,
                0.7402271032333374,
                0.8249605894088745,
                0.7419163584709167,
                0.7924183011054993,
                0.7755289077758789,
                0.7720688581466675,
                0.7886924743652344,
                0.77066570520401,
                0.7807013392448425,
                0.7407934069633484,
                0.7663893103599548,
                0.7886523604393005,
                0.6938591003417969,
                0.7440065741539001,
                0.7331618666648865,
                0.7598105072975159,
                0.8168188333511353,
                0.7803495526313782,
                0.7046816945075989,
                0.7878936529159546,
                0.7518605589866638,
                0.7914187908172607,
                0.6227542161941528,
                0.7845016717910767,
                0.7962337732315063,
                0.8150407671928406,
                0.7761641144752502,
                0.7556638717651367,
                0.8150830268859863,
                0.7565858364105225,
                0.7842341065406799,
                0.798180103302002,
                0.772789478302002,
                0.814353883266449,
                0.7577623724937439,
                0.8395302295684814,
                0.6861551403999329,
                0.7292448282241821,
                0.7316821217536926,
                0.8107922673225403,
                0.7735384106636047,
                0.7642182111740112
            ],
            [
                0.9042332768440247,
                0.8809083104133606,
                0.894457995891571,
                0.8883675336837769,
                0.9075502157211304,
                0.9038205742835999,
                0.8912234902381897,
                0.8965489268302917,
                0.6285618543624878,
                0.8817423582077026,
                0.8785817623138428,
                0.9009469151496887,
                0.8693169355392456,
                0.8704962134361267,
                0.9088822603225708,
                0.8951600790023804,
                0.9033597111701965,
                0.8987324237823486,
                0.8462433218955994,
                0.8909637331962585,
                0.9347591400146484,
                0.8567320108413696,
                0.8462541103363037,
                0.8552606105804443,
                0.8996164202690125,
                0.8950626254081726,
                0.8985294103622437,
                0.8330329060554504,
                0.927545428276062,
                0.8321807384490967,
                0.884853720664978,
                0.747399091720581,
                0.8435274362564087,
                0.8796262741088867,
                0.898543119430542,
                0.8832622170448303,
                0.8326206207275391,
                0.8568446636199951,
                0.8681355118751526,
                0.8795369863510132,
                0.8101291656494141,
                0.9097006916999817,
                0.872263491153717,
                0.8050993084907532,
                0.8780868649482727,
                0.8024190664291382,
                0.8287180662155151,
                0.8364009261131287,
                0.9295915961265564,
                0.8627384901046753,
                0.8981270790100098
            ],
            [
                0.7585045099258423,
                0.7423052191734314,
                0.735292375087738,
                0.7939168810844421,
                0.8127936124801636,
                0.7614502906799316,
                0.7781175374984741,
                0.7541929483413696,
                0.7026939392089844,
                0.7262886762619019,
                0.785330593585968,
                0.7539287805557251,
                0.7608669400215149,
                0.7759709358215332,
                0.7350658178329468,
                0.7528313994407654,
                0.722711980342865,
                0.7737720608711243,
                0.7106994390487671,
                0.7340156435966492,
                0.7828966379165649,
                0.6758008003234863,
                0.7168113589286804,
                0.6907761096954346,
                0.7375010251998901,
                0.7575427293777466,
                0.7745944261550903,
                0.6949047446250916,
                0.7489321231842041,
                0.7219626307487488,
                0.76458340883255,
                0.6014581322669983,
                0.7294517755508423,
                0.7460685968399048,
                0.7885423302650452,
                0.7418655753135681,
                0.7126919627189636,
                0.7564623355865479,
                0.748648464679718,
                0.7421400547027588,
                0.7560234665870667,
                0.7634943127632141,
                0.7660329341888428,
                0.7767553925514221,
                0.7796366810798645,
                0.7030292749404907,
                0.6935164928436279,
                0.7043982148170471,
                0.7946426272392273,
                0.7295669913291931,
                0.7703251242637634
            ]
        ],
        [
            [
                0.9308034777641296,
                0.9059052467346191,
                0.9140627384185791,
                0.8848468065261841,
                0.8819449543952942,
                0.7807672023773193,
                0.8637728095054626,
                0.7698729038238525,
                0.8877795934677124,
                0.785991907119751,
                0.893507182598114,
                0.7378313541412354,
                0.7226777076721191,
                0.760694146156311,
                0.7804288864135742,
                0.7986292839050293,
                0.7322777509689331,
                0.8212085366249084,
                0.7394008040428162,
                0.8623577356338501,
                0.7113128304481506,
                0.8753701448440552,
                0.7410171627998352,
                0.6974177360534668,
                0.7608264088630676,
                0.7663335204124451,
                0.7617219090461731,
                0.7387685179710388,
                0.7786359786987305,
                0.7589219212532043,
                0.7462058663368225,
                0.747505784034729,
                0.7600528597831726,
                0.9200359582901001,
                0.7729553580284119,
                0.7747638821601868,
                0.9219765663146973,
                0.7943288087844849,
                0.7445340156555176,
                0.7592079639434814,
                0.7743372321128845,
                0.9199628829956055,
                0.8605442047119141,
                0.7328569293022156,
                0.8184564113616943,
                0.7236204147338867,
                0.7295972108840942,
                0.7891536355018616,
                0.8202693462371826,
                0.7816314101219177,
                0.8046880960464478
            ],
            [
                0.825385332107544,
                0.792770504951477,
                0.8057881593704224,
                0.7785572409629822,
                0.7957871556282043,
                0.8333234190940857,
                0.7639492750167847,
                0.8112059831619263,
                0.8445192575454712,
                0.8206495642662048,
                0.8113114833831787,
                0.7916605472564697,
                0.812222421169281,
                0.8506379127502441,
                0.8546695709228516,
                0.8518157005310059,
                0.8392752408981323,
                0.7309349775314331,
                0.8298459649085999,
                0.8412754535675049,
                0.8159551620483398,
                0.7458882927894592,
                0.8264147043228149,
                0.7837841510772705,
                0.8634889125823975,
                0.8459665179252625,
                0.8459166884422302,
                0.8241583108901978,
                0.7910617589950562,
                0.7838612794876099,
                0.759096622467041,
                0.7775002121925354,
                0.8365848064422607,
                0.8068187832832336,
                0.8319597840309143,
                0.8107176423072815,
                0.8010827898979187,
                0.8481330871582031,
                0.822492778301239,
                0.8420422077178955,
                0.8360497951507568,
                0.8082317113876343,
                0.8461953997612,
                0.8486833572387695,
                0.8465015292167664,
                0.849226713180542,
                0.7659707069396973,
                0.7323560118675232,
                0.7345284819602966,
                0.8421235680580139,
                0.8709680438041687
            ],
            [
                0.913064181804657,
                0.9149102568626404,
                0.9131066799163818,
                0.9823563694953918,
                0.8729550838470459,
                0.8231744170188904,
                0.8358631134033203,
                0.8178950548171997,
                0.9015792012214661,
                0.850325345993042,
                0.9179625511169434,
                0.7802804112434387,
                0.793876051902771,
                0.8427126407623291,
                0.8466321229934692,
                0.8492122888565063,
                0.818239688873291,
                0.839017927646637,
                0.7928423285484314,
                0.8914385437965393,
                0.7925338745117188,
                0.8761716485023499,
                0.8158009052276611,
                0.7630068063735962,
                0.8424935340881348,
                0.8464956879615784,
                0.8477325439453125,
                0.8235031962394714,
                0.8455781936645508,
                0.8239260315895081,
                0.8158281445503235,
                0.7876834273338318,
                0.8258078098297119,
                0.9016371369361877,
                0.8254860639572144,
                0.8318527936935425,
                0.9164480566978455,
                0.8591119050979614,
                0.82852703332901,
                0.8437025547027588,
                0.8341168165206909,
                0.9068280458450317,
                0.8857492208480835,
                0.8102942109107971,
                0.8539204001426697,
                0.8082724213600159,
                0.7848488688468933,
                0.8086525201797485,
                0.8171360492706299,
                0.8442518711090088,
                0.8608034253120422
            ],
            [
                0.8453698754310608,
                0.8523273468017578,
                0.8443576693534851,
                0.8171733021736145,
                0.8411064147949219,
                0.9206774234771729,
                0.8690797686576843,
                0.972366213798523,
                0.879386842250824,
                0.8937710523605347,
                0.8594147562980652,
                0.8399741053581238,
                0.8338609933853149,
                0.9027571678161621,
                0.9133961200714111,
                0.8993729948997498,
                0.8910746574401855,
                0.7329338788986206,
                0.8577374219894409,
                0.8900194764137268,
                0.8549005389213562,
                0.8316584825515747,
                0.8847693204879761,
                0.8401716947555542,
                0.8823673129081726,
                0.9003050327301025,
                0.887530505657196,
                0.8783931136131287,
                0.8709874153137207,
                0.8582274913787842,
                0.8447586297988892,
                0.8519573211669922,
                0.9008145332336426,
                0.8160069584846497,
                0.9356187582015991,
                0.8827987313270569,
                0.831506609916687,
                0.9072300791740417,
                0.8838933706283569,
                0.8994057178497314,
                0.9192831516265869,
                0.8529309034347534,
                0.8910638093948364,
                0.898442268371582,
                0.8888153433799744,
                0.8920890092849731,
                0.8666914701461792,
                0.7803894877433777,
                0.8160068988800049,
                0.912680983543396,
                0.8935606479644775
            ],
            [
                0.7932599782943726,
                0.8042063117027283,
                0.8054171800613403,
                0.7538120746612549,
                0.8752570748329163,
                0.8944887518882751,
                0.8547616004943848,
                0.877861738204956,
                0.8508551716804504,
                0.884669303894043,
                0.8192089200019836,
                0.9232666492462158,
                0.7617791891098022,
                0.8915584683418274,
                0.8946390151977539,
                0.8332099914550781,
                0.8424472808837891,
                0.727729856967926,
                0.9027227163314819,
                0.8338853120803833,
                0.8197861909866333,
                0.8195277452468872,
                0.883720338344574,
                0.7510916590690613,
                0.8178895115852356,
                0.8243083357810974,
                0.8119256496429443,
                0.8627174496650696,
                0.8760040998458862,
                0.9127882719039917,
                0.8914496898651123,
                0.9131103157997131,
                0.8807768821716309,
                0.7631657123565674,
                0.8321987390518188,
                0.8603849411010742,
                0.7799195647239685,
                0.8808457255363464,
                0.846264123916626,
                0.8790909051895142,
                0.9175479412078857,
                0.8078838586807251,
                0.8464967012405396,
                0.8859753012657166,
                0.8588789105415344,
                0.8697972893714905,
                0.876251220703125,
                0.8493492007255554,
                0.8308491706848145,
                0.8346319198608398,
                0.8466573357582092
            ],
            [
                0.8325656652450562,
                0.8309349417686462,
                0.8304061889648438,
                0.8034387230873108,
                0.8512707352638245,
                0.9078309535980225,
                0.8268515467643738,
                0.8575766682624817,
                0.8890732526779175,
                0.9259482026100159,
                0.8464192152023315,
                0.9245544672012329,
                0.8557578325271606,
                0.9247269034385681,
                0.9063035845756531,
                0.8940115571022034,
                0.8749699592590332,
                0.7621895670890808,
                0.9366366863250732,
                0.8913238048553467,
                0.877990186214447,
                0.8293128609657288,
                0.9023808836936951,
                0.8183004260063171,
                0.8651387095451355,
                0.8698002696037292,
                0.8620001673698425,
                0.8901659846305847,
                0.8768723607063293,
                0.8891130089759827,
                0.8651562929153442,
                0.8701786398887634,
                0.8911120891571045,
                0.8016735315322876,
                0.8725164532661438,
                0.8802408576011658,
                0.8222229480743408,
                0.9093391299247742,
                0.8810515403747559,
                0.8855501413345337,
                0.9160640239715576,
                0.8455206751823425,
                0.8910675048828125,
                0.9317027926445007,
                0.8950018286705017,
                0.9166662693023682,
                0.8697925806045532,
                0.8445656895637512,
                0.7952694296836853,
                0.8949246406555176,
                0.8858196139335632
            ],
            [
                0.8378227949142456,
                0.8402424454689026,
                0.8243170380592346,
                0.8399671316146851,
                0.8080492615699768,
                0.7234352827072144,
                0.8145806193351746,
                0.7392851114273071,
                0.846696138381958,
                0.7776939272880554,
                0.8585291504859924,
                0.7516887187957764,
                0.6616461873054504,
                0.7651917934417725,
                0.7560374140739441,
                0.7498570680618286,
                0.7404140830039978,
                0.8301156163215637,
                0.742233395576477,
                0.826515793800354,
                0.7126991152763367,
                0.8444928526878357,
                0.7236273288726807,
                0.65069580078125,
                0.7294386625289917,
                0.7611750364303589,
                0.7679629325866699,
                0.730341374874115,
                0.7479428052902222,
                0.7672857046127319,
                0.7602819800376892,
                0.7326635122299194,
                0.7380465269088745,
                0.8123337626457214,
                0.7251790761947632,
                0.7442637085914612,
                0.8575949668884277,
                0.7853649854660034,
                0.7270435094833374,
                0.773804247379303,
                0.7547065019607544,
                0.858495831489563,
                0.8015390634536743,
                0.7432275414466858,
                0.7773664593696594,
                0.750244677066803,
                0.7018207311630249,
                0.792656660079956,
                0.8010655641555786,
                0.743283748626709,
                0.7697564959526062
            ],
            [
                0.840384840965271,
                0.8443537950515747,
                0.8632292747497559,
                0.8054736256599426,
                0.9217472076416016,
                0.8795680999755859,
                0.8792063593864441,
                0.8527756929397583,
                0.9061984419822693,
                0.8738023638725281,
                0.8805861473083496,
                0.902678370475769,
                0.7993643283843994,
                0.8840318918228149,
                0.8914877772331238,
                0.8759913444519043,
                0.8532891273498535,
                0.776817798614502,
                0.8923320770263672,
                0.8675812482833862,
                0.8313989043235779,
                0.9044570922851562,
                0.878109335899353,
                0.7618908882141113,
                0.8544763326644897,
                0.8516074419021606,
                0.8491246104240417,
                0.8512222766876221,
                0.8564324378967285,
                0.8823883533477783,
                0.8671978712081909,
                0.8928616046905518,
                0.8832890391349792,
                0.8411459922790527,
                0.859281599521637,
                0.8520071506500244,
                0.8462367057800293,
                0.886597752571106,
                0.8396850228309631,
                0.855956494808197,
                0.8862313628196716,
                0.8528609275817871,
                0.8784972429275513,
                0.8769856095314026,
                0.8807587027549744,
                0.8442127704620361,
                0.8457735180854797,
                0.9086113572120667,
                0.8526045680046082,
                0.8626697659492493,
                0.8534691333770752
            ],
            [
                0.8258071541786194,
                0.8421192169189453,
                0.8452506065368652,
                0.7885172963142395,
                0.8995110988616943,
                0.8540921211242676,
                0.8629405498504639,
                0.8584834933280945,
                0.885918378829956,
                0.8948076963424683,
                0.8657104969024658,
                0.9261906743049622,
                0.7430087327957153,
                0.9108526706695557,
                0.8965566158294678,
                0.8279455900192261,
                0.8481737971305847,
                0.7803292870521545,
                0.9042908549308777,
                0.8505293130874634,
                0.8311905264854431,
                0.8685497045516968,
                0.8696375489234924,
                0.7107709646224976,
                0.8242707848548889,
                0.8420355319976807,
                0.8322211503982544,
                0.8534063100814819,
                0.8688668608665466,
                0.9266541004180908,
                0.9021431803703308,
                0.9202693104743958,
                0.8846109509468079,
                0.8034069538116455,
                0.83519446849823,
                0.8391978740692139,
                0.8237285017967224,
                0.8797496557235718,
                0.838914692401886,
                0.880597710609436,
                0.9073637127876282,
                0.8590397834777832,
                0.8479750752449036,
                0.8831390738487244,
                0.8500765562057495,
                0.8639140725135803,
                0.8637108206748962,
                0.8706351518630981,
                0.8848544359207153,
                0.8288612365722656,
                0.8463760018348694
            ],
            [
                0.8001240491867065,
                0.8105500936508179,
                0.8226065039634705,
                0.7741892337799072,
                0.8103126883506775,
                0.8133633732795715,
                0.7820587158203125,
                0.8020448684692383,
                0.857300877571106,
                0.8280290961265564,
                0.8376092910766602,
                0.8580441474914551,
                0.7543981075286865,
                0.8789427876472473,
                0.8582184314727783,
                0.8108673095703125,
                0.8406461477279663,
                0.7386693954467773,
                0.8669092059135437,
                0.8107978701591492,
                0.7991653084754944,
                0.8318318128585815,
                0.8354059457778931,
                0.7092325687408447,
                0.8195233345031738,
                0.8316071033477783,
                0.8264887928962708,
                0.8705337047576904,
                0.8154610395431519,
                0.865119218826294,
                0.8464685082435608,
                0.8502343893051147,
                0.8446700572967529,
                0.7794568538665771,
                0.8186802864074707,
                0.7997928261756897,
                0.7896319627761841,
                0.845239520072937,
                0.8260496258735657,
                0.8569537997245789,
                0.8586530089378357,
                0.7962619662284851,
                0.8039720058441162,
                0.8485645651817322,
                0.8074039816856384,
                0.8430163860321045,
                0.789152204990387,
                0.795133650302887,
                0.8133028745651245,
                0.8199817538261414,
                0.8134444952011108
            ],
            [
                0.8736429214477539,
                0.87259441614151,
                0.8706093430519104,
                0.8851063847541809,
                0.8242301940917969,
                0.8320343494415283,
                0.8148693442344666,
                0.8258183002471924,
                0.9103520512580872,
                0.8534807562828064,
                0.8956389427185059,
                0.8108653426170349,
                0.8151165843009949,
                0.8805953860282898,
                0.8685146570205688,
                0.8616458177566528,
                0.8521634340286255,
                0.7812352180480957,
                0.8368850350379944,
                0.8722280263900757,
                0.8108408451080322,
                0.8255370259284973,
                0.8372840285301208,
                0.7894023060798645,
                0.8678702712059021,
                0.8774756789207458,
                0.8781331181526184,
                0.8703022003173828,
                0.8435453772544861,
                0.8489934802055359,
                0.8314045667648315,
                0.8171722292900085,
                0.8547618985176086,
                0.8416902422904968,
                0.8583120107650757,
                0.8364307880401611,
                0.8725268840789795,
                0.8848387598991394,
                0.8572551608085632,
                0.881657600402832,
                0.8649770021438599,
                0.8483276963233948,
                0.8714708685874939,
                0.8544076085090637,
                0.8469711542129517,
                0.8620824813842773,
                0.7925103902816772,
                0.7815348505973816,
                0.8003435134887695,
                0.870100200176239,
                0.8795190453529358
            ],
            [
                0.7814852595329285,
                0.7909103035926819,
                0.7961181402206421,
                0.7446896433830261,
                0.8547512292861938,
                0.8382336497306824,
                0.8400817513465881,
                0.8232776522636414,
                0.8528813719749451,
                0.8449556827545166,
                0.8103000521659851,
                0.8844982981681824,
                0.7446987628936768,
                0.8569239974021912,
                0.8634659647941589,
                0.8093891739845276,
                0.8154420256614685,
                0.7336307168006897,
                0.8603938221931458,
                0.805967390537262,
                0.777190089225769,
                0.8484965562820435,
                0.855506181716919,
                0.7033414840698242,
                0.7863427996635437,
                0.7952704429626465,
                0.7910144925117493,
                0.8311716914176941,
                0.845660924911499,
                0.8969603180885315,
                0.8767266273498535,
                0.8858559131622314,
                0.8407716751098633,
                0.7542933225631714,
                0.799769401550293,
                0.810884416103363,
                0.7738790512084961,
                0.8382003903388977,
                0.8124290108680725,
                0.8343225717544556,
                0.8658369779586792,
                0.7923225164413452,
                0.8206183314323425,
                0.8367862701416016,
                0.8251545429229736,
                0.8157982230186462,
                0.8291044235229492,
                0.8427127599716187,
                0.8311960697174072,
                0.8068617582321167,
                0.8066209554672241
            ],
            [
                0.8814516067504883,
                0.9156802892684937,
                0.9126945734024048,
                0.8741989731788635,
                0.8937554955482483,
                0.8565517663955688,
                0.8876572847366333,
                0.8860663175582886,
                0.9441725015640259,
                0.8730429410934448,
                0.9244725108146667,
                0.8503445982933044,
                0.7889880537986755,
                0.8960089087486267,
                0.8932120203971863,
                0.8810672760009766,
                0.8788191080093384,
                0.7975404262542725,
                0.8580420613288879,
                0.8922435641288757,
                0.8335751891136169,
                0.9158822298049927,
                0.8594818711280823,
                0.7658205628395081,
                0.8766041398048401,
                0.8995290994644165,
                0.8945415019989014,
                0.8713840246200562,
                0.857742190361023,
                0.8742273449897766,
                0.868468701839447,
                0.8787701725959778,
                0.9011595249176025,
                0.8898489475250244,
                0.9008408188819885,
                0.8570913672447205,
                0.9004091024398804,
                0.9028175473213196,
                0.8576302528381348,
                0.8895155191421509,
                0.8948377370834351,
                0.9059313535690308,
                0.8915555477142334,
                0.8725937604904175,
                0.8723775744438171,
                0.8594212532043457,
                0.8320081830024719,
                0.8281459212303162,
                0.8832177519798279,
                0.8828392624855042,
                0.8724367618560791
            ],
            [
                0.8518664836883545,
                0.8748906850814819,
                0.8663947582244873,
                0.824196457862854,
                0.8634756803512573,
                0.8921940922737122,
                0.8360320329666138,
                0.9051643013954163,
                0.9112316370010376,
                0.9115946292877197,
                0.8920701742172241,
                0.903120219707489,
                0.8116744160652161,
                0.9379145503044128,
                0.9285963177680969,
                0.8833921551704407,
                0.9053868055343628,
                0.7898154854774475,
                0.9098174571990967,
                0.8813108205795288,
                0.8895634412765503,
                0.8608115911483765,
                0.9115407466888428,
                0.799640953540802,
                0.9084129929542542,
                0.9248767495155334,
                0.9169905185699463,
                0.9228196740150452,
                0.8962579965591431,
                0.9245946407318115,
                0.9050599932670593,
                0.929949164390564,
                0.9445483088493347,
                0.8250858187675476,
                0.8946595788002014,
                0.8949463367462158,
                0.8629732728004456,
                0.936877429485321,
                0.897165060043335,
                0.9319058656692505,
                0.952982485294342,
                0.8682044148445129,
                0.8851932287216187,
                0.9316516518592834,
                0.8795081377029419,
                0.9277873039245605,
                0.8815698623657227,
                0.8170463442802429,
                0.8733488917350769,
                0.8889829516410828,
                0.9121924042701721
            ],
            [
                0.7615906000137329,
                0.749507486820221,
                0.7512485980987549,
                0.7217066287994385,
                0.8444212675094604,
                0.8359586596488953,
                0.7865915894508362,
                0.7858499884605408,
                0.7971634268760681,
                0.8422507643699646,
                0.7654002904891968,
                0.8427731990814209,
                0.7882665395736694,
                0.8152011632919312,
                0.856616199016571,
                0.8139462471008301,
                0.7652830481529236,
                0.7444954514503479,
                0.8232486844062805,
                0.8074914216995239,
                0.7855613231658936,
                0.7769315242767334,
                0.8519481420516968,
                0.7699458599090576,
                0.8038954734802246,
                0.7769766449928284,
                0.7742465734481812,
                0.78451007604599,
                0.8586447834968567,
                0.8540657162666321,
                0.8395407795906067,
                0.8432947397232056,
                0.8181619644165039,
                0.7186623215675354,
                0.7548500895500183,
                0.844217836856842,
                0.7437013387680054,
                0.8467742204666138,
                0.8049731254577637,
                0.7954071760177612,
                0.8368141055107117,
                0.7520771026611328,
                0.8307708501815796,
                0.816045343875885,
                0.8564686179161072,
                0.7947770953178406,
                0.8452674746513367,
                0.8736053109169006,
                0.7681537866592407,
                0.8042433261871338,
                0.8363149166107178
            ],
            [
                0.7982162237167358,
                0.8111358880996704,
                0.8088140487670898,
                0.8357140421867371,
                0.7545485496520996,
                0.7136927247047424,
                0.7398308515548706,
                0.7483792304992676,
                0.8100844621658325,
                0.7582696676254272,
                0.8221724033355713,
                0.7161713242530823,
                0.6880000829696655,
                0.7823442816734314,
                0.77527916431427,
                0.7466884255409241,
                0.7500187158584595,
                0.7670664191246033,
                0.7215653657913208,
                0.7722440361976624,
                0.6951603889465332,
                0.8063626885414124,
                0.7438765168190002,
                0.6675975322723389,
                0.7472662329673767,
                0.7878071069717407,
                0.7807443737983704,
                0.7678478360176086,
                0.783301830291748,
                0.8044850826263428,
                0.7932719588279724,
                0.7566736936569214,
                0.7615852952003479,
                0.761224627494812,
                0.7567312121391296,
                0.7527409791946411,
                0.7897436618804932,
                0.7913379669189453,
                0.7509928941726685,
                0.8002946376800537,
                0.784803569316864,
                0.7773508429527283,
                0.7654337286949158,
                0.7355269193649292,
                0.7605741024017334,
                0.75043785572052,
                0.711580753326416,
                0.733112096786499,
                0.7875933647155762,
                0.7583929300308228,
                0.7902029752731323
            ],
            [
                0.821277916431427,
                0.8595321178436279,
                0.8337107300758362,
                0.8820538520812988,
                0.7747113704681396,
                0.70654296875,
                0.7544358372688293,
                0.7455165386199951,
                0.8419358134269714,
                0.7706313133239746,
                0.8612237572669983,
                0.717647910118103,
                0.6926628947257996,
                0.7885230779647827,
                0.7769151329994202,
                0.7562386393547058,
                0.7572516798973083,
                0.7999149560928345,
                0.7259483337402344,
                0.8014493584632874,
                0.7208914756774902,
                0.8058854341506958,
                0.7408875823020935,
                0.6669532060623169,
                0.7733467221260071,
                0.8006022572517395,
                0.801762580871582,
                0.7633243799209595,
                0.7863454222679138,
                0.8046667575836182,
                0.7936440706253052,
                0.7592718601226807,
                0.7794142365455627,
                0.8041142821311951,
                0.7573955059051514,
                0.7559599876403809,
                0.8528560400009155,
                0.8032419085502625,
                0.7603943347930908,
                0.8074707984924316,
                0.7726863622665405,
                0.8247157335281372,
                0.7902188897132874,
                0.7412662506103516,
                0.7623072266578674,
                0.7509663105010986,
                0.7163545489311218,
                0.7105252146720886,
                0.8085054755210876,
                0.7671792507171631,
                0.7986934185028076
            ],
            [
                0.764527440071106,
                0.7531033754348755,
                0.7539207339286804,
                0.7250023484230042,
                0.8350141048431396,
                0.8346458673477173,
                0.7801865339279175,
                0.7839438319206238,
                0.808927595615387,
                0.8423393368721008,
                0.7653917670249939,
                0.8248746991157532,
                0.7968696355819702,
                0.8109145164489746,
                0.8535420298576355,
                0.8208458423614502,
                0.7710908055305481,
                0.7489839196205139,
                0.811290979385376,
                0.8141769170761108,
                0.7840422987937927,
                0.7806089520454407,
                0.8475097417831421,
                0.7875135540962219,
                0.8081268072128296,
                0.7854430079460144,
                0.7887388467788696,
                0.7995719313621521,
                0.8642478585243225,
                0.8392815589904785,
                0.840268611907959,
                0.8325530886650085,
                0.8195555806159973,
                0.727755606174469,
                0.7510783672332764,
                0.8489713668823242,
                0.749956488609314,
                0.8437045812606812,
                0.8129435181617737,
                0.7964512705802917,
                0.8359973430633545,
                0.7530131936073303,
                0.8360241651535034,
                0.8146069049835205,
                0.8604333996772766,
                0.7921064496040344,
                0.8434085249900818,
                0.864979088306427,
                0.7620590329170227,
                0.807256817817688,
                0.838512659072876
            ],
            [
                0.7907973527908325,
                0.8187299370765686,
                0.8158095479011536,
                0.7862067222595215,
                0.7664197087287903,
                0.7260041236877441,
                0.7583154439926147,
                0.7520246505737305,
                0.8346415162086487,
                0.7668272256851196,
                0.8156497478485107,
                0.7420089244842529,
                0.6915906667709351,
                0.7883058786392212,
                0.7871281504631042,
                0.766082763671875,
                0.7627741098403931,
                0.7652119994163513,
                0.7432584762573242,
                0.7809664607048035,
                0.7031816840171814,
                0.8298693299293518,
                0.7614030241966248,
                0.6723898649215698,
                0.747382640838623,
                0.7910693883895874,
                0.798058271408081,
                0.7882006764411926,
                0.7929331064224243,
                0.8051501512527466,
                0.8124454617500305,
                0.7732691764831543,
                0.7769904732704163,
                0.7712134718894958,
                0.7555961012840271,
                0.7690927982330322,
                0.8007630109786987,
                0.7941786646842957,
                0.7639944553375244,
                0.7979349493980408,
                0.8021963834762573,
                0.7925596237182617,
                0.7797524929046631,
                0.752729594707489,
                0.7754157781600952,
                0.7566028833389282,
                0.7223342657089233,
                0.7542158961296082,
                0.8069397807121277,
                0.7619970440864563,
                0.7880069017410278
            ],
            [
                0.8479178547859192,
                0.8715251684188843,
                0.8593411445617676,
                0.8409401178359985,
                0.8410284519195557,
                0.8131673336029053,
                0.811198353767395,
                0.8327074646949768,
                0.8976832032203674,
                0.8516242504119873,
                0.8822987079620361,
                0.8077648282051086,
                0.7692363262176514,
                0.8491706252098083,
                0.8642240762710571,
                0.8374036550521851,
                0.8381300568580627,
                0.8086503148078918,
                0.8124823570251465,
                0.8612252473831177,
                0.8089637160301208,
                0.8648648858070374,
                0.8437638282775879,
                0.7593740224838257,
                0.8512739539146423,
                0.8762239217758179,
                0.8817356824874878,
                0.8516573309898376,
                0.8631519079208374,
                0.8533183336257935,
                0.8784483075141907,
                0.852581799030304,
                0.8756464719772339,
                0.8349906206130981,
                0.8300488591194153,
                0.8536274433135986,
                0.8633442521095276,
                0.8811653256416321,
                0.8465421199798584,
                0.8759036064147949,
                0.8671296834945679,
                0.8550974130630493,
                0.8610495924949646,
                0.8369152545928955,
                0.8523635864257812,
                0.835922122001648,
                0.8218585848808289,
                0.8117468953132629,
                0.8592544794082642,
                0.8459815979003906,
                0.8688920736312866
            ],
            [
                0.7957112193107605,
                0.8055062890052795,
                0.8072125315666199,
                0.7748461365699768,
                0.7988847494125366,
                0.7693142890930176,
                0.7907710075378418,
                0.7984753847122192,
                0.8257836699485779,
                0.7923232913017273,
                0.8189009428024292,
                0.7675337791442871,
                0.7166680693626404,
                0.7998578548431396,
                0.8159379959106445,
                0.7888261079788208,
                0.7647693157196045,
                0.7661558985710144,
                0.7648658752441406,
                0.795069694519043,
                0.7214899659156799,
                0.8319052457809448,
                0.7882877588272095,
                0.7011690735816956,
                0.7705391645431519,
                0.8057077527046204,
                0.7953627109527588,
                0.7872579097747803,
                0.8268173336982727,
                0.8360240459442139,
                0.8310304284095764,
                0.8054037094116211,
                0.812224268913269,
                0.7712424993515015,
                0.7976205945014954,
                0.8056930899620056,
                0.7942034006118774,
                0.8121411800384521,
                0.76729416847229,
                0.8008021712303162,
                0.832574188709259,
                0.7953431010246277,
                0.8018189072608948,
                0.7698092460632324,
                0.810390830039978,
                0.7726498246192932,
                0.7644952535629272,
                0.7951143383979797,
                0.8232488036155701,
                0.798122227191925,
                0.8103513717651367
            ],
            [
                0.8719688653945923,
                0.8801054954528809,
                0.8790592551231384,
                0.8588470220565796,
                0.880818247795105,
                0.8396711945533752,
                0.8434116840362549,
                0.8593893647193909,
                0.9077401161193848,
                0.8620915412902832,
                0.9023386836051941,
                0.8260616064071655,
                0.7766396999359131,
                0.8691807389259338,
                0.8849607110023499,
                0.8490626811981201,
                0.8496328592300415,
                0.8144341707229614,
                0.8308013677597046,
                0.8727460503578186,
                0.8137732148170471,
                0.8797118067741394,
                0.8544963002204895,
                0.7696356177330017,
                0.8653293251991272,
                0.8921514749526978,
                0.8836660385131836,
                0.8633584976196289,
                0.8686317801475525,
                0.8673137426376343,
                0.875983476638794,
                0.8669543862342834,
                0.8859717845916748,
                0.8567882776260376,
                0.857670247554779,
                0.8532145023345947,
                0.8750299215316772,
                0.8838794231414795,
                0.8429380059242249,
                0.8815518021583557,
                0.8834052681922913,
                0.8697671294212341,
                0.8729966282844543,
                0.8511451482772827,
                0.8707452416419983,
                0.8475610613822937,
                0.8246647119522095,
                0.8373059034347534,
                0.8728004693984985,
                0.8612355589866638,
                0.8747379183769226
            ],
            [
                0.7612970471382141,
                0.7759911417961121,
                0.783989667892456,
                0.7645530104637146,
                0.7517910599708557,
                0.7257797718048096,
                0.7412579655647278,
                0.7561330199241638,
                0.8019867539405823,
                0.7640439867973328,
                0.8046776056289673,
                0.7419368624687195,
                0.6795518398284912,
                0.7982568740844727,
                0.7846546769142151,
                0.7532009482383728,
                0.7571240067481995,
                0.7406983375549316,
                0.7419404983520508,
                0.7570083141326904,
                0.7002997994422913,
                0.8056182265281677,
                0.755928635597229,
                0.6621675491333008,
                0.7398324608802795,
                0.7770905494689941,
                0.7765042185783386,
                0.7618222236633301,
                0.7953554391860962,
                0.8196814656257629,
                0.8047084808349609,
                0.7700710296630859,
                0.7749378681182861,
                0.7360469698905945,
                0.7584600448608398,
                0.7676934599876404,
                0.7646294832229614,
                0.7880932092666626,
                0.7512654662132263,
                0.790653645992279,
                0.8053593039512634,
                0.755562424659729,
                0.7595149278640747,
                0.7468684911727905,
                0.7660133242607117,
                0.7561354637145996,
                0.7280483841896057,
                0.750421404838562,
                0.7828001379966736,
                0.7604712247848511,
                0.777898371219635
            ],
            [
                0.8391709327697754,
                0.8459451198577881,
                0.8487028479576111,
                0.8622861504554749,
                0.8386083841323853,
                0.7941584587097168,
                0.8069030046463013,
                0.8135714530944824,
                0.8720121383666992,
                0.8431184887886047,
                0.878130316734314,
                0.8002175092697144,
                0.757232129573822,
                0.8565122485160828,
                0.8568124175071716,
                0.8185132741928101,
                0.8214395046234131,
                0.8101733922958374,
                0.8013418912887573,
                0.8431960344314575,
                0.7807359099388123,
                0.84376060962677,
                0.8228092193603516,
                0.7424026131629944,
                0.8306463956832886,
                0.8441638946533203,
                0.8460057377815247,
                0.8177709579467773,
                0.8641964197158813,
                0.8591219186782837,
                0.8524020910263062,
                0.8268012404441833,
                0.8428863883018494,
                0.8178523778915405,
                0.8002094030380249,
                0.8376092314720154,
                0.8468495607376099,
                0.8595947027206421,
                0.834540843963623,
                0.8627094030380249,
                0.8460788130760193,
                0.8321914672851562,
                0.8471963405609131,
                0.8128154873847961,
                0.8364197611808777,
                0.8182497024536133,
                0.801742672920227,
                0.8081029653549194,
                0.8287227153778076,
                0.8281216621398926,
                0.8552522659301758
            ],
            [
                0.7963409423828125,
                0.8089026212692261,
                0.8031463623046875,
                0.780056893825531,
                0.821178138256073,
                0.8234544992446899,
                0.8093244433403015,
                0.8437827229499817,
                0.859567403793335,
                0.8690991997718811,
                0.8331691026687622,
                0.8735332489013672,
                0.756275475025177,
                0.8821069598197937,
                0.8719261884689331,
                0.8195225596427917,
                0.823924720287323,
                0.7526222467422485,
                0.8571659922599792,
                0.8224250078201294,
                0.8009707927703857,
                0.825050413608551,
                0.8682571053504944,
                0.7321216464042664,
                0.8120294213294983,
                0.8308959007263184,
                0.8234291076660156,
                0.8364908695220947,
                0.8992099761962891,
                0.9257519841194153,
                0.9129672050476074,
                0.8904412984848022,
                0.8727004528045654,
                0.7508050203323364,
                0.8325192332267761,
                0.8591082692146301,
                0.7897579669952393,
                0.874122142791748,
                0.8445491790771484,
                0.8735780715942383,
                0.8957004547119141,
                0.8055928349494934,
                0.8417208790779114,
                0.8502072095870972,
                0.8489497900009155,
                0.847478985786438,
                0.8705905675888062,
                0.824522852897644,
                0.8423231244087219,
                0.8366222977638245,
                0.8454789519309998
            ],
            [
                0.845258355140686,
                0.8346039652824402,
                0.842214822769165,
                0.8370826244354248,
                0.8160580992698669,
                0.7769291996955872,
                0.8042854070663452,
                0.7891371846199036,
                0.8733546733856201,
                0.8203722834587097,
                0.8796417713165283,
                0.8062340617179871,
                0.7290964126586914,
                0.8402729034423828,
                0.826474666595459,
                0.793611466884613,
                0.7989805936813354,
                0.81413733959198,
                0.8036668300628662,
                0.8295495510101318,
                0.74054354429245,
                0.8565587401390076,
                0.8048779368400574,
                0.7066473960876465,
                0.7882974147796631,
                0.8169178366661072,
                0.8113294839859009,
                0.8163672685623169,
                0.8507723808288574,
                0.8636520504951477,
                0.859439492225647,
                0.820854663848877,
                0.8187751770019531,
                0.8082134127616882,
                0.7927118539810181,
                0.822698712348938,
                0.8441028594970703,
                0.8379042148590088,
                0.8028504252433777,
                0.8477338552474976,
                0.84211665391922,
                0.830214262008667,
                0.8404453992843628,
                0.7949225902557373,
                0.828453779220581,
                0.8040618300437927,
                0.7871771454811096,
                0.8002848029136658,
                0.8310810923576355,
                0.8108606338500977,
                0.8206955790519714
            ],
            [
                0.8077986836433411,
                0.796916127204895,
                0.8038913607597351,
                0.7844144105911255,
                0.806215226650238,
                0.7673981785774231,
                0.7756637334823608,
                0.7728428244590759,
                0.8413587212562561,
                0.8100638389587402,
                0.8415035605430603,
                0.8136654496192932,
                0.6951489448547363,
                0.8283871412277222,
                0.8102807998657227,
                0.7613604068756104,
                0.7656724452972412,
                0.7795699238777161,
                0.8036824464797974,
                0.793027937412262,
                0.7291164994239807,
                0.8298580646514893,
                0.7864845395088196,
                0.6841740608215332,
                0.7438784837722778,
                0.7738420367240906,
                0.7639161944389343,
                0.790831446647644,
                0.8277836441993713,
                0.8614901900291443,
                0.8427812457084656,
                0.8143190145492554,
                0.7925982475280762,
                0.7546790242195129,
                0.7518660426139832,
                0.7911694049835205,
                0.7950310111045837,
                0.813640296459198,
                0.7713897228240967,
                0.8182370662689209,
                0.8305637836456299,
                0.8005656003952026,
                0.8112888932228088,
                0.7831258177757263,
                0.806849479675293,
                0.7878029942512512,
                0.7822081446647644,
                0.815342903137207,
                0.8146207332611084,
                0.7713621854782104,
                0.7959429025650024
            ],
            [
                0.8804225325584412,
                0.8786140084266663,
                0.8859075307846069,
                0.8742342591285706,
                0.8953395485877991,
                0.8401207327842712,
                0.8639355301856995,
                0.8469650149345398,
                0.9219478964805603,
                0.8712983727455139,
                0.9144223928451538,
                0.8378982543945312,
                0.7764049768447876,
                0.8703727722167969,
                0.8765919208526611,
                0.8438518047332764,
                0.8368815183639526,
                0.8253926038742065,
                0.8355917930603027,
                0.8785223364830017,
                0.8075926303863525,
                0.885802149772644,
                0.8461674451828003,
                0.7584665417671204,
                0.8369259238243103,
                0.8550595641136169,
                0.8482006192207336,
                0.8422505855560303,
                0.8765398859977722,
                0.8831989169120789,
                0.8824554681777954,
                0.859622061252594,
                0.8643964529037476,
                0.8616700172424316,
                0.8405807614326477,
                0.851356029510498,
                0.8816166520118713,
                0.8879491686820984,
                0.8343679308891296,
                0.8699977993965149,
                0.8804585337638855,
                0.8787968754768372,
                0.8936176300048828,
                0.8411502242088318,
                0.8828712701797485,
                0.8372271656990051,
                0.8487826585769653,
                0.8642489314079285,
                0.8682155013084412,
                0.8511497974395752,
                0.8739267587661743
            ],
            [
                0.7841504812240601,
                0.7789301872253418,
                0.7861684560775757,
                0.7435532808303833,
                0.8138626217842102,
                0.8184037804603577,
                0.7949281930923462,
                0.7915952801704407,
                0.83940190076828,
                0.8364455103874207,
                0.8005791306495667,
                0.8721016645431519,
                0.7490086555480957,
                0.8626982569694519,
                0.8486237525939941,
                0.7920324802398682,
                0.8009384870529175,
                0.739806056022644,
                0.8605074286460876,
                0.7972642183303833,
                0.7707340121269226,
                0.8099657297134399,
                0.841410756111145,
                0.7120910882949829,
                0.7753521203994751,
                0.7881727814674377,
                0.7723938226699829,
                0.8199031949043274,
                0.8549655079841614,
                0.8915950059890747,
                0.8722068667411804,
                0.858557403087616,
                0.8229461908340454,
                0.7435062527656555,
                0.7945948243141174,
                0.8199649453163147,
                0.7586733102798462,
                0.8378778696060181,
                0.8147896528244019,
                0.8344391584396362,
                0.8595523238182068,
                0.7738046050071716,
                0.814895749092102,
                0.8276196718215942,
                0.822847843170166,
                0.8128111958503723,
                0.8348750472068787,
                0.8108412027359009,
                0.8025170564651489,
                0.8091280460357666,
                0.8069866299629211
            ],
            [
                0.8038728833198547,
                0.7976301312446594,
                0.8095400333404541,
                0.7548179626464844,
                0.8478960990905762,
                0.7933220863342285,
                0.8063247203826904,
                0.768335223197937,
                0.8568894267082214,
                0.8258892297744751,
                0.8189438581466675,
                0.8742231726646423,
                0.711449921131134,
                0.8359251022338867,
                0.829603374004364,
                0.7733556628227234,
                0.7712867259979248,
                0.7850902080535889,
                0.8495123386383057,
                0.7987900376319885,
                0.7429842948913574,
                0.831207275390625,
                0.8158934116363525,
                0.6815767884254456,
                0.7530693411827087,
                0.7658208608627319,
                0.7553055286407471,
                0.7961186170578003,
                0.8434062600135803,
                0.8841726183891296,
                0.8690909743309021,
                0.8559394478797913,
                0.8046695590019226,
                0.7677631974220276,
                0.7511690855026245,
                0.8028777241706848,
                0.7915844321250916,
                0.819631040096283,
                0.7846155166625977,
                0.8137632012367249,
                0.8450379967689514,
                0.8020179271697998,
                0.815883457660675,
                0.80192631483078,
                0.8164740204811096,
                0.7876942157745361,
                0.8071771860122681,
                0.8526573181152344,
                0.8199033737182617,
                0.7716261148452759,
                0.7893909811973572
            ],
            [
                0.8828772306442261,
                0.8694164156913757,
                0.87428879737854,
                0.8506961464881897,
                0.8958297371864319,
                0.8480691909790039,
                0.8636306524276733,
                0.8359029293060303,
                0.9009073376655579,
                0.8852275609970093,
                0.8815962672233582,
                0.8394259214401245,
                0.788292646408081,
                0.8497610092163086,
                0.880217432975769,
                0.8446335196495056,
                0.8079153299331665,
                0.8386492729187012,
                0.8249189257621765,
                0.8792001008987427,
                0.7993303537368774,
                0.8743259906768799,
                0.8550353646278381,
                0.7807282209396362,
                0.8285749554634094,
                0.83526211977005,
                0.8286413550376892,
                0.8265644907951355,
                0.8880327939987183,
                0.8753312230110168,
                0.8758788704872131,
                0.8478814959526062,
                0.8443530201911926,
                0.8355509042739868,
                0.8093478083610535,
                0.8673338890075684,
                0.8730417490005493,
                0.8949251770973206,
                0.8368555903434753,
                0.8600901365280151,
                0.8680821657180786,
                0.8695379495620728,
                0.8985177278518677,
                0.8306637406349182,
                0.8950819969177246,
                0.8263341188430786,
                0.8563671112060547,
                0.8885981440544128,
                0.8529502749443054,
                0.8414310812950134,
                0.8828486800193787
            ],
            [
                0.782158374786377,
                0.7902239561080933,
                0.7855563163757324,
                0.7544205188751221,
                0.7938900589942932,
                0.8005645275115967,
                0.7775012254714966,
                0.792715311050415,
                0.8383848667144775,
                0.8386135697364807,
                0.8059207797050476,
                0.8680510520935059,
                0.7292959094047546,
                0.8736255764961243,
                0.8445461988449097,
                0.7794793248176575,
                0.8058421611785889,
                0.759014368057251,
                0.8591310977935791,
                0.7947778701782227,
                0.7762647867202759,
                0.8005105257034302,
                0.836288332939148,
                0.6999943256378174,
                0.7791897058486938,
                0.8033509254455566,
                0.7860602736473083,
                0.8274301290512085,
                0.8442280292510986,
                0.9002642035484314,
                0.8702473640441895,
                0.8596329092979431,
                0.8263776898384094,
                0.7334027886390686,
                0.7892599701881409,
                0.8123890161514282,
                0.7732099294662476,
                0.8466829657554626,
                0.8180951476097107,
                0.852125346660614,
                0.8609288930892944,
                0.7789676785469055,
                0.8015836477279663,
                0.8322405219078064,
                0.8013030290603638,
                0.8279638886451721,
                0.8162166476249695,
                0.785164475440979,
                0.8223402500152588,
                0.8038700222969055,
                0.8102511763572693
            ],
            [
                0.7826274633407593,
                0.7750957012176514,
                0.7748363614082336,
                0.741268515586853,
                0.7647993564605713,
                0.7497795820236206,
                0.7414512038230896,
                0.7429567575454712,
                0.8125779032707214,
                0.8000149726867676,
                0.7857563495635986,
                0.8001487851142883,
                0.6875459551811218,
                0.8152928948402405,
                0.7946298122406006,
                0.7379165291786194,
                0.747029185295105,
                0.7554168105125427,
                0.7922109365463257,
                0.7631124258041382,
                0.7034862041473389,
                0.7782610058784485,
                0.7781754732131958,
                0.6657403707504272,
                0.7238684296607971,
                0.7541795969009399,
                0.7353145480155945,
                0.7721390724182129,
                0.8226811289787292,
                0.8509498834609985,
                0.8300184011459351,
                0.7861372232437134,
                0.760470449924469,
                0.7168387770652771,
                0.7348417639732361,
                0.7799553275108337,
                0.7548179626464844,
                0.7982478141784668,
                0.7632730603218079,
                0.8008983731269836,
                0.813450038433075,
                0.758357048034668,
                0.7780076265335083,
                0.759092390537262,
                0.7749286890029907,
                0.766286313533783,
                0.7569110989570618,
                0.776261568069458,
                0.7776716947555542,
                0.762013852596283,
                0.775224506855011
            ],
            [
                0.8924728035926819,
                0.882222592830658,
                0.8864462375640869,
                0.8515914678573608,
                0.9118105173110962,
                0.8683965802192688,
                0.8885011076927185,
                0.8498402237892151,
                0.9186180830001831,
                0.8918022513389587,
                0.892298698425293,
                0.85589599609375,
                0.8045610189437866,
                0.8584232330322266,
                0.8911944627761841,
                0.8678761720657349,
                0.8227241039276123,
                0.8460977673530579,
                0.8432952165603638,
                0.8953743577003479,
                0.8079518675804138,
                0.8903809189796448,
                0.8705264329910278,
                0.786827802658081,
                0.8401076793670654,
                0.8454234600067139,
                0.8384455442428589,
                0.8327856659889221,
                0.8978729844093323,
                0.885342001914978,
                0.8843753337860107,
                0.8683499097824097,
                0.8649150729179382,
                0.8566329479217529,
                0.8316627740859985,
                0.8756894469261169,
                0.8821459412574768,
                0.8995775580406189,
                0.8427285552024841,
                0.8605075478553772,
                0.8822324275970459,
                0.8834021091461182,
                0.9119822382926941,
                0.8432899713516235,
                0.9113283157348633,
                0.8337231874465942,
                0.8691955208778381,
                0.8970962762832642,
                0.8726544976234436,
                0.8633617162704468,
                0.8912703990936279
            ],
            [
                0.819893479347229,
                0.8365693688392639,
                0.8398612141609192,
                0.8014078140258789,
                0.8248950242996216,
                0.769568920135498,
                0.8206560611724854,
                0.8018116354942322,
                0.8570381999015808,
                0.7957294583320618,
                0.846139669418335,
                0.7809937000274658,
                0.7214471697807312,
                0.8006932735443115,
                0.8165492415428162,
                0.8011599779129028,
                0.7645848393440247,
                0.7996616363525391,
                0.775488555431366,
                0.8218927383422852,
                0.72577303647995,
                0.871955394744873,
                0.790675163269043,
                0.7003679871559143,
                0.77414870262146,
                0.8037227392196655,
                0.8013394474983215,
                0.7819989323616028,
                0.8069088459014893,
                0.8231431841850281,
                0.8211512565612793,
                0.8101493120193481,
                0.8191765546798706,
                0.8043866753578186,
                0.8106716871261597,
                0.8005717992782593,
                0.8269330263137817,
                0.8216449618339539,
                0.7666676044464111,
                0.8012824654579163,
                0.8234466910362244,
                0.8304404616355896,
                0.8143343925476074,
                0.7777417898178101,
                0.8174378871917725,
                0.7751421928405762,
                0.7518268823623657,
                0.8144501447677612,
                0.8612666130065918,
                0.8065029382705688,
                0.8054924607276917
            ],
            [
                0.8715364933013916,
                0.876513659954071,
                0.8786633610725403,
                0.8832356929779053,
                0.852270245552063,
                0.8089442253112793,
                0.8167672753334045,
                0.8102149963378906,
                0.898135781288147,
                0.8476710915565491,
                0.9024010896682739,
                0.8016863465309143,
                0.786443293094635,
                0.8536683917045593,
                0.8639951348304749,
                0.8437703251838684,
                0.8156375885009766,
                0.8353822827339172,
                0.8076828122138977,
                0.8660724759101868,
                0.7920795679092407,
                0.8713114261627197,
                0.8348355293273926,
                0.7716160416603088,
                0.8469530940055847,
                0.8547582626342773,
                0.8558825254440308,
                0.8379491567611694,
                0.8674717545509338,
                0.8628889918327332,
                0.8595296144485474,
                0.8328354358673096,
                0.8568119406700134,
                0.8496295809745789,
                0.8178531527519226,
                0.8500102162361145,
                0.8801329731941223,
                0.8720163702964783,
                0.8304369449615479,
                0.8569123148918152,
                0.850125789642334,
                0.8593207001686096,
                0.8718879818916321,
                0.8153044581413269,
                0.8550697565078735,
                0.8125274777412415,
                0.8129388093948364,
                0.8205903768539429,
                0.8461484313011169,
                0.8417296409606934,
                0.8666605353355408
            ],
            [
                0.7662255764007568,
                0.7802691459655762,
                0.7881304621696472,
                0.7489498853683472,
                0.7640933394432068,
                0.7414761781692505,
                0.762454092502594,
                0.7714531421661377,
                0.7997706532478333,
                0.76023930311203,
                0.7990613579750061,
                0.7335228323936462,
                0.6969035267829895,
                0.7756707668304443,
                0.7922438383102417,
                0.7667417526245117,
                0.7469373345375061,
                0.7443686723709106,
                0.7333945631980896,
                0.7707551717758179,
                0.7009305953979492,
                0.8119527697563171,
                0.7615185379981995,
                0.6810598969459534,
                0.7445169687271118,
                0.7760909199714661,
                0.7725544571876526,
                0.7693305611610413,
                0.7970299124717712,
                0.8116168975830078,
                0.8059293627738953,
                0.7791157960891724,
                0.7904200553894043,
                0.7527485489845276,
                0.7692475318908691,
                0.7828155755996704,
                0.7719607353210449,
                0.7888635396957397,
                0.7480899691581726,
                0.7790341377258301,
                0.804664134979248,
                0.7633270025253296,
                0.7753978967666626,
                0.7428730726242065,
                0.7862915992736816,
                0.7465951442718506,
                0.7393237352371216,
                0.7540236711502075,
                0.8103080987930298,
                0.7731008529663086,
                0.7928177714347839
            ],
            [
                0.9006308317184448,
                0.9097557067871094,
                0.9114492535591125,
                0.9045628309249878,
                0.8765764832496643,
                0.8363630175590515,
                0.8578317761421204,
                0.8464342951774597,
                0.9327893853187561,
                0.8586519360542297,
                0.9330790042877197,
                0.8099893927574158,
                0.7933968305587769,
                0.8708196878433228,
                0.8737142086029053,
                0.8668571710586548,
                0.8495801687240601,
                0.840872585773468,
                0.8249892592430115,
                0.8948573470115662,
                0.8218061923980713,
                0.9118279814720154,
                0.837485671043396,
                0.7846810221672058,
                0.8718760013580322,
                0.8895388841629028,
                0.8892419934272766,
                0.8676681518554688,
                0.8483090400695801,
                0.8492354154586792,
                0.8546966314315796,
                0.8423610329627991,
                0.8836108446121216,
                0.9001521468162537,
                0.8529412150382996,
                0.8554098010063171,
                0.9225108623504639,
                0.8953274488449097,
                0.8444604873657227,
                0.8773592710494995,
                0.8709041476249695,
                0.9007395505905151,
                0.8903432488441467,
                0.8470327258110046,
                0.8651388883590698,
                0.8416310548782349,
                0.8076571226119995,
                0.8092200756072998,
                0.8699280619621277,
                0.8582388162612915,
                0.88273024559021
            ],
            [
                0.8400698304176331,
                0.8558511137962341,
                0.8574610352516174,
                0.8118643164634705,
                0.8498295545578003,
                0.9111452102661133,
                0.8228317499160767,
                0.9067077040672302,
                0.8984009623527527,
                0.9084898233413696,
                0.8725443482398987,
                0.9047428965568542,
                0.8320399522781372,
                0.9414913654327393,
                0.9341099262237549,
                0.8890233635902405,
                0.9156718850135803,
                0.7573950290679932,
                0.9196417927742004,
                0.8829668760299683,
                0.9076776504516602,
                0.8460877537727356,
                0.9229189157485962,
                0.8284100890159607,
                0.9288986325263977,
                0.9322965145111084,
                0.9255204796791077,
                0.9489205479621887,
                0.890364408493042,
                0.913867175579071,
                0.9069852828979492,
                0.9294293522834778,
                0.9547319412231445,
                0.817797064781189,
                0.8953574299812317,
                0.9002567529678345,
                0.8420345783233643,
                0.9380210041999817,
                0.9074141383171082,
                0.9276419878005981,
                0.954170823097229,
                0.8499331474304199,
                0.8847874999046326,
                0.9429188370704651,
                0.8810936212539673,
                0.9306207895278931,
                0.8879690170288086,
                0.8083330988883972,
                0.8459005951881409,
                0.8949439525604248,
                0.9111273884773254
            ],
            [
                0.7758474946022034,
                0.7663131952285767,
                0.7684506177902222,
                0.7358759641647339,
                0.8402959704399109,
                0.835135281085968,
                0.7802495360374451,
                0.7890369892120361,
                0.8155674934387207,
                0.8518661856651306,
                0.7827146649360657,
                0.8366673588752747,
                0.792663037776947,
                0.8359951972961426,
                0.8662663102149963,
                0.8228017687797546,
                0.7823270559310913,
                0.7661693692207336,
                0.8259363174438477,
                0.8158159255981445,
                0.7915684580802917,
                0.7911675572395325,
                0.8463799357414246,
                0.7828862071037292,
                0.8130470514297485,
                0.7958873510360718,
                0.7875181436538696,
                0.8003137707710266,
                0.8668279647827148,
                0.8573845028877258,
                0.8371949195861816,
                0.8348612785339355,
                0.8250712156295776,
                0.7367037534713745,
                0.7652838230133057,
                0.851284384727478,
                0.7639421820640564,
                0.8527888059616089,
                0.8102962970733643,
                0.804650068283081,
                0.8423362970352173,
                0.7624333500862122,
                0.8388639688491821,
                0.8206213712692261,
                0.8610019683837891,
                0.802582859992981,
                0.838261604309082,
                0.8649387359619141,
                0.7680243253707886,
                0.8163549900054932,
                0.8470944166183472
            ],
            [
                0.7747008204460144,
                0.7950034141540527,
                0.7979549169540405,
                0.766899585723877,
                0.7751093506813049,
                0.7540774345397949,
                0.7882218360900879,
                0.7822760343551636,
                0.8258726596832275,
                0.7896135449409485,
                0.7994622588157654,
                0.7667185068130493,
                0.7216954827308655,
                0.8126810193061829,
                0.8124892115592957,
                0.7848749756813049,
                0.8015310168266296,
                0.7792335748672485,
                0.7614849805831909,
                0.793315589427948,
                0.7104721069335938,
                0.8288447260856628,
                0.7918859720230103,
                0.6996745467185974,
                0.7767804265022278,
                0.8238939046859741,
                0.8213545083999634,
                0.7673240303993225,
                0.802269458770752,
                0.8253241777420044,
                0.8287786245346069,
                0.7953274250030518,
                0.7980561852455139,
                0.7656816244125366,
                0.7729684710502625,
                0.798579216003418,
                0.7869221568107605,
                0.8107436299324036,
                0.7916340827941895,
                0.8136409521102905,
                0.8183574080467224,
                0.7801180481910706,
                0.7866615056991577,
                0.7704468965530396,
                0.7822079062461853,
                0.7753815650939941,
                0.7270497679710388,
                0.7624877095222473,
                0.8054036498069763,
                0.7877610921859741,
                0.7892429828643799
            ],
            [
                0.8763496279716492,
                0.9038593173027039,
                0.9008911848068237,
                0.876234769821167,
                0.8666098117828369,
                0.7642113566398621,
                0.840012788772583,
                0.787057638168335,
                0.9083357453346252,
                0.8017923831939697,
                0.9053018689155579,
                0.7656700611114502,
                0.7248842120170593,
                0.8161174058914185,
                0.819488525390625,
                0.808934211730957,
                0.7896313071250916,
                0.8224624991416931,
                0.7728142142295837,
                0.8596993088722229,
                0.747278094291687,
                0.8776397705078125,
                0.7745331525802612,
                0.7104644775390625,
                0.8083773255348206,
                0.8317850828170776,
                0.8257396817207336,
                0.7983282208442688,
                0.801620602607727,
                0.8101101517677307,
                0.8096067309379578,
                0.8002822399139404,
                0.8269684314727783,
                0.9017733335494995,
                0.802794873714447,
                0.7995173931121826,
                0.909191370010376,
                0.8333081603050232,
                0.779107928276062,
                0.8157932758331299,
                0.8163518309593201,
                0.8998497128486633,
                0.851879358291626,
                0.7758559584617615,
                0.8178196549415588,
                0.7716224789619446,
                0.7433114051818848,
                0.7746196389198303,
                0.8657299876213074,
                0.8002046942710876,
                0.8186733722686768
            ],
            [
                0.773596465587616,
                0.7768118977546692,
                0.7785016298294067,
                0.7568767070770264,
                0.76031494140625,
                0.7571448087692261,
                0.7516254186630249,
                0.7515121698379517,
                0.8112630844116211,
                0.7839007377624512,
                0.8003098964691162,
                0.773556113243103,
                0.7115546464920044,
                0.816493034362793,
                0.7998782396316528,
                0.7656952142715454,
                0.7611782550811768,
                0.739494800567627,
                0.7775869369506836,
                0.7744291424751282,
                0.6991689801216125,
                0.7999598979949951,
                0.7681017518043518,
                0.6888214945793152,
                0.7409522533416748,
                0.7740442752838135,
                0.7605183124542236,
                0.7784258723258972,
                0.7981051802635193,
                0.8306347131729126,
                0.7993152141571045,
                0.7646387815475464,
                0.7663090825080872,
                0.7309118509292603,
                0.754549503326416,
                0.7821203470230103,
                0.7706021666526794,
                0.7973066568374634,
                0.7566303610801697,
                0.7871217131614685,
                0.8041797280311584,
                0.7618403434753418,
                0.7776970267295837,
                0.7559261322021484,
                0.7724958658218384,
                0.7571983933448792,
                0.7352249026298523,
                0.7541947960853577,
                0.7672010064125061,
                0.7725067734718323,
                0.77256840467453
            ],
            [
                0.848353385925293,
                0.8786364197731018,
                0.8696590662002563,
                0.8412162661552429,
                0.8328050374984741,
                0.8051837086677551,
                0.8103587627410889,
                0.8296144008636475,
                0.9004615545272827,
                0.8317530751228333,
                0.8966084122657776,
                0.7997770309448242,
                0.7707770466804504,
                0.849772572517395,
                0.857852041721344,
                0.8393541574478149,
                0.8223928213119507,
                0.7938575744628906,
                0.8104851245880127,
                0.8669567108154297,
                0.8033349514007568,
                0.8434941172599792,
                0.8255877494812012,
                0.7528523206710815,
                0.8507819771766663,
                0.8695117831230164,
                0.8694360256195068,
                0.8531283736228943,
                0.815896213054657,
                0.8297183513641357,
                0.8264985680580139,
                0.8358237743377686,
                0.8811960220336914,
                0.8455784320831299,
                0.8454753756523132,
                0.8261380791664124,
                0.8900856971740723,
                0.8799102902412415,
                0.8266641497612,
                0.8601131439208984,
                0.8607885241508484,
                0.867462694644928,
                0.8563661575317383,
                0.8413081169128418,
                0.8389624357223511,
                0.8385925889015198,
                0.7829858064651489,
                0.7734382748603821,
                0.8741496205329895,
                0.8422819972038269,
                0.8654956817626953
            ],
            [
                0.7893145084381104,
                0.7966734766960144,
                0.8055024147033691,
                0.779087483882904,
                0.773264467716217,
                0.7720151543617249,
                0.7845667004585266,
                0.783753514289856,
                0.8285951614379883,
                0.7841778993606567,
                0.812182605266571,
                0.7488886117935181,
                0.7341859936714172,
                0.7976693511009216,
                0.8025525808334351,
                0.7909201979637146,
                0.7728055715560913,
                0.7495041489601135,
                0.7552021145820618,
                0.7948675155639648,
                0.7148774266242981,
                0.835725724697113,
                0.7848711013793945,
                0.7206711769104004,
                0.7673566341400146,
                0.8026836514472961,
                0.8003360629081726,
                0.7936119437217712,
                0.8099842071533203,
                0.8236474394798279,
                0.837544322013855,
                0.7818302512168884,
                0.8008623123168945,
                0.7698500752449036,
                0.7847052812576294,
                0.8000174164772034,
                0.789957582950592,
                0.815182089805603,
                0.7740004062652588,
                0.8034284114837646,
                0.8215019106864929,
                0.7793777585029602,
                0.7989997863769531,
                0.7652592658996582,
                0.8006942868232727,
                0.7663971185684204,
                0.7466983795166016,
                0.7727987766265869,
                0.7951744794845581,
                0.7928560376167297,
                0.7983759045600891
            ],
            [
                0.7781014442443848,
                0.769791841506958,
                0.7678603529930115,
                0.7453591823577881,
                0.7644942402839661,
                0.767703115940094,
                0.7764192819595337,
                0.7635313868522644,
                0.8028273582458496,
                0.7870698571205139,
                0.7837885022163391,
                0.760663628578186,
                0.7212759852409363,
                0.781208336353302,
                0.7884925603866577,
                0.761675238609314,
                0.7409791350364685,
                0.742766261100769,
                0.7555870413780212,
                0.776601254940033,
                0.6883490085601807,
                0.8055360913276672,
                0.7743933200836182,
                0.6919494271278381,
                0.7328227758407593,
                0.7592158317565918,
                0.7488322257995605,
                0.7570172548294067,
                0.8182287812232971,
                0.8308318257331848,
                0.8248600363731384,
                0.7699851989746094,
                0.7692449688911438,
                0.7249341011047363,
                0.74898362159729,
                0.7912053465843201,
                0.7637262344360352,
                0.7988163828849792,
                0.7567867040634155,
                0.7794532775878906,
                0.8048707842826843,
                0.7633731961250305,
                0.7853584289550781,
                0.7395136952400208,
                0.7842879891395569,
                0.739611029624939,
                0.7628049254417419,
                0.7718978524208069,
                0.7734992504119873,
                0.7727054357528687,
                0.7787907123565674
            ],
            [
                0.793674886226654,
                0.8087650537490845,
                0.7973421812057495,
                0.8200831413269043,
                0.7392488718032837,
                0.6764847040176392,
                0.7199617028236389,
                0.6966869831085205,
                0.8241388201713562,
                0.7308850884437561,
                0.8426039814949036,
                0.7082531452178955,
                0.6708366274833679,
                0.7690587639808655,
                0.7564784288406372,
                0.7258872389793396,
                0.7361546754837036,
                0.7734644412994385,
                0.7182039618492126,
                0.7662927508354187,
                0.6924890875816345,
                0.7745806574821472,
                0.7161570191383362,
                0.6427993178367615,
                0.7587418556213379,
                0.7794340252876282,
                0.776426374912262,
                0.7558059692382812,
                0.7589917778968811,
                0.7848086953163147,
                0.7759960889816284,
                0.7368305325508118,
                0.7596171498298645,
                0.7851842045783997,
                0.7230877876281738,
                0.7326411008834839,
                0.823567807674408,
                0.7747048735618591,
                0.7441281676292419,
                0.7898321747779846,
                0.7425529956817627,
                0.7833976149559021,
                0.7688506841659546,
                0.7214308977127075,
                0.7337484359741211,
                0.7332972884178162,
                0.6887790560722351,
                0.6953276991844177,
                0.7690542936325073,
                0.7359687089920044,
                0.771050214767456
            ],
            [
                0.8614192605018616,
                0.8789445757865906,
                0.8725733757019043,
                0.8483558297157288,
                0.8567749261856079,
                0.8051337003707886,
                0.832473635673523,
                0.8135941028594971,
                0.9129951000213623,
                0.8381524682044983,
                0.8963185548782349,
                0.7923684120178223,
                0.7701928615570068,
                0.834261417388916,
                0.847838819026947,
                0.8297288417816162,
                0.8090307116508484,
                0.8186488747596741,
                0.8007725477218628,
                0.8738601207733154,
                0.7807261347770691,
                0.8646497130393982,
                0.8187319040298462,
                0.7540740966796875,
                0.8284677863121033,
                0.8491024374961853,
                0.8488324284553528,
                0.8273777365684509,
                0.8292294144630432,
                0.834073007106781,
                0.8358813524246216,
                0.8252278566360474,
                0.8566026091575623,
                0.8585219383239746,
                0.8150719404220581,
                0.8342621922492981,
                0.899272620677948,
                0.879059910774231,
                0.8161892890930176,
                0.845524787902832,
                0.8505237102508545,
                0.8802332878112793,
                0.8731819987297058,
                0.8203088641166687,
                0.8532203435897827,
                0.8203670382499695,
                0.7873393893241882,
                0.8021151423454285,
                0.8790723085403442,
                0.8318480253219604,
                0.8639426231384277
            ],
            [
                0.7880107164382935,
                0.7769300937652588,
                0.7914095520973206,
                0.7519382834434509,
                0.8159815073013306,
                0.7881330847740173,
                0.7780850529670715,
                0.7639629244804382,
                0.8233920335769653,
                0.8126857280731201,
                0.7983241081237793,
                0.8275960087776184,
                0.7141560912132263,
                0.8229138255119324,
                0.8140974044799805,
                0.7683249711990356,
                0.750725269317627,
                0.7567417621612549,
                0.811302125453949,
                0.7796292901039124,
                0.727683424949646,
                0.8098757266998291,
                0.7952218055725098,
                0.6869993805885315,
                0.7398506999015808,
                0.7542861700057983,
                0.7417258024215698,
                0.7798380851745605,
                0.8417801260948181,
                0.8645428419113159,
                0.8475552797317505,
                0.8169702887535095,
                0.7835658192634583,
                0.7417864799499512,
                0.7500032186508179,
                0.7904364466667175,
                0.7622495889663696,
                0.8022958040237427,
                0.7726045250892639,
                0.8000043034553528,
                0.8279852867126465,
                0.7692261934280396,
                0.7993565797805786,
                0.7778001427650452,
                0.807276725769043,
                0.7695306539535522,
                0.7902825474739075,
                0.8220654129981995,
                0.7860212922096252,
                0.7720217704772949,
                0.7874352931976318
            ],
            [
                0.9182323813438416,
                0.9096294641494751,
                0.9195301532745361,
                0.8949310183525085,
                0.9252601265907288,
                0.8890366554260254,
                0.8994491100311279,
                0.877140998840332,
                0.9392377138137817,
                0.9066582918167114,
                0.9427798986434937,
                0.865644633769989,
                0.8222217559814453,
                0.8957105278968811,
                0.9120163917541504,
                0.8915113806724548,
                0.8669437170028687,
                0.8499978184700012,
                0.8645369410514832,
                0.9187012910842896,
                0.8298280239105225,
                0.9356212615966797,
                0.8779897689819336,
                0.8068844676017761,
                0.8745328783988953,
                0.883025586605072,
                0.8777163028717041,
                0.8736236095428467,
                0.9022244215011597,
                0.8942179679870605,
                0.8862535953521729,
                0.8720355033874512,
                0.8849818706512451,
                0.8880175948143005,
                0.8618742227554321,
                0.8919467926025391,
                0.9146882891654968,
                0.9142777323722839,
                0.8719638586044312,
                0.8949043154716492,
                0.9002847671508789,
                0.9113203883171082,
                0.9289728403091431,
                0.8681422472000122,
                0.9184524416923523,
                0.8606822490692139,
                0.8628165125846863,
                0.8983662724494934,
                0.8792972564697266,
                0.8867504596710205,
                0.9053106307983398
            ],
            [
                0.8033100366592407,
                0.7671685218811035,
                0.7834184169769287,
                0.7685112357139587,
                0.7637952566146851,
                0.7391270995140076,
                0.7498292326927185,
                0.7278825044631958,
                0.8149323463439941,
                0.790765106678009,
                0.8052278757095337,
                0.7719661593437195,
                0.6982666254043579,
                0.7912051677703857,
                0.7739931344985962,
                0.7464379668235779,
                0.7295034527778625,
                0.7867632508277893,
                0.7665154337882996,
                0.7778416872024536,
                0.6925013661384583,
                0.7920970320701599,
                0.7559352517127991,
                0.6772355437278748,
                0.7182286381721497,
                0.7450258731842041,
                0.7337669134140015,
                0.7601771950721741,
                0.8143029808998108,
                0.8187875151634216,
                0.8083274960517883,
                0.7595095634460449,
                0.7482283711433411,
                0.7405552268028259,
                0.7191631197929382,
                0.7771829962730408,
                0.7752209305763245,
                0.7804784178733826,
                0.752225935459137,
                0.7822636961936951,
                0.7952012419700623,
                0.7694631814956665,
                0.7969074249267578,
                0.7445679306983948,
                0.7886446714401245,
                0.754122793674469,
                0.7519744038581848,
                0.7724063992500305,
                0.7655699849128723,
                0.7537267804145813,
                0.773079514503479
            ]
        ],
        [
            [
                0.6761007308959961,
                0.8388912677764893,
                0.9028648734092712,
                0.8338538408279419,
                0.7451854944229126,
                0.7371240854263306,
                0.7012386322021484,
                0.6190861463546753,
                0.6980515122413635,
                0.7829775810241699,
                0.6548970937728882,
                0.7501800060272217,
                0.8587412238121033,
                0.825793981552124,
                0.7027198076248169,
                0.6321626305580139,
                0.6923638582229614,
                0.7452011108398438,
                0.8481375575065613,
                0.6704220175743103,
                0.7061378955841064,
                0.749984622001648,
                0.8373757004737854,
                0.7010216116905212,
                0.7300558686256409,
                0.8492605686187744,
                0.629501223564148,
                0.7092550992965698,
                0.7467626929283142,
                0.8011621832847595,
                0.8663647770881653,
                0.7329707741737366,
                0.8077116012573242,
                0.7257068753242493,
                0.8165115118026733,
                0.680629312992096,
                0.7401816844940186,
                0.5302883386611938,
                0.7392618656158447,
                0.6887983679771423,
                0.7422065734863281,
                0.7543814778327942,
                0.7445324063301086,
                0.6802003979682922,
                0.6096292734146118,
                0.7022215127944946,
                0.7083450555801392,
                0.734444260597229,
                0.7170925140380859,
                0.7291821837425232,
                0.8115221261978149
            ],
            [
                0.6263993382453918,
                0.6913126707077026,
                0.7678696513175964,
                0.863815426826477,
                0.709151029586792,
                0.7281835675239563,
                0.7242752909660339,
                0.6352035999298096,
                0.6515382528305054,
                0.6584714651107788,
                0.6263831853866577,
                0.8636091351509094,
                0.7621955275535583,
                0.8344842791557312,
                0.6253476738929749,
                0.6241906881332397,
                0.7502308487892151,
                0.8564640879631042,
                0.7543182373046875,
                0.6613938808441162,
                0.7162758708000183,
                0.8581979870796204,
                0.7791342735290527,
                0.7318381667137146,
                0.7487804889678955,
                0.7805951833724976,
                0.6087449789047241,
                0.7873139977455139,
                0.8631258606910706,
                0.7644534111022949,
                0.7979201674461365,
                0.7534549832344055,
                0.7508828043937683,
                0.7347441911697388,
                0.707190990447998,
                0.735343337059021,
                0.7402966618537903,
                0.5229828953742981,
                0.8609271049499512,
                0.6841472387313843,
                0.878823459148407,
                0.7625084519386292,
                0.757574737071991,
                0.5887714624404907,
                0.5962674021720886,
                0.7446567416191101,
                0.6400921940803528,
                0.791922926902771,
                0.6665792465209961,
                0.8677599430084229,
                0.7893486022949219
            ],
            [
                0.6976760029792786,
                0.8085736632347107,
                0.9562572836875916,
                0.859350323677063,
                0.776542603969574,
                0.7569289207458496,
                0.7308554649353027,
                0.6262620687484741,
                0.6867385506629944,
                0.7950612306594849,
                0.7058640122413635,
                0.8092690706253052,
                0.9045085310935974,
                0.8666499853134155,
                0.6958644390106201,
                0.6737991571426392,
                0.7628386616706848,
                0.8210521936416626,
                0.8835198283195496,
                0.6795505285263062,
                0.737343430519104,
                0.825434684753418,
                0.8804522156715393,
                0.7545920014381409,
                0.7863710522651672,
                0.8800987005233765,
                0.6791180968284607,
                0.8035876750946045,
                0.8318285346031189,
                0.8361008763313293,
                0.8935986161231995,
                0.7576309442520142,
                0.8023717999458313,
                0.7682236433029175,
                0.8033244013786316,
                0.7310763001441956,
                0.7742370963096619,
                0.5513160228729248,
                0.8140805959701538,
                0.6907358765602112,
                0.818217396736145,
                0.8360373973846436,
                0.7854180932044983,
                0.7091472744941711,
                0.648476243019104,
                0.763009786605835,
                0.7839491367340088,
                0.7922471761703491,
                0.7579437494277954,
                0.8352850079536438,
                0.8809792995452881
            ],
            [
                0.7035849690437317,
                0.6962267160415649,
                0.8194639682769775,
                0.8662876486778259,
                0.7514606714248657,
                0.8655706644058228,
                0.7821345925331116,
                0.6380007266998291,
                0.7090466618537903,
                0.7126762270927429,
                0.6011104583740234,
                0.8742508888244629,
                0.7740769386291504,
                0.8835219740867615,
                0.6761830449104309,
                0.671857476234436,
                0.7559071183204651,
                0.8746089339256287,
                0.781408429145813,
                0.724866509437561,
                0.820779025554657,
                0.8897749185562134,
                0.8185493350028992,
                0.8276665210723877,
                0.8196654319763184,
                0.8488458395004272,
                0.6652250289916992,
                0.7827568650245667,
                0.8808130621910095,
                0.7590595483779907,
                0.8416641354560852,
                0.8075461983680725,
                0.8034878969192505,
                0.8129215836524963,
                0.7362696528434753,
                0.7184935212135315,
                0.7686487436294556,
                0.5383484363555908,
                0.8662866950035095,
                0.7321005463600159,
                0.8697425127029419,
                0.7214880585670471,
                0.8256301879882812,
                0.6074709892272949,
                0.6616141200065613,
                0.8378154039382935,
                0.6538049578666687,
                0.8448871374130249,
                0.6859918236732483,
                0.8764474391937256,
                0.8045227527618408
            ],
            [
                0.7273862957954407,
                0.6733918190002441,
                0.7427291870117188,
                0.8318986892700195,
                0.7324379682540894,
                0.8882308006286621,
                0.8725180625915527,
                0.7479388117790222,
                0.8448013663291931,
                0.7211670875549316,
                0.6647176146507263,
                0.885779857635498,
                0.7173209190368652,
                0.8335378766059875,
                0.7514686584472656,
                0.793526828289032,
                0.7952931523323059,
                0.8723635673522949,
                0.723429799079895,
                0.8557034134864807,
                0.9106552600860596,
                0.8910004496574402,
                0.7393355369567871,
                0.901178777217865,
                0.8721277117729187,
                0.7939648032188416,
                0.7598878741264343,
                0.7535369396209717,
                0.8386966586112976,
                0.6956124305725098,
                0.8196348547935486,
                0.9155091047286987,
                0.8777096271514893,
                0.8986603021621704,
                0.7468266487121582,
                0.7064170837402344,
                0.8388326168060303,
                0.653335452079773,
                0.8389950394630432,
                0.8763372898101807,
                0.8455666899681091,
                0.6900148987770081,
                0.8897742033004761,
                0.5757142901420593,
                0.8203173875808716,
                0.9006091356277466,
                0.6571828126907349,
                0.9141579866409302,
                0.6470348238945007,
                0.8121336102485657,
                0.735072135925293
            ],
            [
                0.6848704218864441,
                0.6985994577407837,
                0.7892129421234131,
                0.8592435121536255,
                0.740852952003479,
                0.8170344233512878,
                0.896310031414032,
                0.7451501488685608,
                0.7816057801246643,
                0.7093460559844971,
                0.6579909920692444,
                0.8953887820243835,
                0.780462384223938,
                0.8608813285827637,
                0.6960952877998352,
                0.7229907512664795,
                0.8071920275688171,
                0.8935070037841797,
                0.7781529426574707,
                0.7628601789474487,
                0.8562101125717163,
                0.9026280045509338,
                0.7930473685264587,
                0.8615424633026123,
                0.8548499345779419,
                0.810146689414978,
                0.700445830821991,
                0.8332886695861816,
                0.8857533931732178,
                0.7516330480575562,
                0.8455929160118103,
                0.8637633323669434,
                0.8297507166862488,
                0.8666011691093445,
                0.7415000200271606,
                0.7376241087913513,
                0.8306046724319458,
                0.5675063729286194,
                0.9050793647766113,
                0.8142078518867493,
                0.8907477855682373,
                0.7541786432266235,
                0.8696900010108948,
                0.5932025909423828,
                0.7224863171577454,
                0.8670209646224976,
                0.6772114038467407,
                0.8940354585647583,
                0.6826125383377075,
                0.869164764881134,
                0.7922379374504089
            ],
            [
                0.7310366034507751,
                0.7700658440589905,
                0.8331387639045715,
                0.7784601449966431,
                0.739253044128418,
                0.7149896025657654,
                0.7108961939811707,
                0.6359018087387085,
                0.7016045451164246,
                0.8627432584762573,
                0.6926873922348022,
                0.7473569512367249,
                0.8772120475769043,
                0.7985840439796448,
                0.711978018283844,
                0.6755661368370056,
                0.7406408190727234,
                0.7563371658325195,
                0.8476413488388062,
                0.6669585108757019,
                0.7105402946472168,
                0.7425920367240906,
                0.8443267345428467,
                0.7248120307922363,
                0.7599214911460876,
                0.8578841686248779,
                0.6736488342285156,
                0.7296467423439026,
                0.7430706024169922,
                0.8029019236564636,
                0.8686626553535461,
                0.7168500423431396,
                0.7870834469795227,
                0.7547276616096497,
                0.7925969362258911,
                0.6428942084312439,
                0.7613047957420349,
                0.5998496413230896,
                0.7302863001823425,
                0.7086125016212463,
                0.7281845211982727,
                0.7828132510185242,
                0.7548940181732178,
                0.695431649684906,
                0.6620383262634277,
                0.7269574999809265,
                0.7630653977394104,
                0.7537845969200134,
                0.7537792325019836,
                0.7319709658622742,
                0.8391379117965698
            ],
            [
                0.6904840469360352,
                0.7029194235801697,
                0.7734116315841675,
                0.8788036108016968,
                0.8031671047210693,
                0.8290005326271057,
                0.8464000225067139,
                0.7499407529830933,
                0.8513340950012207,
                0.7211812734603882,
                0.6640194654464722,
                0.893551766872406,
                0.7937987446784973,
                0.9002060890197754,
                0.7459725141525269,
                0.761096715927124,
                0.8044896125793457,
                0.8810335397720337,
                0.7798018455505371,
                0.8209272027015686,
                0.8458335995674133,
                0.8789321780204773,
                0.7685482501983643,
                0.8415766358375549,
                0.8562699556350708,
                0.8380436301231384,
                0.7140139937400818,
                0.7808236479759216,
                0.8608651161193848,
                0.770374059677124,
                0.8573082685470581,
                0.8982104659080505,
                0.8681554794311523,
                0.8467835783958435,
                0.7696854472160339,
                0.7196632623672485,
                0.8497878909111023,
                0.5735160708427429,
                0.8682917356491089,
                0.8486435413360596,
                0.8672411441802979,
                0.7490260004997253,
                0.8769273161888123,
                0.6493026614189148,
                0.7877745032310486,
                0.8427554368972778,
                0.6844161152839661,
                0.8783974051475525,
                0.7095858454704285,
                0.8352328538894653,
                0.7580893039703369
            ],
            [
                0.7401043176651001,
                0.6889192461967468,
                0.7775828838348389,
                0.8526507019996643,
                0.7716087698936462,
                0.8635677695274353,
                0.872920572757721,
                0.7631930708885193,
                0.869160532951355,
                0.7534043788909912,
                0.6326828598976135,
                0.8897762894630432,
                0.775979220867157,
                0.8513726592063904,
                0.7472314834594727,
                0.7561209201812744,
                0.8282630443572998,
                0.8837630152702332,
                0.757940948009491,
                0.8205927610397339,
                0.9106720685958862,
                0.886700451374054,
                0.7729430794715881,
                0.9055739641189575,
                0.8914075493812561,
                0.8241279721260071,
                0.7304036617279053,
                0.7925292253494263,
                0.8495678305625916,
                0.7277978658676147,
                0.8366537094116211,
                0.9149733781814575,
                0.8784612417221069,
                0.8973342180252075,
                0.7597561478614807,
                0.7086631059646606,
                0.8583076596260071,
                0.5976496934890747,
                0.8458899259567261,
                0.8787367939949036,
                0.849759578704834,
                0.7371963858604431,
                0.9097384214401245,
                0.6110997200012207,
                0.7980033159255981,
                0.908126175403595,
                0.6641417145729065,
                0.9236218929290771,
                0.6929258108139038,
                0.8300777673721313,
                0.7603791952133179
            ],
            [
                0.6683367490768433,
                0.6785486340522766,
                0.7595362663269043,
                0.8402467966079712,
                0.752180814743042,
                0.7595799565315247,
                0.7779101133346558,
                0.720745861530304,
                0.7578763961791992,
                0.7086817622184753,
                0.650109052658081,
                0.8405429124832153,
                0.758936882019043,
                0.8638321757316589,
                0.7009825110435486,
                0.7011781930923462,
                0.835357666015625,
                0.8549246788024902,
                0.7558009028434753,
                0.7190636396408081,
                0.8089273571968079,
                0.8450437784194946,
                0.7456537485122681,
                0.8217235207557678,
                0.843701183795929,
                0.7824342846870422,
                0.6797175407409668,
                0.8307843804359436,
                0.8419776558876038,
                0.7222762107849121,
                0.8269424438476562,
                0.834771454334259,
                0.8169488906860352,
                0.8244730830192566,
                0.7498367428779602,
                0.7385695576667786,
                0.8227401375770569,
                0.5539087057113647,
                0.8693610429763794,
                0.777069091796875,
                0.838678240776062,
                0.7505133152008057,
                0.8448013663291931,
                0.6194575428962708,
                0.7216187119483948,
                0.8294249176979065,
                0.6634310483932495,
                0.8536865711212158,
                0.6739896535873413,
                0.8231296539306641,
                0.7478185296058655
            ],
            [
                0.672835111618042,
                0.7619518637657166,
                0.8694594502449036,
                0.8599207997322083,
                0.739932656288147,
                0.7472429871559143,
                0.7532371878623962,
                0.6395042538642883,
                0.6741626262664795,
                0.8022316694259644,
                0.7075810432434082,
                0.8510304093360901,
                0.8563404679298401,
                0.9109832644462585,
                0.6680595278739929,
                0.6923742294311523,
                0.800475537776947,
                0.8672593235969543,
                0.8777276277542114,
                0.6800359487533569,
                0.7505530714988708,
                0.8609036207199097,
                0.8964425325393677,
                0.7796743512153625,
                0.8071383237838745,
                0.8861539959907532,
                0.6761161088943481,
                0.8532791137695312,
                0.8735469579696655,
                0.8277872204780579,
                0.9178257584571838,
                0.7713825702667236,
                0.8282662034034729,
                0.7933638095855713,
                0.7738963961601257,
                0.7467160820960999,
                0.7981880903244019,
                0.5933165550231934,
                0.8792082071304321,
                0.7212001085281372,
                0.8651392459869385,
                0.8428207635879517,
                0.7934783697128296,
                0.6852001547813416,
                0.6726667881011963,
                0.7915294170379639,
                0.7454772591590881,
                0.8128464221954346,
                0.7473449110984802,
                0.8841999769210815,
                0.8729935884475708
            ],
            [
                0.7186331748962402,
                0.6624782085418701,
                0.7261343002319336,
                0.813104510307312,
                0.7534621953964233,
                0.843040406703949,
                0.8516291379928589,
                0.7778748273849487,
                0.8474336862564087,
                0.7184036374092102,
                0.6725132465362549,
                0.8481321334838867,
                0.7355319857597351,
                0.8297765851020813,
                0.780529797077179,
                0.7849143743515015,
                0.8395219445228577,
                0.8519668579101562,
                0.7367618083953857,
                0.8297711610794067,
                0.8888130187988281,
                0.8528879880905151,
                0.723742663860321,
                0.8902295827865601,
                0.8806331753730774,
                0.7796924710273743,
                0.7556474804878235,
                0.7689855098724365,
                0.8110377192497253,
                0.7025230526924133,
                0.8146690130233765,
                0.9005480408668518,
                0.8524665236473083,
                0.8843789100646973,
                0.7479645013809204,
                0.6799834966659546,
                0.8609527349472046,
                0.6181474328041077,
                0.8245639801025391,
                0.8682388067245483,
                0.8131461143493652,
                0.7082850337028503,
                0.8877795338630676,
                0.6048302054405212,
                0.8132910132408142,
                0.891848087310791,
                0.6654137969017029,
                0.8960142731666565,
                0.663290798664093,
                0.7772995233535767,
                0.71441650390625
            ],
            [
                0.7034764289855957,
                0.7606231570243835,
                0.8535659909248352,
                0.8853815197944641,
                0.8067835569381714,
                0.8022108674049377,
                0.7783340215682983,
                0.6803168654441833,
                0.7642349004745483,
                0.7743135690689087,
                0.6363449096679688,
                0.8753231167793274,
                0.8610420227050781,
                0.9518246054649353,
                0.7089229822158813,
                0.6940957903862,
                0.8019174337387085,
                0.8822944164276123,
                0.8463660478591919,
                0.7181099653244019,
                0.8072261810302734,
                0.8713586926460266,
                0.8514320850372314,
                0.8197850584983826,
                0.8500300645828247,
                0.8991105556488037,
                0.6593196392059326,
                0.8251200318336487,
                0.8784821629524231,
                0.8271893858909607,
                0.9088406562805176,
                0.829856276512146,
                0.8466126322746277,
                0.820350170135498,
                0.7846009731292725,
                0.747120201587677,
                0.8233662843704224,
                0.5243446230888367,
                0.8733820915222168,
                0.7565531134605408,
                0.8691107630729675,
                0.7957583665847778,
                0.8462111949920654,
                0.7043353915214539,
                0.6999260783195496,
                0.8274515867233276,
                0.6854207515716553,
                0.8500388860702515,
                0.7685576677322388,
                0.8685728311538696,
                0.8246872425079346
            ],
            [
                0.7122148871421814,
                0.7377272248268127,
                0.8140160441398621,
                0.8735131025314331,
                0.7698691487312317,
                0.8424310684204102,
                0.8257623910903931,
                0.6907257437705994,
                0.7713579535484314,
                0.7420949339866638,
                0.671704113483429,
                0.9238488674163818,
                0.7955495119094849,
                0.9128773212432861,
                0.7008852958679199,
                0.7332884669303894,
                0.8131349086761475,
                0.9168419241905212,
                0.8017194271087646,
                0.7740718126296997,
                0.8670556545257568,
                0.9324676990509033,
                0.8200040459632874,
                0.8735705614089966,
                0.8736035227775574,
                0.8485429286956787,
                0.7158613204956055,
                0.837647557258606,
                0.9222829937934875,
                0.7901960611343384,
                0.8727614879608154,
                0.875957727432251,
                0.8527140021324158,
                0.863094687461853,
                0.7687583565711975,
                0.7617793083190918,
                0.8295261263847351,
                0.6021703481674194,
                0.9035420417785645,
                0.7973167896270752,
                0.9119143486022949,
                0.7720419764518738,
                0.8733350038528442,
                0.6373140811920166,
                0.7552785873413086,
                0.880425214767456,
                0.6920143365859985,
                0.9009334444999695,
                0.7290798425674438,
                0.9120312929153442,
                0.8084385395050049
            ],
            [
                0.7023796439170837,
                0.6880738735198975,
                0.7032504677772522,
                0.8025237321853638,
                0.7512911558151245,
                0.8235680460929871,
                0.8565734028816223,
                0.7570039629936218,
                0.8019827008247375,
                0.6935823559761047,
                0.747105062007904,
                0.8542548418045044,
                0.7096006274223328,
                0.7725192904472351,
                0.7654839754104614,
                0.8135290145874023,
                0.7981406450271606,
                0.8311495184898376,
                0.7081102728843689,
                0.87758469581604,
                0.8513941764831543,
                0.838828980922699,
                0.7219369411468506,
                0.8460711240768433,
                0.833168625831604,
                0.7579142451286316,
                0.8078319430351257,
                0.7094296216964722,
                0.8084039092063904,
                0.7055321931838989,
                0.7759308815002441,
                0.8712593913078308,
                0.8190548419952393,
                0.8533749580383301,
                0.7262119650840759,
                0.6588640809059143,
                0.8302141427993774,
                0.6806870698928833,
                0.7930508852005005,
                0.853208065032959,
                0.8187057375907898,
                0.716773509979248,
                0.8545275330543518,
                0.5921821594238281,
                0.822697103023529,
                0.8396367430686951,
                0.7327660918235779,
                0.8670145273208618,
                0.6858474016189575,
                0.7810511589050293,
                0.7271139621734619
            ],
            [
                0.7371878623962402,
                0.7543239593505859,
                0.8178153038024902,
                0.7983698844909668,
                0.7731316089630127,
                0.7153769731521606,
                0.6771935820579529,
                0.655968427658081,
                0.6569612622261047,
                0.785537600517273,
                0.724756121635437,
                0.7523233890533447,
                0.8249872922897339,
                0.7861721515655518,
                0.7153537273406982,
                0.7057358026504517,
                0.797233521938324,
                0.7770312428474426,
                0.7934685945510864,
                0.6758499145507812,
                0.7244669795036316,
                0.7677860260009766,
                0.8137705326080322,
                0.7484576106071472,
                0.7828767895698547,
                0.8069643378257751,
                0.7191523909568787,
                0.7808178663253784,
                0.773849606513977,
                0.778369665145874,
                0.8048470616340637,
                0.7097591161727905,
                0.727089524269104,
                0.7577080130577087,
                0.7413887977600098,
                0.6847553253173828,
                0.7719264626502991,
                0.6345036625862122,
                0.7508164644241333,
                0.680087149143219,
                0.7459000945091248,
                0.8296051025390625,
                0.7669094204902649,
                0.712715208530426,
                0.6865538358688354,
                0.7609662413597107,
                0.7741724252700806,
                0.7828501462936401,
                0.7509425282478333,
                0.7733376026153564,
                0.8280951380729675
            ],
            [
                0.6940090656280518,
                0.7496486902236938,
                0.8550797700881958,
                0.7808538675308228,
                0.7321245074272156,
                0.7060366868972778,
                0.6754462718963623,
                0.6086863875389099,
                0.6386578679084778,
                0.7818579077720642,
                0.70445716381073,
                0.7602702975273132,
                0.907518744468689,
                0.81656813621521,
                0.654746949672699,
                0.6291249990463257,
                0.7715274095535278,
                0.7760777473449707,
                0.8788952231407166,
                0.6139227747917175,
                0.6983988881111145,
                0.770117461681366,
                0.8869256377220154,
                0.7280701994895935,
                0.776241660118103,
                0.872026801109314,
                0.6513102650642395,
                0.7920371890068054,
                0.7787599563598633,
                0.8561077117919922,
                0.8524141311645508,
                0.6963527798652649,
                0.7355951070785522,
                0.7338757514953613,
                0.7590522766113281,
                0.6809278726577759,
                0.7633477449417114,
                0.5518344044685364,
                0.7686018347740173,
                0.6650282144546509,
                0.7578378915786743,
                0.8757933378219604,
                0.7552220225334167,
                0.7127678394317627,
                0.6139684319496155,
                0.7388173937797546,
                0.7534665465354919,
                0.7697744965553284,
                0.8436477780342102,
                0.7864936590194702,
                0.8999000191688538
            ],
            [
                0.7076117992401123,
                0.7039376497268677,
                0.7047247886657715,
                0.8022628426551819,
                0.7512974143028259,
                0.8122200965881348,
                0.8525054454803467,
                0.7628379464149475,
                0.7825111746788025,
                0.6962352991104126,
                0.7423703074455261,
                0.841610312461853,
                0.7164963483810425,
                0.7926466464996338,
                0.7667930126190186,
                0.8385284543037415,
                0.8091158270835876,
                0.8374814391136169,
                0.7308571338653564,
                0.8623163104057312,
                0.8370698690414429,
                0.8339176177978516,
                0.7333385348320007,
                0.8483150601387024,
                0.8398792743682861,
                0.7696917653083801,
                0.8106323480606079,
                0.7205987572669983,
                0.8071514368057251,
                0.7268641591072083,
                0.7853095531463623,
                0.854958176612854,
                0.8113557696342468,
                0.8652086853981018,
                0.7299770712852478,
                0.6684311628341675,
                0.8332068920135498,
                0.6834287047386169,
                0.8002194762229919,
                0.8341564536094666,
                0.8162525296211243,
                0.7241455316543579,
                0.8402937054634094,
                0.6189499497413635,
                0.8114389181137085,
                0.8419821262359619,
                0.7364693880081177,
                0.8558616042137146,
                0.6875833868980408,
                0.7881113290786743,
                0.7305837273597717
            ],
            [
                0.7683722376823425,
                0.7403552532196045,
                0.7752389311790466,
                0.7956937551498413,
                0.7985628247261047,
                0.7323831915855408,
                0.7253521680831909,
                0.7135442495346069,
                0.7052756547927856,
                0.7715855836868286,
                0.6894262433052063,
                0.7664798498153687,
                0.7777769565582275,
                0.8220295310020447,
                0.731364369392395,
                0.7706731557846069,
                0.8292049169540405,
                0.8082323670387268,
                0.7798081040382385,
                0.708873450756073,
                0.7474404573440552,
                0.7789952754974365,
                0.7901732325553894,
                0.7839981913566589,
                0.8236940503120422,
                0.8071529865264893,
                0.7281574010848999,
                0.7915468811988831,
                0.78333580493927,
                0.7852002382278442,
                0.8172917366027832,
                0.7547158598899841,
                0.7680650949478149,
                0.8024119138717651,
                0.7485101819038391,
                0.6913987994194031,
                0.8066882491111755,
                0.6381658315658569,
                0.7732122540473938,
                0.7166181802749634,
                0.7536897659301758,
                0.7777550220489502,
                0.7865374088287354,
                0.7347962260246277,
                0.7317716479301453,
                0.796281099319458,
                0.7357535362243652,
                0.7958992123603821,
                0.7365592122077942,
                0.7771638631820679,
                0.7627457976341248
            ],
            [
                0.7507210373878479,
                0.7395802736282349,
                0.815574049949646,
                0.8453875184059143,
                0.8018916249275208,
                0.7911291718482971,
                0.7699308395385742,
                0.6975372433662415,
                0.7312688827514648,
                0.7727585434913635,
                0.698894202709198,
                0.8440444469451904,
                0.8585298657417297,
                0.8952631950378418,
                0.721307098865509,
                0.7494487166404724,
                0.834866464138031,
                0.8684511780738831,
                0.8663526773452759,
                0.7279061675071716,
                0.798708975315094,
                0.84822678565979,
                0.8635128140449524,
                0.8328629732131958,
                0.8604211807250977,
                0.8989661335945129,
                0.7369159460067749,
                0.8188287019729614,
                0.8553087115287781,
                0.8831810355186462,
                0.8893016576766968,
                0.7987462878227234,
                0.8075547814369202,
                0.8429440259933472,
                0.7728423476219177,
                0.7245280742645264,
                0.838985800743103,
                0.6073803901672363,
                0.8493385314941406,
                0.7561962604522705,
                0.8392736315727234,
                0.8398385047912598,
                0.8307587504386902,
                0.7338957786560059,
                0.7178249955177307,
                0.8381159901618958,
                0.7250860929489136,
                0.8506183624267578,
                0.8269347548484802,
                0.8484054207801819,
                0.8552090525627136
            ],
            [
                0.7891522645950317,
                0.6942978501319885,
                0.7712075710296631,
                0.8162603378295898,
                0.8376299142837524,
                0.7848327159881592,
                0.7640202641487122,
                0.7426968216896057,
                0.7355272173881531,
                0.7532646059989929,
                0.669219434261322,
                0.789212703704834,
                0.7665907144546509,
                0.7998058199882507,
                0.7536286115646362,
                0.7361719608306885,
                0.8039519190788269,
                0.8011354207992554,
                0.7536696791648865,
                0.7740238904953003,
                0.8051097393035889,
                0.8105689287185669,
                0.7907313704490662,
                0.8120731115341187,
                0.8398223519325256,
                0.8211403489112854,
                0.7483499050140381,
                0.7781063914299011,
                0.7998979687690735,
                0.7717136740684509,
                0.8087952733039856,
                0.7821864485740662,
                0.779404878616333,
                0.8096855282783508,
                0.7500120997428894,
                0.6719095706939697,
                0.8131100535392761,
                0.6308135986328125,
                0.7747083306312561,
                0.7495260834693909,
                0.7649739980697632,
                0.7544301152229309,
                0.8334351778030396,
                0.6799713373184204,
                0.7418617606163025,
                0.8213117122650146,
                0.7337332963943481,
                0.8404327630996704,
                0.7485548853874207,
                0.7816395163536072,
                0.7751662135124207
            ],
            [
                0.7569729089736938,
                0.749147891998291,
                0.8383317589759827,
                0.8770010471343994,
                0.8155943155288696,
                0.8128566145896912,
                0.7768080234527588,
                0.6987422704696655,
                0.7515304088592529,
                0.770456850528717,
                0.6969530582427979,
                0.8677285313606262,
                0.8623695969581604,
                0.9107212424278259,
                0.7381501197814941,
                0.7419882416725159,
                0.823814868927002,
                0.8738408088684082,
                0.8597467541694641,
                0.769965410232544,
                0.8113219738006592,
                0.875471293926239,
                0.8770912289619446,
                0.8304722309112549,
                0.857147216796875,
                0.9193291068077087,
                0.7477433681488037,
                0.8208454251289368,
                0.8726093173027039,
                0.8835391402244568,
                0.8986830115318298,
                0.8258490562438965,
                0.8373247385025024,
                0.83260577917099,
                0.7947440147399902,
                0.7389916777610779,
                0.8439406752586365,
                0.6127815842628479,
                0.8587709069252014,
                0.7779152393341064,
                0.8581231236457825,
                0.8258244395256042,
                0.8492652773857117,
                0.7152869701385498,
                0.733802080154419,
                0.8372935056686401,
                0.7247805595397949,
                0.8630321025848389,
                0.8224665522575378,
                0.8585665822029114,
                0.8749334216117859
            ],
            [
                0.7542367577552795,
                0.6744161248207092,
                0.7505947351455688,
                0.7851536870002747,
                0.8026174306869507,
                0.7397003173828125,
                0.7278508543968201,
                0.712781548500061,
                0.6978654861450195,
                0.766566276550293,
                0.6653502583503723,
                0.7542497515678406,
                0.7554991841316223,
                0.7882819175720215,
                0.7170385718345642,
                0.7216001152992249,
                0.8033508062362671,
                0.7781262993812561,
                0.7367343902587891,
                0.7187817096710205,
                0.7615694999694824,
                0.7740186452865601,
                0.763582706451416,
                0.7792719006538391,
                0.8083962202072144,
                0.7728648781776428,
                0.7200981378555298,
                0.7881825566291809,
                0.7671058177947998,
                0.7419833540916443,
                0.7851283550262451,
                0.7481253743171692,
                0.74614018201828,
                0.780828058719635,
                0.724847137928009,
                0.6661276817321777,
                0.7903711795806885,
                0.6321311593055725,
                0.7574719190597534,
                0.7142333388328552,
                0.7349039316177368,
                0.7524468898773193,
                0.7919908165931702,
                0.6824939846992493,
                0.7415401339530945,
                0.794847309589386,
                0.7565386891365051,
                0.8110972046852112,
                0.7263244390487671,
                0.7759525179862976,
                0.7559365034103394
            ],
            [
                0.7518870234489441,
                0.731982946395874,
                0.8387362957000732,
                0.8288129568099976,
                0.7841032147407532,
                0.7923571467399597,
                0.7721328735351562,
                0.6844300627708435,
                0.711490273475647,
                0.8032252788543701,
                0.7091776132583618,
                0.8177459836006165,
                0.8591043949127197,
                0.8571904897689819,
                0.7110370397567749,
                0.7261701822280884,
                0.8173766136169434,
                0.8349699974060059,
                0.8531292080879211,
                0.7233867049217224,
                0.7864360809326172,
                0.8320388793945312,
                0.8695505857467651,
                0.810349702835083,
                0.8390778303146362,
                0.8643385767936707,
                0.7274038195610046,
                0.824805498123169,
                0.821958065032959,
                0.8348073959350586,
                0.8694849014282227,
                0.7904727458953857,
                0.8059691190719604,
                0.8173630833625793,
                0.7774502635002136,
                0.7245999574661255,
                0.8258302807807922,
                0.6280347108840942,
                0.8233789205551147,
                0.7434447407722473,
                0.8081809878349304,
                0.8311744928359985,
                0.825630247592926,
                0.7096928954124451,
                0.7285927534103394,
                0.822765052318573,
                0.7795805335044861,
                0.8474009037017822,
                0.8278619647026062,
                0.8452125191688538,
                0.8802233338356018
            ],
            [
                0.7810168266296387,
                0.6759917140007019,
                0.7665227651596069,
                0.8067466020584106,
                0.7766753435134888,
                0.8520920872688293,
                0.8525453805923462,
                0.7762145400047302,
                0.8156766295433044,
                0.760526180267334,
                0.6804296970367432,
                0.8566313982009888,
                0.776554524898529,
                0.817453920841217,
                0.7483503222465515,
                0.7889183759689331,
                0.8491080403327942,
                0.8638219833374023,
                0.7718390822410583,
                0.80747389793396,
                0.9083018898963928,
                0.8705786466598511,
                0.7808116674423218,
                0.9178348779678345,
                0.8936471939086914,
                0.8129650950431824,
                0.7831807732582092,
                0.8012869358062744,
                0.8341071009635925,
                0.7538719773292542,
                0.8255519866943359,
                0.8674326539039612,
                0.8244929313659668,
                0.9128755331039429,
                0.7406347393989563,
                0.6871927380561829,
                0.8755913972854614,
                0.6524601578712463,
                0.8378298878669739,
                0.8514399528503418,
                0.8239661455154419,
                0.768239438533783,
                0.8884991407394409,
                0.6328027844429016,
                0.8104562163352966,
                0.920833945274353,
                0.7234629988670349,
                0.9214311242103577,
                0.7213397026062012,
                0.8208838701248169,
                0.7790930271148682
            ],
            [
                0.7758414149284363,
                0.7264383435249329,
                0.8240071535110474,
                0.8215671181678772,
                0.7999459505081177,
                0.7794216275215149,
                0.7584198713302612,
                0.7457420825958252,
                0.7555795907974243,
                0.8051532506942749,
                0.7087142467498779,
                0.7983824610710144,
                0.8501588106155396,
                0.8319189548492432,
                0.7687817811965942,
                0.7533156871795654,
                0.835699200630188,
                0.8225285410881042,
                0.8369007110595703,
                0.7386177182197571,
                0.8000614047050476,
                0.821086585521698,
                0.8284933567047119,
                0.8211315274238586,
                0.8488943576812744,
                0.8463232517242432,
                0.7508947253227234,
                0.8228670358657837,
                0.8058764934539795,
                0.8063223958015442,
                0.8696470856666565,
                0.7941509485244751,
                0.8065286874771118,
                0.8372912406921387,
                0.7827582955360413,
                0.7089337706565857,
                0.8634999394416809,
                0.6693816184997559,
                0.8160147070884705,
                0.7740424871444702,
                0.788497269153595,
                0.824236273765564,
                0.8295654058456421,
                0.6966978311538696,
                0.7458043694496155,
                0.8274094462394714,
                0.7586132884025574,
                0.8517829775810242,
                0.7515162229537964,
                0.801158607006073,
                0.830787181854248
            ],
            [
                0.7661013603210449,
                0.708847165107727,
                0.7737200260162354,
                0.8098925352096558,
                0.762188196182251,
                0.7961387038230896,
                0.7832942605018616,
                0.7451761960983276,
                0.767471969127655,
                0.7899861335754395,
                0.6860654354095459,
                0.7824099659919739,
                0.789858877658844,
                0.7903696298599243,
                0.7730379700660706,
                0.7661161422729492,
                0.8091087937355042,
                0.7968704700469971,
                0.7811842560768127,
                0.7752019762992859,
                0.8306240439414978,
                0.8050913214683533,
                0.7797563672065735,
                0.8379375338554382,
                0.8314961791038513,
                0.7951108813285828,
                0.7623277902603149,
                0.7784303426742554,
                0.7755388021469116,
                0.7490141987800598,
                0.820344865322113,
                0.803491473197937,
                0.8102045655250549,
                0.8571349382400513,
                0.7531458735466003,
                0.6804182529449463,
                0.8410929441452026,
                0.673961877822876,
                0.7751545310020447,
                0.797144889831543,
                0.7661827802658081,
                0.7720829248428345,
                0.8273147344589233,
                0.6361902952194214,
                0.7627406716346741,
                0.8396816849708557,
                0.7368968725204468,
                0.8530043363571167,
                0.7099113464355469,
                0.7640947699546814,
                0.7796981334686279
            ],
            [
                0.7497256994247437,
                0.7686744928359985,
                0.8627222180366516,
                0.8703808188438416,
                0.8046034574508667,
                0.8182470798492432,
                0.8039618730545044,
                0.7228043079376221,
                0.78046715259552,
                0.8292497396469116,
                0.7102645039558411,
                0.8551034927368164,
                0.8963726162910461,
                0.9001806378364563,
                0.7680051922798157,
                0.7689875960350037,
                0.8274338841438293,
                0.8631137609481812,
                0.8802760243415833,
                0.7830369472503662,
                0.8355343341827393,
                0.8603794574737549,
                0.8773036003112793,
                0.8508452773094177,
                0.8563066720962524,
                0.8994191288948059,
                0.7577071785926819,
                0.807783842086792,
                0.8482793569564819,
                0.8383138179779053,
                0.9079679250717163,
                0.8382472991943359,
                0.8616066575050354,
                0.8660539388656616,
                0.821307897567749,
                0.7313249707221985,
                0.8645381927490234,
                0.6379085183143616,
                0.8450388312339783,
                0.8115524053573608,
                0.8438419699668884,
                0.8387109041213989,
                0.8524673581123352,
                0.7020367383956909,
                0.7576832175254822,
                0.8536103963851929,
                0.7570074200630188,
                0.8728847503662109,
                0.7811706066131592,
                0.8389960527420044,
                0.8721697926521301
            ],
            [
                0.7172060012817383,
                0.6722735166549683,
                0.7343533039093018,
                0.8065030574798584,
                0.7523450255393982,
                0.8114970326423645,
                0.8342739343643188,
                0.8198870420455933,
                0.8441215753555298,
                0.7103538513183594,
                0.6961578726768494,
                0.836555004119873,
                0.7334440350532532,
                0.8111928701400757,
                0.7806709408760071,
                0.7891855239868164,
                0.8569362163543701,
                0.8453429341316223,
                0.732616126537323,
                0.8090071678161621,
                0.8685593008995056,
                0.8406642079353333,
                0.7155585289001465,
                0.8770792484283447,
                0.8682388067245483,
                0.7591661810874939,
                0.7687798142433167,
                0.7857118844985962,
                0.8005040287971497,
                0.6965625286102295,
                0.8045988082885742,
                0.8723693490028381,
                0.8195719718933105,
                0.8843631744384766,
                0.7390836477279663,
                0.6852904558181763,
                0.8833796381950378,
                0.65483558177948,
                0.8354734182357788,
                0.867221474647522,
                0.8093475103378296,
                0.7397236824035645,
                0.8679090738296509,
                0.6101214289665222,
                0.8108044862747192,
                0.8766186237335205,
                0.6855100989341736,
                0.8909972310066223,
                0.6455832123756409,
                0.7784366607666016,
                0.7228580117225647
            ],
            [
                0.7358508706092834,
                0.6948617696762085,
                0.7470858097076416,
                0.7987819910049438,
                0.747053325176239,
                0.8262529969215393,
                0.8379008769989014,
                0.8171289563179016,
                0.8630340099334717,
                0.7465553283691406,
                0.699512243270874,
                0.8255707621574402,
                0.7456545829772949,
                0.7981694340705872,
                0.7922260761260986,
                0.7956370115280151,
                0.8312951922416687,
                0.8286961913108826,
                0.7494950294494629,
                0.8334287405014038,
                0.869986891746521,
                0.825872004032135,
                0.7342312932014465,
                0.8701484799385071,
                0.8637425899505615,
                0.7791398763656616,
                0.7728636860847473,
                0.7621268033981323,
                0.7839305400848389,
                0.7046045660972595,
                0.8303775191307068,
                0.8890463709831238,
                0.8720794320106506,
                0.8953683376312256,
                0.7750113010406494,
                0.6907593011856079,
                0.886121392250061,
                0.6652506589889526,
                0.8019086718559265,
                0.8822765350341797,
                0.7905198931694031,
                0.7301977872848511,
                0.87301105260849,
                0.6081671118736267,
                0.819078266620636,
                0.8660274147987366,
                0.6999808549880981,
                0.8816584348678589,
                0.667772650718689,
                0.7530830502510071,
                0.732794463634491
            ],
            [
                0.7759745121002197,
                0.7833118438720703,
                0.8498954176902771,
                0.8599656820297241,
                0.789480447769165,
                0.8359599113464355,
                0.8258243799209595,
                0.7276241183280945,
                0.7839841842651367,
                0.8302146792411804,
                0.7660712599754333,
                0.8505997657775879,
                0.8507921695709229,
                0.8516879677772522,
                0.7905246019363403,
                0.813034176826477,
                0.8114134669303894,
                0.8492933511734009,
                0.8480565547943115,
                0.829132616519928,
                0.8455960750579834,
                0.8539918065071106,
                0.8661022782325745,
                0.8551369905471802,
                0.8503202199935913,
                0.8698456287384033,
                0.8040205240249634,
                0.7722805738449097,
                0.8330615162849426,
                0.7968795895576477,
                0.8947931528091431,
                0.8465749025344849,
                0.8795124292373657,
                0.8736260533332825,
                0.8182917237281799,
                0.7151318788528442,
                0.8591561317443848,
                0.7091387510299683,
                0.8149092197418213,
                0.825657308101654,
                0.8274906873703003,
                0.7967507839202881,
                0.8557829260826111,
                0.6625813245773315,
                0.8046510815620422,
                0.856529712677002,
                0.7909446954727173,
                0.8706881403923035,
                0.7587964534759521,
                0.8165467977523804,
                0.8573275208473206
            ],
            [
                0.7351757287979126,
                0.6735698580741882,
                0.7432217001914978,
                0.7944404482841492,
                0.7367973327636719,
                0.8028914332389832,
                0.8239270448684692,
                0.7907235622406006,
                0.8148240447044373,
                0.7338863611221313,
                0.7015290856361389,
                0.8354294300079346,
                0.7528871297836304,
                0.8048602938652039,
                0.7504512071609497,
                0.7720543742179871,
                0.8486251831054688,
                0.8472998738288879,
                0.7474309206008911,
                0.7824394106864929,
                0.85621178150177,
                0.8509514927864075,
                0.755273699760437,
                0.8673116564750671,
                0.8656201362609863,
                0.7719343900680542,
                0.7583621740341187,
                0.8077154755592346,
                0.8085732460021973,
                0.7200104594230652,
                0.8173966407775879,
                0.8503260612487793,
                0.810185432434082,
                0.8720697164535522,
                0.7258272171020508,
                0.679060697555542,
                0.8667747974395752,
                0.6799136996269226,
                0.8296903371810913,
                0.8442394137382507,
                0.8102533221244812,
                0.7611979842185974,
                0.8585482835769653,
                0.6094710826873779,
                0.7946659326553345,
                0.8703067302703857,
                0.7098304033279419,
                0.8885953426361084,
                0.6685505509376526,
                0.7953457236289978,
                0.7638216614723206
            ],
            [
                0.7662955522537231,
                0.6781001091003418,
                0.7345439791679382,
                0.7680745124816895,
                0.7336613535881042,
                0.784787654876709,
                0.7750110626220703,
                0.7610170841217041,
                0.7468981146812439,
                0.7355820536613464,
                0.6913011074066162,
                0.7679024934768677,
                0.7306727170944214,
                0.7473682165145874,
                0.755584180355072,
                0.7839589715003967,
                0.8127471208572388,
                0.7870261669158936,
                0.7197538614273071,
                0.768297553062439,
                0.8153136372566223,
                0.7913609147071838,
                0.7433966994285583,
                0.8263248205184937,
                0.8254468441009521,
                0.7463245391845703,
                0.7801118493080139,
                0.7691140174865723,
                0.7510794401168823,
                0.7001107931137085,
                0.7927767634391785,
                0.7890756130218506,
                0.7723166942596436,
                0.842207670211792,
                0.7211523056030273,
                0.6602528095245361,
                0.8372873067855835,
                0.708994448184967,
                0.7545316815376282,
                0.7867611646652222,
                0.7412782311439514,
                0.7432838678359985,
                0.8176447749137878,
                0.608572781085968,
                0.7768948078155518,
                0.8293384909629822,
                0.7254384756088257,
                0.8389014005661011,
                0.6525716781616211,
                0.7420245409011841,
                0.752834677696228
            ],
            [
                0.784735918045044,
                0.7860730290412903,
                0.8498731851577759,
                0.8802019953727722,
                0.8268206119537354,
                0.8471401929855347,
                0.8378303647041321,
                0.7553551197052002,
                0.8136101365089417,
                0.8143848180770874,
                0.7600911855697632,
                0.8658259510993958,
                0.8592144250869751,
                0.8763492703437805,
                0.8147127628326416,
                0.8147956728935242,
                0.8245311379432678,
                0.8629273772239685,
                0.8544323444366455,
                0.8457345962524414,
                0.8582937717437744,
                0.8669085502624512,
                0.870246946811676,
                0.8650389909744263,
                0.8651907444000244,
                0.8969096541404724,
                0.80867600440979,
                0.7757043838500977,
                0.8380479216575623,
                0.8212880492210388,
                0.9012464284896851,
                0.8636545538902283,
                0.8823134303092957,
                0.87691730260849,
                0.8112884163856506,
                0.7149884700775146,
                0.8735196590423584,
                0.694837749004364,
                0.8267530798912048,
                0.8420620560646057,
                0.8395800590515137,
                0.8018479943275452,
                0.8706245422363281,
                0.6800701022148132,
                0.806283175945282,
                0.8648167848587036,
                0.7792365550994873,
                0.8856795430183411,
                0.7688379883766174,
                0.8186060786247253,
                0.854331374168396
            ],
            [
                0.777896523475647,
                0.7170736789703369,
                0.7956158518791199,
                0.8348074555397034,
                0.8549553751945496,
                0.7755998373031616,
                0.7492008209228516,
                0.7397853136062622,
                0.7630078792572021,
                0.7703589797019958,
                0.6678742170333862,
                0.7933982014656067,
                0.7983993887901306,
                0.8311898708343506,
                0.7506928443908691,
                0.7209017276763916,
                0.7929385900497437,
                0.8056716322898865,
                0.7807930111885071,
                0.7390393018722534,
                0.7809702754020691,
                0.7939507961273193,
                0.8045915961265564,
                0.7875556349754333,
                0.8320139646530151,
                0.8473849296569824,
                0.7139427661895752,
                0.7754382491111755,
                0.7955162525177002,
                0.7978553175926208,
                0.8444361686706543,
                0.7826341986656189,
                0.8024949431419373,
                0.7961244583129883,
                0.7566782832145691,
                0.6674841046333313,
                0.8178653717041016,
                0.6028802990913391,
                0.7791971564292908,
                0.7497298717498779,
                0.7702120542526245,
                0.7695273160934448,
                0.8257914185523987,
                0.7039477825164795,
                0.7244504690170288,
                0.7951132655143738,
                0.7256181836128235,
                0.8328589200973511,
                0.7817876935005188,
                0.7769324779510498,
                0.7846139073371887
            ],
            [
                0.7570667266845703,
                0.7684308886528015,
                0.8531272411346436,
                0.8522052764892578,
                0.8164270520210266,
                0.7774604558944702,
                0.7619027495384216,
                0.7027615308761597,
                0.7278468012809753,
                0.8073746562004089,
                0.7381633520126343,
                0.8299962878227234,
                0.8873703479766846,
                0.8750391602516174,
                0.7311864495277405,
                0.7444665431976318,
                0.8184489607810974,
                0.8436989784240723,
                0.8786969184875488,
                0.7353009581565857,
                0.7761126756668091,
                0.8430287837982178,
                0.881076455116272,
                0.8023456335067749,
                0.8380655646324158,
                0.8952746391296387,
                0.7510281205177307,
                0.8275275826454163,
                0.8433359265327454,
                0.8767164945602417,
                0.899863600730896,
                0.7803699970245361,
                0.8055213093757629,
                0.8129377961158752,
                0.7891378998756409,
                0.7213646173477173,
                0.8339201211929321,
                0.6422650814056396,
                0.8328412771224976,
                0.7538787126541138,
                0.8276760578155518,
                0.8766690492630005,
                0.8206218481063843,
                0.7263368368148804,
                0.7286787033081055,
                0.8098347783088684,
                0.7889142036437988,
                0.8411946296691895,
                0.81438809633255,
                0.8466999530792236,
                0.8834425210952759
            ],
            [
                0.7761805057525635,
                0.6887799501419067,
                0.7484816908836365,
                0.797881007194519,
                0.8239586353302002,
                0.7424386143684387,
                0.7277055978775024,
                0.7231332063674927,
                0.7084331512451172,
                0.7528534531593323,
                0.6703354716300964,
                0.7558901906013489,
                0.747584342956543,
                0.7948414087295532,
                0.7371418476104736,
                0.7350060939788818,
                0.7896378636360168,
                0.774568498134613,
                0.7345734238624573,
                0.7407215237617493,
                0.7669810652732849,
                0.7729881405830383,
                0.7563610672950745,
                0.7788787484169006,
                0.8111593127250671,
                0.7895626425743103,
                0.7379340529441833,
                0.7635394334793091,
                0.767457127571106,
                0.750948429107666,
                0.7899529933929443,
                0.7545056939125061,
                0.7638775110244751,
                0.7823296189308167,
                0.7309508323669434,
                0.6647458672523499,
                0.788879930973053,
                0.6346378326416016,
                0.7537593245506287,
                0.7188900709152222,
                0.7403773665428162,
                0.7453972101211548,
                0.7926790714263916,
                0.6835117340087891,
                0.7395937442779541,
                0.7896550297737122,
                0.7314861416816711,
                0.8105400204658508,
                0.7435645461082458,
                0.7581241726875305,
                0.747599184513092
            ],
            [
                0.7151454091072083,
                0.7788920998573303,
                0.8842300772666931,
                0.8875281810760498,
                0.8090161085128784,
                0.7657445669174194,
                0.7457172274589539,
                0.6714407801628113,
                0.7195043563842773,
                0.7917189598083496,
                0.7016832232475281,
                0.8437977433204651,
                0.9137989282608032,
                0.9226203560829163,
                0.7168954014778137,
                0.6888011693954468,
                0.7937622666358948,
                0.8556458950042725,
                0.8968245387077332,
                0.6950380802154541,
                0.7587510943412781,
                0.8544657826423645,
                0.8879839181900024,
                0.7841951251029968,
                0.8272719979286194,
                0.9112530946731567,
                0.6864531636238098,
                0.8351641297340393,
                0.8658409714698792,
                0.8771425485610962,
                0.9235068559646606,
                0.7799541354179382,
                0.816584587097168,
                0.7959396243095398,
                0.8108463883399963,
                0.7430983781814575,
                0.8197115063667297,
                0.5716233849525452,
                0.862587571144104,
                0.7265706062316895,
                0.8541279435157776,
                0.8640838861465454,
                0.8118574619293213,
                0.7139937281608582,
                0.6693130731582642,
                0.7930111885070801,
                0.7299551367759705,
                0.826759934425354,
                0.8039381504058838,
                0.8625110387802124,
                0.8815784454345703
            ],
            [
                0.6795580983161926,
                0.7112412452697754,
                0.799125611782074,
                0.8682129979133606,
                0.7477053999900818,
                0.8236827850341797,
                0.8149886131286621,
                0.6854844689369202,
                0.7548259496688843,
                0.7113680243492126,
                0.6645795702934265,
                0.9291278123855591,
                0.7805313467979431,
                0.9093675017356873,
                0.6833915114402771,
                0.7210277915000916,
                0.805092990398407,
                0.9249252080917358,
                0.7884664535522461,
                0.7594934105873108,
                0.8520179986953735,
                0.9395928382873535,
                0.7971720099449158,
                0.8634846210479736,
                0.8677259683609009,
                0.8298113942146301,
                0.7018852829933167,
                0.8338228464126587,
                0.9365887641906738,
                0.7676973342895508,
                0.8639965653419495,
                0.8622157573699951,
                0.8335492610931396,
                0.8515481948852539,
                0.7493565678596497,
                0.767428994178772,
                0.8142107129096985,
                0.5685926079750061,
                0.9196469783782959,
                0.7843645811080933,
                0.9364908337593079,
                0.7508928775787354,
                0.866087794303894,
                0.5974149107933044,
                0.7291879057884216,
                0.8690118789672852,
                0.6604325771331787,
                0.8908913135528564,
                0.6930788159370422,
                0.9214560389518738,
                0.7895249128341675
            ],
            [
                0.7115246057510376,
                0.7040104269981384,
                0.7146123647689819,
                0.8126781582832336,
                0.7639360427856445,
                0.817291259765625,
                0.8588374257087708,
                0.7510260343551636,
                0.7733883857727051,
                0.7040129899978638,
                0.7375452518463135,
                0.8430274128913879,
                0.7284097671508789,
                0.7944527268409729,
                0.7569047808647156,
                0.8222814798355103,
                0.7968679070472717,
                0.8291029334068298,
                0.7240074276924133,
                0.8643046617507935,
                0.8363949656486511,
                0.8422629833221436,
                0.7440219521522522,
                0.8376582860946655,
                0.8369122743606567,
                0.7627612352371216,
                0.8109360933303833,
                0.7399360537528992,
                0.8103356957435608,
                0.7197736501693726,
                0.7899635434150696,
                0.8509605526924133,
                0.8047226667404175,
                0.8482619524002075,
                0.7388008832931519,
                0.6770791411399841,
                0.8315565586090088,
                0.6899399757385254,
                0.7994142770767212,
                0.8235529661178589,
                0.8163335919380188,
                0.7308140397071838,
                0.849057674407959,
                0.6129943132400513,
                0.8189804553985596,
                0.8353577256202698,
                0.750386118888855,
                0.8634951114654541,
                0.699356198310852,
                0.7972781658172607,
                0.7521005272865295
            ],
            [
                0.7527686357498169,
                0.6806530952453613,
                0.7655885219573975,
                0.7952826619148254,
                0.8032283782958984,
                0.7650941610336304,
                0.7577695846557617,
                0.7234336137771606,
                0.7261970639228821,
                0.7579315900802612,
                0.6624006628990173,
                0.7890722155570984,
                0.7730771899223328,
                0.8174473643302917,
                0.7346749305725098,
                0.7314623594284058,
                0.834679365158081,
                0.8216111063957214,
                0.743594229221344,
                0.7311179041862488,
                0.766828179359436,
                0.8078964948654175,
                0.7785381078720093,
                0.7834959030151367,
                0.850980818271637,
                0.7964099049568176,
                0.707807719707489,
                0.8250166177749634,
                0.7842820882797241,
                0.733255922794342,
                0.8268292546272278,
                0.7909576296806335,
                0.7918277978897095,
                0.7936678528785706,
                0.7541013956069946,
                0.7303180694580078,
                0.8271979093551636,
                0.6030488014221191,
                0.7943527698516846,
                0.7272526025772095,
                0.7755443453788757,
                0.734247624874115,
                0.8370599746704102,
                0.6701119542121887,
                0.7285962700843811,
                0.7958108186721802,
                0.7118953466415405,
                0.821929395198822,
                0.7247046828269958,
                0.7926190495491028,
                0.7694710493087769
            ],
            [
                0.686457633972168,
                0.7739200592041016,
                0.8622345924377441,
                0.8276548385620117,
                0.7829481959342957,
                0.7356134057044983,
                0.7116973996162415,
                0.6533706188201904,
                0.7110897898674011,
                0.7646315097808838,
                0.6289293169975281,
                0.7931604981422424,
                0.880512535572052,
                0.8907751441001892,
                0.6793697476387024,
                0.6512340307235718,
                0.7563384771347046,
                0.8064394593238831,
                0.8729947805404663,
                0.6599709987640381,
                0.7201539874076843,
                0.8002850413322449,
                0.8625617027282715,
                0.7340230941772461,
                0.7959173917770386,
                0.8940867185592651,
                0.6341118812561035,
                0.8013269901275635,
                0.808262288570404,
                0.855303168296814,
                0.8956058025360107,
                0.7576232552528381,
                0.8121852278709412,
                0.7531507015228271,
                0.8031431436538696,
                0.717136025428772,
                0.7940047979354858,
                0.5132346153259277,
                0.7990570068359375,
                0.6959391832351685,
                0.799788773059845,
                0.8220514059066772,
                0.7886983156204224,
                0.7333040833473206,
                0.6406409740447998,
                0.7404787540435791,
                0.6879197359085083,
                0.7914390563964844,
                0.7915914058685303,
                0.8009100556373596,
                0.8497673869132996
            ],
            [
                0.7329633235931396,
                0.6784325242042542,
                0.74344402551651,
                0.78412264585495,
                0.7735233902931213,
                0.7430881857872009,
                0.7394758462905884,
                0.725053071975708,
                0.7152276039123535,
                0.7225534915924072,
                0.6630925536155701,
                0.751794695854187,
                0.7546647787094116,
                0.7776864767074585,
                0.7355316281318665,
                0.7044315338134766,
                0.7902028560638428,
                0.7718375325202942,
                0.7280210852622986,
                0.703272819519043,
                0.7566398978233337,
                0.7731274962425232,
                0.7481608986854553,
                0.7731021642684937,
                0.8065062165260315,
                0.7588064670562744,
                0.7079124450683594,
                0.783618152141571,
                0.7549952864646912,
                0.7195370197296143,
                0.7896256446838379,
                0.7507010698318481,
                0.7324873208999634,
                0.779556155204773,
                0.717548668384552,
                0.6441958546638489,
                0.7993217706680298,
                0.6325663924217224,
                0.766174852848053,
                0.7279130220413208,
                0.7341942191123962,
                0.7455907464027405,
                0.7941693067550659,
                0.6415849924087524,
                0.7091425657272339,
                0.7827176451683044,
                0.7137490510940552,
                0.8047244548797607,
                0.6756047010421753,
                0.7507706880569458,
                0.754608154296875
            ],
            [
                0.6675627827644348,
                0.7391550540924072,
                0.8347424268722534,
                0.8305271863937378,
                0.7524763941764832,
                0.7455002069473267,
                0.7337450385093689,
                0.6426946520805359,
                0.7113049030303955,
                0.7375643253326416,
                0.6480023860931396,
                0.8434692025184631,
                0.8365863561630249,
                0.9166240692138672,
                0.6489545106887817,
                0.6640933752059937,
                0.7736870050430298,
                0.8491175770759583,
                0.8637732267379761,
                0.6713511347770691,
                0.750453531742096,
                0.8376051783561707,
                0.8720613718032837,
                0.7695636749267578,
                0.8028337359428406,
                0.902305006980896,
                0.6463832259178162,
                0.8180398344993591,
                0.8594957590103149,
                0.8491861820220947,
                0.9066494107246399,
                0.7883810997009277,
                0.8393484950065613,
                0.7785749435424805,
                0.7787711024284363,
                0.717538595199585,
                0.8021451234817505,
                0.530623197555542,
                0.8521530628204346,
                0.7241532206535339,
                0.8496462106704712,
                0.800717294216156,
                0.7913057208061218,
                0.6967644095420837,
                0.6659077405929565,
                0.777427077293396,
                0.6741899251937866,
                0.8135677576065063,
                0.8076596856117249,
                0.8445428013801575,
                0.8489442467689514
            ],
            [
                0.763001561164856,
                0.6871545314788818,
                0.7756580114364624,
                0.8137730956077576,
                0.8283196091651917,
                0.7420452237129211,
                0.7404905557632446,
                0.7385649085044861,
                0.7117413878440857,
                0.7648743391036987,
                0.6740017533302307,
                0.7690259218215942,
                0.7881647348403931,
                0.8133916258811951,
                0.7506632208824158,
                0.7189084887504578,
                0.8106698393821716,
                0.7978565096855164,
                0.766724705696106,
                0.723021388053894,
                0.7700889110565186,
                0.7905544638633728,
                0.777361273765564,
                0.7901569604873657,
                0.825594961643219,
                0.8037487268447876,
                0.7237433195114136,
                0.7961186170578003,
                0.7892022132873535,
                0.7571630477905273,
                0.8200806975364685,
                0.7561048865318298,
                0.761595606803894,
                0.8029322624206543,
                0.7485247850418091,
                0.6731230616569519,
                0.824918270111084,
                0.6104281544685364,
                0.797784686088562,
                0.726026713848114,
                0.7695419788360596,
                0.761624276638031,
                0.8094840049743652,
                0.6581630706787109,
                0.7079816460609436,
                0.7995904684066772,
                0.723703145980835,
                0.817680299282074,
                0.7274364233016968,
                0.7731980085372925,
                0.7671510577201843
            ],
            [
                0.7764808535575867,
                0.6692990660667419,
                0.7520505785942078,
                0.7777273654937744,
                0.7961243391036987,
                0.7689566612243652,
                0.7523733973503113,
                0.7679933309555054,
                0.7409706711769104,
                0.7497165203094482,
                0.6824928522109985,
                0.7449162006378174,
                0.7552947998046875,
                0.7448992729187012,
                0.7885047197341919,
                0.7160949110984802,
                0.8012951612472534,
                0.7623793482780457,
                0.7445462942123413,
                0.7345103621482849,
                0.7864475250244141,
                0.7632225155830383,
                0.7452260851860046,
                0.8005912899971008,
                0.8172454237937927,
                0.7604986429214478,
                0.7485155463218689,
                0.7644035220146179,
                0.7427419424057007,
                0.7292267084121704,
                0.7898640632629395,
                0.7568067312240601,
                0.7267531752586365,
                0.8082479238510132,
                0.7150317430496216,
                0.6227149367332458,
                0.8354223966598511,
                0.6625024080276489,
                0.761439859867096,
                0.7558693289756775,
                0.7252440452575684,
                0.7495267987251282,
                0.8065735697746277,
                0.6365556120872498,
                0.7148324251174927,
                0.8055427074432373,
                0.7174900770187378,
                0.8194609880447388,
                0.6895523071289062,
                0.7298234701156616,
                0.7381139993667603
            ],
            [
                0.662950336933136,
                0.7212526798248291,
                0.8002281188964844,
                0.7343312501907349,
                0.7043110132217407,
                0.6800773739814758,
                0.6641942262649536,
                0.6247891783714294,
                0.6267350912094116,
                0.7743018269538879,
                0.6693676710128784,
                0.7490166425704956,
                0.8522533774375916,
                0.8024913668632507,
                0.6391451358795166,
                0.6402556300163269,
                0.7782344818115234,
                0.7677180767059326,
                0.8696707487106323,
                0.6137852668762207,
                0.6740286350250244,
                0.7574220299720764,
                0.8483923673629761,
                0.7062333822250366,
                0.7605041861534119,
                0.8381653428077698,
                0.6734219789505005,
                0.828160285949707,
                0.7803813815116882,
                0.8607041239738464,
                0.8544560670852661,
                0.6940330862998962,
                0.7276123762130737,
                0.7218691110610962,
                0.7461151480674744,
                0.6918179988861084,
                0.7968589663505554,
                0.5545474886894226,
                0.7783718109130859,
                0.6704803109169006,
                0.7656309008598328,
                0.8918461799621582,
                0.7378496527671814,
                0.7201135158538818,
                0.6223511695861816,
                0.7138621807098389,
                0.7085585594177246,
                0.7482520937919617,
                0.8262544274330139,
                0.7752598524093628,
                0.8499994277954102
            ],
            [
                0.7026535272598267,
                0.7626428604125977,
                0.8530005812644958,
                0.8387306928634644,
                0.7710124254226685,
                0.7557175755500793,
                0.7592443227767944,
                0.6746265292167664,
                0.7205514311790466,
                0.773539125919342,
                0.6748676300048828,
                0.824837863445282,
                0.8802254796028137,
                0.8951981663703918,
                0.6950583457946777,
                0.683371901512146,
                0.7839034795761108,
                0.8328626155853271,
                0.8909289240837097,
                0.6941390037536621,
                0.7689647078514099,
                0.8269179463386536,
                0.890220046043396,
                0.7867284417152405,
                0.8154350519180298,
                0.9059309363365173,
                0.6811839938163757,
                0.8129441738128662,
                0.8339634537696838,
                0.8574262261390686,
                0.9199693202972412,
                0.7929428815841675,
                0.8496657609939575,
                0.805688202381134,
                0.8086065053939819,
                0.7170907855033875,
                0.8318064212799072,
                0.5656479597091675,
                0.8424320220947266,
                0.7438907623291016,
                0.8299604058265686,
                0.8222706913948059,
                0.8038172125816345,
                0.6985107064247131,
                0.6697800755500793,
                0.7927212715148926,
                0.701099157333374,
                0.8251881003379822,
                0.824694812297821,
                0.8218325972557068,
                0.878277599811554
            ],
            [
                0.7765242457389832,
                0.6791118383407593,
                0.7420984506607056,
                0.7937500476837158,
                0.7753433585166931,
                0.8110920190811157,
                0.823100209236145,
                0.8089461326599121,
                0.7991518378257751,
                0.7453382015228271,
                0.7262297868728638,
                0.7855310440063477,
                0.7415722012519836,
                0.7701855897903442,
                0.790945827960968,
                0.8101189136505127,
                0.8260520696640015,
                0.7961823344230652,
                0.7324634194374084,
                0.8215794563293457,
                0.8437262773513794,
                0.804002046585083,
                0.7398156523704529,
                0.8490012288093567,
                0.8459171652793884,
                0.7551138401031494,
                0.7974239587783813,
                0.7614521980285645,
                0.76344895362854,
                0.702885627746582,
                0.8036338686943054,
                0.8277723789215088,
                0.804398238658905,
                0.8545528650283813,
                0.7441768646240234,
                0.6600795984268188,
                0.8451760411262512,
                0.6842718124389648,
                0.7714347243309021,
                0.8326055407524109,
                0.758496105670929,
                0.7344632744789124,
                0.8479982614517212,
                0.6207456588745117,
                0.8165091276168823,
                0.8529813289642334,
                0.7320217490196228,
                0.8660651445388794,
                0.6730312705039978,
                0.7492847442626953,
                0.7390820980072021
            ],
            [
                0.7557855248451233,
                0.7901448607444763,
                0.881058394908905,
                0.9113742113113403,
                0.8306273818016052,
                0.8400706052780151,
                0.8152213096618652,
                0.7066778540611267,
                0.7775506377220154,
                0.8186064958572388,
                0.7213520407676697,
                0.8717931509017944,
                0.8895175457000732,
                0.9092488288879395,
                0.790641725063324,
                0.7733941674232483,
                0.8207041025161743,
                0.8767210245132446,
                0.865501344203949,
                0.8058153986930847,
                0.8345397710800171,
                0.8819776177406311,
                0.8800452947616577,
                0.8431620597839355,
                0.8598738312721252,
                0.9046914577484131,
                0.7691755890846252,
                0.8224970102310181,
                0.8700613975524902,
                0.8286880850791931,
                0.9222368597984314,
                0.8518810868263245,
                0.874325156211853,
                0.8522508144378662,
                0.8232643008232117,
                0.7577306032180786,
                0.8577030897140503,
                0.6382395625114441,
                0.8571596741676331,
                0.7948276996612549,
                0.864017128944397,
                0.8189857006072998,
                0.8656403422355652,
                0.6863943338394165,
                0.7587409019470215,
                0.8475865125656128,
                0.7641619443893433,
                0.8705010414123535,
                0.7638001441955566,
                0.8596049547195435,
                0.8654492497444153
            ],
            [
                0.7557626962661743,
                0.7029904127120972,
                0.7625913023948669,
                0.7754236459732056,
                0.7349459528923035,
                0.7509221434593201,
                0.75387042760849,
                0.7530398964881897,
                0.7306577563285828,
                0.7725648880004883,
                0.7039454579353333,
                0.7445449233055115,
                0.759192943572998,
                0.7450002431869507,
                0.7672358751296997,
                0.7668156623840332,
                0.792710542678833,
                0.7685492038726807,
                0.7563462853431702,
                0.7415299415588379,
                0.7860469222068787,
                0.7696509957313538,
                0.7560135722160339,
                0.7989331483840942,
                0.7982226610183716,
                0.757674515247345,
                0.7589249610900879,
                0.7594940662384033,
                0.7435793876647949,
                0.7212966680526733,
                0.7979936003684998,
                0.7555250525474548,
                0.7686357498168945,
                0.8234757781028748,
                0.7228047847747803,
                0.6629951000213623,
                0.8214117288589478,
                0.703457772731781,
                0.7466343641281128,
                0.7592631578445435,
                0.7309378981590271,
                0.7590878009796143,
                0.7858009338378906,
                0.6179311871528625,
                0.742886483669281,
                0.7996569275856018,
                0.7442632913589478,
                0.8148031234741211,
                0.6646878719329834,
                0.7363360524177551,
                0.7562697529792786
            ]
        ],
        [
            [
                0.7491700649261475,
                0.8489121198654175,
                0.7475489377975464,
                0.7201700210571289,
                0.7346293330192566,
                0.6881040930747986,
                0.7762019038200378,
                0.8427330851554871,
                0.7315988540649414,
                0.7582905292510986,
                0.7140461206436157,
                0.6917465925216675,
                0.7678672075271606,
                0.8107755184173584,
                0.6873710751533508,
                0.7124655842781067,
                0.791412353515625,
                0.7035452127456665,
                0.5990200638771057,
                0.574349582195282,
                0.7324962615966797,
                0.7107576727867126,
                0.7559971809387207,
                0.8211153745651245,
                0.5698593854904175,
                0.7443628311157227,
                0.83748859167099,
                0.5399113893508911,
                0.7478228807449341,
                0.7770674228668213,
                0.48692476749420166,
                0.7253814935684204,
                0.8279198408126831,
                0.7556307911872864,
                0.7749882340431213,
                0.47747477889060974,
                0.6979516744613647,
                0.7152099609375,
                0.8218140006065369,
                0.7251676321029663,
                0.8273109793663025,
                0.7491309642791748,
                0.7232761383056641,
                0.6743130087852478,
                0.6242653131484985,
                0.7311496734619141,
                0.6987999677658081,
                0.8396918773651123,
                0.5331493020057678,
                0.7456271052360535,
                0.7350782752037048
            ],
            [
                0.8865314722061157,
                0.7598326802253723,
                0.7767996191978455,
                0.7727582454681396,
                0.7973595857620239,
                0.7367032766342163,
                0.8494735956192017,
                0.7656609416007996,
                0.7255809307098389,
                0.6853246688842773,
                0.7239091396331787,
                0.7320871949195862,
                0.7421360015869141,
                0.6733058094978333,
                0.7061347365379333,
                0.7057809829711914,
                0.7171553373336792,
                0.7044481039047241,
                0.6041855216026306,
                0.5426549911499023,
                0.7095771431922913,
                0.7649484872817993,
                0.7720198631286621,
                0.699171245098114,
                0.6144729256629944,
                0.764864444732666,
                0.753040075302124,
                0.5736745595932007,
                0.7657307982444763,
                0.7580758929252625,
                0.5464996099472046,
                0.7282465100288391,
                0.7318651080131531,
                0.8553394675254822,
                0.6736693382263184,
                0.5248224139213562,
                0.706186830997467,
                0.7481567859649658,
                0.6587468385696411,
                0.7749552130699158,
                0.6614641547203064,
                0.7455645799636841,
                0.7790040969848633,
                0.556736946105957,
                0.7169560790061951,
                0.7531471848487854,
                0.7288779020309448,
                0.6913127899169922,
                0.5776374340057373,
                0.7664569616317749,
                0.7607067823410034
            ],
            [
                0.8029587268829346,
                0.8812866806983948,
                0.809476912021637,
                0.7373777627944946,
                0.7913292646408081,
                0.7106550931930542,
                0.846687376499176,
                0.8641149401664734,
                0.7818797826766968,
                0.801784873008728,
                0.7552922368049622,
                0.7337796688079834,
                0.7878458499908447,
                0.7829933762550354,
                0.6867303252220154,
                0.7294259071350098,
                0.8215379118919373,
                0.7374008893966675,
                0.6279313564300537,
                0.5933603048324585,
                0.7548776865005493,
                0.7296950221061707,
                0.8248361349105835,
                0.8109140396118164,
                0.6065347194671631,
                0.7898889780044556,
                0.8603845834732056,
                0.5625365972518921,
                0.7892345786094666,
                0.8283514976501465,
                0.5284332633018494,
                0.7824038863182068,
                0.8519421219825745,
                0.8266790509223938,
                0.7841604948043823,
                0.5219272375106812,
                0.7269302606582642,
                0.779949963092804,
                0.7907202839851379,
                0.7900000214576721,
                0.7789537906646729,
                0.7814236283302307,
                0.7858800292015076,
                0.6329588890075684,
                0.6760537624359131,
                0.7887868881225586,
                0.7508785128593445,
                0.8943542242050171,
                0.5624196529388428,
                0.796049952507019,
                0.7957961559295654
            ],
            [
                0.8635528683662415,
                0.8460814356803894,
                0.9741593599319458,
                0.747717022895813,
                0.8521980047225952,
                0.6814033389091492,
                0.9040101766586304,
                0.8309562802314758,
                0.7879812717437744,
                0.7072526216506958,
                0.784843385219574,
                0.6833655834197998,
                0.8330011963844299,
                0.7416670918464661,
                0.6998356580734253,
                0.8037775754928589,
                0.8057723641395569,
                0.7466949820518494,
                0.5671497583389282,
                0.595277726650238,
                0.7930787801742554,
                0.7292183041572571,
                0.8484932780265808,
                0.7422165870666504,
                0.6117713451385498,
                0.8487816452980042,
                0.7757306694984436,
                0.5552358031272888,
                0.8483948707580566,
                0.7555423378944397,
                0.5008640885353088,
                0.8167230486869812,
                0.7600946426391602,
                0.8683714270591736,
                0.7000375986099243,
                0.49095824360847473,
                0.7589988708496094,
                0.8091921806335449,
                0.6950929760932922,
                0.84086012840271,
                0.7137205600738525,
                0.8182979822158813,
                0.8366507887840271,
                0.6308401226997375,
                0.6681826710700989,
                0.8077934384346008,
                0.7327786684036255,
                0.7231056690216064,
                0.5648150444030762,
                0.8489704728126526,
                0.8431088328361511
            ],
            [
                0.7885002493858337,
                0.8072478175163269,
                0.8444814682006836,
                0.8416362404823303,
                0.9109780192375183,
                0.7425980567932129,
                0.8807185888290405,
                0.7910484671592712,
                0.8645288348197937,
                0.666534423828125,
                0.8862089514732361,
                0.7270605564117432,
                0.913590133190155,
                0.7697688937187195,
                0.8601776957511902,
                0.9032085537910461,
                0.836073637008667,
                0.8008580803871155,
                0.6325823664665222,
                0.6439037919044495,
                0.8399653434753418,
                0.8026589751243591,
                0.8746514320373535,
                0.7002381086349487,
                0.7323483228683472,
                0.9222314953804016,
                0.7261022329330444,
                0.6734119057655334,
                0.9212934970855713,
                0.7076312899589539,
                0.6355531811714172,
                0.8807110786437988,
                0.6835255026817322,
                0.8846865892410278,
                0.6681715250015259,
                0.6226664781570435,
                0.839153528213501,
                0.8870890140533447,
                0.6842573881149292,
                0.9032027125358582,
                0.6838342547416687,
                0.8824614882469177,
                0.904982328414917,
                0.6287043690681458,
                0.777737557888031,
                0.8622143864631653,
                0.7943574786186218,
                0.6776171922683716,
                0.6876946687698364,
                0.91522616147995,
                0.8982969522476196
            ],
            [
                0.835926353931427,
                0.8222049474716187,
                0.8350695371627808,
                0.834906816482544,
                0.9580301642417908,
                0.7169341444969177,
                0.8835011124610901,
                0.8035860061645508,
                0.8436175584793091,
                0.7164198160171509,
                0.85923171043396,
                0.7513241171836853,
                0.8806775808334351,
                0.7677151560783386,
                0.7781712412834167,
                0.8438717126846313,
                0.8306078314781189,
                0.8335951566696167,
                0.6958572268486023,
                0.6663182973861694,
                0.8183832764625549,
                0.7723826169967651,
                0.8845272064208984,
                0.7211587429046631,
                0.6589431166648865,
                0.8790788054466248,
                0.768911600112915,
                0.5985163450241089,
                0.8768783211708069,
                0.7514453530311584,
                0.5712437629699707,
                0.8529331684112549,
                0.7424224615097046,
                0.915375828742981,
                0.6933752298355103,
                0.5586891174316406,
                0.8300192952156067,
                0.8812907338142395,
                0.6966257691383362,
                0.8920267820358276,
                0.6999150514602661,
                0.8558130860328674,
                0.8960111141204834,
                0.5962923169136047,
                0.7232866883277893,
                0.8626629710197449,
                0.7986136674880981,
                0.7251754403114319,
                0.6089054942131042,
                0.8789797425270081,
                0.867121160030365
            ],
            [
                0.7662398219108582,
                0.8656656742095947,
                0.729817271232605,
                0.727778434753418,
                0.7492865920066833,
                0.7357872724533081,
                0.7719445824623108,
                0.817068874835968,
                0.7649327516555786,
                0.7953690886497498,
                0.7442599534988403,
                0.7914382219314575,
                0.7816752791404724,
                0.7999569773674011,
                0.7147699594497681,
                0.7222840785980225,
                0.865341305732727,
                0.7437037229537964,
                0.6720737814903259,
                0.6623642444610596,
                0.7438452839851379,
                0.7117839455604553,
                0.7703282237052917,
                0.8333250284194946,
                0.5953598022460938,
                0.7582616806030273,
                0.8494907021522522,
                0.5575810670852661,
                0.7563638687133789,
                0.8038480877876282,
                0.5466668009757996,
                0.7513822317123413,
                0.818803608417511,
                0.746487557888031,
                0.7748188376426697,
                0.5453583002090454,
                0.7009710669517517,
                0.736178457736969,
                0.8286857008934021,
                0.7362285256385803,
                0.7668710350990295,
                0.7455892562866211,
                0.7357785701751709,
                0.6536020040512085,
                0.6635658144950867,
                0.7705972790718079,
                0.736112117767334,
                0.834745466709137,
                0.5602312088012695,
                0.7610299587249756,
                0.7594724297523499
            ],
            [
                0.80221027135849,
                0.8177829384803772,
                0.825406014919281,
                0.8608080744743347,
                0.8840159177780151,
                0.7391347885131836,
                0.8872616291046143,
                0.8677735924720764,
                0.8197281360626221,
                0.7251439094543457,
                0.85520339012146,
                0.715884268283844,
                0.9103115797042847,
                0.8646227121353149,
                0.8343666791915894,
                0.8829737305641174,
                0.8405501246452332,
                0.7718418836593628,
                0.6333038210868835,
                0.6063762307167053,
                0.8308258056640625,
                0.8221638798713684,
                0.8550923466682434,
                0.8006693720817566,
                0.6719248294830322,
                0.8843685984611511,
                0.7983631491661072,
                0.6062528491020203,
                0.8817771077156067,
                0.7619882822036743,
                0.5746314525604248,
                0.8293073177337646,
                0.7715745568275452,
                0.8641220331192017,
                0.7542372345924377,
                0.5579126477241516,
                0.8503058552742004,
                0.880337119102478,
                0.7762460708618164,
                0.8627798557281494,
                0.7904157638549805,
                0.8997651934623718,
                0.8731529712677002,
                0.7042509913444519,
                0.7480252981185913,
                0.8803286552429199,
                0.7739938497543335,
                0.739307165145874,
                0.6136656403541565,
                0.8770570158958435,
                0.8630445003509521
            ],
            [
                0.7867950201034546,
                0.8203843235969543,
                0.8379815816879272,
                0.8520951271057129,
                0.8965608477592468,
                0.7397762537002563,
                0.8789393305778503,
                0.8586884140968323,
                0.88254714012146,
                0.7445692420005798,
                0.9175324440002441,
                0.7467218637466431,
                0.9620489478111267,
                0.8682171106338501,
                0.8627558350563049,
                0.9119060039520264,
                0.9170218706130981,
                0.8203599452972412,
                0.6736153364181519,
                0.6743525862693787,
                0.8472251296043396,
                0.7967268228530884,
                0.9042598605155945,
                0.7671617865562439,
                0.6643592119216919,
                0.9298801422119141,
                0.790158212184906,
                0.5926120281219482,
                0.925356924533844,
                0.7780342102050781,
                0.5546225309371948,
                0.885803759098053,
                0.7501952052116394,
                0.8761707544326782,
                0.7598857879638672,
                0.561838686466217,
                0.8760380148887634,
                0.9170488119125366,
                0.7668153643608093,
                0.914324939250946,
                0.7715646624565125,
                0.9137807488441467,
                0.9199724197387695,
                0.69451904296875,
                0.7259613275527954,
                0.8944108486175537,
                0.8111242055892944,
                0.7354532480239868,
                0.6076465249061584,
                0.9213733673095703,
                0.9039540886878967
            ],
            [
                0.776448667049408,
                0.7790563702583313,
                0.7872099280357361,
                0.7807288765907288,
                0.8322495222091675,
                0.6896942257881165,
                0.8697164058685303,
                0.8227725625038147,
                0.8061720728874207,
                0.6967437267303467,
                0.8094557523727417,
                0.6863846182823181,
                0.8429258465766907,
                0.7742757797241211,
                0.7625370621681213,
                0.8081697225570679,
                0.8290242552757263,
                0.7587913870811462,
                0.6406251192092896,
                0.5816006660461426,
                0.7959250211715698,
                0.7608538269996643,
                0.8648083806037903,
                0.7486769556999207,
                0.6147658228874207,
                0.8535855412483215,
                0.7715874910354614,
                0.5647510290145874,
                0.8564247488975525,
                0.7441818118095398,
                0.543016791343689,
                0.80806964635849,
                0.7552486062049866,
                0.876901388168335,
                0.7268475890159607,
                0.5243988633155823,
                0.8301900029182434,
                0.8819824457168579,
                0.7295820116996765,
                0.8772562146186829,
                0.7020144462585449,
                0.8415599465370178,
                0.8865025043487549,
                0.6364796161651611,
                0.7024815082550049,
                0.8476060032844543,
                0.799869179725647,
                0.7230059504508972,
                0.5551772117614746,
                0.8513883352279663,
                0.852961540222168
            ],
            [
                0.8993484377861023,
                0.8782898187637329,
                0.8208016157150269,
                0.7545526027679443,
                0.8253947496414185,
                0.7260141372680664,
                0.8744284510612488,
                0.8274224996566772,
                0.7846006751060486,
                0.7915644645690918,
                0.7651359438896179,
                0.7510579824447632,
                0.786376416683197,
                0.7174531817436218,
                0.6968076825141907,
                0.7373772859573364,
                0.8225824236869812,
                0.7739182710647583,
                0.6552201509475708,
                0.6012203693389893,
                0.7611340284347534,
                0.7370689511299133,
                0.8453875184059143,
                0.7808946967124939,
                0.6432893872261047,
                0.8145157694816589,
                0.8504648208618164,
                0.5925527811050415,
                0.8101533651351929,
                0.8276965022087097,
                0.5890936851501465,
                0.7872077226638794,
                0.8342186808586121,
                0.8683860301971436,
                0.7412191033363342,
                0.5804846286773682,
                0.7448364496231079,
                0.7998102903366089,
                0.7259892225265503,
                0.8255985379219055,
                0.717265784740448,
                0.8030046224594116,
                0.8225690126419067,
                0.6021406650543213,
                0.7350980043411255,
                0.8170468807220459,
                0.7807109355926514,
                0.812175452709198,
                0.5923476815223694,
                0.8188289999961853,
                0.8321588039398193
            ],
            [
                0.7329322695732117,
                0.7797253131866455,
                0.792685329914093,
                0.8317664861679077,
                0.8680659532546997,
                0.729186475276947,
                0.8511454463005066,
                0.7959235310554504,
                0.8584631085395813,
                0.6821603178977966,
                0.8621780276298523,
                0.7069623470306396,
                0.9008547067642212,
                0.812240719795227,
                0.8461551666259766,
                0.8819758892059326,
                0.8404196500778198,
                0.7974339127540588,
                0.6368511319160461,
                0.659356951713562,
                0.8558287620544434,
                0.7968213558197021,
                0.8599693179130554,
                0.742904007434845,
                0.6969741582870483,
                0.8990544080734253,
                0.7553166151046753,
                0.6229758262634277,
                0.8975420594215393,
                0.7088773846626282,
                0.598060131072998,
                0.8631608486175537,
                0.7170169353485107,
                0.8501201868057251,
                0.7204758524894714,
                0.5813430547714233,
                0.8738934993743896,
                0.8991404175758362,
                0.7149596810340881,
                0.889165997505188,
                0.6943118572235107,
                0.8775086402893066,
                0.8960155248641968,
                0.646645188331604,
                0.7477014660835266,
                0.8707221746444702,
                0.8137941360473633,
                0.698070228099823,
                0.6332718133926392,
                0.8903965950012207,
                0.879477858543396
            ],
            [
                0.8442947864532471,
                0.8560316562652588,
                0.87903892993927,
                0.7720012664794922,
                0.8252712488174438,
                0.7038717269897461,
                0.9060966968536377,
                0.9382032155990601,
                0.7955200672149658,
                0.8010310530662537,
                0.8109891414642334,
                0.690095841884613,
                0.871152400970459,
                0.8503725528717041,
                0.7363004684448242,
                0.81232088804245,
                0.872121274471283,
                0.7480840086936951,
                0.6165878772735596,
                0.588164210319519,
                0.8099135756492615,
                0.7601308822631836,
                0.8798924684524536,
                0.8706789612770081,
                0.5951768159866333,
                0.8714736700057983,
                0.8638221025466919,
                0.5333839654922485,
                0.8687108755111694,
                0.8440690040588379,
                0.4941064715385437,
                0.807968258857727,
                0.8692436814308167,
                0.8558791875839233,
                0.82649827003479,
                0.4945650100708008,
                0.8078762888908386,
                0.8564015030860901,
                0.825509786605835,
                0.8644137382507324,
                0.8561632633209229,
                0.8820688724517822,
                0.8650500774383545,
                0.7380384802818298,
                0.6930930614471436,
                0.8682394027709961,
                0.7670154571533203,
                0.8128694891929626,
                0.5303844809532166,
                0.8663219809532166,
                0.8673620223999023
            ],
            [
                0.8390317559242249,
                0.8265696167945862,
                0.8856726884841919,
                0.812330961227417,
                0.8865469098091125,
                0.7355211973190308,
                0.943958580493927,
                0.8772180080413818,
                0.8471868634223938,
                0.7515226006507874,
                0.8842538595199585,
                0.7204445600509644,
                0.9037920832633972,
                0.7737792134284973,
                0.7929403185844421,
                0.8436592817306519,
                0.8452808856964111,
                0.7756162881851196,
                0.6254720687866211,
                0.618202805519104,
                0.8153925538063049,
                0.7868960499763489,
                0.9172166585922241,
                0.7745059132575989,
                0.6608900427818298,
                0.9232479333877563,
                0.7976715564727783,
                0.6206037402153015,
                0.9264306426048279,
                0.7991048693656921,
                0.5861855149269104,
                0.8628961443901062,
                0.7892757654190063,
                0.9227392673492432,
                0.7693378925323486,
                0.5746199488639832,
                0.8079740405082703,
                0.8893634080886841,
                0.7528743743896484,
                0.9169038534164429,
                0.7599911093711853,
                0.8861843943595886,
                0.9163426160812378,
                0.6678884625434875,
                0.7507259845733643,
                0.8932271003723145,
                0.7866696715354919,
                0.7541428804397583,
                0.6217166781425476,
                0.927209198474884,
                0.9257168769836426
            ],
            [
                0.7700437307357788,
                0.7520662546157837,
                0.7407214045524597,
                0.8875311613082886,
                0.8813251256942749,
                0.8120745420455933,
                0.8130711317062378,
                0.7184863686561584,
                0.8388398289680481,
                0.654632568359375,
                0.8394752144813538,
                0.778044581413269,
                0.8331753611564636,
                0.7188477516174316,
                0.864534318447113,
                0.8356407880783081,
                0.7660994529724121,
                0.7734326124191284,
                0.6348376274108887,
                0.6425315141677856,
                0.7990292906761169,
                0.8439652919769287,
                0.7894964814186096,
                0.6614052653312683,
                0.7897034287452698,
                0.8521293997764587,
                0.7119152545928955,
                0.732502281665802,
                0.8498839139938354,
                0.7021207213401794,
                0.7127193808555603,
                0.8399925827980042,
                0.6613432765007019,
                0.8308299779891968,
                0.6457154154777527,
                0.6667883992195129,
                0.7936246395111084,
                0.8121507167816162,
                0.6595948934555054,
                0.8165673017501831,
                0.6340076327323914,
                0.8158066272735596,
                0.8228498101234436,
                0.5957931280136108,
                0.8151511549949646,
                0.8218783736228943,
                0.7580024003982544,
                0.6571561098098755,
                0.7375486493110657,
                0.8478416204452515,
                0.830537736415863
            ],
            [
                0.7578228116035461,
                0.8145877122879028,
                0.7456839084625244,
                0.7035917043685913,
                0.7212139368057251,
                0.7566941380500793,
                0.8077041506767273,
                0.8100729584693909,
                0.7674388289451599,
                0.7759360671043396,
                0.7210925817489624,
                0.7696088552474976,
                0.7414831519126892,
                0.7311040759086609,
                0.6840170621871948,
                0.6997990608215332,
                0.799735963344574,
                0.74872887134552,
                0.6710154414176941,
                0.6547315716743469,
                0.7567199468612671,
                0.7456397414207458,
                0.8112666606903076,
                0.7830551266670227,
                0.6289482116699219,
                0.7732092142105103,
                0.8235328793525696,
                0.6012559533119202,
                0.7779519557952881,
                0.8163341283798218,
                0.5841646790504456,
                0.7785711884498596,
                0.7971176505088806,
                0.7775095701217651,
                0.77675461769104,
                0.5782155394554138,
                0.7437711358070374,
                0.7762352228164673,
                0.7298846244812012,
                0.7943214178085327,
                0.6859205365180969,
                0.7501552104949951,
                0.7851943373680115,
                0.6291455626487732,
                0.7164474129676819,
                0.7724629044532776,
                0.7913734912872314,
                0.8237330317497253,
                0.5992462038993835,
                0.7834054827690125,
                0.7911555767059326
            ],
            [
                0.7698268294334412,
                0.8089303970336914,
                0.7452974319458008,
                0.684339702129364,
                0.7184551954269409,
                0.709547221660614,
                0.81302809715271,
                0.8425962328910828,
                0.7445868253707886,
                0.8785462379455566,
                0.7223973274230957,
                0.7199642658233643,
                0.7417751550674438,
                0.729734480381012,
                0.6519646644592285,
                0.6834986209869385,
                0.8290337920188904,
                0.7316649556159973,
                0.627657413482666,
                0.6201896071434021,
                0.7215673923492432,
                0.693838357925415,
                0.8155999183654785,
                0.8341784477233887,
                0.5742899179458618,
                0.7731913924217224,
                0.8783554434776306,
                0.5305063724517822,
                0.7698594927787781,
                0.8804467916488647,
                0.5142660140991211,
                0.7654154300689697,
                0.8921194672584534,
                0.7694482803344727,
                0.82422935962677,
                0.5217730402946472,
                0.7072995901107788,
                0.7527363300323486,
                0.7852237820625305,
                0.7792423963546753,
                0.7569687366485596,
                0.7502244710922241,
                0.7714488506317139,
                0.6311382055282593,
                0.6675773859024048,
                0.7853394746780396,
                0.7386643290519714,
                0.8755756616592407,
                0.5324462652206421,
                0.7809717059135437,
                0.7888045310974121
            ],
            [
                0.7828643321990967,
                0.7534851431846619,
                0.7408682107925415,
                0.8800930380821228,
                0.881738007068634,
                0.8195731043815613,
                0.8111257553100586,
                0.7146226763725281,
                0.8373910188674927,
                0.6648949384689331,
                0.8270783424377441,
                0.7872366309165955,
                0.8171494007110596,
                0.7103310823440552,
                0.8425791263580322,
                0.8188924789428711,
                0.7478320002555847,
                0.7858902215957642,
                0.6584686636924744,
                0.6553646326065063,
                0.8021330237388611,
                0.8310641646385193,
                0.7843486070632935,
                0.6751750111579895,
                0.7828611731529236,
                0.838662326335907,
                0.7263894081115723,
                0.7291829586029053,
                0.8375809192657471,
                0.7125338315963745,
                0.7129825353622437,
                0.8252891898155212,
                0.6679779291152954,
                0.8263595104217529,
                0.6608521342277527,
                0.6678898930549622,
                0.7907465696334839,
                0.8100454807281494,
                0.651411771774292,
                0.8158471584320068,
                0.6371563076972961,
                0.8163719773292542,
                0.8205046653747559,
                0.5962494015693665,
                0.8426539897918701,
                0.8269001245498657,
                0.7880517840385437,
                0.6629023551940918,
                0.7314715385437012,
                0.8367725014686584,
                0.8349740505218506
            ],
            [
                0.740336000919342,
                0.785946249961853,
                0.7420799732208252,
                0.7271535396575928,
                0.7568161487579346,
                0.763513445854187,
                0.8124985098838806,
                0.829671323299408,
                0.7802602052688599,
                0.7515694499015808,
                0.7390885949134827,
                0.7524221539497375,
                0.768812358379364,
                0.7689778804779053,
                0.710938572883606,
                0.7328464388847351,
                0.7814173102378845,
                0.7665185332298279,
                0.6982353925704956,
                0.6715996861457825,
                0.8003488183021545,
                0.7472434043884277,
                0.8293398022651672,
                0.8092213273048401,
                0.6381251215934753,
                0.7863687872886658,
                0.8156619071960449,
                0.6155288815498352,
                0.7928140759468079,
                0.782853901386261,
                0.5926111936569214,
                0.7854691743850708,
                0.7955583333969116,
                0.7932370901107788,
                0.8121031522750854,
                0.5918036699295044,
                0.8079027533531189,
                0.8218564987182617,
                0.7476454973220825,
                0.8235796689987183,
                0.7237151265144348,
                0.8098999261856079,
                0.8177699446678162,
                0.6878036856651306,
                0.7589026093482971,
                0.8214637041091919,
                0.8603777885437012,
                0.7919997572898865,
                0.6064251661300659,
                0.7970783114433289,
                0.8199837803840637
            ],
            [
                0.8355568051338196,
                0.8250961899757385,
                0.8211594820022583,
                0.7819671630859375,
                0.8158183097839355,
                0.7812705039978027,
                0.8898996114730835,
                0.8812091946601868,
                0.7969865202903748,
                0.8239324688911438,
                0.7889118194580078,
                0.7483887672424316,
                0.8155815601348877,
                0.7678287625312805,
                0.7454995512962341,
                0.7804422378540039,
                0.8388190269470215,
                0.7637066841125488,
                0.6319485902786255,
                0.6283493638038635,
                0.7981711626052856,
                0.7870277166366577,
                0.8550645112991333,
                0.8655908703804016,
                0.6678724884986877,
                0.8532687425613403,
                0.8697284460067749,
                0.611282467842102,
                0.8513689041137695,
                0.8562517166137695,
                0.597533106803894,
                0.8155291080474854,
                0.8690404295921326,
                0.8376098871231079,
                0.8433438539505005,
                0.577636182308197,
                0.7738981246948242,
                0.8216387033462524,
                0.7906618118286133,
                0.846308171749115,
                0.7725909948348999,
                0.8293017745018005,
                0.8440626859664917,
                0.6658934950828552,
                0.7814810276031494,
                0.8640912771224976,
                0.7985697984695435,
                0.823733925819397,
                0.6177210807800293,
                0.8564258813858032,
                0.8748565316200256
            ],
            [
                0.7514186501502991,
                0.7919099926948547,
                0.7843077778816223,
                0.7633392214775085,
                0.7875731587409973,
                0.7830851078033447,
                0.8396627902984619,
                0.8415777087211609,
                0.8045139312744141,
                0.7692409753799438,
                0.7730196118354797,
                0.7561544179916382,
                0.8044670820236206,
                0.784168004989624,
                0.7469856142997742,
                0.7638705968856812,
                0.805817186832428,
                0.7868455648422241,
                0.6877509951591492,
                0.6789765954017639,
                0.8157908916473389,
                0.7890033721923828,
                0.8620426058769226,
                0.7808588743209839,
                0.6774497032165527,
                0.8244949579238892,
                0.8023720383644104,
                0.6219114661216736,
                0.8250208497047424,
                0.7767600417137146,
                0.5862882137298584,
                0.8198673129081726,
                0.771960973739624,
                0.8069083094596863,
                0.7971735596656799,
                0.5866440534591675,
                0.8376534581184387,
                0.8323546648025513,
                0.743739128112793,
                0.8510655164718628,
                0.7302014231681824,
                0.8210927248001099,
                0.8471879959106445,
                0.6990358829498291,
                0.724273681640625,
                0.8184736967086792,
                0.802676796913147,
                0.7520190477371216,
                0.6391981244087219,
                0.8346925377845764,
                0.8310280442237854
            ],
            [
                0.8441808223724365,
                0.8480910658836365,
                0.8432307243347168,
                0.8086571097373962,
                0.8295465111732483,
                0.7978502511978149,
                0.9130789041519165,
                0.8974626064300537,
                0.8209227323532104,
                0.8325493931770325,
                0.8063375353813171,
                0.7704246640205383,
                0.8410840034484863,
                0.7994318604469299,
                0.773889422416687,
                0.8032605051994324,
                0.8539566993713379,
                0.772286057472229,
                0.6339035630226135,
                0.6292453408241272,
                0.8121429681777954,
                0.8135383129119873,
                0.8701397776603699,
                0.8656033873558044,
                0.6904175281524658,
                0.863357663154602,
                0.8789076805114746,
                0.6239680051803589,
                0.8591787219047546,
                0.8527669310569763,
                0.6004483699798584,
                0.8286300897598267,
                0.8676443099975586,
                0.8580451011657715,
                0.8419089913368225,
                0.588778018951416,
                0.7932339906692505,
                0.841454267501831,
                0.7926756739616394,
                0.8623666167259216,
                0.7886707186698914,
                0.8476098775863647,
                0.8609771728515625,
                0.685943067073822,
                0.7731887102127075,
                0.8554881811141968,
                0.7987428903579712,
                0.8180883526802063,
                0.6447758078575134,
                0.8678749799728394,
                0.872105062007904
            ],
            [
                0.7286378741264343,
                0.7724242210388184,
                0.7456925511360168,
                0.7300534248352051,
                0.7541437745094299,
                0.7516701221466064,
                0.810628354549408,
                0.8132110238075256,
                0.7896422147750854,
                0.7487107515335083,
                0.7502996325492859,
                0.7494922280311584,
                0.7735114693641663,
                0.7533529996871948,
                0.7107207775115967,
                0.7338030338287354,
                0.7911064028739929,
                0.7713427543640137,
                0.6959407329559326,
                0.6737491488456726,
                0.799833357334137,
                0.7533490657806396,
                0.8362159729003906,
                0.7672590613365173,
                0.6377573609352112,
                0.7846323847770691,
                0.7918293476104736,
                0.6059321165084839,
                0.7901977896690369,
                0.7703167796134949,
                0.584036111831665,
                0.8006638288497925,
                0.7642062306404114,
                0.780235230922699,
                0.7846292853355408,
                0.5920552015304565,
                0.8145180940628052,
                0.8251351714134216,
                0.7208545804023743,
                0.8292571902275085,
                0.6889729499816895,
                0.7985928058624268,
                0.8196343183517456,
                0.6724979877471924,
                0.716901421546936,
                0.7990567088127136,
                0.8078941702842712,
                0.7546354532241821,
                0.6062421798706055,
                0.7939271926879883,
                0.7999672889709473
            ],
            [
                0.8218379020690918,
                0.8371961116790771,
                0.8047322630882263,
                0.7748697996139526,
                0.8071850538253784,
                0.7546773552894592,
                0.8568823337554932,
                0.8435997366905212,
                0.8227809071540833,
                0.8489477038383484,
                0.786189079284668,
                0.7743229269981384,
                0.8043016195297241,
                0.7572233080863953,
                0.7311981916427612,
                0.7672910690307617,
                0.8469874262809753,
                0.7934333086013794,
                0.6657648682594299,
                0.6647517681121826,
                0.7975690364837646,
                0.7647866606712341,
                0.8635628819465637,
                0.8047159910202026,
                0.6780866980552673,
                0.8311983942985535,
                0.8580356240272522,
                0.6247325539588928,
                0.8287381529808044,
                0.867331862449646,
                0.5974423289299011,
                0.8283397555351257,
                0.8362497091293335,
                0.822168231010437,
                0.8180954456329346,
                0.6031842827796936,
                0.7825645804405212,
                0.8239637613296509,
                0.7619986534118652,
                0.8446007966995239,
                0.7438961267471313,
                0.8178948760032654,
                0.8332553505897522,
                0.6477596163749695,
                0.7543997764587402,
                0.8252773284912109,
                0.8048127293586731,
                0.8237422704696655,
                0.6214060187339783,
                0.8348735570907593,
                0.8402412533760071
            ],
            [
                0.7680157423019409,
                0.7962639927864075,
                0.8297989368438721,
                0.8055003881454468,
                0.8733937740325928,
                0.7651079297065735,
                0.8803234100341797,
                0.8188076615333557,
                0.8787966966629028,
                0.7467018365859985,
                0.8765760064125061,
                0.7427896857261658,
                0.8859769105911255,
                0.7676596641540527,
                0.8086458444595337,
                0.8622341156005859,
                0.8640409111976624,
                0.8363589644432068,
                0.6756831407546997,
                0.6934827566146851,
                0.8514958620071411,
                0.7823981046676636,
                0.90458744764328,
                0.7571255564689636,
                0.7170591354370117,
                0.9175430536270142,
                0.8003608584403992,
                0.6453474164009094,
                0.9155170321464539,
                0.7938932180404663,
                0.6269277930259705,
                0.9042105674743652,
                0.7520862817764282,
                0.8723657131195068,
                0.7472800612449646,
                0.6186287999153137,
                0.8633856773376465,
                0.8923901915550232,
                0.7144683003425598,
                0.9200218915939331,
                0.700248122215271,
                0.8720874190330505,
                0.9197405576705933,
                0.6515475511550903,
                0.7642124891281128,
                0.8931493163108826,
                0.8317582607269287,
                0.7449575066566467,
                0.650780200958252,
                0.9152281880378723,
                0.9101308584213257
            ],
            [
                0.7721810936927795,
                0.8384486436843872,
                0.77794349193573,
                0.7548323273658752,
                0.7971487641334534,
                0.7689111828804016,
                0.8575031161308289,
                0.8412870168685913,
                0.8259661197662354,
                0.7902464270591736,
                0.7849355936050415,
                0.7641862034797668,
                0.8058071732521057,
                0.7697455286979675,
                0.740481972694397,
                0.7833646535873413,
                0.8474087119102478,
                0.8147114515304565,
                0.6986328959465027,
                0.6724518537521362,
                0.838441789150238,
                0.7730379700660706,
                0.86822509765625,
                0.8128330707550049,
                0.6926701068878174,
                0.837035596370697,
                0.8466373085975647,
                0.6392573714256287,
                0.8390748500823975,
                0.8224679231643677,
                0.6310749053955078,
                0.8366081118583679,
                0.8104347586631775,
                0.8324583768844604,
                0.7996361255645752,
                0.6274312734603882,
                0.8219167590141296,
                0.8489242792129517,
                0.7677835822105408,
                0.868331789970398,
                0.7352710366249084,
                0.8247517347335815,
                0.8627034425735474,
                0.6573858857154846,
                0.7404911518096924,
                0.8245351910591125,
                0.8301169872283936,
                0.8197978138923645,
                0.6410920023918152,
                0.8412922620773315,
                0.8458043336868286
            ],
            [
                0.7515066862106323,
                0.8197330832481384,
                0.7495816349983215,
                0.7878360152244568,
                0.8187629580497742,
                0.7818102240562439,
                0.8247275948524475,
                0.7947965860366821,
                0.8632984757423401,
                0.7496185898780823,
                0.8304757475852966,
                0.7946528196334839,
                0.8331964015960693,
                0.7723526358604431,
                0.7949581742286682,
                0.7945019006729126,
                0.8625585436820984,
                0.8136786818504333,
                0.7147085070610046,
                0.6923900246620178,
                0.8192813992500305,
                0.7846128940582275,
                0.8468595147132874,
                0.7646278738975525,
                0.6909304857254028,
                0.8439517021179199,
                0.7922799587249756,
                0.6439597010612488,
                0.8472879528999329,
                0.7815454006195068,
                0.6307307481765747,
                0.8384762406349182,
                0.7548671960830688,
                0.8168287873268127,
                0.7623521685600281,
                0.6256195902824402,
                0.81120365858078,
                0.8407988548278809,
                0.734045147895813,
                0.8541430830955505,
                0.6988283395767212,
                0.8130645155906677,
                0.8515284061431885,
                0.6383825540542603,
                0.7414907217025757,
                0.8084208965301514,
                0.8204869627952576,
                0.7596948146820068,
                0.6592113971710205,
                0.8467927575111389,
                0.8435620069503784
            ],
            [
                0.8469861149787903,
                0.8826625347137451,
                0.8276984691619873,
                0.8358021974563599,
                0.8544914722442627,
                0.8027884364128113,
                0.8871877789497375,
                0.8733235597610474,
                0.8563527464866638,
                0.8237760066986084,
                0.8381121158599854,
                0.7932444214820862,
                0.8624774813652039,
                0.8112048506736755,
                0.8089854717254639,
                0.82099848985672,
                0.8916866183280945,
                0.7994863986968994,
                0.6637837886810303,
                0.6514197587966919,
                0.8267809748649597,
                0.8111354112625122,
                0.8609724044799805,
                0.8591179251670837,
                0.6951292753219604,
                0.8749867677688599,
                0.8877652287483215,
                0.6381320953369141,
                0.8752242922782898,
                0.8655223250389099,
                0.6253604292869568,
                0.849162757396698,
                0.8600248694419861,
                0.8615703582763672,
                0.8087651133537292,
                0.6065981388092041,
                0.8044429421424866,
                0.8411695957183838,
                0.7972691655158997,
                0.8634759187698364,
                0.7876232862472534,
                0.8577218651771545,
                0.8647465705871582,
                0.6899972558021545,
                0.7780439853668213,
                0.8634226322174072,
                0.8159523606300354,
                0.8303917646408081,
                0.6445469856262207,
                0.8755744099617004,
                0.8756033778190613
            ],
            [
                0.7335230708122253,
                0.7604070901870728,
                0.7695363759994507,
                0.8223165273666382,
                0.8593123555183411,
                0.7474080920219421,
                0.847105860710144,
                0.778867244720459,
                0.8580769896507263,
                0.6733386516571045,
                0.8575035929679871,
                0.7206408977508545,
                0.8595073223114014,
                0.7586060762405396,
                0.8265785574913025,
                0.8698846101760864,
                0.8225128650665283,
                0.84022057056427,
                0.6927703619003296,
                0.653517484664917,
                0.8648566007614136,
                0.7946180105209351,
                0.8502930402755737,
                0.7171351313591003,
                0.7246178984642029,
                0.8737202882766724,
                0.7455684542655945,
                0.656834602355957,
                0.8731741905212402,
                0.7030041217803955,
                0.6505088806152344,
                0.8598849773406982,
                0.6957635879516602,
                0.8570846915245056,
                0.6863077282905579,
                0.6277464628219604,
                0.8786524534225464,
                0.9008229970932007,
                0.683342456817627,
                0.8945217728614807,
                0.664758563041687,
                0.8652418851852417,
                0.8981747627258301,
                0.625892698764801,
                0.7653329968452454,
                0.8532968163490295,
                0.8265916705131531,
                0.6919461488723755,
                0.6581860184669495,
                0.8679749965667725,
                0.8611463904380798
            ],
            [
                0.7187800407409668,
                0.7870110869407654,
                0.7369440197944641,
                0.8307173252105713,
                0.849972665309906,
                0.7592386603355408,
                0.820675253868103,
                0.789011538028717,
                0.864450216293335,
                0.6821157932281494,
                0.8672642707824707,
                0.745598554611206,
                0.8748185634613037,
                0.7859450578689575,
                0.8594253063201904,
                0.8687312006950378,
                0.8467919826507568,
                0.8251970410346985,
                0.7081894874572754,
                0.6655874848365784,
                0.8387682437896729,
                0.7915122509002686,
                0.8424836993217468,
                0.7389451265335083,
                0.7223137617111206,
                0.8761706352233887,
                0.7508538365364075,
                0.6615371108055115,
                0.8749638795852661,
                0.7116820216178894,
                0.6468971371650696,
                0.8546969294548035,
                0.7113614678382874,
                0.8380835056304932,
                0.7185763716697693,
                0.6260137557983398,
                0.8684071898460388,
                0.8810232281684875,
                0.7339195609092712,
                0.8727279305458069,
                0.7046112418174744,
                0.8621969223022461,
                0.880389392375946,
                0.6551926732063293,
                0.7532023191452026,
                0.8440581560134888,
                0.8319597840309143,
                0.7216241359710693,
                0.6654431819915771,
                0.8713261485099792,
                0.8599088191986084
            ],
            [
                0.846966028213501,
                0.89539635181427,
                0.8054637312889099,
                0.847929835319519,
                0.8670480251312256,
                0.822514533996582,
                0.8610396385192871,
                0.8222116231918335,
                0.8627618551254272,
                0.7878572344779968,
                0.8342130780220032,
                0.836807131767273,
                0.8535892963409424,
                0.7806370854377747,
                0.8255208134651184,
                0.822740912437439,
                0.859249472618103,
                0.8152621984481812,
                0.672012984752655,
                0.6832728981971741,
                0.8394003510475159,
                0.8363795876502991,
                0.8532225489616394,
                0.8037464618682861,
                0.7643163204193115,
                0.8741617798805237,
                0.8428837656974792,
                0.7165038585662842,
                0.8735739588737488,
                0.8191468715667725,
                0.6911839246749878,
                0.8650737404823303,
                0.8025183081626892,
                0.8521718978881836,
                0.7556166648864746,
                0.6792551279067993,
                0.7977892756462097,
                0.8302589654922485,
                0.7712966799736023,
                0.8536654114723206,
                0.7383348345756531,
                0.8367937207221985,
                0.8472860455513,
                0.652475893497467,
                0.8107748031616211,
                0.8457498550415039,
                0.8084295988082886,
                0.8033490777015686,
                0.716856062412262,
                0.8739023208618164,
                0.866695761680603
            ],
            [
                0.7451812624931335,
                0.7776119112968445,
                0.772691011428833,
                0.8033484220504761,
                0.8540976047515869,
                0.7539055347442627,
                0.8524008989334106,
                0.7908155918121338,
                0.8603324890136719,
                0.7360236048698425,
                0.8582963943481445,
                0.7577521800994873,
                0.8614870309829712,
                0.7458860874176025,
                0.8108301162719727,
                0.853199303150177,
                0.8432259559631348,
                0.8654921650886536,
                0.7304384708404541,
                0.6991116404533386,
                0.852917492389679,
                0.7808390259742737,
                0.8792021870613098,
                0.7273990511894226,
                0.7187048196792603,
                0.8807036876678467,
                0.7704080939292908,
                0.6547468304634094,
                0.8789579272270203,
                0.7444136738777161,
                0.6498979330062866,
                0.8712530136108398,
                0.7306507229804993,
                0.8637997508049011,
                0.7103003263473511,
                0.656092643737793,
                0.8708888292312622,
                0.906222939491272,
                0.6996042728424072,
                0.9155891537666321,
                0.6806569695472717,
                0.8737287521362305,
                0.9105602502822876,
                0.633399486541748,
                0.7661841511726379,
                0.8614250421524048,
                0.8335927724838257,
                0.7135165929794312,
                0.6684953570365906,
                0.8803192377090454,
                0.8759423494338989
            ],
            [
                0.7281272411346436,
                0.7884760499000549,
                0.722196638584137,
                0.7597328424453735,
                0.8092243075370789,
                0.758381187915802,
                0.7926604747772217,
                0.7410418391227722,
                0.8204330205917358,
                0.723434567451477,
                0.7876278758049011,
                0.7895725965499878,
                0.7933081388473511,
                0.7072859406471252,
                0.7602367401123047,
                0.7847966551780701,
                0.813544511795044,
                0.8547295928001404,
                0.7383230924606323,
                0.7155694961547852,
                0.827111542224884,
                0.7614594101905823,
                0.8470073938369751,
                0.7045362591743469,
                0.7240766286849976,
                0.8291982412338257,
                0.7625176310539246,
                0.6637898087501526,
                0.828024685382843,
                0.7271655797958374,
                0.6596515774726868,
                0.8513218760490417,
                0.7038668990135193,
                0.8125033974647522,
                0.686063826084137,
                0.6752898693084717,
                0.8290873169898987,
                0.8554548025131226,
                0.6643553972244263,
                0.8684561848640442,
                0.6335543990135193,
                0.8147444725036621,
                0.8554338812828064,
                0.5902764201164246,
                0.7599312663078308,
                0.7970377802848816,
                0.8384386897087097,
                0.7184550762176514,
                0.6807786822319031,
                0.8300758004188538,
                0.8265462517738342
            ],
            [
                0.8517521023750305,
                0.8920164108276367,
                0.8185132741928101,
                0.8689892292022705,
                0.8751938343048096,
                0.8374572396278381,
                0.8809097409248352,
                0.848456621170044,
                0.8621894121170044,
                0.8039090633392334,
                0.8449318408966064,
                0.824176013469696,
                0.869033932685852,
                0.8082339763641357,
                0.844552755355835,
                0.8436900973320007,
                0.8685133457183838,
                0.8268511295318604,
                0.6734186410903931,
                0.6838589906692505,
                0.8559038639068604,
                0.8585603833198547,
                0.8630503416061401,
                0.8321019411087036,
                0.7800620198249817,
                0.8878961205482483,
                0.8636534214019775,
                0.711127758026123,
                0.8830603957176208,
                0.822068989276886,
                0.6863445043563843,
                0.8670611381530762,
                0.8170230984687805,
                0.8580514192581177,
                0.7791783809661865,
                0.6743765473365784,
                0.8222371339797974,
                0.8477944731712341,
                0.7865238785743713,
                0.8698881268501282,
                0.7734860777854919,
                0.8634374141693115,
                0.8677361011505127,
                0.6848121285438538,
                0.8200122714042664,
                0.8611079454421997,
                0.8089413642883301,
                0.8018932342529297,
                0.7211111187934875,
                0.8826434016227722,
                0.8738723993301392
            ],
            [
                0.7646561861038208,
                0.8116503953933716,
                0.7842790484428406,
                0.7674261331558228,
                0.7700014114379883,
                0.7867283821105957,
                0.8524162173271179,
                0.9000922441482544,
                0.7879427075386047,
                0.796750545501709,
                0.7667648196220398,
                0.7506232857704163,
                0.8083496689796448,
                0.8318842053413391,
                0.7486350536346436,
                0.7805699110031128,
                0.8210351467132568,
                0.7668453454971313,
                0.6766220927238464,
                0.6594927906990051,
                0.8156460523605347,
                0.7858462333679199,
                0.8575162291526794,
                0.8438403606414795,
                0.6715594530105591,
                0.8189047574996948,
                0.8387285470962524,
                0.5984669923782349,
                0.8130249381065369,
                0.7961779832839966,
                0.5541880130767822,
                0.8023043870925903,
                0.8222290873527527,
                0.7956617474555969,
                0.8509481549263,
                0.5613014698028564,
                0.8390787839889526,
                0.8341913819313049,
                0.8169804811477661,
                0.8443058133125305,
                0.8175331950187683,
                0.8476975560188293,
                0.8420173525810242,
                0.763995885848999,
                0.7086752653121948,
                0.8260419368743896,
                0.7847163677215576,
                0.782316267490387,
                0.5927904844284058,
                0.8146642446517944,
                0.8122244477272034
            ],
            [
                0.8348828554153442,
                0.8356591463088989,
                0.7941721081733704,
                0.7894075512886047,
                0.8142113089561462,
                0.7882633805274963,
                0.8796844482421875,
                0.870833158493042,
                0.8153302669525146,
                0.8662319779396057,
                0.7949849963188171,
                0.7761558294296265,
                0.8104652166366577,
                0.7799831032752991,
                0.7439259886741638,
                0.772026777267456,
                0.8491666316986084,
                0.7940506339073181,
                0.675961434841156,
                0.6558270454406738,
                0.7963204383850098,
                0.7852569818496704,
                0.8710407018661499,
                0.8455200791358948,
                0.6978775262832642,
                0.8358920812606812,
                0.8989566564559937,
                0.641495406627655,
                0.832594096660614,
                0.8846499919891357,
                0.6210066080093384,
                0.8203489780426025,
                0.8714441657066345,
                0.8394944667816162,
                0.8397253751754761,
                0.6154564619064331,
                0.7843470573425293,
                0.8312138915061951,
                0.7884384393692017,
                0.8461482524871826,
                0.7684437036514282,
                0.8255780339241028,
                0.8395199775695801,
                0.6569976210594177,
                0.7648729085922241,
                0.8399205803871155,
                0.8004265427589417,
                0.8461266160011292,
                0.6364835500717163,
                0.8385633230209351,
                0.8456544876098633
            ],
            [
                0.732931911945343,
                0.7644289135932922,
                0.7525191307067871,
                0.7328381538391113,
                0.7513811588287354,
                0.7727063298225403,
                0.8218128681182861,
                0.8375906348228455,
                0.787260115146637,
                0.7500115036964417,
                0.7518243789672852,
                0.7446930408477783,
                0.7742340564727783,
                0.7669842839241028,
                0.7193342447280884,
                0.7377065420150757,
                0.7790682911872864,
                0.7672961354255676,
                0.6883765459060669,
                0.6640287637710571,
                0.7923614978790283,
                0.7703299522399902,
                0.8448390960693359,
                0.7918856143951416,
                0.654833197593689,
                0.7938916683197021,
                0.794498860836029,
                0.6489515900611877,
                0.8081381320953369,
                0.7768974304199219,
                0.5906479954719543,
                0.796442985534668,
                0.7744782567024231,
                0.7873340845108032,
                0.8077219724655151,
                0.5891478061676025,
                0.8215091228485107,
                0.8138678669929504,
                0.7442662119865417,
                0.8322749137878418,
                0.7298175692558289,
                0.8096458911895752,
                0.8251811265945435,
                0.7274561524391174,
                0.7197282314300537,
                0.8016703724861145,
                0.7932778596878052,
                0.7474302053451538,
                0.6135494709014893,
                0.800092875957489,
                0.8072049617767334
            ],
            [
                0.8520702123641968,
                0.8643738031387329,
                0.8313326835632324,
                0.7814705967903137,
                0.8135504722595215,
                0.7391815185546875,
                0.8960482478141785,
                0.9122151136398315,
                0.7895891070365906,
                0.8565245270729065,
                0.7836827039718628,
                0.7407848834991455,
                0.8231095671653748,
                0.8110004663467407,
                0.7200056314468384,
                0.7660875916481018,
                0.846526026725769,
                0.7593958973884583,
                0.6391986012458801,
                0.6084192991256714,
                0.8030669093132019,
                0.7806352376937866,
                0.867196798324585,
                0.8736213445663452,
                0.6218253970146179,
                0.8312646746635437,
                0.8981115221977234,
                0.579838216304779,
                0.8330707550048828,
                0.8817952871322632,
                0.5454219579696655,
                0.7843111753463745,
                0.8970872759819031,
                0.8445367813110352,
                0.8571733236312866,
                0.5384465456008911,
                0.7717326283454895,
                0.8288524150848389,
                0.8310943841934204,
                0.8403886556625366,
                0.8272497653961182,
                0.8326940536499023,
                0.837236762046814,
                0.6881948113441467,
                0.7181678414344788,
                0.8373031616210938,
                0.7659415006637573,
                0.8550434112548828,
                0.5712382793426514,
                0.8357195258140564,
                0.843988299369812
            ],
            [
                0.8437327742576599,
                0.80423504114151,
                0.8826778531074524,
                0.8047060966491699,
                0.8910274505615234,
                0.708550214767456,
                0.9364240169525146,
                0.8480954766273499,
                0.8239312171936035,
                0.7154530882835388,
                0.8658554553985596,
                0.6931703686714172,
                0.8853902220726013,
                0.7475185990333557,
                0.7680413722991943,
                0.8375389575958252,
                0.8166816830635071,
                0.7588409185409546,
                0.607994794845581,
                0.5809352397918701,
                0.7999218702316284,
                0.7736450433731079,
                0.8992117643356323,
                0.7524193525314331,
                0.6479623317718506,
                0.9168453216552734,
                0.7776163816452026,
                0.6050024628639221,
                0.9208575487136841,
                0.7731379270553589,
                0.5682185888290405,
                0.8461732864379883,
                0.768333911895752,
                0.9355025887489319,
                0.7251790761947632,
                0.5439167022705078,
                0.7951855659484863,
                0.880405843257904,
                0.7257107496261597,
                0.9088579416275024,
                0.7273126244544983,
                0.8723507523536682,
                0.9103586673736572,
                0.6245748996734619,
                0.7342915534973145,
                0.8879883885383606,
                0.7729766964912415,
                0.7223610877990723,
                0.6026784777641296,
                0.9196397662162781,
                0.9225063323974609
            ],
            [
                0.7917436361312866,
                0.765661895275116,
                0.7510450482368469,
                0.882960855960846,
                0.8918008208274841,
                0.8183432817459106,
                0.8239930868148804,
                0.7327426671981812,
                0.8543597459793091,
                0.7230688333511353,
                0.8366374969482422,
                0.8107117414474487,
                0.8294399976730347,
                0.7263746857643127,
                0.8348509669303894,
                0.8171282410621643,
                0.77344810962677,
                0.8198527693748474,
                0.6836890578269958,
                0.6903443336486816,
                0.8173183798789978,
                0.8414906859397888,
                0.8256795406341553,
                0.6813157796859741,
                0.7805584073066711,
                0.8489505052566528,
                0.7429778575897217,
                0.725803792476654,
                0.8473696112632751,
                0.7436074018478394,
                0.7047405242919922,
                0.852165699005127,
                0.6839033961296082,
                0.8381619453430176,
                0.6680312156677246,
                0.6980098485946655,
                0.8175815343856812,
                0.8485087156295776,
                0.6587474346160889,
                0.8531239628791809,
                0.6540930867195129,
                0.8411061763763428,
                0.8489198684692383,
                0.6045705676078796,
                0.8284857273101807,
                0.8277355432510376,
                0.7876073122024536,
                0.668256938457489,
                0.7329789996147156,
                0.8469932079315186,
                0.8340388536453247
            ],
            [
                0.7379164695739746,
                0.7906427979469299,
                0.7723254561424255,
                0.7453796863555908,
                0.7617897987365723,
                0.7310367226600647,
                0.8040432929992676,
                0.834313154220581,
                0.7774198055267334,
                0.7599714994430542,
                0.7373079061508179,
                0.751857578754425,
                0.7849959135055542,
                0.7838720083236694,
                0.7036387920379639,
                0.7587021589279175,
                0.7980202436447144,
                0.7991124391555786,
                0.6972321271896362,
                0.6807664036750793,
                0.8198078870773315,
                0.7632941603660583,
                0.824341893196106,
                0.7882298231124878,
                0.6371399760246277,
                0.7762675881385803,
                0.8048915266990662,
                0.5929037928581238,
                0.7777410745620728,
                0.7663780450820923,
                0.5545002818107605,
                0.8042235374450684,
                0.7760305404663086,
                0.7667896747589111,
                0.7886524796485901,
                0.5692402720451355,
                0.8409505486488342,
                0.828365683555603,
                0.7469042539596558,
                0.8195488452911377,
                0.7327848672866821,
                0.815592885017395,
                0.8138719797134399,
                0.6999539732933044,
                0.7133413553237915,
                0.7910107970237732,
                0.8165997266769409,
                0.7457021474838257,
                0.589329183101654,
                0.7801892757415771,
                0.7832536697387695
            ],
            [
                0.7731179594993591,
                0.8213961124420166,
                0.7749020457267761,
                0.7275906205177307,
                0.748479425907135,
                0.6927606463432312,
                0.8346044421195984,
                0.9227334260940552,
                0.7546617388725281,
                0.8547880053520203,
                0.7471890449523926,
                0.6969188451766968,
                0.7979182004928589,
                0.8266863822937012,
                0.6789666414260864,
                0.7313448786735535,
                0.8453510403633118,
                0.7395356893539429,
                0.6422387361526489,
                0.5897881984710693,
                0.7553070783615112,
                0.7211347222328186,
                0.8442324995994568,
                0.8930281400680542,
                0.5589927434921265,
                0.7954117059707642,
                0.894342303276062,
                0.5082470178604126,
                0.7941150665283203,
                0.8702390193939209,
                0.47068390250205994,
                0.7615271806716919,
                0.9148708581924438,
                0.7916433811187744,
                0.8705251812934875,
                0.48437076807022095,
                0.7785877585411072,
                0.8106008172035217,
                0.8601387739181519,
                0.8170685172080994,
                0.9015951156616211,
                0.8378838300704956,
                0.8133305311203003,
                0.7578621506690979,
                0.6520618200302124,
                0.8048719167709351,
                0.7536285519599915,
                0.8678311705589294,
                0.5022432804107666,
                0.7966719269752502,
                0.798229992389679
            ],
            [
                0.7280831336975098,
                0.7675378322601318,
                0.748046338558197,
                0.7313748598098755,
                0.779085636138916,
                0.7045806646347046,
                0.796764612197876,
                0.7772091627120972,
                0.784960925579071,
                0.7623941898345947,
                0.7454371452331543,
                0.7348302006721497,
                0.777358889579773,
                0.7387455105781555,
                0.6973352432250977,
                0.7610413432121277,
                0.8088566064834595,
                0.8442977666854858,
                0.7197983264923096,
                0.6855785846710205,
                0.845317542552948,
                0.7479976415634155,
                0.8536043167114258,
                0.7349094748497009,
                0.6523212194442749,
                0.7902039885520935,
                0.7774317860603333,
                0.5914900898933411,
                0.7886415719985962,
                0.7509628534317017,
                0.5769794583320618,
                0.814583957195282,
                0.7355043888092041,
                0.7899153828620911,
                0.7127162218093872,
                0.6058332920074463,
                0.8463038206100464,
                0.8703657984733582,
                0.6793555617332458,
                0.8622354865074158,
                0.6691821217536926,
                0.8207857608795166,
                0.8469590544700623,
                0.6169470548629761,
                0.7024590969085693,
                0.7862911820411682,
                0.7932524681091309,
                0.7221250534057617,
                0.6004663109779358,
                0.7923034429550171,
                0.7904054522514343
            ],
            [
                0.8380864858627319,
                0.824069082736969,
                0.8175850510597229,
                0.7440770864486694,
                0.793099582195282,
                0.7206476926803589,
                0.8878843188285828,
                0.9149622917175293,
                0.7763707041740417,
                0.8183585405349731,
                0.7835379838943481,
                0.6986035704612732,
                0.8047201633453369,
                0.7578274011611938,
                0.7175053358078003,
                0.7605388164520264,
                0.8214169144630432,
                0.7247745990753174,
                0.6078391671180725,
                0.565125048160553,
                0.7523503303527832,
                0.7365259528160095,
                0.8595978021621704,
                0.8624861240386963,
                0.5932844281196594,
                0.826639711856842,
                0.8657398223876953,
                0.5426588654518127,
                0.823664128780365,
                0.8316308856010437,
                0.5187535881996155,
                0.7733995914459229,
                0.8901636600494385,
                0.8426411151885986,
                0.8518869280815125,
                0.5090345740318298,
                0.7644345760345459,
                0.8192641139030457,
                0.8384157419204712,
                0.8433165550231934,
                0.8655890226364136,
                0.856781542301178,
                0.8457667231559753,
                0.7673755884170532,
                0.6986971497535706,
                0.8323550224304199,
                0.7486779093742371,
                0.814785897731781,
                0.5306478142738342,
                0.8274223208427429,
                0.8361098170280457
            ],
            [
                0.7534743547439575,
                0.795945405960083,
                0.7688271403312683,
                0.7481160163879395,
                0.7811376452445984,
                0.7427091002464294,
                0.8231065273284912,
                0.8282905220985413,
                0.7762308716773987,
                0.7366728782653809,
                0.7396621108055115,
                0.7431005835533142,
                0.7762361168861389,
                0.7650323510169983,
                0.701585054397583,
                0.7520119547843933,
                0.7994092702865601,
                0.7837467789649963,
                0.6874502897262573,
                0.6427605748176575,
                0.8303650617599487,
                0.7801738381385803,
                0.8377425074577332,
                0.7953421473503113,
                0.6344952583312988,
                0.7954203486442566,
                0.809159517288208,
                0.5975000858306885,
                0.8016520738601685,
                0.7686898112297058,
                0.5774274468421936,
                0.8051782846450806,
                0.7867441773414612,
                0.7988830804824829,
                0.7863674759864807,
                0.5508260726928711,
                0.8310672640800476,
                0.8264578580856323,
                0.7421987056732178,
                0.8310451507568359,
                0.712936520576477,
                0.8015972375869751,
                0.8272625207901001,
                0.6781015992164612,
                0.7108309268951416,
                0.8059247136116028,
                0.7951844930648804,
                0.7591083645820618,
                0.5967193841934204,
                0.8033193945884705,
                0.8097222447395325
            ],
            [
                0.7178307771682739,
                0.774261474609375,
                0.7560839056968689,
                0.7507563233375549,
                0.7773138284683228,
                0.7322179079055786,
                0.7913667559623718,
                0.7651625871658325,
                0.7726725935935974,
                0.7105602622032166,
                0.7456166744232178,
                0.7359902858734131,
                0.7734099626541138,
                0.7373602390289307,
                0.7136214971542358,
                0.7762688398361206,
                0.7993478775024414,
                0.8286673426628113,
                0.6850776076316833,
                0.680474579334259,
                0.8690135478973389,
                0.7712083458900452,
                0.8231382369995117,
                0.7277289628982544,
                0.6796053051948547,
                0.793262779712677,
                0.7738417983055115,
                0.6137261390686035,
                0.790664792060852,
                0.7378829121589661,
                0.6152361631393433,
                0.8250756859779358,
                0.7253595590591431,
                0.7703740000724792,
                0.7228858470916748,
                0.5894802808761597,
                0.833466112613678,
                0.8214098215103149,
                0.6821999549865723,
                0.8226399421691895,
                0.6485384106636047,
                0.7810588479042053,
                0.8146487474441528,
                0.6162930727005005,
                0.7013890147209167,
                0.7811022996902466,
                0.7741392254829407,
                0.7199693322181702,
                0.6337562799453735,
                0.795702338218689,
                0.790389358997345
            ],
            [
                0.7327000498771667,
                0.764743447303772,
                0.7021448016166687,
                0.6648303270339966,
                0.7030938267707825,
                0.6871790885925293,
                0.7955909967422485,
                0.8239027857780457,
                0.7356219291687012,
                0.8517464399337769,
                0.7152932286262512,
                0.7020139098167419,
                0.7120398879051208,
                0.6970334649085999,
                0.6319001913070679,
                0.6587555408477783,
                0.8007683157920837,
                0.719045877456665,
                0.6517269611358643,
                0.5914998650550842,
                0.69277024269104,
                0.6666415929794312,
                0.8046436309814453,
                0.8129353523254395,
                0.5609273910522461,
                0.7465359568595886,
                0.8616427183151245,
                0.5208978652954102,
                0.74583899974823,
                0.8666407465934753,
                0.542354941368103,
                0.7444176077842712,
                0.8892022371292114,
                0.7722629308700562,
                0.8462799191474915,
                0.5170973539352417,
                0.704305112361908,
                0.7558202147483826,
                0.7579168081283569,
                0.7661985158920288,
                0.7387562990188599,
                0.7445157766342163,
                0.7607277631759644,
                0.6204355955123901,
                0.6461489796638489,
                0.7592057585716248,
                0.7544448971748352,
                0.8389257788658142,
                0.523118793964386,
                0.7564212679862976,
                0.7672383785247803
            ],
            [
                0.8285942673683167,
                0.8549712896347046,
                0.7874479293823242,
                0.7750426530838013,
                0.8098270297050476,
                0.7513927817344666,
                0.8661367893218994,
                0.9011034369468689,
                0.7965090870857239,
                0.8365835547447205,
                0.7888287305831909,
                0.7464679479598999,
                0.809212863445282,
                0.7690975666046143,
                0.7317156791687012,
                0.7607546448707581,
                0.8385932445526123,
                0.7611459493637085,
                0.6333503127098083,
                0.5986327528953552,
                0.7785443067550659,
                0.7656601667404175,
                0.8478072285652161,
                0.8790925145149231,
                0.6171972751617432,
                0.8207116723060608,
                0.8915076851844788,
                0.575709342956543,
                0.8223176002502441,
                0.8534592390060425,
                0.551155149936676,
                0.7845577597618103,
                0.9065303802490234,
                0.8317984342575073,
                0.8708317279815674,
                0.5296716690063477,
                0.770642101764679,
                0.8107016086578369,
                0.8537262678146362,
                0.8300224542617798,
                0.8637369871139526,
                0.839735209941864,
                0.8278895020484924,
                0.7474139928817749,
                0.7155624628067017,
                0.8226522207260132,
                0.7625126242637634,
                0.8398661613464355,
                0.5607575178146362,
                0.8237879276275635,
                0.8306407928466797
            ],
            [
                0.7209043502807617,
                0.782056450843811,
                0.7355940341949463,
                0.8121641278266907,
                0.845664381980896,
                0.7717593312263489,
                0.8045969605445862,
                0.7583727240562439,
                0.8456697463989258,
                0.7110119462013245,
                0.8169316649436951,
                0.7733085751533508,
                0.8314348459243774,
                0.7661649584770203,
                0.8035253286361694,
                0.8256824016571045,
                0.8232613801956177,
                0.8441219329833984,
                0.734653115272522,
                0.7197433114051819,
                0.8456141948699951,
                0.7944910526275635,
                0.8427492380142212,
                0.7202109694480896,
                0.7339711785316467,
                0.8470574021339417,
                0.7648259997367859,
                0.6741207838058472,
                0.8466607332229614,
                0.7311866879463196,
                0.6495789289474487,
                0.8613269925117493,
                0.7127324938774109,
                0.8225587010383606,
                0.7120707035064697,
                0.649370014667511,
                0.8654842972755432,
                0.8707194924354553,
                0.6865269541740417,
                0.8685567378997803,
                0.653709352016449,
                0.8350494503974915,
                0.8643078207969666,
                0.615280032157898,
                0.7641651630401611,
                0.8223872184753418,
                0.8401061296463013,
                0.7210559248924255,
                0.6863663792610168,
                0.8469662070274353,
                0.8368854522705078
            ],
            [
                0.8615106344223022,
                0.9104968309402466,
                0.8573050498962402,
                0.8284171223640442,
                0.8694477677345276,
                0.7697372436523438,
                0.9027010202407837,
                0.8861656785011292,
                0.8458254337310791,
                0.8111238479614258,
                0.8285517692565918,
                0.7853535413742065,
                0.8742475509643555,
                0.8460073471069336,
                0.7851331233978271,
                0.8215697407722473,
                0.8898881077766418,
                0.8038588166236877,
                0.6514759063720703,
                0.6472486853599548,
                0.8384857773780823,
                0.8199329376220703,
                0.8867530226707458,
                0.8447938561439514,
                0.6999753713607788,
                0.8767312169075012,
                0.8815606832504272,
                0.6508588194847107,
                0.8786035180091858,
                0.8468490839004517,
                0.6089244484901428,
                0.8498944044113159,
                0.8428847789764404,
                0.8760347366333008,
                0.7987475991249084,
                0.6060057878494263,
                0.804771363735199,
                0.8603442907333374,
                0.8077389001846313,
                0.8687763214111328,
                0.7976255416870117,
                0.8606314659118652,
                0.8640923500061035,
                0.6771937012672424,
                0.7516889572143555,
                0.8459112644195557,
                0.8062878251075745,
                0.8264502286911011,
                0.6500900983810425,
                0.8759000897407532,
                0.8701940774917603
            ],
            [
                0.7283793091773987,
                0.797235369682312,
                0.7059378027915955,
                0.7431010007858276,
                0.7865896224975586,
                0.7581215500831604,
                0.7774486541748047,
                0.7367185950279236,
                0.8162441849708557,
                0.7003374695777893,
                0.7674056887626648,
                0.7892431020736694,
                0.7655659317970276,
                0.7152219414710999,
                0.735142707824707,
                0.750465989112854,
                0.8012035489082336,
                0.8215276598930359,
                0.7414810061454773,
                0.7048903703689575,
                0.8054348826408386,
                0.7533829212188721,
                0.807542085647583,
                0.7182497382164001,
                0.7022812962532043,
                0.7923278212547302,
                0.7579259872436523,
                0.6658359169960022,
                0.7975481152534485,
                0.7390569448471069,
                0.6594220995903015,
                0.8109449744224548,
                0.7106216549873352,
                0.7887470126152039,
                0.7130981683731079,
                0.655419111251831,
                0.7870910167694092,
                0.8016679286956787,
                0.6823723912239075,
                0.8164114356040955,
                0.6499072909355164,
                0.7676235437393188,
                0.8099374771118164,
                0.5992017388343811,
                0.7369202971458435,
                0.761911928653717,
                0.8178598880767822,
                0.7494924068450928,
                0.6743342876434326,
                0.7965841889381409,
                0.7974672913551331
            ]
        ]
    ],
    "nb_order": [],
    "summary_data_VA": null
}