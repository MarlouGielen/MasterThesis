{
    "nb_idx": 57,
    "nb_name": "d0057",
    "filename": "titanic-eda-model-pipeline-keras-nn.ipynb",
    "filepath": "data/data_Kaggle/raw/titanic-eda-model-pipeline-keras-nn.ipynb",
    "source": "<h1> Welcome to my Titanic Kernel! </h1>\n<h2>This kernel will provide a analysis through the Titanic Disaster to understand the Survivors patterns</h2><br>\n\nI will handle with data (<i>transform, missings, manipulation</i>), explore the data (<i>descritive and visual</i>) and also create a Deep Learning model \n Are you looking for another interesting Kernels? <a href=\"https://www.kaggle.com/kabure/kernels\">CLICK HERE</a> <br>\nGive me your feedback and if yo like this kernel, votes up \n <i>*I'm from Brazil, so english is not my first language, sorry about some mistakes</i> \n # Table of Contents:\n\n**1. [Introduction](#Introduction)** <br>\n**2. [Librarys](#Librarys)** <br>\n**3. [Knowning the data](#Known)** <br>\n**4. [Exploring some Variables](#Explorations)** <br>\n**5. [Preprocessing](#Prepocess)** <br>\n**6. [Modelling](#Model)** <br>\n**7. [Validation](#Validation)** <br>\n \n <a id=\"Introduction\"></a> <br> \n# **1. Introduction:** \n<h3> The data have 891 entries on train dataset and 418 on test dataset</h3>\n- 10 columns in train_csv and 9 columns in train_test\n \n <h2>Competition Description: </h2>\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n\nOne of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n\nIn this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. \n <h3>Data Dictionary</h3><br>\nVariable\tDefinition\tKey<br>\n<b>survival</b>\tSurvival\t0 = No, 1 = Yes<br>\n<b>pclass</b>\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd<br>\n<b>sex</b>\tSex\t<br>\n<b>Age</b>\tAge in years\t<br>\n<b>sibsp</b>\t# of siblings / spouses aboard the Titanic\t<br>\n<b>parch</b>\t# of parents / children aboard the Titanic\t<br>\n<b>ticket</b>\tTicket number\t<br>\n<b>fare</b>\tPassenger fare\t<br>\n<b>cabin</b>\tCabin number\t<br>\n<b>embarked\t</b>Port of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton<br>\n<h3>Variable Notes</h3><br>\n<b>pclass: </b>A proxy for socio-economic status (SES)<br>\n1st = Upper<br>\n2nd = Middle<br>\n3rd = Lower<br>\n<b>age: </b>Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br>\n<b>sibsp:</b> The dataset defines family relations in this way...<br>\n- <b>Sibling </b>= brother, sister, stepbrother, stepsister<br>\n- <b>Spouse </b>= husband, wife (mistresses and fianc\u00e9s were ignored)<br>\n\n<b>parch: </b>The dataset defines family relations in this way...<br>\n- <b>Parent</b> = mother, father<br>\n- <b>Child </b>= daughter, son, stepdaughter, stepson<br>\n\nSome children travelled only with a nanny, therefore parch=0 for them.<br> \n I am using the beapproachs as possible but if you think I can do anything another best way, please, let me know. \n <a id=\"Librarys\"></a> <br> \n# **2. Librarys:**  \n #This librarys is to work with matrices\nimport pandas as pd \n# This librarys is to work with vectors\nimport numpy as np\n# This library is to create some graphics algorithmn\nimport seaborn as sns\n# to render the graphs\nimport matplotlib.pyplot as plt\n# import module to set some ploting parameters\nfrom matplotlib import rcParams\n# Library to work with Regular Expressions\nimport re\n\n# This function makes the plot directly on browser\n%matplotlib inline\n\n# Seting a universal figure size \nrcParams['figure.figsize'] = 10,8 \n # Importing train dataset\ndf_train = pd.read_csv(\"../input/train.csv\")\n\n# Importing test dataset\ndf_test = pd.read_csv(\"../input/test.csv\") \n <a id=\"Known\"></a> <br> \n# **3. First look at the data:**  \n I will start looking the type and informations of the datasets \n #Looking data format and types\nprint(df_train.info())\n\n# printing test info()\nprint(df_test.info()) \n #Some Statistics\ndf_train.describe() \n #Take a look at the data\nprint(df_train.head()) \n <a id=\"Known\"></a> <br> \n# **4. Exploring the data:**  \n <h2>To try a new approach in the data, I will start the data analysis by the Name column \n #Looking how the data is and searching for a re patterns\ndf_train[\"Name\"].head() \n #GettingLooking the prefix of all Passengers\ndf_train['Title'] = df_train.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\\.', x).group(1))\n\n#defining the figure size of our graphic\nplt.figure(figsize=(12,5))\n\n#Plotting the result\nsns.countplot(x='Title', data=df_train, palette=\"hls\")\nplt.xlabel(\"Title\", fontsize=16) #seting the xtitle and size\nplt.ylabel(\"Count\", fontsize=16) # Seting the ytitle and size\nplt.title(\"Title Name Count\", fontsize=20) \nplt.xticks(rotation=45)\nplt.show() \n #Doing the same on df_test with regular expressions\ndf_test['Title'] = df_test.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\\.', x).group(1)) \n ## Grouping some titles and ploting the results \n #Now, I will identify the social status of each title\n\nTitle_Dictionary = {\n        \"Capt\":       \"Officer\",\n        \"Col\":        \"Officer\",\n        \"Major\":      \"Officer\",\n        \"Dr\":         \"Officer\",\n        \"Rev\":        \"Officer\",\n        \"Jonkheer\":   \"Royalty\",\n        \"Don\":        \"Royalty\",\n        \"Sir\" :       \"Royalty\",\n        \"the Countess\":\"Royalty\",\n        \"Dona\":       \"Royalty\",\n        \"Lady\" :      \"Royalty\",\n        \"Mme\":        \"Mrs\",\n        \"Ms\":         \"Mrs\",\n        \"Mrs\" :       \"Mrs\",\n        \"Mlle\":       \"Miss\",\n        \"Miss\" :      \"Miss\",\n        \"Mr\" :        \"Mr\",\n        \"Master\" :    \"Master\"\n                   }\n    \n# we map each title to correct category\ndf_train['Title'] = df_train.Title.map(Title_Dictionary)\ndf_test['Title'] = df_test.Title.map(Title_Dictionary) \n ## Title grouped \n #printing the chance to survive by each title\nprint(\"Chances to survive based on titles: \") \nprint(df_train.groupby(\"Title\")[\"Survived\"].mean())\n\n# figure size\nplt.figure(figsize=(12,5))\n\n#Plotting the count of title by Survived or not category\nsns.countplot(x='Title', data=df_train, palette=\"hls\",\n              hue=\"Survived\")\nplt.xlabel(\"Titles\", fontsize=16)\nplt.ylabel(\"Count\", fontsize=16)\nplt.title(\"Title Grouped Count\", fontsize=20)\nplt.xticks(rotation=45)\nplt.show() \n It's interesting... Children's and ladys first, huh? \n <h1> Now I will handle the Age variable that has a high number of NaN's, using some columns to correctly input he missing Age's \n #First I will look my distribuition without NaN's\n#I will create a df to look distribuition \nage_high_zero_died = df_train[(df_train[\"Age\"] > 0) & \n                              (df_train[\"Survived\"] == 0)]\nage_high_zero_surv = df_train[(df_train[\"Age\"] > 0) & \n                              (df_train[\"Survived\"] == 1)]\n\n#figure size\nplt.figure(figsize=(10,5))\n\n# Ploting the 2 variables that we create and compare the two\nsns.distplot(age_high_zero_surv[\"Age\"], bins=24, color='g')\nsns.distplot(age_high_zero_died[\"Age\"], bins=24, color='r')\nplt.title(\"Distribuition and density by Age\",fontsize=20)\nplt.xlabel(\"Age\",fontsize=15)\nplt.ylabel(\"Distribuition Died and Survived\",fontsize=15)\nplt.show() \n #Let's group the median age by sex, pclass and title, to have any idea and maybe input in Age NAN's\nage_group = df_train.groupby([\"Sex\",\"Pclass\",\"Title\"])[\"Age\"]\n\n#printing the variabe that we created by median\nprint(age_group.median()) \n This might show us a better way to input the NAN's \n\n<b>For example: </b> an male in 2 class that is a Officer the median Age is 42. <br>\nAnd we will use that to complete the missing data\n \n #inputing the values on Age Na's \n# using the groupby to transform this variables\ndf_train.loc[df_train.Age.isnull(), 'Age'] = df_train.groupby(['Sex','Pclass','Title']).Age.transform('median')\n\n# printing the total of nulls in Age Feature\nprint(df_train[\"Age\"].isnull().sum()) \n #Let's see the result of the inputation\n\n#seting the figure size\nplt.figure(figsize=(12,5))\n\n#ploting again the Age Distribuition after the transformation in our dataset\nsns.distplot(df_train[\"Age\"], bins=24)\nplt.title(\"Distribuition and density by Age\")\nplt.xlabel(\"Age\")\nplt.show() \n #separate by survivors or not\n\n# figure size\nplt.figure(figsize=(12,5))\n\n# using facetgrid that is a great way to get information of our dataset\ng = sns.FacetGrid(df_train, col='Survived',size=5)\ng = g.map(sns.distplot, \"Age\")\nplt.show() \n Now let's categorize them  \n #df_train.Age = df_train.Age.fillna(-0.5)\n\n#creating the intervals that we need to cut each range of ages\ninterval = (0, 5, 12, 18, 25, 35, 60, 120) \n\n#Seting the names that we want use to the categorys\ncats = ['babies', 'Children', 'Teen', 'Student', 'Young', 'Adult', 'Senior']\n\n# Applying the pd.cut and using the parameters that we created \ndf_train[\"Age_cat\"] = pd.cut(df_train.Age, interval, labels=cats)\n\n# Printing the new Category\ndf_train[\"Age_cat\"].head() \n #Do the same to test dataset \ninterval = (0, 5, 12, 18, 25, 35, 60, 120)\n\n#same as the other df train\ncats = ['babies', 'Children', 'Teen', 'Student', 'Young', 'Adult', 'Senior']\n\n# same that we used above in df train\ndf_test[\"Age_cat\"] = pd.cut(df_test.Age, interval, labels=cats) \n #Describe of categorical Age\n\n# Using pd.crosstab to understand the Survived rate by Age Category's\nprint(pd.crosstab(df_train.Age_cat, df_train.Survived))\n\n#Seting the figure size\nplt.figure(figsize=(12,10))\n\n#Plotting the result\nplt.subplot(2,1,1)\nsns.countplot(\"Age_cat\",data=df_train,hue=\"Survived\", palette=\"hls\")\nplt.ylabel(\"Count\", fontsize=18)\nplt.xlabel(\"Age Categorys\", fontsize=18)\nplt.title(\"Age Distribution \", fontsize=20)\n\nplt.subplot(2,1,2)\nsns.swarmplot(x='Age_cat',y=\"Fare\",data=df_train,\n              hue=\"Survived\", palette=\"hls\", )\nplt.ylabel(\"Fare Distribution\", fontsize=18)\nplt.xlabel(\"Age Categorys\", fontsize=18)\nplt.title(\"Fare Distribution by Age Categorys \", fontsize=20)\n\nplt.subplots_adjust(hspace = 0.5, top = 0.9)\n\nplt.show() \n Now it look's better and clearly \n ## Let's cross our Pclass with the Age_cat \nWe will aggregate than to get the mean of Fare by each category pair\n \n Age_fare = ['Pclass', 'Age_cat'] #seting the desired \n\ncm = sns.light_palette(\"green\", as_cmap=True)\npd.crosstab(df_train[Age_fare[0]], df_train[Age_fare[1]], \n            values=df_train['Fare'], aggfunc=['mean']).style.background_gradient(cmap = cm)\n \n - Very interesting. We can see that babies has the highest mean value.  \n ### Looking the Fare distribuition to survivors and not survivors\n \n # Seting the figure size\nplt.figure(figsize=(12,5))\n\n# Understanding the Fare Distribuition \nsns.distplot(df_train[df_train.Survived == 0][\"Fare\"], \n             bins=50, color='r')\nsns.distplot(df_train[df_train.Survived == 1][\"Fare\"], \n             bins=50, color='g')\nplt.title(\"Fare Distribuition by Survived\", fontsize=20)\nplt.xlabel(\"Fare\", fontsize=15)\nplt.ylabel(\"Density\",fontsize=15)\nplt.show() \n <br>\nDescription of Fare variable<br>\n- Min: 0<br>\n- Median: 14.45<br>\n- Mean: 32.20<br>\n- Max: 512.32<br> \n- Std: 49.69<br>\n\n<h3>I will create a categorical variable to treat the Fare expend</h3><br>\nI will use the same technique used in Age but now I will use the quantiles to binning\n\n \n #Filling the NA's with -0.5\ndf_train.Fare = df_train.Fare.fillna(-0.5)\n\n#intervals to categorize\nquant = (-1, 0, 8, 15, 31, 600)\n\n#Labels without input values\nlabel_quants = ['NoInf', 'quart_1', 'quart_2', 'quart_3', 'quart_4']\n\n#doing the cut in fare and puting in a new column\ndf_train[\"Fare_cat\"] = pd.cut(df_train.Fare, quant, labels=label_quants)\n\n#Description of transformation\nprint(pd.crosstab(df_train.Fare_cat, df_train.Survived))\n\nplt.figure(figsize=(12,5))\n\n#Plotting the new feature\nsns.countplot(x=\"Fare_cat\", hue=\"Survived\", data=df_train, palette=\"hls\")\nplt.title(\"Count of survived x Fare expending\",fontsize=20)\nplt.xlabel(\"Fare Cat\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\n\nplt.show() \n # Replicate the same to df_test\ndf_test.Fare = df_test.Fare.fillna(-0.5)\n\nquant = (-1, 0, 8, 15, 31, 1000)\nlabel_quants = ['NoInf', 'quart_1', 'quart_2', 'quart_3', 'quart_4']\n\ndf_test[\"Fare_cat\"] = pd.cut(df_test.Fare, quant, labels=label_quants) \n <h2>To complete this part, I will now work on \"Names\" \n #Now lets drop the variable Fare, Age and ticket that is irrelevant now\ndel df_train[\"Fare\"]\ndel df_train[\"Ticket\"]\ndel df_train[\"Age\"]\ndel df_train[\"Cabin\"]\ndel df_train[\"Name\"]\n\n#same in df_test\ndel df_test[\"Fare\"]\ndel df_test[\"Ticket\"]\ndel df_test[\"Age\"]\ndel df_test[\"Cabin\"]\ndel df_test[\"Name\"] \n #Looking the result of transformations\ndf_train.head() \n <h1>It's looking ok \n Now, lets start explore the data \n # Let see how many people die or survived\nprint(\"Total of Survived or not: \")\nprint(df_train.groupby(\"Survived\")[\"PassengerId\"].count())\n\nplt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Survived\", data=df_train,palette=\"hls\")\nplt.title('Total Distribuition by survived or not', fontsize=22)\nplt.xlabel('Target Distribuition', fontsize=18)\nplt.ylabel('Count', fontsize=18)\n\nplt.show() \n print(pd.crosstab(df_train.Survived, df_train.Sex))\n\nplt.figure(figsize=(12,5))\nsns.countplot(x=\"Sex\", data=df_train, hue=\"Survived\",palette=\"hls\")\nplt.title('Sex Distribuition by survived or not', fontsize=20)\nplt.xlabel('Sex Distribuition',fontsize=17)\nplt.ylabel('Count', fontsize=17)\n\nplt.show() \n <h2>We can look that % dies to mens are much higher than female \n <h1>Now, lets do some exploration in Pclass and Embarked to see if might have some information to build the model \n # Distribuition by class\nprint(pd.crosstab(df_train.Pclass, df_train.Embarked))\n\nplt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Embarked\", data=df_train, hue=\"Pclass\",palette=\"hls\")\nplt.title('Embarked x Pclass Count', fontsize=20)\nplt.xlabel('Embarked with PClass',fontsize=17)\nplt.ylabel('Count', fontsize=17)\n\nplt.show() \n #lets input the NA's with the highest frequency\ndf_train[\"Embarked\"] = df_train[\"Embarked\"].fillna('S') \n # Exploring Survivors vs Embarked\nprint(pd.crosstab(df_train.Survived, df_train.Embarked))\n\nplt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Embarked\", data=df_train, hue=\"Survived\",palette=\"hls\")\nplt.title('Class Distribuition by survived or not',fontsize=20)\nplt.xlabel('Embarked',fontsize=17)\nplt.ylabel('Count', fontsize=17)\n\nplt.show() \n # Exploring Survivors vs Pclass\nprint(pd.crosstab(df_train.Survived, df_train.Pclass))\n\nplt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Pclass\", data=df_train, hue=\"Survived\",palette=\"hls\")\nplt.xlabel('PClass',fontsize=17)\nplt.ylabel('Count', fontsize=17)\nplt.title('Class Distribuition by Survived or not', fontsize=20)\n\nplt.show() \n <b>Looking the graphs, is clear that 3st class and Embarked at Southampton have a high probabilities to not survive</b> \n To finish the analysis I let's look the Sibsp and Parch variables \n g = sns.factorplot(x=\"SibSp\",y=\"Survived\",data=df_train,\n                   kind=\"bar\", height = 5, aspect= 1.6, palette = \"hls\")\ng.set_ylabels(\"Probability(Survive)\", fontsize=15)\ng.set_xlabels(\"SibSp Number\", fontsize=15)\n\nplt.show()\n \n f \n Interesting. With 1 or 2 siblings/spouses have more chance to survived the disaster \n # Explore Parch feature vs Survived\ng  = sns.factorplot(x=\"Parch\",y=\"Survived\",data=df_train, kind=\"bar\", size = 6,palette = \"hls\")\ng = g.set_ylabels(\"survival probability\") \n We can see a high standard deviation in the survival with 3 parents/children person's <br>\nAlso that small families (1~2) have more chance to survival than single or big families \n So to Finish our exploration I will create a new column to with familiees size \n #Create a new column and sum the Parch + SibSp + 1 that refers the people self\ndf_train[\"FSize\"] = df_train[\"Parch\"] + df_train[\"SibSp\"] + 1\n\ndf_test[\"FSize\"] = df_test[\"Parch\"] + df_test[\"SibSp\"] + 1 \n print(pd.crosstab(df_train.FSize, df_train.Survived))\nsns.factorplot(x=\"FSize\",y=\"Survived\", data=df_train, kind=\"bar\",size=6, aspect=1.6)\nplt.show() \n del df_train[\"SibSp\"]\ndel df_train[\"Parch\"]\n\ndel df_test[\"SibSp\"]\ndel df_test[\"Parch\"] \n OK, its might be enough to start with the preprocess and builting the model\n \n <a id=\"Preprocess\"></a> <br> \n# **5. Preprocessing :**  \n df_train.head() \n Now we might have information enough to think about the model structure \n df_train = pd.get_dummies(df_train, columns=[\"Sex\",\"Embarked\",\"Age_cat\",\"Fare_cat\",\"Title\"],\\\n                          prefix=[\"Sex\",\"Emb\",\"Age\",\"Fare\",\"Prefix\"], drop_first=True)\n\ndf_test = pd.get_dummies(df_test, columns=[\"Sex\",\"Embarked\",\"Age_cat\",\"Fare_cat\",\"Title\"],\\\n                         prefix=[\"Sex\",\"Emb\",\"Age\",\"Fare\",\"Prefix\"], drop_first=True) \n #Finallt, lets look the correlation of df_train\nplt.figure(figsize=(15,12))\nplt.title('Correlation of Features for Train Set')\nsns.heatmap(df_train.astype(float).corr(),vmax=1.0,  annot=True)\nplt.show() \n df_train.shape \n train = df_train.drop([\"Survived\",\"PassengerId\"],axis=1)\ntrain_ = df_train[\"Survived\"]\n\ntest_ = df_test.drop([\"PassengerId\"],axis=1)\n\nX_train = train.values\ny_train = train_.values\n\nX_test = test_.values\nX_test = X_test.astype(np.float64, copy=False) \n # Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test) \n <a id=\"Model\"></a> <br> \n# **6. Modelling : **  \n <h3>Titanic survivors prediction: <br>\na binary classification example</h3>\nTwo-class classification, or binary classification, may be the most widely applied kind of machine-learning problem. \n from keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nimport keras\nfrom keras.optimizers import SGD\nimport graphviz \n <h1>Anatomy of a neural network: </h1>\n\nAs you saw in the previous chapters, training a neural network revolves around the following\nobjects:\n- Layers, which are combined into a network (or model)\n- The input data and corresponding targets\n- The loss function, which defines the feedback signal used for learning\n- The optimizer, which determines how learning proceeds\n\n\n\n\n<h2> Layers: the building blocks of deep learning</h2>\nfrom keras import layers<br>\nlayer = layers.Dense(32, input_dim=data_dimension)) \n\n- We can think of layers as the LEGO bricks of deep learning, a metaphor that is\nmade explicit by frameworks like Keras. Building deep-learning models in Keras is\ndone by clipping together compatible layers to form useful data-transformation pipelines.\n\n\n<h2>What are activation functions, and why are they necessary?</h2>\nWithout an activation function like relu (also called a non-linearity), the Dense layer would consist of two linear operations\u2014a dot product and an addition: <br><br>\n<i>output = dot(W, input) + b</i><br><br>\n\nSo the layer could only learn linear transformations (affine transformations) of the\ninput data: the hypothesis space of the layer would be the set of all possible linear\ntransformations of the input data into a 16-dimensional space. \n\n\n<h2>Loss functions and optimizers:<br>\nkeys to configuring the learning process</h2>\nOnce the network architecture is defined, you still have to choose two more things:\n- <b>Loss function (objective function) </b>- The quantity that will be minimized during\ntraining. It represents a measure of success for the task at hand.\n- <b>Optimizer</b> - Determines how the network will be updated based on the loss function.\nIt implements a specific variant of stochastic gradient descent (SGD). \n # Creating the model\nmodel = Sequential()\n\n# Inputing the first layer with input dimensions\nmodel.add(Dense(18, \n                activation='relu',  \n                input_dim=20,\n                kernel_initializer='uniform'))\n#The argument being passed to each Dense layer (18) is the number of hidden units of the layer. \n# A hidden unit is a dimension in the representation space of the layer.\n\n#Stacks of Dense layers with relu activations can solve a wide range of problems\n#(including sentiment classification), and you\u2019ll likely use them frequently.\n\n# Adding an Dropout layer to previne from overfitting\nmodel.add(Dropout(0.50))\n\n#adding second hidden layer \nmodel.add(Dense(60,\n                kernel_initializer='uniform',\n                activation='relu'))\n\n# Adding another Dropout layer\nmodel.add(Dropout(0.50))\n\n# adding the output layer that is binary [0,1]\nmodel.add(Dense(1,\n                kernel_initializer='uniform',\n                activation='sigmoid'))\n#With such a scalar sigmoid output on a binary classification problem, the loss\n#function you should use is binary_crossentropy\n\n#Visualizing the model\nmodel.summary() \n Stacks of Dense layers with relu activations can solve a wide range of problems (including sentiment classification), and you\u2019ll likely use them frequently. \n Finally, we need to choose a loss function and an optimizer.  \n #Creating an Stochastic Gradient Descent\nsgd = SGD(lr = 0.01, momentum = 0.9)\n\n# Compiling our model\nmodel.compile(optimizer = sgd, \n                   loss = 'binary_crossentropy', \n                   metrics = ['accuracy'])\n#optimizers list\n#optimizers['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n\n# Fitting the ANN to the Training set\nmodel.fit(X_train, y_train, \n               batch_size = 60, \n               epochs = 30, verbose=2) \n Because you\u2019re facing a binary classification problem and the output of your network is a probability (you end your network with a single-unit layer with a sigmoid activation), it\u2019s best to use the <i>binary_crossentropy</i> loss. \n ## Predicting X_test \n y_preds = model.predict(X_test)\n\nsubmission = pd.read_csv(\"../input/gender_submission.csv\", index_col='PassengerId')\nsubmission['Survived'] = y_preds.astype(int)\nsubmission.to_csv('TitanicKNN.csv') \n <h1>Evaluating the model</h1> \n scores = model.evaluate(X_train, y_train, batch_size=30)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100)) \n Not bad result to a simple model! Let's now verify the validation of our model, to see and understand the learning curve \n <a id=\"Validation\"></a> <br> \n# **7. Validation: **  \n # Fit the model\nhistory = model.fit(X_train, y_train, validation_split=0.20, \n                    epochs=180, batch_size=10, verbose=0)\n\n# list all data in history\nprint(history.history.keys()) \n Let's look this keys values further \n # summarizing historical accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n \n Why this occurs and how to solve this problem in graph? it's a overffiting?  \n \n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show() \n y_pred = model.predict(X_test) \n <h1>It's my first Deep Learning implementation... I am studying about this and I will continue editing this Kernel to improve the results</h1> \n Give me your feedback how can I increase this model =)  \n # Trying to implementing the TensorBoard to evaluate the model\n\ncallbacks = [\n    keras.callbacks.TensorBoard(log_dir='my_log_dir',\n                                histogram_freq=1,\n                                embeddings_freq=1,\n                               )\n] \n #Importing the auxiliar and preprocessing librarys \nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate\nfrom sklearn.metrics import accuracy_score\n\n#Models\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import RidgeClassifier, SGDClassifier, LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, VotingClassifier, RandomTreesEmbedding \n clfs = []\nseed = 3\n\nclfs.append((\"LogReg\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"LogReg\", LogisticRegression())])))\n\nclfs.append((\"XGBClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"XGB\", XGBClassifier())]))) \nclfs.append((\"KNN\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"KNN\", KNeighborsClassifier())]))) \n\nclfs.append((\"DecisionTreeClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"DecisionTrees\", DecisionTreeClassifier())]))) \n\nclfs.append((\"RandomForestClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"RandomForest\", RandomForestClassifier())]))) \n\nclfs.append((\"GradientBoostingClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"GradientBoosting\", GradientBoostingClassifier(max_features=15, n_estimators=150))]))) \n\nclfs.append((\"RidgeClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"RidgeClassifier\", RidgeClassifier())])))\n\nclfs.append((\"BaggingRidgeClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"BaggingClassifier\", BaggingClassifier())])))\n\nclfs.append((\"ExtraTreesClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"ExtraTrees\", ExtraTreesClassifier())])))\n\n#'neg_mean_absolute_error', 'neg_mean_squared_error','r2'\nscoring = 'accuracy'\nn_folds = 10\n\nresults, names  = [], [] \n\nfor name, model  in clfs:\n    kfold = KFold(n_splits=n_folds, random_state=seed)\n    cv_results = cross_val_score(model, X_train, y_train, cv= 5, scoring=scoring, n_jobs=-1)    \n    names.append(name)\n    results.append(cv_results)    \n    msg = \"%s: %f (+/- %f)\" % (name, cv_results.mean(),  cv_results.std())\n    print(msg)\n    \n# boxplot algorithm comparison\nfig = plt.figure(figsize=(15,6))\nfig.suptitle('Classifier Algorithm Comparison', fontsize=22)\nax = fig.add_subplot(111)\nsns.boxplot(x=names, y=results)\nax.set_xticklabels(names)\nax.set_xlabel(\"Algorithmn\", fontsize=20)\nax.set_ylabel(\"Accuracy of Models\", fontsize=18)\nax.set_xticklabels(ax.get_xticklabels(),rotation=45)\nplt.show() \n # Stay tuned and don't forget to votesup this kernel",
    "code_source": "#This librarys is to work with matrices\nimport pandas as pd \n# This librarys is to work with vectors\nimport numpy as np\n# This library is to create some graphics algorithmn\nimport seaborn as sns\n# to render the graphs\nimport matplotlib.pyplot as plt\n# import module to set some ploting parameters\nfrom matplotlib import rcParams\n# Library to work with Regular Expressions\nimport re\n\n# This function makes the plot directly on browser\n%matplotlib inline\n\n# Seting a universal figure size \nrcParams['figure.figsize'] = 10,8 \n # Importing train dataset\ndf_train = pd.read_csv(\"../input/train.csv\")\n\n# Importing test dataset\ndf_test = pd.read_csv(\"../input/test.csv\") \n #Looking data format and types\nprint(df_train.info())\n\n# printing test info()\nprint(df_test.info()) \n #Some Statistics\ndf_train.describe() \n #Take a look at the data\nprint(df_train.head()) \n #Looking how the data is and searching for a re patterns\ndf_train[\"Name\"].head() \n #GettingLooking the prefix of all Passengers\ndf_train['Title'] = df_train.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\\.', x).group(1))\n\n#defining the figure size of our graphic\nplt.figure(figsize=(12,5))\n\n#Plotting the result\nsns.countplot(x='Title', data=df_train, palette=\"hls\")\nplt.xlabel(\"Title\", fontsize=16) #seting the xtitle and size\nplt.ylabel(\"Count\", fontsize=16) # Seting the ytitle and size\nplt.title(\"Title Name Count\", fontsize=20) \nplt.xticks(rotation=45)\nplt.show() \n #Doing the same on df_test with regular expressions\ndf_test['Title'] = df_test.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\\.', x).group(1)) \n #Now, I will identify the social status of each title\n\nTitle_Dictionary = {\n        \"Capt\":       \"Officer\",\n        \"Col\":        \"Officer\",\n        \"Major\":      \"Officer\",\n        \"Dr\":         \"Officer\",\n        \"Rev\":        \"Officer\",\n        \"Jonkheer\":   \"Royalty\",\n        \"Don\":        \"Royalty\",\n        \"Sir\" :       \"Royalty\",\n        \"the Countess\":\"Royalty\",\n        \"Dona\":       \"Royalty\",\n        \"Lady\" :      \"Royalty\",\n        \"Mme\":        \"Mrs\",\n        \"Ms\":         \"Mrs\",\n        \"Mrs\" :       \"Mrs\",\n        \"Mlle\":       \"Miss\",\n        \"Miss\" :      \"Miss\",\n        \"Mr\" :        \"Mr\",\n        \"Master\" :    \"Master\"\n                   }\n    \n# we map each title to correct category\ndf_train['Title'] = df_train.Title.map(Title_Dictionary)\ndf_test['Title'] = df_test.Title.map(Title_Dictionary) \n #printing the chance to survive by each title\nprint(\"Chances to survive based on titles: \") \nprint(df_train.groupby(\"Title\")[\"Survived\"].mean())\n\n# figure size\nplt.figure(figsize=(12,5))\n\n#Plotting the count of title by Survived or not category\nsns.countplot(x='Title', data=df_train, palette=\"hls\",\n              hue=\"Survived\")\nplt.xlabel(\"Titles\", fontsize=16)\nplt.ylabel(\"Count\", fontsize=16)\nplt.title(\"Title Grouped Count\", fontsize=20)\nplt.xticks(rotation=45)\nplt.show() \n #First I will look my distribuition without NaN's\n#I will create a df to look distribuition \nage_high_zero_died = df_train[(df_train[\"Age\"] > 0) & \n                              (df_train[\"Survived\"] == 0)]\nage_high_zero_surv = df_train[(df_train[\"Age\"] > 0) & \n                              (df_train[\"Survived\"] == 1)]\n\n#figure size\nplt.figure(figsize=(10,5))\n\n# Ploting the 2 variables that we create and compare the two\nsns.distplot(age_high_zero_surv[\"Age\"], bins=24, color='g')\nsns.distplot(age_high_zero_died[\"Age\"], bins=24, color='r')\nplt.title(\"Distribuition and density by Age\",fontsize=20)\nplt.xlabel(\"Age\",fontsize=15)\nplt.ylabel(\"Distribuition Died and Survived\",fontsize=15)\nplt.show() \n #Let's group the median age by sex, pclass and title, to have any idea and maybe input in Age NAN's\nage_group = df_train.groupby([\"Sex\",\"Pclass\",\"Title\"])[\"Age\"]\n\n#printing the variabe that we created by median\nprint(age_group.median()) \n #inputing the values on Age Na's \n# using the groupby to transform this variables\ndf_train.loc[df_train.Age.isnull(), 'Age'] = df_train.groupby(['Sex','Pclass','Title']).Age.transform('median')\n\n# printing the total of nulls in Age Feature\nprint(df_train[\"Age\"].isnull().sum()) \n #Let's see the result of the inputation\n\n#seting the figure size\nplt.figure(figsize=(12,5))\n\n#ploting again the Age Distribuition after the transformation in our dataset\nsns.distplot(df_train[\"Age\"], bins=24)\nplt.title(\"Distribuition and density by Age\")\nplt.xlabel(\"Age\")\nplt.show() \n #separate by survivors or not\n\n# figure size\nplt.figure(figsize=(12,5))\n\n# using facetgrid that is a great way to get information of our dataset\ng = sns.FacetGrid(df_train, col='Survived',size=5)\ng = g.map(sns.distplot, \"Age\")\nplt.show() \n #df_train.Age = df_train.Age.fillna(-0.5)\n\n#creating the intervals that we need to cut each range of ages\ninterval = (0, 5, 12, 18, 25, 35, 60, 120) \n\n#Seting the names that we want use to the categorys\ncats = ['babies', 'Children', 'Teen', 'Student', 'Young', 'Adult', 'Senior']\n\n# Applying the pd.cut and using the parameters that we created \ndf_train[\"Age_cat\"] = pd.cut(df_train.Age, interval, labels=cats)\n\n# Printing the new Category\ndf_train[\"Age_cat\"].head() \n #Do the same to test dataset \ninterval = (0, 5, 12, 18, 25, 35, 60, 120)\n\n#same as the other df train\ncats = ['babies', 'Children', 'Teen', 'Student', 'Young', 'Adult', 'Senior']\n\n# same that we used above in df train\ndf_test[\"Age_cat\"] = pd.cut(df_test.Age, interval, labels=cats) \n #Describe of categorical Age\n\n# Using pd.crosstab to understand the Survived rate by Age Category's\nprint(pd.crosstab(df_train.Age_cat, df_train.Survived))\n\n#Seting the figure size\nplt.figure(figsize=(12,10))\n\n#Plotting the result\nplt.subplot(2,1,1)\nsns.countplot(\"Age_cat\",data=df_train,hue=\"Survived\", palette=\"hls\")\nplt.ylabel(\"Count\", fontsize=18)\nplt.xlabel(\"Age Categorys\", fontsize=18)\nplt.title(\"Age Distribution \", fontsize=20)\n\nplt.subplot(2,1,2)\nsns.swarmplot(x='Age_cat',y=\"Fare\",data=df_train,\n              hue=\"Survived\", palette=\"hls\", )\nplt.ylabel(\"Fare Distribution\", fontsize=18)\nplt.xlabel(\"Age Categorys\", fontsize=18)\nplt.title(\"Fare Distribution by Age Categorys \", fontsize=20)\n\nplt.subplots_adjust(hspace = 0.5, top = 0.9)\n\nplt.show() \n Age_fare = ['Pclass', 'Age_cat'] #seting the desired \n\ncm = sns.light_palette(\"green\", as_cmap=True)\npd.crosstab(df_train[Age_fare[0]], df_train[Age_fare[1]], \n            values=df_train['Fare'], aggfunc=['mean']).style.background_gradient(cmap = cm)\n \n # Seting the figure size\nplt.figure(figsize=(12,5))\n\n# Understanding the Fare Distribuition \nsns.distplot(df_train[df_train.Survived == 0][\"Fare\"], \n             bins=50, color='r')\nsns.distplot(df_train[df_train.Survived == 1][\"Fare\"], \n             bins=50, color='g')\nplt.title(\"Fare Distribuition by Survived\", fontsize=20)\nplt.xlabel(\"Fare\", fontsize=15)\nplt.ylabel(\"Density\",fontsize=15)\nplt.show() \n #Filling the NA's with -0.5\ndf_train.Fare = df_train.Fare.fillna(-0.5)\n\n#intervals to categorize\nquant = (-1, 0, 8, 15, 31, 600)\n\n#Labels without input values\nlabel_quants = ['NoInf', 'quart_1', 'quart_2', 'quart_3', 'quart_4']\n\n#doing the cut in fare and puting in a new column\ndf_train[\"Fare_cat\"] = pd.cut(df_train.Fare, quant, labels=label_quants)\n\n#Description of transformation\nprint(pd.crosstab(df_train.Fare_cat, df_train.Survived))\n\nplt.figure(figsize=(12,5))\n\n#Plotting the new feature\nsns.countplot(x=\"Fare_cat\", hue=\"Survived\", data=df_train, palette=\"hls\")\nplt.title(\"Count of survived x Fare expending\",fontsize=20)\nplt.xlabel(\"Fare Cat\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\n\nplt.show() \n # Replicate the same to df_test\ndf_test.Fare = df_test.Fare.fillna(-0.5)\n\nquant = (-1, 0, 8, 15, 31, 1000)\nlabel_quants = ['NoInf', 'quart_1', 'quart_2', 'quart_3', 'quart_4']\n\ndf_test[\"Fare_cat\"] = pd.cut(df_test.Fare, quant, labels=label_quants) \n #Now lets drop the variable Fare, Age and ticket that is irrelevant now\ndel df_train[\"Fare\"]\ndel df_train[\"Ticket\"]\ndel df_train[\"Age\"]\ndel df_train[\"Cabin\"]\ndel df_train[\"Name\"]\n\n#same in df_test\ndel df_test[\"Fare\"]\ndel df_test[\"Ticket\"]\ndel df_test[\"Age\"]\ndel df_test[\"Cabin\"]\ndel df_test[\"Name\"] \n #Looking the result of transformations\ndf_train.head() \n # Let see how many people die or survived\nprint(\"Total of Survived or not: \")\nprint(df_train.groupby(\"Survived\")[\"PassengerId\"].count())\n\nplt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Survived\", data=df_train,palette=\"hls\")\nplt.title('Total Distribuition by survived or not', fontsize=22)\nplt.xlabel('Target Distribuition', fontsize=18)\nplt.ylabel('Count', fontsize=18)\n\nplt.show() \n print(pd.crosstab(df_train.Survived, df_train.Sex))\n\nplt.figure(figsize=(12,5))\nsns.countplot(x=\"Sex\", data=df_train, hue=\"Survived\",palette=\"hls\")\nplt.title('Sex Distribuition by survived or not', fontsize=20)\nplt.xlabel('Sex Distribuition',fontsize=17)\nplt.ylabel('Count', fontsize=17)\n\nplt.show() \n # Distribuition by class\nprint(pd.crosstab(df_train.Pclass, df_train.Embarked))\n\nplt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Embarked\", data=df_train, hue=\"Pclass\",palette=\"hls\")\nplt.title('Embarked x Pclass Count', fontsize=20)\nplt.xlabel('Embarked with PClass',fontsize=17)\nplt.ylabel('Count', fontsize=17)\n\nplt.show() \n #lets input the NA's with the highest frequency\ndf_train[\"Embarked\"] = df_train[\"Embarked\"].fillna('S') \n # Exploring Survivors vs Embarked\nprint(pd.crosstab(df_train.Survived, df_train.Embarked))\n\nplt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Embarked\", data=df_train, hue=\"Survived\",palette=\"hls\")\nplt.title('Class Distribuition by survived or not',fontsize=20)\nplt.xlabel('Embarked',fontsize=17)\nplt.ylabel('Count', fontsize=17)\n\nplt.show() \n # Exploring Survivors vs Pclass\nprint(pd.crosstab(df_train.Survived, df_train.Pclass))\n\nplt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Pclass\", data=df_train, hue=\"Survived\",palette=\"hls\")\nplt.xlabel('PClass',fontsize=17)\nplt.ylabel('Count', fontsize=17)\nplt.title('Class Distribuition by Survived or not', fontsize=20)\n\nplt.show() \n g = sns.factorplot(x=\"SibSp\",y=\"Survived\",data=df_train,\n                   kind=\"bar\", height = 5, aspect= 1.6, palette = \"hls\")\ng.set_ylabels(\"Probability(Survive)\", fontsize=15)\ng.set_xlabels(\"SibSp Number\", fontsize=15)\n\nplt.show()\n \n f \n # Explore Parch feature vs Survived\ng  = sns.factorplot(x=\"Parch\",y=\"Survived\",data=df_train, kind=\"bar\", size = 6,palette = \"hls\")\ng = g.set_ylabels(\"survival probability\") \n #Create a new column and sum the Parch + SibSp + 1 that refers the people self\ndf_train[\"FSize\"] = df_train[\"Parch\"] + df_train[\"SibSp\"] + 1\n\ndf_test[\"FSize\"] = df_test[\"Parch\"] + df_test[\"SibSp\"] + 1 \n print(pd.crosstab(df_train.FSize, df_train.Survived))\nsns.factorplot(x=\"FSize\",y=\"Survived\", data=df_train, kind=\"bar\",size=6, aspect=1.6)\nplt.show() \n del df_train[\"SibSp\"]\ndel df_train[\"Parch\"]\n\ndel df_test[\"SibSp\"]\ndel df_test[\"Parch\"] \n df_train.head() \n df_train = pd.get_dummies(df_train, columns=[\"Sex\",\"Embarked\",\"Age_cat\",\"Fare_cat\",\"Title\"],\\\n                          prefix=[\"Sex\",\"Emb\",\"Age\",\"Fare\",\"Prefix\"], drop_first=True)\n\ndf_test = pd.get_dummies(df_test, columns=[\"Sex\",\"Embarked\",\"Age_cat\",\"Fare_cat\",\"Title\"],\\\n                         prefix=[\"Sex\",\"Emb\",\"Age\",\"Fare\",\"Prefix\"], drop_first=True) \n #Finallt, lets look the correlation of df_train\nplt.figure(figsize=(15,12))\nplt.title('Correlation of Features for Train Set')\nsns.heatmap(df_train.astype(float).corr(),vmax=1.0,  annot=True)\nplt.show() \n df_train.shape \n train = df_train.drop([\"Survived\",\"PassengerId\"],axis=1)\ntrain_ = df_train[\"Survived\"]\n\ntest_ = df_test.drop([\"PassengerId\"],axis=1)\n\nX_train = train.values\ny_train = train_.values\n\nX_test = test_.values\nX_test = X_test.astype(np.float64, copy=False) \n # Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test) \n from keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nimport keras\nfrom keras.optimizers import SGD\nimport graphviz \n # Creating the model\nmodel = Sequential()\n\n# Inputing the first layer with input dimensions\nmodel.add(Dense(18, \n                activation='relu',  \n                input_dim=20,\n                kernel_initializer='uniform'))\n#The argument being passed to each Dense layer (18) is the number of hidden units of the layer. \n# A hidden unit is a dimension in the representation space of the layer.\n\n#Stacks of Dense layers with relu activations can solve a wide range of problems\n#(including sentiment classification), and you\u2019ll likely use them frequently.\n\n# Adding an Dropout layer to previne from overfitting\nmodel.add(Dropout(0.50))\n\n#adding second hidden layer \nmodel.add(Dense(60,\n                kernel_initializer='uniform',\n                activation='relu'))\n\n# Adding another Dropout layer\nmodel.add(Dropout(0.50))\n\n# adding the output layer that is binary [0,1]\nmodel.add(Dense(1,\n                kernel_initializer='uniform',\n                activation='sigmoid'))\n#With such a scalar sigmoid output on a binary classification problem, the loss\n#function you should use is binary_crossentropy\n\n#Visualizing the model\nmodel.summary() \n #Creating an Stochastic Gradient Descent\nsgd = SGD(lr = 0.01, momentum = 0.9)\n\n# Compiling our model\nmodel.compile(optimizer = sgd, \n                   loss = 'binary_crossentropy', \n                   metrics = ['accuracy'])\n#optimizers list\n#optimizers['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n\n# Fitting the ANN to the Training set\nmodel.fit(X_train, y_train, \n               batch_size = 60, \n               epochs = 30, verbose=2) \n y_preds = model.predict(X_test)\n\nsubmission = pd.read_csv(\"../input/gender_submission.csv\", index_col='PassengerId')\nsubmission['Survived'] = y_preds.astype(int)\nsubmission.to_csv('TitanicKNN.csv') \n scores = model.evaluate(X_train, y_train, batch_size=30)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100)) \n # Fit the model\nhistory = model.fit(X_train, y_train, validation_split=0.20, \n                    epochs=180, batch_size=10, verbose=0)\n\n# list all data in history\nprint(history.history.keys()) \n # summarizing historical accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n \n \n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show() \n y_pred = model.predict(X_test) \n # Trying to implementing the TensorBoard to evaluate the model\n\ncallbacks = [\n    keras.callbacks.TensorBoard(log_dir='my_log_dir',\n                                histogram_freq=1,\n                                embeddings_freq=1,\n                               )\n] \n #Importing the auxiliar and preprocessing librarys \nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate\nfrom sklearn.metrics import accuracy_score\n\n#Models\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import RidgeClassifier, SGDClassifier, LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, VotingClassifier, RandomTreesEmbedding \n clfs = []\nseed = 3\n\nclfs.append((\"LogReg\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"LogReg\", LogisticRegression())])))\n\nclfs.append((\"XGBClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"XGB\", XGBClassifier())]))) \nclfs.append((\"KNN\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"KNN\", KNeighborsClassifier())]))) \n\nclfs.append((\"DecisionTreeClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"DecisionTrees\", DecisionTreeClassifier())]))) \n\nclfs.append((\"RandomForestClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"RandomForest\", RandomForestClassifier())]))) \n\nclfs.append((\"GradientBoostingClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"GradientBoosting\", GradientBoostingClassifier(max_features=15, n_estimators=150))]))) \n\nclfs.append((\"RidgeClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"RidgeClassifier\", RidgeClassifier())])))\n\nclfs.append((\"BaggingRidgeClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"BaggingClassifier\", BaggingClassifier())])))\n\nclfs.append((\"ExtraTreesClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"ExtraTrees\", ExtraTreesClassifier())])))\n\n#'neg_mean_absolute_error', 'neg_mean_squared_error','r2'\nscoring = 'accuracy'\nn_folds = 10\n\nresults, names  = [], [] \n\nfor name, model  in clfs:\n    kfold = KFold(n_splits=n_folds, random_state=seed)\n    cv_results = cross_val_score(model, X_train, y_train, cv= 5, scoring=scoring, n_jobs=-1)    \n    names.append(name)\n    results.append(cv_results)    \n    msg = \"%s: %f (+/- %f)\" % (name, cv_results.mean(),  cv_results.std())\n    print(msg)\n    \n# boxplot algorithm comparison\nfig = plt.figure(figsize=(15,6))\nfig.suptitle('Classifier Algorithm Comparison', fontsize=22)\nax = fig.add_subplot(111)\nsns.boxplot(x=names, y=results)\nax.set_xticklabels(names)\nax.set_xlabel(\"Algorithmn\", fontsize=20)\nax.set_ylabel(\"Accuracy of Models\", fontsize=18)\nax.set_xticklabels(ax.get_xticklabels(),rotation=45)\nplt.show()",
    "markdown_source": "<h1> Welcome to my Titanic Kernel! </h1>\n<h2>This kernel will provide a analysis through the Titanic Disaster to understand the Survivors patterns</h2><br>\n\nI will handle with data (<i>transform, missings, manipulation</i>), explore the data (<i>descritive and visual</i>) and also create a Deep Learning model \n Are you looking for another interesting Kernels? <a href=\"https://www.kaggle.com/kabure/kernels\">CLICK HERE</a> <br>\nGive me your feedback and if yo like this kernel, votes up \n <i>*I'm from Brazil, so english is not my first language, sorry about some mistakes</i> \n # Table of Contents:\n\n**1. [Introduction](#Introduction)** <br>\n**2. [Librarys](#Librarys)** <br>\n**3. [Knowning the data](#Known)** <br>\n**4. [Exploring some Variables](#Explorations)** <br>\n**5. [Preprocessing](#Prepocess)** <br>\n**6. [Modelling](#Model)** <br>\n**7. [Validation](#Validation)** <br>\n \n <a id=\"Introduction\"></a> <br> \n# **1. Introduction:** \n<h3> The data have 891 entries on train dataset and 418 on test dataset</h3>\n- 10 columns in train_csv and 9 columns in train_test\n \n <h2>Competition Description: </h2>\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n\nOne of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n\nIn this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy. \n <h3>Data Dictionary</h3><br>\nVariable\tDefinition\tKey<br>\n<b>survival</b>\tSurvival\t0 = No, 1 = Yes<br>\n<b>pclass</b>\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd<br>\n<b>sex</b>\tSex\t<br>\n<b>Age</b>\tAge in years\t<br>\n<b>sibsp</b>\t# of siblings / spouses aboard the Titanic\t<br>\n<b>parch</b>\t# of parents / children aboard the Titanic\t<br>\n<b>ticket</b>\tTicket number\t<br>\n<b>fare</b>\tPassenger fare\t<br>\n<b>cabin</b>\tCabin number\t<br>\n<b>embarked\t</b>Port of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton<br>\n<h3>Variable Notes</h3><br>\n<b>pclass: </b>A proxy for socio-economic status (SES)<br>\n1st = Upper<br>\n2nd = Middle<br>\n3rd = Lower<br>\n<b>age: </b>Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br>\n<b>sibsp:</b> The dataset defines family relations in this way...<br>\n- <b>Sibling </b>= brother, sister, stepbrother, stepsister<br>\n- <b>Spouse </b>= husband, wife (mistresses and fianc\u00e9s were ignored)<br>\n\n<b>parch: </b>The dataset defines family relations in this way...<br>\n- <b>Parent</b> = mother, father<br>\n- <b>Child </b>= daughter, son, stepdaughter, stepson<br>\n\nSome children travelled only with a nanny, therefore parch=0 for them.<br> \n I am using the beapproachs as possible but if you think I can do anything another best way, please, let me know. \n <a id=\"Librarys\"></a> <br> \n# **2. Librarys:**  \n <a id=\"Known\"></a> <br> \n# **3. First look at the data:**  \n I will start looking the type and informations of the datasets \n <a id=\"Known\"></a> <br> \n# **4. Exploring the data:**  \n <h2>To try a new approach in the data, I will start the data analysis by the Name column \n ## Grouping some titles and ploting the results \n ## Title grouped \n It's interesting... Children's and ladys first, huh? \n <h1> Now I will handle the Age variable that has a high number of NaN's, using some columns to correctly input he missing Age's \n This might show us a better way to input the NAN's \n\n<b>For example: </b> an male in 2 class that is a Officer the median Age is 42. <br>\nAnd we will use that to complete the missing data\n \n Now let's categorize them  \n Now it look's better and clearly \n ## Let's cross our Pclass with the Age_cat \nWe will aggregate than to get the mean of Fare by each category pair\n \n - Very interesting. We can see that babies has the highest mean value.  \n ### Looking the Fare distribuition to survivors and not survivors\n \n <br>\nDescription of Fare variable<br>\n- Min: 0<br>\n- Median: 14.45<br>\n- Mean: 32.20<br>\n- Max: 512.32<br> \n- Std: 49.69<br>\n\n<h3>I will create a categorical variable to treat the Fare expend</h3><br>\nI will use the same technique used in Age but now I will use the quantiles to binning\n\n \n <h2>To complete this part, I will now work on \"Names\" \n <h1>It's looking ok \n Now, lets start explore the data \n <h2>We can look that % dies to mens are much higher than female \n <h1>Now, lets do some exploration in Pclass and Embarked to see if might have some information to build the model \n <b>Looking the graphs, is clear that 3st class and Embarked at Southampton have a high probabilities to not survive</b> \n To finish the analysis I let's look the Sibsp and Parch variables \n Interesting. With 1 or 2 siblings/spouses have more chance to survived the disaster \n We can see a high standard deviation in the survival with 3 parents/children person's <br>\nAlso that small families (1~2) have more chance to survival than single or big families \n So to Finish our exploration I will create a new column to with familiees size \n OK, its might be enough to start with the preprocess and builting the model\n \n <a id=\"Preprocess\"></a> <br> \n# **5. Preprocessing :**  \n Now we might have information enough to think about the model structure \n <a id=\"Model\"></a> <br> \n# **6. Modelling : **  \n <h3>Titanic survivors prediction: <br>\na binary classification example</h3>\nTwo-class classification, or binary classification, may be the most widely applied kind of machine-learning problem. \n <h1>Anatomy of a neural network: </h1>\n\nAs you saw in the previous chapters, training a neural network revolves around the following\nobjects:\n- Layers, which are combined into a network (or model)\n- The input data and corresponding targets\n- The loss function, which defines the feedback signal used for learning\n- The optimizer, which determines how learning proceeds\n\n\n\n\n<h2> Layers: the building blocks of deep learning</h2>\nfrom keras import layers<br>\nlayer = layers.Dense(32, input_dim=data_dimension)) \n\n- We can think of layers as the LEGO bricks of deep learning, a metaphor that is\nmade explicit by frameworks like Keras. Building deep-learning models in Keras is\ndone by clipping together compatible layers to form useful data-transformation pipelines.\n\n\n<h2>What are activation functions, and why are they necessary?</h2>\nWithout an activation function like relu (also called a non-linearity), the Dense layer would consist of two linear operations\u2014a dot product and an addition: <br><br>\n<i>output = dot(W, input) + b</i><br><br>\n\nSo the layer could only learn linear transformations (affine transformations) of the\ninput data: the hypothesis space of the layer would be the set of all possible linear\ntransformations of the input data into a 16-dimensional space. \n\n\n<h2>Loss functions and optimizers:<br>\nkeys to configuring the learning process</h2>\nOnce the network architecture is defined, you still have to choose two more things:\n- <b>Loss function (objective function) </b>- The quantity that will be minimized during\ntraining. It represents a measure of success for the task at hand.\n- <b>Optimizer</b> - Determines how the network will be updated based on the loss function.\nIt implements a specific variant of stochastic gradient descent (SGD). \n Stacks of Dense layers with relu activations can solve a wide range of problems (including sentiment classification), and you\u2019ll likely use them frequently. \n Finally, we need to choose a loss function and an optimizer.  \n Because you\u2019re facing a binary classification problem and the output of your network is a probability (you end your network with a single-unit layer with a sigmoid activation), it\u2019s best to use the <i>binary_crossentropy</i> loss. \n ## Predicting X_test \n <h1>Evaluating the model</h1> \n Not bad result to a simple model! Let's now verify the validation of our model, to see and understand the learning curve \n <a id=\"Validation\"></a> <br> \n# **7. Validation: **  \n Let's look this keys values further \n Why this occurs and how to solve this problem in graph? it's a overffiting?  \n <h1>It's my first Deep Learning implementation... I am studying about this and I will continue editing this Kernel to improve the results</h1> \n Give me your feedback how can I increase this model =)  \n # Stay tuned and don't forget to votesup this kernel",
    "n_cells": 106,
    "n_code_cells": 54,
    "n_markdown_cells": 52,
    "n_raw_cells": 0,
    "n_outputs": 54,
    "r_code_cells": 0.5094339622641509,
    "r_markdown_cells": 0.49056603773584906,
    "r_raw_cells": 0.0,
    "r_outputs": 1.0,
    "n_exceptions": 0,
    "r_exceptions": 0.0,
    "n_lines": 693,
    "n_lines_code": 529,
    "n_lines_markdown": 164,
    "lines_per_cell": [
        4,
        2,
        1,
        10,
        5,
        6,
        27,
        1,
        2,
        18,
        5,
        2,
        1,
        5,
        2,
        2,
        2,
        1,
        2,
        13,
        2,
        1,
        26,
        1,
        15,
        1,
        1,
        17,
        5,
        5,
        6,
        10,
        9,
        1,
        13,
        8,
        25,
        1,
        3,
        6,
        1,
        2,
        12,
        12,
        24,
        7,
        1,
        13,
        2,
        1,
        1,
        12,
        9,
        1,
        1,
        11,
        2,
        11,
        11,
        1,
        1,
        7,
        1,
        1,
        3,
        2,
        1,
        4,
        3,
        5,
        2,
        2,
        1,
        1,
        5,
        5,
        1,
        10,
        5,
        2,
        3,
        5,
        37,
        34,
        1,
        1,
        14,
        1,
        1,
        5,
        1,
        2,
        1,
        2,
        6,
        1,
        9,
        1,
        9,
        1,
        1,
        1,
        8,
        21,
        62,
        1
    ],
    "lines_per_code_cell": [
        18,
        5,
        5,
        2,
        2,
        2,
        13,
        2,
        26,
        15,
        17,
        5,
        6,
        10,
        9,
        13,
        8,
        25,
        6,
        12,
        24,
        7,
        13,
        2,
        12,
        9,
        11,
        2,
        11,
        11,
        7,
        1,
        3,
        4,
        3,
        5,
        1,
        5,
        5,
        1,
        10,
        5,
        5,
        34,
        14,
        5,
        2,
        6,
        9,
        9,
        1,
        8,
        21,
        62
    ],
    "lines_per_markdown_cell": [
        4,
        2,
        1,
        10,
        5,
        6,
        27,
        1,
        2,
        2,
        1,
        2,
        1,
        1,
        1,
        1,
        1,
        5,
        1,
        1,
        3,
        1,
        2,
        12,
        1,
        1,
        1,
        1,
        1,
        1,
        1,
        1,
        2,
        1,
        2,
        2,
        1,
        2,
        3,
        37,
        1,
        1,
        1,
        1,
        1,
        1,
        2,
        1,
        1,
        1,
        1,
        1
    ],
    "ave_lines_per_cell": 6.537735849056604,
    "ave_lines_per_code_cell": 9.796296296296296,
    "ave_lines_per_markdown_cell": 3.1538461538461537,
    "max_lines_per_cell": 62,
    "max_lines_per_code_cell": 62,
    "max_lines_per_markdown_cell": 37,
    "min_lines_per_cell": 1,
    "min_lines_per_code_cell": 1,
    "min_lines_per_markdown_cell": 1,
    "n_chars": 26622,
    "n_chars_code": 17971,
    "n_chars_markdown": 8651,
    "chars_per_cell": [
        310,
        175,
        87,
        302,
        187,
        904,
        1199,
        112,
        47,
        521,
        139,
        58,
        62,
        99,
        36,
        47,
        54,
        88,
        80,
        485,
        142,
        47,
        823,
        16,
        477,
        52,
        127,
        700,
        236,
        188,
        277,
        283,
        237,
        26,
        466,
        281,
        759,
        32,
        113,
        252,
        71,
        66,
        404,
        288,
        708,
        247,
        53,
        298,
        54,
        19,
        32,
        380,
        299,
        63,
        113,
        321,
        103,
        336,
        329,
        119,
        65,
        236,
        1,
        83,
        173,
        178,
        78,
        200,
        149,
        86,
        76,
        55,
        15,
        71,
        359,
        202,
        14,
        250,
        158,
        47,
        192,
        149,
        1768,
        1145,
        156,
        61,
        462,
        230,
        20,
        197,
        29,
        118,
        120,
        52,
        193,
        35,
        234,
        76,
        223,
        30,
        142,
        55,
        267,
        1035,
        2256,
        52
    ],
    "chars_per_code_cell": [
        521,
        139,
        99,
        36,
        47,
        80,
        485,
        142,
        823,
        477,
        700,
        236,
        277,
        283,
        237,
        466,
        281,
        759,
        252,
        404,
        708,
        247,
        298,
        54,
        380,
        299,
        321,
        103,
        336,
        329,
        236,
        1,
        173,
        200,
        149,
        86,
        15,
        359,
        202,
        14,
        250,
        158,
        149,
        1145,
        462,
        197,
        118,
        193,
        234,
        223,
        30,
        267,
        1035,
        2256
    ],
    "chars_per_markdown_cell": [
        310,
        175,
        87,
        302,
        187,
        904,
        1199,
        112,
        47,
        58,
        62,
        54,
        88,
        47,
        16,
        52,
        127,
        188,
        26,
        32,
        113,
        71,
        66,
        288,
        53,
        19,
        32,
        63,
        113,
        119,
        65,
        83,
        178,
        78,
        76,
        55,
        71,
        47,
        192,
        1768,
        156,
        61,
        230,
        20,
        29,
        120,
        52,
        35,
        76,
        142,
        55,
        52
    ],
    "ave_chars_per_line": 38.41558441558441,
    "ave_chars_per_cell": 251.1509433962264,
    "ave_chars_per_code_cell": 332.7962962962963,
    "ave_chars_per_markdown_cell": 166.3653846153846,
    "max_chars_per_cell": 2256,
    "max_chars_per_code_cell": 2256,
    "max_chars_per_markdownell": 1768,
    "min_chars_per_cell": 1,
    "min_chars_per_code_cell": 1,
    "min_chars_per_markdown_cell": 16,
    "r_lines_code": 0.7633477633477633,
    "r_lines_markdown": 0.23665223665223664,
    "r_chars_markdown": 0.32495680264442944,
    "r_chars_code": 0.6750431973555706,
    "all_cells": [
        {
            "source": "<h1> Welcome to my Titanic Kernel! </h1>\n<h2>This kernel will provide a analysis through the Titanic Disaster to understand the Survivors patterns</h2><br>\n\nI will handle with data (<i>transform, missings, manipulation</i>), explore the data (<i>descritive and visual</i>) and also create a Deep Learning model",
            "mc_idx": 0,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Are you looking for another interesting Kernels? <a href=\"https://www.kaggle.com/kabure/kernels\">CLICK HERE</a> <br>\nGive me your feedback and if yo like this kernel, votes up",
            "mc_idx": 1,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<i>*I'm from Brazil, so english is not my first language, sorry about some mistakes</i>",
            "mc_idx": 2,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Table of Contents:\n\n**1. [Introduction](#Introduction)** <br>\n**2. [Librarys](#Librarys)** <br>\n**3. [Knowning the data](#Known)** <br>\n**4. [Exploring some Variables](#Explorations)** <br>\n**5. [Preprocessing](#Prepocess)** <br>\n**6. [Modelling](#Model)** <br>\n**7. [Validation](#Validation)** <br>\n",
            "mc_idx": 3,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<a id=\"Introduction\"></a> <br> \n# **1. Introduction:** \n<h3> The data have 891 entries on train dataset and 418 on test dataset</h3>\n- 10 columns in train_csv and 9 columns in train_test\n",
            "mc_idx": 4,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h2>Competition Description: </h2>\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n\nOne of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n\nIn this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.",
            "mc_idx": 5,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h3>Data Dictionary</h3><br>\nVariable\tDefinition\tKey<br>\n<b>survival</b>\tSurvival\t0 = No, 1 = Yes<br>\n<b>pclass</b>\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd<br>\n<b>sex</b>\tSex\t<br>\n<b>Age</b>\tAge in years\t<br>\n<b>sibsp</b>\t# of siblings / spouses aboard the Titanic\t<br>\n<b>parch</b>\t# of parents / children aboard the Titanic\t<br>\n<b>ticket</b>\tTicket number\t<br>\n<b>fare</b>\tPassenger fare\t<br>\n<b>cabin</b>\tCabin number\t<br>\n<b>embarked\t</b>Port of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton<br>\n<h3>Variable Notes</h3><br>\n<b>pclass: </b>A proxy for socio-economic status (SES)<br>\n1st = Upper<br>\n2nd = Middle<br>\n3rd = Lower<br>\n<b>age: </b>Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br>\n<b>sibsp:</b> The dataset defines family relations in this way...<br>\n- <b>Sibling </b>= brother, sister, stepbrother, stepsister<br>\n- <b>Spouse </b>= husband, wife (mistresses and fianc\u00e9s were ignored)<br>\n\n<b>parch: </b>The dataset defines family relations in this way...<br>\n- <b>Parent</b> = mother, father<br>\n- <b>Child </b>= daughter, son, stepdaughter, stepson<br>\n\nSome children travelled only with a nanny, therefore parch=0 for them.<br>",
            "mc_idx": 6,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "I am using the beapproachs as possible but if you think I can do anything another best way, please, let me know.",
            "mc_idx": 7,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<a id=\"Librarys\"></a> <br> \n# **2. Librarys:** ",
            "mc_idx": 8,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#This librarys is to work with matrices\nimport pandas as pd \n# This librarys is to work with vectors\nimport numpy as np\n# This library is to create some graphics algorithmn\nimport seaborn as sns\n# to render the graphs\nimport matplotlib.pyplot as plt\n# import module to set some ploting parameters\nfrom matplotlib import rcParams\n# Library to work with Regular Expressions\nimport re\n\n# This function makes the plot directly on browser\n%matplotlib inline\n\n# Seting a universal figure size \nrcParams['figure.figsize'] = 10,8",
            "mc_idx": 9,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.07142857142857142,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.04285714285714286,
                "Visualization": 0.08571428571428572,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 7
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "matplotlib": 3,
                    "size": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 3
                },
                "Visualization": {
                    "matplotlib": 3,
                    "pyplot": 1,
                    "graph": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    0,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 9,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 0,
                "o_idx": 0
            }
        },
        {
            "source": "# Importing train dataset\ndf_train = pd.read_csv(\"../input/train.csv\")\n\n# Importing test dataset\ndf_test = pd.read_csv(\"../input/test.csv\")",
            "mc_idx": 10,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 4,
                    "pd.read_": 4,
                    "dataset": 2
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    1,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 10,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 1,
                "o_idx": 0
            }
        },
        {
            "source": "<a id=\"Known\"></a> <br> \n# **3. First look at the data:** ",
            "mc_idx": 11,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "I will start looking the type and informations of the datasets",
            "mc_idx": 12,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#Looking data format and types\nprint(df_train.info())\n\n# printing test info()\nprint(df_test.info())",
            "mc_idx": 13,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".info(": 2,
                    "info": 3,
                    ".info": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    2,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\nPassengerId    891 non-null int64\nSurvived       891 non-null int64\nPclass         891 non-null int64\nName           891 non-null object\nSex            891 non-null object\nAge            714 non-null float64\nSibSp          891 non-null int64\nParch          891 non-null int64\nTicket         891 non-null object\nFare           891 non-null float64\nCabin          204 non-null object\nEmbarked       889 non-null object\ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.6+ KB\nNone\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 418 entries, 0 to 417\nData columns (total 11 columns):\nPassengerId    418 non-null int64\nPclass         418 non-null int64\nName           418 non-null object\nSex            418 non-null object\nAge            332 non-null float64\nSibSp          418 non-null int64\nParch          418 non-null int64\nTicket         418 non-null object\nFare           417 non-null float64\nCabin          91 non-null object\nEmbarked       418 non-null object\ndtypes: float64(2), int64(4), object(5)\nmemory usage: 36.0+ KB\nNone\n"
                    ]
                },
                "mc_idx": 13,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 2,
                "o_idx": 0
            }
        },
        {
            "source": "#Some Statistics\ndf_train.describe()",
            "mc_idx": 14,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".describe(": 1,
                    "describe": 1,
                    ".describe": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    3,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "       PassengerId    Survived      Pclass         Age       SibSp  \\\ncount   891.000000  891.000000  891.000000  714.000000  891.000000   \nmean    446.000000    0.383838    2.308642   29.699118    0.523008   \nstd     257.353842    0.486592    0.836071   14.526497    1.102743   \nmin       1.000000    0.000000    1.000000    0.420000    0.000000   \n25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n75%     668.500000    1.000000    3.000000   38.000000    1.000000   \nmax     891.000000    1.000000    3.000000   80.000000    8.000000   \n\n            Parch        Fare  \ncount  891.000000  891.000000  \nmean     0.381594   32.204208  \nstd      0.806057   49.693429  \nmin      0.000000    0.000000  \n25%      0.000000    7.910400  \n50%      0.000000   14.454200  \n75%      0.000000   31.000000  \nmax      6.000000  512.329200  "
                    ]
                },
                "mc_idx": 14,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 3,
                "o_idx": 0
            }
        },
        {
            "source": "#Take a look at the data\nprint(df_train.head())",
            "mc_idx": 15,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    4,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  \n"
                    ]
                },
                "mc_idx": 15,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 4,
                "o_idx": 0
            }
        },
        {
            "source": "<a id=\"Known\"></a> <br> \n# **4. Exploring the data:** ",
            "mc_idx": 16,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h2>To try a new approach in the data, I will start the data analysis by the Name column",
            "mc_idx": 17,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#Looking how the data is and searching for a re patterns\ndf_train[\"Name\"].head()",
            "mc_idx": 18,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    5,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0                              Braund, Mr. Owen Harris\n1    Cumings, Mrs. John Bradley (Florence Briggs Th...\n2                               Heikkinen, Miss. Laina\n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)\n4                             Allen, Mr. William Henry\nName: Name, dtype: object"
                    ]
                },
                "mc_idx": 18,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 5,
                "o_idx": 0
            }
        },
        {
            "source": "#GettingLooking the prefix of all Passengers\ndf_train['Title'] = df_train.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\\.', x).group(1))\n\n#defining the figure size of our graphic\nplt.figure(figsize=(12,5))\n\n#Plotting the result\nsns.countplot(x='Title', data=df_train, palette=\"hls\")\nplt.xlabel(\"Title\", fontsize=16) #seting the xtitle and size\nplt.ylabel(\"Count\", fontsize=16) # Seting the ytitle and size\nplt.title(\"Title Name Count\", fontsize=20) \nplt.xticks(rotation=45)\nplt.show()",
            "mc_idx": 19,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.125,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.25,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 7
                },
                "Data_Transform": {
                    ".apply(": 1,
                    ".apply": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1,
                    "graph": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c006_o000_image_0.png",
                    6,
                    0,
                    0
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 864x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 19,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 6,
                "o_idx": 0
            }
        },
        {
            "source": "#Doing the same on df_test with regular expressions\ndf_test['Title'] = df_test.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\\.', x).group(1))",
            "mc_idx": 20,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".apply(": 1,
                    ".apply": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    7,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 20,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 7,
                "o_idx": 0
            }
        },
        {
            "source": "## Grouping some titles and ploting the results",
            "mc_idx": 21,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#Now, I will identify the social status of each title\n\nTitle_Dictionary = {\n        \"Capt\":       \"Officer\",\n        \"Col\":        \"Officer\",\n        \"Major\":      \"Officer\",\n        \"Dr\":         \"Officer\",\n        \"Rev\":        \"Officer\",\n        \"Jonkheer\":   \"Royalty\",\n        \"Don\":        \"Royalty\",\n        \"Sir\" :       \"Royalty\",\n        \"the Countess\":\"Royalty\",\n        \"Dona\":       \"Royalty\",\n        \"Lady\" :      \"Royalty\",\n        \"Mme\":        \"Mrs\",\n        \"Ms\":         \"Mrs\",\n        \"Mrs\" :       \"Mrs\",\n        \"Mlle\":       \"Miss\",\n        \"Miss\" :      \"Miss\",\n        \"Mr\" :        \"Mr\",\n        \"Master\" :    \"Master\"\n                   }\n    \n# we map each title to correct category\ndf_train['Title'] = df_train.Title.map(Title_Dictionary)\ndf_test['Title'] = df_test.Title.map(Title_Dictionary)",
            "mc_idx": 22,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".map(": 2,
                    ".map": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    8,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 22,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 8,
                "o_idx": 0
            }
        },
        {
            "source": "## Title grouped",
            "mc_idx": 23,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#printing the chance to survive by each title\nprint(\"Chances to survive based on titles: \") \nprint(df_train.groupby(\"Title\")[\"Survived\"].mean())\n\n# figure size\nplt.figure(figsize=(12,5))\n\n#Plotting the count of title by Survived or not category\nsns.countplot(x='Title', data=df_train, palette=\"hls\",\n              hue=\"Survived\")\nplt.xlabel(\"Titles\", fontsize=16)\nplt.ylabel(\"Count\", fontsize=16)\nplt.title(\"Title Grouped Count\", fontsize=20)\nplt.xticks(rotation=45)\nplt.show()",
            "mc_idx": 24,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.1111111111111111,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.1111111111111111,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.1111111111111111,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    "sns.": 1,
                    "size": 5,
                    ".mean": 1,
                    ".groupby": 1
                },
                "Data_Transform": {
                    ".groupby(": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c009_o001_image_1.png",
                    9,
                    1,
                    1
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Chances to survive based on titles: \nTitle\nMaster     0.575000\nMiss       0.701087\nMr         0.156673\nMrs        0.795276\nOfficer    0.277778\nRoyalty    0.500000\nName: Survived, dtype: float64\n",
                        "<Figure size 864x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 24,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 9,
                "o_idx": 1
            }
        },
        {
            "source": "It's interesting... Children's and ladys first, huh?",
            "mc_idx": 25,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h1> Now I will handle the Age variable that has a high number of NaN's, using some columns to correctly input he missing Age's",
            "mc_idx": 26,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#First I will look my distribuition without NaN's\n#I will create a df to look distribuition \nage_high_zero_died = df_train[(df_train[\"Age\"] > 0) & \n                              (df_train[\"Survived\"] == 0)]\nage_high_zero_surv = df_train[(df_train[\"Age\"] > 0) & \n                              (df_train[\"Survived\"] == 1)]\n\n#figure size\nplt.figure(figsize=(10,5))\n\n# Ploting the 2 variables that we create and compare the two\nsns.distplot(age_high_zero_surv[\"Age\"], bins=24, color='g')\nsns.distplot(age_high_zero_died[\"Age\"], bins=24, color='r')\nplt.title(\"Distribuition and density by Age\",fontsize=20)\nplt.xlabel(\"Age\",fontsize=15)\nplt.ylabel(\"Distribuition Died and Survived\",fontsize=15)\nplt.show()",
            "mc_idx": 27,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2222222222222222,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2222222222222222,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1,
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "distplot": 2,
                    "sns.": 2,
                    "size": 5
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c010_o000_image_2.png",
                    10,
                    0,
                    2
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 720x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 27,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 10,
                "o_idx": 0
            }
        },
        {
            "source": "#Let's group the median age by sex, pclass and title, to have any idea and maybe input in Age NAN's\nage_group = df_train.groupby([\"Sex\",\"Pclass\",\"Title\"])[\"Age\"]\n\n#printing the variabe that we created by median\nprint(age_group.median())",
            "mc_idx": 28,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".median": 2,
                    ".groupby": 1
                },
                "Data_Transform": {
                    ".groupby(": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    11,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Sex     Pclass  Title  \nfemale  1       Miss       30.0\n                Mrs        40.0\n                Officer    49.0\n                Royalty    48.0\n        2       Miss       24.0\n                Mrs        31.5\n        3       Miss       18.0\n                Mrs        31.0\nmale    1       Master      4.0\n                Mr         40.0\n                Officer    51.0\n                Royalty    40.0\n        2       Master      1.0\n                Mr         31.0\n                Officer    46.5\n        3       Master      4.0\n                Mr         26.0\nName: Age, dtype: float64\n"
                    ]
                },
                "mc_idx": 28,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 11,
                "o_idx": 0
            }
        },
        {
            "source": "This might show us a better way to input the NAN's \n\n<b>For example: </b> an male in 2 class that is a Officer the median Age is 42. <br>\nAnd we will use that to complete the missing data\n",
            "mc_idx": 29,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#inputing the values on Age Na's \n# using the groupby to transform this variables\ndf_train.loc[df_train.Age.isnull(), 'Age'] = df_train.groupby(['Sex','Pclass','Title']).Age.transform('median')\n\n# printing the total of nulls in Age Feature\nprint(df_train[\"Age\"].isnull().sum())",
            "mc_idx": 30,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.25,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.75,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".isnull": 2,
                    ".sum": 1,
                    ".groupby": 1
                },
                "Data_Transform": {
                    ".groupby(": 1,
                    "transform": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    12,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0\n"
                    ]
                },
                "mc_idx": 30,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 12,
                "o_idx": 0
            }
        },
        {
            "source": "#Let's see the result of the inputation\n\n#seting the figure size\nplt.figure(figsize=(12,5))\n\n#ploting again the Age Distribuition after the transformation in our dataset\nsns.distplot(df_train[\"Age\"], bins=24)\nplt.title(\"Distribuition and density by Age\")\nplt.xlabel(\"Age\")\nplt.show()",
            "mc_idx": 31,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.25,
                "Data_Extraction": 0.25,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.25,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {
                    "dataset": 1
                },
                "Exploratory_Data_Analysis": {
                    "distplot": 1,
                    "sns.": 1,
                    "size": 2
                },
                "Data_Transform": {
                    "transform": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c013_o000_image_3.png",
                    13,
                    0,
                    3
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 864x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 31,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 13,
                "o_idx": 0
            }
        },
        {
            "source": "#separate by survivors or not\n\n# figure size\nplt.figure(figsize=(12,5))\n\n# using facetgrid that is a great way to get information of our dataset\ng = sns.FacetGrid(df_train, col='Survived',size=5)\ng = g.map(sns.distplot, \"Age\")\nplt.show()",
            "mc_idx": 32,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.14285714285714285,
                "Data_Extraction": 0.14285714285714285,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2857142857142857,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {
                    "dataset": 1
                },
                "Exploratory_Data_Analysis": {
                    "distplot": 1,
                    "sns.": 2,
                    "info": 1,
                    "size": 3
                },
                "Data_Transform": {
                    ".map(": 1,
                    ".map": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c014_o002_image_4.png",
                    14,
                    2,
                    4
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/opt/conda/lib/python3.6/site-packages/seaborn/axisgrid.py:230: UserWarning: The `size` paramter has been renamed to `height`; please update your code.\n  warnings.warn(msg, UserWarning)\n",
                        "<Figure size 864x360 with 0 Axes>",
                        "<Figure size 720x360 with 2 Axes>"
                    ]
                },
                "mc_idx": 32,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 14,
                "o_idx": 2
            }
        },
        {
            "source": "Now let's categorize them ",
            "mc_idx": 33,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#df_train.Age = df_train.Age.fillna(-0.5)\n\n#creating the intervals that we need to cut each range of ages\ninterval = (0, 5, 12, 18, 25, 35, 60, 120) \n\n#Seting the names that we want use to the categorys\ncats = ['babies', 'Children', 'Teen', 'Student', 'Young', 'Adult', 'Senior']\n\n# Applying the pd.cut and using the parameters that we created \ndf_train[\"Age_cat\"] = pd.cut(df_train.Age, interval, labels=cats)\n\n# Printing the new Category\ndf_train[\"Age_cat\"].head()",
            "mc_idx": 34,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.6,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.2,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".fillna(": 1,
                    ".cut(": 1,
                    ".fillna": 1,
                    ".cut": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    15,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0    Student\n1      Adult\n2      Young\n3      Young\n4      Young\nName: Age_cat, dtype: category\nCategories (7, object): [babies < Children < Teen < Student < Young < Adult < Senior]"
                    ]
                },
                "mc_idx": 34,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 15,
                "o_idx": 0
            }
        },
        {
            "source": "#Do the same to test dataset \ninterval = (0, 5, 12, 18, 25, 35, 60, 120)\n\n#same as the other df train\ncats = ['babies', 'Children', 'Teen', 'Student', 'Young', 'Adult', 'Senior']\n\n# same that we used above in df train\ndf_test[\"Age_cat\"] = pd.cut(df_test.Age, interval, labels=cats)",
            "mc_idx": 35,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.5,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "dataset": 1
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".cut(": 1,
                    ".cut": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    16,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 35,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 16,
                "o_idx": 0
            }
        },
        {
            "source": "#Describe of categorical Age\n\n# Using pd.crosstab to understand the Survived rate by Age Category's\nprint(pd.crosstab(df_train.Age_cat, df_train.Survived))\n\n#Seting the figure size\nplt.figure(figsize=(12,10))\n\n#Plotting the result\nplt.subplot(2,1,1)\nsns.countplot(\"Age_cat\",data=df_train,hue=\"Survived\", palette=\"hls\")\nplt.ylabel(\"Count\", fontsize=18)\nplt.xlabel(\"Age Categorys\", fontsize=18)\nplt.title(\"Age Distribution \", fontsize=20)\n\nplt.subplot(2,1,2)\nsns.swarmplot(x='Age_cat',y=\"Fare\",data=df_train,\n              hue=\"Survived\", palette=\"hls\", )\nplt.ylabel(\"Fare Distribution\", fontsize=18)\nplt.xlabel(\"Age Categorys\", fontsize=18)\nplt.title(\"Fare Distribution by Age Categorys \", fontsize=20)\n\nplt.subplots_adjust(hspace = 0.5, top = 0.9)\n\nplt.show()",
            "mc_idx": 36,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.09090909090909091,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.18181818181818182,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.18181818181818182,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 2,
                    "describe": 1,
                    "size": 8
                },
                "Data_Transform": {
                    ".cross": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c017_o001_image_5.png",
                    17,
                    1,
                    5
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Survived    0   1\nAge_cat          \nbabies     15  33\nChildren   16   9\nTeen       54  49\nStudent   108  56\nYoung     206  99\nAdult     133  91\nSenior     17   5\n",
                        "<Figure size 864x720 with 2 Axes>"
                    ]
                },
                "mc_idx": 36,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 17,
                "o_idx": 1
            }
        },
        {
            "source": "Now it look's better and clearly",
            "mc_idx": 37,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## Let's cross our Pclass with the Age_cat \nWe will aggregate than to get the mean of Fare by each category pair\n",
            "mc_idx": 38,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Age_fare = ['Pclass', 'Age_cat'] #seting the desired \n\ncm = sns.light_palette(\"green\", as_cmap=True)\npd.crosstab(df_train[Age_fare[0]], df_train[Age_fare[1]], \n            values=df_train['Fare'], aggfunc=['mean']).style.background_gradient(cmap = cm)\n",
            "mc_idx": 39,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1
                },
                "Data_Transform": {
                    ".cross": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    18,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<pandas.io.formats.style.Styler at 0x7f67c2e7cda0>"
                    ]
                },
                "mc_idx": 39,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 18,
                "o_idx": 0
            }
        },
        {
            "source": "- Very interesting. We can see that babies has the highest mean value. ",
            "mc_idx": 40,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### Looking the Fare distribuition to survivors and not survivors\n",
            "mc_idx": 41,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Seting the figure size\nplt.figure(figsize=(12,5))\n\n# Understanding the Fare Distribuition \nsns.distplot(df_train[df_train.Survived == 0][\"Fare\"], \n             bins=50, color='r')\nsns.distplot(df_train[df_train.Survived == 1][\"Fare\"], \n             bins=50, color='g')\nplt.title(\"Fare Distribuition by Survived\", fontsize=20)\nplt.xlabel(\"Fare\", fontsize=15)\nplt.ylabel(\"Density\",fontsize=15)\nplt.show()",
            "mc_idx": 42,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.1111111111111111,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2222222222222222,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "distplot": 2,
                    "sns.": 2,
                    "size": 5
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c019_o000_image_6.png",
                    19,
                    0,
                    6
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 864x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 42,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 19,
                "o_idx": 0
            }
        },
        {
            "source": "<br>\nDescription of Fare variable<br>\n- Min: 0<br>\n- Median: 14.45<br>\n- Mean: 32.20<br>\n- Max: 512.32<br> \n- Std: 49.69<br>\n\n<h3>I will create a categorical variable to treat the Fare expend</h3><br>\nI will use the same technique used in Age but now I will use the quantiles to binning\n\n",
            "mc_idx": 43,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#Filling the NA's with -0.5\ndf_train.Fare = df_train.Fare.fillna(-0.5)\n\n#intervals to categorize\nquant = (-1, 0, 8, 15, 31, 600)\n\n#Labels without input values\nlabel_quants = ['NoInf', 'quart_1', 'quart_2', 'quart_3', 'quart_4']\n\n#doing the cut in fare and puting in a new column\ndf_train[\"Fare_cat\"] = pd.cut(df_train.Fare, quant, labels=label_quants)\n\n#Description of transformation\nprint(pd.crosstab(df_train.Fare_cat, df_train.Survived))\n\nplt.figure(figsize=(12,5))\n\n#Plotting the new feature\nsns.countplot(x=\"Fare_cat\", hue=\"Survived\", data=df_train, palette=\"hls\")\nplt.title(\"Count of survived x Fare expending\",fontsize=20)\nplt.xlabel(\"Fare Cat\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\n\nplt.show()",
            "mc_idx": 44,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.16666666666666666,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.8333333333333334,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.16666666666666666,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 4
                },
                "Data_Transform": {
                    ".fillna(": 1,
                    "transform": 1,
                    ".cut(": 1,
                    ".cross": 1,
                    ".fillna": 1,
                    ".cut": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c020_o001_image_7.png",
                    20,
                    1,
                    7
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Survived    0    1\nFare_cat          \nNoInf      14    1\nquart_1   175   51\nquart_2   155   62\nquart_3   112   99\nquart_4    93  129\n",
                        "<Figure size 864x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 44,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 20,
                "o_idx": 1
            }
        },
        {
            "source": "# Replicate the same to df_test\ndf_test.Fare = df_test.Fare.fillna(-0.5)\n\nquant = (-1, 0, 8, 15, 31, 1000)\nlabel_quants = ['NoInf', 'quart_1', 'quart_2', 'quart_3', 'quart_4']\n\ndf_test[\"Fare_cat\"] = pd.cut(df_test.Fare, quant, labels=label_quants)",
            "mc_idx": 45,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".fillna(": 1,
                    ".cut(": 1,
                    ".fillna": 1,
                    ".cut": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    21,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 45,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 21,
                "o_idx": 0
            }
        },
        {
            "source": "<h2>To complete this part, I will now work on \"Names\"",
            "mc_idx": 46,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#Now lets drop the variable Fare, Age and ticket that is irrelevant now\ndel df_train[\"Fare\"]\ndel df_train[\"Ticket\"]\ndel df_train[\"Age\"]\ndel df_train[\"Cabin\"]\ndel df_train[\"Name\"]\n\n#same in df_test\ndel df_test[\"Fare\"]\ndel df_test[\"Ticket\"]\ndel df_test[\"Age\"]\ndel df_test[\"Cabin\"]\ndel df_test[\"Name\"]",
            "mc_idx": 47,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    22,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 47,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 22,
                "o_idx": 0
            }
        },
        {
            "source": "#Looking the result of transformations\ndf_train.head()",
            "mc_idx": 48,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    "transform": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    23,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived  Pclass     Sex  SibSp  Parch Embarked Title  \\\n0            1         0       3    male      1      0        S    Mr   \n1            2         1       1  female      1      0        C   Mrs   \n2            3         1       3  female      0      0        S  Miss   \n3            4         1       1  female      1      0        S   Mrs   \n4            5         0       3    male      0      0        S    Mr   \n\n   Age_cat Fare_cat  \n0  Student  quart_1  \n1    Adult  quart_4  \n2    Young  quart_1  \n3    Young  quart_4  \n4    Young  quart_2  "
                    ]
                },
                "mc_idx": 48,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 23,
                "o_idx": 0
            }
        },
        {
            "source": "<h1>It's looking ok",
            "mc_idx": 49,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Now, lets start explore the data",
            "mc_idx": 50,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Let see how many people die or survived\nprint(\"Total of Survived or not: \")\nprint(df_train.groupby(\"Survived\")[\"PassengerId\"].count())\n\nplt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Survived\", data=df_train,palette=\"hls\")\nplt.title('Total Distribuition by survived or not', fontsize=22)\nplt.xlabel('Target Distribuition', fontsize=18)\nplt.ylabel('Count', fontsize=18)\n\nplt.show()",
            "mc_idx": 51,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.16666666666666666,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.16666666666666666,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.16666666666666666,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 4,
                    ".groupby": 1
                },
                "Data_Transform": {
                    ".groupby(": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c024_o001_image_8.png",
                    24,
                    1,
                    8
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Total of Survived or not: \nSurvived\n0    549\n1    342\nName: PassengerId, dtype: int64\n",
                        "<Figure size 864x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 51,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 24,
                "o_idx": 1
            }
        },
        {
            "source": "print(pd.crosstab(df_train.Survived, df_train.Sex))\n\nplt.figure(figsize=(12,5))\nsns.countplot(x=\"Sex\", data=df_train, hue=\"Survived\",palette=\"hls\")\nplt.title('Sex Distribuition by survived or not', fontsize=20)\nplt.xlabel('Sex Distribuition',fontsize=17)\nplt.ylabel('Count', fontsize=17)\n\nplt.show()",
            "mc_idx": 52,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.2,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 4
                },
                "Data_Transform": {
                    ".cross": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c025_o001_image_9.png",
                    25,
                    1,
                    9
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Sex       female  male\nSurvived              \n0             81   468\n1            233   109\n",
                        "<Figure size 864x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 52,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 25,
                "o_idx": 1
            }
        },
        {
            "source": "<h2>We can look that % dies to mens are much higher than female",
            "mc_idx": 53,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h1>Now, lets do some exploration in Pclass and Embarked to see if might have some information to build the model",
            "mc_idx": 54,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Distribuition by class\nprint(pd.crosstab(df_train.Pclass, df_train.Embarked))\n\nplt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Embarked\", data=df_train, hue=\"Pclass\",palette=\"hls\")\nplt.title('Embarked x Pclass Count', fontsize=20)\nplt.xlabel('Embarked with PClass',fontsize=17)\nplt.ylabel('Count', fontsize=17)\n\nplt.show()",
            "mc_idx": 55,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.2,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 4
                },
                "Data_Transform": {
                    ".cross": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c026_o001_image_10.png",
                    26,
                    1,
                    10
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Embarked   C   Q    S\nPclass               \n1         85   2  127\n2         17   3  164\n3         66  72  353\n",
                        "<Figure size 864x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 55,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 26,
                "o_idx": 1
            }
        },
        {
            "source": "#lets input the NA's with the highest frequency\ndf_train[\"Embarked\"] = df_train[\"Embarked\"].fillna('S')",
            "mc_idx": 56,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".fillna(": 1,
                    ".fillna": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    27,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 56,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 27,
                "o_idx": 0
            }
        },
        {
            "source": "# Exploring Survivors vs Embarked\nprint(pd.crosstab(df_train.Survived, df_train.Embarked))\n\nplt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Embarked\", data=df_train, hue=\"Survived\",palette=\"hls\")\nplt.title('Class Distribuition by survived or not',fontsize=20)\nplt.xlabel('Embarked',fontsize=17)\nplt.ylabel('Count', fontsize=17)\n\nplt.show()",
            "mc_idx": 57,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.2,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 4
                },
                "Data_Transform": {
                    ".cross": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c028_o001_image_11.png",
                    28,
                    1,
                    11
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Embarked   C   Q    S\nSurvived             \n0         75  47  427\n1         93  30  219\n",
                        "<Figure size 864x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 57,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 28,
                "o_idx": 1
            }
        },
        {
            "source": "# Exploring Survivors vs Pclass\nprint(pd.crosstab(df_train.Survived, df_train.Pclass))\n\nplt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Pclass\", data=df_train, hue=\"Survived\",palette=\"hls\")\nplt.xlabel('PClass',fontsize=17)\nplt.ylabel('Count', fontsize=17)\nplt.title('Class Distribuition by Survived or not', fontsize=20)\n\nplt.show()",
            "mc_idx": 58,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.2,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 4
                },
                "Data_Transform": {
                    ".cross": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c029_o001_image_12.png",
                    29,
                    1,
                    12
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Pclass      1   2    3\nSurvived              \n0          80  97  372\n1         136  87  119\n",
                        "<Figure size 864x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 58,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 29,
                "o_idx": 1
            }
        },
        {
            "source": "<b>Looking the graphs, is clear that 3st class and Embarked at Southampton have a high probabilities to not survive</b>",
            "mc_idx": 59,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "To finish the analysis I let's look the Sibsp and Parch variables",
            "mc_idx": 60,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "g = sns.factorplot(x=\"SibSp\",y=\"Survived\",data=df_train,\n                   kind=\"bar\", height = 5, aspect= 1.6, palette = \"hls\")\ng.set_ylabels(\"Probability(Survive)\", fontsize=15)\ng.set_xlabels(\"SibSp Number\", fontsize=15)\n\nplt.show()\n",
            "mc_idx": 61,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.3333333333333333,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.3333333333333333,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c030_o001_image_13.png",
                    30,
                    1,
                    13
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/opt/conda/lib/python3.6/site-packages/seaborn/categorical.py:3666: UserWarning: The `factorplot` function has been renamed to `catplot`. The original name will be removed in a future release. Please update your code. Note that the default `kind` in `factorplot` (`'point'`) has changed `'strip'` in `catplot`.\n  warnings.warn(msg)\n",
                        "<Figure size 576x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 61,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 30,
                "o_idx": 1
            }
        },
        {
            "source": "f",
            "mc_idx": 62,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    31,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 62,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 31,
                "o_idx": 0
            }
        },
        {
            "source": "Interesting. With 1 or 2 siblings/spouses have more chance to survived the disaster",
            "mc_idx": 63,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Explore Parch feature vs Survived\ng  = sns.factorplot(x=\"Parch\",y=\"Survived\",data=df_train, kind=\"bar\", size = 6,palette = \"hls\")\ng = g.set_ylabels(\"survival probability\")",
            "mc_idx": 64,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.5,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c032_o001_image_14.png",
                    32,
                    1,
                    14
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/opt/conda/lib/python3.6/site-packages/seaborn/categorical.py:3672: UserWarning: The `size` paramter has been renamed to `height`; please update your code.\n  warnings.warn(msg, UserWarning)\n",
                        "<Figure size 432x432 with 1 Axes>"
                    ]
                },
                "mc_idx": 64,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 32,
                "o_idx": 1
            }
        },
        {
            "source": "We can see a high standard deviation in the survival with 3 parents/children person's <br>\nAlso that small families (1~2) have more chance to survival than single or big families",
            "mc_idx": 65,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "So to Finish our exploration I will create a new column to with familiees size",
            "mc_idx": 66,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#Create a new column and sum the Parch + SibSp + 1 that refers the people self\ndf_train[\"FSize\"] = df_train[\"Parch\"] + df_train[\"SibSp\"] + 1\n\ndf_test[\"FSize\"] = df_test[\"Parch\"] + df_test[\"SibSp\"] + 1",
            "mc_idx": 67,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    33,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 67,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 33,
                "o_idx": 0
            }
        },
        {
            "source": "print(pd.crosstab(df_train.FSize, df_train.Survived))\nsns.factorplot(x=\"FSize\",y=\"Survived\", data=df_train, kind=\"bar\",size=6, aspect=1.6)\nplt.show()",
            "mc_idx": 68,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.25,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.25,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 3
                },
                "Data_Transform": {
                    ".cross": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c034_o001_image_15.png",
                    34,
                    1,
                    15
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Survived    0    1\nFSize             \n1         374  163\n2          72   89\n3          43   59\n4           8   21\n5          12    3\n6          19    3\n7           8    4\n8           6    0\n11          7    0\n",
                        "<Figure size 691.2x432 with 1 Axes>"
                    ]
                },
                "mc_idx": 68,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 34,
                "o_idx": 1
            }
        },
        {
            "source": "del df_train[\"SibSp\"]\ndel df_train[\"Parch\"]\n\ndel df_test[\"SibSp\"]\ndel df_test[\"Parch\"]",
            "mc_idx": 69,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    35,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 69,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 35,
                "o_idx": 0
            }
        },
        {
            "source": "OK, its might be enough to start with the preprocess and builting the model\n",
            "mc_idx": 70,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<a id=\"Preprocess\"></a> <br> \n# **5. Preprocessing :** ",
            "mc_idx": 71,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "df_train.head()",
            "mc_idx": 72,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    36,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived  Pclass     Sex Embarked Title  Age_cat Fare_cat  \\\n0            1         0       3    male        S    Mr  Student  quart_1   \n1            2         1       1  female        C   Mrs    Adult  quart_4   \n2            3         1       3  female        S  Miss    Young  quart_1   \n3            4         1       1  female        S   Mrs    Young  quart_4   \n4            5         0       3    male        S    Mr    Young  quart_2   \n\n   FSize  \n0      2  \n1      2  \n2      1  \n3      2  \n4      1  "
                    ]
                },
                "mc_idx": 72,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 36,
                "o_idx": 0
            }
        },
        {
            "source": "Now we might have information enough to think about the model structure",
            "mc_idx": 73,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "df_train = pd.get_dummies(df_train, columns=[\"Sex\",\"Embarked\",\"Age_cat\",\"Fare_cat\",\"Title\"],\\\n                          prefix=[\"Sex\",\"Emb\",\"Age\",\"Fare\",\"Prefix\"], drop_first=True)\n\ndf_test = pd.get_dummies(df_test, columns=[\"Sex\",\"Embarked\",\"Age_cat\",\"Fare_cat\",\"Title\"],\\\n                         prefix=[\"Sex\",\"Emb\",\"Age\",\"Fare\",\"Prefix\"], drop_first=True)",
            "mc_idx": 74,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 2
                },
                "Data_Transform": {
                    ".get_dummies": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    37,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 74,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 37,
                "o_idx": 0
            }
        },
        {
            "source": "#Finallt, lets look the correlation of df_train\nplt.figure(figsize=(15,12))\nplt.title('Correlation of Features for Train Set')\nsns.heatmap(df_train.astype(float).corr(),vmax=1.0,  annot=True)\nplt.show()",
            "mc_idx": 75,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.16666666666666666,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.16666666666666666,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.5,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".corr": 2,
                    "sns.heatmap": 1,
                    ".heatmap(": 1,
                    "sns.": 1,
                    "size": 1
                },
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.heatmap": 1,
                    ".heatmap(": 1,
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c038_o000_image_16.png",
                    38,
                    0,
                    16
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1080x864 with 2 Axes>"
                    ]
                },
                "mc_idx": 75,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 38,
                "o_idx": 0
            }
        },
        {
            "source": "df_train.shape",
            "mc_idx": 76,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "shape": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    39,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "(891, 22)"
                    ]
                },
                "mc_idx": 76,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 39,
                "o_idx": 0
            }
        },
        {
            "source": "train = df_train.drop([\"Survived\",\"PassengerId\"],axis=1)\ntrain_ = df_train[\"Survived\"]\n\ntest_ = df_test.drop([\"PassengerId\"],axis=1)\n\nX_train = train.values\ny_train = train_.values\n\nX_test = test_.values\nX_test = X_test.astype(np.float64, copy=False)",
            "mc_idx": 77,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1,
                    ".drop": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    40,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 77,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 40,
                "o_idx": 0
            }
        },
        {
            "source": "# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)",
            "mc_idx": 78,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.6,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 10
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "fit_transform": 2,
                    "transform": 2,
                    "standardscaler": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    41,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 78,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 41,
                "o_idx": 0
            }
        },
        {
            "source": "<a id=\"Model\"></a> <br> \n# **6. Modelling : ** ",
            "mc_idx": 79,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h3>Titanic survivors prediction: <br>\na binary classification example</h3>\nTwo-class classification, or binary classification, may be the most widely applied kind of machine-learning problem.",
            "mc_idx": 80,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "from keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nimport keras\nfrom keras.optimizers import SGD\nimport graphviz",
            "mc_idx": 81,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.02,
                "Data_Transform": 0.02,
                "Model_Train": 0.02,
                "Model_Evaluation": 0.02,
                "Model_Interpretation": 0.02,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.02,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 5
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mode": 1
                },
                "Data_Transform": {
                    ".mod": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "graph": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    42,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Using TensorFlow backend.\n"
                    ]
                },
                "mc_idx": 81,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 42,
                "o_idx": 0
            }
        },
        {
            "source": "<h1>Anatomy of a neural network: </h1>\n\nAs you saw in the previous chapters, training a neural network revolves around the following\nobjects:\n- Layers, which are combined into a network (or model)\n- The input data and corresponding targets\n- The loss function, which defines the feedback signal used for learning\n- The optimizer, which determines how learning proceeds\n\n\n\n\n<h2> Layers: the building blocks of deep learning</h2>\nfrom keras import layers<br>\nlayer = layers.Dense(32, input_dim=data_dimension)) \n\n- We can think of layers as the LEGO bricks of deep learning, a metaphor that is\nmade explicit by frameworks like Keras. Building deep-learning models in Keras is\ndone by clipping together compatible layers to form useful data-transformation pipelines.\n\n\n<h2>What are activation functions, and why are they necessary?</h2>\nWithout an activation function like relu (also called a non-linearity), the Dense layer would consist of two linear operations\u2014a dot product and an addition: <br><br>\n<i>output = dot(W, input) + b</i><br><br>\n\nSo the layer could only learn linear transformations (affine transformations) of the\ninput data: the hypothesis space of the layer would be the set of all possible linear\ntransformations of the input data into a 16-dimensional space. \n\n\n<h2>Loss functions and optimizers:<br>\nkeys to configuring the learning process</h2>\nOnce the network architecture is defined, you still have to choose two more things:\n- <b>Loss function (objective function) </b>- The quantity that will be minimized during\ntraining. It represents a measure of success for the task at hand.\n- <b>Optimizer</b> - Determines how the network will be updated based on the loss function.\nIt implements a specific variant of stochastic gradient descent (SGD).",
            "mc_idx": 82,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Creating the model\nmodel = Sequential()\n\n# Inputing the first layer with input dimensions\nmodel.add(Dense(18, \n                activation='relu',  \n                input_dim=20,\n                kernel_initializer='uniform'))\n#The argument being passed to each Dense layer (18) is the number of hidden units of the layer. \n# A hidden unit is a dimension in the representation space of the layer.\n\n#Stacks of Dense layers with relu activations can solve a wide range of problems\n#(including sentiment classification), and you\u2019ll likely use them frequently.\n\n# Adding an Dropout layer to previne from overfitting\nmodel.add(Dropout(0.50))\n\n#adding second hidden layer \nmodel.add(Dense(60,\n                kernel_initializer='uniform',\n                activation='relu'))\n\n# Adding another Dropout layer\nmodel.add(Dropout(0.50))\n\n# adding the output layer that is binary [0,1]\nmodel.add(Dense(1,\n                kernel_initializer='uniform',\n                activation='sigmoid'))\n#With such a scalar sigmoid output on a binary classification problem, the loss\n#function you should use is binary_crossentropy\n\n#Visualizing the model\nmodel.summary()",
            "mc_idx": 83,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.1,
                "Data_Transform": 0.6,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.9,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".sum": 1
                },
                "Data_Transform": {
                    "stack": 1,
                    ".add": 5
                },
                "Model_Train": {
                    "sequential(": 1,
                    "model": 9
                },
                "Model_Evaluation": {
                    "model": 9
                },
                "Model_Interpretation": {
                    "model": 9,
                    "summary": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    43,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 18)                378       \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 18)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 60)                1140      \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 60)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 61        \n=================================================================\nTotal params: 1,579\nTrainable params: 1,579\nNon-trainable params: 0\n_________________________________________________________________\n"
                    ]
                },
                "mc_idx": 83,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 43,
                "o_idx": 0
            }
        },
        {
            "source": "Stacks of Dense layers with relu activations can solve a wide range of problems (including sentiment classification), and you\u2019ll likely use them frequently.",
            "mc_idx": 84,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Finally, we need to choose a loss function and an optimizer. ",
            "mc_idx": 85,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "#Creating an Stochastic Gradient Descent\nsgd = SGD(lr = 0.01, momentum = 0.9)\n\n# Compiling our model\nmodel.compile(optimizer = sgd, \n                   loss = 'binary_crossentropy', \n                   metrics = ['accuracy'])\n#optimizers list\n#optimizers['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n\n# Fitting the ANN to the Training set\nmodel.fit(X_train, y_train, \n               batch_size = 60, \n               epochs = 30, verbose=2)",
            "mc_idx": 86,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.16666666666666666,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.6666666666666666,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model.fit": 1,
                    "compile": 1,
                    ".fit(": 1,
                    "model": 3
                },
                "Model_Evaluation": {
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3,
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    44,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Epoch 1/30\n - 4s - loss: 0.6899 - acc: 0.6150\nEpoch 2/30\n - 0s - loss: 0.6789 - acc: 0.6162\nEpoch 3/30\n - 0s - loss: 0.6711 - acc: 0.6162\nEpoch 4/30\n - 0s - loss: 0.6675 - acc: 0.6162\nEpoch 5/30\n - 0s - loss: 0.6660 - acc: 0.6162\nEpoch 6/30\n - 0s - loss: 0.6655 - acc: 0.6162\nEpoch 7/30\n - 0s - loss: 0.6652 - acc: 0.6162\nEpoch 8/30\n - 0s - loss: 0.6650 - acc: 0.6162\nEpoch 9/30\n - 0s - loss: 0.6646 - acc: 0.6162\nEpoch 10/30\n - 0s - loss: 0.6642 - acc: 0.6162\nEpoch 11/30\n - 0s - loss: 0.6640 - acc: 0.6162\nEpoch 12/30\n - 0s - loss: 0.6633 - acc: 0.6162\nEpoch 13/30\n - 0s - loss: 0.6621 - acc: 0.6162\nEpoch 14/30\n - 0s - loss: 0.6613 - acc: 0.6162\nEpoch 15/30\n - 0s - loss: 0.6594 - acc: 0.6162\nEpoch 16/30\n - 0s - loss: 0.6577 - acc: 0.6162\nEpoch 17/30\n - 0s - loss: 0.6549 - acc: 0.6162\nEpoch 18/30\n - 0s - loss: 0.6494 - acc: 0.6162\nEpoch 19/30\n - 0s - loss: 0.6440 - acc: 0.6162\nEpoch 20/30\n - 0s - loss: 0.6330 - acc: 0.6184\nEpoch 21/30\n - 0s - loss: 0.6154 - acc: 0.6532\nEpoch 22/30\n - 0s - loss: 0.5893 - acc: 0.7059\nEpoch 23/30\n - 0s - loss: 0.5621 - acc: 0.7497\nEpoch 24/30\n - 0s - loss: 0.5289 - acc: 0.7744\nEpoch 25/30\n - 0s - loss: 0.5310 - acc: 0.7587\nEpoch 26/30\n - 0s - loss: 0.4989 - acc: 0.7856\nEpoch 27/30\n - 0s - loss: 0.4777 - acc: 0.7811\nEpoch 28/30\n - 0s - loss: 0.4986 - acc: 0.7957\nEpoch 29/30\n - 0s - loss: 0.4710 - acc: 0.7912\nEpoch 30/30\n - 0s - loss: 0.4614 - acc: 0.7890\n",
                        "<keras.callbacks.History at 0x7f678a614828>"
                    ]
                },
                "mc_idx": 86,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 44,
                "o_idx": 1
            }
        },
        {
            "source": "Because you\u2019re facing a binary classification problem and the output of your network is a probability (you end your network with a single-unit layer with a sigmoid activation), it\u2019s best to use the <i>binary_crossentropy</i> loss.",
            "mc_idx": 87,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## Predicting X_test",
            "mc_idx": 88,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "y_preds = model.predict(X_test)\n\nsubmission = pd.read_csv(\"../input/gender_submission.csv\", index_col='PassengerId')\nsubmission['Survived'] = y_preds.astype(int)\nsubmission.to_csv('TitanicKNN.csv')",
            "mc_idx": 89,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.25,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.25,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.5,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 2,
                    "pd.read_": 2
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    45,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 89,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 45,
                "o_idx": 0
            }
        },
        {
            "source": "<h1>Evaluating the model</h1>",
            "mc_idx": 90,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "scores = model.evaluate(X_train, y_train, batch_size=30)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))",
            "mc_idx": 91,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 0.0,
                "Model_Train": 0.6666666666666666,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.6666666666666666,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 2
                },
                "Model_Evaluation": {
                    "model.evaluate": 1,
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    46,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "891/891 [==============================] - 0s 114us/step\nacc: 81.14%\n"
                    ]
                },
                "mc_idx": 91,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 46,
                "o_idx": 0
            }
        },
        {
            "source": "Not bad result to a simple model! Let's now verify the validation of our model, to see and understand the learning curve",
            "mc_idx": 92,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<a id=\"Validation\"></a> <br> \n# **7. Validation: ** ",
            "mc_idx": 93,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Fit the model\nhistory = model.fit(X_train, y_train, validation_split=0.20, \n                    epochs=180, batch_size=10, verbose=0)\n\n# list all data in history\nprint(history.history.keys())",
            "mc_idx": 94,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.75,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model.fit": 1,
                    ".fit(": 1,
                    "model": 2
                },
                "Model_Evaluation": {
                    "model": 2,
                    "validation_split": 1
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    47,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
                    ]
                },
                "mc_idx": 94,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 47,
                "o_idx": 0
            }
        },
        {
            "source": "Let's look this keys values further",
            "mc_idx": 95,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# summarizing historical accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n",
            "mc_idx": 96,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.16666666666666666,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.16666666666666666,
                "Model_Evaluation": 0.16666666666666666,
                "Model_Interpretation": 0.16666666666666666,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.6666666666666666,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plt.plot": 2,
                    ".plot(": 4
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "plt.plot": 2,
                    ".plot(": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c048_o000_image_17.png",
                    48,
                    0,
                    17
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 432x288 with 1 Axes>"
                    ]
                },
                "mc_idx": 96,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 48,
                "o_idx": 0
            }
        },
        {
            "source": "Why this occurs and how to solve this problem in graph? it's a overffiting? ",
            "mc_idx": 97,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()",
            "mc_idx": 98,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.16666666666666666,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.16666666666666666,
                "Model_Evaluation": 0.16666666666666666,
                "Model_Interpretation": 0.16666666666666666,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.6666666666666666,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plt.plot": 2,
                    ".plot(": 4
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "plt.plot": 2,
                    ".plot(": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c049_o000_image_18.png",
                    49,
                    0,
                    18
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 432x288 with 1 Axes>"
                    ]
                },
                "mc_idx": 98,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 49,
                "o_idx": 0
            }
        },
        {
            "source": "y_pred = model.predict(X_test)",
            "mc_idx": 99,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.5,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    50,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 99,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 50,
                "o_idx": 0
            }
        },
        {
            "source": "<h1>It's my first Deep Learning implementation... I am studying about this and I will continue editing this Kernel to improve the results</h1>",
            "mc_idx": 100,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Give me your feedback how can I increase this model =) ",
            "mc_idx": 101,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Trying to implementing the TensorBoard to evaluate the model\n\ncallbacks = [\n    keras.callbacks.TensorBoard(log_dir='my_log_dir',\n                                histogram_freq=1,\n                                embeddings_freq=1,\n                               )\n]",
            "mc_idx": 102,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    51,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 102,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 51,
                "o_idx": 0
            }
        },
        {
            "source": "#Importing the auxiliar and preprocessing librarys \nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate\nfrom sklearn.metrics import accuracy_score\n\n#Models\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import RidgeClassifier, SGDClassifier, LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, VotingClassifier, RandomTreesEmbedding",
            "mc_idx": 103,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.011764705882352941,
                "Data_Transform": 0.041176470588235294,
                "Model_Train": 0.15294117647058825,
                "Model_Evaluation": 0.08235294117647059,
                "Model_Interpretation": 0.03529411764705882,
                "Hyperparameter_Tuning": 0.01764705882352941,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 17
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mode": 2
                },
                "Data_Transform": {
                    "labelencoder": 2,
                    "standardscaler": 1,
                    "pca": 1,
                    "randomtreesembedding": 1,
                    ".mod": 2
                },
                "Model_Train": {
                    "train_test_split": 1,
                    "cross_validate": 1,
                    "model": 5,
                    "randomforestclassifier": 2,
                    "kmeans": 1,
                    "model_selection": 2,
                    "logisticregression": 1,
                    "ridge": 1,
                    "sgdclassifier": 1,
                    "gradientboostingclassifier": 1,
                    "decisiontreeclassifier": 1,
                    "kneighborsclassifier": 1,
                    "svc": 3,
                    "multinomialnb": 1,
                    "votingclassifier": 1,
                    "pipeline": 2,
                    ".linear": 1
                },
                "Model_Evaluation": {
                    "confusion_matrix": 2,
                    "accuracy_score": 4,
                    "classification_report": 2,
                    "cross_val_score": 1,
                    "model": 5
                },
                "Model_Interpretation": {
                    "model": 5,
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {
                    "cross_val_score": 1,
                    "kfold": 1,
                    "train_test_split": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    52,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 103,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 52,
                "o_idx": 0
            }
        },
        {
            "source": "clfs = []\nseed = 3\n\nclfs.append((\"LogReg\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"LogReg\", LogisticRegression())])))\n\nclfs.append((\"XGBClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"XGB\", XGBClassifier())]))) \nclfs.append((\"KNN\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"KNN\", KNeighborsClassifier())]))) \n\nclfs.append((\"DecisionTreeClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"DecisionTrees\", DecisionTreeClassifier())]))) \n\nclfs.append((\"RandomForestClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"RandomForest\", RandomForestClassifier())]))) \n\nclfs.append((\"GradientBoostingClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"GradientBoosting\", GradientBoostingClassifier(max_features=15, n_estimators=150))]))) \n\nclfs.append((\"RidgeClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"RidgeClassifier\", RidgeClassifier())])))\n\nclfs.append((\"BaggingRidgeClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"BaggingClassifier\", BaggingClassifier())])))\n\nclfs.append((\"ExtraTreesClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"ExtraTrees\", ExtraTreesClassifier())])))\n\n#'neg_mean_absolute_error', 'neg_mean_squared_error','r2'\nscoring = 'accuracy'\nn_folds = 10\n\nresults, names  = [], [] \n\nfor name, model  in clfs:\n    kfold = KFold(n_splits=n_folds, random_state=seed)\n    cv_results = cross_val_score(model, X_train, y_train, cv= 5, scoring=scoring, n_jobs=-1)    \n    names.append(name)\n    results.append(cv_results)    \n    msg = \"%s: %f (+/- %f)\" % (name, cv_results.mean(),  cv_results.std())\n    print(msg)\n    \n# boxplot algorithm comparison\nfig = plt.figure(figsize=(15,6))\nfig.suptitle('Classifier Algorithm Comparison', fontsize=22)\nax = fig.add_subplot(111)\nsns.boxplot(x=names, y=results)\nax.set_xticklabels(names)\nax.set_xlabel(\"Algorithmn\", fontsize=20)\nax.set_ylabel(\"Accuracy of Models\", fontsize=18)\nax.set_xticklabels(ax.get_xticklabels(),rotation=45)\nplt.show()",
            "mc_idx": 104,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.038461538461538464,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.4230769230769231,
                "Data_Transform": 0.38461538461538464,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.34615384615384615,
                "Model_Interpretation": 0.23076923076923078,
                "Hyperparameter_Tuning": 0.11538461538461539,
                "Visualization": 0.07692307692307693,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".boxplot(": 2,
                    ".mean(": 1,
                    ".std(": 1,
                    "sns.": 1,
                    "size": 4,
                    ".mean": 1,
                    ".std": 1
                },
                "Data_Transform": {
                    "standardscaler": 9,
                    ".add": 1
                },
                "Model_Train": {
                    "model": 3,
                    "randomforestclassifier": 4,
                    "logisticregression": 1,
                    "ridge": 4,
                    "gradientboostingclassifier": 2,
                    "decisiontreeclassifier": 2,
                    "kneighborsclassifier": 1,
                    "pipeline": 9
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    "model": 3,
                    "mean_squared_error": 3,
                    "mean_absolute_error": 2
                },
                "Model_Interpretation": {
                    "model": 3,
                    "gradient": 3
                },
                "Hyperparameter_Tuning": {
                    "cross_val_score": 1,
                    "kfold": 2
                },
                "Visualization": {
                    ".boxplot(": 1,
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c053_o003_image_19.png",
                    53,
                    3,
                    19
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "LogReg: 0.829444 (+/- 0.015722)\n",
                        "/opt/conda/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n",
                        "XGBClassifier: 0.820404 (+/- 0.019012)\nKNN: 0.782283 (+/- 0.021518)\nDecisionTreeClassifier: 0.797995 (+/- 0.016039)\nRandomForestClassifier: 0.804724 (+/- 0.012755)\nGradientBoostingClassifier: 0.815979 (+/- 0.020409)\nRidgeClassifier: 0.818239 (+/- 0.025687)\nBaggingRidgeClassifier: 0.801359 (+/- 0.016683)\nExtraTreesClassifier: 0.802496 (+/- 0.010934)\n",
                        "<Figure size 1080x432 with 1 Axes>"
                    ]
                },
                "mc_idx": 104,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 53,
                "o_idx": 3
            }
        },
        {
            "source": "# Stay tuned and don't forget to votesup this kernel",
            "mc_idx": 105,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        }
    ],
    "code_cells": [
        {
            "source": "#This librarys is to work with matrices\nimport pandas as pd \n# This librarys is to work with vectors\nimport numpy as np\n# This library is to create some graphics algorithmn\nimport seaborn as sns\n# to render the graphs\nimport matplotlib.pyplot as plt\n# import module to set some ploting parameters\nfrom matplotlib import rcParams\n# Library to work with Regular Expressions\nimport re\n\n# This function makes the plot directly on browser\n%matplotlib inline\n\n# Seting a universal figure size \nrcParams['figure.figsize'] = 10,8",
            "mc_idx": 9,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.07142857142857142,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.04285714285714286,
                "Visualization": 0.08571428571428572,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 7
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "matplotlib": 3,
                    "size": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 3
                },
                "Visualization": {
                    "matplotlib": 3,
                    "pyplot": 1,
                    "graph": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    0,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 9,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 0,
                "o_idx": 0
            }
        },
        {
            "source": "# Importing train dataset\ndf_train = pd.read_csv(\"../input/train.csv\")\n\n# Importing test dataset\ndf_test = pd.read_csv(\"../input/test.csv\")",
            "mc_idx": 10,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 4,
                    "pd.read_": 4,
                    "dataset": 2
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    1,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 10,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 1,
                "o_idx": 0
            }
        },
        {
            "source": "#Looking data format and types\nprint(df_train.info())\n\n# printing test info()\nprint(df_test.info())",
            "mc_idx": 13,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".info(": 2,
                    "info": 3,
                    ".info": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    2,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\nPassengerId    891 non-null int64\nSurvived       891 non-null int64\nPclass         891 non-null int64\nName           891 non-null object\nSex            891 non-null object\nAge            714 non-null float64\nSibSp          891 non-null int64\nParch          891 non-null int64\nTicket         891 non-null object\nFare           891 non-null float64\nCabin          204 non-null object\nEmbarked       889 non-null object\ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.6+ KB\nNone\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 418 entries, 0 to 417\nData columns (total 11 columns):\nPassengerId    418 non-null int64\nPclass         418 non-null int64\nName           418 non-null object\nSex            418 non-null object\nAge            332 non-null float64\nSibSp          418 non-null int64\nParch          418 non-null int64\nTicket         418 non-null object\nFare           417 non-null float64\nCabin          91 non-null object\nEmbarked       418 non-null object\ndtypes: float64(2), int64(4), object(5)\nmemory usage: 36.0+ KB\nNone\n"
                    ]
                },
                "mc_idx": 13,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 2,
                "o_idx": 0
            }
        },
        {
            "source": "#Some Statistics\ndf_train.describe()",
            "mc_idx": 14,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".describe(": 1,
                    "describe": 1,
                    ".describe": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    3,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "       PassengerId    Survived      Pclass         Age       SibSp  \\\ncount   891.000000  891.000000  891.000000  714.000000  891.000000   \nmean    446.000000    0.383838    2.308642   29.699118    0.523008   \nstd     257.353842    0.486592    0.836071   14.526497    1.102743   \nmin       1.000000    0.000000    1.000000    0.420000    0.000000   \n25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n75%     668.500000    1.000000    3.000000   38.000000    1.000000   \nmax     891.000000    1.000000    3.000000   80.000000    8.000000   \n\n            Parch        Fare  \ncount  891.000000  891.000000  \nmean     0.381594   32.204208  \nstd      0.806057   49.693429  \nmin      0.000000    0.000000  \n25%      0.000000    7.910400  \n50%      0.000000   14.454200  \n75%      0.000000   31.000000  \nmax      6.000000  512.329200  "
                    ]
                },
                "mc_idx": 14,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 3,
                "o_idx": 0
            }
        },
        {
            "source": "#Take a look at the data\nprint(df_train.head())",
            "mc_idx": 15,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    4,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  \n"
                    ]
                },
                "mc_idx": 15,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 4,
                "o_idx": 0
            }
        },
        {
            "source": "#Looking how the data is and searching for a re patterns\ndf_train[\"Name\"].head()",
            "mc_idx": 18,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    5,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0                              Braund, Mr. Owen Harris\n1    Cumings, Mrs. John Bradley (Florence Briggs Th...\n2                               Heikkinen, Miss. Laina\n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)\n4                             Allen, Mr. William Henry\nName: Name, dtype: object"
                    ]
                },
                "mc_idx": 18,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 5,
                "o_idx": 0
            }
        },
        {
            "source": "#GettingLooking the prefix of all Passengers\ndf_train['Title'] = df_train.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\\.', x).group(1))\n\n#defining the figure size of our graphic\nplt.figure(figsize=(12,5))\n\n#Plotting the result\nsns.countplot(x='Title', data=df_train, palette=\"hls\")\nplt.xlabel(\"Title\", fontsize=16) #seting the xtitle and size\nplt.ylabel(\"Count\", fontsize=16) # Seting the ytitle and size\nplt.title(\"Title Name Count\", fontsize=20) \nplt.xticks(rotation=45)\nplt.show()",
            "mc_idx": 19,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.125,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.25,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 7
                },
                "Data_Transform": {
                    ".apply(": 1,
                    ".apply": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1,
                    "graph": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c006_o000_image_0.png",
                    6,
                    0,
                    0
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 864x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 19,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 6,
                "o_idx": 0
            }
        },
        {
            "source": "#Doing the same on df_test with regular expressions\ndf_test['Title'] = df_test.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\\.', x).group(1))",
            "mc_idx": 20,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".apply(": 1,
                    ".apply": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    7,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 20,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 7,
                "o_idx": 0
            }
        },
        {
            "source": "#Now, I will identify the social status of each title\n\nTitle_Dictionary = {\n        \"Capt\":       \"Officer\",\n        \"Col\":        \"Officer\",\n        \"Major\":      \"Officer\",\n        \"Dr\":         \"Officer\",\n        \"Rev\":        \"Officer\",\n        \"Jonkheer\":   \"Royalty\",\n        \"Don\":        \"Royalty\",\n        \"Sir\" :       \"Royalty\",\n        \"the Countess\":\"Royalty\",\n        \"Dona\":       \"Royalty\",\n        \"Lady\" :      \"Royalty\",\n        \"Mme\":        \"Mrs\",\n        \"Ms\":         \"Mrs\",\n        \"Mrs\" :       \"Mrs\",\n        \"Mlle\":       \"Miss\",\n        \"Miss\" :      \"Miss\",\n        \"Mr\" :        \"Mr\",\n        \"Master\" :    \"Master\"\n                   }\n    \n# we map each title to correct category\ndf_train['Title'] = df_train.Title.map(Title_Dictionary)\ndf_test['Title'] = df_test.Title.map(Title_Dictionary)",
            "mc_idx": 22,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".map(": 2,
                    ".map": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    8,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 22,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 8,
                "o_idx": 0
            }
        },
        {
            "source": "#printing the chance to survive by each title\nprint(\"Chances to survive based on titles: \") \nprint(df_train.groupby(\"Title\")[\"Survived\"].mean())\n\n# figure size\nplt.figure(figsize=(12,5))\n\n#Plotting the count of title by Survived or not category\nsns.countplot(x='Title', data=df_train, palette=\"hls\",\n              hue=\"Survived\")\nplt.xlabel(\"Titles\", fontsize=16)\nplt.ylabel(\"Count\", fontsize=16)\nplt.title(\"Title Grouped Count\", fontsize=20)\nplt.xticks(rotation=45)\nplt.show()",
            "mc_idx": 24,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.1111111111111111,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.1111111111111111,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.1111111111111111,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mean(": 1,
                    "sns.": 1,
                    "size": 5,
                    ".mean": 1,
                    ".groupby": 1
                },
                "Data_Transform": {
                    ".groupby(": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c009_o001_image_1.png",
                    9,
                    1,
                    1
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Chances to survive based on titles: \nTitle\nMaster     0.575000\nMiss       0.701087\nMr         0.156673\nMrs        0.795276\nOfficer    0.277778\nRoyalty    0.500000\nName: Survived, dtype: float64\n",
                        "<Figure size 864x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 24,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 9,
                "o_idx": 1
            }
        },
        {
            "source": "#First I will look my distribuition without NaN's\n#I will create a df to look distribuition \nage_high_zero_died = df_train[(df_train[\"Age\"] > 0) & \n                              (df_train[\"Survived\"] == 0)]\nage_high_zero_surv = df_train[(df_train[\"Age\"] > 0) & \n                              (df_train[\"Survived\"] == 1)]\n\n#figure size\nplt.figure(figsize=(10,5))\n\n# Ploting the 2 variables that we create and compare the two\nsns.distplot(age_high_zero_surv[\"Age\"], bins=24, color='g')\nsns.distplot(age_high_zero_died[\"Age\"], bins=24, color='r')\nplt.title(\"Distribuition and density by Age\",fontsize=20)\nplt.xlabel(\"Age\",fontsize=15)\nplt.ylabel(\"Distribuition Died and Survived\",fontsize=15)\nplt.show()",
            "mc_idx": 27,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2222222222222222,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2222222222222222,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1,
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "distplot": 2,
                    "sns.": 2,
                    "size": 5
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c010_o000_image_2.png",
                    10,
                    0,
                    2
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 720x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 27,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 10,
                "o_idx": 0
            }
        },
        {
            "source": "#Let's group the median age by sex, pclass and title, to have any idea and maybe input in Age NAN's\nage_group = df_train.groupby([\"Sex\",\"Pclass\",\"Title\"])[\"Age\"]\n\n#printing the variabe that we created by median\nprint(age_group.median())",
            "mc_idx": 28,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".median": 2,
                    ".groupby": 1
                },
                "Data_Transform": {
                    ".groupby(": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    11,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Sex     Pclass  Title  \nfemale  1       Miss       30.0\n                Mrs        40.0\n                Officer    49.0\n                Royalty    48.0\n        2       Miss       24.0\n                Mrs        31.5\n        3       Miss       18.0\n                Mrs        31.0\nmale    1       Master      4.0\n                Mr         40.0\n                Officer    51.0\n                Royalty    40.0\n        2       Master      1.0\n                Mr         31.0\n                Officer    46.5\n        3       Master      4.0\n                Mr         26.0\nName: Age, dtype: float64\n"
                    ]
                },
                "mc_idx": 28,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 11,
                "o_idx": 0
            }
        },
        {
            "source": "#inputing the values on Age Na's \n# using the groupby to transform this variables\ndf_train.loc[df_train.Age.isnull(), 'Age'] = df_train.groupby(['Sex','Pclass','Title']).Age.transform('median')\n\n# printing the total of nulls in Age Feature\nprint(df_train[\"Age\"].isnull().sum())",
            "mc_idx": 30,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.25,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.75,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".isnull": 2,
                    ".sum": 1,
                    ".groupby": 1
                },
                "Data_Transform": {
                    ".groupby(": 1,
                    "transform": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    12,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0\n"
                    ]
                },
                "mc_idx": 30,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 12,
                "o_idx": 0
            }
        },
        {
            "source": "#Let's see the result of the inputation\n\n#seting the figure size\nplt.figure(figsize=(12,5))\n\n#ploting again the Age Distribuition after the transformation in our dataset\nsns.distplot(df_train[\"Age\"], bins=24)\nplt.title(\"Distribuition and density by Age\")\nplt.xlabel(\"Age\")\nplt.show()",
            "mc_idx": 31,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.25,
                "Data_Extraction": 0.25,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.25,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {
                    "dataset": 1
                },
                "Exploratory_Data_Analysis": {
                    "distplot": 1,
                    "sns.": 1,
                    "size": 2
                },
                "Data_Transform": {
                    "transform": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c013_o000_image_3.png",
                    13,
                    0,
                    3
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 864x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 31,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 13,
                "o_idx": 0
            }
        },
        {
            "source": "#separate by survivors or not\n\n# figure size\nplt.figure(figsize=(12,5))\n\n# using facetgrid that is a great way to get information of our dataset\ng = sns.FacetGrid(df_train, col='Survived',size=5)\ng = g.map(sns.distplot, \"Age\")\nplt.show()",
            "mc_idx": 32,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.14285714285714285,
                "Data_Extraction": 0.14285714285714285,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.2857142857142857,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2857142857142857,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {
                    "dataset": 1
                },
                "Exploratory_Data_Analysis": {
                    "distplot": 1,
                    "sns.": 2,
                    "info": 1,
                    "size": 3
                },
                "Data_Transform": {
                    ".map(": 1,
                    ".map": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c014_o002_image_4.png",
                    14,
                    2,
                    4
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/opt/conda/lib/python3.6/site-packages/seaborn/axisgrid.py:230: UserWarning: The `size` paramter has been renamed to `height`; please update your code.\n  warnings.warn(msg, UserWarning)\n",
                        "<Figure size 864x360 with 0 Axes>",
                        "<Figure size 720x360 with 2 Axes>"
                    ]
                },
                "mc_idx": 32,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 14,
                "o_idx": 2
            }
        },
        {
            "source": "#df_train.Age = df_train.Age.fillna(-0.5)\n\n#creating the intervals that we need to cut each range of ages\ninterval = (0, 5, 12, 18, 25, 35, 60, 120) \n\n#Seting the names that we want use to the categorys\ncats = ['babies', 'Children', 'Teen', 'Student', 'Young', 'Adult', 'Senior']\n\n# Applying the pd.cut and using the parameters that we created \ndf_train[\"Age_cat\"] = pd.cut(df_train.Age, interval, labels=cats)\n\n# Printing the new Category\ndf_train[\"Age_cat\"].head()",
            "mc_idx": 34,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.6,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.2,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".fillna(": 1,
                    ".cut(": 1,
                    ".fillna": 1,
                    ".cut": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "param": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    15,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "0    Student\n1      Adult\n2      Young\n3      Young\n4      Young\nName: Age_cat, dtype: category\nCategories (7, object): [babies < Children < Teen < Student < Young < Adult < Senior]"
                    ]
                },
                "mc_idx": 34,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 15,
                "o_idx": 0
            }
        },
        {
            "source": "#Do the same to test dataset \ninterval = (0, 5, 12, 18, 25, 35, 60, 120)\n\n#same as the other df train\ncats = ['babies', 'Children', 'Teen', 'Student', 'Young', 'Adult', 'Senior']\n\n# same that we used above in df train\ndf_test[\"Age_cat\"] = pd.cut(df_test.Age, interval, labels=cats)",
            "mc_idx": 35,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.5,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "dataset": 1
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".cut(": 1,
                    ".cut": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    16,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 35,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 16,
                "o_idx": 0
            }
        },
        {
            "source": "#Describe of categorical Age\n\n# Using pd.crosstab to understand the Survived rate by Age Category's\nprint(pd.crosstab(df_train.Age_cat, df_train.Survived))\n\n#Seting the figure size\nplt.figure(figsize=(12,10))\n\n#Plotting the result\nplt.subplot(2,1,1)\nsns.countplot(\"Age_cat\",data=df_train,hue=\"Survived\", palette=\"hls\")\nplt.ylabel(\"Count\", fontsize=18)\nplt.xlabel(\"Age Categorys\", fontsize=18)\nplt.title(\"Age Distribution \", fontsize=20)\n\nplt.subplot(2,1,2)\nsns.swarmplot(x='Age_cat',y=\"Fare\",data=df_train,\n              hue=\"Survived\", palette=\"hls\", )\nplt.ylabel(\"Fare Distribution\", fontsize=18)\nplt.xlabel(\"Age Categorys\", fontsize=18)\nplt.title(\"Fare Distribution by Age Categorys \", fontsize=20)\n\nplt.subplots_adjust(hspace = 0.5, top = 0.9)\n\nplt.show()",
            "mc_idx": 36,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.09090909090909091,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.18181818181818182,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.18181818181818182,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 2,
                    "describe": 1,
                    "size": 8
                },
                "Data_Transform": {
                    ".cross": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c017_o001_image_5.png",
                    17,
                    1,
                    5
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Survived    0   1\nAge_cat          \nbabies     15  33\nChildren   16   9\nTeen       54  49\nStudent   108  56\nYoung     206  99\nAdult     133  91\nSenior     17   5\n",
                        "<Figure size 864x720 with 2 Axes>"
                    ]
                },
                "mc_idx": 36,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 17,
                "o_idx": 1
            }
        },
        {
            "source": "Age_fare = ['Pclass', 'Age_cat'] #seting the desired \n\ncm = sns.light_palette(\"green\", as_cmap=True)\npd.crosstab(df_train[Age_fare[0]], df_train[Age_fare[1]], \n            values=df_train['Fare'], aggfunc=['mean']).style.background_gradient(cmap = cm)\n",
            "mc_idx": 39,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1
                },
                "Data_Transform": {
                    ".cross": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    18,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<pandas.io.formats.style.Styler at 0x7f67c2e7cda0>"
                    ]
                },
                "mc_idx": 39,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 18,
                "o_idx": 0
            }
        },
        {
            "source": "# Seting the figure size\nplt.figure(figsize=(12,5))\n\n# Understanding the Fare Distribuition \nsns.distplot(df_train[df_train.Survived == 0][\"Fare\"], \n             bins=50, color='r')\nsns.distplot(df_train[df_train.Survived == 1][\"Fare\"], \n             bins=50, color='g')\nplt.title(\"Fare Distribuition by Survived\", fontsize=20)\nplt.xlabel(\"Fare\", fontsize=15)\nplt.ylabel(\"Density\",fontsize=15)\nplt.show()",
            "mc_idx": 42,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.1111111111111111,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2222222222222222,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "distplot": 2,
                    "sns.": 2,
                    "size": 5
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c019_o000_image_6.png",
                    19,
                    0,
                    6
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 864x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 42,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 19,
                "o_idx": 0
            }
        },
        {
            "source": "#Filling the NA's with -0.5\ndf_train.Fare = df_train.Fare.fillna(-0.5)\n\n#intervals to categorize\nquant = (-1, 0, 8, 15, 31, 600)\n\n#Labels without input values\nlabel_quants = ['NoInf', 'quart_1', 'quart_2', 'quart_3', 'quart_4']\n\n#doing the cut in fare and puting in a new column\ndf_train[\"Fare_cat\"] = pd.cut(df_train.Fare, quant, labels=label_quants)\n\n#Description of transformation\nprint(pd.crosstab(df_train.Fare_cat, df_train.Survived))\n\nplt.figure(figsize=(12,5))\n\n#Plotting the new feature\nsns.countplot(x=\"Fare_cat\", hue=\"Survived\", data=df_train, palette=\"hls\")\nplt.title(\"Count of survived x Fare expending\",fontsize=20)\nplt.xlabel(\"Fare Cat\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\n\nplt.show()",
            "mc_idx": 44,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.16666666666666666,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.8333333333333334,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.16666666666666666,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 4
                },
                "Data_Transform": {
                    ".fillna(": 1,
                    "transform": 1,
                    ".cut(": 1,
                    ".cross": 1,
                    ".fillna": 1,
                    ".cut": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c020_o001_image_7.png",
                    20,
                    1,
                    7
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Survived    0    1\nFare_cat          \nNoInf      14    1\nquart_1   175   51\nquart_2   155   62\nquart_3   112   99\nquart_4    93  129\n",
                        "<Figure size 864x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 44,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 20,
                "o_idx": 1
            }
        },
        {
            "source": "# Replicate the same to df_test\ndf_test.Fare = df_test.Fare.fillna(-0.5)\n\nquant = (-1, 0, 8, 15, 31, 1000)\nlabel_quants = ['NoInf', 'quart_1', 'quart_2', 'quart_3', 'quart_4']\n\ndf_test[\"Fare_cat\"] = pd.cut(df_test.Fare, quant, labels=label_quants)",
            "mc_idx": 45,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".fillna(": 1,
                    ".cut(": 1,
                    ".fillna": 1,
                    ".cut": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    21,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 45,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 21,
                "o_idx": 0
            }
        },
        {
            "source": "#Now lets drop the variable Fare, Age and ticket that is irrelevant now\ndel df_train[\"Fare\"]\ndel df_train[\"Ticket\"]\ndel df_train[\"Age\"]\ndel df_train[\"Cabin\"]\ndel df_train[\"Name\"]\n\n#same in df_test\ndel df_test[\"Fare\"]\ndel df_test[\"Ticket\"]\ndel df_test[\"Age\"]\ndel df_test[\"Cabin\"]\ndel df_test[\"Name\"]",
            "mc_idx": 47,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    22,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 47,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 22,
                "o_idx": 0
            }
        },
        {
            "source": "#Looking the result of transformations\ndf_train.head()",
            "mc_idx": 48,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.3333333333333333,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    "transform": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    23,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived  Pclass     Sex  SibSp  Parch Embarked Title  \\\n0            1         0       3    male      1      0        S    Mr   \n1            2         1       1  female      1      0        C   Mrs   \n2            3         1       3  female      0      0        S  Miss   \n3            4         1       1  female      1      0        S   Mrs   \n4            5         0       3    male      0      0        S    Mr   \n\n   Age_cat Fare_cat  \n0  Student  quart_1  \n1    Adult  quart_4  \n2    Young  quart_1  \n3    Young  quart_4  \n4    Young  quart_2  "
                    ]
                },
                "mc_idx": 48,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 23,
                "o_idx": 0
            }
        },
        {
            "source": "# Let see how many people die or survived\nprint(\"Total of Survived or not: \")\nprint(df_train.groupby(\"Survived\")[\"PassengerId\"].count())\n\nplt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Survived\", data=df_train,palette=\"hls\")\nplt.title('Total Distribuition by survived or not', fontsize=22)\nplt.xlabel('Target Distribuition', fontsize=18)\nplt.ylabel('Count', fontsize=18)\n\nplt.show()",
            "mc_idx": 51,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.16666666666666666,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.16666666666666666,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.16666666666666666,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 4,
                    ".groupby": 1
                },
                "Data_Transform": {
                    ".groupby(": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c024_o001_image_8.png",
                    24,
                    1,
                    8
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Total of Survived or not: \nSurvived\n0    549\n1    342\nName: PassengerId, dtype: int64\n",
                        "<Figure size 864x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 51,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 24,
                "o_idx": 1
            }
        },
        {
            "source": "print(pd.crosstab(df_train.Survived, df_train.Sex))\n\nplt.figure(figsize=(12,5))\nsns.countplot(x=\"Sex\", data=df_train, hue=\"Survived\",palette=\"hls\")\nplt.title('Sex Distribuition by survived or not', fontsize=20)\nplt.xlabel('Sex Distribuition',fontsize=17)\nplt.ylabel('Count', fontsize=17)\n\nplt.show()",
            "mc_idx": 52,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.2,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 4
                },
                "Data_Transform": {
                    ".cross": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c025_o001_image_9.png",
                    25,
                    1,
                    9
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Sex       female  male\nSurvived              \n0             81   468\n1            233   109\n",
                        "<Figure size 864x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 52,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 25,
                "o_idx": 1
            }
        },
        {
            "source": "# Distribuition by class\nprint(pd.crosstab(df_train.Pclass, df_train.Embarked))\n\nplt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Embarked\", data=df_train, hue=\"Pclass\",palette=\"hls\")\nplt.title('Embarked x Pclass Count', fontsize=20)\nplt.xlabel('Embarked with PClass',fontsize=17)\nplt.ylabel('Count', fontsize=17)\n\nplt.show()",
            "mc_idx": 55,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.2,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 4
                },
                "Data_Transform": {
                    ".cross": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c026_o001_image_10.png",
                    26,
                    1,
                    10
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Embarked   C   Q    S\nPclass               \n1         85   2  127\n2         17   3  164\n3         66  72  353\n",
                        "<Figure size 864x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 55,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 26,
                "o_idx": 1
            }
        },
        {
            "source": "#lets input the NA's with the highest frequency\ndf_train[\"Embarked\"] = df_train[\"Embarked\"].fillna('S')",
            "mc_idx": 56,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".fillna(": 1,
                    ".fillna": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    27,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 56,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 27,
                "o_idx": 0
            }
        },
        {
            "source": "# Exploring Survivors vs Embarked\nprint(pd.crosstab(df_train.Survived, df_train.Embarked))\n\nplt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Embarked\", data=df_train, hue=\"Survived\",palette=\"hls\")\nplt.title('Class Distribuition by survived or not',fontsize=20)\nplt.xlabel('Embarked',fontsize=17)\nplt.ylabel('Count', fontsize=17)\n\nplt.show()",
            "mc_idx": 57,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.2,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 4
                },
                "Data_Transform": {
                    ".cross": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c028_o001_image_11.png",
                    28,
                    1,
                    11
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Embarked   C   Q    S\nSurvived             \n0         75  47  427\n1         93  30  219\n",
                        "<Figure size 864x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 57,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 28,
                "o_idx": 1
            }
        },
        {
            "source": "# Exploring Survivors vs Pclass\nprint(pd.crosstab(df_train.Survived, df_train.Pclass))\n\nplt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Pclass\", data=df_train, hue=\"Survived\",palette=\"hls\")\nplt.xlabel('PClass',fontsize=17)\nplt.ylabel('Count', fontsize=17)\nplt.title('Class Distribuition by Survived or not', fontsize=20)\n\nplt.show()",
            "mc_idx": 58,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.2,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 4
                },
                "Data_Transform": {
                    ".cross": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c029_o001_image_12.png",
                    29,
                    1,
                    12
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Pclass      1   2    3\nSurvived              \n0          80  97  372\n1         136  87  119\n",
                        "<Figure size 864x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 58,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 29,
                "o_idx": 1
            }
        },
        {
            "source": "g = sns.factorplot(x=\"SibSp\",y=\"Survived\",data=df_train,\n                   kind=\"bar\", height = 5, aspect= 1.6, palette = \"hls\")\ng.set_ylabels(\"Probability(Survive)\", fontsize=15)\ng.set_xlabels(\"SibSp Number\", fontsize=15)\n\nplt.show()\n",
            "mc_idx": 61,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.3333333333333333,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.3333333333333333,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c030_o001_image_13.png",
                    30,
                    1,
                    13
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/opt/conda/lib/python3.6/site-packages/seaborn/categorical.py:3666: UserWarning: The `factorplot` function has been renamed to `catplot`. The original name will be removed in a future release. Please update your code. Note that the default `kind` in `factorplot` (`'point'`) has changed `'strip'` in `catplot`.\n  warnings.warn(msg)\n",
                        "<Figure size 576x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 61,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 30,
                "o_idx": 1
            }
        },
        {
            "source": "f",
            "mc_idx": 62,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    31,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 62,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 31,
                "o_idx": 0
            }
        },
        {
            "source": "# Explore Parch feature vs Survived\ng  = sns.factorplot(x=\"Parch\",y=\"Survived\",data=df_train, kind=\"bar\", size = 6,palette = \"hls\")\ng = g.set_ylabels(\"survival probability\")",
            "mc_idx": 64,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.5,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c032_o001_image_14.png",
                    32,
                    1,
                    14
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "/opt/conda/lib/python3.6/site-packages/seaborn/categorical.py:3672: UserWarning: The `size` paramter has been renamed to `height`; please update your code.\n  warnings.warn(msg, UserWarning)\n",
                        "<Figure size 432x432 with 1 Axes>"
                    ]
                },
                "mc_idx": 64,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 32,
                "o_idx": 1
            }
        },
        {
            "source": "#Create a new column and sum the Parch + SibSp + 1 that refers the people self\ndf_train[\"FSize\"] = df_train[\"Parch\"] + df_train[\"SibSp\"] + 1\n\ndf_test[\"FSize\"] = df_test[\"Parch\"] + df_test[\"SibSp\"] + 1",
            "mc_idx": 67,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    33,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 67,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 33,
                "o_idx": 0
            }
        },
        {
            "source": "print(pd.crosstab(df_train.FSize, df_train.Survived))\nsns.factorplot(x=\"FSize\",y=\"Survived\", data=df_train, kind=\"bar\",size=6, aspect=1.6)\nplt.show()",
            "mc_idx": 68,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.25,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.25,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 3
                },
                "Data_Transform": {
                    ".cross": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c034_o001_image_15.png",
                    34,
                    1,
                    15
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Survived    0    1\nFSize             \n1         374  163\n2          72   89\n3          43   59\n4           8   21\n5          12    3\n6          19    3\n7           8    4\n8           6    0\n11          7    0\n",
                        "<Figure size 691.2x432 with 1 Axes>"
                    ]
                },
                "mc_idx": 68,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 34,
                "o_idx": 1
            }
        },
        {
            "source": "del df_train[\"SibSp\"]\ndel df_train[\"Parch\"]\n\ndel df_test[\"SibSp\"]\ndel df_test[\"Parch\"]",
            "mc_idx": 69,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    35,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 69,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 35,
                "o_idx": 0
            }
        },
        {
            "source": "df_train.head()",
            "mc_idx": 72,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    36,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived  Pclass     Sex Embarked Title  Age_cat Fare_cat  \\\n0            1         0       3    male        S    Mr  Student  quart_1   \n1            2         1       1  female        C   Mrs    Adult  quart_4   \n2            3         1       3  female        S  Miss    Young  quart_1   \n3            4         1       1  female        S   Mrs    Young  quart_4   \n4            5         0       3    male        S    Mr    Young  quart_2   \n\n   FSize  \n0      2  \n1      2  \n2      1  \n3      2  \n4      1  "
                    ]
                },
                "mc_idx": 72,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 36,
                "o_idx": 0
            }
        },
        {
            "source": "df_train = pd.get_dummies(df_train, columns=[\"Sex\",\"Embarked\",\"Age_cat\",\"Fare_cat\",\"Title\"],\\\n                          prefix=[\"Sex\",\"Emb\",\"Age\",\"Fare\",\"Prefix\"], drop_first=True)\n\ndf_test = pd.get_dummies(df_test, columns=[\"Sex\",\"Embarked\",\"Age_cat\",\"Fare_cat\",\"Title\"],\\\n                         prefix=[\"Sex\",\"Emb\",\"Age\",\"Fare\",\"Prefix\"], drop_first=True)",
            "mc_idx": 74,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 2
                },
                "Data_Transform": {
                    ".get_dummies": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    37,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 74,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 37,
                "o_idx": 0
            }
        },
        {
            "source": "#Finallt, lets look the correlation of df_train\nplt.figure(figsize=(15,12))\nplt.title('Correlation of Features for Train Set')\nsns.heatmap(df_train.astype(float).corr(),vmax=1.0,  annot=True)\nplt.show()",
            "mc_idx": 75,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.16666666666666666,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.16666666666666666,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.5,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".corr": 2,
                    "sns.heatmap": 1,
                    ".heatmap(": 1,
                    "sns.": 1,
                    "size": 1
                },
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.heatmap": 1,
                    ".heatmap(": 1,
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c038_o000_image_16.png",
                    38,
                    0,
                    16
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 1080x864 with 2 Axes>"
                    ]
                },
                "mc_idx": 75,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 38,
                "o_idx": 0
            }
        },
        {
            "source": "df_train.shape",
            "mc_idx": 76,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "shape": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "shap": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    39,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "(891, 22)"
                    ]
                },
                "mc_idx": 76,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 39,
                "o_idx": 0
            }
        },
        {
            "source": "train = df_train.drop([\"Survived\",\"PassengerId\"],axis=1)\ntrain_ = df_train[\"Survived\"]\n\ntest_ = df_test.drop([\"PassengerId\"],axis=1)\n\nX_train = train.values\ny_train = train_.values\n\nX_test = test_.values\nX_test = X_test.astype(np.float64, copy=False)",
            "mc_idx": 77,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1,
                    ".drop": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    40,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 77,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 40,
                "o_idx": 0
            }
        },
        {
            "source": "# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)",
            "mc_idx": 78,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.6,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 10
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "fit_transform": 2,
                    "transform": 2,
                    "standardscaler": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    41,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 78,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 41,
                "o_idx": 0
            }
        },
        {
            "source": "from keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nimport keras\nfrom keras.optimizers import SGD\nimport graphviz",
            "mc_idx": 81,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.02,
                "Data_Transform": 0.02,
                "Model_Train": 0.02,
                "Model_Evaluation": 0.02,
                "Model_Interpretation": 0.02,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.02,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 5
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mode": 1
                },
                "Data_Transform": {
                    ".mod": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "graph": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    42,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Using TensorFlow backend.\n"
                    ]
                },
                "mc_idx": 81,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 42,
                "o_idx": 0
            }
        },
        {
            "source": "# Creating the model\nmodel = Sequential()\n\n# Inputing the first layer with input dimensions\nmodel.add(Dense(18, \n                activation='relu',  \n                input_dim=20,\n                kernel_initializer='uniform'))\n#The argument being passed to each Dense layer (18) is the number of hidden units of the layer. \n# A hidden unit is a dimension in the representation space of the layer.\n\n#Stacks of Dense layers with relu activations can solve a wide range of problems\n#(including sentiment classification), and you\u2019ll likely use them frequently.\n\n# Adding an Dropout layer to previne from overfitting\nmodel.add(Dropout(0.50))\n\n#adding second hidden layer \nmodel.add(Dense(60,\n                kernel_initializer='uniform',\n                activation='relu'))\n\n# Adding another Dropout layer\nmodel.add(Dropout(0.50))\n\n# adding the output layer that is binary [0,1]\nmodel.add(Dense(1,\n                kernel_initializer='uniform',\n                activation='sigmoid'))\n#With such a scalar sigmoid output on a binary classification problem, the loss\n#function you should use is binary_crossentropy\n\n#Visualizing the model\nmodel.summary()",
            "mc_idx": 83,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.1,
                "Data_Transform": 0.6,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.9,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".sum": 1
                },
                "Data_Transform": {
                    "stack": 1,
                    ".add": 5
                },
                "Model_Train": {
                    "sequential(": 1,
                    "model": 9
                },
                "Model_Evaluation": {
                    "model": 9
                },
                "Model_Interpretation": {
                    "model": 9,
                    "summary": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    43,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 18)                378       \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 18)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 60)                1140      \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 60)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 61        \n=================================================================\nTotal params: 1,579\nTrainable params: 1,579\nNon-trainable params: 0\n_________________________________________________________________\n"
                    ]
                },
                "mc_idx": 83,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 43,
                "o_idx": 0
            }
        },
        {
            "source": "#Creating an Stochastic Gradient Descent\nsgd = SGD(lr = 0.01, momentum = 0.9)\n\n# Compiling our model\nmodel.compile(optimizer = sgd, \n                   loss = 'binary_crossentropy', \n                   metrics = ['accuracy'])\n#optimizers list\n#optimizers['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n\n# Fitting the ANN to the Training set\nmodel.fit(X_train, y_train, \n               batch_size = 60, \n               epochs = 30, verbose=2)",
            "mc_idx": 86,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.16666666666666666,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.6666666666666666,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model.fit": 1,
                    "compile": 1,
                    ".fit(": 1,
                    "model": 3
                },
                "Model_Evaluation": {
                    "model": 3
                },
                "Model_Interpretation": {
                    "model": 3,
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    44,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Epoch 1/30\n - 4s - loss: 0.6899 - acc: 0.6150\nEpoch 2/30\n - 0s - loss: 0.6789 - acc: 0.6162\nEpoch 3/30\n - 0s - loss: 0.6711 - acc: 0.6162\nEpoch 4/30\n - 0s - loss: 0.6675 - acc: 0.6162\nEpoch 5/30\n - 0s - loss: 0.6660 - acc: 0.6162\nEpoch 6/30\n - 0s - loss: 0.6655 - acc: 0.6162\nEpoch 7/30\n - 0s - loss: 0.6652 - acc: 0.6162\nEpoch 8/30\n - 0s - loss: 0.6650 - acc: 0.6162\nEpoch 9/30\n - 0s - loss: 0.6646 - acc: 0.6162\nEpoch 10/30\n - 0s - loss: 0.6642 - acc: 0.6162\nEpoch 11/30\n - 0s - loss: 0.6640 - acc: 0.6162\nEpoch 12/30\n - 0s - loss: 0.6633 - acc: 0.6162\nEpoch 13/30\n - 0s - loss: 0.6621 - acc: 0.6162\nEpoch 14/30\n - 0s - loss: 0.6613 - acc: 0.6162\nEpoch 15/30\n - 0s - loss: 0.6594 - acc: 0.6162\nEpoch 16/30\n - 0s - loss: 0.6577 - acc: 0.6162\nEpoch 17/30\n - 0s - loss: 0.6549 - acc: 0.6162\nEpoch 18/30\n - 0s - loss: 0.6494 - acc: 0.6162\nEpoch 19/30\n - 0s - loss: 0.6440 - acc: 0.6162\nEpoch 20/30\n - 0s - loss: 0.6330 - acc: 0.6184\nEpoch 21/30\n - 0s - loss: 0.6154 - acc: 0.6532\nEpoch 22/30\n - 0s - loss: 0.5893 - acc: 0.7059\nEpoch 23/30\n - 0s - loss: 0.5621 - acc: 0.7497\nEpoch 24/30\n - 0s - loss: 0.5289 - acc: 0.7744\nEpoch 25/30\n - 0s - loss: 0.5310 - acc: 0.7587\nEpoch 26/30\n - 0s - loss: 0.4989 - acc: 0.7856\nEpoch 27/30\n - 0s - loss: 0.4777 - acc: 0.7811\nEpoch 28/30\n - 0s - loss: 0.4986 - acc: 0.7957\nEpoch 29/30\n - 0s - loss: 0.4710 - acc: 0.7912\nEpoch 30/30\n - 0s - loss: 0.4614 - acc: 0.7890\n",
                        "<keras.callbacks.History at 0x7f678a614828>"
                    ]
                },
                "mc_idx": 86,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 44,
                "o_idx": 1
            }
        },
        {
            "source": "y_preds = model.predict(X_test)\n\nsubmission = pd.read_csv(\"../input/gender_submission.csv\", index_col='PassengerId')\nsubmission['Survived'] = y_preds.astype(int)\nsubmission.to_csv('TitanicKNN.csv')",
            "mc_idx": 89,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.25,
                "Model_Evaluation": 0.5,
                "Model_Interpretation": 0.25,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.5,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 2,
                    "pd.read_": 2
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    45,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 89,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 45,
                "o_idx": 0
            }
        },
        {
            "source": "scores = model.evaluate(X_train, y_train, batch_size=30)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))",
            "mc_idx": 91,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 0.0,
                "Model_Train": 0.6666666666666666,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.6666666666666666,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 2
                },
                "Model_Evaluation": {
                    "model.evaluate": 1,
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    46,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "891/891 [==============================] - 0s 114us/step\nacc: 81.14%\n"
                    ]
                },
                "mc_idx": 91,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 46,
                "o_idx": 0
            }
        },
        {
            "source": "# Fit the model\nhistory = model.fit(X_train, y_train, validation_split=0.20, \n                    epochs=180, batch_size=10, verbose=0)\n\n# list all data in history\nprint(history.history.keys())",
            "mc_idx": 94,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.75,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model.fit": 1,
                    ".fit(": 1,
                    "model": 2
                },
                "Model_Evaluation": {
                    "model": 2,
                    "validation_split": 1
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    47,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
                    ]
                },
                "mc_idx": 94,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 47,
                "o_idx": 0
            }
        },
        {
            "source": "# summarizing historical accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n",
            "mc_idx": 96,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.16666666666666666,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.16666666666666666,
                "Model_Evaluation": 0.16666666666666666,
                "Model_Interpretation": 0.16666666666666666,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.6666666666666666,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plt.plot": 2,
                    ".plot(": 4
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "plt.plot": 2,
                    ".plot(": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c048_o000_image_17.png",
                    48,
                    0,
                    17
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 432x288 with 1 Axes>"
                    ]
                },
                "mc_idx": 96,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 48,
                "o_idx": 0
            }
        },
        {
            "source": "\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()",
            "mc_idx": 98,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.16666666666666666,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.16666666666666666,
                "Model_Evaluation": 0.16666666666666666,
                "Model_Interpretation": 0.16666666666666666,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.6666666666666666,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plt.plot": 2,
                    ".plot(": 4
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "plt.plot": 2,
                    ".plot(": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c049_o000_image_18.png",
                    49,
                    0,
                    18
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 432x288 with 1 Axes>"
                    ]
                },
                "mc_idx": 98,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 49,
                "o_idx": 0
            }
        },
        {
            "source": "y_pred = model.predict(X_test)",
            "mc_idx": 99,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.5,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1,
                    ".predict(": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    50,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 99,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 50,
                "o_idx": 0
            }
        },
        {
            "source": "# Trying to implementing the TensorBoard to evaluate the model\n\ncallbacks = [\n    keras.callbacks.TensorBoard(log_dir='my_log_dir',\n                                histogram_freq=1,\n                                embeddings_freq=1,\n                               )\n]",
            "mc_idx": 102,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    51,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 102,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 51,
                "o_idx": 0
            }
        },
        {
            "source": "#Importing the auxiliar and preprocessing librarys \nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate\nfrom sklearn.metrics import accuracy_score\n\n#Models\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import RidgeClassifier, SGDClassifier, LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, VotingClassifier, RandomTreesEmbedding",
            "mc_idx": 103,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.011764705882352941,
                "Data_Transform": 0.041176470588235294,
                "Model_Train": 0.15294117647058825,
                "Model_Evaluation": 0.08235294117647059,
                "Model_Interpretation": 0.03529411764705882,
                "Hyperparameter_Tuning": 0.01764705882352941,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 17
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".mode": 2
                },
                "Data_Transform": {
                    "labelencoder": 2,
                    "standardscaler": 1,
                    "pca": 1,
                    "randomtreesembedding": 1,
                    ".mod": 2
                },
                "Model_Train": {
                    "train_test_split": 1,
                    "cross_validate": 1,
                    "model": 5,
                    "randomforestclassifier": 2,
                    "kmeans": 1,
                    "model_selection": 2,
                    "logisticregression": 1,
                    "ridge": 1,
                    "sgdclassifier": 1,
                    "gradientboostingclassifier": 1,
                    "decisiontreeclassifier": 1,
                    "kneighborsclassifier": 1,
                    "svc": 3,
                    "multinomialnb": 1,
                    "votingclassifier": 1,
                    "pipeline": 2,
                    ".linear": 1
                },
                "Model_Evaluation": {
                    "confusion_matrix": 2,
                    "accuracy_score": 4,
                    "classification_report": 2,
                    "cross_val_score": 1,
                    "model": 5
                },
                "Model_Interpretation": {
                    "model": 5,
                    "gradient": 1
                },
                "Hyperparameter_Tuning": {
                    "cross_val_score": 1,
                    "kfold": 1,
                    "train_test_split": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    52,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 103,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 52,
                "o_idx": 0
            }
        },
        {
            "source": "clfs = []\nseed = 3\n\nclfs.append((\"LogReg\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"LogReg\", LogisticRegression())])))\n\nclfs.append((\"XGBClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"XGB\", XGBClassifier())]))) \nclfs.append((\"KNN\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"KNN\", KNeighborsClassifier())]))) \n\nclfs.append((\"DecisionTreeClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"DecisionTrees\", DecisionTreeClassifier())]))) \n\nclfs.append((\"RandomForestClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"RandomForest\", RandomForestClassifier())]))) \n\nclfs.append((\"GradientBoostingClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"GradientBoosting\", GradientBoostingClassifier(max_features=15, n_estimators=150))]))) \n\nclfs.append((\"RidgeClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"RidgeClassifier\", RidgeClassifier())])))\n\nclfs.append((\"BaggingRidgeClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"BaggingClassifier\", BaggingClassifier())])))\n\nclfs.append((\"ExtraTreesClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"ExtraTrees\", ExtraTreesClassifier())])))\n\n#'neg_mean_absolute_error', 'neg_mean_squared_error','r2'\nscoring = 'accuracy'\nn_folds = 10\n\nresults, names  = [], [] \n\nfor name, model  in clfs:\n    kfold = KFold(n_splits=n_folds, random_state=seed)\n    cv_results = cross_val_score(model, X_train, y_train, cv= 5, scoring=scoring, n_jobs=-1)    \n    names.append(name)\n    results.append(cv_results)    \n    msg = \"%s: %f (+/- %f)\" % (name, cv_results.mean(),  cv_results.std())\n    print(msg)\n    \n# boxplot algorithm comparison\nfig = plt.figure(figsize=(15,6))\nfig.suptitle('Classifier Algorithm Comparison', fontsize=22)\nax = fig.add_subplot(111)\nsns.boxplot(x=names, y=results)\nax.set_xticklabels(names)\nax.set_xlabel(\"Algorithmn\", fontsize=20)\nax.set_ylabel(\"Accuracy of Models\", fontsize=18)\nax.set_xticklabels(ax.get_xticklabels(),rotation=45)\nplt.show()",
            "mc_idx": 104,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Model_Train",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.038461538461538464,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.4230769230769231,
                "Data_Transform": 0.38461538461538464,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.34615384615384615,
                "Model_Interpretation": 0.23076923076923078,
                "Hyperparameter_Tuning": 0.11538461538461539,
                "Visualization": 0.07692307692307693,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".boxplot(": 2,
                    ".mean(": 1,
                    ".std(": 1,
                    "sns.": 1,
                    "size": 4,
                    ".mean": 1,
                    ".std": 1
                },
                "Data_Transform": {
                    "standardscaler": 9,
                    ".add": 1
                },
                "Model_Train": {
                    "model": 3,
                    "randomforestclassifier": 4,
                    "logisticregression": 1,
                    "ridge": 4,
                    "gradientboostingclassifier": 2,
                    "decisiontreeclassifier": 2,
                    "kneighborsclassifier": 1,
                    "pipeline": 9
                },
                "Model_Evaluation": {
                    "cross_val_score": 1,
                    "model": 3,
                    "mean_squared_error": 3,
                    "mean_absolute_error": 2
                },
                "Model_Interpretation": {
                    "model": 3,
                    "gradient": 3
                },
                "Hyperparameter_Tuning": {
                    "cross_val_score": 1,
                    "kfold": 2
                },
                "Visualization": {
                    ".boxplot(": 1,
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0057_c053_o003_image_19.png",
                    53,
                    3,
                    19
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "LogReg: 0.829444 (+/- 0.015722)\n",
                        "/opt/conda/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n",
                        "XGBClassifier: 0.820404 (+/- 0.019012)\nKNN: 0.782283 (+/- 0.021518)\nDecisionTreeClassifier: 0.797995 (+/- 0.016039)\nRandomForestClassifier: 0.804724 (+/- 0.012755)\nGradientBoostingClassifier: 0.815979 (+/- 0.020409)\nRidgeClassifier: 0.818239 (+/- 0.025687)\nBaggingRidgeClassifier: 0.801359 (+/- 0.016683)\nExtraTreesClassifier: 0.802496 (+/- 0.010934)\n",
                        "<Figure size 1080x432 with 1 Axes>"
                    ]
                },
                "mc_idx": 104,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 53,
                "o_idx": 3
            }
        }
    ],
    "markdown_cells": [
        {
            "source": "<h1> Welcome to my Titanic Kernel! </h1>\n<h2>This kernel will provide a analysis through the Titanic Disaster to understand the Survivors patterns</h2><br>\n\nI will handle with data (<i>transform, missings, manipulation</i>), explore the data (<i>descritive and visual</i>) and also create a Deep Learning model",
            "mc_idx": 0,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Are you looking for another interesting Kernels? <a href=\"https://www.kaggle.com/kabure/kernels\">CLICK HERE</a> <br>\nGive me your feedback and if yo like this kernel, votes up",
            "mc_idx": 1,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<i>*I'm from Brazil, so english is not my first language, sorry about some mistakes</i>",
            "mc_idx": 2,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Table of Contents:\n\n**1. [Introduction](#Introduction)** <br>\n**2. [Librarys](#Librarys)** <br>\n**3. [Knowning the data](#Known)** <br>\n**4. [Exploring some Variables](#Explorations)** <br>\n**5. [Preprocessing](#Prepocess)** <br>\n**6. [Modelling](#Model)** <br>\n**7. [Validation](#Validation)** <br>\n",
            "mc_idx": 3,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<a id=\"Introduction\"></a> <br> \n# **1. Introduction:** \n<h3> The data have 891 entries on train dataset and 418 on test dataset</h3>\n- 10 columns in train_csv and 9 columns in train_test\n",
            "mc_idx": 4,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h2>Competition Description: </h2>\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n\nOne of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n\nIn this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.",
            "mc_idx": 5,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h3>Data Dictionary</h3><br>\nVariable\tDefinition\tKey<br>\n<b>survival</b>\tSurvival\t0 = No, 1 = Yes<br>\n<b>pclass</b>\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd<br>\n<b>sex</b>\tSex\t<br>\n<b>Age</b>\tAge in years\t<br>\n<b>sibsp</b>\t# of siblings / spouses aboard the Titanic\t<br>\n<b>parch</b>\t# of parents / children aboard the Titanic\t<br>\n<b>ticket</b>\tTicket number\t<br>\n<b>fare</b>\tPassenger fare\t<br>\n<b>cabin</b>\tCabin number\t<br>\n<b>embarked\t</b>Port of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton<br>\n<h3>Variable Notes</h3><br>\n<b>pclass: </b>A proxy for socio-economic status (SES)<br>\n1st = Upper<br>\n2nd = Middle<br>\n3rd = Lower<br>\n<b>age: </b>Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br>\n<b>sibsp:</b> The dataset defines family relations in this way...<br>\n- <b>Sibling </b>= brother, sister, stepbrother, stepsister<br>\n- <b>Spouse </b>= husband, wife (mistresses and fianc\u00e9s were ignored)<br>\n\n<b>parch: </b>The dataset defines family relations in this way...<br>\n- <b>Parent</b> = mother, father<br>\n- <b>Child </b>= daughter, son, stepdaughter, stepson<br>\n\nSome children travelled only with a nanny, therefore parch=0 for them.<br>",
            "mc_idx": 6,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "I am using the beapproachs as possible but if you think I can do anything another best way, please, let me know.",
            "mc_idx": 7,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<a id=\"Librarys\"></a> <br> \n# **2. Librarys:** ",
            "mc_idx": 8,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<a id=\"Known\"></a> <br> \n# **3. First look at the data:** ",
            "mc_idx": 11,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "I will start looking the type and informations of the datasets",
            "mc_idx": 12,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<a id=\"Known\"></a> <br> \n# **4. Exploring the data:** ",
            "mc_idx": 16,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h2>To try a new approach in the data, I will start the data analysis by the Name column",
            "mc_idx": 17,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## Grouping some titles and ploting the results",
            "mc_idx": 21,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## Title grouped",
            "mc_idx": 23,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "It's interesting... Children's and ladys first, huh?",
            "mc_idx": 25,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h1> Now I will handle the Age variable that has a high number of NaN's, using some columns to correctly input he missing Age's",
            "mc_idx": 26,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "This might show us a better way to input the NAN's \n\n<b>For example: </b> an male in 2 class that is a Officer the median Age is 42. <br>\nAnd we will use that to complete the missing data\n",
            "mc_idx": 29,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Now let's categorize them ",
            "mc_idx": 33,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Now it look's better and clearly",
            "mc_idx": 37,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## Let's cross our Pclass with the Age_cat \nWe will aggregate than to get the mean of Fare by each category pair\n",
            "mc_idx": 38,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "- Very interesting. We can see that babies has the highest mean value. ",
            "mc_idx": 40,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "### Looking the Fare distribuition to survivors and not survivors\n",
            "mc_idx": 41,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<br>\nDescription of Fare variable<br>\n- Min: 0<br>\n- Median: 14.45<br>\n- Mean: 32.20<br>\n- Max: 512.32<br> \n- Std: 49.69<br>\n\n<h3>I will create a categorical variable to treat the Fare expend</h3><br>\nI will use the same technique used in Age but now I will use the quantiles to binning\n\n",
            "mc_idx": 43,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h2>To complete this part, I will now work on \"Names\"",
            "mc_idx": 46,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h1>It's looking ok",
            "mc_idx": 49,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Now, lets start explore the data",
            "mc_idx": 50,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h2>We can look that % dies to mens are much higher than female",
            "mc_idx": 53,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h1>Now, lets do some exploration in Pclass and Embarked to see if might have some information to build the model",
            "mc_idx": 54,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<b>Looking the graphs, is clear that 3st class and Embarked at Southampton have a high probabilities to not survive</b>",
            "mc_idx": 59,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "To finish the analysis I let's look the Sibsp and Parch variables",
            "mc_idx": 60,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Interesting. With 1 or 2 siblings/spouses have more chance to survived the disaster",
            "mc_idx": 63,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "We can see a high standard deviation in the survival with 3 parents/children person's <br>\nAlso that small families (1~2) have more chance to survival than single or big families",
            "mc_idx": 65,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "So to Finish our exploration I will create a new column to with familiees size",
            "mc_idx": 66,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "OK, its might be enough to start with the preprocess and builting the model\n",
            "mc_idx": 70,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<a id=\"Preprocess\"></a> <br> \n# **5. Preprocessing :** ",
            "mc_idx": 71,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Now we might have information enough to think about the model structure",
            "mc_idx": 73,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<a id=\"Model\"></a> <br> \n# **6. Modelling : ** ",
            "mc_idx": 79,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h3>Titanic survivors prediction: <br>\na binary classification example</h3>\nTwo-class classification, or binary classification, may be the most widely applied kind of machine-learning problem.",
            "mc_idx": 80,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h1>Anatomy of a neural network: </h1>\n\nAs you saw in the previous chapters, training a neural network revolves around the following\nobjects:\n- Layers, which are combined into a network (or model)\n- The input data and corresponding targets\n- The loss function, which defines the feedback signal used for learning\n- The optimizer, which determines how learning proceeds\n\n\n\n\n<h2> Layers: the building blocks of deep learning</h2>\nfrom keras import layers<br>\nlayer = layers.Dense(32, input_dim=data_dimension)) \n\n- We can think of layers as the LEGO bricks of deep learning, a metaphor that is\nmade explicit by frameworks like Keras. Building deep-learning models in Keras is\ndone by clipping together compatible layers to form useful data-transformation pipelines.\n\n\n<h2>What are activation functions, and why are they necessary?</h2>\nWithout an activation function like relu (also called a non-linearity), the Dense layer would consist of two linear operations\u2014a dot product and an addition: <br><br>\n<i>output = dot(W, input) + b</i><br><br>\n\nSo the layer could only learn linear transformations (affine transformations) of the\ninput data: the hypothesis space of the layer would be the set of all possible linear\ntransformations of the input data into a 16-dimensional space. \n\n\n<h2>Loss functions and optimizers:<br>\nkeys to configuring the learning process</h2>\nOnce the network architecture is defined, you still have to choose two more things:\n- <b>Loss function (objective function) </b>- The quantity that will be minimized during\ntraining. It represents a measure of success for the task at hand.\n- <b>Optimizer</b> - Determines how the network will be updated based on the loss function.\nIt implements a specific variant of stochastic gradient descent (SGD).",
            "mc_idx": 82,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Stacks of Dense layers with relu activations can solve a wide range of problems (including sentiment classification), and you\u2019ll likely use them frequently.",
            "mc_idx": 84,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Finally, we need to choose a loss function and an optimizer. ",
            "mc_idx": 85,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Because you\u2019re facing a binary classification problem and the output of your network is a probability (you end your network with a single-unit layer with a sigmoid activation), it\u2019s best to use the <i>binary_crossentropy</i> loss.",
            "mc_idx": 87,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## Predicting X_test",
            "mc_idx": 88,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h1>Evaluating the model</h1>",
            "mc_idx": 90,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Not bad result to a simple model! Let's now verify the validation of our model, to see and understand the learning curve",
            "mc_idx": 92,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<a id=\"Validation\"></a> <br> \n# **7. Validation: ** ",
            "mc_idx": 93,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Let's look this keys values further",
            "mc_idx": 95,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Why this occurs and how to solve this problem in graph? it's a overffiting? ",
            "mc_idx": 97,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "<h1>It's my first Deep Learning implementation... I am studying about this and I will continue editing this Kernel to improve the results</h1>",
            "mc_idx": 100,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "Give me your feedback how can I increase this model =) ",
            "mc_idx": 101,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# Stay tuned and don't forget to votesup this kernel",
            "mc_idx": 105,
            "nb_idx": 57,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        }
    ],
    "sim_matrix": [
        0.9575974345207214,
        0.9450547695159912,
        0.9610203504562378,
        0.954998254776001,
        0.9390446543693542,
        0.9508012533187866,
        0.9612219333648682,
        0.9701793193817139,
        0.9487913846969604,
        0.9320403933525085,
        0.9802579283714294,
        0.9532926678657532,
        0.9648164510726929,
        0.9542344212532043,
        0.9696455001831055,
        0.9641981720924377,
        0.9680435657501221,
        0.9508012533187866,
        0.9543457627296448,
        0.94694983959198,
        0.9609538316726685,
        0.9701793193817139,
        0.9766483902931213,
        0.9429617524147034,
        0.9245274662971497,
        0.9676370620727539,
        0.9622169733047485,
        0.9714602828025818,
        0.9622841477394104,
        0.906592071056366,
        0.9626765847206116,
        0.941504955291748,
        0.9294054508209229,
        0.9431607127189636,
        0.9427069425582886,
        0.9487805962562561,
        0.9427069425582886,
        0.9675516486167908,
        0.9479390382766724,
        0.9064654111862183,
        0.9328438639640808,
        0.9678338170051575,
        0.9382115006446838,
        0.9609538316726685,
        0.9518360495567322,
        0.9429617524147034,
        0.9446359276771545,
        0.9294054508209229,
        0.9586982727050781,
        0.9667903780937195,
        0.9553825855255127,
        0.9487805962562561,
        0.9641981720924377,
        0.9620503187179565,
        0.945523202419281,
        0.9564089775085449,
        0.9272002577781677,
        1.0000001192092896,
        0.9631184339523315,
        0.9700621962547302,
        0.9612694978713989,
        0.9626980423927307,
        0.9540948271751404,
        0.9524748921394348,
        0.9575691223144531,
        0.9649747610092163,
        0.9261787533760071,
        0.7576076984405518,
        0.9748585224151611,
        0.9399071335792542,
        0.9644254446029663,
        0.9471720457077026,
        0.9654406309127808,
        0.9514113068580627,
        0.9603792428970337,
        0.9630657434463501,
        0.923166036605835,
        0.9655247330665588,
        0.9509546756744385,
        0.9545702338218689,
        0.9402389526367188,
        0.9551839232444763,
        0.9560770392417908,
        0.9281577467918396,
        0.9554301500320435,
        0.9708139896392822,
        0.9668723344802856,
        0.9766483902931213,
        0.9517263174057007,
        0.9466794729232788,
        0.9675516486167908,
        0.94694983959198,
        0.9431607127189636,
        0.9633597135543823,
        0.925015389919281,
        0.92600417137146,
        0.9147711992263794,
        0.9077368378639221
    ],
    "cell_sim_matrix": [],
    "nb_order": [],
    "summary_data_VA": null
}