{
    "nb_idx": 89,
    "nb_name": "d0089",
    "filename": "titanic-survivor-predict-eda-lightgbm-kor-eng.ipynb",
    "filepath": "data/data_Kaggle/raw/titanic-survivor-predict-eda-lightgbm-kor-eng.ipynb",
    "source": "#### \ucc98\uc74c\uc73c\ub85c kaggle\uc5d0 \ucc38\uc5ec\ud558\uc5ec \ucf54\ub4dc\ub97c \uc62c\ub9bd\ub2c8\ub2e4. \n#### \ub300\ud68c Rule\uacfc Scoring\uae30\uc900\uc5d0 \ub530\ub77c \ud0c0\uc774\ud0c0\ub2c9 \uc0dd\uc874\uc790 \uc608\uce21\uc758 Accuracy\ub97c \uac00\uc7a5 \ub192\uac8c \uc0b0\ucd9c\ud558\ub294 \ubaa8\ub378\uc744 \ub9cc\ub4e4 \uc608\uc815\uc785\ub2c8\ub2e4.    \n#### This is my first time participating in kaggle. \n#### In this code, I tried to make a model with high accuracy to predict the Titanic survivor. \n ## 1. \ubaa8\ub4c8 \ubd88\ub7ec\uc624\uae30 (Import module)\n \n#### \uc81c\uac00 \uac00\uc7a5 \uc790\uc8fc \uc4f0\ub294 \ubaa8\ub4c8\ub4e4\uc744 \ubd88\ub7ec\uc62c \uc608\uc815\uc785\ub2c8\ub2e4.\n#### It will load all the modules I use the most. \n import seaborn as sns\nimport sys\nimport csv\nimport datetime\nimport operator\nimport joblib\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import scale\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score\nfrom statsmodels.formula.api import ols\nfrom sklearn.metrics import cohen_kappa_score\nfrom collections import OrderedDict\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom scipy.stats import norm, skew, probplot \n ## 2. \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30(Read Dataset) \n df_train = pd.read_csv('/kaggle/input/titanic/train.csv')\ndf_test = pd.read_csv('/kaggle/input/titanic/test.csv')\ngender_submission = pd.read_csv('/kaggle/input/titanic/gender_submission.csv') \n ## 3. \ud0d0\uc0c9\uc801 \ub370\uc774\ud130 \ubd84\uc11d (EDA)\n#### \ud5a5\ud6c4 \ub2e8\uacc4\ubcc4\ub85c Competition \ucc38\uc5ec\ub97c \ud558\uba74\uc11c def \ud568\uc218\ub85c \ubb36\uc5b4\uc11c \uc790\ub3d9\uc73c\ub85c \ud560 \uc218 \uc788\ub3c4\ub85d \ub9cc\ub4e4 \uc608\uc815\uc785\ub2c8\ub2e4.\n#### \uc6b0\uc120 \ud574\ub2f9 \ub370\uc774\ud130\uc758 Column\ub4e4\uc774 \uc5b4\ub5a4 \uac83\uc774 \uc788\uace0, \ud1b5\uacc4\uc801\uc73c\ub85c \uc5b4\ub5a0\ud55c \uacb0\uacfc\uac00 \uc788\ub294\uc9c0 \ud655\uc778\ud560 \uac81\ub2c8\ub2e4.\n\n#### In the future, while participating in the competition step by step, \n#### I plan to bind it with the def function so that it can be done automatically.\n#### First, I will check what the columns of the data are and what the statistical results are. \n df_train.head(5) \n df_test.head(5) \n gender_submission.head(5)\n# head()\ub97c \ud65c\uc6a9\ud558\uc5ec \ubcfc\ub54c PassengerId\ub97c \ud1b5\ud574\uc11c test data\uc758 \uacb0\uacfc\ub97c \uc608\uce21\ud560 \uc218 \uc788\uc74c\uc744 \uc608\uc0c1\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n# When using head(), it can be expected that the result of test data can be predicted through PassengerId. \n # 'Survived' column\uc744 \uc798 \ubd99\uc600\ub294\uc9c0 \ud655\uc778 \ud569\ub2c8\ub2e4.\n# Check if the 'Survived' column is attached properly.\ndf_test['Survived'] = gender_submission['Survived']\ndf_test.head(5) \n #\ud1b5\uacc4\uc801\uc73c\ub85c \ubd84\ud3ec\uac00 \uc5b4\ub5a0\ud55c\uc9c0 Pair Plot \ubc0f \uc5ec\ub7ec \uadf8\ub798\ud504\ub97c \ud1b5\ud558\uc5ec \ubd84\uc11d\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n# Let's analyze how the distribution is statistically through pair plots and several graphs.\n\nsns.pairplot(data = df_train) \n def analysis(data):\n    print(\"1. \uccab\ubc88\uc9f8 \uadf8\ub798\ud504\ub294 Data\uc758 Heatmap \ubd84\uc11d \uacb0\uacfc\uc785\ub2c8\ub2e4.\uc0c1\uad00\uad00\uacc4\uac00 \ub192\uc744\uc218\ub85d \uc0c9\uae54\uc774 \uc9c4\ud558\ub3c4\ub85d \ud45c\uc2dc\ud558\uc600\uc2b5\ub2c8\ub2e4.\")\n    print(\"2. \ub450\ubc88\uc9f8 \uadf8\ub798\ud504\ub294 null ratio\ub97c \uadf8\ub798\ud504\ub85c \ud45c\uc2dc\ud558\uc600\uc2b5\ub2c8\ub2e4.\")\n    sns.heatmap(data.corr(), annot=True, cmap='Reds')\n    null_percent = 100*(data.isnull().sum()/len(data))\n    null_percent = null_percent[null_percent>0].sort_values()\n    plt.figure(figsize= (10,4))\n    sns.barplot(x=null_percent.index, y= null_percent)\n    plt.xticks(rotation=90) \n analysis(df_train) \n analysis(df_test) \n fat=ols(formula='Survived~PassengerId+Pclass+Age+Sex+SibSp+Parch+Fare+Embarked', data=df_train).fit()\nprint(fat.summary())\n\n# \ud1b5\uacc4\uc801\uc73c\ub85c\ub294 \uc131\ubcc4\uc5d0 \ub530\ub978 \uad6c\ubd84\uacfc Pclass\uc5d0 \ub530\ub77c \uc0dd\uc874\ub960\uc774 \uc601\ud5a5\ub3c4\uac00 \uac00\uc7a5 \ub192\uc740 \uac83\uc73c\ub85c \ub098\uc654\uace0, \n# OLS Regression\uc73c\ub85c \uc608\uce21\uc2dc \uc0c1\uae30\uc758 8\uac1c \ubcc0\uc218\ub9cc\uc73c\ub85c \ubcf8\ub2e4\uba74, R-squre 0.4/ Adjust R-square 0.39\uc218\uc900\uc758 \uc608\uce21\uc774 \uac00\ub2a5 \ud560 \uac83\uc73c\ub85c \uc608\uc0c1 \ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n\n# Statistically, it was found that the survival rate was the most influential according to the classification according to gender and Pclass.\n# When predicting with OLS regression, if we consider only the above 8 variables, it was expected that the R-squre 0.4/ Adjust R-square 0.39 level could be predicted. \n # \uc22b\uc790 \ud0c0\uc785\uc758 \ub370\uc774\ud130 \ucd94\ucd9c\n# Numeric Feature Enginearing\n\nnum_cols = [col for col in df_train.columns if df_train[col].dtype in ['int64','float64']]\ndf_train[num_cols].describe() \n df_train.corr(method='pearson') \n df_train.info() \n # \ub370\uc774\ud130\ub0b4 \uc911\ubcf5 \uac12\uc740 \uc5c6\ub294\uc9c0 \ud655\uc778\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \n# Let's check that there are no duplicate values in the data.\n\ndf_train=df_train.drop_duplicates() \n df_train.info() \n # \uc65c\ub3c4\uc640 \ucca8\ub3c4\ub97c \ud655\uc778\ud558\ub294 \uacbd\uc6b0 Regression Modeling\ud560 \uacbd\uc6b0 \ub9ce\uc774 \ubcf4\ub098, \uae08\ubc88\uc758 \uacbd\uc6b0\ub294 \ub2e8\uc21c\ud788 \uc6b0\ub9ac\uac00 \uc54c\uace0 \uc2f6\uc740 Y\uac12(Survived)\uc758 \ubd84\ud3ec\uac00 3:2\ub77c\ub294 \uac83\n# \uc815\ub3c4 \ubc16\uc758 \uc815\ubcf4\ub97c \uc5bb\uc744\uc218 \uc5c6\uc5c8\uc2b5\ub2c8\ub2e4.\n\n# When checking skewness and kurtosis, it is often seen in Regression Modeling, but in this case, we could not simply obtain information other than that the distribution of Y-value (Survived) we wanted to know was 3:2.\nprint(f'skew: {df_train.Survived.skew()}')\nprint(f'kert: {df_train.Survived.kurt()}')\nsns.distplot(df_train.Survived, fit = norm)\nf = plt.figure()\nprobplot(df_train.Survived, plot = plt)\nplt.show() \n def count_plot(d, y, x):\n    plt.figure(figsize=(12,6))\n    sns.countplot(x = d[y], hue = x, data=d)\n    plt.ylabel('Number of people')\n    plt.title('Survival count by '+ x) \n numeric_cols = [col for col in df_train if df_train[col].dtype in ['int64','float64']]\nnumeric_cols.remove('Survived')\ny = 'Survived'\nover_column_name = list()\n\nfor i in numeric_cols:\n    if (len(df_train[i].value_counts())<20):\n        count_plot(df_train, y, i)\n    elif (len(df_train[i].value_counts())>20):\n        over_column_name.append(i)\n\nprint('Column\ub0b4 \ubcc0\uc218\uac00 20\uac1c \uc774\uc0c1\uc758 Column\uc740 \ud558\ub2e8\uacfc \uac19\uc2b5\ub2c8\ub2e4.\\n\ubcc0\uc218 20\uac1c \ubbf8\ub9cc\uc758 Column\uacfc Survived \uc22b\uc790 \ubd84\ud3ec\ub294 \uadf8\ub798\ud504\uc640 \uac19\uc2b5\ub2c8\ub2e4.')\nprint(over_column_name) \n print(num_cols)\nnum_cols.remove('PassengerId')\n\nfig, ax = plt.subplots(3, 2, figsize=(20, 10))\n\nfor variable, subplot in zip(num_cols, ax.flatten()):\n    sns.countplot(df_train[variable], ax=subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(60)\n        \nplt.tight_layout() \n cat_cols = [col for col in df_train if df_train[col].dtype not in ['int64','float64']]\nprint(cat_cols)\ncat_cols.remove('Name')\n\nfig, ax = plt.subplots(2, 2, figsize=(20, 10))\n\nfor variable, subplot in zip(cat_cols, ax.flatten()):\n    sns.countplot(df_train[variable], ax=subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(90)\n        \nplt.tight_layout() \n # train data\uc0c1 null\uac12\uc744 \ud655\uc778\ndf_train.isna().sum() \n df_train=df_train.drop(['Name','Ticket'],axis=1)\ndf_test=df_test.drop(['Name','Ticket'],axis=1) \n # Cabin \uc815\ubcf4\ub294 \ub2e4 \ubc84\ub9ac\uae30 \uc544\uae4c\uc6cc \uae00\uc790\uc218\ub97c \ubcc0\uc218\ub85c \ud55c\ubc88 \ud65c\uc6a9\ud574\ubcfc \uc0dd\uac01\uc785\ub2c8\ub2e4.\n# Rather than deleting the Cabin column, I will use \"len()\" to use the number of characters in the variable.\ndf_train['CabinCode'] = df_train['Cabin'].apply(lambda x : len(str(x)) if x!='nan' else 0)\ndf_test['CabinCode'] = df_test['Cabin'].apply(lambda x  : len(str(x)) if x!='nan' else 0) \n df_train=df_train.drop(['Cabin'],axis=1)\ndf_test=df_test.drop(['Cabin'],axis=1) \n # nan\uac12 \uc5ed\uc2dc \ud558\ub098\uc758 \ubcc0\uc218\uac00 \uc544\ub2d0\uae4c\ub77c\ub294 \uac00\uc815\ud558\uc5d0 \uae08\ubc88 \ubd84\uc11d\uc5d0\uc11c\ub294 null\uac12\uc5d0 \ub300\ud55c \ubcf4\uc815 \uc5c6\uc774 \uc9c4\ud589\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n# Assuming that the nan value is also a variable, in this analysis, we will proceed without correction for the null value.\n\ndf_train=pd.get_dummies(df_train)\ndf_test=pd.get_dummies(df_test) \n df_train.info()\ndf_test.info() \n df_train.head(5) \n ## 4. \ubaa8\ub378\ub9c1(Modeling) \n#### \ud559\uc2b5 \uc9c4\ud589\uc744 \uc704\ud558\uc5ec Train, validation, test data\ub97c \ub098\ub204\uace0, HyperParameter\ub97c \ub123\uc5b4 \ud559\uc2b5\uae4c\uc9c0 \uc2dc\ud0a4\uaca0\uc2b5\ub2c8\ub2e4.\n#### In order to proceed with the training, we will divide the Train, validation, and test data, and put HyperParameter to train it. \n # 7:3\uc73c\ub85c \uc81c\uacf5\ub41c train data\ub97c train\uacfc validation data\ub85c \uad6c\ubd84\n\nfrom sklearn.model_selection import train_test_split\n\nrandom_state_val =42\ntest_size_val =0.3\ntrain,validation = train_test_split(df_train, test_size = test_size_val, random_state = random_state_val) \n # \"read.csv\"\ub97c \uc4f0\ub2e4\ubcf4\uba74 \uac00\ub054 Unnamed: 0\uc73c\ub85c \ubb38\uc81c\ubc1c\uc0dd\uc774 \ub9ce\uc774 \ubc1c\uc0dd\ud568\n# \uadf8\ub798\uc11c \uc800\ub294 \ubd84\uc11d\uc2dc \ubb34\uc870\uac74 \ub123\uc5b4\uc11c \uc2e4\ud589\ud558\uace4 \ud569\ub2c8\ub2e4.\n\n# When I use the \"read.csv\" function, sometimes I get a lot of problems with Unnamed: 0. So, when I analyze, I put it in unconditionally and run it.\n#train = train.drop(['Unnamed: 0'], axis= 1)\n#validation = validation.drop(['Unnamed: 0'], axis= 1)\n#test = df_test.drop(['Unnamed: 0'], axis= 1) \n drop_col = ['Survived']\ny_nm = 'Survived'\n\ndf_train_x = train.drop(drop_col, axis = 1)\ndf_train_y = pd.DataFrame(train[y_nm])\n\ndf_val_x = validation.drop(drop_col, axis = 1)\ndf_val_y = pd.DataFrame(validation[y_nm])\n\ndf_test_x = df_test.drop(drop_col, axis = 1)\ndf_test_y = pd.DataFrame(df_test[y_nm]) \n LGBClassifier = lgb.LGBMClassifier(objective='binary',\n                                   max_depth = 8,\n                                   learning_rate = 0.01,\n                                   n_estimators = 9000,\n                                   max_bin = 200,\n                                   bagging_freq = 4,\n                                   bagging_seed = 8,\n                                   feature_fraction = 0.2,\n                                   feature_fraction_seed = 8,\n                                   min_sum_hessian_in_leaf = 11,\n                                   verbose = -1,\n                                   random_state = 42) \n start = datetime.datetime.now()\nlgbm = LGBClassifier.fit(df_train_x.values,\n                       df_train_y.values.ravel(),\n                       eval_set = [(df_train_x.values, df_train_y), (df_val_x.values, df_val_y)],\n                       eval_metric ='logloss',\n                       early_stopping_rounds = 20,\n                       verbose =False)\nend = datetime.datetime.now()\nend-start \n # Importance \ud655\uc778 \n# \uc8fc\uc694 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294 \ubcc0\uc218\uac00 \ubb34\uc5c7\uc778\uc9c0 \ud655\uc778\uc744 \ud558\uace0, \uc774\ub97c \uadf8\ub798\ud504\ud654 \uc9c4\ud589\ud558\uc600\uc2b5\ub2c8\ub2e4.\n# We checked the variables that have a major impact, and graphed them.\n\nfeature_imp= pd.DataFrame(sorted(zip(lgbm.feature_importances_, df_test_x.columns), reverse = True), columns = ['Value', 'Feature'])\n# feature_imp.to_excel(\"feature_imp.xlsx\")\n\nplt.figure(figsize=(7,5))\nsns.barplot(x='Value', y='Feature', data=feature_imp.sort_values(by='Value', ascending=False))\nplt.tight_layout()\nplt.show()\n# plt.savefig('lightGBM_ Importances.png') \n # for loop\ub97c \uc0ac\uc6a9\ud558\uc5ec \uac00\uc7a5 \ub192\uc740 accuracy\ub97c \uc0b0\ucd9c\ud558\ub294 \ub85c\uc9c1\uc744 \ub123\uc5c8\uc2b5\ub2c8\ub2e4. \n# I put the logic that yields the highest accuracy using a for loop.\n\nresult_lst =[]\nmax_accuracy =0.\nopt_threshold =0.\nval_y_prob = lgbm.predict_proba(df_val_x.values)[:, 1]\n\nfor n in range(0,60):\n    threshold = round(((n+1)*0.01),2)\n    pred_yn = val_y_prob.copy()\n    pred_yn = np.where(pred_yn > threshold, 1., 0.)\n    \n    result_dict = {}\n    precision, recall, f1_score, support = precision_recall_fscore_support(df_val_y.values.ravel(), pred_yn, average='binary')\n    accuracy = accuracy_score(df_val_y.values.ravel(), pred_yn)\n    kappa = cohen_kappa_score(df_val_y.values.ravel(), pred_yn)\n    \n    result_dict ={'Threshold': threshold, 'Accuracy': round(accuracy,4), 'Precision': round(precision,4), 'Recall': round(recall,4), 'F1_Score': round(f1_score,4), 'Kappa': round(kappa,4)}\n    result_lst.append(result_dict)\n    \n    if max_accuracy <= accuracy:\n        max_accuracy = accuracy\n        opt_threshold = threshold\n        \n    confMat = confusion_matrix(df_val_y.values.ravel(), pred_yn, labels=[1,0])\n    \nmatric_df = pd.DataFrame(result_lst, columns=['Threshold','Accuracy', 'Precision', 'Recall', 'F1_Score', 'Kappa'])\nmatric_df.to_csv('REC_scores.csv',sep=',', header=True, index=False, encoding='UTF-8')\n\nprint('\ucd5c\uace0 Accuracy-SCORE =%f, \uc784\uacc4\uce58=%f'%(max_accuracy, opt_threshold))\nprint('Threshold \uc124\uc815 \uc644\ub8cc') \n ## 5. \ubaa8\ub378 \uacb0\uacfc \ubd84\uc11d(Analyze model results)\n#### \ubaa8\ub378\uc744 \ud1b5\ud574 \ub098\uc628 train, validation, test \uacb0\uacfc\uce58(precision\uc5d0\uc11c\ubd80\ud130 F1-Score, AUROC\uae4c\uc9c0)\ub97c \uc0b0\uc2dd\uc744 \uc9c1\uc811 \uacc4\uc0b0\ud558\uc5ec \uacb0\uacfc\uac00 \ub098\uc624\ub3c4\ub85d \uad6c\ud604\ud574 \ubcf4\uc558\uc2b5\ub2c8\ub2e4.\n#### I tried to implement the results by directly calculating the train, validation, and test results (from precision to F1-Score, AUROC) through the model. \n predict_lgbm = lgbm.predict_proba(df_train_x.values)[:,1]\npred_train = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_train_y.values.ravel(), pred_train, labels=[1,0]).ravel() \n conf_matrix = pd.DataFrame(\n    confusion_matrix(df_train_y.values.ravel(), pred_train),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_train_y.values.ravel(), pred_train)) \n from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_train_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show() \n Accuracy_Rate = (tp + tn) / (tp + tn + fp + fn)\nRecall_Rate = tp / (tp + fn)\nPrecision_Rate = tp / (tp + fp)\nSpecificity_Rate = tn / (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) / (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100)) \n predict_lgbm = lgbm.predict_proba(df_val_x.values)[:,1]\npred_val = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_val_y.values.ravel(), pred_val, labels=[1,0]).ravel()\n\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_val_y.values.ravel(), pred_val),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_val_y.values.ravel(), pred_val))\n\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_val_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nAccuracy_Rate = (tp + tn) / (tp + tn + fp + fn)\nRecall_Rate = tp / (tp + fn)\nPrecision_Rate = tp / (tp + fp)\nSpecificity_Rate = tn / (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) / (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100)) \n predict_lgbm = lgbm.predict_proba(df_test_x.values)[:,1]\npred_test = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_test_y.values.ravel(), pred_test, labels=[1,0]).ravel()\n\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_test_y.values.ravel(), pred_test),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_test_y.values.ravel(), pred_test))\n\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_test_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nAccuracy_Rate = (tp + tn) / (tp + tn + fp + fn)\nRecall_Rate = tp / (tp + fn)\nPrecision_Rate = tp / (tp + fp)\nSpecificity_Rate = tn / (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) / (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100)) \n ## 6.\uc81c\ucd9c\uc790\ub8cc \uc791\uc131(Prepare submission materials) \n test_result= pd.DataFrame(pred_test)\ntest_result.columns = ['Survived']\npredict = test_result['Survived']\nId_No = df_test['PassengerId']\nsubmission = pd.DataFrame({'PassengerId': Id_No, \"Survived\": predict})\nsubmission['Survived'] = submission['Survived'].astype('Int64')\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()",
    "code_source": "import seaborn as sns\nimport sys\nimport csv\nimport datetime\nimport operator\nimport joblib\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import scale\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score\nfrom statsmodels.formula.api import ols\nfrom sklearn.metrics import cohen_kappa_score\nfrom collections import OrderedDict\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom scipy.stats import norm, skew, probplot \n df_train = pd.read_csv('/kaggle/input/titanic/train.csv')\ndf_test = pd.read_csv('/kaggle/input/titanic/test.csv')\ngender_submission = pd.read_csv('/kaggle/input/titanic/gender_submission.csv') \n df_train.head(5) \n df_test.head(5) \n gender_submission.head(5)\n# head()\ub97c \ud65c\uc6a9\ud558\uc5ec \ubcfc\ub54c PassengerId\ub97c \ud1b5\ud574\uc11c test data\uc758 \uacb0\uacfc\ub97c \uc608\uce21\ud560 \uc218 \uc788\uc74c\uc744 \uc608\uc0c1\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n# When using head(), it can be expected that the result of test data can be predicted through PassengerId. \n # 'Survived' column\uc744 \uc798 \ubd99\uc600\ub294\uc9c0 \ud655\uc778 \ud569\ub2c8\ub2e4.\n# Check if the 'Survived' column is attached properly.\ndf_test['Survived'] = gender_submission['Survived']\ndf_test.head(5) \n #\ud1b5\uacc4\uc801\uc73c\ub85c \ubd84\ud3ec\uac00 \uc5b4\ub5a0\ud55c\uc9c0 Pair Plot \ubc0f \uc5ec\ub7ec \uadf8\ub798\ud504\ub97c \ud1b5\ud558\uc5ec \ubd84\uc11d\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n# Let's analyze how the distribution is statistically through pair plots and several graphs.\n\nsns.pairplot(data = df_train) \n def analysis(data):\n    print(\"1. \uccab\ubc88\uc9f8 \uadf8\ub798\ud504\ub294 Data\uc758 Heatmap \ubd84\uc11d \uacb0\uacfc\uc785\ub2c8\ub2e4.\uc0c1\uad00\uad00\uacc4\uac00 \ub192\uc744\uc218\ub85d \uc0c9\uae54\uc774 \uc9c4\ud558\ub3c4\ub85d \ud45c\uc2dc\ud558\uc600\uc2b5\ub2c8\ub2e4.\")\n    print(\"2. \ub450\ubc88\uc9f8 \uadf8\ub798\ud504\ub294 null ratio\ub97c \uadf8\ub798\ud504\ub85c \ud45c\uc2dc\ud558\uc600\uc2b5\ub2c8\ub2e4.\")\n    sns.heatmap(data.corr(), annot=True, cmap='Reds')\n    null_percent = 100*(data.isnull().sum()/len(data))\n    null_percent = null_percent[null_percent>0].sort_values()\n    plt.figure(figsize= (10,4))\n    sns.barplot(x=null_percent.index, y= null_percent)\n    plt.xticks(rotation=90) \n analysis(df_train) \n analysis(df_test) \n fat=ols(formula='Survived~PassengerId+Pclass+Age+Sex+SibSp+Parch+Fare+Embarked', data=df_train).fit()\nprint(fat.summary())\n\n# \ud1b5\uacc4\uc801\uc73c\ub85c\ub294 \uc131\ubcc4\uc5d0 \ub530\ub978 \uad6c\ubd84\uacfc Pclass\uc5d0 \ub530\ub77c \uc0dd\uc874\ub960\uc774 \uc601\ud5a5\ub3c4\uac00 \uac00\uc7a5 \ub192\uc740 \uac83\uc73c\ub85c \ub098\uc654\uace0, \n# OLS Regression\uc73c\ub85c \uc608\uce21\uc2dc \uc0c1\uae30\uc758 8\uac1c \ubcc0\uc218\ub9cc\uc73c\ub85c \ubcf8\ub2e4\uba74, R-squre 0.4/ Adjust R-square 0.39\uc218\uc900\uc758 \uc608\uce21\uc774 \uac00\ub2a5 \ud560 \uac83\uc73c\ub85c \uc608\uc0c1 \ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n\n# Statistically, it was found that the survival rate was the most influential according to the classification according to gender and Pclass.\n# When predicting with OLS regression, if we consider only the above 8 variables, it was expected that the R-squre 0.4/ Adjust R-square 0.39 level could be predicted. \n # \uc22b\uc790 \ud0c0\uc785\uc758 \ub370\uc774\ud130 \ucd94\ucd9c\n# Numeric Feature Enginearing\n\nnum_cols = [col for col in df_train.columns if df_train[col].dtype in ['int64','float64']]\ndf_train[num_cols].describe() \n df_train.corr(method='pearson') \n df_train.info() \n # \ub370\uc774\ud130\ub0b4 \uc911\ubcf5 \uac12\uc740 \uc5c6\ub294\uc9c0 \ud655\uc778\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \n# Let's check that there are no duplicate values in the data.\n\ndf_train=df_train.drop_duplicates() \n df_train.info() \n # \uc65c\ub3c4\uc640 \ucca8\ub3c4\ub97c \ud655\uc778\ud558\ub294 \uacbd\uc6b0 Regression Modeling\ud560 \uacbd\uc6b0 \ub9ce\uc774 \ubcf4\ub098, \uae08\ubc88\uc758 \uacbd\uc6b0\ub294 \ub2e8\uc21c\ud788 \uc6b0\ub9ac\uac00 \uc54c\uace0 \uc2f6\uc740 Y\uac12(Survived)\uc758 \ubd84\ud3ec\uac00 3:2\ub77c\ub294 \uac83\n# \uc815\ub3c4 \ubc16\uc758 \uc815\ubcf4\ub97c \uc5bb\uc744\uc218 \uc5c6\uc5c8\uc2b5\ub2c8\ub2e4.\n\n# When checking skewness and kurtosis, it is often seen in Regression Modeling, but in this case, we could not simply obtain information other than that the distribution of Y-value (Survived) we wanted to know was 3:2.\nprint(f'skew: {df_train.Survived.skew()}')\nprint(f'kert: {df_train.Survived.kurt()}')\nsns.distplot(df_train.Survived, fit = norm)\nf = plt.figure()\nprobplot(df_train.Survived, plot = plt)\nplt.show() \n def count_plot(d, y, x):\n    plt.figure(figsize=(12,6))\n    sns.countplot(x = d[y], hue = x, data=d)\n    plt.ylabel('Number of people')\n    plt.title('Survival count by '+ x) \n numeric_cols = [col for col in df_train if df_train[col].dtype in ['int64','float64']]\nnumeric_cols.remove('Survived')\ny = 'Survived'\nover_column_name = list()\n\nfor i in numeric_cols:\n    if (len(df_train[i].value_counts())<20):\n        count_plot(df_train, y, i)\n    elif (len(df_train[i].value_counts())>20):\n        over_column_name.append(i)\n\nprint('Column\ub0b4 \ubcc0\uc218\uac00 20\uac1c \uc774\uc0c1\uc758 Column\uc740 \ud558\ub2e8\uacfc \uac19\uc2b5\ub2c8\ub2e4.\\n\ubcc0\uc218 20\uac1c \ubbf8\ub9cc\uc758 Column\uacfc Survived \uc22b\uc790 \ubd84\ud3ec\ub294 \uadf8\ub798\ud504\uc640 \uac19\uc2b5\ub2c8\ub2e4.')\nprint(over_column_name) \n print(num_cols)\nnum_cols.remove('PassengerId')\n\nfig, ax = plt.subplots(3, 2, figsize=(20, 10))\n\nfor variable, subplot in zip(num_cols, ax.flatten()):\n    sns.countplot(df_train[variable], ax=subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(60)\n        \nplt.tight_layout() \n cat_cols = [col for col in df_train if df_train[col].dtype not in ['int64','float64']]\nprint(cat_cols)\ncat_cols.remove('Name')\n\nfig, ax = plt.subplots(2, 2, figsize=(20, 10))\n\nfor variable, subplot in zip(cat_cols, ax.flatten()):\n    sns.countplot(df_train[variable], ax=subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(90)\n        \nplt.tight_layout() \n # train data\uc0c1 null\uac12\uc744 \ud655\uc778\ndf_train.isna().sum() \n df_train=df_train.drop(['Name','Ticket'],axis=1)\ndf_test=df_test.drop(['Name','Ticket'],axis=1) \n # Cabin \uc815\ubcf4\ub294 \ub2e4 \ubc84\ub9ac\uae30 \uc544\uae4c\uc6cc \uae00\uc790\uc218\ub97c \ubcc0\uc218\ub85c \ud55c\ubc88 \ud65c\uc6a9\ud574\ubcfc \uc0dd\uac01\uc785\ub2c8\ub2e4.\n# Rather than deleting the Cabin column, I will use \"len()\" to use the number of characters in the variable.\ndf_train['CabinCode'] = df_train['Cabin'].apply(lambda x : len(str(x)) if x!='nan' else 0)\ndf_test['CabinCode'] = df_test['Cabin'].apply(lambda x  : len(str(x)) if x!='nan' else 0) \n df_train=df_train.drop(['Cabin'],axis=1)\ndf_test=df_test.drop(['Cabin'],axis=1) \n # nan\uac12 \uc5ed\uc2dc \ud558\ub098\uc758 \ubcc0\uc218\uac00 \uc544\ub2d0\uae4c\ub77c\ub294 \uac00\uc815\ud558\uc5d0 \uae08\ubc88 \ubd84\uc11d\uc5d0\uc11c\ub294 null\uac12\uc5d0 \ub300\ud55c \ubcf4\uc815 \uc5c6\uc774 \uc9c4\ud589\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n# Assuming that the nan value is also a variable, in this analysis, we will proceed without correction for the null value.\n\ndf_train=pd.get_dummies(df_train)\ndf_test=pd.get_dummies(df_test) \n df_train.info()\ndf_test.info() \n df_train.head(5) \n # 7:3\uc73c\ub85c \uc81c\uacf5\ub41c train data\ub97c train\uacfc validation data\ub85c \uad6c\ubd84\n\nfrom sklearn.model_selection import train_test_split\n\nrandom_state_val =42\ntest_size_val =0.3\ntrain,validation = train_test_split(df_train, test_size = test_size_val, random_state = random_state_val) \n # \"read.csv\"\ub97c \uc4f0\ub2e4\ubcf4\uba74 \uac00\ub054 Unnamed: 0\uc73c\ub85c \ubb38\uc81c\ubc1c\uc0dd\uc774 \ub9ce\uc774 \ubc1c\uc0dd\ud568\n# \uadf8\ub798\uc11c \uc800\ub294 \ubd84\uc11d\uc2dc \ubb34\uc870\uac74 \ub123\uc5b4\uc11c \uc2e4\ud589\ud558\uace4 \ud569\ub2c8\ub2e4.\n\n# When I use the \"read.csv\" function, sometimes I get a lot of problems with Unnamed: 0. So, when I analyze, I put it in unconditionally and run it.\n#train = train.drop(['Unnamed: 0'], axis= 1)\n#validation = validation.drop(['Unnamed: 0'], axis= 1)\n#test = df_test.drop(['Unnamed: 0'], axis= 1) \n drop_col = ['Survived']\ny_nm = 'Survived'\n\ndf_train_x = train.drop(drop_col, axis = 1)\ndf_train_y = pd.DataFrame(train[y_nm])\n\ndf_val_x = validation.drop(drop_col, axis = 1)\ndf_val_y = pd.DataFrame(validation[y_nm])\n\ndf_test_x = df_test.drop(drop_col, axis = 1)\ndf_test_y = pd.DataFrame(df_test[y_nm]) \n LGBClassifier = lgb.LGBMClassifier(objective='binary',\n                                   max_depth = 8,\n                                   learning_rate = 0.01,\n                                   n_estimators = 9000,\n                                   max_bin = 200,\n                                   bagging_freq = 4,\n                                   bagging_seed = 8,\n                                   feature_fraction = 0.2,\n                                   feature_fraction_seed = 8,\n                                   min_sum_hessian_in_leaf = 11,\n                                   verbose = -1,\n                                   random_state = 42) \n start = datetime.datetime.now()\nlgbm = LGBClassifier.fit(df_train_x.values,\n                       df_train_y.values.ravel(),\n                       eval_set = [(df_train_x.values, df_train_y), (df_val_x.values, df_val_y)],\n                       eval_metric ='logloss',\n                       early_stopping_rounds = 20,\n                       verbose =False)\nend = datetime.datetime.now()\nend-start \n # Importance \ud655\uc778 \n# \uc8fc\uc694 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294 \ubcc0\uc218\uac00 \ubb34\uc5c7\uc778\uc9c0 \ud655\uc778\uc744 \ud558\uace0, \uc774\ub97c \uadf8\ub798\ud504\ud654 \uc9c4\ud589\ud558\uc600\uc2b5\ub2c8\ub2e4.\n# We checked the variables that have a major impact, and graphed them.\n\nfeature_imp= pd.DataFrame(sorted(zip(lgbm.feature_importances_, df_test_x.columns), reverse = True), columns = ['Value', 'Feature'])\n# feature_imp.to_excel(\"feature_imp.xlsx\")\n\nplt.figure(figsize=(7,5))\nsns.barplot(x='Value', y='Feature', data=feature_imp.sort_values(by='Value', ascending=False))\nplt.tight_layout()\nplt.show()\n# plt.savefig('lightGBM_ Importances.png') \n # for loop\ub97c \uc0ac\uc6a9\ud558\uc5ec \uac00\uc7a5 \ub192\uc740 accuracy\ub97c \uc0b0\ucd9c\ud558\ub294 \ub85c\uc9c1\uc744 \ub123\uc5c8\uc2b5\ub2c8\ub2e4. \n# I put the logic that yields the highest accuracy using a for loop.\n\nresult_lst =[]\nmax_accuracy =0.\nopt_threshold =0.\nval_y_prob = lgbm.predict_proba(df_val_x.values)[:, 1]\n\nfor n in range(0,60):\n    threshold = round(((n+1)*0.01),2)\n    pred_yn = val_y_prob.copy()\n    pred_yn = np.where(pred_yn > threshold, 1., 0.)\n    \n    result_dict = {}\n    precision, recall, f1_score, support = precision_recall_fscore_support(df_val_y.values.ravel(), pred_yn, average='binary')\n    accuracy = accuracy_score(df_val_y.values.ravel(), pred_yn)\n    kappa = cohen_kappa_score(df_val_y.values.ravel(), pred_yn)\n    \n    result_dict ={'Threshold': threshold, 'Accuracy': round(accuracy,4), 'Precision': round(precision,4), 'Recall': round(recall,4), 'F1_Score': round(f1_score,4), 'Kappa': round(kappa,4)}\n    result_lst.append(result_dict)\n    \n    if max_accuracy <= accuracy:\n        max_accuracy = accuracy\n        opt_threshold = threshold\n        \n    confMat = confusion_matrix(df_val_y.values.ravel(), pred_yn, labels=[1,0])\n    \nmatric_df = pd.DataFrame(result_lst, columns=['Threshold','Accuracy', 'Precision', 'Recall', 'F1_Score', 'Kappa'])\nmatric_df.to_csv('REC_scores.csv',sep=',', header=True, index=False, encoding='UTF-8')\n\nprint('\ucd5c\uace0 Accuracy-SCORE =%f, \uc784\uacc4\uce58=%f'%(max_accuracy, opt_threshold))\nprint('Threshold \uc124\uc815 \uc644\ub8cc') \n predict_lgbm = lgbm.predict_proba(df_train_x.values)[:,1]\npred_train = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_train_y.values.ravel(), pred_train, labels=[1,0]).ravel() \n conf_matrix = pd.DataFrame(\n    confusion_matrix(df_train_y.values.ravel(), pred_train),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_train_y.values.ravel(), pred_train)) \n from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_train_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show() \n Accuracy_Rate = (tp + tn) / (tp + tn + fp + fn)\nRecall_Rate = tp / (tp + fn)\nPrecision_Rate = tp / (tp + fp)\nSpecificity_Rate = tn / (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) / (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100)) \n predict_lgbm = lgbm.predict_proba(df_val_x.values)[:,1]\npred_val = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_val_y.values.ravel(), pred_val, labels=[1,0]).ravel()\n\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_val_y.values.ravel(), pred_val),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_val_y.values.ravel(), pred_val))\n\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_val_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nAccuracy_Rate = (tp + tn) / (tp + tn + fp + fn)\nRecall_Rate = tp / (tp + fn)\nPrecision_Rate = tp / (tp + fp)\nSpecificity_Rate = tn / (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) / (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100)) \n predict_lgbm = lgbm.predict_proba(df_test_x.values)[:,1]\npred_test = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_test_y.values.ravel(), pred_test, labels=[1,0]).ravel()\n\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_test_y.values.ravel(), pred_test),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_test_y.values.ravel(), pred_test))\n\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_test_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nAccuracy_Rate = (tp + tn) / (tp + tn + fp + fn)\nRecall_Rate = tp / (tp + fn)\nPrecision_Rate = tp / (tp + fp)\nSpecificity_Rate = tn / (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) / (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100)) \n test_result= pd.DataFrame(pred_test)\ntest_result.columns = ['Survived']\npredict = test_result['Survived']\nId_No = df_test['PassengerId']\nsubmission = pd.DataFrame({'PassengerId': Id_No, \"Survived\": predict})\nsubmission['Survived'] = submission['Survived'].astype('Int64')\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()",
    "markdown_source": "#### \ucc98\uc74c\uc73c\ub85c kaggle\uc5d0 \ucc38\uc5ec\ud558\uc5ec \ucf54\ub4dc\ub97c \uc62c\ub9bd\ub2c8\ub2e4. \n#### \ub300\ud68c Rule\uacfc Scoring\uae30\uc900\uc5d0 \ub530\ub77c \ud0c0\uc774\ud0c0\ub2c9 \uc0dd\uc874\uc790 \uc608\uce21\uc758 Accuracy\ub97c \uac00\uc7a5 \ub192\uac8c \uc0b0\ucd9c\ud558\ub294 \ubaa8\ub378\uc744 \ub9cc\ub4e4 \uc608\uc815\uc785\ub2c8\ub2e4.    \n#### This is my first time participating in kaggle. \n#### In this code, I tried to make a model with high accuracy to predict the Titanic survivor. \n ## 1. \ubaa8\ub4c8 \ubd88\ub7ec\uc624\uae30 (Import module)\n \n#### \uc81c\uac00 \uac00\uc7a5 \uc790\uc8fc \uc4f0\ub294 \ubaa8\ub4c8\ub4e4\uc744 \ubd88\ub7ec\uc62c \uc608\uc815\uc785\ub2c8\ub2e4.\n#### It will load all the modules I use the most. \n ## 2. \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30(Read Dataset) \n ## 3. \ud0d0\uc0c9\uc801 \ub370\uc774\ud130 \ubd84\uc11d (EDA)\n#### \ud5a5\ud6c4 \ub2e8\uacc4\ubcc4\ub85c Competition \ucc38\uc5ec\ub97c \ud558\uba74\uc11c def \ud568\uc218\ub85c \ubb36\uc5b4\uc11c \uc790\ub3d9\uc73c\ub85c \ud560 \uc218 \uc788\ub3c4\ub85d \ub9cc\ub4e4 \uc608\uc815\uc785\ub2c8\ub2e4.\n#### \uc6b0\uc120 \ud574\ub2f9 \ub370\uc774\ud130\uc758 Column\ub4e4\uc774 \uc5b4\ub5a4 \uac83\uc774 \uc788\uace0, \ud1b5\uacc4\uc801\uc73c\ub85c \uc5b4\ub5a0\ud55c \uacb0\uacfc\uac00 \uc788\ub294\uc9c0 \ud655\uc778\ud560 \uac81\ub2c8\ub2e4.\n\n#### In the future, while participating in the competition step by step, \n#### I plan to bind it with the def function so that it can be done automatically.\n#### First, I will check what the columns of the data are and what the statistical results are. \n ## 4. \ubaa8\ub378\ub9c1(Modeling) \n#### \ud559\uc2b5 \uc9c4\ud589\uc744 \uc704\ud558\uc5ec Train, validation, test data\ub97c \ub098\ub204\uace0, HyperParameter\ub97c \ub123\uc5b4 \ud559\uc2b5\uae4c\uc9c0 \uc2dc\ud0a4\uaca0\uc2b5\ub2c8\ub2e4.\n#### In order to proceed with the training, we will divide the Train, validation, and test data, and put HyperParameter to train it. \n ## 5. \ubaa8\ub378 \uacb0\uacfc \ubd84\uc11d(Analyze model results)\n#### \ubaa8\ub378\uc744 \ud1b5\ud574 \ub098\uc628 train, validation, test \uacb0\uacfc\uce58(precision\uc5d0\uc11c\ubd80\ud130 F1-Score, AUROC\uae4c\uc9c0)\ub97c \uc0b0\uc2dd\uc744 \uc9c1\uc811 \uacc4\uc0b0\ud558\uc5ec \uacb0\uacfc\uac00 \ub098\uc624\ub3c4\ub85d \uad6c\ud604\ud574 \ubcf4\uc558\uc2b5\ub2c8\ub2e4.\n#### I tried to implement the results by directly calculating the train, validation, and test results (from precision to F1-Score, AUROC) through the model. \n ## 6.\uc81c\ucd9c\uc790\ub8cc \uc791\uc131(Prepare submission materials)",
    "n_cells": 49,
    "n_code_cells": 42,
    "n_markdown_cells": 7,
    "n_raw_cells": 0,
    "n_outputs": 42,
    "r_code_cells": 0.8571428571428571,
    "r_markdown_cells": 0.14285714285714285,
    "r_raw_cells": 0.0,
    "r_outputs": 1.0,
    "n_exceptions": 0,
    "r_exceptions": 0.0,
    "n_lines": 406,
    "n_lines_code": 383,
    "n_lines_markdown": 23,
    "lines_per_cell": [
        4,
        4,
        25,
        1,
        3,
        7,
        1,
        1,
        3,
        4,
        4,
        9,
        1,
        1,
        8,
        5,
        1,
        1,
        4,
        1,
        10,
        5,
        13,
        11,
        12,
        2,
        2,
        4,
        2,
        5,
        2,
        1,
        3,
        7,
        7,
        11,
        12,
        9,
        12,
        32,
        3,
        4,
        12,
        17,
        13,
        49,
        49,
        1,
        8
    ],
    "lines_per_code_cell": [
        25,
        3,
        1,
        1,
        3,
        4,
        4,
        9,
        1,
        1,
        8,
        5,
        1,
        1,
        4,
        1,
        10,
        5,
        13,
        11,
        12,
        2,
        2,
        4,
        2,
        5,
        2,
        1,
        7,
        7,
        11,
        12,
        9,
        12,
        32,
        4,
        12,
        17,
        13,
        49,
        49,
        8
    ],
    "lines_per_markdown_cell": [
        4,
        4,
        1,
        7,
        3,
        3,
        1
    ],
    "ave_lines_per_cell": 8.285714285714286,
    "ave_lines_per_code_cell": 9.119047619047619,
    "ave_lines_per_markdown_cell": 3.2857142857142856,
    "max_lines_per_cell": 49,
    "max_lines_per_code_cell": 49,
    "max_lines_per_markdown_cell": 7,
    "min_lines_per_cell": 1,
    "min_lines_per_code_cell": 1,
    "min_lines_per_markdown_cell": 1,
    "n_chars": 16475,
    "n_chars_code": 15085,
    "n_chars_markdown": 1390,
    "chars_per_cell": [
        261,
        114,
        753,
        28,
        192,
        406,
        16,
        15,
        204,
        158,
        174,
        433,
        18,
        17,
        591,
        167,
        31,
        15,
        127,
        15,
        537,
        174,
        464,
        302,
        382,
        45,
        95,
        335,
        79,
        254,
        30,
        16,
        236,
        251,
        374,
        301,
        662,
        400,
        506,
        1373,
        303,
        213,
        354,
        539,
        646,
        1740,
        1749,
        42,
        338
    ],
    "chars_per_code_cell": [
        753,
        192,
        16,
        15,
        204,
        158,
        174,
        433,
        18,
        17,
        591,
        167,
        31,
        15,
        127,
        15,
        537,
        174,
        464,
        302,
        382,
        45,
        95,
        335,
        79,
        254,
        30,
        16,
        251,
        374,
        301,
        662,
        400,
        506,
        1373,
        213,
        354,
        539,
        646,
        1740,
        1749,
        338
    ],
    "chars_per_markdown_cell": [
        261,
        114,
        28,
        406,
        236,
        303,
        42
    ],
    "ave_chars_per_line": 40.57881773399015,
    "ave_chars_per_cell": 336.2244897959184,
    "ave_chars_per_code_cell": 359.1666666666667,
    "ave_chars_per_markdown_cell": 198.57142857142858,
    "max_chars_per_cell": 1749,
    "max_chars_per_code_cell": 1749,
    "max_chars_per_markdownell": 406,
    "min_chars_per_cell": 15,
    "min_chars_per_code_cell": 15,
    "min_chars_per_markdown_cell": 28,
    "r_lines_code": 0.9433497536945813,
    "r_lines_markdown": 0.05665024630541872,
    "r_chars_markdown": 0.08437025796661608,
    "r_chars_code": 0.9156297420333839,
    "all_cells": [
        {
            "source": "#### \ucc98\uc74c\uc73c\ub85c kaggle\uc5d0 \ucc38\uc5ec\ud558\uc5ec \ucf54\ub4dc\ub97c \uc62c\ub9bd\ub2c8\ub2e4. \n#### \ub300\ud68c Rule\uacfc Scoring\uae30\uc900\uc5d0 \ub530\ub77c \ud0c0\uc774\ud0c0\ub2c9 \uc0dd\uc874\uc790 \uc608\uce21\uc758 Accuracy\ub97c \uac00\uc7a5 \ub192\uac8c \uc0b0\ucd9c\ud558\ub294 \ubaa8\ub378\uc744 \ub9cc\ub4e4 \uc608\uc815\uc785\ub2c8\ub2e4.    \n#### This is my first time participating in kaggle. \n#### In this code, I tried to make a model with high accuracy to predict the Titanic survivor.",
            "mc_idx": 0,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 1. \ubaa8\ub4c8 \ubd88\ub7ec\uc624\uae30 (Import module)\n \n#### \uc81c\uac00 \uac00\uc7a5 \uc790\uc8fc \uc4f0\ub294 \ubaa8\ub4c8\ub4e4\uc744 \ubd88\ub7ec\uc62c \uc608\uc815\uc785\ub2c8\ub2e4.\n#### It will load all the modules I use the most.",
            "mc_idx": 1,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "import seaborn as sns\nimport sys\nimport csv\nimport datetime\nimport operator\nimport joblib\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import scale\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score\nfrom statsmodels.formula.api import ols\nfrom sklearn.metrics import cohen_kappa_score\nfrom collections import OrderedDict\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom scipy.stats import norm, skew, probplot",
            "mc_idx": 2,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.00909090909090909,
                "Data_Transform": 0.01818181818181818,
                "Model_Train": 0.01818181818181818,
                "Model_Evaluation": 0.045454545454545456,
                "Model_Interpretation": 0.00909090909090909,
                "Hyperparameter_Tuning": 0.004545454545454545,
                "Visualization": 0.00909090909090909,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 22
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "matplotlib": 1,
                    ".mode": 1
                },
                "Data_Transform": {
                    "labelencoder": 2,
                    "onehotencoder": 1,
                    ".mod": 1
                },
                "Model_Train": {
                    "train_test_split": 1,
                    "model": 2,
                    "model_selection": 1
                },
                "Model_Evaluation": {
                    "confusion_matrix": 2,
                    "accuracy_score": 2,
                    "precision": 1,
                    "recall": 1,
                    "classification_report": 2,
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {
                    "train_test_split": 1
                },
                "Visualization": {
                    "matplotlib": 1,
                    "pyplot": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    0,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.HTML object>"
                    ]
                },
                "mc_idx": 2,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 0,
                "o_idx": 0
            }
        },
        {
            "source": "## 2. \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30(Read Dataset)",
            "mc_idx": 3,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "df_train = pd.read_csv('/kaggle/input/titanic/train.csv')\ndf_test = pd.read_csv('/kaggle/input/titanic/test.csv')\ngender_submission = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')",
            "mc_idx": 4,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 6,
                    "pd.read_": 6
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    1,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 4,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 1,
                "o_idx": 0
            }
        },
        {
            "source": "## 3. \ud0d0\uc0c9\uc801 \ub370\uc774\ud130 \ubd84\uc11d (EDA)\n#### \ud5a5\ud6c4 \ub2e8\uacc4\ubcc4\ub85c Competition \ucc38\uc5ec\ub97c \ud558\uba74\uc11c def \ud568\uc218\ub85c \ubb36\uc5b4\uc11c \uc790\ub3d9\uc73c\ub85c \ud560 \uc218 \uc788\ub3c4\ub85d \ub9cc\ub4e4 \uc608\uc815\uc785\ub2c8\ub2e4.\n#### \uc6b0\uc120 \ud574\ub2f9 \ub370\uc774\ud130\uc758 Column\ub4e4\uc774 \uc5b4\ub5a4 \uac83\uc774 \uc788\uace0, \ud1b5\uacc4\uc801\uc73c\ub85c \uc5b4\ub5a0\ud55c \uacb0\uacfc\uac00 \uc788\ub294\uc9c0 \ud655\uc778\ud560 \uac81\ub2c8\ub2e4.\n\n#### In the future, while participating in the competition step by step, \n#### I plan to bind it with the def function so that it can be done automatically.\n#### First, I will check what the columns of the data are and what the statistical results are.",
            "mc_idx": 5,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "df_train.head(5)",
            "mc_idx": 6,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    2,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  "
                    ]
                },
                "mc_idx": 6,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 2,
                "o_idx": 0
            }
        },
        {
            "source": "df_test.head(5)",
            "mc_idx": 7,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    3,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Pclass                                          Name     Sex  \\\n0          892       3                              Kelly, Mr. James    male   \n1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n2          894       2                     Myles, Mr. Thomas Francis    male   \n3          895       3                              Wirz, Mr. Albert    male   \n4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n\n    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n0  34.5      0      0   330911   7.8292   NaN        Q  \n1  47.0      1      0   363272   7.0000   NaN        S  \n2  62.0      0      0   240276   9.6875   NaN        Q  \n3  27.0      0      0   315154   8.6625   NaN        S  \n4  22.0      1      1  3101298  12.2875   NaN        S  "
                    ]
                },
                "mc_idx": 7,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 3,
                "o_idx": 0
            }
        },
        {
            "source": "gender_submission.head(5)\n# head()\ub97c \ud65c\uc6a9\ud558\uc5ec \ubcfc\ub54c PassengerId\ub97c \ud1b5\ud574\uc11c test data\uc758 \uacb0\uacfc\ub97c \uc608\uce21\ud560 \uc218 \uc788\uc74c\uc744 \uc608\uc0c1\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n# When using head(), it can be expected that the result of test data can be predicted through PassengerId.",
            "mc_idx": 8,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 3,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    4,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived\n0          892         0\n1          893         1\n2          894         0\n3          895         0\n4          896         1"
                    ]
                },
                "mc_idx": 8,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 4,
                "o_idx": 0
            }
        },
        {
            "source": "# 'Survived' column\uc744 \uc798 \ubd99\uc600\ub294\uc9c0 \ud655\uc778 \ud569\ub2c8\ub2e4.\n# Check if the 'Survived' column is attached properly.\ndf_test['Survived'] = gender_submission['Survived']\ndf_test.head(5)",
            "mc_idx": 9,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    5,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Pclass                                          Name     Sex  \\\n0          892       3                              Kelly, Mr. James    male   \n1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n2          894       2                     Myles, Mr. Thomas Francis    male   \n3          895       3                              Wirz, Mr. Albert    male   \n4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n\n    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  Survived  \n0  34.5      0      0   330911   7.8292   NaN        Q         0  \n1  47.0      1      0   363272   7.0000   NaN        S         1  \n2  62.0      0      0   240276   9.6875   NaN        Q         0  \n3  27.0      0      0   315154   8.6625   NaN        S         0  \n4  22.0      1      1  3101298  12.2875   NaN        S         1  "
                    ]
                },
                "mc_idx": 9,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 5,
                "o_idx": 0
            }
        },
        {
            "source": "#\ud1b5\uacc4\uc801\uc73c\ub85c \ubd84\ud3ec\uac00 \uc5b4\ub5a0\ud55c\uc9c0 Pair Plot \ubc0f \uc5ec\ub7ec \uadf8\ub798\ud504\ub97c \ud1b5\ud558\uc5ec \ubd84\uc11d\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n# Let's analyze how the distribution is statistically through pair plots and several graphs.\n\nsns.pairplot(data = df_train)",
            "mc_idx": 10,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.pairplot": 1,
                    "sns.": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1,
                    "graph": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0089_c006_o001_image_0.png",
                    6,
                    1,
                    0
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<seaborn.axisgrid.PairGrid at 0x7f6597d84190>",
                        "<Figure size 1260x1260 with 56 Axes>"
                    ]
                },
                "mc_idx": 10,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 6,
                "o_idx": 1
            }
        },
        {
            "source": "def analysis(data):\n    print(\"1. \uccab\ubc88\uc9f8 \uadf8\ub798\ud504\ub294 Data\uc758 Heatmap \ubd84\uc11d \uacb0\uacfc\uc785\ub2c8\ub2e4.\uc0c1\uad00\uad00\uacc4\uac00 \ub192\uc744\uc218\ub85d \uc0c9\uae54\uc774 \uc9c4\ud558\ub3c4\ub85d \ud45c\uc2dc\ud558\uc600\uc2b5\ub2c8\ub2e4.\")\n    print(\"2. \ub450\ubc88\uc9f8 \uadf8\ub798\ud504\ub294 null ratio\ub97c \uadf8\ub798\ud504\ub85c \ud45c\uc2dc\ud558\uc600\uc2b5\ub2c8\ub2e4.\")\n    sns.heatmap(data.corr(), annot=True, cmap='Reds')\n    null_percent = 100*(data.isnull().sum()/len(data))\n    null_percent = null_percent[null_percent>0].sort_values()\n    plt.figure(figsize= (10,4))\n    sns.barplot(x=null_percent.index, y= null_percent)\n    plt.xticks(rotation=90)",
            "mc_idx": 11,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.1111111111111111,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.4444444444444444,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".corr": 2,
                    "sns.heatmap": 1,
                    ".heatmap(": 1,
                    "sns.": 2,
                    "size": 1,
                    ".isnull": 1,
                    ".sum": 1
                },
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.heatmap": 1,
                    ".heatmap(": 1,
                    "sns.": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    7,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 11,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 7,
                "o_idx": 0
            }
        },
        {
            "source": "analysis(df_train)",
            "mc_idx": 12,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0089_c008_o002_image_2.png",
                    8,
                    2,
                    2
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "1. \uccab\ubc88\uc9f8 \uadf8\ub798\ud504\ub294 Data\uc758 Heatmap \ubd84\uc11d \uacb0\uacfc\uc785\ub2c8\ub2e4.\uc0c1\uad00\uad00\uacc4\uac00 \ub192\uc744\uc218\ub85d \uc0c9\uae54\uc774 \uc9c4\ud558\ub3c4\ub85d \ud45c\uc2dc\ud558\uc600\uc2b5\ub2c8\ub2e4.\n2. \ub450\ubc88\uc9f8 \uadf8\ub798\ud504\ub294 null ratio\ub97c \uadf8\ub798\ud504\ub85c \ud45c\uc2dc\ud558\uc600\uc2b5\ub2c8\ub2e4.\n",
                        "<Figure size 432x288 with 2 Axes>",
                        "<Figure size 720x288 with 1 Axes>"
                    ]
                },
                "mc_idx": 12,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 8,
                "o_idx": 2
            }
        },
        {
            "source": "analysis(df_test)",
            "mc_idx": 13,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0089_c009_o002_image_4.png",
                    9,
                    2,
                    4
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "1. \uccab\ubc88\uc9f8 \uadf8\ub798\ud504\ub294 Data\uc758 Heatmap \ubd84\uc11d \uacb0\uacfc\uc785\ub2c8\ub2e4.\uc0c1\uad00\uad00\uacc4\uac00 \ub192\uc744\uc218\ub85d \uc0c9\uae54\uc774 \uc9c4\ud558\ub3c4\ub85d \ud45c\uc2dc\ud558\uc600\uc2b5\ub2c8\ub2e4.\n2. \ub450\ubc88\uc9f8 \uadf8\ub798\ud504\ub294 null ratio\ub97c \uadf8\ub798\ud504\ub85c \ud45c\uc2dc\ud558\uc600\uc2b5\ub2c8\ub2e4.\n",
                        "<Figure size 432x288 with 2 Axes>",
                        "<Figure size 720x288 with 1 Axes>"
                    ]
                },
                "mc_idx": 13,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 9,
                "o_idx": 2
            }
        },
        {
            "source": "fat=ols(formula='Survived~PassengerId+Pclass+Age+Sex+SibSp+Parch+Fare+Embarked', data=df_train).fit()\nprint(fat.summary())\n\n# \ud1b5\uacc4\uc801\uc73c\ub85c\ub294 \uc131\ubcc4\uc5d0 \ub530\ub978 \uad6c\ubd84\uacfc Pclass\uc5d0 \ub530\ub77c \uc0dd\uc874\ub960\uc774 \uc601\ud5a5\ub3c4\uac00 \uac00\uc7a5 \ub192\uc740 \uac83\uc73c\ub85c \ub098\uc654\uace0, \n# OLS Regression\uc73c\ub85c \uc608\uce21\uc2dc \uc0c1\uae30\uc758 8\uac1c \ubcc0\uc218\ub9cc\uc73c\ub85c \ubcf8\ub2e4\uba74, R-squre 0.4/ Adjust R-square 0.39\uc218\uc900\uc758 \uc608\uce21\uc774 \uac00\ub2a5 \ud560 \uac83\uc73c\ub85c \uc608\uc0c1 \ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n\n# Statistically, it was found that the survival rate was the most influential according to the classification according to gender and Pclass.\n# When predicting with OLS regression, if we consider only the above 8 variables, it was expected that the R-squre 0.4/ Adjust R-square 0.39 level could be predicted.",
            "mc_idx": 14,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".sum": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "summary": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    10,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "                            OLS Regression Results                            \n==============================================================================\nDep. Variable:               Survived   R-squared:                       0.402\nModel:                            OLS   Adj. R-squared:                  0.394\nMethod:                 Least Squares   F-statistic:                     52.39\nDate:                Wed, 20 Oct 2021   Prob (F-statistic):           1.41e-72\nTime:                        07:13:36   Log-Likelihood:                -320.62\nNo. Observations:                 712   AIC:                             661.2\nDf Residuals:                     702   BIC:                             706.9\nDf Model:                           9                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P>|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nIntercept         1.3786      0.086     16.100      0.000       1.210       1.547\nSex[T.male]      -0.4861      0.032    -15.406      0.000      -0.548      -0.424\nEmbarked[T.Q]    -0.0977      0.082     -1.185      0.236      -0.259       0.064\nEmbarked[T.S]    -0.0665      0.040     -1.678      0.094      -0.144       0.011\nPassengerId    5.192e-05   5.57e-05      0.932      0.351   -5.74e-05       0.000\nPclass           -0.1869      0.023     -8.157      0.000      -0.232      -0.142\nAge              -0.0064      0.001     -5.657      0.000      -0.009      -0.004\nSibSp            -0.0495      0.018     -2.829      0.005      -0.084      -0.015\nParch            -0.0111      0.019     -0.584      0.559      -0.049       0.026\nFare              0.0002      0.000      0.562      0.574      -0.000       0.001\n==============================================================================\nOmnibus:                       26.257   Durbin-Watson:                   1.848\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               28.488\nSkew:                           0.490   Prob(JB):                     6.52e-07\nKurtosis:                       3.019   Cond. No.                     3.28e+03\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 3.28e+03. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n"
                    ]
                },
                "mc_idx": 14,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 10,
                "o_idx": 0
            }
        },
        {
            "source": "# \uc22b\uc790 \ud0c0\uc785\uc758 \ub370\uc774\ud130 \ucd94\ucd9c\n# Numeric Feature Enginearing\n\nnum_cols = [col for col in df_train.columns if df_train[col].dtype in ['int64','float64']]\ndf_train[num_cols].describe()",
            "mc_idx": 15,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".describe(": 1,
                    "describe": 1,
                    "columns": 1,
                    ".describe": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    11,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "       PassengerId    Survived      Pclass         Age       SibSp  \\\ncount   891.000000  891.000000  891.000000  714.000000  891.000000   \nmean    446.000000    0.383838    2.308642   29.699118    0.523008   \nstd     257.353842    0.486592    0.836071   14.526497    1.102743   \nmin       1.000000    0.000000    1.000000    0.420000    0.000000   \n25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n75%     668.500000    1.000000    3.000000   38.000000    1.000000   \nmax     891.000000    1.000000    3.000000   80.000000    8.000000   \n\n            Parch        Fare  \ncount  891.000000  891.000000  \nmean     0.381594   32.204208  \nstd      0.806057   49.693429  \nmin      0.000000    0.000000  \n25%      0.000000    7.910400  \n50%      0.000000   14.454200  \n75%      0.000000   31.000000  \nmax      6.000000  512.329200  "
                    ]
                },
                "mc_idx": 15,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 11,
                "o_idx": 0
            }
        },
        {
            "source": "df_train.corr(method='pearson')",
            "mc_idx": 16,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".corr": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    12,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "             PassengerId  Survived    Pclass       Age     SibSp     Parch  \\\nPassengerId     1.000000 -0.005007 -0.035144  0.036847 -0.057527 -0.001652   \nSurvived       -0.005007  1.000000 -0.338481 -0.077221 -0.035322  0.081629   \nPclass         -0.035144 -0.338481  1.000000 -0.369226  0.083081  0.018443   \nAge             0.036847 -0.077221 -0.369226  1.000000 -0.308247 -0.189119   \nSibSp          -0.057527 -0.035322  0.083081 -0.308247  1.000000  0.414838   \nParch          -0.001652  0.081629  0.018443 -0.189119  0.414838  1.000000   \nFare            0.012658  0.257307 -0.549500  0.096067  0.159651  0.216225   \n\n                 Fare  \nPassengerId  0.012658  \nSurvived     0.257307  \nPclass      -0.549500  \nAge          0.096067  \nSibSp        0.159651  \nParch        0.216225  \nFare         1.000000  "
                    ]
                },
                "mc_idx": 16,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 12,
                "o_idx": 0
            }
        },
        {
            "source": "df_train.info()",
            "mc_idx": 17,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".info(": 1,
                    "info": 1,
                    ".info": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    13,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n"
                    ]
                },
                "mc_idx": 17,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 13,
                "o_idx": 0
            }
        },
        {
            "source": "# \ub370\uc774\ud130\ub0b4 \uc911\ubcf5 \uac12\uc740 \uc5c6\ub294\uc9c0 \ud655\uc778\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \n# Let's check that there are no duplicate values in the data.\n\ndf_train=df_train.drop_duplicates()",
            "mc_idx": 18,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "duplicates": 1
                },
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    14,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 18,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 14,
                "o_idx": 0
            }
        },
        {
            "source": "df_train.info()",
            "mc_idx": 19,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".info(": 1,
                    "info": 1,
                    ".info": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    15,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 90.5+ KB\n"
                    ]
                },
                "mc_idx": 19,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 15,
                "o_idx": 0
            }
        },
        {
            "source": "# \uc65c\ub3c4\uc640 \ucca8\ub3c4\ub97c \ud655\uc778\ud558\ub294 \uacbd\uc6b0 Regression Modeling\ud560 \uacbd\uc6b0 \ub9ce\uc774 \ubcf4\ub098, \uae08\ubc88\uc758 \uacbd\uc6b0\ub294 \ub2e8\uc21c\ud788 \uc6b0\ub9ac\uac00 \uc54c\uace0 \uc2f6\uc740 Y\uac12(Survived)\uc758 \ubd84\ud3ec\uac00 3:2\ub77c\ub294 \uac83\n# \uc815\ub3c4 \ubc16\uc758 \uc815\ubcf4\ub97c \uc5bb\uc744\uc218 \uc5c6\uc5c8\uc2b5\ub2c8\ub2e4.\n\n# When checking skewness and kurtosis, it is often seen in Regression Modeling, but in this case, we could not simply obtain information other than that the distribution of Y-value (Survived) we wanted to know was 3:2.\nprint(f'skew: {df_train.Survived.skew()}')\nprint(f'kert: {df_train.Survived.kurt()}')\nsns.distplot(df_train.Survived, fit = norm)\nf = plt.figure()\nprobplot(df_train.Survived, plot = plt)\nplt.show()",
            "mc_idx": 20,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.4,
                "Model_Evaluation": 0.4,
                "Model_Interpretation": 0.4,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "distplot": 1,
                    "sns.": 1,
                    "info": 1,
                    ".skew": 1,
                    ".kurt": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 2
                },
                "Model_Evaluation": {
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0089_c016_o002_image_6.png",
                    16,
                    2,
                    6
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "skew: 0.4785234382949897\nkert: -1.775004671066304\n",
                        "<Figure size 432x288 with 1 Axes>",
                        "<Figure size 432x288 with 1 Axes>"
                    ]
                },
                "mc_idx": 20,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 16,
                "o_idx": 2
            }
        },
        {
            "source": "def count_plot(d, y, x):\n    plt.figure(figsize=(12,6))\n    sns.countplot(x = d[y], hue = x, data=d)\n    plt.ylabel('Number of people')\n    plt.title('Survival count by '+ x)",
            "mc_idx": 21,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.5,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    17,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 21,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 17,
                "o_idx": 0
            }
        },
        {
            "source": "numeric_cols = [col for col in df_train if df_train[col].dtype in ['int64','float64']]\nnumeric_cols.remove('Survived')\ny = 'Survived'\nover_column_name = list()\n\nfor i in numeric_cols:\n    if (len(df_train[i].value_counts())<20):\n        count_plot(df_train, y, i)\n    elif (len(df_train[i].value_counts())>20):\n        over_column_name.append(i)\n\nprint('Column\ub0b4 \ubcc0\uc218\uac00 20\uac1c \uc774\uc0c1\uc758 Column\uc740 \ud558\ub2e8\uacfc \uac19\uc2b5\ub2c8\ub2e4.\\n\ubcc0\uc218 20\uac1c \ubbf8\ub9cc\uc758 Column\uacfc Survived \uc22b\uc790 \ubd84\ud3ec\ub294 \uadf8\ub798\ud504\uc640 \uac19\uc2b5\ub2c8\ub2e4.')\nprint(over_column_name)",
            "mc_idx": 22,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "value_counts()": 2,
                    ".value_counts": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0089_c018_o003_image_9.png",
                    18,
                    3,
                    9
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Column\ub0b4 \ubcc0\uc218\uac00 20\uac1c \uc774\uc0c1\uc758 Column\uc740 \ud558\ub2e8\uacfc \uac19\uc2b5\ub2c8\ub2e4.\n\ubcc0\uc218 20\uac1c \ubbf8\ub9cc\uc758 Column\uacfc Survived \uc22b\uc790 \ubd84\ud3ec\ub294 \uadf8\ub798\ud504\uc640 \uac19\uc2b5\ub2c8\ub2e4.\n['PassengerId', 'Age', 'Fare']\n",
                        "<Figure size 864x432 with 1 Axes>",
                        "<Figure size 864x432 with 1 Axes>",
                        "<Figure size 864x432 with 1 Axes>"
                    ]
                },
                "mc_idx": 22,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 18,
                "o_idx": 3
            }
        },
        {
            "source": "print(num_cols)\nnum_cols.remove('PassengerId')\n\nfig, ax = plt.subplots(3, 2, figsize=(20, 10))\n\nfor variable, subplot in zip(num_cols, ax.flatten()):\n    sns.countplot(df_train[variable], ax=subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(60)\n        \nplt.tight_layout()",
            "mc_idx": 23,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.6666666666666666,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.6666666666666666,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 2
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "fig, ax = plt.subplots": 1,
                    "sns.": 1,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "fig, ax = plt.subplots": 1,
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0089_c019_o001_image_10.png",
                    19,
                    1,
                    10
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
                        "<Figure size 1440x720 with 6 Axes>"
                    ]
                },
                "mc_idx": 23,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 19,
                "o_idx": 1
            }
        },
        {
            "source": "cat_cols = [col for col in df_train if df_train[col].dtype not in ['int64','float64']]\nprint(cat_cols)\ncat_cols.remove('Name')\n\nfig, ax = plt.subplots(2, 2, figsize=(20, 10))\n\nfor variable, subplot in zip(cat_cols, ax.flatten()):\n    sns.countplot(df_train[variable], ax=subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(90)\n        \nplt.tight_layout()",
            "mc_idx": 24,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.6666666666666666,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.6666666666666666,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 2
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "fig, ax = plt.subplots": 1,
                    "sns.": 1,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "fig, ax = plt.subplots": 1,
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0089_c020_o001_image_11.png",
                    20,
                    1,
                    11
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
                        "<Figure size 1440x720 with 4 Axes>"
                    ]
                },
                "mc_idx": 24,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 20,
                "o_idx": 1
            }
        },
        {
            "source": "# train data\uc0c1 null\uac12\uc744 \ud655\uc778\ndf_train.isna().sum()",
            "mc_idx": 25,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".isna": 1,
                    ".sum": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    21,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "PassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64"
                    ]
                },
                "mc_idx": 25,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 21,
                "o_idx": 0
            }
        },
        {
            "source": "df_train=df_train.drop(['Name','Ticket'],axis=1)\ndf_test=df_test.drop(['Name','Ticket'],axis=1)",
            "mc_idx": 26,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    22,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 26,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 22,
                "o_idx": 0
            }
        },
        {
            "source": "# Cabin \uc815\ubcf4\ub294 \ub2e4 \ubc84\ub9ac\uae30 \uc544\uae4c\uc6cc \uae00\uc790\uc218\ub97c \ubcc0\uc218\ub85c \ud55c\ubc88 \ud65c\uc6a9\ud574\ubcfc \uc0dd\uac01\uc785\ub2c8\ub2e4.\n# Rather than deleting the Cabin column, I will use \"len()\" to use the number of characters in the variable.\ndf_train['CabinCode'] = df_train['Cabin'].apply(lambda x : len(str(x)) if x!='nan' else 0)\ndf_test['CabinCode'] = df_test['Cabin'].apply(lambda x  : len(str(x)) if x!='nan' else 0)",
            "mc_idx": 27,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.25,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".apply(": 2,
                    ".apply": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    23,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 27,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 23,
                "o_idx": 0
            }
        },
        {
            "source": "df_train=df_train.drop(['Cabin'],axis=1)\ndf_test=df_test.drop(['Cabin'],axis=1)",
            "mc_idx": 28,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    24,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 28,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 24,
                "o_idx": 0
            }
        },
        {
            "source": "# nan\uac12 \uc5ed\uc2dc \ud558\ub098\uc758 \ubcc0\uc218\uac00 \uc544\ub2d0\uae4c\ub77c\ub294 \uac00\uc815\ud558\uc5d0 \uae08\ubc88 \ubd84\uc11d\uc5d0\uc11c\ub294 null\uac12\uc5d0 \ub300\ud55c \ubcf4\uc815 \uc5c6\uc774 \uc9c4\ud589\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n# Assuming that the nan value is also a variable, in this analysis, we will proceed without correction for the null value.\n\ndf_train=pd.get_dummies(df_train)\ndf_test=pd.get_dummies(df_test)",
            "mc_idx": 29,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".get_dummies": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    25,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 29,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 25,
                "o_idx": 0
            }
        },
        {
            "source": "df_train.info()\ndf_test.info()",
            "mc_idx": 30,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".info(": 2,
                    "info": 2,
                    ".info": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    26,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 891 entries, 0 to 890\nData columns (total 13 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Age          714 non-null    float64\n 4   SibSp        891 non-null    int64  \n 5   Parch        891 non-null    int64  \n 6   Fare         891 non-null    float64\n 7   CabinCode    891 non-null    int64  \n 8   Sex_female   891 non-null    uint8  \n 9   Sex_male     891 non-null    uint8  \n 10  Embarked_C   891 non-null    uint8  \n 11  Embarked_Q   891 non-null    uint8  \n 12  Embarked_S   891 non-null    uint8  \ndtypes: float64(2), int64(6), uint8(5)\nmemory usage: 99.3 KB\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 418 entries, 0 to 417\nData columns (total 13 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  418 non-null    int64  \n 1   Pclass       418 non-null    int64  \n 2   Age          332 non-null    float64\n 3   SibSp        418 non-null    int64  \n 4   Parch        418 non-null    int64  \n 5   Fare         417 non-null    float64\n 6   Survived     418 non-null    int64  \n 7   CabinCode    418 non-null    int64  \n 8   Sex_female   418 non-null    uint8  \n 9   Sex_male     418 non-null    uint8  \n 10  Embarked_C   418 non-null    uint8  \n 11  Embarked_Q   418 non-null    uint8  \n 12  Embarked_S   418 non-null    uint8  \ndtypes: float64(2), int64(6), uint8(5)\nmemory usage: 28.3 KB\n"
                    ]
                },
                "mc_idx": 30,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 26,
                "o_idx": 0
            }
        },
        {
            "source": "df_train.head(5)",
            "mc_idx": 31,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    27,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  CabinCode  \\\n0            1         0       3  22.0      1      0   7.2500          3   \n1            2         1       1  38.0      1      0  71.2833          3   \n2            3         1       3  26.0      0      0   7.9250          3   \n3            4         1       1  35.0      1      0  53.1000          4   \n4            5         0       3  35.0      0      0   8.0500          3   \n\n   Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n0           0         1           0           0           1  \n1           1         0           1           0           0  \n2           1         0           0           0           1  \n3           1         0           0           0           1  \n4           0         1           0           0           1  "
                    ]
                },
                "mc_idx": 31,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 27,
                "o_idx": 0
            }
        },
        {
            "source": "## 4. \ubaa8\ub378\ub9c1(Modeling) \n#### \ud559\uc2b5 \uc9c4\ud589\uc744 \uc704\ud558\uc5ec Train, validation, test data\ub97c \ub098\ub204\uace0, HyperParameter\ub97c \ub123\uc5b4 \ud559\uc2b5\uae4c\uc9c0 \uc2dc\ud0a4\uaca0\uc2b5\ub2c8\ub2e4.\n#### In order to proceed with the training, we will divide the Train, validation, and test data, and put HyperParameter to train it.",
            "mc_idx": 32,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "# 7:3\uc73c\ub85c \uc81c\uacf5\ub41c train data\ub97c train\uacfc validation data\ub85c \uad6c\ubd84\n\nfrom sklearn.model_selection import train_test_split\n\nrandom_state_val =42\ntest_size_val =0.3\ntrain,validation = train_test_split(df_train, test_size = test_size_val, random_state = random_state_val)",
            "mc_idx": 33,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.4,
                "Data_Transform": 0.1,
                "Model_Train": 0.4,
                "Model_Evaluation": 0.1,
                "Model_Interpretation": 0.1,
                "Hyperparameter_Tuning": 0.2,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 10
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 3,
                    ".mode": 1
                },
                "Data_Transform": {
                    ".mod": 1
                },
                "Model_Train": {
                    "train_test_split": 2,
                    "model": 1,
                    "model_selection": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {
                    "train_test_split": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    28,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 33,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 28,
                "o_idx": 0
            }
        },
        {
            "source": "# \"read.csv\"\ub97c \uc4f0\ub2e4\ubcf4\uba74 \uac00\ub054 Unnamed: 0\uc73c\ub85c \ubb38\uc81c\ubc1c\uc0dd\uc774 \ub9ce\uc774 \ubc1c\uc0dd\ud568\n# \uadf8\ub798\uc11c \uc800\ub294 \ubd84\uc11d\uc2dc \ubb34\uc870\uac74 \ub123\uc5b4\uc11c \uc2e4\ud589\ud558\uace4 \ud569\ub2c8\ub2e4.\n\n# When I use the \"read.csv\" function, sometimes I get a lot of problems with Unnamed: 0. So, when I analyze, I put it in unconditionally and run it.\n#train = train.drop(['Unnamed: 0'], axis= 1)\n#validation = validation.drop(['Unnamed: 0'], axis= 1)\n#test = df_test.drop(['Unnamed: 0'], axis= 1)",
            "mc_idx": 34,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 3
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    29,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 34,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 29,
                "o_idx": 0
            }
        },
        {
            "source": "drop_col = ['Survived']\ny_nm = 'Survived'\n\ndf_train_x = train.drop(drop_col, axis = 1)\ndf_train_y = pd.DataFrame(train[y_nm])\n\ndf_val_x = validation.drop(drop_col, axis = 1)\ndf_val_y = pd.DataFrame(validation[y_nm])\n\ndf_test_x = df_test.drop(drop_col, axis = 1)\ndf_test_y = pd.DataFrame(df_test[y_nm])",
            "mc_idx": 35,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 3
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    30,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 35,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 30,
                "o_idx": 0
            }
        },
        {
            "source": "LGBClassifier = lgb.LGBMClassifier(objective='binary',\n                                   max_depth = 8,\n                                   learning_rate = 0.01,\n                                   n_estimators = 9000,\n                                   max_bin = 200,\n                                   bagging_freq = 4,\n                                   bagging_seed = 8,\n                                   feature_fraction = 0.2,\n                                   feature_fraction_seed = 8,\n                                   min_sum_hessian_in_leaf = 11,\n                                   verbose = -1,\n                                   random_state = 42)",
            "mc_idx": 36,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "hessian": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    31,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 36,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 31,
                "o_idx": 0
            }
        },
        {
            "source": "start = datetime.datetime.now()\nlgbm = LGBClassifier.fit(df_train_x.values,\n                       df_train_y.values.ravel(),\n                       eval_set = [(df_train_x.values, df_train_y), (df_val_x.values, df_val_y)],\n                       eval_metric ='logloss',\n                       early_stopping_rounds = 20,\n                       verbose =False)\nend = datetime.datetime.now()\nend-start",
            "mc_idx": 37,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "ravel": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "early_stopping": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    32,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
                        "datetime.timedelta(microseconds=304034)"
                    ]
                },
                "mc_idx": 37,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 32,
                "o_idx": 1
            }
        },
        {
            "source": "# Importance \ud655\uc778 \n# \uc8fc\uc694 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294 \ubcc0\uc218\uac00 \ubb34\uc5c7\uc778\uc9c0 \ud655\uc778\uc744 \ud558\uace0, \uc774\ub97c \uadf8\ub798\ud504\ud654 \uc9c4\ud589\ud558\uc600\uc2b5\ub2c8\ub2e4.\n# We checked the variables that have a major impact, and graphed them.\n\nfeature_imp= pd.DataFrame(sorted(zip(lgbm.feature_importances_, df_test_x.columns), reverse = True), columns = ['Value', 'Feature'])\n# feature_imp.to_excel(\"feature_imp.xlsx\")\n\nplt.figure(figsize=(7,5))\nsns.barplot(x='Value', y='Feature', data=feature_imp.sort_values(by='Value', ascending=False))\nplt.tight_layout()\nplt.show()\n# plt.savefig('lightGBM_ Importances.png')",
            "mc_idx": 38,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.75,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.5,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1,
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "columns": 2,
                    "size": 1
                },
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "feature_importances_": 2,
                    "impact": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1,
                    "graph": 1
                },
                "Debug": {},
                "Data_Export": {
                    ".to_excel(": 1,
                    "savefig": 1,
                    "save": 1,
                    "to_excel": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0089_c033_o000_image_12.png",
                    33,
                    0,
                    12
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 504x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 38,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 33,
                "o_idx": 0
            }
        },
        {
            "source": "# for loop\ub97c \uc0ac\uc6a9\ud558\uc5ec \uac00\uc7a5 \ub192\uc740 accuracy\ub97c \uc0b0\ucd9c\ud558\ub294 \ub85c\uc9c1\uc744 \ub123\uc5c8\uc2b5\ub2c8\ub2e4. \n# I put the logic that yields the highest accuracy using a for loop.\n\nresult_lst =[]\nmax_accuracy =0.\nopt_threshold =0.\nval_y_prob = lgbm.predict_proba(df_val_x.values)[:, 1]\n\nfor n in range(0,60):\n    threshold = round(((n+1)*0.01),2)\n    pred_yn = val_y_prob.copy()\n    pred_yn = np.where(pred_yn > threshold, 1., 0.)\n    \n    result_dict = {}\n    precision, recall, f1_score, support = precision_recall_fscore_support(df_val_y.values.ravel(), pred_yn, average='binary')\n    accuracy = accuracy_score(df_val_y.values.ravel(), pred_yn)\n    kappa = cohen_kappa_score(df_val_y.values.ravel(), pred_yn)\n    \n    result_dict ={'Threshold': threshold, 'Accuracy': round(accuracy,4), 'Precision': round(precision,4), 'Recall': round(recall,4), 'F1_Score': round(f1_score,4), 'Kappa': round(kappa,4)}\n    result_lst.append(result_dict)\n    \n    if max_accuracy <= accuracy:\n        max_accuracy = accuracy\n        opt_threshold = threshold\n        \n    confMat = confusion_matrix(df_val_y.values.ravel(), pred_yn, labels=[1,0])\n    \nmatric_df = pd.DataFrame(result_lst, columns=['Threshold','Accuracy', 'Precision', 'Recall', 'F1_Score', 'Kappa'])\nmatric_df.to_csv('REC_scores.csv',sep=',', header=True, index=False, encoding='UTF-8')\n\nprint('\ucd5c\uace0 Accuracy-SCORE =%f, \uc784\uacc4\uce58=%f'%(max_accuracy, opt_threshold))\nprint('Threshold \uc124\uc815 \uc644\ub8cc')",
            "mc_idx": 39,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.07692307692307693,
                "Data_Transform": 0.15384615384615385,
                "Model_Train": 0.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.038461538461538464,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.07692307692307693,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "head": 1,
                    "columns": 1
                },
                "Data_Transform": {
                    "ravel": 4
                },
                "Model_Train": {},
                "Model_Evaluation": {
                    "confusion_matrix": 2,
                    "accuracy_score": 2,
                    "f1_score": 12,
                    "precision": 5,
                    "recall": 5
                },
                "Model_Interpretation": {
                    "predict_proba": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    34,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "\ucd5c\uace0 Accuracy-SCORE =0.809701, \uc784\uacc4\uce58=0.540000\nThreshold \uc124\uc815 \uc644\ub8cc\n"
                    ]
                },
                "mc_idx": 39,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 34,
                "o_idx": 0
            }
        },
        {
            "source": "## 5. \ubaa8\ub378 \uacb0\uacfc \ubd84\uc11d(Analyze model results)\n#### \ubaa8\ub378\uc744 \ud1b5\ud574 \ub098\uc628 train, validation, test \uacb0\uacfc\uce58(precision\uc5d0\uc11c\ubd80\ud130 F1-Score, AUROC\uae4c\uc9c0)\ub97c \uc0b0\uc2dd\uc744 \uc9c1\uc811 \uacc4\uc0b0\ud558\uc5ec \uacb0\uacfc\uac00 \ub098\uc624\ub3c4\ub85d \uad6c\ud604\ud574 \ubcf4\uc558\uc2b5\ub2c8\ub2e4.\n#### I tried to implement the results by directly calculating the train, validation, and test results (from precision to F1-Score, AUROC) through the model.",
            "mc_idx": 40,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "predict_lgbm = lgbm.predict_proba(df_train_x.values)[:,1]\npred_train = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_train_y.values.ravel(), pred_train, labels=[1,0]).ravel()",
            "mc_idx": 41,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "ravel": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {
                    "confusion_matrix": 2
                },
                "Model_Interpretation": {
                    "predict_proba": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    35,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 41,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 35,
                "o_idx": 0
            }
        },
        {
            "source": "conf_matrix = pd.DataFrame(\n    confusion_matrix(df_train_y.values.ravel(), pred_train),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_train_y.values.ravel(), pred_train))",
            "mc_idx": 42,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.5,
                "Model_Train": 0.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {
                    "ravel": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {
                    "confusion_matrix": 2,
                    "classification_report": 2
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    36,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "1. Counfusion Matrix\n                   True Value 0  True Value 1\nPredicted Value 0           370            81\nPredicted Value 1            22           150\n\n2. Classification Report\n              precision    recall  f1-score   support\n\n           0       0.82      0.94      0.88       392\n           1       0.87      0.65      0.74       231\n\n    accuracy                           0.83       623\n   macro avg       0.85      0.80      0.81       623\nweighted avg       0.84      0.83      0.83       623\n\n"
                    ]
                },
                "mc_idx": 42,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 36,
                "o_idx": 0
            }
        },
        {
            "source": "from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_train_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()",
            "mc_idx": 43,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 0.047619047619047616,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.09523809523809523,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2857142857142857,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 20,
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plt.plot": 2,
                    ".plot(": 4,
                    "matplotlib": 1
                },
                "Data_Transform": {
                    "ravel": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {
                    "roc_curve": 2
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "plt.plot": 2,
                    ".plot(": 2,
                    "matplotlib": 1,
                    "pyplot": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0089_c037_o000_image_13.png",
                    37,
                    0,
                    13
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 432x288 with 1 Axes>"
                    ]
                },
                "mc_idx": 43,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 37,
                "o_idx": 0
            }
        },
        {
            "source": "Accuracy_Rate = (tp + tn) / (tp + tn + fp + fn)\nRecall_Rate = tp / (tp + fn)\nPrecision_Rate = tp / (tp + fp)\nSpecificity_Rate = tn / (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) / (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))",
            "mc_idx": 44,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.058823529411764705,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.058823529411764705,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "f1_score": 6,
                    "precision": 5,
                    "recall": 5,
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    38,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "3. Model Metric Sumamry\n - Accuracy Rate    : 83.467 %\n - Recall Rate      : 64.935 %\n - Precision Rate   : 87.209 %\n - Specificity Rate : 94.388 %\n - F1 Score         : 74.442 \n - ROC AUC          : 88.703 \n"
                    ]
                },
                "mc_idx": 44,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 38,
                "o_idx": 0
            }
        },
        {
            "source": "predict_lgbm = lgbm.predict_proba(df_val_x.values)[:,1]\npred_val = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_val_y.values.ravel(), pred_val, labels=[1,0]).ravel()\n\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_val_y.values.ravel(), pred_val),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_val_y.values.ravel(), pred_val))\n\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_val_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nAccuracy_Rate = (tp + tn) / (tp + tn + fp + fn)\nRecall_Rate = tp / (tp + fn)\nPrecision_Rate = tp / (tp + fp)\nSpecificity_Rate = tn / (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) / (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))",
            "mc_idx": 45,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.84,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.32,
                "Data_Transform": 0.2,
                "Model_Train": 0.04,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.08,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.24,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 20,
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plt.plot": 2,
                    ".plot(": 4,
                    "matplotlib": 1,
                    "columns": 1
                },
                "Data_Transform": {
                    "ravel": 5
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "confusion_matrix": 4,
                    "f1_score": 6,
                    "precision": 5,
                    "recall": 5,
                    "classification_report": 2,
                    "model": 1,
                    "roc_curve": 2
                },
                "Model_Interpretation": {
                    "model": 1,
                    "predict_proba": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "plt.plot": 2,
                    ".plot(": 2,
                    "matplotlib": 1,
                    "pyplot": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    39,
                    2,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "1. Counfusion Matrix\n                   True Value 0  True Value 1\nPredicted Value 0           145            39\nPredicted Value 1            12            72\n\n2. Classification Report\n              precision    recall  f1-score   support\n\n           0       0.79      0.92      0.85       157\n           1       0.86      0.65      0.74       111\n\n    accuracy                           0.81       268\n   macro avg       0.82      0.79      0.79       268\nweighted avg       0.82      0.81      0.80       268\n\n",
                        "<Figure size 432x288 with 1 Axes>",
                        "3. Model Metric Sumamry\n - Accuracy Rate    : 80.970 %\n - Recall Rate      : 64.865 %\n - Precision Rate   : 85.714 %\n - Specificity Rate : 92.357 %\n - F1 Score         : 73.846 \n - ROC AUC          : 86.934 \n"
                    ]
                },
                "mc_idx": 45,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 39,
                "o_idx": 2
            }
        },
        {
            "source": "predict_lgbm = lgbm.predict_proba(df_test_x.values)[:,1]\npred_test = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_test_y.values.ravel(), pred_test, labels=[1,0]).ravel()\n\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_test_y.values.ravel(), pred_test),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_test_y.values.ravel(), pred_test))\n\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_test_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nAccuracy_Rate = (tp + tn) / (tp + tn + fp + fn)\nRecall_Rate = tp / (tp + fn)\nPrecision_Rate = tp / (tp + fp)\nSpecificity_Rate = tn / (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) / (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))",
            "mc_idx": 46,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.84,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.32,
                "Data_Transform": 0.2,
                "Model_Train": 0.04,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.08,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.24,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 20,
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plt.plot": 2,
                    ".plot(": 4,
                    "matplotlib": 1,
                    "columns": 1
                },
                "Data_Transform": {
                    "ravel": 5
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "confusion_matrix": 4,
                    "f1_score": 6,
                    "precision": 5,
                    "recall": 5,
                    "classification_report": 2,
                    "model": 1,
                    "roc_curve": 2
                },
                "Model_Interpretation": {
                    "model": 1,
                    "predict_proba": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "plt.plot": 2,
                    ".plot(": 2,
                    "matplotlib": 1,
                    "pyplot": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    40,
                    2,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "1. Counfusion Matrix\n                   True Value 0  True Value 1\nPredicted Value 0           259            30\nPredicted Value 1             7           122\n\n2. Classification Report\n              precision    recall  f1-score   support\n\n           0       0.90      0.97      0.93       266\n           1       0.95      0.80      0.87       152\n\n    accuracy                           0.91       418\n   macro avg       0.92      0.89      0.90       418\nweighted avg       0.91      0.91      0.91       418\n\n",
                        "<Figure size 432x288 with 1 Axes>",
                        "3. Model Metric Sumamry\n - Accuracy Rate    : 91.148 %\n - Recall Rate      : 80.263 %\n - Precision Rate   : 94.574 %\n - Specificity Rate : 97.368 %\n - F1 Score         : 86.833 \n - ROC AUC          : 98.434 \n"
                    ]
                },
                "mc_idx": 46,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 40,
                "o_idx": 2
            }
        },
        {
            "source": "## 6.\uc81c\ucd9c\uc790\ub8cc \uc791\uc131(Prepare submission materials)",
            "mc_idx": 47,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "test_result= pd.DataFrame(pred_test)\ntest_result.columns = ['Survived']\npredict = test_result['Survived']\nId_No = df_test['PassengerId']\nsubmission = pd.DataFrame({'PassengerId': Id_No, \"Survived\": predict})\nsubmission['Survived'] = submission['Survived'].astype('Int64')\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()",
            "mc_idx": 48,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.5,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    "columns": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    41,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived\n0          892         0\n1          893         0\n2          894         0\n3          895         0\n4          896         1"
                    ]
                },
                "mc_idx": 48,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 41,
                "o_idx": 0
            }
        }
    ],
    "code_cells": [
        {
            "source": "import seaborn as sns\nimport sys\nimport csv\nimport datetime\nimport operator\nimport joblib\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import scale\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score\nfrom statsmodels.formula.api import ols\nfrom sklearn.metrics import cohen_kappa_score\nfrom collections import OrderedDict\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom scipy.stats import norm, skew, probplot",
            "mc_idx": 2,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.00909090909090909,
                "Data_Transform": 0.01818181818181818,
                "Model_Train": 0.01818181818181818,
                "Model_Evaluation": 0.045454545454545456,
                "Model_Interpretation": 0.00909090909090909,
                "Hyperparameter_Tuning": 0.004545454545454545,
                "Visualization": 0.00909090909090909,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 22
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "matplotlib": 1,
                    ".mode": 1
                },
                "Data_Transform": {
                    "labelencoder": 2,
                    "onehotencoder": 1,
                    ".mod": 1
                },
                "Model_Train": {
                    "train_test_split": 1,
                    "model": 2,
                    "model_selection": 1
                },
                "Model_Evaluation": {
                    "confusion_matrix": 2,
                    "accuracy_score": 2,
                    "precision": 1,
                    "recall": 1,
                    "classification_report": 2,
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {
                    "train_test_split": 1
                },
                "Visualization": {
                    "matplotlib": 1,
                    "pyplot": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    0,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<IPython.core.display.HTML object>"
                    ]
                },
                "mc_idx": 2,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 0,
                "o_idx": 0
            }
        },
        {
            "source": "df_train = pd.read_csv('/kaggle/input/titanic/train.csv')\ndf_test = pd.read_csv('/kaggle/input/titanic/test.csv')\ngender_submission = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')",
            "mc_idx": 4,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Data_Extraction",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 1.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {
                    "read_csv": 6,
                    "pd.read_": 6
                },
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    1,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 4,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 1,
                "o_idx": 0
            }
        },
        {
            "source": "df_train.head(5)",
            "mc_idx": 6,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    2,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  "
                    ]
                },
                "mc_idx": 6,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 2,
                "o_idx": 0
            }
        },
        {
            "source": "df_test.head(5)",
            "mc_idx": 7,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    3,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Pclass                                          Name     Sex  \\\n0          892       3                              Kelly, Mr. James    male   \n1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n2          894       2                     Myles, Mr. Thomas Francis    male   \n3          895       3                              Wirz, Mr. Albert    male   \n4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n\n    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n0  34.5      0      0   330911   7.8292   NaN        Q  \n1  47.0      1      0   363272   7.0000   NaN        S  \n2  62.0      0      0   240276   9.6875   NaN        Q  \n3  27.0      0      0   315154   8.6625   NaN        S  \n4  22.0      1      1  3101298  12.2875   NaN        S  "
                    ]
                },
                "mc_idx": 7,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 3,
                "o_idx": 0
            }
        },
        {
            "source": "gender_submission.head(5)\n# head()\ub97c \ud65c\uc6a9\ud558\uc5ec \ubcfc\ub54c PassengerId\ub97c \ud1b5\ud574\uc11c test data\uc758 \uacb0\uacfc\ub97c \uc608\uce21\ud560 \uc218 \uc788\uc74c\uc744 \uc608\uc0c1\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n# When using head(), it can be expected that the result of test data can be predicted through PassengerId.",
            "mc_idx": 8,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 3,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    4,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived\n0          892         0\n1          893         1\n2          894         0\n3          895         0\n4          896         1"
                    ]
                },
                "mc_idx": 8,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 4,
                "o_idx": 0
            }
        },
        {
            "source": "# 'Survived' column\uc744 \uc798 \ubd99\uc600\ub294\uc9c0 \ud655\uc778 \ud569\ub2c8\ub2e4.\n# Check if the 'Survived' column is attached properly.\ndf_test['Survived'] = gender_submission['Survived']\ndf_test.head(5)",
            "mc_idx": 9,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    5,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Pclass                                          Name     Sex  \\\n0          892       3                              Kelly, Mr. James    male   \n1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n2          894       2                     Myles, Mr. Thomas Francis    male   \n3          895       3                              Wirz, Mr. Albert    male   \n4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n\n    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  Survived  \n0  34.5      0      0   330911   7.8292   NaN        Q         0  \n1  47.0      1      0   363272   7.0000   NaN        S         1  \n2  62.0      0      0   240276   9.6875   NaN        Q         0  \n3  27.0      0      0   315154   8.6625   NaN        S         0  \n4  22.0      1      1  3101298  12.2875   NaN        S         1  "
                    ]
                },
                "mc_idx": 9,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 5,
                "o_idx": 0
            }
        },
        {
            "source": "#\ud1b5\uacc4\uc801\uc73c\ub85c \ubd84\ud3ec\uac00 \uc5b4\ub5a0\ud55c\uc9c0 Pair Plot \ubc0f \uc5ec\ub7ec \uadf8\ub798\ud504\ub97c \ud1b5\ud558\uc5ec \ubd84\uc11d\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n# Let's analyze how the distribution is statistically through pair plots and several graphs.\n\nsns.pairplot(data = df_train)",
            "mc_idx": 10,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 1.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.pairplot": 1,
                    "sns.": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1,
                    "graph": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0089_c006_o001_image_0.png",
                    6,
                    1,
                    0
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<seaborn.axisgrid.PairGrid at 0x7f6597d84190>",
                        "<Figure size 1260x1260 with 56 Axes>"
                    ]
                },
                "mc_idx": 10,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 6,
                "o_idx": 1
            }
        },
        {
            "source": "def analysis(data):\n    print(\"1. \uccab\ubc88\uc9f8 \uadf8\ub798\ud504\ub294 Data\uc758 Heatmap \ubd84\uc11d \uacb0\uacfc\uc785\ub2c8\ub2e4.\uc0c1\uad00\uad00\uacc4\uac00 \ub192\uc744\uc218\ub85d \uc0c9\uae54\uc774 \uc9c4\ud558\ub3c4\ub85d \ud45c\uc2dc\ud558\uc600\uc2b5\ub2c8\ub2e4.\")\n    print(\"2. \ub450\ubc88\uc9f8 \uadf8\ub798\ud504\ub294 null ratio\ub97c \uadf8\ub798\ud504\ub85c \ud45c\uc2dc\ud558\uc600\uc2b5\ub2c8\ub2e4.\")\n    sns.heatmap(data.corr(), annot=True, cmap='Reds')\n    null_percent = 100*(data.isnull().sum()/len(data))\n    null_percent = null_percent[null_percent>0].sort_values()\n    plt.figure(figsize= (10,4))\n    sns.barplot(x=null_percent.index, y= null_percent)\n    plt.xticks(rotation=90)",
            "mc_idx": 11,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.1111111111111111,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.4444444444444444,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".corr": 2,
                    "sns.heatmap": 1,
                    ".heatmap(": 1,
                    "sns.": 2,
                    "size": 1,
                    ".isnull": 1,
                    ".sum": 1
                },
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.heatmap": 1,
                    ".heatmap(": 1,
                    "sns.": 2
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    7,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 11,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 7,
                "o_idx": 0
            }
        },
        {
            "source": "analysis(df_train)",
            "mc_idx": 12,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0089_c008_o002_image_2.png",
                    8,
                    2,
                    2
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "1. \uccab\ubc88\uc9f8 \uadf8\ub798\ud504\ub294 Data\uc758 Heatmap \ubd84\uc11d \uacb0\uacfc\uc785\ub2c8\ub2e4.\uc0c1\uad00\uad00\uacc4\uac00 \ub192\uc744\uc218\ub85d \uc0c9\uae54\uc774 \uc9c4\ud558\ub3c4\ub85d \ud45c\uc2dc\ud558\uc600\uc2b5\ub2c8\ub2e4.\n2. \ub450\ubc88\uc9f8 \uadf8\ub798\ud504\ub294 null ratio\ub97c \uadf8\ub798\ud504\ub85c \ud45c\uc2dc\ud558\uc600\uc2b5\ub2c8\ub2e4.\n",
                        "<Figure size 432x288 with 2 Axes>",
                        "<Figure size 720x288 with 1 Axes>"
                    ]
                },
                "mc_idx": 12,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 8,
                "o_idx": 2
            }
        },
        {
            "source": "analysis(df_test)",
            "mc_idx": 13,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Other",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [],
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0089_c009_o002_image_4.png",
                    9,
                    2,
                    4
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "1. \uccab\ubc88\uc9f8 \uadf8\ub798\ud504\ub294 Data\uc758 Heatmap \ubd84\uc11d \uacb0\uacfc\uc785\ub2c8\ub2e4.\uc0c1\uad00\uad00\uacc4\uac00 \ub192\uc744\uc218\ub85d \uc0c9\uae54\uc774 \uc9c4\ud558\ub3c4\ub85d \ud45c\uc2dc\ud558\uc600\uc2b5\ub2c8\ub2e4.\n2. \ub450\ubc88\uc9f8 \uadf8\ub798\ud504\ub294 null ratio\ub97c \uadf8\ub798\ud504\ub85c \ud45c\uc2dc\ud558\uc600\uc2b5\ub2c8\ub2e4.\n",
                        "<Figure size 432x288 with 2 Axes>",
                        "<Figure size 720x288 with 1 Axes>"
                    ]
                },
                "mc_idx": 13,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 9,
                "o_idx": 2
            }
        },
        {
            "source": "fat=ols(formula='Survived~PassengerId+Pclass+Age+Sex+SibSp+Parch+Fare+Embarked', data=df_train).fit()\nprint(fat.summary())\n\n# \ud1b5\uacc4\uc801\uc73c\ub85c\ub294 \uc131\ubcc4\uc5d0 \ub530\ub978 \uad6c\ubd84\uacfc Pclass\uc5d0 \ub530\ub77c \uc0dd\uc874\ub960\uc774 \uc601\ud5a5\ub3c4\uac00 \uac00\uc7a5 \ub192\uc740 \uac83\uc73c\ub85c \ub098\uc654\uace0, \n# OLS Regression\uc73c\ub85c \uc608\uce21\uc2dc \uc0c1\uae30\uc758 8\uac1c \ubcc0\uc218\ub9cc\uc73c\ub85c \ubcf8\ub2e4\uba74, R-squre 0.4/ Adjust R-square 0.39\uc218\uc900\uc758 \uc608\uce21\uc774 \uac00\ub2a5 \ud560 \uac83\uc73c\ub85c \uc608\uc0c1 \ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n\n# Statistically, it was found that the survival rate was the most influential according to the classification according to gender and Pclass.\n# When predicting with OLS regression, if we consider only the above 8 variables, it was expected that the R-squre 0.4/ Adjust R-square 0.39 level could be predicted.",
            "mc_idx": 14,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".sum": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "summary": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    10,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "                            OLS Regression Results                            \n==============================================================================\nDep. Variable:               Survived   R-squared:                       0.402\nModel:                            OLS   Adj. R-squared:                  0.394\nMethod:                 Least Squares   F-statistic:                     52.39\nDate:                Wed, 20 Oct 2021   Prob (F-statistic):           1.41e-72\nTime:                        07:13:36   Log-Likelihood:                -320.62\nNo. Observations:                 712   AIC:                             661.2\nDf Residuals:                     702   BIC:                             706.9\nDf Model:                           9                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P>|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nIntercept         1.3786      0.086     16.100      0.000       1.210       1.547\nSex[T.male]      -0.4861      0.032    -15.406      0.000      -0.548      -0.424\nEmbarked[T.Q]    -0.0977      0.082     -1.185      0.236      -0.259       0.064\nEmbarked[T.S]    -0.0665      0.040     -1.678      0.094      -0.144       0.011\nPassengerId    5.192e-05   5.57e-05      0.932      0.351   -5.74e-05       0.000\nPclass           -0.1869      0.023     -8.157      0.000      -0.232      -0.142\nAge              -0.0064      0.001     -5.657      0.000      -0.009      -0.004\nSibSp            -0.0495      0.018     -2.829      0.005      -0.084      -0.015\nParch            -0.0111      0.019     -0.584      0.559      -0.049       0.026\nFare              0.0002      0.000      0.562      0.574      -0.000       0.001\n==============================================================================\nOmnibus:                       26.257   Durbin-Watson:                   1.848\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               28.488\nSkew:                           0.490   Prob(JB):                     6.52e-07\nKurtosis:                       3.019   Cond. No.                     3.28e+03\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 3.28e+03. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n"
                    ]
                },
                "mc_idx": 14,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 10,
                "o_idx": 0
            }
        },
        {
            "source": "# \uc22b\uc790 \ud0c0\uc785\uc758 \ub370\uc774\ud130 \ucd94\ucd9c\n# Numeric Feature Enginearing\n\nnum_cols = [col for col in df_train.columns if df_train[col].dtype in ['int64','float64']]\ndf_train[num_cols].describe()",
            "mc_idx": 15,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".describe(": 1,
                    "describe": 1,
                    "columns": 1,
                    ".describe": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    11,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "       PassengerId    Survived      Pclass         Age       SibSp  \\\ncount   891.000000  891.000000  891.000000  714.000000  891.000000   \nmean    446.000000    0.383838    2.308642   29.699118    0.523008   \nstd     257.353842    0.486592    0.836071   14.526497    1.102743   \nmin       1.000000    0.000000    1.000000    0.420000    0.000000   \n25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n75%     668.500000    1.000000    3.000000   38.000000    1.000000   \nmax     891.000000    1.000000    3.000000   80.000000    8.000000   \n\n            Parch        Fare  \ncount  891.000000  891.000000  \nmean     0.381594   32.204208  \nstd      0.806057   49.693429  \nmin      0.000000    0.000000  \n25%      0.000000    7.910400  \n50%      0.000000   14.454200  \n75%      0.000000   31.000000  \nmax      6.000000  512.329200  "
                    ]
                },
                "mc_idx": 15,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 11,
                "o_idx": 0
            }
        },
        {
            "source": "df_train.corr(method='pearson')",
            "mc_idx": 16,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".corr": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    12,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "             PassengerId  Survived    Pclass       Age     SibSp     Parch  \\\nPassengerId     1.000000 -0.005007 -0.035144  0.036847 -0.057527 -0.001652   \nSurvived       -0.005007  1.000000 -0.338481 -0.077221 -0.035322  0.081629   \nPclass         -0.035144 -0.338481  1.000000 -0.369226  0.083081  0.018443   \nAge             0.036847 -0.077221 -0.369226  1.000000 -0.308247 -0.189119   \nSibSp          -0.057527 -0.035322  0.083081 -0.308247  1.000000  0.414838   \nParch          -0.001652  0.081629  0.018443 -0.189119  0.414838  1.000000   \nFare            0.012658  0.257307 -0.549500  0.096067  0.159651  0.216225   \n\n                 Fare  \nPassengerId  0.012658  \nSurvived     0.257307  \nPclass      -0.549500  \nAge          0.096067  \nSibSp        0.159651  \nParch        0.216225  \nFare         1.000000  "
                    ]
                },
                "mc_idx": 16,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 12,
                "o_idx": 0
            }
        },
        {
            "source": "df_train.info()",
            "mc_idx": 17,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".info(": 1,
                    "info": 1,
                    ".info": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    13,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n"
                    ]
                },
                "mc_idx": 17,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 13,
                "o_idx": 0
            }
        },
        {
            "source": "# \ub370\uc774\ud130\ub0b4 \uc911\ubcf5 \uac12\uc740 \uc5c6\ub294\uc9c0 \ud655\uc778\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \n# Let's check that there are no duplicate values in the data.\n\ndf_train=df_train.drop_duplicates()",
            "mc_idx": 18,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "duplicates": 1
                },
                "Data_Transform": {
                    ".drop": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    14,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 18,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 14,
                "o_idx": 0
            }
        },
        {
            "source": "df_train.info()",
            "mc_idx": 19,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".info(": 1,
                    "info": 1,
                    ".info": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    15,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 90.5+ KB\n"
                    ]
                },
                "mc_idx": 19,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 15,
                "o_idx": 0
            }
        },
        {
            "source": "# \uc65c\ub3c4\uc640 \ucca8\ub3c4\ub97c \ud655\uc778\ud558\ub294 \uacbd\uc6b0 Regression Modeling\ud560 \uacbd\uc6b0 \ub9ce\uc774 \ubcf4\ub098, \uae08\ubc88\uc758 \uacbd\uc6b0\ub294 \ub2e8\uc21c\ud788 \uc6b0\ub9ac\uac00 \uc54c\uace0 \uc2f6\uc740 Y\uac12(Survived)\uc758 \ubd84\ud3ec\uac00 3:2\ub77c\ub294 \uac83\n# \uc815\ub3c4 \ubc16\uc758 \uc815\ubcf4\ub97c \uc5bb\uc744\uc218 \uc5c6\uc5c8\uc2b5\ub2c8\ub2e4.\n\n# When checking skewness and kurtosis, it is often seen in Regression Modeling, but in this case, we could not simply obtain information other than that the distribution of Y-value (Survived) we wanted to know was 3:2.\nprint(f'skew: {df_train.Survived.skew()}')\nprint(f'kert: {df_train.Survived.kurt()}')\nsns.distplot(df_train.Survived, fit = norm)\nf = plt.figure()\nprobplot(df_train.Survived, plot = plt)\nplt.show()",
            "mc_idx": 20,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.2,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.4,
                "Model_Evaluation": 0.4,
                "Model_Interpretation": 0.4,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "distplot": 1,
                    "sns.": 1,
                    "info": 1,
                    ".skew": 1,
                    ".kurt": 1
                },
                "Data_Transform": {},
                "Model_Train": {
                    "model": 2
                },
                "Model_Evaluation": {
                    "model": 2
                },
                "Model_Interpretation": {
                    "model": 2
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0089_c016_o002_image_6.png",
                    16,
                    2,
                    6
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "skew: 0.4785234382949897\nkert: -1.775004671066304\n",
                        "<Figure size 432x288 with 1 Axes>",
                        "<Figure size 432x288 with 1 Axes>"
                    ]
                },
                "mc_idx": 20,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 16,
                "o_idx": 2
            }
        },
        {
            "source": "def count_plot(d, y, x):\n    plt.figure(figsize=(12,6))\n    sns.countplot(x = d[y], hue = x, data=d)\n    plt.ylabel('Number of people')\n    plt.title('Survival count by '+ x)",
            "mc_idx": 21,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.5,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    17,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 21,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 17,
                "o_idx": 0
            }
        },
        {
            "source": "numeric_cols = [col for col in df_train if df_train[col].dtype in ['int64','float64']]\nnumeric_cols.remove('Survived')\ny = 'Survived'\nover_column_name = list()\n\nfor i in numeric_cols:\n    if (len(df_train[i].value_counts())<20):\n        count_plot(df_train, y, i)\n    elif (len(df_train[i].value_counts())>20):\n        over_column_name.append(i)\n\nprint('Column\ub0b4 \ubcc0\uc218\uac00 20\uac1c \uc774\uc0c1\uc758 Column\uc740 \ud558\ub2e8\uacfc \uac19\uc2b5\ub2c8\ub2e4.\\n\ubcc0\uc218 20\uac1c \ubbf8\ub9cc\uc758 Column\uacfc Survived \uc22b\uc790 \ubd84\ud3ec\ub294 \uadf8\ub798\ud504\uc640 \uac19\uc2b5\ub2c8\ub2e4.')\nprint(over_column_name)",
            "mc_idx": 22,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "value_counts()": 2,
                    ".value_counts": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0089_c018_o003_image_9.png",
                    18,
                    3,
                    9
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "Column\ub0b4 \ubcc0\uc218\uac00 20\uac1c \uc774\uc0c1\uc758 Column\uc740 \ud558\ub2e8\uacfc \uac19\uc2b5\ub2c8\ub2e4.\n\ubcc0\uc218 20\uac1c \ubbf8\ub9cc\uc758 Column\uacfc Survived \uc22b\uc790 \ubd84\ud3ec\ub294 \uadf8\ub798\ud504\uc640 \uac19\uc2b5\ub2c8\ub2e4.\n['PassengerId', 'Age', 'Fare']\n",
                        "<Figure size 864x432 with 1 Axes>",
                        "<Figure size 864x432 with 1 Axes>",
                        "<Figure size 864x432 with 1 Axes>"
                    ]
                },
                "mc_idx": 22,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 18,
                "o_idx": 3
            }
        },
        {
            "source": "print(num_cols)\nnum_cols.remove('PassengerId')\n\nfig, ax = plt.subplots(3, 2, figsize=(20, 10))\n\nfor variable, subplot in zip(num_cols, ax.flatten()):\n    sns.countplot(df_train[variable], ax=subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(60)\n        \nplt.tight_layout()",
            "mc_idx": 23,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.6666666666666666,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.6666666666666666,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 2
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "fig, ax = plt.subplots": 1,
                    "sns.": 1,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "fig, ax = plt.subplots": 1,
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0089_c019_o001_image_10.png",
                    19,
                    1,
                    10
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
                        "<Figure size 1440x720 with 6 Axes>"
                    ]
                },
                "mc_idx": 23,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 19,
                "o_idx": 1
            }
        },
        {
            "source": "cat_cols = [col for col in df_train if df_train[col].dtype not in ['int64','float64']]\nprint(cat_cols)\ncat_cols.remove('Name')\n\nfig, ax = plt.subplots(2, 2, figsize=(20, 10))\n\nfor variable, subplot in zip(cat_cols, ax.flatten()):\n    sns.countplot(df_train[variable], ax=subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(90)\n        \nplt.tight_layout()",
            "mc_idx": 24,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.6666666666666666,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.6666666666666666,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 2
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "fig, ax = plt.subplots": 1,
                    "sns.": 1,
                    "size": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "fig, ax = plt.subplots": 1,
                    "sns.": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0089_c020_o001_image_11.png",
                    20,
                    1,
                    11
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
                        "<Figure size 1440x720 with 4 Axes>"
                    ]
                },
                "mc_idx": 24,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 20,
                "o_idx": 1
            }
        },
        {
            "source": "# train data\uc0c1 null\uac12\uc744 \ud655\uc778\ndf_train.isna().sum()",
            "mc_idx": 25,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".isna": 1,
                    ".sum": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    21,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "PassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64"
                    ]
                },
                "mc_idx": 25,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 21,
                "o_idx": 0
            }
        },
        {
            "source": "df_train=df_train.drop(['Name','Ticket'],axis=1)\ndf_test=df_test.drop(['Name','Ticket'],axis=1)",
            "mc_idx": 26,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    22,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 26,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 22,
                "o_idx": 0
            }
        },
        {
            "source": "# Cabin \uc815\ubcf4\ub294 \ub2e4 \ubc84\ub9ac\uae30 \uc544\uae4c\uc6cc \uae00\uc790\uc218\ub97c \ubcc0\uc218\ub85c \ud55c\ubc88 \ud65c\uc6a9\ud574\ubcfc \uc0dd\uac01\uc785\ub2c8\ub2e4.\n# Rather than deleting the Cabin column, I will use \"len()\" to use the number of characters in the variable.\ndf_train['CabinCode'] = df_train['Cabin'].apply(lambda x : len(str(x)) if x!='nan' else 0)\ndf_test['CabinCode'] = df_test['Cabin'].apply(lambda x  : len(str(x)) if x!='nan' else 0)",
            "mc_idx": 27,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.25,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".apply(": 2,
                    ".apply": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    23,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 27,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 23,
                "o_idx": 0
            }
        },
        {
            "source": "df_train=df_train.drop(['Cabin'],axis=1)\ndf_test=df_test.drop(['Cabin'],axis=1)",
            "mc_idx": 28,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    24,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 28,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 24,
                "o_idx": 0
            }
        },
        {
            "source": "# nan\uac12 \uc5ed\uc2dc \ud558\ub098\uc758 \ubcc0\uc218\uac00 \uc544\ub2d0\uae4c\ub77c\ub294 \uac00\uc815\ud558\uc5d0 \uae08\ubc88 \ubd84\uc11d\uc5d0\uc11c\ub294 null\uac12\uc5d0 \ub300\ud55c \ubcf4\uc815 \uc5c6\uc774 \uc9c4\ud589\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n# Assuming that the nan value is also a variable, in this analysis, we will proceed without correction for the null value.\n\ndf_train=pd.get_dummies(df_train)\ndf_test=pd.get_dummies(df_test)",
            "mc_idx": 29,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".get_dummies": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    25,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 29,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 25,
                "o_idx": 0
            }
        },
        {
            "source": "df_train.info()\ndf_test.info()",
            "mc_idx": 30,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".info(": 2,
                    "info": 2,
                    ".info": 2
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    26,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 891 entries, 0 to 890\nData columns (total 13 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Age          714 non-null    float64\n 4   SibSp        891 non-null    int64  \n 5   Parch        891 non-null    int64  \n 6   Fare         891 non-null    float64\n 7   CabinCode    891 non-null    int64  \n 8   Sex_female   891 non-null    uint8  \n 9   Sex_male     891 non-null    uint8  \n 10  Embarked_C   891 non-null    uint8  \n 11  Embarked_Q   891 non-null    uint8  \n 12  Embarked_S   891 non-null    uint8  \ndtypes: float64(2), int64(6), uint8(5)\nmemory usage: 99.3 KB\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 418 entries, 0 to 417\nData columns (total 13 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  418 non-null    int64  \n 1   Pclass       418 non-null    int64  \n 2   Age          332 non-null    float64\n 3   SibSp        418 non-null    int64  \n 4   Parch        418 non-null    int64  \n 5   Fare         417 non-null    float64\n 6   Survived     418 non-null    int64  \n 7   CabinCode    418 non-null    int64  \n 8   Sex_female   418 non-null    uint8  \n 9   Sex_male     418 non-null    uint8  \n 10  Embarked_C   418 non-null    uint8  \n 11  Embarked_Q   418 non-null    uint8  \n 12  Embarked_S   418 non-null    uint8  \ndtypes: float64(2), int64(6), uint8(5)\nmemory usage: 28.3 KB\n"
                    ]
                },
                "mc_idx": 30,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 26,
                "o_idx": 0
            }
        },
        {
            "source": "df_train.head(5)",
            "mc_idx": 31,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    ".head": 1
                },
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    27,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  CabinCode  \\\n0            1         0       3  22.0      1      0   7.2500          3   \n1            2         1       1  38.0      1      0  71.2833          3   \n2            3         1       3  26.0      0      0   7.9250          3   \n3            4         1       1  35.0      1      0  53.1000          4   \n4            5         0       3  35.0      0      0   8.0500          3   \n\n   Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n0           0         1           0           0           1  \n1           1         0           1           0           0  \n2           1         0           0           0           1  \n3           1         0           0           0           1  \n4           0         1           0           0           1  "
                    ]
                },
                "mc_idx": 31,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 27,
                "o_idx": 0
            }
        },
        {
            "source": "# 7:3\uc73c\ub85c \uc81c\uacf5\ub41c train data\ub97c train\uacfc validation data\ub85c \uad6c\ubd84\n\nfrom sklearn.model_selection import train_test_split\n\nrandom_state_val =42\ntest_size_val =0.3\ntrain,validation = train_test_split(df_train, test_size = test_size_val, random_state = random_state_val)",
            "mc_idx": 33,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.4,
                "Data_Transform": 0.1,
                "Model_Train": 0.4,
                "Model_Evaluation": 0.1,
                "Model_Interpretation": 0.1,
                "Hyperparameter_Tuning": 0.2,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 10
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "size": 3,
                    ".mode": 1
                },
                "Data_Transform": {
                    ".mod": 1
                },
                "Model_Train": {
                    "train_test_split": 2,
                    "model": 1,
                    "model_selection": 1
                },
                "Model_Evaluation": {
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {
                    "train_test_split": 2
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    28,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 33,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 28,
                "o_idx": 0
            }
        },
        {
            "source": "# \"read.csv\"\ub97c \uc4f0\ub2e4\ubcf4\uba74 \uac00\ub054 Unnamed: 0\uc73c\ub85c \ubb38\uc81c\ubc1c\uc0dd\uc774 \ub9ce\uc774 \ubc1c\uc0dd\ud568\n# \uadf8\ub798\uc11c \uc800\ub294 \ubd84\uc11d\uc2dc \ubb34\uc870\uac74 \ub123\uc5b4\uc11c \uc2e4\ud589\ud558\uace4 \ud569\ub2c8\ub2e4.\n\n# When I use the \"read.csv\" function, sometimes I get a lot of problems with Unnamed: 0. So, when I analyze, I put it in unconditionally and run it.\n#train = train.drop(['Unnamed: 0'], axis= 1)\n#validation = validation.drop(['Unnamed: 0'], axis= 1)\n#test = df_test.drop(['Unnamed: 0'], axis= 1)",
            "mc_idx": 34,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 3
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    29,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 34,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 29,
                "o_idx": 0
            }
        },
        {
            "source": "drop_col = ['Survived']\ny_nm = 'Survived'\n\ndf_train_x = train.drop(drop_col, axis = 1)\ndf_train_y = pd.DataFrame(train[y_nm])\n\ndf_val_x = validation.drop(drop_col, axis = 1)\ndf_val_y = pd.DataFrame(validation[y_nm])\n\ndf_test_x = df_test.drop(drop_col, axis = 1)\ndf_test_y = pd.DataFrame(df_test[y_nm])",
            "mc_idx": 35,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    ".drop": 3
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    30,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 35,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 30,
                "o_idx": 0
            }
        },
        {
            "source": "LGBClassifier = lgb.LGBMClassifier(objective='binary',\n                                   max_depth = 8,\n                                   learning_rate = 0.01,\n                                   n_estimators = 9000,\n                                   max_bin = 200,\n                                   bagging_freq = 4,\n                                   bagging_seed = 8,\n                                   feature_fraction = 0.2,\n                                   feature_fraction_seed = 8,\n                                   min_sum_hessian_in_leaf = 11,\n                                   verbose = -1,\n                                   random_state = 42)",
            "mc_idx": 36,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Model_Interpretation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 1.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "hessian": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    31,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 36,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 31,
                "o_idx": 0
            }
        },
        {
            "source": "start = datetime.datetime.now()\nlgbm = LGBClassifier.fit(df_train_x.values,\n                       df_train_y.values.ravel(),\n                       eval_set = [(df_train_x.values, df_train_y), (df_val_x.values, df_val_y)],\n                       eval_metric ='logloss',\n                       early_stopping_rounds = 20,\n                       verbose =False)\nend = datetime.datetime.now()\nend-start",
            "mc_idx": 37,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 1.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 1.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "ravel": 1
                },
                "Model_Train": {
                    ".fit(": 1
                },
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {
                    "early_stopping": 1
                },
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    32,
                    1,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
                        "datetime.timedelta(microseconds=304034)"
                    ]
                },
                "mc_idx": 37,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 32,
                "o_idx": 1
            }
        },
        {
            "source": "# Importance \ud655\uc778 \n# \uc8fc\uc694 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294 \ubcc0\uc218\uac00 \ubb34\uc5c7\uc778\uc9c0 \ud655\uc778\uc744 \ud558\uace0, \uc774\ub97c \uadf8\ub798\ud504\ud654 \uc9c4\ud589\ud558\uc600\uc2b5\ub2c8\ub2e4.\n# We checked the variables that have a major impact, and graphed them.\n\nfeature_imp= pd.DataFrame(sorted(zip(lgbm.feature_importances_, df_test_x.columns), reverse = True), columns = ['Value', 'Feature'])\n# feature_imp.to_excel(\"feature_imp.xlsx\")\n\nplt.figure(figsize=(7,5))\nsns.barplot(x='Value', y='Feature', data=feature_imp.sort_values(by='Value', ascending=False))\nplt.tight_layout()\nplt.show()\n# plt.savefig('lightGBM_ Importances.png')",
            "mc_idx": 38,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.5,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.75,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.5,
                "Debug": 0.0,
                "Data_Export": 1.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    ".show": 1,
                    "variable": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "sns.": 1,
                    "columns": 2,
                    "size": 1
                },
                "Data_Transform": {
                    ".sort_values": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {
                    "feature_importances_": 2,
                    "impact": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "sns.": 1,
                    "graph": 1
                },
                "Debug": {},
                "Data_Export": {
                    ".to_excel(": 1,
                    "savefig": 1,
                    "save": 1,
                    "to_excel": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0089_c033_o000_image_12.png",
                    33,
                    0,
                    12
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 504x360 with 1 Axes>"
                    ]
                },
                "mc_idx": 38,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 33,
                "o_idx": 0
            }
        },
        {
            "source": "# for loop\ub97c \uc0ac\uc6a9\ud558\uc5ec \uac00\uc7a5 \ub192\uc740 accuracy\ub97c \uc0b0\ucd9c\ud558\ub294 \ub85c\uc9c1\uc744 \ub123\uc5c8\uc2b5\ub2c8\ub2e4. \n# I put the logic that yields the highest accuracy using a for loop.\n\nresult_lst =[]\nmax_accuracy =0.\nopt_threshold =0.\nval_y_prob = lgbm.predict_proba(df_val_x.values)[:, 1]\n\nfor n in range(0,60):\n    threshold = round(((n+1)*0.01),2)\n    pred_yn = val_y_prob.copy()\n    pred_yn = np.where(pred_yn > threshold, 1., 0.)\n    \n    result_dict = {}\n    precision, recall, f1_score, support = precision_recall_fscore_support(df_val_y.values.ravel(), pred_yn, average='binary')\n    accuracy = accuracy_score(df_val_y.values.ravel(), pred_yn)\n    kappa = cohen_kappa_score(df_val_y.values.ravel(), pred_yn)\n    \n    result_dict ={'Threshold': threshold, 'Accuracy': round(accuracy,4), 'Precision': round(precision,4), 'Recall': round(recall,4), 'F1_Score': round(f1_score,4), 'Kappa': round(kappa,4)}\n    result_lst.append(result_dict)\n    \n    if max_accuracy <= accuracy:\n        max_accuracy = accuracy\n        opt_threshold = threshold\n        \n    confMat = confusion_matrix(df_val_y.values.ravel(), pred_yn, labels=[1,0])\n    \nmatric_df = pd.DataFrame(result_lst, columns=['Threshold','Accuracy', 'Precision', 'Recall', 'F1_Score', 'Kappa'])\nmatric_df.to_csv('REC_scores.csv',sep=',', header=True, index=False, encoding='UTF-8')\n\nprint('\ucd5c\uace0 Accuracy-SCORE =%f, \uc784\uacc4\uce58=%f'%(max_accuracy, opt_threshold))\nprint('Threshold \uc124\uc815 \uc644\ub8cc')",
            "mc_idx": 39,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.07692307692307693,
                "Data_Transform": 0.15384615384615385,
                "Model_Train": 0.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.038461538461538464,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.07692307692307693,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "head": 1,
                    "columns": 1
                },
                "Data_Transform": {
                    "ravel": 4
                },
                "Model_Train": {},
                "Model_Evaluation": {
                    "confusion_matrix": 2,
                    "accuracy_score": 2,
                    "f1_score": 12,
                    "precision": 5,
                    "recall": 5
                },
                "Model_Interpretation": {
                    "predict_proba": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    34,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "\ucd5c\uace0 Accuracy-SCORE =0.809701, \uc784\uacc4\uce58=0.540000\nThreshold \uc124\uc815 \uc644\ub8cc\n"
                    ]
                },
                "mc_idx": 39,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 34,
                "o_idx": 0
            }
        },
        {
            "source": "predict_lgbm = lgbm.predict_proba(df_train_x.values)[:,1]\npred_train = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_train_y.values.ravel(), pred_train, labels=[1,0]).ravel()",
            "mc_idx": 41,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Data_Transform",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 1.0,
                "Model_Train": 0.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.5,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {
                    "ravel": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {
                    "confusion_matrix": 2
                },
                "Model_Interpretation": {
                    "predict_proba": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    35,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": []
                },
                "mc_idx": 41,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 35,
                "o_idx": 0
            }
        },
        {
            "source": "conf_matrix = pd.DataFrame(\n    confusion_matrix(df_train_y.values.ravel(), pred_train),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_train_y.values.ravel(), pred_train))",
            "mc_idx": 42,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.25,
                "Data_Transform": 0.5,
                "Model_Train": 0.0,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "columns": 1
                },
                "Data_Transform": {
                    "ravel": 2
                },
                "Model_Train": {},
                "Model_Evaluation": {
                    "confusion_matrix": 2,
                    "classification_report": 2
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    36,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "1. Counfusion Matrix\n                   True Value 0  True Value 1\nPredicted Value 0           370            81\nPredicted Value 1            22           150\n\n2. Classification Report\n              precision    recall  f1-score   support\n\n           0       0.82      0.94      0.88       392\n           1       0.87      0.65      0.74       231\n\n    accuracy                           0.83       623\n   macro avg       0.85      0.80      0.81       623\nweighted avg       0.84      0.83      0.83       623\n\n"
                    ]
                },
                "mc_idx": 42,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 36,
                "o_idx": 0
            }
        },
        {
            "source": "from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_train_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()",
            "mc_idx": 43,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Environment",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 1.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.3333333333333333,
                "Data_Transform": 0.047619047619047616,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.09523809523809523,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.2857142857142857,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 20,
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plt.plot": 2,
                    ".plot(": 4,
                    "matplotlib": 1
                },
                "Data_Transform": {
                    "ravel": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {
                    "roc_curve": 2
                },
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "plt.plot": 2,
                    ".plot(": 2,
                    "matplotlib": 1,
                    "pyplot": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    "data/data_Kaggle/outp/images/d0089_c037_o000_image_13.png",
                    37,
                    0,
                    13
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "<Figure size 432x288 with 1 Axes>"
                    ]
                },
                "mc_idx": 43,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 37,
                "o_idx": 0
            }
        },
        {
            "source": "Accuracy_Rate = (tp + tn) / (tp + tn + fp + fn)\nRecall_Rate = tp / (tp + fn)\nPrecision_Rate = tp / (tp + fp)\nSpecificity_Rate = tn / (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) / (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))",
            "mc_idx": 44,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.0,
                "Data_Transform": 0.0,
                "Model_Train": 0.058823529411764705,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.058823529411764705,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {},
                "Data_Transform": {},
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "f1_score": 6,
                    "precision": 5,
                    "recall": 5,
                    "model": 1
                },
                "Model_Interpretation": {
                    "model": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    38,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "3. Model Metric Sumamry\n - Accuracy Rate    : 83.467 %\n - Recall Rate      : 64.935 %\n - Precision Rate   : 87.209 %\n - Specificity Rate : 94.388 %\n - F1 Score         : 74.442 \n - ROC AUC          : 88.703 \n"
                    ]
                },
                "mc_idx": 44,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 38,
                "o_idx": 0
            }
        },
        {
            "source": "predict_lgbm = lgbm.predict_proba(df_val_x.values)[:,1]\npred_val = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_val_y.values.ravel(), pred_val, labels=[1,0]).ravel()\n\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_val_y.values.ravel(), pred_val),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_val_y.values.ravel(), pred_val))\n\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_val_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nAccuracy_Rate = (tp + tn) / (tp + tn + fp + fn)\nRecall_Rate = tp / (tp + fn)\nPrecision_Rate = tp / (tp + fp)\nSpecificity_Rate = tn / (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) / (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))",
            "mc_idx": 45,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.84,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.32,
                "Data_Transform": 0.2,
                "Model_Train": 0.04,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.08,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.24,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 20,
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plt.plot": 2,
                    ".plot(": 4,
                    "matplotlib": 1,
                    "columns": 1
                },
                "Data_Transform": {
                    "ravel": 5
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "confusion_matrix": 4,
                    "f1_score": 6,
                    "precision": 5,
                    "recall": 5,
                    "classification_report": 2,
                    "model": 1,
                    "roc_curve": 2
                },
                "Model_Interpretation": {
                    "model": 1,
                    "predict_proba": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "plt.plot": 2,
                    ".plot(": 2,
                    "matplotlib": 1,
                    "pyplot": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    39,
                    2,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "1. Counfusion Matrix\n                   True Value 0  True Value 1\nPredicted Value 0           145            39\nPredicted Value 1            12            72\n\n2. Classification Report\n              precision    recall  f1-score   support\n\n           0       0.79      0.92      0.85       157\n           1       0.86      0.65      0.74       111\n\n    accuracy                           0.81       268\n   macro avg       0.82      0.79      0.79       268\nweighted avg       0.82      0.81      0.80       268\n\n",
                        "<Figure size 432x288 with 1 Axes>",
                        "3. Model Metric Sumamry\n - Accuracy Rate    : 80.970 %\n - Recall Rate      : 64.865 %\n - Precision Rate   : 85.714 %\n - Specificity Rate : 92.357 %\n - F1 Score         : 73.846 \n - ROC AUC          : 86.934 \n"
                    ]
                },
                "mc_idx": 45,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 39,
                "o_idx": 2
            }
        },
        {
            "source": "predict_lgbm = lgbm.predict_proba(df_test_x.values)[:,1]\npred_test = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_test_y.values.ravel(), pred_test, labels=[1,0]).ravel()\n\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_test_y.values.ravel(), pred_test),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_test_y.values.ravel(), pred_test))\n\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_test_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nAccuracy_Rate = (tp + tn) / (tp + tn + fp + fn)\nRecall_Rate = tp / (tp + fn)\nPrecision_Rate = tp / (tp + fp)\nSpecificity_Rate = tn / (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) / (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))",
            "mc_idx": 46,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Model_Evaluation",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.84,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 0.32,
                "Data_Transform": 0.2,
                "Model_Train": 0.04,
                "Model_Evaluation": 1.0,
                "Model_Interpretation": 0.08,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.24,
                "Debug": 0.0,
                "Data_Export": 0.0,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {
                    "import ": 20,
                    ".show": 1
                },
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    "plt.plot": 2,
                    ".plot(": 4,
                    "matplotlib": 1,
                    "columns": 1
                },
                "Data_Transform": {
                    "ravel": 5
                },
                "Model_Train": {
                    "model": 1
                },
                "Model_Evaluation": {
                    "confusion_matrix": 4,
                    "f1_score": 6,
                    "precision": 5,
                    "recall": 5,
                    "classification_report": 2,
                    "model": 1,
                    "roc_curve": 2
                },
                "Model_Interpretation": {
                    "model": 1,
                    "predict_proba": 1
                },
                "Hyperparameter_Tuning": {},
                "Visualization": {
                    "plt.plot": 2,
                    ".plot(": 2,
                    "matplotlib": 1,
                    "pyplot": 1
                },
                "Debug": {},
                "Data_Export": {},
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    40,
                    2,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "1. Counfusion Matrix\n                   True Value 0  True Value 1\nPredicted Value 0           259            30\nPredicted Value 1             7           122\n\n2. Classification Report\n              precision    recall  f1-score   support\n\n           0       0.90      0.97      0.93       266\n           1       0.95      0.80      0.87       152\n\n    accuracy                           0.91       418\n   macro avg       0.92      0.89      0.90       418\nweighted avg       0.91      0.91      0.91       418\n\n",
                        "<Figure size 432x288 with 1 Axes>",
                        "3. Model Metric Sumamry\n - Accuracy Rate    : 91.148 %\n - Recall Rate      : 80.263 %\n - Precision Rate   : 94.574 %\n - Specificity Rate : 97.368 %\n - F1 Score         : 86.833 \n - ROC AUC          : 98.434 \n"
                    ]
                },
                "mc_idx": 46,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 40,
                "o_idx": 2
            }
        },
        {
            "source": "test_result= pd.DataFrame(pred_test)\ntest_result.columns = ['Survived']\npredict = test_result['Survived']\nId_No = df_test['PassengerId']\nsubmission = pd.DataFrame({'PassengerId': Id_No, \"Survived\": predict})\nsubmission['Survived'] = submission['Survived'].astype('Int64')\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()",
            "mc_idx": 48,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Exploratory_Data_Analysis",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0.0,
                "Data_Extraction": 0.0,
                "Exploratory_Data_Analysis": 1.0,
                "Data_Transform": 0.25,
                "Model_Train": 0.0,
                "Model_Evaluation": 0.0,
                "Model_Interpretation": 0.0,
                "Hyperparameter_Tuning": 0.0,
                "Visualization": 0.0,
                "Debug": 0.0,
                "Data_Export": 0.5,
                "Other": 0.0
            },
            "detailed_scores": {
                "Environment": {},
                "Data_Extraction": {},
                "Exploratory_Data_Analysis": {
                    ".head(": 1,
                    "head": 1,
                    "columns": 1,
                    ".head": 1
                },
                "Data_Transform": {
                    ".astype(": 1
                },
                "Model_Train": {},
                "Model_Evaluation": {},
                "Model_Interpretation": {},
                "Hyperparameter_Tuning": {},
                "Visualization": {},
                "Debug": {},
                "Data_Export": {
                    ".to_csv(": 1,
                    "to_csv": 1
                },
                "Other": {}
            },
            "emb": 0,
            "cell_type": "code",
            "image_path": [
                [
                    null,
                    41,
                    0,
                    null
                ]
            ],
            "output": {
                "source": {
                    "source": [
                        "   PassengerId  Survived\n0          892         0\n1          893         0\n2          894         0\n3          895         0\n4          896         1"
                    ]
                },
                "mc_idx": 48,
                "nb_idx": 0,
                "embedding": {},
                "classification": null,
                "keywords": {},
                "summary": null,
                "q_number": null,
                "duration": null,
                "exception": null,
                "class_probability": {},
                "detailed_scores": {},
                "emb": 0,
                "cell_type": "output",
                "c_idx": 41,
                "o_idx": 0
            }
        }
    ],
    "markdown_cells": [
        {
            "source": "#### \ucc98\uc74c\uc73c\ub85c kaggle\uc5d0 \ucc38\uc5ec\ud558\uc5ec \ucf54\ub4dc\ub97c \uc62c\ub9bd\ub2c8\ub2e4. \n#### \ub300\ud68c Rule\uacfc Scoring\uae30\uc900\uc5d0 \ub530\ub77c \ud0c0\uc774\ud0c0\ub2c9 \uc0dd\uc874\uc790 \uc608\uce21\uc758 Accuracy\ub97c \uac00\uc7a5 \ub192\uac8c \uc0b0\ucd9c\ud558\ub294 \ubaa8\ub378\uc744 \ub9cc\ub4e4 \uc608\uc815\uc785\ub2c8\ub2e4.    \n#### This is my first time participating in kaggle. \n#### In this code, I tried to make a model with high accuracy to predict the Titanic survivor.",
            "mc_idx": 0,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 1. \ubaa8\ub4c8 \ubd88\ub7ec\uc624\uae30 (Import module)\n \n#### \uc81c\uac00 \uac00\uc7a5 \uc790\uc8fc \uc4f0\ub294 \ubaa8\ub4c8\ub4e4\uc744 \ubd88\ub7ec\uc62c \uc608\uc815\uc785\ub2c8\ub2e4.\n#### It will load all the modules I use the most.",
            "mc_idx": 1,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 2. \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30(Read Dataset)",
            "mc_idx": 3,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 3. \ud0d0\uc0c9\uc801 \ub370\uc774\ud130 \ubd84\uc11d (EDA)\n#### \ud5a5\ud6c4 \ub2e8\uacc4\ubcc4\ub85c Competition \ucc38\uc5ec\ub97c \ud558\uba74\uc11c def \ud568\uc218\ub85c \ubb36\uc5b4\uc11c \uc790\ub3d9\uc73c\ub85c \ud560 \uc218 \uc788\ub3c4\ub85d \ub9cc\ub4e4 \uc608\uc815\uc785\ub2c8\ub2e4.\n#### \uc6b0\uc120 \ud574\ub2f9 \ub370\uc774\ud130\uc758 Column\ub4e4\uc774 \uc5b4\ub5a4 \uac83\uc774 \uc788\uace0, \ud1b5\uacc4\uc801\uc73c\ub85c \uc5b4\ub5a0\ud55c \uacb0\uacfc\uac00 \uc788\ub294\uc9c0 \ud655\uc778\ud560 \uac81\ub2c8\ub2e4.\n\n#### In the future, while participating in the competition step by step, \n#### I plan to bind it with the def function so that it can be done automatically.\n#### First, I will check what the columns of the data are and what the statistical results are.",
            "mc_idx": 5,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 4. \ubaa8\ub378\ub9c1(Modeling) \n#### \ud559\uc2b5 \uc9c4\ud589\uc744 \uc704\ud558\uc5ec Train, validation, test data\ub97c \ub098\ub204\uace0, HyperParameter\ub97c \ub123\uc5b4 \ud559\uc2b5\uae4c\uc9c0 \uc2dc\ud0a4\uaca0\uc2b5\ub2c8\ub2e4.\n#### In order to proceed with the training, we will divide the Train, validation, and test data, and put HyperParameter to train it.",
            "mc_idx": 32,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 5. \ubaa8\ub378 \uacb0\uacfc \ubd84\uc11d(Analyze model results)\n#### \ubaa8\ub378\uc744 \ud1b5\ud574 \ub098\uc628 train, validation, test \uacb0\uacfc\uce58(precision\uc5d0\uc11c\ubd80\ud130 F1-Score, AUROC\uae4c\uc9c0)\ub97c \uc0b0\uc2dd\uc744 \uc9c1\uc811 \uacc4\uc0b0\ud558\uc5ec \uacb0\uacfc\uac00 \ub098\uc624\ub3c4\ub85d \uad6c\ud604\ud574 \ubcf4\uc558\uc2b5\ub2c8\ub2e4.\n#### I tried to implement the results by directly calculating the train, validation, and test results (from precision to F1-Score, AUROC) through the model.",
            "mc_idx": 40,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        },
        {
            "source": "## 6.\uc81c\ucd9c\uc790\ub8cc \uc791\uc131(Prepare submission materials)",
            "mc_idx": 47,
            "nb_idx": 89,
            "embedding": {},
            "classification": "Markdown",
            "keywords": {},
            "summary": null,
            "q_number": null,
            "duration": null,
            "exception": null,
            "class_probability": {
                "Environment": 0,
                "Data_Extraction": 0,
                "Exploratory_Data_Analysis": 0,
                "Data_Transform": 0,
                "Model_Train": 0,
                "Model_Evaluation": 0,
                "Model_Interpretation": 0,
                "Hyperparameter_Tuning": 0,
                "Visualization": 0,
                "Debug": 0,
                "Data_Export": 0,
                "Other": 0
            },
            "detailed_scores": [
                {
                    "Environment": [],
                    "Data_Extraction": [],
                    "Exploratory_Data_Analysis": [],
                    "Data_Transform": [],
                    "Model_Train": [],
                    "Model_Evaluation": [],
                    "Model_Interpretation": [],
                    "Hyperparameter_Tuning": [],
                    "Visualization": [],
                    "Debug": [],
                    "Data_Export": [],
                    "Other": []
                }
            ],
            "emb": 0,
            "cell_type": "markdown"
        }
    ],
    "sim_matrix": [
        0.9407198429107666,
        0.9742619395256042,
        0.9750069379806519,
        0.9508082270622253,
        0.9668598771095276,
        0.9210156798362732,
        0.9404999613761902,
        0.9398330450057983,
        0.9290997982025146,
        0.9155154228210449,
        0.9683473110198975,
        0.9121661186218262,
        0.9349811673164368,
        0.9090986251831055,
        0.927161693572998,
        0.9749155640602112,
        0.9691025018692017,
        0.9210156798362732,
        0.9330286383628845,
        0.9756278395652771,
        0.9623284935951233,
        0.9398330450057983,
        0.9427179098129272,
        0.9168051481246948,
        0.934074342250824,
        0.9699630737304688,
        0.9739985466003418,
        0.9560412168502808,
        0.9522923827171326,
        0.9700482487678528,
        0.956358015537262,
        0.9720653295516968,
        0.9149994850158691,
        0.9662317633628845,
        0.9339269995689392,
        0.979711651802063,
        0.9339269995689392,
        0.9658918976783752,
        0.9332276582717896,
        0.9655508399009705,
        0.9693263173103333,
        0.9757803082466125,
        0.9459935426712036,
        0.9623284935951233,
        0.9290491938591003,
        0.9168051481246948,
        0.9321893453598022,
        0.9149994850158691,
        0.9436863660812378,
        0.9541423916816711,
        0.9209079742431641,
        0.979711651802063,
        0.9749155640602112,
        0.959714949131012,
        0.9819112420082092,
        0.9299312829971313,
        0.9518884420394897,
        0.9466794729232788,
        0.9408295750617981,
        0.9772646427154541,
        0.9431294202804565,
        0.9367815256118774,
        0.9113501310348511,
        0.9138182997703552,
        0.9742178320884705,
        0.9350090622901917,
        0.9753079414367676,
        0.7536294460296631,
        0.9404590129852295,
        0.9247670769691467,
        0.9573590159416199,
        0.938575267791748,
        0.9580845832824707,
        0.9085623621940613,
        0.9379620552062988,
        0.9686721563339233,
        0.9200257062911987,
        0.9521962404251099,
        0.9361678957939148,
        0.9112547039985657,
        0.9159841537475586,
        0.9269375205039978,
        0.9405480623245239,
        0.8994225859642029,
        0.985815703868866,
        0.9488438367843628,
        0.9332817196846008,
        0.9427179098129272,
        0.9560524225234985,
        1.0,
        0.9658918976783752,
        0.9756278395652771,
        0.9662317633628845,
        0.9417232275009155,
        0.9045238494873047,
        0.9680596590042114,
        0.9042326211929321,
        0.8810877799987793
    ],
    "cell_sim_matrix": [],
    "nb_order": [],
    "summary_data_VA": null
}